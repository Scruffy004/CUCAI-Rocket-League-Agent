Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 613.55594
Policy Entropy: 3.27640
Value Function Loss: 0.00520

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01545
Policy Update Magnitude: 0.19605
Value Function Update Magnitude: 0.21658

Collected Steps per Second: 7,686.79874
Overall Steps per Second: 4,146.61585

Timestep Collection Time: 6.50856
Timestep Consumption Time: 5.55670
PPO Batch Consumption Time: 2.20534
Total Iteration Time: 12.06526

Cumulative Model Updates: 81,188
Cumulative Timesteps: 677,161,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.34486
Policy Entropy: 3.27577
Value Function Loss: 0.00448

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.07204
Policy Update Magnitude: 0.41401
Value Function Update Magnitude: 0.46664

Collected Steps per Second: 20,433.72423
Overall Steps per Second: 11,573.51795

Timestep Collection Time: 2.44713
Timestep Consumption Time: 1.87342
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.32055

Cumulative Model Updates: 81,192
Cumulative Timesteps: 677,211,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 677211726...
Checkpoint 677211726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.20798
Policy Entropy: 3.26266
Value Function Loss: 0.00404

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.40652
Value Function Update Magnitude: 0.45688

Collected Steps per Second: 20,480.47620
Overall Steps per Second: 11,641.87553

Timestep Collection Time: 2.44174
Timestep Consumption Time: 1.85379
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.29553

Cumulative Model Updates: 81,196
Cumulative Timesteps: 677,261,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.82162
Policy Entropy: 3.26478
Value Function Loss: 0.00391

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.56124
Value Function Update Magnitude: 0.61181

Collected Steps per Second: 21,412.33541
Overall Steps per Second: 10,460.50730

Timestep Collection Time: 2.33520
Timestep Consumption Time: 2.44488
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.78007

Cumulative Model Updates: 81,202
Cumulative Timesteps: 677,311,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 677311736...
Checkpoint 677311736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.57569
Policy Entropy: 3.26308
Value Function Loss: 0.00384

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.54247
Value Function Update Magnitude: 0.59662

Collected Steps per Second: 21,250.65471
Overall Steps per Second: 10,323.23545

Timestep Collection Time: 2.35296
Timestep Consumption Time: 2.49067
PPO Batch Consumption Time: 0.30088
Total Iteration Time: 4.84364

Cumulative Model Updates: 81,208
Cumulative Timesteps: 677,361,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.84005
Policy Entropy: 3.28026
Value Function Loss: 0.00388

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10306
Policy Update Magnitude: 0.53446
Value Function Update Magnitude: 0.60796

Collected Steps per Second: 21,216.45026
Overall Steps per Second: 10,488.40509

Timestep Collection Time: 2.35694
Timestep Consumption Time: 2.41080
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.76774

Cumulative Model Updates: 81,214
Cumulative Timesteps: 677,411,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 677411744...
Checkpoint 677411744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.12753
Policy Entropy: 3.29089
Value Function Loss: 0.00370

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.52984
Value Function Update Magnitude: 0.59123

Collected Steps per Second: 21,288.67050
Overall Steps per Second: 10,407.30616

Timestep Collection Time: 2.34867
Timestep Consumption Time: 2.45565
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.80432

Cumulative Model Updates: 81,220
Cumulative Timesteps: 677,461,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.18730
Policy Entropy: 3.29599
Value Function Loss: 0.00390

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.52904
Value Function Update Magnitude: 0.59095

Collected Steps per Second: 21,421.06181
Overall Steps per Second: 10,479.21284

Timestep Collection Time: 2.33424
Timestep Consumption Time: 2.43730
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.77154

Cumulative Model Updates: 81,226
Cumulative Timesteps: 677,511,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 677511746...
Checkpoint 677511746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 748.25084
Policy Entropy: 3.28643
Value Function Loss: 0.00373

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.52996
Value Function Update Magnitude: 0.59545

Collected Steps per Second: 21,109.90639
Overall Steps per Second: 10,330.51811

Timestep Collection Time: 2.36875
Timestep Consumption Time: 2.47167
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.84042

Cumulative Model Updates: 81,232
Cumulative Timesteps: 677,561,750

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.59589
Policy Entropy: 3.28461
Value Function Loss: 0.00397

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.53030
Value Function Update Magnitude: 0.59785

Collected Steps per Second: 22,239.95344
Overall Steps per Second: 10,403.55121

Timestep Collection Time: 2.24902
Timestep Consumption Time: 2.55877
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.80778

Cumulative Model Updates: 81,238
Cumulative Timesteps: 677,611,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 677611768...
Checkpoint 677611768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.85223
Policy Entropy: 3.28219
Value Function Loss: 0.00390

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07982
Policy Update Magnitude: 0.53664
Value Function Update Magnitude: 0.61652

Collected Steps per Second: 21,713.02393
Overall Steps per Second: 10,426.46454

Timestep Collection Time: 2.30286
Timestep Consumption Time: 2.49282
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.79568

Cumulative Model Updates: 81,244
Cumulative Timesteps: 677,661,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.87784
Policy Entropy: 3.28845
Value Function Loss: 0.00389

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.53544
Value Function Update Magnitude: 0.61967

Collected Steps per Second: 21,137.81924
Overall Steps per Second: 10,277.32439

Timestep Collection Time: 2.36600
Timestep Consumption Time: 2.50025
PPO Batch Consumption Time: 0.29967
Total Iteration Time: 4.86625

Cumulative Model Updates: 81,250
Cumulative Timesteps: 677,711,782

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 677711782...
Checkpoint 677711782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.03135
Policy Entropy: 3.28781
Value Function Loss: 0.00388

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.52990
Value Function Update Magnitude: 0.61084

Collected Steps per Second: 20,614.18114
Overall Steps per Second: 10,234.04832

Timestep Collection Time: 2.42726
Timestep Consumption Time: 2.46191
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.88917

Cumulative Model Updates: 81,256
Cumulative Timesteps: 677,761,818

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.92477
Policy Entropy: 3.30638
Value Function Loss: 0.00408

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08559
Policy Update Magnitude: 0.53240
Value Function Update Magnitude: 0.61967

Collected Steps per Second: 21,435.90576
Overall Steps per Second: 10,371.76765

Timestep Collection Time: 2.33393
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.29935
Total Iteration Time: 4.82367

Cumulative Model Updates: 81,262
Cumulative Timesteps: 677,811,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 677811848...
Checkpoint 677811848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.73580
Policy Entropy: 3.30279
Value Function Loss: 0.00412

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.53953
Value Function Update Magnitude: 0.60876

Collected Steps per Second: 21,124.86573
Overall Steps per Second: 10,430.28339

Timestep Collection Time: 2.36745
Timestep Consumption Time: 2.42744
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.79488

Cumulative Model Updates: 81,268
Cumulative Timesteps: 677,861,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851.89960
Policy Entropy: 3.31505
Value Function Loss: 0.00409

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.59469

Collected Steps per Second: 21,212.14061
Overall Steps per Second: 10,369.47031

Timestep Collection Time: 2.35846
Timestep Consumption Time: 2.46609
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.82455

Cumulative Model Updates: 81,274
Cumulative Timesteps: 677,911,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 677911888...
Checkpoint 677911888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.05042
Policy Entropy: 3.28800
Value Function Loss: 0.00388

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08853
Policy Update Magnitude: 0.53414
Value Function Update Magnitude: 0.59642

Collected Steps per Second: 21,090.64691
Overall Steps per Second: 10,435.28876

Timestep Collection Time: 2.37195
Timestep Consumption Time: 2.42197
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.79393

Cumulative Model Updates: 81,280
Cumulative Timesteps: 677,961,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.48045
Policy Entropy: 3.29635
Value Function Loss: 0.00405

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.53736
Value Function Update Magnitude: 0.61040

Collected Steps per Second: 21,345.50615
Overall Steps per Second: 10,481.70750

Timestep Collection Time: 2.34288
Timestep Consumption Time: 2.42829
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.77117

Cumulative Model Updates: 81,286
Cumulative Timesteps: 678,011,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 678011924...
Checkpoint 678011924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.67701
Policy Entropy: 3.28072
Value Function Loss: 0.00403

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.54012
Value Function Update Magnitude: 0.62759

Collected Steps per Second: 22,146.50563
Overall Steps per Second: 10,484.60278

Timestep Collection Time: 2.25869
Timestep Consumption Time: 2.51231
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.77100

Cumulative Model Updates: 81,292
Cumulative Timesteps: 678,061,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789.85557
Policy Entropy: 3.28563
Value Function Loss: 0.00400

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10953
Policy Update Magnitude: 0.53245
Value Function Update Magnitude: 0.62595

Collected Steps per Second: 22,625.65947
Overall Steps per Second: 10,563.96349

Timestep Collection Time: 2.21059
Timestep Consumption Time: 2.52400
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.73459

Cumulative Model Updates: 81,298
Cumulative Timesteps: 678,111,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 678111962...
Checkpoint 678111962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.79075
Policy Entropy: 3.25846
Value Function Loss: 0.00389

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.52270
Value Function Update Magnitude: 0.59908

Collected Steps per Second: 20,912.27784
Overall Steps per Second: 10,217.58799

Timestep Collection Time: 2.39113
Timestep Consumption Time: 2.50278
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.89391

Cumulative Model Updates: 81,304
Cumulative Timesteps: 678,161,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.03726
Policy Entropy: 3.24878
Value Function Loss: 0.00391

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.53071
Value Function Update Magnitude: 0.59115

Collected Steps per Second: 21,883.93065
Overall Steps per Second: 10,424.21908

Timestep Collection Time: 2.28588
Timestep Consumption Time: 2.51295
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.79882

Cumulative Model Updates: 81,310
Cumulative Timesteps: 678,211,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 678211990...
Checkpoint 678211990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.93214
Policy Entropy: 3.23370
Value Function Loss: 0.00414

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.53661
Value Function Update Magnitude: 0.58547

Collected Steps per Second: 21,410.59994
Overall Steps per Second: 10,419.35563

Timestep Collection Time: 2.33632
Timestep Consumption Time: 2.46455
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.80087

Cumulative Model Updates: 81,316
Cumulative Timesteps: 678,262,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.03474
Policy Entropy: 3.24260
Value Function Loss: 0.00418

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.54566
Value Function Update Magnitude: 0.58766

Collected Steps per Second: 22,413.88371
Overall Steps per Second: 10,489.42480

Timestep Collection Time: 2.23219
Timestep Consumption Time: 2.53757
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.76976

Cumulative Model Updates: 81,322
Cumulative Timesteps: 678,312,044

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 678312044...
Checkpoint 678312044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.69408
Policy Entropy: 3.25161
Value Function Loss: 0.00420

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.54533
Value Function Update Magnitude: 0.60100

Collected Steps per Second: 21,112.60195
Overall Steps per Second: 10,299.81131

Timestep Collection Time: 2.36854
Timestep Consumption Time: 2.48650
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.85504

Cumulative Model Updates: 81,328
Cumulative Timesteps: 678,362,050

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.88730
Policy Entropy: 3.26813
Value Function Loss: 0.00414

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.53814
Value Function Update Magnitude: 0.61235

Collected Steps per Second: 21,440.08688
Overall Steps per Second: 10,489.59906

Timestep Collection Time: 2.33320
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.76891

Cumulative Model Updates: 81,334
Cumulative Timesteps: 678,412,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 678412074...
Checkpoint 678412074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.41073
Policy Entropy: 3.26497
Value Function Loss: 0.00418

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.53897
Value Function Update Magnitude: 0.62103

Collected Steps per Second: 21,839.61600
Overall Steps per Second: 10,279.73100

Timestep Collection Time: 2.29116
Timestep Consumption Time: 2.57648
PPO Batch Consumption Time: 0.29925
Total Iteration Time: 4.86764

Cumulative Model Updates: 81,340
Cumulative Timesteps: 678,462,112

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.17118
Policy Entropy: 3.25446
Value Function Loss: 0.00413

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10658
Policy Update Magnitude: 0.54408
Value Function Update Magnitude: 0.62197

Collected Steps per Second: 21,823.50123
Overall Steps per Second: 10,447.52291

Timestep Collection Time: 2.29239
Timestep Consumption Time: 2.49611
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.78850

Cumulative Model Updates: 81,346
Cumulative Timesteps: 678,512,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 678512140...
Checkpoint 678512140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.05080
Policy Entropy: 3.26610
Value Function Loss: 0.00420

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.54127
Value Function Update Magnitude: 0.62278

Collected Steps per Second: 21,809.95977
Overall Steps per Second: 10,292.32025

Timestep Collection Time: 2.29308
Timestep Consumption Time: 2.56608
PPO Batch Consumption Time: 0.30129
Total Iteration Time: 4.85916

Cumulative Model Updates: 81,352
Cumulative Timesteps: 678,562,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.36382
Policy Entropy: 3.27069
Value Function Loss: 0.00401

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.53878
Value Function Update Magnitude: 0.62894

Collected Steps per Second: 21,853.95173
Overall Steps per Second: 10,428.09468

Timestep Collection Time: 2.28828
Timestep Consumption Time: 2.50723
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.79551

Cumulative Model Updates: 81,358
Cumulative Timesteps: 678,612,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 678612160...
Checkpoint 678612160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.37443
Policy Entropy: 3.28481
Value Function Loss: 0.00376

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.53508
Value Function Update Magnitude: 0.60989

Collected Steps per Second: 21,873.38013
Overall Steps per Second: 10,302.40849

Timestep Collection Time: 2.28625
Timestep Consumption Time: 2.56776
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 4.85401

Cumulative Model Updates: 81,364
Cumulative Timesteps: 678,662,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.94284
Policy Entropy: 3.28894
Value Function Loss: 0.00389

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.52497
Value Function Update Magnitude: 0.59830

Collected Steps per Second: 22,940.17633
Overall Steps per Second: 10,657.19103

Timestep Collection Time: 2.18063
Timestep Consumption Time: 2.51329
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.69392

Cumulative Model Updates: 81,370
Cumulative Timesteps: 678,712,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 678712192...
Checkpoint 678712192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.06710
Policy Entropy: 3.29064
Value Function Loss: 0.00399

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.52115
Value Function Update Magnitude: 0.59862

Collected Steps per Second: 22,113.22489
Overall Steps per Second: 10,345.74913

Timestep Collection Time: 2.26218
Timestep Consumption Time: 2.57305
PPO Batch Consumption Time: 0.30043
Total Iteration Time: 4.83522

Cumulative Model Updates: 81,376
Cumulative Timesteps: 678,762,216

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.86241
Policy Entropy: 3.28168
Value Function Loss: 0.00425

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.53716
Value Function Update Magnitude: 0.61484

Collected Steps per Second: 22,220.05639
Overall Steps per Second: 10,441.94586

Timestep Collection Time: 2.25112
Timestep Consumption Time: 2.53918
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.79029

Cumulative Model Updates: 81,382
Cumulative Timesteps: 678,812,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 678812236...
Checkpoint 678812236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 896.28203
Policy Entropy: 3.27606
Value Function Loss: 0.00437

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.55320
Value Function Update Magnitude: 0.62883

Collected Steps per Second: 22,134.51216
Overall Steps per Second: 10,405.89069

Timestep Collection Time: 2.25982
Timestep Consumption Time: 2.54707
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.80689

Cumulative Model Updates: 81,388
Cumulative Timesteps: 678,862,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.31307
Policy Entropy: 3.28036
Value Function Loss: 0.00451

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.67126

Collected Steps per Second: 22,339.66313
Overall Steps per Second: 10,468.11477

Timestep Collection Time: 2.23844
Timestep Consumption Time: 2.53854
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.77698

Cumulative Model Updates: 81,394
Cumulative Timesteps: 678,912,262

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 678912262...
Checkpoint 678912262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.35721
Policy Entropy: 3.28662
Value Function Loss: 0.00434

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.56839
Value Function Update Magnitude: 0.67357

Collected Steps per Second: 22,353.96474
Overall Steps per Second: 10,457.24367

Timestep Collection Time: 2.23728
Timestep Consumption Time: 2.54525
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.78252

Cumulative Model Updates: 81,400
Cumulative Timesteps: 678,962,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.49108
Policy Entropy: 3.26696
Value Function Loss: 0.00425

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.56067
Value Function Update Magnitude: 0.65272

Collected Steps per Second: 22,105.57649
Overall Steps per Second: 10,377.95738

Timestep Collection Time: 2.26260
Timestep Consumption Time: 2.55685
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.81945

Cumulative Model Updates: 81,406
Cumulative Timesteps: 679,012,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 679012290...
Checkpoint 679012290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.38298
Policy Entropy: 3.26850
Value Function Loss: 0.00406

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.54842
Value Function Update Magnitude: 0.63890

Collected Steps per Second: 21,886.98120
Overall Steps per Second: 10,301.83338

Timestep Collection Time: 2.28556
Timestep Consumption Time: 2.57028
PPO Batch Consumption Time: 0.30098
Total Iteration Time: 4.85583

Cumulative Model Updates: 81,412
Cumulative Timesteps: 679,062,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.66155
Policy Entropy: 3.27745
Value Function Loss: 0.00376

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.62761

Collected Steps per Second: 22,022.27177
Overall Steps per Second: 10,452.62618

Timestep Collection Time: 2.27097
Timestep Consumption Time: 2.51366
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.78463

Cumulative Model Updates: 81,418
Cumulative Timesteps: 679,112,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 679112326...
Checkpoint 679112326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.66676
Policy Entropy: 3.28761
Value Function Loss: 0.00378

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.08007
Policy Update Magnitude: 0.53362
Value Function Update Magnitude: 0.63484

Collected Steps per Second: 21,424.03696
Overall Steps per Second: 10,230.31038

Timestep Collection Time: 2.33560
Timestep Consumption Time: 2.55555
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 4.89115

Cumulative Model Updates: 81,424
Cumulative Timesteps: 679,162,364

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.46110
Policy Entropy: 3.28664
Value Function Loss: 0.00356

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08279
Policy Update Magnitude: 0.53083
Value Function Update Magnitude: 0.63639

Collected Steps per Second: 22,037.27687
Overall Steps per Second: 10,472.28410

Timestep Collection Time: 2.27024
Timestep Consumption Time: 2.50713
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.77737

Cumulative Model Updates: 81,430
Cumulative Timesteps: 679,212,394

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 679212394...
Checkpoint 679212394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.26132
Policy Entropy: 3.26778
Value Function Loss: 0.00392

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.53353
Value Function Update Magnitude: 0.62430

Collected Steps per Second: 21,862.60900
Overall Steps per Second: 10,391.36287

Timestep Collection Time: 2.28866
Timestep Consumption Time: 2.52650
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.81515

Cumulative Model Updates: 81,436
Cumulative Timesteps: 679,262,430

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.48343
Policy Entropy: 3.26225
Value Function Loss: 0.00376

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.53079
Value Function Update Magnitude: 0.59422

Collected Steps per Second: 22,267.53371
Overall Steps per Second: 10,328.94735

Timestep Collection Time: 2.24677
Timestep Consumption Time: 2.59690
PPO Batch Consumption Time: 0.29940
Total Iteration Time: 4.84367

Cumulative Model Updates: 81,442
Cumulative Timesteps: 679,312,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 679312460...
Checkpoint 679312460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.39391
Policy Entropy: 3.25666
Value Function Loss: 0.00387

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.51893
Value Function Update Magnitude: 0.57034

Collected Steps per Second: 21,883.08922
Overall Steps per Second: 10,519.92581

Timestep Collection Time: 2.28587
Timestep Consumption Time: 2.46910
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.75498

Cumulative Model Updates: 81,448
Cumulative Timesteps: 679,362,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.01804
Policy Entropy: 3.26867
Value Function Loss: 0.00362

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.50965
Value Function Update Magnitude: 0.54497

Collected Steps per Second: 22,371.24256
Overall Steps per Second: 10,479.28951

Timestep Collection Time: 2.23546
Timestep Consumption Time: 2.53681
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.77227

Cumulative Model Updates: 81,454
Cumulative Timesteps: 679,412,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 679412492...
Checkpoint 679412492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.72065
Policy Entropy: 3.27680
Value Function Loss: 0.00368

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.51329
Value Function Update Magnitude: 0.55133

Collected Steps per Second: 22,612.12607
Overall Steps per Second: 10,565.54953

Timestep Collection Time: 2.21147
Timestep Consumption Time: 2.52146
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.73293

Cumulative Model Updates: 81,460
Cumulative Timesteps: 679,462,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.18845
Policy Entropy: 3.27319
Value Function Loss: 0.00387

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.52014
Value Function Update Magnitude: 0.56959

Collected Steps per Second: 22,021.88794
Overall Steps per Second: 10,535.78492

Timestep Collection Time: 2.27110
Timestep Consumption Time: 2.47596
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.74706

Cumulative Model Updates: 81,466
Cumulative Timesteps: 679,512,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 679512512...
Checkpoint 679512512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.06571
Policy Entropy: 3.27056
Value Function Loss: 0.00387

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.51770
Value Function Update Magnitude: 0.58706

Collected Steps per Second: 22,316.66428
Overall Steps per Second: 10,558.63251

Timestep Collection Time: 2.24137
Timestep Consumption Time: 2.49598
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.73736

Cumulative Model Updates: 81,472
Cumulative Timesteps: 679,562,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.29985
Policy Entropy: 3.25324
Value Function Loss: 0.00412

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.52296
Value Function Update Magnitude: 0.59166

Collected Steps per Second: 22,307.22989
Overall Steps per Second: 10,561.67004

Timestep Collection Time: 2.24241
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.73618

Cumulative Model Updates: 81,478
Cumulative Timesteps: 679,612,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 679612554...
Checkpoint 679612554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.61915
Policy Entropy: 3.25931
Value Function Loss: 0.00408

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.52828
Value Function Update Magnitude: 0.59357

Collected Steps per Second: 22,099.76771
Overall Steps per Second: 10,396.12542

Timestep Collection Time: 2.26382
Timestep Consumption Time: 2.54855
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.81237

Cumulative Model Updates: 81,484
Cumulative Timesteps: 679,662,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.81277
Policy Entropy: 3.26280
Value Function Loss: 0.00414

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.53535
Value Function Update Magnitude: 0.60779

Collected Steps per Second: 21,766.32021
Overall Steps per Second: 10,288.41259

Timestep Collection Time: 2.29722
Timestep Consumption Time: 2.56281
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 4.86003

Cumulative Model Updates: 81,490
Cumulative Timesteps: 679,712,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 679712586...
Checkpoint 679712586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 890.27055
Policy Entropy: 3.25015
Value Function Loss: 0.00414

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.53826
Value Function Update Magnitude: 0.62495

Collected Steps per Second: 21,607.51481
Overall Steps per Second: 10,333.47972

Timestep Collection Time: 2.31577
Timestep Consumption Time: 2.52655
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.84232

Cumulative Model Updates: 81,496
Cumulative Timesteps: 679,762,624

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.99603
Policy Entropy: 3.23513
Value Function Loss: 0.00421

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.55365
Value Function Update Magnitude: 0.63466

Collected Steps per Second: 22,177.18198
Overall Steps per Second: 10,408.21667

Timestep Collection Time: 2.25502
Timestep Consumption Time: 2.54984
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.80486

Cumulative Model Updates: 81,502
Cumulative Timesteps: 679,812,634

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 679812634...
Checkpoint 679812634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.89212
Policy Entropy: 3.21518
Value Function Loss: 0.00416

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.56122
Value Function Update Magnitude: 0.63747

Collected Steps per Second: 22,185.86125
Overall Steps per Second: 10,524.98612

Timestep Collection Time: 2.25486
Timestep Consumption Time: 2.49821
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.75307

Cumulative Model Updates: 81,508
Cumulative Timesteps: 679,862,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.84662
Policy Entropy: 3.24507
Value Function Loss: 0.00410

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.54206
Value Function Update Magnitude: 0.63033

Collected Steps per Second: 21,901.08245
Overall Steps per Second: 10,362.19832

Timestep Collection Time: 2.28354
Timestep Consumption Time: 2.54285
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.82639

Cumulative Model Updates: 81,514
Cumulative Timesteps: 679,912,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 679912672...
Checkpoint 679912672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.24574
Policy Entropy: 3.26427
Value Function Loss: 0.00391

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.59091

Collected Steps per Second: 22,088.22326
Overall Steps per Second: 10,314.40099

Timestep Collection Time: 2.26483
Timestep Consumption Time: 2.58529
PPO Batch Consumption Time: 0.30040
Total Iteration Time: 4.85011

Cumulative Model Updates: 81,520
Cumulative Timesteps: 679,962,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.22533
Policy Entropy: 3.27487
Value Function Loss: 0.00382

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.52373
Value Function Update Magnitude: 0.57104

Collected Steps per Second: 22,268.89918
Overall Steps per Second: 10,442.53237

Timestep Collection Time: 2.24636
Timestep Consumption Time: 2.54405
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.79041

Cumulative Model Updates: 81,526
Cumulative Timesteps: 680,012,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 680012722...
Checkpoint 680012722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.38472
Policy Entropy: 3.27498
Value Function Loss: 0.00387

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10007
Policy Update Magnitude: 0.52400
Value Function Update Magnitude: 0.58099

Collected Steps per Second: 22,262.72607
Overall Steps per Second: 10,502.03966

Timestep Collection Time: 2.24654
Timestep Consumption Time: 2.51578
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.76231

Cumulative Model Updates: 81,532
Cumulative Timesteps: 680,062,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.82548
Policy Entropy: 3.27209
Value Function Loss: 0.00399

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.52553
Value Function Update Magnitude: 0.60993

Collected Steps per Second: 22,120.02177
Overall Steps per Second: 10,528.60471

Timestep Collection Time: 2.26094
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.75011

Cumulative Model Updates: 81,538
Cumulative Timesteps: 680,112,748

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 680112748...
Checkpoint 680112748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.30060
Policy Entropy: 3.26734
Value Function Loss: 0.00393

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.52598
Value Function Update Magnitude: 0.62735

Collected Steps per Second: 20,509.84473
Overall Steps per Second: 9,945.29313

Timestep Collection Time: 2.43815
Timestep Consumption Time: 2.58996
PPO Batch Consumption Time: 0.29887
Total Iteration Time: 5.02811

Cumulative Model Updates: 81,544
Cumulative Timesteps: 680,162,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.49996
Policy Entropy: 3.26844
Value Function Loss: 0.00374

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.52077
Value Function Update Magnitude: 0.61189

Collected Steps per Second: 21,575.58160
Overall Steps per Second: 10,270.28228

Timestep Collection Time: 2.31855
Timestep Consumption Time: 2.55221
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.87075

Cumulative Model Updates: 81,550
Cumulative Timesteps: 680,212,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 680212778...
Checkpoint 680212778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.36437
Policy Entropy: 3.26345
Value Function Loss: 0.00368

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.11101
Policy Update Magnitude: 0.51330
Value Function Update Magnitude: 0.59135

Collected Steps per Second: 20,544.93788
Overall Steps per Second: 9,873.06666

Timestep Collection Time: 2.43447
Timestep Consumption Time: 2.63143
PPO Batch Consumption Time: 0.30006
Total Iteration Time: 5.06590

Cumulative Model Updates: 81,556
Cumulative Timesteps: 680,262,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.10693
Policy Entropy: 3.26805
Value Function Loss: 0.00390

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.52260
Value Function Update Magnitude: 0.59833

Collected Steps per Second: 21,020.73541
Overall Steps per Second: 10,065.02259

Timestep Collection Time: 2.37936
Timestep Consumption Time: 2.58992
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.96929

Cumulative Model Updates: 81,562
Cumulative Timesteps: 680,312,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 680312810...
Checkpoint 680312810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.21907
Policy Entropy: 3.27449
Value Function Loss: 0.00410

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.53225
Value Function Update Magnitude: 0.62265

Collected Steps per Second: 21,383.12374
Overall Steps per Second: 10,181.65933

Timestep Collection Time: 2.33829
Timestep Consumption Time: 2.57250
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.91079

Cumulative Model Updates: 81,568
Cumulative Timesteps: 680,362,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.02396
Policy Entropy: 3.27246
Value Function Loss: 0.00405

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.53515
Value Function Update Magnitude: 0.62790

Collected Steps per Second: 22,033.66198
Overall Steps per Second: 10,523.88578

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.48254
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.75243

Cumulative Model Updates: 81,574
Cumulative Timesteps: 680,412,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 680412824...
Checkpoint 680412824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.36260
Policy Entropy: 3.27708
Value Function Loss: 0.00386

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.53233
Value Function Update Magnitude: 0.63523

Collected Steps per Second: 21,719.07735
Overall Steps per Second: 10,479.28863

Timestep Collection Time: 2.30258
Timestep Consumption Time: 2.46969
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.77227

Cumulative Model Updates: 81,580
Cumulative Timesteps: 680,462,834

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.17088
Policy Entropy: 3.28521
Value Function Loss: 0.00400

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.53158
Value Function Update Magnitude: 0.64328

Collected Steps per Second: 21,222.29016
Overall Steps per Second: 10,302.42013

Timestep Collection Time: 2.35601
Timestep Consumption Time: 2.49722
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.85323

Cumulative Model Updates: 81,586
Cumulative Timesteps: 680,512,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 680512834...
Checkpoint 680512834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.90284
Policy Entropy: 3.30376
Value Function Loss: 0.00381

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.52967
Value Function Update Magnitude: 0.64909

Collected Steps per Second: 21,889.88733
Overall Steps per Second: 10,442.96942

Timestep Collection Time: 2.28516
Timestep Consumption Time: 2.50485
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.79002

Cumulative Model Updates: 81,592
Cumulative Timesteps: 680,562,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.40940
Policy Entropy: 3.30738
Value Function Loss: 0.00372

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.51744
Value Function Update Magnitude: 0.62353

Collected Steps per Second: 21,949.09317
Overall Steps per Second: 10,433.35695

Timestep Collection Time: 2.27827
Timestep Consumption Time: 2.51462
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.79290

Cumulative Model Updates: 81,598
Cumulative Timesteps: 680,612,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 680612862...
Checkpoint 680612862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.79743
Policy Entropy: 3.30107
Value Function Loss: 0.00382

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07818
Policy Update Magnitude: 0.50541
Value Function Update Magnitude: 0.58683

Collected Steps per Second: 21,757.57655
Overall Steps per Second: 10,341.40150

Timestep Collection Time: 2.29823
Timestep Consumption Time: 2.53709
PPO Batch Consumption Time: 0.29872
Total Iteration Time: 4.83532

Cumulative Model Updates: 81,604
Cumulative Timesteps: 680,662,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.14344
Policy Entropy: 3.27402
Value Function Loss: 0.00398

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.52205
Value Function Update Magnitude: 0.57102

Collected Steps per Second: 22,193.73648
Overall Steps per Second: 10,385.07543

Timestep Collection Time: 2.25415
Timestep Consumption Time: 2.56315
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.81730

Cumulative Model Updates: 81,610
Cumulative Timesteps: 680,712,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 680712894...
Checkpoint 680712894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611.98338
Policy Entropy: 3.26995
Value Function Loss: 0.00441

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11702
Policy Update Magnitude: 0.53623
Value Function Update Magnitude: 0.57745

Collected Steps per Second: 22,039.15715
Overall Steps per Second: 10,554.73202

Timestep Collection Time: 2.26869
Timestep Consumption Time: 2.46852
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.73721

Cumulative Model Updates: 81,616
Cumulative Timesteps: 680,762,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.75854
Policy Entropy: 3.26747
Value Function Loss: 0.00416

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12175
Policy Update Magnitude: 0.53455
Value Function Update Magnitude: 0.59712

Collected Steps per Second: 22,562.89690
Overall Steps per Second: 10,521.93623

Timestep Collection Time: 2.21603
Timestep Consumption Time: 2.53595
PPO Batch Consumption Time: 0.29929
Total Iteration Time: 4.75198

Cumulative Model Updates: 81,622
Cumulative Timesteps: 680,812,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 680812894...
Checkpoint 680812894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.52582
Policy Entropy: 3.28336
Value Function Loss: 0.00385

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.52530
Value Function Update Magnitude: 0.59095

Collected Steps per Second: 22,305.67844
Overall Steps per Second: 10,575.67464

Timestep Collection Time: 2.24176
Timestep Consumption Time: 2.48645
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.72821

Cumulative Model Updates: 81,628
Cumulative Timesteps: 680,862,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.85930
Policy Entropy: 3.28809
Value Function Loss: 0.00364

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08788
Policy Update Magnitude: 0.51534
Value Function Update Magnitude: 0.57773

Collected Steps per Second: 22,326.53053
Overall Steps per Second: 10,540.96817

Timestep Collection Time: 2.24047
Timestep Consumption Time: 2.50501
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.74548

Cumulative Model Updates: 81,634
Cumulative Timesteps: 680,912,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 680912920...
Checkpoint 680912920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.00994
Policy Entropy: 3.29090
Value Function Loss: 0.00352

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.07512
Policy Update Magnitude: 0.51486
Value Function Update Magnitude: 0.58048

Collected Steps per Second: 22,152.17591
Overall Steps per Second: 10,546.52123

Timestep Collection Time: 2.25720
Timestep Consumption Time: 2.48388
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.74109

Cumulative Model Updates: 81,640
Cumulative Timesteps: 680,962,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.31830
Policy Entropy: 3.28205
Value Function Loss: 0.00371

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07734
Policy Update Magnitude: 0.52170
Value Function Update Magnitude: 0.59070

Collected Steps per Second: 22,104.72725
Overall Steps per Second: 10,561.61694

Timestep Collection Time: 2.26196
Timestep Consumption Time: 2.47216
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.73412

Cumulative Model Updates: 81,646
Cumulative Timesteps: 681,012,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 681012922...
Checkpoint 681012922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.84322
Policy Entropy: 3.26429
Value Function Loss: 0.00398

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08349
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.62538

Collected Steps per Second: 21,989.64995
Overall Steps per Second: 10,481.72502

Timestep Collection Time: 2.27398
Timestep Consumption Time: 2.49661
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.77059

Cumulative Model Updates: 81,652
Cumulative Timesteps: 681,062,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.76249
Policy Entropy: 3.25573
Value Function Loss: 0.00412

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.64424

Collected Steps per Second: 22,199.04188
Overall Steps per Second: 10,530.78814

Timestep Collection Time: 2.25325
Timestep Consumption Time: 2.49663
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.74988

Cumulative Model Updates: 81,658
Cumulative Timesteps: 681,112,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 681112946...
Checkpoint 681112946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.88975
Policy Entropy: 3.25803
Value Function Loss: 0.00386

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.07535
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.63930

Collected Steps per Second: 21,621.15343
Overall Steps per Second: 10,341.79440

Timestep Collection Time: 2.31366
Timestep Consumption Time: 2.52341
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 4.83707

Cumulative Model Updates: 81,664
Cumulative Timesteps: 681,162,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.46207
Policy Entropy: 3.25553
Value Function Loss: 0.00394

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.60077

Collected Steps per Second: 22,116.84103
Overall Steps per Second: 10,390.59067

Timestep Collection Time: 2.26108
Timestep Consumption Time: 2.55173
PPO Batch Consumption Time: 0.30173
Total Iteration Time: 4.81282

Cumulative Model Updates: 81,670
Cumulative Timesteps: 681,212,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 681212978...
Checkpoint 681212978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.54988
Policy Entropy: 3.27428
Value Function Loss: 0.00419

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.54520
Value Function Update Magnitude: 0.59017

Collected Steps per Second: 21,368.89535
Overall Steps per Second: 10,284.20231

Timestep Collection Time: 2.34050
Timestep Consumption Time: 2.52268
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.86319

Cumulative Model Updates: 81,676
Cumulative Timesteps: 681,262,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 873.58521
Policy Entropy: 3.26823
Value Function Loss: 0.00422

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.53848
Value Function Update Magnitude: 0.60466

Collected Steps per Second: 22,357.81400
Overall Steps per Second: 10,496.45411

Timestep Collection Time: 2.23653
Timestep Consumption Time: 2.52736
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.76389

Cumulative Model Updates: 81,682
Cumulative Timesteps: 681,312,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 681312996...
Checkpoint 681312996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.65642
Policy Entropy: 3.27073
Value Function Loss: 0.00412

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.54374
Value Function Update Magnitude: 0.61706

Collected Steps per Second: 22,059.25560
Overall Steps per Second: 10,501.34934

Timestep Collection Time: 2.26680
Timestep Consumption Time: 2.49487
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.76167

Cumulative Model Updates: 81,688
Cumulative Timesteps: 681,363,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.84654
Policy Entropy: 3.25968
Value Function Loss: 0.00418

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.62923

Collected Steps per Second: 22,441.45491
Overall Steps per Second: 10,478.99568

Timestep Collection Time: 2.22829
Timestep Consumption Time: 2.54374
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.77202

Cumulative Model Updates: 81,694
Cumulative Timesteps: 681,413,006

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 681413006...
Checkpoint 681413006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.10583
Policy Entropy: 3.27077
Value Function Loss: 0.00425

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.55165
Value Function Update Magnitude: 0.64665

Collected Steps per Second: 22,087.43195
Overall Steps per Second: 10,522.04738

Timestep Collection Time: 2.26373
Timestep Consumption Time: 2.48820
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.75193

Cumulative Model Updates: 81,700
Cumulative Timesteps: 681,463,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.60586
Policy Entropy: 3.26465
Value Function Loss: 0.00436

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.55345
Value Function Update Magnitude: 0.64166

Collected Steps per Second: 22,534.73418
Overall Steps per Second: 10,611.12963

Timestep Collection Time: 2.22004
Timestep Consumption Time: 2.49463
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.71467

Cumulative Model Updates: 81,706
Cumulative Timesteps: 681,513,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 681513034...
Checkpoint 681513034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.36446
Policy Entropy: 3.28949
Value Function Loss: 0.00390

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.54540
Value Function Update Magnitude: 0.61207

Collected Steps per Second: 22,319.13879
Overall Steps per Second: 10,547.37302

Timestep Collection Time: 2.24113
Timestep Consumption Time: 2.50129
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.74241

Cumulative Model Updates: 81,712
Cumulative Timesteps: 681,563,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.85940
Policy Entropy: 3.27785
Value Function Loss: 0.00388

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.53325
Value Function Update Magnitude: 0.58325

Collected Steps per Second: 22,687.99857
Overall Steps per Second: 10,519.15143

Timestep Collection Time: 2.20495
Timestep Consumption Time: 2.55075
PPO Batch Consumption Time: 0.30079
Total Iteration Time: 4.75571

Cumulative Model Updates: 81,718
Cumulative Timesteps: 681,613,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 681613080...
Checkpoint 681613080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.03225
Policy Entropy: 3.28626
Value Function Loss: 0.00389

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.52681
Value Function Update Magnitude: 0.58474

Collected Steps per Second: 21,628.00183
Overall Steps per Second: 10,415.46341

Timestep Collection Time: 2.31256
Timestep Consumption Time: 2.48953
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.80209

Cumulative Model Updates: 81,724
Cumulative Timesteps: 681,663,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,333.26463
Policy Entropy: 3.27363
Value Function Loss: 0.00411

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09284
Policy Update Magnitude: 0.53533
Value Function Update Magnitude: 0.60062

Collected Steps per Second: 22,801.66460
Overall Steps per Second: 10,666.93720

Timestep Collection Time: 2.19309
Timestep Consumption Time: 2.49486
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.68794

Cumulative Model Updates: 81,730
Cumulative Timesteps: 681,713,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 681713102...
Checkpoint 681713102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.05297
Policy Entropy: 3.26841
Value Function Loss: 0.00416

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.54100
Value Function Update Magnitude: 0.60374

Collected Steps per Second: 22,160.92362
Overall Steps per Second: 10,636.47390

Timestep Collection Time: 2.25631
Timestep Consumption Time: 2.44468
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.70099

Cumulative Model Updates: 81,736
Cumulative Timesteps: 681,763,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.35957
Policy Entropy: 3.26593
Value Function Loss: 0.00411

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.54528
Value Function Update Magnitude: 0.60416

Collected Steps per Second: 21,895.50392
Overall Steps per Second: 10,443.21583

Timestep Collection Time: 2.28476
Timestep Consumption Time: 2.50553
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.79029

Cumulative Model Updates: 81,742
Cumulative Timesteps: 681,813,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 681813130...
Checkpoint 681813130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.80760
Policy Entropy: 3.26672
Value Function Loss: 0.00434

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.55003
Value Function Update Magnitude: 0.60684

Collected Steps per Second: 21,731.99728
Overall Steps per Second: 10,398.90623

Timestep Collection Time: 2.30278
Timestep Consumption Time: 2.50965
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.81243

Cumulative Model Updates: 81,748
Cumulative Timesteps: 681,863,174

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.81032
Policy Entropy: 3.25864
Value Function Loss: 0.00461

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.56549
Value Function Update Magnitude: 0.65266

Collected Steps per Second: 22,048.40959
Overall Steps per Second: 10,448.55971

Timestep Collection Time: 2.26810
Timestep Consumption Time: 2.51801
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.78611

Cumulative Model Updates: 81,754
Cumulative Timesteps: 681,913,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 681913182...
Checkpoint 681913182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.27762
Policy Entropy: 3.24449
Value Function Loss: 0.00450

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.57820
Value Function Update Magnitude: 0.67091

Collected Steps per Second: 22,246.94896
Overall Steps per Second: 10,448.77314

Timestep Collection Time: 2.24840
Timestep Consumption Time: 2.53877
PPO Batch Consumption Time: 0.30143
Total Iteration Time: 4.78716

Cumulative Model Updates: 81,760
Cumulative Timesteps: 681,963,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.61104
Policy Entropy: 3.23601
Value Function Loss: 0.00443

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.57267
Value Function Update Magnitude: 0.65502

Collected Steps per Second: 21,968.15417
Overall Steps per Second: 10,491.32996

Timestep Collection Time: 2.27602
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.76584

Cumulative Model Updates: 81,766
Cumulative Timesteps: 682,013,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 682013202...
Checkpoint 682013202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.52576
Policy Entropy: 3.22920
Value Function Loss: 0.00435

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.56124
Value Function Update Magnitude: 0.64349

Collected Steps per Second: 22,131.91164
Overall Steps per Second: 10,513.00824

Timestep Collection Time: 2.26045
Timestep Consumption Time: 2.49823
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.75868

Cumulative Model Updates: 81,772
Cumulative Timesteps: 682,063,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.13336
Policy Entropy: 3.23370
Value Function Loss: 0.00431

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08823
Policy Update Magnitude: 0.56101
Value Function Update Magnitude: 0.62775

Collected Steps per Second: 22,499.58849
Overall Steps per Second: 10,572.88197

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.50752
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.73040

Cumulative Model Updates: 81,778
Cumulative Timesteps: 682,113,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 682113244...
Checkpoint 682113244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.69695
Policy Entropy: 3.23682
Value Function Loss: 0.00428

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.56263
Value Function Update Magnitude: 0.61034

Collected Steps per Second: 22,128.79053
Overall Steps per Second: 10,548.37633

Timestep Collection Time: 2.25950
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.74007

Cumulative Model Updates: 81,784
Cumulative Timesteps: 682,163,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.13504
Policy Entropy: 3.23805
Value Function Loss: 0.00410

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08721
Policy Update Magnitude: 0.55761
Value Function Update Magnitude: 0.59849

Collected Steps per Second: 22,500.72463
Overall Steps per Second: 10,648.58911

Timestep Collection Time: 2.22251
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.29819
Total Iteration Time: 4.69621

Cumulative Model Updates: 81,790
Cumulative Timesteps: 682,213,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 682213252...
Checkpoint 682213252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.75385
Policy Entropy: 3.25240
Value Function Loss: 0.00401

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.54991
Value Function Update Magnitude: 0.58335

Collected Steps per Second: 21,552.09443
Overall Steps per Second: 10,506.09045

Timestep Collection Time: 2.32228
Timestep Consumption Time: 2.44162
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.76390

Cumulative Model Updates: 81,796
Cumulative Timesteps: 682,263,302

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.70872
Policy Entropy: 3.24947
Value Function Loss: 0.00405

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.54504
Value Function Update Magnitude: 0.58745

Collected Steps per Second: 21,321.60808
Overall Steps per Second: 10,495.41740

Timestep Collection Time: 2.34607
Timestep Consumption Time: 2.42001
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.76608

Cumulative Model Updates: 81,802
Cumulative Timesteps: 682,313,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 682313324...
Checkpoint 682313324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.01789
Policy Entropy: 3.25301
Value Function Loss: 0.00413

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08134
Policy Update Magnitude: 0.54980
Value Function Update Magnitude: 0.60301

Collected Steps per Second: 20,921.81738
Overall Steps per Second: 10,216.60715

Timestep Collection Time: 2.39061
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.30094
Total Iteration Time: 4.89556

Cumulative Model Updates: 81,808
Cumulative Timesteps: 682,363,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.49988
Policy Entropy: 3.24989
Value Function Loss: 0.00404

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.55267
Value Function Update Magnitude: 0.61711

Collected Steps per Second: 18,688.29402
Overall Steps per Second: 9,640.39719

Timestep Collection Time: 2.67601
Timestep Consumption Time: 2.51154
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 5.18755

Cumulative Model Updates: 81,814
Cumulative Timesteps: 682,413,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 682413350...
Checkpoint 682413350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.04808
Policy Entropy: 3.25624
Value Function Loss: 0.00432

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.55376
Value Function Update Magnitude: 0.63810

Collected Steps per Second: 22,542.22205
Overall Steps per Second: 10,636.90844

Timestep Collection Time: 2.21904
Timestep Consumption Time: 2.48365
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.70268

Cumulative Model Updates: 81,820
Cumulative Timesteps: 682,463,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.55519
Policy Entropy: 3.26476
Value Function Loss: 0.00435

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.55612
Value Function Update Magnitude: 0.63725

Collected Steps per Second: 21,761.26649
Overall Steps per Second: 10,503.55144

Timestep Collection Time: 2.29784
Timestep Consumption Time: 2.46283
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.76068

Cumulative Model Updates: 81,826
Cumulative Timesteps: 682,513,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 682513376...
Checkpoint 682513376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.47349
Policy Entropy: 3.24490
Value Function Loss: 0.00448

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.55809
Value Function Update Magnitude: 0.63594

Collected Steps per Second: 21,803.48375
Overall Steps per Second: 10,472.46205

Timestep Collection Time: 2.29349
Timestep Consumption Time: 2.48151
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.77500

Cumulative Model Updates: 81,832
Cumulative Timesteps: 682,563,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.57751
Policy Entropy: 3.24672
Value Function Loss: 0.00431

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.55439
Value Function Update Magnitude: 0.61500

Collected Steps per Second: 21,710.15737
Overall Steps per Second: 10,341.69785

Timestep Collection Time: 2.30371
Timestep Consumption Time: 2.53244
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.83615

Cumulative Model Updates: 81,838
Cumulative Timesteps: 682,613,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 682613396...
Checkpoint 682613396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751.51294
Policy Entropy: 3.24881
Value Function Loss: 0.00442

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.55543
Value Function Update Magnitude: 0.61606

Collected Steps per Second: 22,128.38808
Overall Steps per Second: 10,356.16562

Timestep Collection Time: 2.26099
Timestep Consumption Time: 2.57014
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.83113

Cumulative Model Updates: 81,844
Cumulative Timesteps: 682,663,428

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.86929
Policy Entropy: 3.25826
Value Function Loss: 0.00439

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.55853
Value Function Update Magnitude: 0.62661

Collected Steps per Second: 21,551.95812
Overall Steps per Second: 10,162.12845

Timestep Collection Time: 2.32109
Timestep Consumption Time: 2.60150
PPO Batch Consumption Time: 0.30050
Total Iteration Time: 4.92259

Cumulative Model Updates: 81,850
Cumulative Timesteps: 682,713,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 682713452...
Checkpoint 682713452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.69000
Policy Entropy: 3.24518
Value Function Loss: 0.00428

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.55658
Value Function Update Magnitude: 0.62891

Collected Steps per Second: 22,490.85575
Overall Steps per Second: 10,575.55188

Timestep Collection Time: 2.22339
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.72845

Cumulative Model Updates: 81,856
Cumulative Timesteps: 682,763,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.90499
Policy Entropy: 3.25080
Value Function Loss: 0.00400

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.54810
Value Function Update Magnitude: 0.62385

Collected Steps per Second: 22,416.16064
Overall Steps per Second: 10,431.53822

Timestep Collection Time: 2.23169
Timestep Consumption Time: 2.56396
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.79565

Cumulative Model Updates: 81,862
Cumulative Timesteps: 682,813,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 682813484...
Checkpoint 682813484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.79896
Policy Entropy: 3.25283
Value Function Loss: 0.00427

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09327
Policy Update Magnitude: 0.55365
Value Function Update Magnitude: 0.60877

Collected Steps per Second: 22,204.88643
Overall Steps per Second: 10,517.50751

Timestep Collection Time: 2.25212
Timestep Consumption Time: 2.50262
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.75474

Cumulative Model Updates: 81,868
Cumulative Timesteps: 682,863,492

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.95298
Policy Entropy: 3.25175
Value Function Loss: 0.00433

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.60589

Collected Steps per Second: 22,771.83577
Overall Steps per Second: 10,618.25177

Timestep Collection Time: 2.19684
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.71132

Cumulative Model Updates: 81,874
Cumulative Timesteps: 682,913,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 682913518...
Checkpoint 682913518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917.90747
Policy Entropy: 3.27376
Value Function Loss: 0.00426

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.54207
Value Function Update Magnitude: 0.59777

Collected Steps per Second: 22,193.90062
Overall Steps per Second: 10,525.59065

Timestep Collection Time: 2.25395
Timestep Consumption Time: 2.49865
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.75261

Cumulative Model Updates: 81,880
Cumulative Timesteps: 682,963,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.99558
Policy Entropy: 3.27039
Value Function Loss: 0.00416

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.52756
Value Function Update Magnitude: 0.58855

Collected Steps per Second: 22,238.03815
Overall Steps per Second: 10,596.24816

Timestep Collection Time: 2.24921
Timestep Consumption Time: 2.47114
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.72035

Cumulative Model Updates: 81,886
Cumulative Timesteps: 683,013,560

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 683013560...
Checkpoint 683013560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.67692
Policy Entropy: 3.27374
Value Function Loss: 0.00429

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.53933
Value Function Update Magnitude: 0.59628

Collected Steps per Second: 21,818.81822
Overall Steps per Second: 10,350.07240

Timestep Collection Time: 2.29242
Timestep Consumption Time: 2.54020
PPO Batch Consumption Time: 0.29629
Total Iteration Time: 4.83262

Cumulative Model Updates: 81,892
Cumulative Timesteps: 683,063,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.97247
Policy Entropy: 3.25676
Value Function Loss: 0.00422

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.55779
Value Function Update Magnitude: 0.63249

Collected Steps per Second: 22,443.09304
Overall Steps per Second: 10,636.24919

Timestep Collection Time: 2.22839
Timestep Consumption Time: 2.47364
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.70203

Cumulative Model Updates: 81,898
Cumulative Timesteps: 683,113,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 683113590...
Checkpoint 683113590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.75760
Policy Entropy: 3.25305
Value Function Loss: 0.00410

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.55390
Value Function Update Magnitude: 0.63407

Collected Steps per Second: 22,023.43064
Overall Steps per Second: 10,380.57997

Timestep Collection Time: 2.27158
Timestep Consumption Time: 2.54780
PPO Batch Consumption Time: 0.29872
Total Iteration Time: 4.81938

Cumulative Model Updates: 81,904
Cumulative Timesteps: 683,163,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.83638
Policy Entropy: 3.25353
Value Function Loss: 0.00417

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11204
Policy Update Magnitude: 0.55696
Value Function Update Magnitude: 0.62874

Collected Steps per Second: 22,292.43164
Overall Steps per Second: 10,358.45501

Timestep Collection Time: 2.24408
Timestep Consumption Time: 2.58540
PPO Batch Consumption Time: 0.30187
Total Iteration Time: 4.82948

Cumulative Model Updates: 81,910
Cumulative Timesteps: 683,213,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 683213644...
Checkpoint 683213644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.10819
Policy Entropy: 3.25146
Value Function Loss: 0.00425

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.13462
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.64014

Collected Steps per Second: 21,862.08067
Overall Steps per Second: 10,363.98358

Timestep Collection Time: 2.28771
Timestep Consumption Time: 2.53805
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.82575

Cumulative Model Updates: 81,916
Cumulative Timesteps: 683,263,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.73395
Policy Entropy: 3.26180
Value Function Loss: 0.00430

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.12940
Policy Update Magnitude: 0.55148
Value Function Update Magnitude: 0.63515

Collected Steps per Second: 22,666.51000
Overall Steps per Second: 10,465.81851

Timestep Collection Time: 2.20590
Timestep Consumption Time: 2.57156
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.77746

Cumulative Model Updates: 81,922
Cumulative Timesteps: 683,313,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 683313658...
Checkpoint 683313658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.13161
Policy Entropy: 3.26719
Value Function Loss: 0.00411

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.14440
Policy Update Magnitude: 0.55897
Value Function Update Magnitude: 0.63774

Collected Steps per Second: 22,387.79649
Overall Steps per Second: 10,474.09575

Timestep Collection Time: 2.23416
Timestep Consumption Time: 2.54124
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.77540

Cumulative Model Updates: 81,928
Cumulative Timesteps: 683,363,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.61652
Policy Entropy: 3.26983
Value Function Loss: 0.00398

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.12717
Policy Update Magnitude: 0.56316
Value Function Update Magnitude: 0.61878

Collected Steps per Second: 22,416.11149
Overall Steps per Second: 10,425.13639

Timestep Collection Time: 2.23090
Timestep Consumption Time: 2.56597
PPO Batch Consumption Time: 0.29798
Total Iteration Time: 4.79687

Cumulative Model Updates: 81,934
Cumulative Timesteps: 683,413,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 683413684...
Checkpoint 683413684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.03611
Policy Entropy: 3.25299
Value Function Loss: 0.00396

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.61556

Collected Steps per Second: 22,398.23745
Overall Steps per Second: 10,527.24836

Timestep Collection Time: 2.23241
Timestep Consumption Time: 2.51736
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.74977

Cumulative Model Updates: 81,940
Cumulative Timesteps: 683,463,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995.09136
Policy Entropy: 3.25685
Value Function Loss: 0.00384

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.62240

Collected Steps per Second: 22,684.45786
Overall Steps per Second: 10,606.60170

Timestep Collection Time: 2.20442
Timestep Consumption Time: 2.51019
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.71461

Cumulative Model Updates: 81,946
Cumulative Timesteps: 683,513,692

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 683513692...
Checkpoint 683513692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.03315
Policy Entropy: 3.25861
Value Function Loss: 0.00384

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.53836
Value Function Update Magnitude: 0.62638

Collected Steps per Second: 22,374.97811
Overall Steps per Second: 10,442.80845

Timestep Collection Time: 2.23500
Timestep Consumption Time: 2.55375
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.78875

Cumulative Model Updates: 81,952
Cumulative Timesteps: 683,563,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.54602
Policy Entropy: 3.27017
Value Function Loss: 0.00384

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.62616

Collected Steps per Second: 22,221.50660
Overall Steps per Second: 10,586.61794

Timestep Collection Time: 2.25133
Timestep Consumption Time: 2.47426
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.72559

Cumulative Model Updates: 81,958
Cumulative Timesteps: 683,613,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 683613728...
Checkpoint 683613728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.75655
Policy Entropy: 3.24824
Value Function Loss: 0.00423

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.54386
Value Function Update Magnitude: 0.61685

Collected Steps per Second: 21,524.80893
Overall Steps per Second: 10,243.71088

Timestep Collection Time: 2.32411
Timestep Consumption Time: 2.55947
PPO Batch Consumption Time: 0.29775
Total Iteration Time: 4.88358

Cumulative Model Updates: 81,964
Cumulative Timesteps: 683,663,754

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.41415
Policy Entropy: 3.25805
Value Function Loss: 0.00439

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.55840
Value Function Update Magnitude: 0.61583

Collected Steps per Second: 22,871.49146
Overall Steps per Second: 10,533.21887

Timestep Collection Time: 2.18622
Timestep Consumption Time: 2.56086
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 4.74708

Cumulative Model Updates: 81,970
Cumulative Timesteps: 683,713,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 683713756...
Checkpoint 683713756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.96861
Policy Entropy: 3.25278
Value Function Loss: 0.00434

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.56641
Value Function Update Magnitude: 0.65009

Collected Steps per Second: 21,794.44061
Overall Steps per Second: 10,482.42237

Timestep Collection Time: 2.29508
Timestep Consumption Time: 2.47672
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.77180

Cumulative Model Updates: 81,976
Cumulative Timesteps: 683,763,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.08797
Policy Entropy: 3.26615
Value Function Loss: 0.00400

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07884
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.64552

Collected Steps per Second: 22,200.28593
Overall Steps per Second: 10,495.47271

Timestep Collection Time: 2.25339
Timestep Consumption Time: 2.51304
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.76644

Cumulative Model Updates: 81,982
Cumulative Timesteps: 683,813,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 683813802...
Checkpoint 683813802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796.29566
Policy Entropy: 3.26755
Value Function Loss: 0.00402

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.07772
Policy Update Magnitude: 0.55400
Value Function Update Magnitude: 0.63429

Collected Steps per Second: 21,549.47472
Overall Steps per Second: 10,263.85661

Timestep Collection Time: 2.32052
Timestep Consumption Time: 2.55153
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.87205

Cumulative Model Updates: 81,988
Cumulative Timesteps: 683,863,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 905.95934
Policy Entropy: 3.27281
Value Function Loss: 0.00396

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08229
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.62033

Collected Steps per Second: 22,007.90926
Overall Steps per Second: 10,461.23551

Timestep Collection Time: 2.27227
Timestep Consumption Time: 2.50804
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.78031

Cumulative Model Updates: 81,994
Cumulative Timesteps: 683,913,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 683913816...
Checkpoint 683913816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.48323
Policy Entropy: 3.26287
Value Function Loss: 0.00391

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.53669
Value Function Update Magnitude: 0.60426

Collected Steps per Second: 21,900.42677
Overall Steps per Second: 10,370.69199

Timestep Collection Time: 2.28333
Timestep Consumption Time: 2.53852
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.82186

Cumulative Model Updates: 82,000
Cumulative Timesteps: 683,963,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.69510
Policy Entropy: 3.25374
Value Function Loss: 0.00409

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.53080
Value Function Update Magnitude: 0.59978

Collected Steps per Second: 22,492.30677
Overall Steps per Second: 10,601.52237

Timestep Collection Time: 2.22387
Timestep Consumption Time: 2.49432
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.71819

Cumulative Model Updates: 82,006
Cumulative Timesteps: 684,013,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 684013842...
Checkpoint 684013842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.68343
Policy Entropy: 3.24731
Value Function Loss: 0.00414

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.54057
Value Function Update Magnitude: 0.60468

Collected Steps per Second: 22,498.38492
Overall Steps per Second: 10,422.96744

Timestep Collection Time: 2.22327
Timestep Consumption Time: 2.57575
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.79902

Cumulative Model Updates: 82,012
Cumulative Timesteps: 684,063,862

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.72226
Policy Entropy: 3.25526
Value Function Loss: 0.00431

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.62081

Collected Steps per Second: 22,716.22703
Overall Steps per Second: 10,676.69903

Timestep Collection Time: 2.20221
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.68553

Cumulative Model Updates: 82,018
Cumulative Timesteps: 684,113,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 684113888...
Checkpoint 684113888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.72780
Policy Entropy: 3.26246
Value Function Loss: 0.00418

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.54371
Value Function Update Magnitude: 0.62415

Collected Steps per Second: 21,914.42588
Overall Steps per Second: 10,291.72605

Timestep Collection Time: 2.28261
Timestep Consumption Time: 2.57780
PPO Batch Consumption Time: 0.30039
Total Iteration Time: 4.86041

Cumulative Model Updates: 82,024
Cumulative Timesteps: 684,163,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.54116
Policy Entropy: 3.26027
Value Function Loss: 0.00413

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08491
Policy Update Magnitude: 0.54713
Value Function Update Magnitude: 0.60713

Collected Steps per Second: 22,619.26800
Overall Steps per Second: 10,437.92122

Timestep Collection Time: 2.21104
Timestep Consumption Time: 2.58034
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.79138

Cumulative Model Updates: 82,030
Cumulative Timesteps: 684,213,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 684213922...
Checkpoint 684213922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.69256
Policy Entropy: 3.25783
Value Function Loss: 0.00408

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.54584
Value Function Update Magnitude: 0.59656

Collected Steps per Second: 21,119.09137
Overall Steps per Second: 10,302.12429

Timestep Collection Time: 2.36762
Timestep Consumption Time: 2.48594
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.85356

Cumulative Model Updates: 82,036
Cumulative Timesteps: 684,263,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.39806
Policy Entropy: 3.24850
Value Function Loss: 0.00418

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.54544
Value Function Update Magnitude: 0.59320

Collected Steps per Second: 22,284.98021
Overall Steps per Second: 10,421.99909

Timestep Collection Time: 2.24492
Timestep Consumption Time: 2.55531
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.80023

Cumulative Model Updates: 82,042
Cumulative Timesteps: 684,313,952

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 684313952...
Checkpoint 684313952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.19620
Policy Entropy: 3.24213
Value Function Loss: 0.00422

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.55607
Value Function Update Magnitude: 0.59003

Collected Steps per Second: 21,306.51662
Overall Steps per Second: 10,210.47935

Timestep Collection Time: 2.34811
Timestep Consumption Time: 2.55176
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.89987

Cumulative Model Updates: 82,048
Cumulative Timesteps: 684,363,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.79998
Policy Entropy: 3.21650
Value Function Loss: 0.00414

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.56471
Value Function Update Magnitude: 0.60375

Collected Steps per Second: 21,835.95227
Overall Steps per Second: 10,445.16474

Timestep Collection Time: 2.29063
Timestep Consumption Time: 2.49800
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.78863

Cumulative Model Updates: 82,054
Cumulative Timesteps: 684,414,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 684414000...
Checkpoint 684414000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.88384
Policy Entropy: 3.20287
Value Function Loss: 0.00430

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.57025
Value Function Update Magnitude: 0.61123

Collected Steps per Second: 21,969.89686
Overall Steps per Second: 10,369.43834

Timestep Collection Time: 2.27702
Timestep Consumption Time: 2.54734
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.82437

Cumulative Model Updates: 82,060
Cumulative Timesteps: 684,464,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.15955
Policy Entropy: 3.19746
Value Function Loss: 0.00414

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.56676
Value Function Update Magnitude: 0.60952

Collected Steps per Second: 22,540.98425
Overall Steps per Second: 10,496.26354

Timestep Collection Time: 2.21898
Timestep Consumption Time: 2.54633
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.76531

Cumulative Model Updates: 82,066
Cumulative Timesteps: 684,514,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 684514044...
Checkpoint 684514044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.88074
Policy Entropy: 3.22180
Value Function Loss: 0.00413

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.60195

Collected Steps per Second: 22,290.16613
Overall Steps per Second: 10,466.52301

Timestep Collection Time: 2.24332
Timestep Consumption Time: 2.53420
PPO Batch Consumption Time: 0.29969
Total Iteration Time: 4.77752

Cumulative Model Updates: 82,072
Cumulative Timesteps: 684,564,048

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.03692
Policy Entropy: 3.21086
Value Function Loss: 0.00432

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.56533
Value Function Update Magnitude: 0.59639

Collected Steps per Second: 22,475.70729
Overall Steps per Second: 10,571.55052

Timestep Collection Time: 2.22578
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.73213

Cumulative Model Updates: 82,078
Cumulative Timesteps: 684,614,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 684614074...
Checkpoint 684614074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.84271
Policy Entropy: 3.22068
Value Function Loss: 0.00432

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.60349

Collected Steps per Second: 22,469.81276
Overall Steps per Second: 10,493.58351

Timestep Collection Time: 2.22539
Timestep Consumption Time: 2.53981
PPO Batch Consumption Time: 0.30175
Total Iteration Time: 4.76520

Cumulative Model Updates: 82,084
Cumulative Timesteps: 684,664,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.41746
Policy Entropy: 3.21327
Value Function Loss: 0.00434

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.56978
Value Function Update Magnitude: 0.59619

Collected Steps per Second: 22,330.35799
Overall Steps per Second: 10,489.96076

Timestep Collection Time: 2.24054
Timestep Consumption Time: 2.52898
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.76951

Cumulative Model Updates: 82,090
Cumulative Timesteps: 684,714,110

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 684714110...
Checkpoint 684714110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.59811
Policy Entropy: 3.22902
Value Function Loss: 0.00398

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.55382
Value Function Update Magnitude: 0.58220

Collected Steps per Second: 22,205.57177
Overall Steps per Second: 10,638.06260

Timestep Collection Time: 2.25286
Timestep Consumption Time: 2.44969
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.70255

Cumulative Model Updates: 82,096
Cumulative Timesteps: 684,764,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.89030
Policy Entropy: 3.24201
Value Function Loss: 0.00406

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.59337

Collected Steps per Second: 22,212.81302
Overall Steps per Second: 10,424.35740

Timestep Collection Time: 2.25122
Timestep Consumption Time: 2.54581
PPO Batch Consumption Time: 0.30065
Total Iteration Time: 4.79703

Cumulative Model Updates: 82,102
Cumulative Timesteps: 684,814,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 684814142...
Checkpoint 684814142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.41051
Policy Entropy: 3.25334
Value Function Loss: 0.00382

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.53714
Value Function Update Magnitude: 0.59744

Collected Steps per Second: 21,722.26654
Overall Steps per Second: 10,172.82554

Timestep Collection Time: 2.30206
Timestep Consumption Time: 2.61358
PPO Batch Consumption Time: 0.30556
Total Iteration Time: 4.91565

Cumulative Model Updates: 82,108
Cumulative Timesteps: 684,864,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.91101
Policy Entropy: 3.26400
Value Function Loss: 0.00398

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.53564
Value Function Update Magnitude: 0.61936

Collected Steps per Second: 21,566.53947
Overall Steps per Second: 10,396.44708

Timestep Collection Time: 2.31878
Timestep Consumption Time: 2.49133
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.81010

Cumulative Model Updates: 82,114
Cumulative Timesteps: 684,914,156

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 684914156...
Checkpoint 684914156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.85015
Policy Entropy: 3.25410
Value Function Loss: 0.00395

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10988
Policy Update Magnitude: 0.54528
Value Function Update Magnitude: 0.63532

Collected Steps per Second: 21,636.63862
Overall Steps per Second: 10,363.84646

Timestep Collection Time: 2.31090
Timestep Consumption Time: 2.51357
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.82446

Cumulative Model Updates: 82,120
Cumulative Timesteps: 684,964,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.22381
Policy Entropy: 3.23527
Value Function Loss: 0.00395

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.55059
Value Function Update Magnitude: 0.61661

Collected Steps per Second: 22,011.65056
Overall Steps per Second: 10,393.56248

Timestep Collection Time: 2.27162
Timestep Consumption Time: 2.53925
PPO Batch Consumption Time: 0.29697
Total Iteration Time: 4.81086

Cumulative Model Updates: 82,126
Cumulative Timesteps: 685,014,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 685014158...
Checkpoint 685014158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.72171
Policy Entropy: 3.23927
Value Function Loss: 0.00405

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.54687
Value Function Update Magnitude: 0.60867

Collected Steps per Second: 22,024.79988
Overall Steps per Second: 10,546.21969

Timestep Collection Time: 2.27035
Timestep Consumption Time: 2.47106
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.74141

Cumulative Model Updates: 82,132
Cumulative Timesteps: 685,064,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.70725
Policy Entropy: 3.25094
Value Function Loss: 0.00393

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11643
Policy Update Magnitude: 0.53993
Value Function Update Magnitude: 0.60923

Collected Steps per Second: 22,087.25924
Overall Steps per Second: 10,540.22354

Timestep Collection Time: 2.26502
Timestep Consumption Time: 2.48137
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.74639

Cumulative Model Updates: 82,138
Cumulative Timesteps: 685,114,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 685114190...
Checkpoint 685114190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.26011
Policy Entropy: 3.24786
Value Function Loss: 0.00441

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11283
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.60592

Collected Steps per Second: 22,306.02115
Overall Steps per Second: 10,555.33382

Timestep Collection Time: 2.24280
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.73959

Cumulative Model Updates: 82,144
Cumulative Timesteps: 685,164,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.04322
Policy Entropy: 3.24762
Value Function Loss: 0.00431

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 22,232.62095
Overall Steps per Second: 10,546.96826

Timestep Collection Time: 2.24985
Timestep Consumption Time: 2.49275
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.74260

Cumulative Model Updates: 82,150
Cumulative Timesteps: 685,214,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 685214238...
Checkpoint 685214238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 834.17922
Policy Entropy: 3.23368
Value Function Loss: 0.00451

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11576
Policy Update Magnitude: 0.54793
Value Function Update Magnitude: 0.61123

Collected Steps per Second: 22,185.05933
Overall Steps per Second: 10,566.69719

Timestep Collection Time: 2.25422
Timestep Consumption Time: 2.47857
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.73279

Cumulative Model Updates: 82,156
Cumulative Timesteps: 685,264,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.55647
Policy Entropy: 3.24383
Value Function Loss: 0.00424

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.12931
Policy Update Magnitude: 0.54563
Value Function Update Magnitude: 0.62293

Collected Steps per Second: 22,506.62762
Overall Steps per Second: 10,508.64661

Timestep Collection Time: 2.22237
Timestep Consumption Time: 2.53733
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 4.75970

Cumulative Model Updates: 82,162
Cumulative Timesteps: 685,314,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 685314266...
Checkpoint 685314266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.20258
Policy Entropy: 3.24553
Value Function Loss: 0.00423

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.54573
Value Function Update Magnitude: 0.63933

Collected Steps per Second: 22,180.31169
Overall Steps per Second: 10,628.84484

Timestep Collection Time: 2.25443
Timestep Consumption Time: 2.45012
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.70456

Cumulative Model Updates: 82,168
Cumulative Timesteps: 685,364,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.16501
Policy Entropy: 3.24937
Value Function Loss: 0.00402

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.54122
Value Function Update Magnitude: 0.64868

Collected Steps per Second: 22,493.98506
Overall Steps per Second: 10,475.03075

Timestep Collection Time: 2.22317
Timestep Consumption Time: 2.55085
PPO Batch Consumption Time: 0.30067
Total Iteration Time: 4.77402

Cumulative Model Updates: 82,174
Cumulative Timesteps: 685,414,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 685414278...
Checkpoint 685414278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 818.08607
Policy Entropy: 3.24358
Value Function Loss: 0.00396

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.54533
Value Function Update Magnitude: 0.63415

Collected Steps per Second: 22,418.16342
Overall Steps per Second: 10,650.46509

Timestep Collection Time: 2.23132
Timestep Consumption Time: 2.46538
PPO Batch Consumption Time: 0.29864
Total Iteration Time: 4.69670

Cumulative Model Updates: 82,180
Cumulative Timesteps: 685,464,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.51233
Policy Entropy: 3.25449
Value Function Loss: 0.00389

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.54505
Value Function Update Magnitude: 0.62938

Collected Steps per Second: 21,056.97953
Overall Steps per Second: 10,409.17681

Timestep Collection Time: 2.37498
Timestep Consumption Time: 2.42943
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.80441

Cumulative Model Updates: 82,186
Cumulative Timesteps: 685,514,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 685514310...
Checkpoint 685514310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.39257
Policy Entropy: 3.26082
Value Function Loss: 0.00396

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.54613
Value Function Update Magnitude: 0.62353

Collected Steps per Second: 21,221.21852
Overall Steps per Second: 10,403.20443

Timestep Collection Time: 2.35764
Timestep Consumption Time: 2.45165
PPO Batch Consumption Time: 0.29796
Total Iteration Time: 4.80929

Cumulative Model Updates: 82,192
Cumulative Timesteps: 685,564,342

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.74606
Policy Entropy: 3.25982
Value Function Loss: 0.00428

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.62596

Collected Steps per Second: 21,399.18899
Overall Steps per Second: 10,428.41350

Timestep Collection Time: 2.33859
Timestep Consumption Time: 2.46022
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.79881

Cumulative Model Updates: 82,198
Cumulative Timesteps: 685,614,386

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 685614386...
Checkpoint 685614386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.44669
Policy Entropy: 3.26552
Value Function Loss: 0.00446

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.66285

Collected Steps per Second: 21,450.13769
Overall Steps per Second: 10,551.26367

Timestep Collection Time: 2.33248
Timestep Consumption Time: 2.40932
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.74180

Cumulative Model Updates: 82,204
Cumulative Timesteps: 685,664,418

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.19651
Policy Entropy: 3.25999
Value Function Loss: 0.00435

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10954
Policy Update Magnitude: 0.57477
Value Function Update Magnitude: 0.67684

Collected Steps per Second: 21,293.60207
Overall Steps per Second: 10,423.63922

Timestep Collection Time: 2.34944
Timestep Consumption Time: 2.45004
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.79948

Cumulative Model Updates: 82,210
Cumulative Timesteps: 685,714,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 685714446...
Checkpoint 685714446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.90669
Policy Entropy: 3.26289
Value Function Loss: 0.00412

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09430
Policy Update Magnitude: 0.55286
Value Function Update Magnitude: 0.65268

Collected Steps per Second: 21,394.23673
Overall Steps per Second: 10,421.69579

Timestep Collection Time: 2.33708
Timestep Consumption Time: 2.46061
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.79768

Cumulative Model Updates: 82,216
Cumulative Timesteps: 685,764,446

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.69421
Policy Entropy: 3.26981
Value Function Loss: 0.00406

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09746
Policy Update Magnitude: 0.54488
Value Function Update Magnitude: 0.63441

Collected Steps per Second: 21,951.49463
Overall Steps per Second: 10,589.33927

Timestep Collection Time: 2.27839
Timestep Consumption Time: 2.44467
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.72305

Cumulative Model Updates: 82,222
Cumulative Timesteps: 685,814,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 685814460...
Checkpoint 685814460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.40304
Policy Entropy: 3.28168
Value Function Loss: 0.00376

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.53874
Value Function Update Magnitude: 0.63713

Collected Steps per Second: 22,225.50442
Overall Steps per Second: 10,500.64167

Timestep Collection Time: 2.24985
Timestep Consumption Time: 2.51215
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.76199

Cumulative Model Updates: 82,228
Cumulative Timesteps: 685,864,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.44313
Policy Entropy: 3.28604
Value Function Loss: 0.00372

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.53434
Value Function Update Magnitude: 0.62102

Collected Steps per Second: 22,427.49753
Overall Steps per Second: 10,583.09028

Timestep Collection Time: 2.23057
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.72697

Cumulative Model Updates: 82,234
Cumulative Timesteps: 685,914,490

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 685914490...
Checkpoint 685914490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 869.04469
Policy Entropy: 3.27581
Value Function Loss: 0.00408

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.61944

Collected Steps per Second: 21,935.93241
Overall Steps per Second: 10,410.34917

Timestep Collection Time: 2.28064
Timestep Consumption Time: 2.52496
PPO Batch Consumption Time: 0.29795
Total Iteration Time: 4.80560

Cumulative Model Updates: 82,240
Cumulative Timesteps: 685,964,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.40801
Policy Entropy: 3.26400
Value Function Loss: 0.00425

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.65673

Collected Steps per Second: 22,491.33198
Overall Steps per Second: 10,511.43345

Timestep Collection Time: 2.22441
Timestep Consumption Time: 2.53517
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.75958

Cumulative Model Updates: 82,246
Cumulative Timesteps: 686,014,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 686014548...
Checkpoint 686014548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.62441
Policy Entropy: 3.27056
Value Function Loss: 0.00410

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.55599
Value Function Update Magnitude: 0.66555

Collected Steps per Second: 22,702.25996
Overall Steps per Second: 10,505.23296

Timestep Collection Time: 2.20251
Timestep Consumption Time: 2.55721
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.75972

Cumulative Model Updates: 82,252
Cumulative Timesteps: 686,064,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.31557
Policy Entropy: 3.26342
Value Function Loss: 0.00417

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.54998
Value Function Update Magnitude: 0.64564

Collected Steps per Second: 22,350.50870
Overall Steps per Second: 10,435.38833

Timestep Collection Time: 2.23896
Timestep Consumption Time: 2.55645
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.79541

Cumulative Model Updates: 82,258
Cumulative Timesteps: 686,114,592

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 686114592...
Checkpoint 686114592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.13455
Policy Entropy: 3.26116
Value Function Loss: 0.00428

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10062
Policy Update Magnitude: 0.55397
Value Function Update Magnitude: 0.65115

Collected Steps per Second: 22,008.45165
Overall Steps per Second: 10,430.12850

Timestep Collection Time: 2.27222
Timestep Consumption Time: 2.52235
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.79457

Cumulative Model Updates: 82,264
Cumulative Timesteps: 686,164,600

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 603.86180
Policy Entropy: 3.24947
Value Function Loss: 0.00433

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.56137
Value Function Update Magnitude: 0.65082

Collected Steps per Second: 21,913.23755
Overall Steps per Second: 10,402.98113

Timestep Collection Time: 2.28209
Timestep Consumption Time: 2.52499
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.80708

Cumulative Model Updates: 82,270
Cumulative Timesteps: 686,214,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 686214608...
Checkpoint 686214608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.40182
Policy Entropy: 3.24622
Value Function Loss: 0.00419

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.55942
Value Function Update Magnitude: 0.65569

Collected Steps per Second: 22,311.99145
Overall Steps per Second: 10,462.08906

Timestep Collection Time: 2.24157
Timestep Consumption Time: 2.53892
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.78050

Cumulative Model Updates: 82,276
Cumulative Timesteps: 686,264,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.17235
Policy Entropy: 3.26332
Value Function Loss: 0.00411

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.64012

Collected Steps per Second: 22,290.64350
Overall Steps per Second: 10,448.23483

Timestep Collection Time: 2.24381
Timestep Consumption Time: 2.54322
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.78703

Cumulative Model Updates: 82,282
Cumulative Timesteps: 686,314,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 686314638...
Checkpoint 686314638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.04067
Policy Entropy: 3.26185
Value Function Loss: 0.00422

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.55915
Value Function Update Magnitude: 0.63606

Collected Steps per Second: 22,206.25172
Overall Steps per Second: 10,390.55177

Timestep Collection Time: 2.25207
Timestep Consumption Time: 2.56096
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.81303

Cumulative Model Updates: 82,288
Cumulative Timesteps: 686,364,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.26402
Policy Entropy: 3.24308
Value Function Loss: 0.00433

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08355
Policy Update Magnitude: 0.56652
Value Function Update Magnitude: 0.64329

Collected Steps per Second: 22,521.83609
Overall Steps per Second: 10,495.25398

Timestep Collection Time: 2.22131
Timestep Consumption Time: 2.54542
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.76673

Cumulative Model Updates: 82,294
Cumulative Timesteps: 686,414,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 686414676...
Checkpoint 686414676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.48389
Policy Entropy: 3.22950
Value Function Loss: 0.00446

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.56844
Value Function Update Magnitude: 0.64827

Collected Steps per Second: 22,513.13758
Overall Steps per Second: 10,517.32057

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.53385
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.75539

Cumulative Model Updates: 82,300
Cumulative Timesteps: 686,464,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 990.46173
Policy Entropy: 3.22600
Value Function Loss: 0.00448

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08833
Policy Update Magnitude: 0.57140
Value Function Update Magnitude: 0.63936

Collected Steps per Second: 22,446.04461
Overall Steps per Second: 10,471.63484

Timestep Collection Time: 2.22899
Timestep Consumption Time: 2.54887
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.77786

Cumulative Model Updates: 82,306
Cumulative Timesteps: 686,514,722

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 686514722...
Checkpoint 686514722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.17689
Policy Entropy: 3.24548
Value Function Loss: 0.00447

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08657
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.63028

Collected Steps per Second: 20,486.98295
Overall Steps per Second: 10,068.09803

Timestep Collection Time: 2.44184
Timestep Consumption Time: 2.52692
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.96876

Cumulative Model Updates: 82,312
Cumulative Timesteps: 686,564,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,860.26194
Policy Entropy: 3.26046
Value Function Loss: 0.00449

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08590
Policy Update Magnitude: 0.56687
Value Function Update Magnitude: 0.62866

Collected Steps per Second: 21,480.46236
Overall Steps per Second: 10,214.02504

Timestep Collection Time: 2.32844
Timestep Consumption Time: 2.56835
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.89680

Cumulative Model Updates: 82,318
Cumulative Timesteps: 686,614,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 686614764...
Checkpoint 686614764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.16289
Policy Entropy: 3.25949
Value Function Loss: 0.00435

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08422
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.64009

Collected Steps per Second: 22,407.93081
Overall Steps per Second: 10,492.11384

Timestep Collection Time: 2.23162
Timestep Consumption Time: 2.53444
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.76606

Cumulative Model Updates: 82,324
Cumulative Timesteps: 686,664,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.72140
Policy Entropy: 3.25234
Value Function Loss: 0.00421

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.55737
Value Function Update Magnitude: 0.64496

Collected Steps per Second: 22,248.99477
Overall Steps per Second: 10,468.89557

Timestep Collection Time: 2.24774
Timestep Consumption Time: 2.52927
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.77701

Cumulative Model Updates: 82,330
Cumulative Timesteps: 686,714,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 686714780...
Checkpoint 686714780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 790.67991
Policy Entropy: 3.23365
Value Function Loss: 0.00419

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.62829

Collected Steps per Second: 22,308.13133
Overall Steps per Second: 10,536.11482

Timestep Collection Time: 2.24134
Timestep Consumption Time: 2.50425
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.74558

Cumulative Model Updates: 82,336
Cumulative Timesteps: 686,764,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.93978
Policy Entropy: 3.21630
Value Function Loss: 0.00433

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.56710
Value Function Update Magnitude: 0.64743

Collected Steps per Second: 21,902.25725
Overall Steps per Second: 10,419.30635

Timestep Collection Time: 2.28333
Timestep Consumption Time: 2.51642
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.79974

Cumulative Model Updates: 82,342
Cumulative Timesteps: 686,814,790

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 686814790...
Checkpoint 686814790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.20860
Policy Entropy: 3.22904
Value Function Loss: 0.00440

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10791
Policy Update Magnitude: 0.58128
Value Function Update Magnitude: 0.66683

Collected Steps per Second: 21,884.94219
Overall Steps per Second: 10,303.74386

Timestep Collection Time: 2.28468
Timestep Consumption Time: 2.56793
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.85261

Cumulative Model Updates: 82,348
Cumulative Timesteps: 686,864,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.32185
Policy Entropy: 3.23688
Value Function Loss: 0.00425

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11120
Policy Update Magnitude: 0.57699
Value Function Update Magnitude: 0.66359

Collected Steps per Second: 22,389.78898
Overall Steps per Second: 10,480.07160

Timestep Collection Time: 2.23370
Timestep Consumption Time: 2.53841
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.77210

Cumulative Model Updates: 82,354
Cumulative Timesteps: 686,914,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 686914802...
Checkpoint 686914802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.85346
Policy Entropy: 3.26758
Value Function Loss: 0.00406

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.56069
Value Function Update Magnitude: 0.64622

Collected Steps per Second: 22,068.51733
Overall Steps per Second: 10,547.07951

Timestep Collection Time: 2.26631
Timestep Consumption Time: 2.47567
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.74198

Cumulative Model Updates: 82,360
Cumulative Timesteps: 686,964,816

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.78156
Policy Entropy: 3.25411
Value Function Loss: 0.00408

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.56207
Value Function Update Magnitude: 0.64125

Collected Steps per Second: 22,078.13332
Overall Steps per Second: 10,420.05262

Timestep Collection Time: 2.26550
Timestep Consumption Time: 2.53467
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.80017

Cumulative Model Updates: 82,366
Cumulative Timesteps: 687,014,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 687014834...
Checkpoint 687014834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713.03567
Policy Entropy: 3.25042
Value Function Loss: 0.00443

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.57197
Value Function Update Magnitude: 0.65996

Collected Steps per Second: 22,332.59353
Overall Steps per Second: 10,421.47408

Timestep Collection Time: 2.23915
Timestep Consumption Time: 2.55921
PPO Batch Consumption Time: 0.29792
Total Iteration Time: 4.79836

Cumulative Model Updates: 82,372
Cumulative Timesteps: 687,064,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.61002
Policy Entropy: 3.22873
Value Function Loss: 0.00441

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.58016
Value Function Update Magnitude: 0.67218

Collected Steps per Second: 22,469.98666
Overall Steps per Second: 10,439.65999

Timestep Collection Time: 2.22564
Timestep Consumption Time: 2.56475
PPO Batch Consumption Time: 0.29846
Total Iteration Time: 4.79039

Cumulative Model Updates: 82,378
Cumulative Timesteps: 687,114,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 687114850...
Checkpoint 687114850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 984.58728
Policy Entropy: 3.23623
Value Function Loss: 0.00421

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08547
Policy Update Magnitude: 0.58078
Value Function Update Magnitude: 0.65292

Collected Steps per Second: 22,465.22418
Overall Steps per Second: 10,540.22577

Timestep Collection Time: 2.22637
Timestep Consumption Time: 2.51887
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.74525

Cumulative Model Updates: 82,384
Cumulative Timesteps: 687,164,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.90570
Policy Entropy: 3.22177
Value Function Loss: 0.00405

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08492
Policy Update Magnitude: 0.56537
Value Function Update Magnitude: 0.61921

Collected Steps per Second: 22,448.47391
Overall Steps per Second: 10,527.11386

Timestep Collection Time: 2.22732
Timestep Consumption Time: 2.52232
PPO Batch Consumption Time: 0.29891
Total Iteration Time: 4.74964

Cumulative Model Updates: 82,390
Cumulative Timesteps: 687,214,866

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 687214866...
Checkpoint 687214866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 956.37804
Policy Entropy: 3.21957
Value Function Loss: 0.00425

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.56150
Value Function Update Magnitude: 0.62640

Collected Steps per Second: 22,462.23205
Overall Steps per Second: 10,548.39970

Timestep Collection Time: 2.22605
Timestep Consumption Time: 2.51420
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.74025

Cumulative Model Updates: 82,396
Cumulative Timesteps: 687,264,868

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.26875
Policy Entropy: 3.19215
Value Function Loss: 0.00431

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.56790
Value Function Update Magnitude: 0.62116

Collected Steps per Second: 22,146.32464
Overall Steps per Second: 10,468.89877

Timestep Collection Time: 2.25807
Timestep Consumption Time: 2.51874
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.77682

Cumulative Model Updates: 82,402
Cumulative Timesteps: 687,314,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 687314876...
Checkpoint 687314876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.21094
Policy Entropy: 3.20011
Value Function Loss: 0.00441

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.61637

Collected Steps per Second: 22,048.41825
Overall Steps per Second: 10,596.98586

Timestep Collection Time: 2.26801
Timestep Consumption Time: 2.45088
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.71889

Cumulative Model Updates: 82,408
Cumulative Timesteps: 687,364,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.30614
Policy Entropy: 3.20079
Value Function Loss: 0.00440

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.57147
Value Function Update Magnitude: 0.62073

Collected Steps per Second: 21,701.90308
Overall Steps per Second: 10,401.45736

Timestep Collection Time: 2.30441
Timestep Consumption Time: 2.50357
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.80798

Cumulative Model Updates: 82,414
Cumulative Timesteps: 687,414,892

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 687414892...
Checkpoint 687414892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.46541
Policy Entropy: 3.19723
Value Function Loss: 0.00425

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.56897
Value Function Update Magnitude: 0.62091

Collected Steps per Second: 21,255.98133
Overall Steps per Second: 10,285.17824

Timestep Collection Time: 2.35303
Timestep Consumption Time: 2.50989
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.86292

Cumulative Model Updates: 82,420
Cumulative Timesteps: 687,464,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.98546
Policy Entropy: 3.20590
Value Function Loss: 0.00425

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.56029
Value Function Update Magnitude: 0.61081

Collected Steps per Second: 21,724.41779
Overall Steps per Second: 10,445.70484

Timestep Collection Time: 2.30266
Timestep Consumption Time: 2.48629
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.78895

Cumulative Model Updates: 82,426
Cumulative Timesteps: 687,514,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 687514932...
Checkpoint 687514932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.01454
Policy Entropy: 3.21822
Value Function Loss: 0.00432

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.60616

Collected Steps per Second: 22,243.89333
Overall Steps per Second: 10,590.92804

Timestep Collection Time: 2.24826
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.72197

Cumulative Model Updates: 82,432
Cumulative Timesteps: 687,564,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.37059
Policy Entropy: 3.24771
Value Function Loss: 0.00431

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.60143

Collected Steps per Second: 22,089.02245
Overall Steps per Second: 10,563.75813

Timestep Collection Time: 2.26484
Timestep Consumption Time: 2.47098
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.73581

Cumulative Model Updates: 82,438
Cumulative Timesteps: 687,614,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 687614970...
Checkpoint 687614970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.08770
Policy Entropy: 3.25858
Value Function Loss: 0.00438

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.55635
Value Function Update Magnitude: 0.60477

Collected Steps per Second: 21,832.42168
Overall Steps per Second: 10,492.19332

Timestep Collection Time: 2.29200
Timestep Consumption Time: 2.47726
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.76926

Cumulative Model Updates: 82,444
Cumulative Timesteps: 687,665,010

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.19715
Policy Entropy: 3.24612
Value Function Loss: 0.00428

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.56278
Value Function Update Magnitude: 0.61108

Collected Steps per Second: 22,389.68882
Overall Steps per Second: 10,630.48578

Timestep Collection Time: 2.23406
Timestep Consumption Time: 2.47127
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.70534

Cumulative Model Updates: 82,450
Cumulative Timesteps: 687,715,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 687715030...
Checkpoint 687715030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.13947
Policy Entropy: 3.25421
Value Function Loss: 0.00437

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.59985

Collected Steps per Second: 22,129.11983
Overall Steps per Second: 10,532.28527

Timestep Collection Time: 2.26064
Timestep Consumption Time: 2.48914
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.74978

Cumulative Model Updates: 82,456
Cumulative Timesteps: 687,765,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.24431
Policy Entropy: 3.25544
Value Function Loss: 0.00422

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.55485
Value Function Update Magnitude: 0.60729

Collected Steps per Second: 22,528.84152
Overall Steps per Second: 10,531.58523

Timestep Collection Time: 2.22018
Timestep Consumption Time: 2.52916
PPO Batch Consumption Time: 0.29934
Total Iteration Time: 4.74933

Cumulative Model Updates: 82,462
Cumulative Timesteps: 687,815,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 687815074...
Checkpoint 687815074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.26366
Policy Entropy: 3.25319
Value Function Loss: 0.00433

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.55028
Value Function Update Magnitude: 0.62412

Collected Steps per Second: 22,035.23461
Overall Steps per Second: 10,505.48493

Timestep Collection Time: 2.26973
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.76075

Cumulative Model Updates: 82,468
Cumulative Timesteps: 687,865,088

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.22027
Policy Entropy: 3.25251
Value Function Loss: 0.00434

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.62507

Collected Steps per Second: 21,880.75853
Overall Steps per Second: 10,507.48520

Timestep Collection Time: 2.28639
Timestep Consumption Time: 2.47478
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.76118

Cumulative Model Updates: 82,474
Cumulative Timesteps: 687,915,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 687915116...
Checkpoint 687915116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.87206
Policy Entropy: 3.23673
Value Function Loss: 0.00455

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.56360
Value Function Update Magnitude: 0.61510

Collected Steps per Second: 22,292.46776
Overall Steps per Second: 10,676.08691

Timestep Collection Time: 2.24318
Timestep Consumption Time: 2.44075
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.68393

Cumulative Model Updates: 82,480
Cumulative Timesteps: 687,965,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.72047
Policy Entropy: 3.25234
Value Function Loss: 0.00454

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.56930
Value Function Update Magnitude: 0.62145

Collected Steps per Second: 21,496.07562
Overall Steps per Second: 10,520.21033

Timestep Collection Time: 2.32610
Timestep Consumption Time: 2.42685
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.75295

Cumulative Model Updates: 82,486
Cumulative Timesteps: 688,015,124

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 688015124...
Checkpoint 688015124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.15916
Policy Entropy: 3.24778
Value Function Loss: 0.00458

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.56429
Value Function Update Magnitude: 0.63432

Collected Steps per Second: 21,146.91056
Overall Steps per Second: 10,375.06118

Timestep Collection Time: 2.36470
Timestep Consumption Time: 2.45513
PPO Batch Consumption Time: 0.29616
Total Iteration Time: 4.81983

Cumulative Model Updates: 82,492
Cumulative Timesteps: 688,065,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.66462
Policy Entropy: 3.25704
Value Function Loss: 0.00436

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.55137
Value Function Update Magnitude: 0.62609

Collected Steps per Second: 21,138.18548
Overall Steps per Second: 10,321.42882

Timestep Collection Time: 2.36652
Timestep Consumption Time: 2.48009
PPO Batch Consumption Time: 0.29979
Total Iteration Time: 4.84662

Cumulative Model Updates: 82,498
Cumulative Timesteps: 688,115,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 688115154...
Checkpoint 688115154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.76426
Policy Entropy: 3.26386
Value Function Loss: 0.00422

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.53998
Value Function Update Magnitude: 0.60937

Collected Steps per Second: 21,162.07100
Overall Steps per Second: 10,501.49400

Timestep Collection Time: 2.36366
Timestep Consumption Time: 2.39947
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.76313

Cumulative Model Updates: 82,504
Cumulative Timesteps: 688,165,174

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.50572
Policy Entropy: 3.25162
Value Function Loss: 0.00421

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.53188
Value Function Update Magnitude: 0.59313

Collected Steps per Second: 21,432.31202
Overall Steps per Second: 10,507.38791

Timestep Collection Time: 2.33405
Timestep Consumption Time: 2.42679
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.76084

Cumulative Model Updates: 82,510
Cumulative Timesteps: 688,215,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 688215198...
Checkpoint 688215198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.75162
Policy Entropy: 3.24820
Value Function Loss: 0.00431

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.53550
Value Function Update Magnitude: 0.59297

Collected Steps per Second: 21,243.42509
Overall Steps per Second: 10,366.16210

Timestep Collection Time: 2.35423
Timestep Consumption Time: 2.47031
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.82454

Cumulative Model Updates: 82,516
Cumulative Timesteps: 688,265,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.93478
Policy Entropy: 3.25308
Value Function Loss: 0.00448

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.54209
Value Function Update Magnitude: 0.62168

Collected Steps per Second: 22,785.69522
Overall Steps per Second: 10,708.23103

Timestep Collection Time: 2.19471
Timestep Consumption Time: 2.47534
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.67005

Cumulative Model Updates: 82,522
Cumulative Timesteps: 688,315,218

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 688315218...
Checkpoint 688315218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.98809
Policy Entropy: 3.26412
Value Function Loss: 0.00415

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.54108
Value Function Update Magnitude: 0.63453

Collected Steps per Second: 22,317.17672
Overall Steps per Second: 10,594.83217

Timestep Collection Time: 2.24114
Timestep Consumption Time: 2.47965
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.72079

Cumulative Model Updates: 82,528
Cumulative Timesteps: 688,365,234

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.86494
Policy Entropy: 3.25959
Value Function Loss: 0.00410

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.54434
Value Function Update Magnitude: 0.62744

Collected Steps per Second: 23,018.45312
Overall Steps per Second: 10,538.08457

Timestep Collection Time: 2.17408
Timestep Consumption Time: 2.57479
PPO Batch Consumption Time: 0.30136
Total Iteration Time: 4.74887

Cumulative Model Updates: 82,534
Cumulative Timesteps: 688,415,278

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 688415278...
Checkpoint 688415278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.56677
Policy Entropy: 3.24609
Value Function Loss: 0.00408

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.53799
Value Function Update Magnitude: 0.63156

Collected Steps per Second: 22,303.39386
Overall Steps per Second: 10,581.96311

Timestep Collection Time: 2.24208
Timestep Consumption Time: 2.48351
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.72559

Cumulative Model Updates: 82,540
Cumulative Timesteps: 688,465,284

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.77399
Policy Entropy: 3.23453
Value Function Loss: 0.00432

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.53905
Value Function Update Magnitude: 0.63995

Collected Steps per Second: 22,684.50515
Overall Steps per Second: 10,549.37375

Timestep Collection Time: 2.20494
Timestep Consumption Time: 2.53638
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.74132

Cumulative Model Updates: 82,546
Cumulative Timesteps: 688,515,302

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 688515302...
Checkpoint 688515302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.70718
Policy Entropy: 3.22033
Value Function Loss: 0.00435

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.53987
Value Function Update Magnitude: 0.64616

Collected Steps per Second: 22,380.70224
Overall Steps per Second: 10,590.23095

Timestep Collection Time: 2.23532
Timestep Consumption Time: 2.48866
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.72398

Cumulative Model Updates: 82,552
Cumulative Timesteps: 688,565,330

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.50319
Policy Entropy: 3.22556
Value Function Loss: 0.00428

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.54284
Value Function Update Magnitude: 0.64942

Collected Steps per Second: 22,149.98767
Overall Steps per Second: 10,515.87297

Timestep Collection Time: 2.25734
Timestep Consumption Time: 2.49738
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.75472

Cumulative Model Updates: 82,558
Cumulative Timesteps: 688,615,330

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 688615330...
Checkpoint 688615330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775.15536
Policy Entropy: 3.22566
Value Function Loss: 0.00422

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.08055
Policy Update Magnitude: 0.54767
Value Function Update Magnitude: 0.64573

Collected Steps per Second: 22,078.81365
Overall Steps per Second: 10,499.44136

Timestep Collection Time: 2.26480
Timestep Consumption Time: 2.49774
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.76254

Cumulative Model Updates: 82,564
Cumulative Timesteps: 688,665,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.27886
Policy Entropy: 3.21927
Value Function Loss: 0.00423

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.56000
Value Function Update Magnitude: 0.63201

Collected Steps per Second: 22,125.36937
Overall Steps per Second: 10,520.56016

Timestep Collection Time: 2.26102
Timestep Consumption Time: 2.49405
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.75507

Cumulative Model Updates: 82,570
Cumulative Timesteps: 688,715,360

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 688715360...
Checkpoint 688715360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825.42112
Policy Entropy: 3.20903
Value Function Loss: 0.00426

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.63655

Collected Steps per Second: 21,875.22959
Overall Steps per Second: 10,345.18252

Timestep Collection Time: 2.28670
Timestep Consumption Time: 2.54860
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.83529

Cumulative Model Updates: 82,576
Cumulative Timesteps: 688,765,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 895.19527
Policy Entropy: 3.19795
Value Function Loss: 0.00442

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.55170
Value Function Update Magnitude: 0.63454

Collected Steps per Second: 21,748.96728
Overall Steps per Second: 10,396.07300

Timestep Collection Time: 2.29970
Timestep Consumption Time: 2.51135
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.81105

Cumulative Model Updates: 82,582
Cumulative Timesteps: 688,815,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 688815398...
Checkpoint 688815398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.40075
Policy Entropy: 3.20903
Value Function Loss: 0.00438

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.54538
Value Function Update Magnitude: 0.61966

Collected Steps per Second: 22,256.39050
Overall Steps per Second: 10,489.33844

Timestep Collection Time: 2.24789
Timestep Consumption Time: 2.52171
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.76960

Cumulative Model Updates: 82,588
Cumulative Timesteps: 688,865,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.59399
Policy Entropy: 3.20680
Value Function Loss: 0.00457

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.55436
Value Function Update Magnitude: 0.62838

Collected Steps per Second: 22,629.02352
Overall Steps per Second: 10,622.99342

Timestep Collection Time: 2.21061
Timestep Consumption Time: 2.49842
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.70903

Cumulative Model Updates: 82,594
Cumulative Timesteps: 688,915,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 688915452...
Checkpoint 688915452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.57296
Policy Entropy: 3.22103
Value Function Loss: 0.00447

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.55531
Value Function Update Magnitude: 0.64651

Collected Steps per Second: 22,435.54872
Overall Steps per Second: 10,570.42455

Timestep Collection Time: 2.22887
Timestep Consumption Time: 2.50187
PPO Batch Consumption Time: 0.28663
Total Iteration Time: 4.73075

Cumulative Model Updates: 82,600
Cumulative Timesteps: 688,965,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.38726
Policy Entropy: 3.20533
Value Function Loss: 0.00447

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.55411
Value Function Update Magnitude: 0.63462

Collected Steps per Second: 22,467.35026
Overall Steps per Second: 10,462.13173

Timestep Collection Time: 2.22607
Timestep Consumption Time: 2.55440
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.78048

Cumulative Model Updates: 82,606
Cumulative Timesteps: 689,015,472

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 689015472...
Checkpoint 689015472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.80059
Policy Entropy: 3.21055
Value Function Loss: 0.00424

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.54743
Value Function Update Magnitude: 0.60505

Collected Steps per Second: 21,926.49188
Overall Steps per Second: 10,388.25997

Timestep Collection Time: 2.28071
Timestep Consumption Time: 2.53318
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.81390

Cumulative Model Updates: 82,612
Cumulative Timesteps: 689,065,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.48784
Policy Entropy: 3.20391
Value Function Loss: 0.00418

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.53954
Value Function Update Magnitude: 0.60214

Collected Steps per Second: 22,726.91329
Overall Steps per Second: 10,619.47978

Timestep Collection Time: 2.20039
Timestep Consumption Time: 2.50870
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.70908

Cumulative Model Updates: 82,618
Cumulative Timesteps: 689,115,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 689115488...
Checkpoint 689115488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.33939
Policy Entropy: 3.21607
Value Function Loss: 0.00417

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.53706
Value Function Update Magnitude: 0.59358

Collected Steps per Second: 22,404.46857
Overall Steps per Second: 10,531.42068

Timestep Collection Time: 2.23241
Timestep Consumption Time: 2.51680
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.74922

Cumulative Model Updates: 82,624
Cumulative Timesteps: 689,165,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.17786
Policy Entropy: 3.21968
Value Function Loss: 0.00452

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.54136
Value Function Update Magnitude: 0.59715

Collected Steps per Second: 21,874.63048
Overall Steps per Second: 10,335.21348

Timestep Collection Time: 2.28758
Timestep Consumption Time: 2.55412
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.84170

Cumulative Model Updates: 82,630
Cumulative Timesteps: 689,215,544

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 689215544...
Checkpoint 689215544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.80158
Policy Entropy: 3.23016
Value Function Loss: 0.00431

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.54312
Value Function Update Magnitude: 0.61694

Collected Steps per Second: 21,969.56655
Overall Steps per Second: 10,480.87927

Timestep Collection Time: 2.27697
Timestep Consumption Time: 2.49591
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.77288

Cumulative Model Updates: 82,636
Cumulative Timesteps: 689,265,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.22983
Policy Entropy: 3.24255
Value Function Loss: 0.00420

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08616
Policy Update Magnitude: 0.53534
Value Function Update Magnitude: 0.60554

Collected Steps per Second: 21,843.62921
Overall Steps per Second: 10,504.06005

Timestep Collection Time: 2.28973
Timestep Consumption Time: 2.47186
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.76159

Cumulative Model Updates: 82,642
Cumulative Timesteps: 689,315,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 689315584...
Checkpoint 689315584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.68039
Policy Entropy: 3.24514
Value Function Loss: 0.00423

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.52883
Value Function Update Magnitude: 0.61096

Collected Steps per Second: 21,913.51773
Overall Steps per Second: 10,326.09536

Timestep Collection Time: 2.28297
Timestep Consumption Time: 2.56184
PPO Batch Consumption Time: 0.29989
Total Iteration Time: 4.84481

Cumulative Model Updates: 82,648
Cumulative Timesteps: 689,365,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,285.33489
Policy Entropy: 3.24092
Value Function Loss: 0.00419

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.52490
Value Function Update Magnitude: 0.60552

Collected Steps per Second: 21,965.22876
Overall Steps per Second: 10,352.75458

Timestep Collection Time: 2.27696
Timestep Consumption Time: 2.55402
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.83098

Cumulative Model Updates: 82,654
Cumulative Timesteps: 689,415,626

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 689415626...
Checkpoint 689415626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.14759
Policy Entropy: 3.24409
Value Function Loss: 0.00434

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.52650
Value Function Update Magnitude: 0.60571

Collected Steps per Second: 21,477.76728
Overall Steps per Second: 10,243.92916

Timestep Collection Time: 2.32836
Timestep Consumption Time: 2.55336
PPO Batch Consumption Time: 0.29566
Total Iteration Time: 4.88172

Cumulative Model Updates: 82,660
Cumulative Timesteps: 689,465,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.57953
Policy Entropy: 3.23557
Value Function Loss: 0.00432

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.53395
Value Function Update Magnitude: 0.62018

Collected Steps per Second: 22,423.43611
Overall Steps per Second: 10,431.48204

Timestep Collection Time: 2.22990
Timestep Consumption Time: 2.56348
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.79337

Cumulative Model Updates: 82,666
Cumulative Timesteps: 689,515,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 689515636...
Checkpoint 689515636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.02443
Policy Entropy: 3.23287
Value Function Loss: 0.00425

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.53005
Value Function Update Magnitude: 0.62072

Collected Steps per Second: 22,516.18908
Overall Steps per Second: 10,669.14689

Timestep Collection Time: 2.22187
Timestep Consumption Time: 2.46717
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.68903

Cumulative Model Updates: 82,672
Cumulative Timesteps: 689,565,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.42379
Policy Entropy: 3.23492
Value Function Loss: 0.00408

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.53348
Value Function Update Magnitude: 0.61289

Collected Steps per Second: 21,890.97247
Overall Steps per Second: 10,380.62901

Timestep Collection Time: 2.28487
Timestep Consumption Time: 2.53353
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.81840

Cumulative Model Updates: 82,678
Cumulative Timesteps: 689,615,682

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 689615682...
Checkpoint 689615682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.62433
Policy Entropy: 3.24313
Value Function Loss: 0.00431

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09652
Policy Update Magnitude: 0.53369
Value Function Update Magnitude: 0.62384

Collected Steps per Second: 22,475.69780
Overall Steps per Second: 10,686.87839

Timestep Collection Time: 2.22543
Timestep Consumption Time: 2.45489
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.68032

Cumulative Model Updates: 82,684
Cumulative Timesteps: 689,665,700

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.18087
Policy Entropy: 3.25181
Value Function Loss: 0.00420

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.54452
Value Function Update Magnitude: 0.62688

Collected Steps per Second: 22,312.02454
Overall Steps per Second: 10,462.68434

Timestep Collection Time: 2.24139
Timestep Consumption Time: 2.53845
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.77984

Cumulative Model Updates: 82,690
Cumulative Timesteps: 689,715,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 689715710...
Checkpoint 689715710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.16797
Policy Entropy: 3.24888
Value Function Loss: 0.00429

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.07924
Policy Update Magnitude: 0.53990
Value Function Update Magnitude: 0.60926

Collected Steps per Second: 22,547.01672
Overall Steps per Second: 10,680.24275

Timestep Collection Time: 2.21812
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.68267

Cumulative Model Updates: 82,696
Cumulative Timesteps: 689,765,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.76107
Policy Entropy: 3.24242
Value Function Loss: 0.00422

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.54222
Value Function Update Magnitude: 0.60627

Collected Steps per Second: 22,225.49441
Overall Steps per Second: 10,481.86785

Timestep Collection Time: 2.24994
Timestep Consumption Time: 2.52078
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.77071

Cumulative Model Updates: 82,702
Cumulative Timesteps: 689,815,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 689815728...
Checkpoint 689815728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.17284
Policy Entropy: 3.24611
Value Function Loss: 0.00434

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.54905
Value Function Update Magnitude: 0.62526

Collected Steps per Second: 22,106.02848
Overall Steps per Second: 10,486.10710

Timestep Collection Time: 2.26201
Timestep Consumption Time: 2.50659
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.76860

Cumulative Model Updates: 82,708
Cumulative Timesteps: 689,865,732

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.96800
Policy Entropy: 3.24952
Value Function Loss: 0.00436

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.55315
Value Function Update Magnitude: 0.64739

Collected Steps per Second: 22,150.11525
Overall Steps per Second: 10,578.32892

Timestep Collection Time: 2.25859
Timestep Consumption Time: 2.47070
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.72929

Cumulative Model Updates: 82,714
Cumulative Timesteps: 689,915,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 689915760...
Checkpoint 689915760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.55601
Policy Entropy: 3.26155
Value Function Loss: 0.00427

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.55293
Value Function Update Magnitude: 0.65213

Collected Steps per Second: 21,793.99550
Overall Steps per Second: 10,419.62187

Timestep Collection Time: 2.29476
Timestep Consumption Time: 2.50503
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.79979

Cumulative Model Updates: 82,720
Cumulative Timesteps: 689,965,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.23866
Policy Entropy: 3.25118
Value Function Loss: 0.00419

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.63980

Collected Steps per Second: 22,301.47533
Overall Steps per Second: 10,658.01862

Timestep Collection Time: 2.24218
Timestep Consumption Time: 2.44950
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.69168

Cumulative Model Updates: 82,726
Cumulative Timesteps: 690,015,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 690015776...
Checkpoint 690015776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.01175
Policy Entropy: 3.24335
Value Function Loss: 0.00410

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08948
Policy Update Magnitude: 0.54492
Value Function Update Magnitude: 0.62413

Collected Steps per Second: 21,231.05930
Overall Steps per Second: 10,374.15316

Timestep Collection Time: 2.35579
Timestep Consumption Time: 2.46542
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.82121

Cumulative Model Updates: 82,732
Cumulative Timesteps: 690,065,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.07066
Policy Entropy: 3.24054
Value Function Loss: 0.00420

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08136
Policy Update Magnitude: 0.54283
Value Function Update Magnitude: 0.61487

Collected Steps per Second: 21,385.65536
Overall Steps per Second: 10,434.69038

Timestep Collection Time: 2.33895
Timestep Consumption Time: 2.45467
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.79363

Cumulative Model Updates: 82,738
Cumulative Timesteps: 690,115,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 690115812...
Checkpoint 690115812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.24884
Policy Entropy: 3.20984
Value Function Loss: 0.00408

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.54404
Value Function Update Magnitude: 0.61369

Collected Steps per Second: 21,375.80404
Overall Steps per Second: 10,565.36198

Timestep Collection Time: 2.34012
Timestep Consumption Time: 2.39441
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.73453

Cumulative Model Updates: 82,744
Cumulative Timesteps: 690,165,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.49213
Policy Entropy: 3.21569
Value Function Loss: 0.00421

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.54404
Value Function Update Magnitude: 0.60794

Collected Steps per Second: 21,391.93186
Overall Steps per Second: 10,362.36506

Timestep Collection Time: 2.33883
Timestep Consumption Time: 2.48942
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.82824

Cumulative Model Updates: 82,750
Cumulative Timesteps: 690,215,866

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 690215866...
Checkpoint 690215866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.97601
Policy Entropy: 3.21982
Value Function Loss: 0.00419

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.07448
Policy Update Magnitude: 0.54143
Value Function Update Magnitude: 0.59763

Collected Steps per Second: 21,659.94271
Overall Steps per Second: 10,533.09232

Timestep Collection Time: 2.31072
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.75169

Cumulative Model Updates: 82,756
Cumulative Timesteps: 690,265,916

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,029.92812
Policy Entropy: 3.22064
Value Function Loss: 0.00423

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.53349
Value Function Update Magnitude: 0.59594

Collected Steps per Second: 21,931.17212
Overall Steps per Second: 10,650.05756

Timestep Collection Time: 2.27995
Timestep Consumption Time: 2.41505
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.69500

Cumulative Model Updates: 82,762
Cumulative Timesteps: 690,315,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 690315918...
Checkpoint 690315918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.66544
Policy Entropy: 3.22839
Value Function Loss: 0.00422

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08247
Policy Update Magnitude: 0.52847
Value Function Update Magnitude: 0.59522

Collected Steps per Second: 21,884.23241
Overall Steps per Second: 10,586.47012

Timestep Collection Time: 2.28475
Timestep Consumption Time: 2.43826
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.72301

Cumulative Model Updates: 82,768
Cumulative Timesteps: 690,365,918

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.13005
Policy Entropy: 3.23436
Value Function Loss: 0.00430

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08838
Policy Update Magnitude: 0.53172
Value Function Update Magnitude: 0.61289

Collected Steps per Second: 21,225.00324
Overall Steps per Second: 10,494.73799

Timestep Collection Time: 2.35590
Timestep Consumption Time: 2.40877
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.76467

Cumulative Model Updates: 82,774
Cumulative Timesteps: 690,415,922

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 690415922...
Checkpoint 690415922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.06756
Policy Entropy: 3.24920
Value Function Loss: 0.00408

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.53350
Value Function Update Magnitude: 0.63307

Collected Steps per Second: 21,487.78233
Overall Steps per Second: 10,543.73957

Timestep Collection Time: 2.32765
Timestep Consumption Time: 2.41602
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.74367

Cumulative Model Updates: 82,780
Cumulative Timesteps: 690,465,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.76604
Policy Entropy: 3.23766
Value Function Loss: 0.00427

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.53147
Value Function Update Magnitude: 0.62463

Collected Steps per Second: 22,045.72027
Overall Steps per Second: 10,519.27231

Timestep Collection Time: 2.26801
Timestep Consumption Time: 2.48517
PPO Batch Consumption Time: 0.29855
Total Iteration Time: 4.75318

Cumulative Model Updates: 82,786
Cumulative Timesteps: 690,515,938

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 690515938...
Checkpoint 690515938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.54873
Policy Entropy: 3.23908
Value Function Loss: 0.00400

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.52806
Value Function Update Magnitude: 0.62373

Collected Steps per Second: 21,283.55063
Overall Steps per Second: 10,543.16572

Timestep Collection Time: 2.34980
Timestep Consumption Time: 2.39375
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.74355

Cumulative Model Updates: 82,792
Cumulative Timesteps: 690,565,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.89850
Policy Entropy: 3.23758
Value Function Loss: 0.00393

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.52628
Value Function Update Magnitude: 0.61443

Collected Steps per Second: 21,545.59572
Overall Steps per Second: 10,582.81264

Timestep Collection Time: 2.32066
Timestep Consumption Time: 2.40398
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.72464

Cumulative Model Updates: 82,798
Cumulative Timesteps: 690,615,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 690615950...
Checkpoint 690615950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847.66965
Policy Entropy: 3.24450
Value Function Loss: 0.00391

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.52225
Value Function Update Magnitude: 0.59778

Collected Steps per Second: 21,927.75003
Overall Steps per Second: 10,531.43514

Timestep Collection Time: 2.28122
Timestep Consumption Time: 2.46856
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.74978

Cumulative Model Updates: 82,804
Cumulative Timesteps: 690,665,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.71686
Policy Entropy: 3.22722
Value Function Loss: 0.00406

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09918
Policy Update Magnitude: 0.52817
Value Function Update Magnitude: 0.60769

Collected Steps per Second: 21,485.69948
Overall Steps per Second: 10,404.64137

Timestep Collection Time: 2.32815
Timestep Consumption Time: 2.47951
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.80766

Cumulative Model Updates: 82,810
Cumulative Timesteps: 690,715,994

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 690715994...
Checkpoint 690715994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,006.52461
Policy Entropy: 3.21900
Value Function Loss: 0.00423

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.53915
Value Function Update Magnitude: 0.63343

Collected Steps per Second: 20,711.82153
Overall Steps per Second: 10,342.14038

Timestep Collection Time: 2.41456
Timestep Consumption Time: 2.42099
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.83556

Cumulative Model Updates: 82,816
Cumulative Timesteps: 690,766,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.29636
Policy Entropy: 3.22181
Value Function Loss: 0.00417

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.54325
Value Function Update Magnitude: 0.62711

Collected Steps per Second: 22,431.92334
Overall Steps per Second: 10,446.40043

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.55799
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.78749

Cumulative Model Updates: 82,822
Cumulative Timesteps: 690,816,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 690816016...
Checkpoint 690816016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 952.86460
Policy Entropy: 3.22551
Value Function Loss: 0.00427

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.54723
Value Function Update Magnitude: 0.63447

Collected Steps per Second: 22,673.19623
Overall Steps per Second: 10,576.30140

Timestep Collection Time: 2.20534
Timestep Consumption Time: 2.52240
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.72774

Cumulative Model Updates: 82,828
Cumulative Timesteps: 690,866,018

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.33425
Policy Entropy: 3.22872
Value Function Loss: 0.00428

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.54605
Value Function Update Magnitude: 0.64375

Collected Steps per Second: 22,537.27549
Overall Steps per Second: 10,525.51263

Timestep Collection Time: 2.21943
Timestep Consumption Time: 2.53283
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.75226

Cumulative Model Updates: 82,834
Cumulative Timesteps: 690,916,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 690916038...
Checkpoint 690916038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.49309
Policy Entropy: 3.24507
Value Function Loss: 0.00433

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.53980
Value Function Update Magnitude: 0.63637

Collected Steps per Second: 22,271.67822
Overall Steps per Second: 10,537.55124

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.50023
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.74550

Cumulative Model Updates: 82,840
Cumulative Timesteps: 690,966,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.52650
Policy Entropy: 3.24773
Value Function Loss: 0.00426

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.53174
Value Function Update Magnitude: 0.62118

Collected Steps per Second: 22,792.92435
Overall Steps per Second: 10,531.68257

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.55473
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.74910

Cumulative Model Updates: 82,846
Cumulative Timesteps: 691,016,060

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 691016060...
Checkpoint 691016060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.77773
Policy Entropy: 3.23113
Value Function Loss: 0.00418

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09170
Policy Update Magnitude: 0.53411
Value Function Update Magnitude: 0.62330

Collected Steps per Second: 22,341.95930
Overall Steps per Second: 10,579.65631

Timestep Collection Time: 2.23848
Timestep Consumption Time: 2.48871
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.72719

Cumulative Model Updates: 82,852
Cumulative Timesteps: 691,066,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.44916
Policy Entropy: 3.20909
Value Function Loss: 0.00413

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.53664
Value Function Update Magnitude: 0.63668

Collected Steps per Second: 22,751.73912
Overall Steps per Second: 10,514.95145

Timestep Collection Time: 2.19763
Timestep Consumption Time: 2.55750
PPO Batch Consumption Time: 0.29978
Total Iteration Time: 4.75513

Cumulative Model Updates: 82,858
Cumulative Timesteps: 691,116,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 691116072...
Checkpoint 691116072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 829.37474
Policy Entropy: 3.20504
Value Function Loss: 0.00421

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.53997
Value Function Update Magnitude: 0.63195

Collected Steps per Second: 21,897.83099
Overall Steps per Second: 10,467.63084

Timestep Collection Time: 2.28424
Timestep Consumption Time: 2.49430
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.77854

Cumulative Model Updates: 82,864
Cumulative Timesteps: 691,166,092

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.34244
Policy Entropy: 3.20844
Value Function Loss: 0.00433

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.54868
Value Function Update Magnitude: 0.62224

Collected Steps per Second: 22,246.94896
Overall Steps per Second: 10,534.54532

Timestep Collection Time: 2.24903
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.74952

Cumulative Model Updates: 82,870
Cumulative Timesteps: 691,216,126

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 691216126...
Checkpoint 691216126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.95307
Policy Entropy: 3.21646
Value Function Loss: 0.00434

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.55807
Value Function Update Magnitude: 0.62427

Collected Steps per Second: 21,895.83695
Overall Steps per Second: 10,269.39725

Timestep Collection Time: 2.28418
Timestep Consumption Time: 2.58602
PPO Batch Consumption Time: 0.30053
Total Iteration Time: 4.87020

Cumulative Model Updates: 82,876
Cumulative Timesteps: 691,266,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,825.12323
Policy Entropy: 3.22103
Value Function Loss: 0.00424

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11592
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.61884

Collected Steps per Second: 21,344.79642
Overall Steps per Second: 10,512.62309

Timestep Collection Time: 2.34352
Timestep Consumption Time: 2.41476
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.75828

Cumulative Model Updates: 82,882
Cumulative Timesteps: 691,316,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 691316162...
Checkpoint 691316162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.15590
Policy Entropy: 3.22246
Value Function Loss: 0.00422

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.54106
Value Function Update Magnitude: 0.62872

Collected Steps per Second: 21,922.88744
Overall Steps per Second: 10,246.46003

Timestep Collection Time: 2.28209
Timestep Consumption Time: 2.60057
PPO Batch Consumption Time: 0.30445
Total Iteration Time: 4.88266

Cumulative Model Updates: 82,888
Cumulative Timesteps: 691,366,192

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.70462
Policy Entropy: 3.22239
Value Function Loss: 0.00429

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.63440

Collected Steps per Second: 21,269.42670
Overall Steps per Second: 10,449.50785

Timestep Collection Time: 2.35201
Timestep Consumption Time: 2.43539
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.78740

Cumulative Model Updates: 82,894
Cumulative Timesteps: 691,416,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 691416218...
Checkpoint 691416218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.83180
Policy Entropy: 3.22157
Value Function Loss: 0.00438

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.55551
Value Function Update Magnitude: 0.64628

Collected Steps per Second: 21,666.29702
Overall Steps per Second: 10,520.62875

Timestep Collection Time: 2.30893
Timestep Consumption Time: 2.44611
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.75504

Cumulative Model Updates: 82,900
Cumulative Timesteps: 691,466,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.30146
Policy Entropy: 3.22021
Value Function Loss: 0.00449

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.63398

Collected Steps per Second: 21,879.76821
Overall Steps per Second: 10,486.32382

Timestep Collection Time: 2.28558
Timestep Consumption Time: 2.48330
PPO Batch Consumption Time: 0.29909
Total Iteration Time: 4.76888

Cumulative Model Updates: 82,906
Cumulative Timesteps: 691,516,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 691516252...
Checkpoint 691516252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.31904
Policy Entropy: 3.23156
Value Function Loss: 0.00419

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.54771
Value Function Update Magnitude: 0.62515

Collected Steps per Second: 21,321.16079
Overall Steps per Second: 10,389.07320

Timestep Collection Time: 2.34565
Timestep Consumption Time: 2.46825
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.81390

Cumulative Model Updates: 82,912
Cumulative Timesteps: 691,566,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.53344
Policy Entropy: 3.22404
Value Function Loss: 0.00412

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.53641
Value Function Update Magnitude: 0.60970

Collected Steps per Second: 22,789.59537
Overall Steps per Second: 10,662.94149

Timestep Collection Time: 2.19477
Timestep Consumption Time: 2.49605
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.69083

Cumulative Model Updates: 82,918
Cumulative Timesteps: 691,616,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 691616282...
Checkpoint 691616282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.15392
Policy Entropy: 3.22402
Value Function Loss: 0.00402

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.07788
Policy Update Magnitude: 0.54242
Value Function Update Magnitude: 0.60951

Collected Steps per Second: 22,112.59576
Overall Steps per Second: 10,484.97461

Timestep Collection Time: 2.26251
Timestep Consumption Time: 2.50908
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.77159

Cumulative Model Updates: 82,924
Cumulative Timesteps: 691,666,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.64462
Policy Entropy: 3.22772
Value Function Loss: 0.00410

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.54854
Value Function Update Magnitude: 0.62058

Collected Steps per Second: 21,958.89226
Overall Steps per Second: 10,658.35723

Timestep Collection Time: 2.27826
Timestep Consumption Time: 2.41552
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.69378

Cumulative Model Updates: 82,930
Cumulative Timesteps: 691,716,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 691716340...
Checkpoint 691716340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.56589
Policy Entropy: 3.21879
Value Function Loss: 0.00418

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.54635
Value Function Update Magnitude: 0.64129

Collected Steps per Second: 21,165.39401
Overall Steps per Second: 10,230.11312

Timestep Collection Time: 2.36329
Timestep Consumption Time: 2.52619
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.88949

Cumulative Model Updates: 82,936
Cumulative Timesteps: 691,766,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.96527
Policy Entropy: 3.23596
Value Function Loss: 0.00444

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.55226
Value Function Update Magnitude: 0.64800

Collected Steps per Second: 22,293.26580
Overall Steps per Second: 10,487.66554

Timestep Collection Time: 2.24310
Timestep Consumption Time: 2.52498
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.76808

Cumulative Model Updates: 82,942
Cumulative Timesteps: 691,816,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 691816366...
Checkpoint 691816366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917.31830
Policy Entropy: 3.25050
Value Function Loss: 0.00447

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.65463

Collected Steps per Second: 21,831.44728
Overall Steps per Second: 10,388.00686

Timestep Collection Time: 2.29128
Timestep Consumption Time: 2.52408
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.81536

Cumulative Model Updates: 82,948
Cumulative Timesteps: 691,866,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.62206
Policy Entropy: 3.26164
Value Function Loss: 0.00434

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08857
Policy Update Magnitude: 0.55030
Value Function Update Magnitude: 0.65297

Collected Steps per Second: 22,313.64295
Overall Steps per Second: 10,639.75981

Timestep Collection Time: 2.24114
Timestep Consumption Time: 2.45897
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.70011

Cumulative Model Updates: 82,954
Cumulative Timesteps: 691,916,396

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 691916396...
Checkpoint 691916396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.64482
Policy Entropy: 3.26449
Value Function Loss: 0.00405

Mean KL Divergence: 0.00728
SB3 Clip Fraction: 0.07921
Policy Update Magnitude: 0.53826
Value Function Update Magnitude: 0.63929

Collected Steps per Second: 21,721.13922
Overall Steps per Second: 10,272.47702

Timestep Collection Time: 2.30209
Timestep Consumption Time: 2.56568
PPO Batch Consumption Time: 0.30103
Total Iteration Time: 4.86776

Cumulative Model Updates: 82,960
Cumulative Timesteps: 691,966,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.61579
Policy Entropy: 3.25406
Value Function Loss: 0.00415

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08210
Policy Update Magnitude: 0.53522
Value Function Update Magnitude: 0.61430

Collected Steps per Second: 22,438.80431
Overall Steps per Second: 10,293.59441

Timestep Collection Time: 2.22935
Timestep Consumption Time: 2.63037
PPO Batch Consumption Time: 0.30881
Total Iteration Time: 4.85972

Cumulative Model Updates: 82,966
Cumulative Timesteps: 692,016,424

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 692016424...
Checkpoint 692016424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.82403
Policy Entropy: 3.25285
Value Function Loss: 0.00435

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08211
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.62408

Collected Steps per Second: 21,572.71137
Overall Steps per Second: 10,397.19172

Timestep Collection Time: 2.31904
Timestep Consumption Time: 2.49264
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.81168

Cumulative Model Updates: 82,972
Cumulative Timesteps: 692,066,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.28588
Policy Entropy: 3.24800
Value Function Loss: 0.00425

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.54572
Value Function Update Magnitude: 0.62061

Collected Steps per Second: 22,505.77328
Overall Steps per Second: 10,399.07825

Timestep Collection Time: 2.22183
Timestep Consumption Time: 2.58667
PPO Batch Consumption Time: 0.29895
Total Iteration Time: 4.80850

Cumulative Model Updates: 82,978
Cumulative Timesteps: 692,116,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 692116456...
Checkpoint 692116456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,670.03621
Policy Entropy: 3.24294
Value Function Loss: 0.00418

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.53830
Value Function Update Magnitude: 0.59951

Collected Steps per Second: 22,007.72734
Overall Steps per Second: 10,334.22918

Timestep Collection Time: 2.27302
Timestep Consumption Time: 2.56759
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.84061

Cumulative Model Updates: 82,984
Cumulative Timesteps: 692,166,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.88744
Policy Entropy: 3.24507
Value Function Loss: 0.00416

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08658
Policy Update Magnitude: 0.53239
Value Function Update Magnitude: 0.57530

Collected Steps per Second: 22,346.04624
Overall Steps per Second: 10,337.68810

Timestep Collection Time: 2.23825
Timestep Consumption Time: 2.59997
PPO Batch Consumption Time: 0.30135
Total Iteration Time: 4.83822

Cumulative Model Updates: 82,990
Cumulative Timesteps: 692,216,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 692216496...
Checkpoint 692216496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.49165
Policy Entropy: 3.23792
Value Function Loss: 0.00429

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.58615

Collected Steps per Second: 22,127.28302
Overall Steps per Second: 10,550.49518

Timestep Collection Time: 2.26056
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.74101

Cumulative Model Updates: 82,996
Cumulative Timesteps: 692,266,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.58348
Policy Entropy: 3.24284
Value Function Loss: 0.00407

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.53988
Value Function Update Magnitude: 0.60774

Collected Steps per Second: 22,813.40940
Overall Steps per Second: 10,581.21872

Timestep Collection Time: 2.19292
Timestep Consumption Time: 2.53508
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.72800

Cumulative Model Updates: 83,002
Cumulative Timesteps: 692,316,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 692316544...
Checkpoint 692316544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.06555
Policy Entropy: 3.24660
Value Function Loss: 0.00391

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.53112
Value Function Update Magnitude: 0.60138

Collected Steps per Second: 22,152.91115
Overall Steps per Second: 10,546.89027

Timestep Collection Time: 2.25803
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.74282

Cumulative Model Updates: 83,008
Cumulative Timesteps: 692,366,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.56035
Policy Entropy: 3.23406
Value Function Loss: 0.00392

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.53460
Value Function Update Magnitude: 0.60184

Collected Steps per Second: 22,505.88186
Overall Steps per Second: 10,594.59137

Timestep Collection Time: 2.22306
Timestep Consumption Time: 2.49935
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.72241

Cumulative Model Updates: 83,014
Cumulative Timesteps: 692,416,598

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 692416598...
Checkpoint 692416598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.84827
Policy Entropy: 3.22262
Value Function Loss: 0.00410

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.54275
Value Function Update Magnitude: 0.59415

Collected Steps per Second: 22,578.87642
Overall Steps per Second: 10,586.21616

Timestep Collection Time: 2.21517
Timestep Consumption Time: 2.50947
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.72463

Cumulative Model Updates: 83,020
Cumulative Timesteps: 692,466,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.87664
Policy Entropy: 3.20477
Value Function Loss: 0.00438

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.60064

Collected Steps per Second: 22,274.53757
Overall Steps per Second: 10,480.49667

Timestep Collection Time: 2.24481
Timestep Consumption Time: 2.52615
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.77096

Cumulative Model Updates: 83,026
Cumulative Timesteps: 692,516,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 692516616...
Checkpoint 692516616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.90269
Policy Entropy: 3.21277
Value Function Loss: 0.00423

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.54218
Value Function Update Magnitude: 0.59966

Collected Steps per Second: 21,857.66848
Overall Steps per Second: 10,394.15525

Timestep Collection Time: 2.28853
Timestep Consumption Time: 2.52398
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.81251

Cumulative Model Updates: 83,032
Cumulative Timesteps: 692,566,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.09749
Policy Entropy: 3.21942
Value Function Loss: 0.00447

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.54048
Value Function Update Magnitude: 0.60434

Collected Steps per Second: 22,354.76144
Overall Steps per Second: 10,562.60488

Timestep Collection Time: 2.23684
Timestep Consumption Time: 2.49722
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.73406

Cumulative Model Updates: 83,038
Cumulative Timesteps: 692,616,642

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 692616642...
Checkpoint 692616642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.92015
Policy Entropy: 3.24544
Value Function Loss: 0.00423

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.54776
Value Function Update Magnitude: 0.62146

Collected Steps per Second: 21,520.92416
Overall Steps per Second: 10,187.91597

Timestep Collection Time: 2.32360
Timestep Consumption Time: 2.58476
PPO Batch Consumption Time: 0.30341
Total Iteration Time: 4.90836

Cumulative Model Updates: 83,044
Cumulative Timesteps: 692,666,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.79421
Policy Entropy: 3.22775
Value Function Loss: 0.00440

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.54884
Value Function Update Magnitude: 0.62075

Collected Steps per Second: 22,315.86577
Overall Steps per Second: 10,568.35949

Timestep Collection Time: 2.24065
Timestep Consumption Time: 2.49064
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.73129

Cumulative Model Updates: 83,050
Cumulative Timesteps: 692,716,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 692716650...
Checkpoint 692716650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.52155
Policy Entropy: 3.23389
Value Function Loss: 0.00424

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.62762

Collected Steps per Second: 21,816.76959
Overall Steps per Second: 10,366.37727

Timestep Collection Time: 2.29218
Timestep Consumption Time: 2.53188
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.82406

Cumulative Model Updates: 83,056
Cumulative Timesteps: 692,766,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.38108
Policy Entropy: 3.21175
Value Function Loss: 0.00431

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.54664
Value Function Update Magnitude: 0.62676

Collected Steps per Second: 22,393.79383
Overall Steps per Second: 10,429.90149

Timestep Collection Time: 2.23303
Timestep Consumption Time: 2.56145
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.79448

Cumulative Model Updates: 83,062
Cumulative Timesteps: 692,816,664

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 692816664...
Checkpoint 692816664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.95398
Policy Entropy: 3.19957
Value Function Loss: 0.00445

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.54793
Value Function Update Magnitude: 0.64050

Collected Steps per Second: 22,832.55303
Overall Steps per Second: 10,517.44837

Timestep Collection Time: 2.19073
Timestep Consumption Time: 2.56517
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 4.75591

Cumulative Model Updates: 83,068
Cumulative Timesteps: 692,866,684

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 549.40126
Policy Entropy: 3.21279
Value Function Loss: 0.00435

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.67192

Collected Steps per Second: 22,413.96886
Overall Steps per Second: 10,483.05970

Timestep Collection Time: 2.23271
Timestep Consumption Time: 2.54108
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.77380

Cumulative Model Updates: 83,074
Cumulative Timesteps: 692,916,728

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 692916728...
Checkpoint 692916728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.96429
Policy Entropy: 3.20952
Value Function Loss: 0.00434

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.55564
Value Function Update Magnitude: 0.70901

Collected Steps per Second: 22,381.94121
Overall Steps per Second: 10,581.48197

Timestep Collection Time: 2.23448
Timestep Consumption Time: 2.49189
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.72637

Cumulative Model Updates: 83,080
Cumulative Timesteps: 692,966,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.42778
Policy Entropy: 3.21169
Value Function Loss: 0.00428

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08987
Policy Update Magnitude: 0.55710
Value Function Update Magnitude: 0.68416

Collected Steps per Second: 22,253.16178
Overall Steps per Second: 10,533.69655

Timestep Collection Time: 2.24732
Timestep Consumption Time: 2.50030
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.74762

Cumulative Model Updates: 83,086
Cumulative Timesteps: 693,016,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 693016750...
Checkpoint 693016750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.26491
Policy Entropy: 3.19561
Value Function Loss: 0.00419

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08875
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.65501

Collected Steps per Second: 22,410.45628
Overall Steps per Second: 10,582.92726

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.49489
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.72724

Cumulative Model Updates: 83,092
Cumulative Timesteps: 693,066,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.76882
Policy Entropy: 3.18481
Value Function Loss: 0.00410

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.54232
Value Function Update Magnitude: 0.61966

Collected Steps per Second: 22,577.40708
Overall Steps per Second: 10,512.74029

Timestep Collection Time: 2.21567
Timestep Consumption Time: 2.54275
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.75842

Cumulative Model Updates: 83,098
Cumulative Timesteps: 693,116,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 693116802...
Checkpoint 693116802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.06466
Policy Entropy: 3.19797
Value Function Loss: 0.00412

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.54543
Value Function Update Magnitude: 0.62705

Collected Steps per Second: 22,117.12133
Overall Steps per Second: 10,549.95601

Timestep Collection Time: 2.26123
Timestep Consumption Time: 2.47926
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.74049

Cumulative Model Updates: 83,104
Cumulative Timesteps: 693,166,814

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.05954
Policy Entropy: 3.18647
Value Function Loss: 0.00423

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.55309
Value Function Update Magnitude: 0.64106

Collected Steps per Second: 22,341.93711
Overall Steps per Second: 10,516.51292

Timestep Collection Time: 2.23938
Timestep Consumption Time: 2.51809
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.75747

Cumulative Model Updates: 83,110
Cumulative Timesteps: 693,216,846

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 693216846...
Checkpoint 693216846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.29105
Policy Entropy: 3.19928
Value Function Loss: 0.00435

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.55681
Value Function Update Magnitude: 0.63511

Collected Steps per Second: 21,677.77371
Overall Steps per Second: 10,342.67251

Timestep Collection Time: 2.30771
Timestep Consumption Time: 2.52914
PPO Batch Consumption Time: 0.29768
Total Iteration Time: 4.83685

Cumulative Model Updates: 83,116
Cumulative Timesteps: 693,266,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.48930
Policy Entropy: 3.18661
Value Function Loss: 0.00426

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.55277
Value Function Update Magnitude: 0.64616

Collected Steps per Second: 22,148.47760
Overall Steps per Second: 10,474.41802

Timestep Collection Time: 2.25858
Timestep Consumption Time: 2.51725
PPO Batch Consumption Time: 0.29705
Total Iteration Time: 4.77583

Cumulative Model Updates: 83,122
Cumulative Timesteps: 693,316,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 693316896...
Checkpoint 693316896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.79869
Policy Entropy: 3.17847
Value Function Loss: 0.00429

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11480
Policy Update Magnitude: 0.55441
Value Function Update Magnitude: 0.62199

Collected Steps per Second: 22,223.13456
Overall Steps per Second: 10,519.09425

Timestep Collection Time: 2.25063
Timestep Consumption Time: 2.50415
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.75478

Cumulative Model Updates: 83,128
Cumulative Timesteps: 693,366,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 872.40993
Policy Entropy: 3.17953
Value Function Loss: 0.00416

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.54839
Value Function Update Magnitude: 0.59264

Collected Steps per Second: 21,996.64806
Overall Steps per Second: 10,471.33511

Timestep Collection Time: 2.27307
Timestep Consumption Time: 2.50187
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.77494

Cumulative Model Updates: 83,134
Cumulative Timesteps: 693,416,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 693416912...
Checkpoint 693416912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.45938
Policy Entropy: 3.18382
Value Function Loss: 0.00411

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.54036
Value Function Update Magnitude: 0.60069

Collected Steps per Second: 22,304.36454
Overall Steps per Second: 10,636.20969

Timestep Collection Time: 2.24234
Timestep Consumption Time: 2.45990
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.70224

Cumulative Model Updates: 83,140
Cumulative Timesteps: 693,466,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.06007
Policy Entropy: 3.21541
Value Function Loss: 0.00400

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.53127
Value Function Update Magnitude: 0.60416

Collected Steps per Second: 22,179.40632
Overall Steps per Second: 10,496.19885

Timestep Collection Time: 2.25461
Timestep Consumption Time: 2.50959
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.76420

Cumulative Model Updates: 83,146
Cumulative Timesteps: 693,516,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 693516932...
Checkpoint 693516932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.27164
Policy Entropy: 3.21178
Value Function Loss: 0.00409

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09101
Policy Update Magnitude: 0.53136
Value Function Update Magnitude: 0.61062

Collected Steps per Second: 22,344.90727
Overall Steps per Second: 10,597.22682

Timestep Collection Time: 2.23854
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.72010

Cumulative Model Updates: 83,152
Cumulative Timesteps: 693,566,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,483.90967
Policy Entropy: 3.20593
Value Function Loss: 0.00418

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.53918
Value Function Update Magnitude: 0.62567

Collected Steps per Second: 22,385.96478
Overall Steps per Second: 10,484.27176

Timestep Collection Time: 2.23390
Timestep Consumption Time: 2.53591
PPO Batch Consumption Time: 0.30005
Total Iteration Time: 4.76981

Cumulative Model Updates: 83,158
Cumulative Timesteps: 693,616,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 693616960...
Checkpoint 693616960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619.76200
Policy Entropy: 3.21112
Value Function Loss: 0.00406

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.54187
Value Function Update Magnitude: 0.63417

Collected Steps per Second: 22,626.74686
Overall Steps per Second: 10,598.56660

Timestep Collection Time: 2.21013
Timestep Consumption Time: 2.50825
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.71837

Cumulative Model Updates: 83,164
Cumulative Timesteps: 693,666,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.21880
Policy Entropy: 3.22527
Value Function Loss: 0.00410

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10771
Policy Update Magnitude: 0.53866
Value Function Update Magnitude: 0.62123

Collected Steps per Second: 22,623.55447
Overall Steps per Second: 10,585.56907

Timestep Collection Time: 2.21124
Timestep Consumption Time: 2.51463
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.72587

Cumulative Model Updates: 83,170
Cumulative Timesteps: 693,716,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 693716994...
Checkpoint 693716994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.18622
Policy Entropy: 3.22279
Value Function Loss: 0.00425

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.54411
Value Function Update Magnitude: 0.62984

Collected Steps per Second: 22,329.22043
Overall Steps per Second: 10,596.23625

Timestep Collection Time: 2.24020
Timestep Consumption Time: 2.48053
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.72073

Cumulative Model Updates: 83,176
Cumulative Timesteps: 693,767,016

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.85229
Policy Entropy: 3.21629
Value Function Loss: 0.00429

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.55338
Value Function Update Magnitude: 0.64244

Collected Steps per Second: 22,047.16648
Overall Steps per Second: 10,354.79919

Timestep Collection Time: 2.26832
Timestep Consumption Time: 2.56133
PPO Batch Consumption Time: 0.30166
Total Iteration Time: 4.82964

Cumulative Model Updates: 83,182
Cumulative Timesteps: 693,817,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 693817026...
Checkpoint 693817026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.61907
Policy Entropy: 3.21108
Value Function Loss: 0.00458

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.64681

Collected Steps per Second: 22,155.27567
Overall Steps per Second: 10,599.01668

Timestep Collection Time: 2.25815
Timestep Consumption Time: 2.46210
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.72025

Cumulative Model Updates: 83,188
Cumulative Timesteps: 693,867,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894.01843
Policy Entropy: 3.21912
Value Function Loss: 0.00455

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.56088
Value Function Update Magnitude: 0.64597

Collected Steps per Second: 21,876.99568
Overall Steps per Second: 10,508.96608

Timestep Collection Time: 2.28697
Timestep Consumption Time: 2.47392
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.76089

Cumulative Model Updates: 83,194
Cumulative Timesteps: 693,917,088

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 693917088...
Checkpoint 693917088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.73736
Policy Entropy: 3.22405
Value Function Loss: 0.00452

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.64278

Collected Steps per Second: 22,106.81872
Overall Steps per Second: 10,451.74153

Timestep Collection Time: 2.26265
Timestep Consumption Time: 2.52315
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.78581

Cumulative Model Updates: 83,200
Cumulative Timesteps: 693,967,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.01823
Policy Entropy: 3.22258
Value Function Loss: 0.00425

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.55006
Value Function Update Magnitude: 0.65772

Collected Steps per Second: 22,217.38989
Overall Steps per Second: 10,519.52289

Timestep Collection Time: 2.25058
Timestep Consumption Time: 2.50268
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.75326

Cumulative Model Updates: 83,206
Cumulative Timesteps: 694,017,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 694017110...
Checkpoint 694017110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 785.53313
Policy Entropy: 3.22644
Value Function Loss: 0.00388

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.54342
Value Function Update Magnitude: 0.66703

Collected Steps per Second: 22,594.54791
Overall Steps per Second: 10,476.69595

Timestep Collection Time: 2.21328
Timestep Consumption Time: 2.55998
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.77326

Cumulative Model Updates: 83,212
Cumulative Timesteps: 694,067,118

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.29108
Policy Entropy: 3.21854
Value Function Loss: 0.00416

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.53587
Value Function Update Magnitude: 0.65606

Collected Steps per Second: 22,572.34893
Overall Steps per Second: 10,675.75224

Timestep Collection Time: 2.21616
Timestep Consumption Time: 2.46960
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.68576

Cumulative Model Updates: 83,218
Cumulative Timesteps: 694,117,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 694117142...
Checkpoint 694117142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 731.53243
Policy Entropy: 3.21676
Value Function Loss: 0.00447

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.55233
Value Function Update Magnitude: 0.65342

Collected Steps per Second: 22,427.37711
Overall Steps per Second: 10,663.80161

Timestep Collection Time: 2.23049
Timestep Consumption Time: 2.46052
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.69101

Cumulative Model Updates: 83,224
Cumulative Timesteps: 694,167,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.65916
Policy Entropy: 3.21255
Value Function Loss: 0.00461

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.55691
Value Function Update Magnitude: 0.64515

Collected Steps per Second: 22,527.55815
Overall Steps per Second: 10,488.27276

Timestep Collection Time: 2.22021
Timestep Consumption Time: 2.54854
PPO Batch Consumption Time: 0.29968
Total Iteration Time: 4.76875

Cumulative Model Updates: 83,230
Cumulative Timesteps: 694,217,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 694217182...
Checkpoint 694217182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.69001
Policy Entropy: 3.21276
Value Function Loss: 0.00443

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.55402
Value Function Update Magnitude: 0.62540

Collected Steps per Second: 22,201.15755
Overall Steps per Second: 10,737.46084

Timestep Collection Time: 2.25412
Timestep Consumption Time: 2.40658
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.66069

Cumulative Model Updates: 83,236
Cumulative Timesteps: 694,267,226

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.09370
Policy Entropy: 3.20586
Value Function Loss: 0.00452

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.54767
Value Function Update Magnitude: 0.62825

Collected Steps per Second: 21,639.89570
Overall Steps per Second: 10,391.83837

Timestep Collection Time: 2.31147
Timestep Consumption Time: 2.50192
PPO Batch Consumption Time: 0.30105
Total Iteration Time: 4.81339

Cumulative Model Updates: 83,242
Cumulative Timesteps: 694,317,246

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 694317246...
Checkpoint 694317246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,602.39971
Policy Entropy: 3.18510
Value Function Loss: 0.00435

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.54913
Value Function Update Magnitude: 0.64565

Collected Steps per Second: 21,766.42058
Overall Steps per Second: 10,658.31617

Timestep Collection Time: 2.29785
Timestep Consumption Time: 2.39482
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.69267

Cumulative Model Updates: 83,248
Cumulative Timesteps: 694,367,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.75468
Policy Entropy: 3.17856
Value Function Loss: 0.00419

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.54990
Value Function Update Magnitude: 0.63889

Collected Steps per Second: 21,572.13988
Overall Steps per Second: 10,459.89714

Timestep Collection Time: 2.31882
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.78227

Cumulative Model Updates: 83,254
Cumulative Timesteps: 694,417,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 694417284...
Checkpoint 694417284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.40110
Policy Entropy: 3.17865
Value Function Loss: 0.00418

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.54561
Value Function Update Magnitude: 0.61552

Collected Steps per Second: 21,326.66396
Overall Steps per Second: 10,401.44279

Timestep Collection Time: 2.34561
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.80933

Cumulative Model Updates: 83,260
Cumulative Timesteps: 694,467,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.97323
Policy Entropy: 3.18765
Value Function Loss: 0.00439

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.55131
Value Function Update Magnitude: 0.61341

Collected Steps per Second: 21,311.63009
Overall Steps per Second: 10,379.02300

Timestep Collection Time: 2.34651
Timestep Consumption Time: 2.47167
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.81818

Cumulative Model Updates: 83,266
Cumulative Timesteps: 694,517,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 694517316...
Checkpoint 694517316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.00932
Policy Entropy: 3.19015
Value Function Loss: 0.00428

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.54641
Value Function Update Magnitude: 0.60668

Collected Steps per Second: 21,494.94931
Overall Steps per Second: 10,524.72230

Timestep Collection Time: 2.32687
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.75224

Cumulative Model Updates: 83,272
Cumulative Timesteps: 694,567,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,931.76072
Policy Entropy: 3.19634
Value Function Loss: 0.00434

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09855
Policy Update Magnitude: 0.54551
Value Function Update Magnitude: 0.61914

Collected Steps per Second: 21,939.92164
Overall Steps per Second: 10,365.70416

Timestep Collection Time: 2.27941
Timestep Consumption Time: 2.54516
PPO Batch Consumption Time: 0.30328
Total Iteration Time: 4.82456

Cumulative Model Updates: 83,278
Cumulative Timesteps: 694,617,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 694617342...
Checkpoint 694617342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.52556
Policy Entropy: 3.20252
Value Function Loss: 0.00423

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.54168
Value Function Update Magnitude: 0.60784

Collected Steps per Second: 21,420.12289
Overall Steps per Second: 10,229.62304

Timestep Collection Time: 2.33565
Timestep Consumption Time: 2.55504
PPO Batch Consumption Time: 0.30898
Total Iteration Time: 4.89070

Cumulative Model Updates: 83,284
Cumulative Timesteps: 694,667,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.88169
Policy Entropy: 3.20362
Value Function Loss: 0.00424

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.54612
Value Function Update Magnitude: 0.59568

Collected Steps per Second: 22,000.51673
Overall Steps per Second: 10,468.50353

Timestep Collection Time: 2.27276
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.77642

Cumulative Model Updates: 83,290
Cumulative Timesteps: 694,717,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 694717374...
Checkpoint 694717374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,726.03826
Policy Entropy: 3.19597
Value Function Loss: 0.00426

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.55020
Value Function Update Magnitude: 0.59543

Collected Steps per Second: 21,595.76054
Overall Steps per Second: 10,598.95430

Timestep Collection Time: 2.31582
Timestep Consumption Time: 2.40275
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.71858

Cumulative Model Updates: 83,296
Cumulative Timesteps: 694,767,386

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.69389
Policy Entropy: 3.22592
Value Function Loss: 0.00409

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.54368
Value Function Update Magnitude: 0.60602

Collected Steps per Second: 21,810.01786
Overall Steps per Second: 10,538.20155

Timestep Collection Time: 2.29381
Timestep Consumption Time: 2.45349
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.74730

Cumulative Model Updates: 83,302
Cumulative Timesteps: 694,817,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 694817414...
Checkpoint 694817414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.26100
Policy Entropy: 3.21872
Value Function Loss: 0.00385

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.53994
Value Function Update Magnitude: 0.59783

Collected Steps per Second: 21,370.26023
Overall Steps per Second: 10,555.82632

Timestep Collection Time: 2.33970
Timestep Consumption Time: 2.39702
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.73672

Cumulative Model Updates: 83,308
Cumulative Timesteps: 694,867,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.06308
Policy Entropy: 3.22584
Value Function Loss: 0.00397

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.53097
Value Function Update Magnitude: 0.60228

Collected Steps per Second: 22,002.18570
Overall Steps per Second: 10,528.93276

Timestep Collection Time: 2.27305
Timestep Consumption Time: 2.47691
PPO Batch Consumption Time: 0.29888
Total Iteration Time: 4.74996

Cumulative Model Updates: 83,314
Cumulative Timesteps: 694,917,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 694917426...
Checkpoint 694917426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.60817
Policy Entropy: 3.20305
Value Function Loss: 0.00408

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.53409
Value Function Update Magnitude: 0.61095

Collected Steps per Second: 22,547.84620
Overall Steps per Second: 10,662.45854

Timestep Collection Time: 2.21786
Timestep Consumption Time: 2.47224
PPO Batch Consumption Time: 0.28516
Total Iteration Time: 4.69010

Cumulative Model Updates: 83,320
Cumulative Timesteps: 694,967,434

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.95078
Policy Entropy: 3.20449
Value Function Loss: 0.00418

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.53756
Value Function Update Magnitude: 0.60644

Collected Steps per Second: 22,136.15635
Overall Steps per Second: 10,480.15640

Timestep Collection Time: 2.25956
Timestep Consumption Time: 2.51308
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.77264

Cumulative Model Updates: 83,326
Cumulative Timesteps: 695,017,452

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 695017452...
Checkpoint 695017452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,842.02528
Policy Entropy: 3.21240
Value Function Loss: 0.00397

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.53006
Value Function Update Magnitude: 0.59112

Collected Steps per Second: 21,950.01245
Overall Steps per Second: 10,505.79230

Timestep Collection Time: 2.27827
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.76004

Cumulative Model Updates: 83,332
Cumulative Timesteps: 695,067,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.46134
Policy Entropy: 3.22386
Value Function Loss: 0.00385

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09044
Policy Update Magnitude: 0.52829
Value Function Update Magnitude: 0.56819

Collected Steps per Second: 22,272.36751
Overall Steps per Second: 10,620.17323

Timestep Collection Time: 2.24565
Timestep Consumption Time: 2.46388
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.70953

Cumulative Model Updates: 83,338
Cumulative Timesteps: 695,117,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 695117476...
Checkpoint 695117476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.62922
Policy Entropy: 3.22883
Value Function Loss: 0.00409

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.52755
Value Function Update Magnitude: 0.55940

Collected Steps per Second: 21,881.34798
Overall Steps per Second: 10,451.40260

Timestep Collection Time: 2.28597
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.78596

Cumulative Model Updates: 83,344
Cumulative Timesteps: 695,167,496

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.57317
Policy Entropy: 3.21778
Value Function Loss: 0.00419

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.53062
Value Function Update Magnitude: 0.58439

Collected Steps per Second: 22,704.59393
Overall Steps per Second: 10,595.95441

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.51658
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.71878

Cumulative Model Updates: 83,350
Cumulative Timesteps: 695,217,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 695217496...
Checkpoint 695217496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808.05224
Policy Entropy: 3.20381
Value Function Loss: 0.00422

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10314
Policy Update Magnitude: 0.53777
Value Function Update Magnitude: 0.61202

Collected Steps per Second: 22,133.69864
Overall Steps per Second: 10,467.51205

Timestep Collection Time: 2.26026
Timestep Consumption Time: 2.51910
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.77936

Cumulative Model Updates: 83,356
Cumulative Timesteps: 695,267,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.84985
Policy Entropy: 3.19111
Value Function Loss: 0.00439

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.54750
Value Function Update Magnitude: 0.64192

Collected Steps per Second: 22,604.36581
Overall Steps per Second: 10,439.30471

Timestep Collection Time: 2.21311
Timestep Consumption Time: 2.57897
PPO Batch Consumption Time: 0.30167
Total Iteration Time: 4.79208

Cumulative Model Updates: 83,362
Cumulative Timesteps: 695,317,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 695317550...
Checkpoint 695317550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.87993
Policy Entropy: 3.20099
Value Function Loss: 0.00426

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11360
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.63034

Collected Steps per Second: 22,284.33752
Overall Steps per Second: 10,460.46413

Timestep Collection Time: 2.24436
Timestep Consumption Time: 2.53688
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.78124

Cumulative Model Updates: 83,368
Cumulative Timesteps: 695,367,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.81294
Policy Entropy: 3.21254
Value Function Loss: 0.00403

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.61231

Collected Steps per Second: 22,706.46545
Overall Steps per Second: 10,543.43138

Timestep Collection Time: 2.20334
Timestep Consumption Time: 2.54180
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.74513

Cumulative Model Updates: 83,374
Cumulative Timesteps: 695,417,594

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 695417594...
Checkpoint 695417594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.51939
Policy Entropy: 3.22522
Value Function Loss: 0.00404

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.53506
Value Function Update Magnitude: 0.59405

Collected Steps per Second: 22,512.04983
Overall Steps per Second: 10,486.00204

Timestep Collection Time: 2.22157
Timestep Consumption Time: 2.54784
PPO Batch Consumption Time: 0.30020
Total Iteration Time: 4.76941

Cumulative Model Updates: 83,380
Cumulative Timesteps: 695,467,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.09319
Policy Entropy: 3.23232
Value Function Loss: 0.00405

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.53514
Value Function Update Magnitude: 0.60446

Collected Steps per Second: 21,578.16097
Overall Steps per Second: 10,344.10979

Timestep Collection Time: 2.31929
Timestep Consumption Time: 2.51883
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.83812

Cumulative Model Updates: 83,386
Cumulative Timesteps: 695,517,652

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 695517652...
Checkpoint 695517652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.80328
Policy Entropy: 3.22870
Value Function Loss: 0.00410

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.53673
Value Function Update Magnitude: 0.61126

Collected Steps per Second: 22,412.06424
Overall Steps per Second: 10,514.43309

Timestep Collection Time: 2.23139
Timestep Consumption Time: 2.52493
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.75632

Cumulative Model Updates: 83,392
Cumulative Timesteps: 695,567,662

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.38695
Policy Entropy: 3.21390
Value Function Loss: 0.00437

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.54352
Value Function Update Magnitude: 0.62806

Collected Steps per Second: 21,882.48444
Overall Steps per Second: 10,393.41175

Timestep Collection Time: 2.28512
Timestep Consumption Time: 2.52601
PPO Batch Consumption Time: 0.29419
Total Iteration Time: 4.81112

Cumulative Model Updates: 83,398
Cumulative Timesteps: 695,617,666

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 695617666...
Checkpoint 695617666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.51355
Policy Entropy: 3.20305
Value Function Loss: 0.00437

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09895
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.64388

Collected Steps per Second: 21,752.40106
Overall Steps per Second: 10,415.56431

Timestep Collection Time: 2.29896
Timestep Consumption Time: 2.50231
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.80128

Cumulative Model Updates: 83,404
Cumulative Timesteps: 695,667,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.60372
Policy Entropy: 3.19661
Value Function Loss: 0.00442

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.63515

Collected Steps per Second: 22,491.16226
Overall Steps per Second: 10,527.58826

Timestep Collection Time: 2.22336
Timestep Consumption Time: 2.52663
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.75000

Cumulative Model Updates: 83,410
Cumulative Timesteps: 695,717,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 695717680...
Checkpoint 695717680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.30859
Policy Entropy: 3.20015
Value Function Loss: 0.00452

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.55686
Value Function Update Magnitude: 0.62394

Collected Steps per Second: 22,196.33567
Overall Steps per Second: 10,535.30058

Timestep Collection Time: 2.25316
Timestep Consumption Time: 2.49392
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.74709

Cumulative Model Updates: 83,416
Cumulative Timesteps: 695,767,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.15870
Policy Entropy: 3.21227
Value Function Loss: 0.00442

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.55675
Value Function Update Magnitude: 0.61216

Collected Steps per Second: 22,609.63587
Overall Steps per Second: 10,590.89503

Timestep Collection Time: 2.21207
Timestep Consumption Time: 2.51029
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.72236

Cumulative Model Updates: 83,422
Cumulative Timesteps: 695,817,706

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 695817706...
Checkpoint 695817706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.96284
Policy Entropy: 3.20559
Value Function Loss: 0.00440

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.55511
Value Function Update Magnitude: 0.60265

Collected Steps per Second: 22,372.08896
Overall Steps per Second: 10,601.28291

Timestep Collection Time: 2.23618
Timestep Consumption Time: 2.48287
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.71905

Cumulative Model Updates: 83,428
Cumulative Timesteps: 695,867,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755.34849
Policy Entropy: 3.19541
Value Function Loss: 0.00421

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.55562
Value Function Update Magnitude: 0.58697

Collected Steps per Second: 22,759.10587
Overall Steps per Second: 10,512.89337

Timestep Collection Time: 2.19754
Timestep Consumption Time: 2.55986
PPO Batch Consumption Time: 0.29990
Total Iteration Time: 4.75740

Cumulative Model Updates: 83,434
Cumulative Timesteps: 695,917,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 695917748...
Checkpoint 695917748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.78934
Policy Entropy: 3.18012
Value Function Loss: 0.00434

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.55562
Value Function Update Magnitude: 0.59553

Collected Steps per Second: 22,055.86772
Overall Steps per Second: 10,406.75166

Timestep Collection Time: 2.26797
Timestep Consumption Time: 2.53872
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.80669

Cumulative Model Updates: 83,440
Cumulative Timesteps: 695,967,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.88560
Policy Entropy: 3.18832
Value Function Loss: 0.00423

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.55365
Value Function Update Magnitude: 0.59949

Collected Steps per Second: 22,846.16218
Overall Steps per Second: 10,644.41299

Timestep Collection Time: 2.19065
Timestep Consumption Time: 2.51116
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.70181

Cumulative Model Updates: 83,446
Cumulative Timesteps: 696,017,818

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 696017818...
Checkpoint 696017818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.64926
Policy Entropy: 3.19034
Value Function Loss: 0.00415

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.59031

Collected Steps per Second: 22,281.82094
Overall Steps per Second: 10,556.20311

Timestep Collection Time: 2.24524
Timestep Consumption Time: 2.49397
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.73920

Cumulative Model Updates: 83,452
Cumulative Timesteps: 696,067,846

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.29659
Policy Entropy: 3.19626
Value Function Loss: 0.00413

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.55156
Value Function Update Magnitude: 0.58267

Collected Steps per Second: 22,455.89388
Overall Steps per Second: 10,536.13275

Timestep Collection Time: 2.22766
Timestep Consumption Time: 2.52020
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.74785

Cumulative Model Updates: 83,458
Cumulative Timesteps: 696,117,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 696117870...
Checkpoint 696117870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.44632
Policy Entropy: 3.18934
Value Function Loss: 0.00428

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.54993
Value Function Update Magnitude: 0.59109

Collected Steps per Second: 22,225.77495
Overall Steps per Second: 10,541.97046

Timestep Collection Time: 2.25054
Timestep Consumption Time: 2.49430
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.74484

Cumulative Model Updates: 83,464
Cumulative Timesteps: 696,167,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.32733
Policy Entropy: 3.21493
Value Function Loss: 0.00417

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.55387
Value Function Update Magnitude: 0.61267

Collected Steps per Second: 22,069.89816
Overall Steps per Second: 10,552.01043

Timestep Collection Time: 2.26571
Timestep Consumption Time: 2.47310
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.73881

Cumulative Model Updates: 83,470
Cumulative Timesteps: 696,217,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 696217894...
Checkpoint 696217894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.13487
Policy Entropy: 3.21325
Value Function Loss: 0.00414

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.54703
Value Function Update Magnitude: 0.62586

Collected Steps per Second: 21,453.22021
Overall Steps per Second: 10,299.95923

Timestep Collection Time: 2.33158
Timestep Consumption Time: 2.52475
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 4.85633

Cumulative Model Updates: 83,476
Cumulative Timesteps: 696,267,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.32063
Policy Entropy: 3.21834
Value Function Loss: 0.00400

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10697
Policy Update Magnitude: 0.53992
Value Function Update Magnitude: 0.61738

Collected Steps per Second: 22,159.16234
Overall Steps per Second: 10,426.73098

Timestep Collection Time: 2.25740
Timestep Consumption Time: 2.54008
PPO Batch Consumption Time: 0.29985
Total Iteration Time: 4.79748

Cumulative Model Updates: 83,482
Cumulative Timesteps: 696,317,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 696317936...
Checkpoint 696317936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.16196
Policy Entropy: 3.21647
Value Function Loss: 0.00398

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09827
Policy Update Magnitude: 0.53376
Value Function Update Magnitude: 0.61645

Collected Steps per Second: 21,773.88229
Overall Steps per Second: 10,518.62092

Timestep Collection Time: 2.29716
Timestep Consumption Time: 2.45803
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.75519

Cumulative Model Updates: 83,488
Cumulative Timesteps: 696,367,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.79177
Policy Entropy: 3.22917
Value Function Loss: 0.00406

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.53521
Value Function Update Magnitude: 0.58602

Collected Steps per Second: 21,936.05802
Overall Steps per Second: 10,504.03135

Timestep Collection Time: 2.27972
Timestep Consumption Time: 2.48112
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.76084

Cumulative Model Updates: 83,494
Cumulative Timesteps: 696,417,962

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 696417962...
Checkpoint 696417962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.03766
Policy Entropy: 3.24102
Value Function Loss: 0.00412

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.59746

Collected Steps per Second: 21,893.44473
Overall Steps per Second: 10,451.23763

Timestep Collection Time: 2.28534
Timestep Consumption Time: 2.50203
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.78738

Cumulative Model Updates: 83,500
Cumulative Timesteps: 696,467,996

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.96632
Policy Entropy: 3.23710
Value Function Loss: 0.00412

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08508
Policy Update Magnitude: 0.54242
Value Function Update Magnitude: 0.62690

Collected Steps per Second: 22,758.02069
Overall Steps per Second: 10,684.58642

Timestep Collection Time: 2.19712
Timestep Consumption Time: 2.48271
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.67983

Cumulative Model Updates: 83,506
Cumulative Timesteps: 696,517,998

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 696517998...
Checkpoint 696517998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752.98496
Policy Entropy: 3.23673
Value Function Loss: 0.00413

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.54182
Value Function Update Magnitude: 0.62970

Collected Steps per Second: 22,649.70777
Overall Steps per Second: 10,608.38449

Timestep Collection Time: 2.20753
Timestep Consumption Time: 2.50572
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.71325

Cumulative Model Updates: 83,512
Cumulative Timesteps: 696,567,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.42770
Policy Entropy: 3.23048
Value Function Loss: 0.00415

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.54204
Value Function Update Magnitude: 0.61551

Collected Steps per Second: 21,827.99791
Overall Steps per Second: 10,405.23002

Timestep Collection Time: 2.29064
Timestep Consumption Time: 2.51464
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.80528

Cumulative Model Updates: 83,518
Cumulative Timesteps: 696,617,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 696617998...
Checkpoint 696617998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.90524
Policy Entropy: 3.22080
Value Function Loss: 0.00428

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.54439
Value Function Update Magnitude: 0.61782

Collected Steps per Second: 22,485.58265
Overall Steps per Second: 10,678.54111

Timestep Collection Time: 2.22409
Timestep Consumption Time: 2.45913
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.68322

Cumulative Model Updates: 83,524
Cumulative Timesteps: 696,668,008

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.42117
Policy Entropy: 3.23560
Value Function Loss: 0.00413

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.53740
Value Function Update Magnitude: 0.60386

Collected Steps per Second: 22,443.81788
Overall Steps per Second: 10,523.10944

Timestep Collection Time: 2.22885
Timestep Consumption Time: 2.52487
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.75373

Cumulative Model Updates: 83,530
Cumulative Timesteps: 696,718,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 696718032...
Checkpoint 696718032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.36571
Policy Entropy: 3.23756
Value Function Loss: 0.00402

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.52809
Value Function Update Magnitude: 0.59278

Collected Steps per Second: 22,273.50884
Overall Steps per Second: 10,561.73575

Timestep Collection Time: 2.24590
Timestep Consumption Time: 2.49045
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.73634

Cumulative Model Updates: 83,536
Cumulative Timesteps: 696,768,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.68532
Policy Entropy: 3.23768
Value Function Loss: 0.00405

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11750
Policy Update Magnitude: 0.53772
Value Function Update Magnitude: 0.59834

Collected Steps per Second: 22,430.92453
Overall Steps per Second: 10,472.46549

Timestep Collection Time: 2.22907
Timestep Consumption Time: 2.54536
PPO Batch Consumption Time: 0.30131
Total Iteration Time: 4.77442

Cumulative Model Updates: 83,542
Cumulative Timesteps: 696,818,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 696818056...
Checkpoint 696818056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.10836
Policy Entropy: 3.23505
Value Function Loss: 0.00423

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.54102
Value Function Update Magnitude: 0.60218

Collected Steps per Second: 21,955.26538
Overall Steps per Second: 10,573.25557

Timestep Collection Time: 2.27790
Timestep Consumption Time: 2.45214
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.73005

Cumulative Model Updates: 83,548
Cumulative Timesteps: 696,868,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.53892
Policy Entropy: 3.24185
Value Function Loss: 0.00433

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.60615

Collected Steps per Second: 22,080.14486
Overall Steps per Second: 10,515.64620

Timestep Collection Time: 2.26620
Timestep Consumption Time: 2.49223
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.75843

Cumulative Model Updates: 83,554
Cumulative Timesteps: 696,918,106

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 696918106...
Checkpoint 696918106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.47156
Policy Entropy: 3.24245
Value Function Loss: 0.00434

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.60280

Collected Steps per Second: 21,815.67136
Overall Steps per Second: 10,468.76087

Timestep Collection Time: 2.29266
Timestep Consumption Time: 2.48498
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.77764

Cumulative Model Updates: 83,560
Cumulative Timesteps: 696,968,122

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.07491
Policy Entropy: 3.26070
Value Function Loss: 0.00410

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08460
Policy Update Magnitude: 0.54530
Value Function Update Magnitude: 0.62051

Collected Steps per Second: 22,070.41801
Overall Steps per Second: 10,558.07973

Timestep Collection Time: 2.26693
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.73874

Cumulative Model Updates: 83,566
Cumulative Timesteps: 697,018,154

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 697018154...
Checkpoint 697018154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 818.91678
Policy Entropy: 3.26537
Value Function Loss: 0.00416

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08002
Policy Update Magnitude: 0.54649
Value Function Update Magnitude: 0.62392

Collected Steps per Second: 22,209.97217
Overall Steps per Second: 10,633.36495

Timestep Collection Time: 2.25178
Timestep Consumption Time: 2.45153
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.70331

Cumulative Model Updates: 83,572
Cumulative Timesteps: 697,068,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.11076
Policy Entropy: 3.26509
Value Function Loss: 0.00401

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.07572
Policy Update Magnitude: 0.55043
Value Function Update Magnitude: 0.62122

Collected Steps per Second: 22,412.23447
Overall Steps per Second: 10,514.62928

Timestep Collection Time: 2.23173
Timestep Consumption Time: 2.52526
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.75699

Cumulative Model Updates: 83,578
Cumulative Timesteps: 697,118,184

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 697118184...
Checkpoint 697118184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.71399
Policy Entropy: 3.24395
Value Function Loss: 0.00410

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08326
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.60618

Collected Steps per Second: 22,318.41830
Overall Steps per Second: 10,602.81763

Timestep Collection Time: 2.24084
Timestep Consumption Time: 2.47602
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.71686

Cumulative Model Updates: 83,584
Cumulative Timesteps: 697,168,196

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.43012
Policy Entropy: 3.23310
Value Function Loss: 0.00398

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.54402
Value Function Update Magnitude: 0.59735

Collected Steps per Second: 22,211.11642
Overall Steps per Second: 10,574.00488

Timestep Collection Time: 2.25248
Timestep Consumption Time: 2.47894
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.73141

Cumulative Model Updates: 83,590
Cumulative Timesteps: 697,218,226

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 697218226...
Checkpoint 697218226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.28100
Policy Entropy: 3.23097
Value Function Loss: 0.00415

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.54124
Value Function Update Magnitude: 0.60489

Collected Steps per Second: 20,145.53934
Overall Steps per Second: 10,142.19968

Timestep Collection Time: 2.48244
Timestep Consumption Time: 2.44845
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.93088

Cumulative Model Updates: 83,596
Cumulative Timesteps: 697,268,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.57679
Policy Entropy: 3.24617
Value Function Loss: 0.00405

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.54042
Value Function Update Magnitude: 0.61907

Collected Steps per Second: 22,497.25970
Overall Steps per Second: 10,542.58498

Timestep Collection Time: 2.22303
Timestep Consumption Time: 2.52078
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.74381

Cumulative Model Updates: 83,602
Cumulative Timesteps: 697,318,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 697318248...
Checkpoint 697318248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.87058
Policy Entropy: 3.25381
Value Function Loss: 0.00394

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08410
Policy Update Magnitude: 0.53876
Value Function Update Magnitude: 0.62047

Collected Steps per Second: 22,381.95978
Overall Steps per Second: 10,642.88042

Timestep Collection Time: 2.23394
Timestep Consumption Time: 2.46403
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.69798

Cumulative Model Updates: 83,608
Cumulative Timesteps: 697,368,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.84220
Policy Entropy: 3.26608
Value Function Loss: 0.00391

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07915
Policy Update Magnitude: 0.53716
Value Function Update Magnitude: 0.62323

Collected Steps per Second: 21,757.28344
Overall Steps per Second: 10,412.89905

Timestep Collection Time: 2.29882
Timestep Consumption Time: 2.50446
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.80327

Cumulative Model Updates: 83,614
Cumulative Timesteps: 697,418,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 697418264...
Checkpoint 697418264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.70622
Policy Entropy: 3.24942
Value Function Loss: 0.00430

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07662
Policy Update Magnitude: 0.54185
Value Function Update Magnitude: 0.64265

Collected Steps per Second: 22,277.36991
Overall Steps per Second: 10,678.23528

Timestep Collection Time: 2.24569
Timestep Consumption Time: 2.43936
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.68504

Cumulative Model Updates: 83,620
Cumulative Timesteps: 697,468,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.76562
Policy Entropy: 3.24891
Value Function Loss: 0.00400

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07947
Policy Update Magnitude: 0.55194
Value Function Update Magnitude: 0.65607

Collected Steps per Second: 22,532.77491
Overall Steps per Second: 10,611.82733

Timestep Collection Time: 2.21943
Timestep Consumption Time: 2.49323
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71267

Cumulative Model Updates: 83,626
Cumulative Timesteps: 697,518,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 697518302...
Checkpoint 697518302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.76867
Policy Entropy: 3.23438
Value Function Loss: 0.00396

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08105
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.63478

Collected Steps per Second: 22,169.18368
Overall Steps per Second: 10,480.71893

Timestep Collection Time: 2.25538
Timestep Consumption Time: 2.51528
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.77067

Cumulative Model Updates: 83,632
Cumulative Timesteps: 697,568,302

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.32797
Policy Entropy: 3.25148
Value Function Loss: 0.00408

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.53634
Value Function Update Magnitude: 0.63895

Collected Steps per Second: 22,881.71853
Overall Steps per Second: 10,788.37890

Timestep Collection Time: 2.18576
Timestep Consumption Time: 2.45015
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.63591

Cumulative Model Updates: 83,638
Cumulative Timesteps: 697,618,316

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 697618316...
Checkpoint 697618316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,766.82578
Policy Entropy: 3.23645
Value Function Loss: 0.00412

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.53908
Value Function Update Magnitude: 0.62976

Collected Steps per Second: 22,707.18364
Overall Steps per Second: 10,741.20939

Timestep Collection Time: 2.20212
Timestep Consumption Time: 2.45322
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.65534

Cumulative Model Updates: 83,644
Cumulative Timesteps: 697,668,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.65982
Policy Entropy: 3.22455
Value Function Loss: 0.00401

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08584
Policy Update Magnitude: 0.53944
Value Function Update Magnitude: 0.60968

Collected Steps per Second: 22,639.75958
Overall Steps per Second: 10,655.03547

Timestep Collection Time: 2.20956
Timestep Consumption Time: 2.48531
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.69487

Cumulative Model Updates: 83,650
Cumulative Timesteps: 697,718,344

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 697718344...
Checkpoint 697718344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.02822
Policy Entropy: 3.22522
Value Function Loss: 0.00393

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08425
Policy Update Magnitude: 0.53381
Value Function Update Magnitude: 0.59857

Collected Steps per Second: 22,913.35941
Overall Steps per Second: 10,811.43963

Timestep Collection Time: 2.18213
Timestep Consumption Time: 2.44260
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.62473

Cumulative Model Updates: 83,656
Cumulative Timesteps: 697,768,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.18375
Policy Entropy: 3.24898
Value Function Loss: 0.00409

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08088
Policy Update Magnitude: 0.53520
Value Function Update Magnitude: 0.60552

Collected Steps per Second: 22,891.29108
Overall Steps per Second: 10,730.29032

Timestep Collection Time: 2.18476
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.66082

Cumulative Model Updates: 83,662
Cumulative Timesteps: 697,818,356

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 697818356...
Checkpoint 697818356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.95162
Policy Entropy: 3.25625
Value Function Loss: 0.00405

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.07629
Policy Update Magnitude: 0.53960
Value Function Update Magnitude: 0.61560

Collected Steps per Second: 22,844.72244
Overall Steps per Second: 10,809.58580

Timestep Collection Time: 2.18939
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.62700

Cumulative Model Updates: 83,668
Cumulative Timesteps: 697,868,372

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.26451
Policy Entropy: 3.25766
Value Function Loss: 0.00418

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.07856
Policy Update Magnitude: 0.54569
Value Function Update Magnitude: 0.62949

Collected Steps per Second: 22,619.96607
Overall Steps per Second: 10,613.13968

Timestep Collection Time: 2.21114
Timestep Consumption Time: 2.50150
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.71265

Cumulative Model Updates: 83,674
Cumulative Timesteps: 697,918,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 697918388...
Checkpoint 697918388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.07365
Policy Entropy: 3.25563
Value Function Loss: 0.00415

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.54387
Value Function Update Magnitude: 0.60770

Collected Steps per Second: 22,320.14090
Overall Steps per Second: 10,542.64797

Timestep Collection Time: 2.24138
Timestep Consumption Time: 2.50391
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.74530

Cumulative Model Updates: 83,680
Cumulative Timesteps: 697,968,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.22519
Policy Entropy: 3.24621
Value Function Loss: 0.00424

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08367
Policy Update Magnitude: 0.54104
Value Function Update Magnitude: 0.59246

Collected Steps per Second: 22,184.35832
Overall Steps per Second: 10,471.56326

Timestep Collection Time: 2.25474
Timestep Consumption Time: 2.52200
PPO Batch Consumption Time: 0.29747
Total Iteration Time: 4.77675

Cumulative Model Updates: 83,686
Cumulative Timesteps: 698,018,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 698018436...
Checkpoint 698018436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.00158
Policy Entropy: 3.26038
Value Function Loss: 0.00402

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08493
Policy Update Magnitude: 0.54156
Value Function Update Magnitude: 0.60571

Collected Steps per Second: 22,207.44942
Overall Steps per Second: 10,701.17398

Timestep Collection Time: 2.25249
Timestep Consumption Time: 2.42195
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.67444

Cumulative Model Updates: 83,692
Cumulative Timesteps: 698,068,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.91388
Policy Entropy: 3.25896
Value Function Loss: 0.00400

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12023
Policy Update Magnitude: 0.54056
Value Function Update Magnitude: 0.62184

Collected Steps per Second: 22,302.36352
Overall Steps per Second: 10,509.64003

Timestep Collection Time: 2.24326
Timestep Consumption Time: 2.51713
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.76039

Cumulative Model Updates: 83,698
Cumulative Timesteps: 698,118,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 698118488...
Checkpoint 698118488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.30632
Policy Entropy: 3.26924
Value Function Loss: 0.00384

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11077
Policy Update Magnitude: 0.53551
Value Function Update Magnitude: 0.60727

Collected Steps per Second: 22,764.51473
Overall Steps per Second: 10,554.27430

Timestep Collection Time: 2.19754
Timestep Consumption Time: 2.54234
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.73988

Cumulative Model Updates: 83,704
Cumulative Timesteps: 698,168,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.54755
Policy Entropy: 3.26191
Value Function Loss: 0.00399

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.53476
Value Function Update Magnitude: 0.59019

Collected Steps per Second: 22,466.30178
Overall Steps per Second: 10,476.35915

Timestep Collection Time: 2.22662
Timestep Consumption Time: 2.54832
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.77494

Cumulative Model Updates: 83,710
Cumulative Timesteps: 698,218,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 698218538...
Checkpoint 698218538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.79588
Policy Entropy: 3.26636
Value Function Loss: 0.00422

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.54123
Value Function Update Magnitude: 0.61109

Collected Steps per Second: 23,016.75253
Overall Steps per Second: 10,612.63732

Timestep Collection Time: 2.17337
Timestep Consumption Time: 2.54025
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.71363

Cumulative Model Updates: 83,716
Cumulative Timesteps: 698,268,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820.98559
Policy Entropy: 3.26452
Value Function Loss: 0.00414

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.54356
Value Function Update Magnitude: 0.64181

Collected Steps per Second: 22,622.25031
Overall Steps per Second: 10,534.71094

Timestep Collection Time: 2.21057
Timestep Consumption Time: 2.53641
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.74697

Cumulative Model Updates: 83,722
Cumulative Timesteps: 698,318,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 698318570...
Checkpoint 698318570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.74759
Policy Entropy: 3.26417
Value Function Loss: 0.00404

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.54250
Value Function Update Magnitude: 0.63010

Collected Steps per Second: 22,694.93995
Overall Steps per Second: 10,544.20809

Timestep Collection Time: 2.20393
Timestep Consumption Time: 2.53972
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.74365

Cumulative Model Updates: 83,728
Cumulative Timesteps: 698,368,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.87865
Policy Entropy: 3.25518
Value Function Loss: 0.00390

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.08093
Policy Update Magnitude: 0.53961
Value Function Update Magnitude: 0.61868

Collected Steps per Second: 22,460.51473
Overall Steps per Second: 10,532.08261

Timestep Collection Time: 2.22720
Timestep Consumption Time: 2.52248
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.74968

Cumulative Model Updates: 83,734
Cumulative Timesteps: 698,418,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 698418612...
Checkpoint 698418612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732.32611
Policy Entropy: 3.25429
Value Function Loss: 0.00396

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.54235
Value Function Update Magnitude: 0.61443

Collected Steps per Second: 22,586.22529
Overall Steps per Second: 10,574.85975

Timestep Collection Time: 2.21471
Timestep Consumption Time: 2.51556
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.73028

Cumulative Model Updates: 83,740
Cumulative Timesteps: 698,468,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.73858
Policy Entropy: 3.25260
Value Function Loss: 0.00424

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.54637
Value Function Update Magnitude: 0.61505

Collected Steps per Second: 22,858.75839
Overall Steps per Second: 10,808.53301

Timestep Collection Time: 2.18875
Timestep Consumption Time: 2.44019
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.62894

Cumulative Model Updates: 83,746
Cumulative Timesteps: 698,518,666

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 698518666...
Checkpoint 698518666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.18411
Policy Entropy: 3.25251
Value Function Loss: 0.00418

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.55508
Value Function Update Magnitude: 0.61688

Collected Steps per Second: 22,137.25470
Overall Steps per Second: 10,671.23916

Timestep Collection Time: 2.25927
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.68680

Cumulative Model Updates: 83,752
Cumulative Timesteps: 698,568,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.23242
Policy Entropy: 3.23772
Value Function Loss: 0.00417

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.61026

Collected Steps per Second: 22,350.33618
Overall Steps per Second: 10,532.88960

Timestep Collection Time: 2.23719
Timestep Consumption Time: 2.51003
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.74723

Cumulative Model Updates: 83,758
Cumulative Timesteps: 698,618,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 698618682...
Checkpoint 698618682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.06153
Policy Entropy: 3.23683
Value Function Loss: 0.00424

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.55028
Value Function Update Magnitude: 0.58914

Collected Steps per Second: 22,097.35711
Overall Steps per Second: 10,628.02160

Timestep Collection Time: 2.26344
Timestep Consumption Time: 2.44261
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.70605

Cumulative Model Updates: 83,764
Cumulative Timesteps: 698,668,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.47588
Policy Entropy: 3.24567
Value Function Loss: 0.00428

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12253
Policy Update Magnitude: 0.55498
Value Function Update Magnitude: 0.58907

Collected Steps per Second: 22,465.96366
Overall Steps per Second: 10,545.67977

Timestep Collection Time: 2.22586
Timestep Consumption Time: 2.51599
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.74185

Cumulative Model Updates: 83,770
Cumulative Timesteps: 698,718,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 698718704...
Checkpoint 698718704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.93148
Policy Entropy: 3.27118
Value Function Loss: 0.00422

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12242
Policy Update Magnitude: 0.54875
Value Function Update Magnitude: 0.60681

Collected Steps per Second: 22,538.72345
Overall Steps per Second: 10,509.43039

Timestep Collection Time: 2.21876
Timestep Consumption Time: 2.53963
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.75839

Cumulative Model Updates: 83,776
Cumulative Timesteps: 698,768,712

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.85163
Policy Entropy: 3.27625
Value Function Loss: 0.00416

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.53828
Value Function Update Magnitude: 0.61818

Collected Steps per Second: 22,736.80363
Overall Steps per Second: 10,622.14247

Timestep Collection Time: 2.19978
Timestep Consumption Time: 2.50887
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.70865

Cumulative Model Updates: 83,782
Cumulative Timesteps: 698,818,728

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 698818728...
Checkpoint 698818728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.98458
Policy Entropy: 3.27079
Value Function Loss: 0.00410

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.54265
Value Function Update Magnitude: 0.63505

Collected Steps per Second: 22,453.22813
Overall Steps per Second: 10,591.56326

Timestep Collection Time: 2.22819
Timestep Consumption Time: 2.49538
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.72357

Cumulative Model Updates: 83,788
Cumulative Timesteps: 698,868,758

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.80829
Policy Entropy: 3.27327
Value Function Loss: 0.00394

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.54121
Value Function Update Magnitude: 0.63885

Collected Steps per Second: 22,842.65618
Overall Steps per Second: 10,790.40283

Timestep Collection Time: 2.18889
Timestep Consumption Time: 2.44486
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.63375

Cumulative Model Updates: 83,794
Cumulative Timesteps: 698,918,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 698918758...
Checkpoint 698918758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.74765
Policy Entropy: 3.26485
Value Function Loss: 0.00408

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.53728
Value Function Update Magnitude: 0.64165

Collected Steps per Second: 22,324.68220
Overall Steps per Second: 10,698.04406

Timestep Collection Time: 2.23994
Timestep Consumption Time: 2.43437
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.67431

Cumulative Model Updates: 83,800
Cumulative Timesteps: 698,968,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.34400
Policy Entropy: 3.27253
Value Function Loss: 0.00423

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.55008
Value Function Update Magnitude: 0.63928

Collected Steps per Second: 22,675.65058
Overall Steps per Second: 10,772.81167

Timestep Collection Time: 2.20510
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.64150

Cumulative Model Updates: 83,806
Cumulative Timesteps: 699,018,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 699018766...
Checkpoint 699018766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.21988
Policy Entropy: 3.27358
Value Function Loss: 0.00432

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.55789
Value Function Update Magnitude: 0.63192

Collected Steps per Second: 22,381.05868
Overall Steps per Second: 10,712.89626

Timestep Collection Time: 2.23528
Timestep Consumption Time: 2.43460
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.66989

Cumulative Model Updates: 83,812
Cumulative Timesteps: 699,068,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.16262
Policy Entropy: 3.27087
Value Function Loss: 0.00445

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.61315

Collected Steps per Second: 22,475.03023
Overall Steps per Second: 10,542.55133

Timestep Collection Time: 2.22478
Timestep Consumption Time: 2.51809
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.74287

Cumulative Model Updates: 83,818
Cumulative Timesteps: 699,118,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 699118796...
Checkpoint 699118796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.31035
Policy Entropy: 3.27795
Value Function Loss: 0.00426

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.55621
Value Function Update Magnitude: 0.60617

Collected Steps per Second: 22,094.10703
Overall Steps per Second: 10,542.21330

Timestep Collection Time: 2.26395
Timestep Consumption Time: 2.48078
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.74473

Cumulative Model Updates: 83,824
Cumulative Timesteps: 699,168,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.26608
Policy Entropy: 3.28436
Value Function Loss: 0.00421

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.55518
Value Function Update Magnitude: 0.61301

Collected Steps per Second: 22,423.43781
Overall Steps per Second: 10,562.97332

Timestep Collection Time: 2.23026
Timestep Consumption Time: 2.50421
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.73446

Cumulative Model Updates: 83,830
Cumulative Timesteps: 699,218,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 699218826...
Checkpoint 699218826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.08033
Policy Entropy: 3.30690
Value Function Loss: 0.00397

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.54692
Value Function Update Magnitude: 0.61842

Collected Steps per Second: 22,054.43996
Overall Steps per Second: 10,572.16349

Timestep Collection Time: 2.26766
Timestep Consumption Time: 2.46287
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.73054

Cumulative Model Updates: 83,836
Cumulative Timesteps: 699,268,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.40348
Policy Entropy: 3.28638
Value Function Loss: 0.00399

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.53889
Value Function Update Magnitude: 0.61067

Collected Steps per Second: 21,813.70321
Overall Steps per Second: 10,403.88588

Timestep Collection Time: 2.29260
Timestep Consumption Time: 2.51426
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.80686

Cumulative Model Updates: 83,842
Cumulative Timesteps: 699,318,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 699318848...
Checkpoint 699318848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,825.21615
Policy Entropy: 3.28122
Value Function Loss: 0.00420

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.54147
Value Function Update Magnitude: 0.59338

Collected Steps per Second: 21,993.93304
Overall Steps per Second: 10,608.01607

Timestep Collection Time: 2.27363
Timestep Consumption Time: 2.44036
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.71398

Cumulative Model Updates: 83,848
Cumulative Timesteps: 699,368,854

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.89736
Policy Entropy: 3.27848
Value Function Loss: 0.00431

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.07639
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.59476

Collected Steps per Second: 22,345.39708
Overall Steps per Second: 10,551.10312

Timestep Collection Time: 2.23778
Timestep Consumption Time: 2.50144
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.73922

Cumulative Model Updates: 83,854
Cumulative Timesteps: 699,418,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 699418858...
Checkpoint 699418858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,054.30964
Policy Entropy: 3.27214
Value Function Loss: 0.00435

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08354
Policy Update Magnitude: 0.55053
Value Function Update Magnitude: 0.60056

Collected Steps per Second: 22,315.96820
Overall Steps per Second: 10,617.09341

Timestep Collection Time: 2.24180
Timestep Consumption Time: 2.47022
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.71202

Cumulative Model Updates: 83,860
Cumulative Timesteps: 699,468,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.76428
Policy Entropy: 3.27117
Value Function Loss: 0.00418

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.60455

Collected Steps per Second: 22,860.41542
Overall Steps per Second: 10,902.64923

Timestep Collection Time: 2.18754
Timestep Consumption Time: 2.39924
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.58678

Cumulative Model Updates: 83,866
Cumulative Timesteps: 699,518,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 699518894...
Checkpoint 699518894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.80645
Policy Entropy: 3.27008
Value Function Loss: 0.00401

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.55180
Value Function Update Magnitude: 0.61203

Collected Steps per Second: 21,789.82780
Overall Steps per Second: 10,572.53845

Timestep Collection Time: 2.29529
Timestep Consumption Time: 2.43527
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.73056

Cumulative Model Updates: 83,872
Cumulative Timesteps: 699,568,908

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.22535
Policy Entropy: 3.28629
Value Function Loss: 0.00409

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08421
Policy Update Magnitude: 0.54837
Value Function Update Magnitude: 0.62710

Collected Steps per Second: 22,145.99315
Overall Steps per Second: 10,647.73773

Timestep Collection Time: 2.25811
Timestep Consumption Time: 2.43848
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.69658

Cumulative Model Updates: 83,878
Cumulative Timesteps: 699,618,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 699618916...
Checkpoint 699618916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.60884
Policy Entropy: 3.30155
Value Function Loss: 0.00407

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08161
Policy Update Magnitude: 0.54368
Value Function Update Magnitude: 0.63495

Collected Steps per Second: 21,882.60402
Overall Steps per Second: 10,535.21291

Timestep Collection Time: 2.28547
Timestep Consumption Time: 2.46166
PPO Batch Consumption Time: 0.29787
Total Iteration Time: 4.74713

Cumulative Model Updates: 83,884
Cumulative Timesteps: 699,668,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.99416
Policy Entropy: 3.29268
Value Function Loss: 0.00423

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.54575
Value Function Update Magnitude: 0.62088

Collected Steps per Second: 22,562.02211
Overall Steps per Second: 10,859.12087

Timestep Collection Time: 2.21727
Timestep Consumption Time: 2.38955
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.60682

Cumulative Model Updates: 83,890
Cumulative Timesteps: 699,718,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 699718954...
Checkpoint 699718954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.13936
Policy Entropy: 3.28916
Value Function Loss: 0.00426

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08791
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.61858

Collected Steps per Second: 22,426.14307
Overall Steps per Second: 10,714.05832

Timestep Collection Time: 2.23079
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.66938

Cumulative Model Updates: 83,896
Cumulative Timesteps: 699,768,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.84010
Policy Entropy: 3.28409
Value Function Loss: 0.00431

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07542
Policy Update Magnitude: 0.56112
Value Function Update Magnitude: 0.63315

Collected Steps per Second: 22,515.61506
Overall Steps per Second: 10,574.02940

Timestep Collection Time: 2.22113
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.72951

Cumulative Model Updates: 83,902
Cumulative Timesteps: 699,818,992

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 699818992...
Checkpoint 699818992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.74717
Policy Entropy: 3.28480
Value Function Loss: 0.00432

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.56714
Value Function Update Magnitude: 0.63982

Collected Steps per Second: 22,439.01730
Overall Steps per Second: 10,541.44883

Timestep Collection Time: 2.22951
Timestep Consumption Time: 2.51633
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.74584

Cumulative Model Updates: 83,908
Cumulative Timesteps: 699,869,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.37604
Policy Entropy: 3.29144
Value Function Loss: 0.00402

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09843
Policy Update Magnitude: 0.56411
Value Function Update Magnitude: 0.64796

Collected Steps per Second: 22,543.01163
Overall Steps per Second: 10,551.04674

Timestep Collection Time: 2.21860
Timestep Consumption Time: 2.52159
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.74019

Cumulative Model Updates: 83,914
Cumulative Timesteps: 699,919,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 699919034...
Checkpoint 699919034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.00171
Policy Entropy: 3.28279
Value Function Loss: 0.00405

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.55141
Value Function Update Magnitude: 0.62526

Collected Steps per Second: 22,393.04936
Overall Steps per Second: 10,470.21127

Timestep Collection Time: 2.23418
Timestep Consumption Time: 2.54414
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.77832

Cumulative Model Updates: 83,920
Cumulative Timesteps: 699,969,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.36099
Policy Entropy: 3.27459
Value Function Loss: 0.00413

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09340
Policy Update Magnitude: 0.54448
Value Function Update Magnitude: 0.61795

Collected Steps per Second: 22,977.90107
Overall Steps per Second: 10,607.46595

Timestep Collection Time: 2.17687
Timestep Consumption Time: 2.53867
PPO Batch Consumption Time: 0.29520
Total Iteration Time: 4.71555

Cumulative Model Updates: 83,926
Cumulative Timesteps: 700,019,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 700019084...
Checkpoint 700019084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.42610
Policy Entropy: 3.26532
Value Function Loss: 0.00444

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.63115

Collected Steps per Second: 22,689.72883
Overall Steps per Second: 10,556.79727

Timestep Collection Time: 2.20390
Timestep Consumption Time: 2.53295
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.73685

Cumulative Model Updates: 83,932
Cumulative Timesteps: 700,069,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 585.61967
Policy Entropy: 3.25624
Value Function Loss: 0.00455

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09727
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.62956

Collected Steps per Second: 22,950.20935
Overall Steps per Second: 10,796.13963

Timestep Collection Time: 2.17889
Timestep Consumption Time: 2.45295
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.63184

Cumulative Model Updates: 83,938
Cumulative Timesteps: 700,119,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 700119096...
Checkpoint 700119096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.59431
Policy Entropy: 3.25436
Value Function Loss: 0.00448

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.56438
Value Function Update Magnitude: 0.62207

Collected Steps per Second: 22,350.78622
Overall Steps per Second: 10,610.70835

Timestep Collection Time: 2.23742
Timestep Consumption Time: 2.47556
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.71297

Cumulative Model Updates: 83,944
Cumulative Timesteps: 700,169,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.09068
Policy Entropy: 3.26077
Value Function Loss: 0.00434

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.55676
Value Function Update Magnitude: 0.61767

Collected Steps per Second: 23,002.16844
Overall Steps per Second: 10,599.75588

Timestep Collection Time: 2.17406
Timestep Consumption Time: 2.54379
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.71784

Cumulative Model Updates: 83,950
Cumulative Timesteps: 700,219,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 700219112...
Checkpoint 700219112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.27170
Policy Entropy: 3.27580
Value Function Loss: 0.00408

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.54809
Value Function Update Magnitude: 0.61969

Collected Steps per Second: 22,275.95148
Overall Steps per Second: 10,610.06089

Timestep Collection Time: 2.24475
Timestep Consumption Time: 2.46813
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.71289

Cumulative Model Updates: 83,956
Cumulative Timesteps: 700,269,116

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.65024
Policy Entropy: 3.27055
Value Function Loss: 0.00429

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08243
Policy Update Magnitude: 0.54791
Value Function Update Magnitude: 0.60251

Collected Steps per Second: 23,080.96757
Overall Steps per Second: 10,716.12544

Timestep Collection Time: 2.16629
Timestep Consumption Time: 2.49958
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.66587

Cumulative Model Updates: 83,962
Cumulative Timesteps: 700,319,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 700319116...
Checkpoint 700319116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.17971
Policy Entropy: 3.26081
Value Function Loss: 0.00456

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.55979
Value Function Update Magnitude: 0.63180

Collected Steps per Second: 22,505.52820
Overall Steps per Second: 10,780.27928

Timestep Collection Time: 2.22292
Timestep Consumption Time: 2.41778
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.64070

Cumulative Model Updates: 83,968
Cumulative Timesteps: 700,369,144

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.74038
Policy Entropy: 3.26395
Value Function Loss: 0.00445

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.56998
Value Function Update Magnitude: 0.65928

Collected Steps per Second: 22,451.45171
Overall Steps per Second: 10,562.47022

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.50822
PPO Batch Consumption Time: 0.29716
Total Iteration Time: 4.73658

Cumulative Model Updates: 83,974
Cumulative Timesteps: 700,419,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 700419174...
Checkpoint 700419174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 712.81854
Policy Entropy: 3.25567
Value Function Loss: 0.00456

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.57100
Value Function Update Magnitude: 0.65728

Collected Steps per Second: 22,091.14876
Overall Steps per Second: 10,590.31644

Timestep Collection Time: 2.26380
Timestep Consumption Time: 2.45844
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.72224

Cumulative Model Updates: 83,980
Cumulative Timesteps: 700,469,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.06991
Policy Entropy: 3.25788
Value Function Loss: 0.00462

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.57069
Value Function Update Magnitude: 0.67704

Collected Steps per Second: 22,662.21752
Overall Steps per Second: 10,655.64761

Timestep Collection Time: 2.20729
Timestep Consumption Time: 2.48713
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.69441

Cumulative Model Updates: 83,986
Cumulative Timesteps: 700,519,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 700519206...
Checkpoint 700519206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.55718
Policy Entropy: 3.22763
Value Function Loss: 0.00492

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.57990
Value Function Update Magnitude: 0.69899

Collected Steps per Second: 22,497.58760
Overall Steps per Second: 10,585.40583

Timestep Collection Time: 2.22299
Timestep Consumption Time: 2.50162
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.72462

Cumulative Model Updates: 83,992
Cumulative Timesteps: 700,569,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.17061
Policy Entropy: 3.24966
Value Function Loss: 0.00468

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.58284
Value Function Update Magnitude: 0.71477

Collected Steps per Second: 22,967.11152
Overall Steps per Second: 10,833.62405

Timestep Collection Time: 2.17816
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.61766

Cumulative Model Updates: 83,998
Cumulative Timesteps: 700,619,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 700619244...
Checkpoint 700619244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,401.69071
Policy Entropy: 3.25217
Value Function Loss: 0.00444

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10036
Policy Update Magnitude: 0.58101
Value Function Update Magnitude: 0.70231

Collected Steps per Second: 22,882.73596
Overall Steps per Second: 10,705.41421

Timestep Collection Time: 2.18505
Timestep Consumption Time: 2.48548
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.67053

Cumulative Model Updates: 84,004
Cumulative Timesteps: 700,669,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.79461
Policy Entropy: 3.26414
Value Function Loss: 0.00442

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.57003
Value Function Update Magnitude: 0.68398

Collected Steps per Second: 22,962.54487
Overall Steps per Second: 10,764.04389

Timestep Collection Time: 2.17746
Timestep Consumption Time: 2.46764
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.64509

Cumulative Model Updates: 84,010
Cumulative Timesteps: 700,719,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 700719244...
Checkpoint 700719244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.97166
Policy Entropy: 3.25346
Value Function Loss: 0.00442

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11735
Policy Update Magnitude: 0.56728
Value Function Update Magnitude: 0.64285

Collected Steps per Second: 22,652.69633
Overall Steps per Second: 10,603.84950

Timestep Collection Time: 2.20777
Timestep Consumption Time: 2.50863
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.71640

Cumulative Model Updates: 84,016
Cumulative Timesteps: 700,769,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.04017
Policy Entropy: 3.24273
Value Function Loss: 0.00449

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.57122
Value Function Update Magnitude: 0.63456

Collected Steps per Second: 23,167.27786
Overall Steps per Second: 10,797.11589

Timestep Collection Time: 2.15899
Timestep Consumption Time: 2.47354
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.63253

Cumulative Model Updates: 84,022
Cumulative Timesteps: 700,819,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 700819274...
Checkpoint 700819274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.21746
Policy Entropy: 3.24243
Value Function Loss: 0.00432

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.56399
Value Function Update Magnitude: 0.63815

Collected Steps per Second: 22,642.25107
Overall Steps per Second: 10,799.43230

Timestep Collection Time: 2.20826
Timestep Consumption Time: 2.42161
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.62987

Cumulative Model Updates: 84,028
Cumulative Timesteps: 700,869,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.65767
Policy Entropy: 3.23242
Value Function Loss: 0.00430

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10417
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.63465

Collected Steps per Second: 22,444.15089
Overall Steps per Second: 10,579.12917

Timestep Collection Time: 2.22855
Timestep Consumption Time: 2.49943
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.72799

Cumulative Model Updates: 84,034
Cumulative Timesteps: 700,919,292

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 700919292...
Checkpoint 700919292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.78211
Policy Entropy: 3.22558
Value Function Loss: 0.00435

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.62587

Collected Steps per Second: 22,231.13154
Overall Steps per Second: 10,509.55000

Timestep Collection Time: 2.25108
Timestep Consumption Time: 2.51069
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.76176

Cumulative Model Updates: 84,040
Cumulative Timesteps: 700,969,336

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.79087
Policy Entropy: 3.24383
Value Function Loss: 0.00427

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11604
Policy Update Magnitude: 0.56578
Value Function Update Magnitude: 0.64615

Collected Steps per Second: 22,473.43791
Overall Steps per Second: 10,599.23638

Timestep Collection Time: 2.22690
Timestep Consumption Time: 2.49477
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.72166

Cumulative Model Updates: 84,046
Cumulative Timesteps: 701,019,382

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 701019382...
Checkpoint 701019382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.09325
Policy Entropy: 3.25054
Value Function Loss: 0.00415

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12211
Policy Update Magnitude: 0.55706
Value Function Update Magnitude: 0.65572

Collected Steps per Second: 22,357.12309
Overall Steps per Second: 10,591.36228

Timestep Collection Time: 2.23768
Timestep Consumption Time: 2.48580
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.72347

Cumulative Model Updates: 84,052
Cumulative Timesteps: 701,069,410

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.88039
Policy Entropy: 3.25791
Value Function Loss: 0.00406

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.54812
Value Function Update Magnitude: 0.62818

Collected Steps per Second: 22,569.21588
Overall Steps per Second: 10,712.03982

Timestep Collection Time: 2.21567
Timestep Consumption Time: 2.45253
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.66821

Cumulative Model Updates: 84,058
Cumulative Timesteps: 701,119,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 701119416...
Checkpoint 701119416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.07955
Policy Entropy: 3.25942
Value Function Loss: 0.00434

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08300
Policy Update Magnitude: 0.55525
Value Function Update Magnitude: 0.60356

Collected Steps per Second: 22,334.58792
Overall Steps per Second: 10,628.47286

Timestep Collection Time: 2.23904
Timestep Consumption Time: 2.46606
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.70510

Cumulative Model Updates: 84,064
Cumulative Timesteps: 701,169,424

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.72740
Policy Entropy: 3.25943
Value Function Loss: 0.00458

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.57130
Value Function Update Magnitude: 0.62608

Collected Steps per Second: 21,586.67498
Overall Steps per Second: 10,495.24517

Timestep Collection Time: 2.31754
Timestep Consumption Time: 2.44919
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.76673

Cumulative Model Updates: 84,070
Cumulative Timesteps: 701,219,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 701219452...
Checkpoint 701219452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.48155
Policy Entropy: 3.25374
Value Function Loss: 0.00479

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.57742
Value Function Update Magnitude: 0.65637

Collected Steps per Second: 22,344.20838
Overall Steps per Second: 10,705.97350

Timestep Collection Time: 2.23843
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.67178

Cumulative Model Updates: 84,076
Cumulative Timesteps: 701,269,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.46130
Policy Entropy: 3.25153
Value Function Loss: 0.00463

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.58418
Value Function Update Magnitude: 0.70494

Collected Steps per Second: 22,081.58510
Overall Steps per Second: 10,660.25096

Timestep Collection Time: 2.26433
Timestep Consumption Time: 2.42599
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.69032

Cumulative Model Updates: 84,082
Cumulative Timesteps: 701,319,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 701319468...
Checkpoint 701319468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.85311
Policy Entropy: 3.26447
Value Function Loss: 0.00456

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11351
Policy Update Magnitude: 0.57855
Value Function Update Magnitude: 0.71408

Collected Steps per Second: 21,727.72888
Overall Steps per Second: 10,535.73762

Timestep Collection Time: 2.30213
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.74765

Cumulative Model Updates: 84,088
Cumulative Timesteps: 701,369,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.47551
Policy Entropy: 3.27958
Value Function Loss: 0.00450

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.56784
Value Function Update Magnitude: 0.68950

Collected Steps per Second: 22,622.59768
Overall Steps per Second: 10,824.85340

Timestep Collection Time: 2.21106
Timestep Consumption Time: 2.40978
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.62085

Cumulative Model Updates: 84,094
Cumulative Timesteps: 701,419,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 701419508...
Checkpoint 701419508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.33870
Policy Entropy: 3.29101
Value Function Loss: 0.00453

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.55558
Value Function Update Magnitude: 0.65452

Collected Steps per Second: 22,051.81895
Overall Steps per Second: 10,629.82883

Timestep Collection Time: 2.26848
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.70600

Cumulative Model Updates: 84,100
Cumulative Timesteps: 701,469,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.18402
Policy Entropy: 3.28904
Value Function Loss: 0.00423

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10557
Policy Update Magnitude: 0.54183
Value Function Update Magnitude: 0.61004

Collected Steps per Second: 21,877.35106
Overall Steps per Second: 10,578.24839

Timestep Collection Time: 2.28620
Timestep Consumption Time: 2.44199
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.72819

Cumulative Model Updates: 84,106
Cumulative Timesteps: 701,519,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 701519548...
Checkpoint 701519548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.21680
Policy Entropy: 3.28521
Value Function Loss: 0.00441

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.53678
Value Function Update Magnitude: 0.58473

Collected Steps per Second: 21,296.69823
Overall Steps per Second: 10,522.62984

Timestep Collection Time: 2.34881
Timestep Consumption Time: 2.40494
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.75375

Cumulative Model Updates: 84,112
Cumulative Timesteps: 701,569,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.21803
Policy Entropy: 3.28386
Value Function Loss: 0.00430

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.11118
Policy Update Magnitude: 0.54045
Value Function Update Magnitude: 0.60591

Collected Steps per Second: 21,811.10012
Overall Steps per Second: 10,538.00500

Timestep Collection Time: 2.29324
Timestep Consumption Time: 2.45320
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.74644

Cumulative Model Updates: 84,118
Cumulative Timesteps: 701,619,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 701619588...
Checkpoint 701619588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.65011
Policy Entropy: 3.27349
Value Function Loss: 0.00462

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11038
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.65048

Collected Steps per Second: 21,834.16981
Overall Steps per Second: 10,560.18052

Timestep Collection Time: 2.29045
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.73571

Cumulative Model Updates: 84,124
Cumulative Timesteps: 701,669,598

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.43566
Policy Entropy: 3.27533
Value Function Loss: 0.00465

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.56376
Value Function Update Magnitude: 0.67522

Collected Steps per Second: 21,689.82775
Overall Steps per Second: 10,519.03089

Timestep Collection Time: 2.30643
Timestep Consumption Time: 2.44933
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.75576

Cumulative Model Updates: 84,130
Cumulative Timesteps: 701,719,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 701719624...
Checkpoint 701719624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.06064
Policy Entropy: 3.26655
Value Function Loss: 0.00470

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10198
Policy Update Magnitude: 0.56425
Value Function Update Magnitude: 0.66218

Collected Steps per Second: 22,015.00320
Overall Steps per Second: 10,532.54651

Timestep Collection Time: 2.27154
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.74795

Cumulative Model Updates: 84,136
Cumulative Timesteps: 701,769,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.27044
Policy Entropy: 3.27996
Value Function Loss: 0.00472

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.56504
Value Function Update Magnitude: 0.64873

Collected Steps per Second: 22,813.38685
Overall Steps per Second: 10,633.13195

Timestep Collection Time: 2.19284
Timestep Consumption Time: 2.51189
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.70473

Cumulative Model Updates: 84,142
Cumulative Timesteps: 701,819,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 701819658...
Checkpoint 701819658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.05163
Policy Entropy: 3.27393
Value Function Loss: 0.00451

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.55448
Value Function Update Magnitude: 0.64516

Collected Steps per Second: 22,702.77874
Overall Steps per Second: 10,622.98194

Timestep Collection Time: 2.20370
Timestep Consumption Time: 2.50591
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.70960

Cumulative Model Updates: 84,148
Cumulative Timesteps: 701,869,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.45384
Policy Entropy: 3.27223
Value Function Loss: 0.00447

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08585
Policy Update Magnitude: 0.54726
Value Function Update Magnitude: 0.62639

Collected Steps per Second: 23,174.91949
Overall Steps per Second: 10,760.94448

Timestep Collection Time: 2.15811
Timestep Consumption Time: 2.48962
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.64773

Cumulative Model Updates: 84,154
Cumulative Timesteps: 701,919,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 701919702...
Checkpoint 701919702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.34254
Policy Entropy: 3.26893
Value Function Loss: 0.00420

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07779
Policy Update Magnitude: 0.54922
Value Function Update Magnitude: 0.63423

Collected Steps per Second: 22,201.88379
Overall Steps per Second: 10,604.60162

Timestep Collection Time: 2.25233
Timestep Consumption Time: 2.46317
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.71550

Cumulative Model Updates: 84,160
Cumulative Timesteps: 701,969,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.05436
Policy Entropy: 3.26719
Value Function Loss: 0.00432

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.61994

Collected Steps per Second: 23,237.50117
Overall Steps per Second: 10,852.85881

Timestep Collection Time: 2.15290
Timestep Consumption Time: 2.45676
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.60966

Cumulative Model Updates: 84,166
Cumulative Timesteps: 702,019,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 702019736...
Checkpoint 702019736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.88037
Policy Entropy: 3.27832
Value Function Loss: 0.00426

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07674
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.61045

Collected Steps per Second: 22,205.39135
Overall Steps per Second: 10,678.80159

Timestep Collection Time: 2.25261
Timestep Consumption Time: 2.43144
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.68405

Cumulative Model Updates: 84,172
Cumulative Timesteps: 702,069,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.52096
Policy Entropy: 3.27381
Value Function Loss: 0.00432

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.54781
Value Function Update Magnitude: 0.62242

Collected Steps per Second: 22,409.25468
Overall Steps per Second: 10,509.56430

Timestep Collection Time: 2.23247
Timestep Consumption Time: 2.52776
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.76024

Cumulative Model Updates: 84,178
Cumulative Timesteps: 702,119,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 702119784...
Checkpoint 702119784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.50202
Policy Entropy: 3.27302
Value Function Loss: 0.00410

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07627
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.59774

Collected Steps per Second: 22,268.08189
Overall Steps per Second: 10,636.29999

Timestep Collection Time: 2.24555
Timestep Consumption Time: 2.45571
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.70126

Cumulative Model Updates: 84,184
Cumulative Timesteps: 702,169,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.90922
Policy Entropy: 3.26851
Value Function Loss: 0.00443

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08049
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.59643

Collected Steps per Second: 22,455.37812
Overall Steps per Second: 10,504.44322

Timestep Collection Time: 2.22762
Timestep Consumption Time: 2.53437
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.76198

Cumulative Model Updates: 84,190
Cumulative Timesteps: 702,219,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 702219810...
Checkpoint 702219810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758.53320
Policy Entropy: 3.26199
Value Function Loss: 0.00426

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.55200
Value Function Update Magnitude: 0.60833

Collected Steps per Second: 22,777.50767
Overall Steps per Second: 10,602.42358

Timestep Collection Time: 2.19541
Timestep Consumption Time: 2.52106
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.71647

Cumulative Model Updates: 84,196
Cumulative Timesteps: 702,269,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.73245
Policy Entropy: 3.26970
Value Function Loss: 0.00426

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.54207
Value Function Update Magnitude: 0.59297

Collected Steps per Second: 22,393.86926
Overall Steps per Second: 10,457.57809

Timestep Collection Time: 2.23409
Timestep Consumption Time: 2.55000
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.78409

Cumulative Model Updates: 84,202
Cumulative Timesteps: 702,319,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 702319846...
Checkpoint 702319846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.05216
Policy Entropy: 3.27202
Value Function Loss: 0.00416

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.54232
Value Function Update Magnitude: 0.58643

Collected Steps per Second: 22,854.04314
Overall Steps per Second: 10,663.54346

Timestep Collection Time: 2.18858
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.69056

Cumulative Model Updates: 84,208
Cumulative Timesteps: 702,369,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 609.58862
Policy Entropy: 3.25851
Value Function Loss: 0.00444

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.60767

Collected Steps per Second: 23,003.03738
Overall Steps per Second: 10,783.77995

Timestep Collection Time: 2.17441
Timestep Consumption Time: 2.46385
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.63826

Cumulative Model Updates: 84,214
Cumulative Timesteps: 702,419,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 702419882...
Checkpoint 702419882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.36893
Policy Entropy: 3.23662
Value Function Loss: 0.00450

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.56688
Value Function Update Magnitude: 0.63389

Collected Steps per Second: 22,710.95480
Overall Steps per Second: 10,739.75652

Timestep Collection Time: 2.20184
Timestep Consumption Time: 2.45431
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.65616

Cumulative Model Updates: 84,220
Cumulative Timesteps: 702,469,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.50174
Policy Entropy: 3.23310
Value Function Loss: 0.00450

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.65077

Collected Steps per Second: 22,626.19478
Overall Steps per Second: 10,571.90126

Timestep Collection Time: 2.21054
Timestep Consumption Time: 2.52050
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.73103

Cumulative Model Updates: 84,226
Cumulative Timesteps: 702,519,904

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 702519904...
Checkpoint 702519904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.02624
Policy Entropy: 3.22645
Value Function Loss: 0.00469

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11966
Policy Update Magnitude: 0.57250
Value Function Update Magnitude: 0.64796

Collected Steps per Second: 22,246.59781
Overall Steps per Second: 10,550.22010

Timestep Collection Time: 2.24906
Timestep Consumption Time: 2.49340
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.74246

Cumulative Model Updates: 84,232
Cumulative Timesteps: 702,569,938

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.32417
Policy Entropy: 3.21945
Value Function Loss: 0.00473

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.57787
Value Function Update Magnitude: 0.65995

Collected Steps per Second: 22,855.17290
Overall Steps per Second: 10,677.63462

Timestep Collection Time: 2.18830
Timestep Consumption Time: 2.49570
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.68400

Cumulative Model Updates: 84,238
Cumulative Timesteps: 702,619,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 702619952...
Checkpoint 702619952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.32693
Policy Entropy: 3.23002
Value Function Loss: 0.00465

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12925
Policy Update Magnitude: 0.57720
Value Function Update Magnitude: 0.67511

Collected Steps per Second: 22,692.39143
Overall Steps per Second: 10,756.36292

Timestep Collection Time: 2.20338
Timestep Consumption Time: 2.44503
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.64841

Cumulative Model Updates: 84,244
Cumulative Timesteps: 702,669,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.37056
Policy Entropy: 3.25076
Value Function Loss: 0.00437

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11985
Policy Update Magnitude: 0.56396
Value Function Update Magnitude: 0.68892

Collected Steps per Second: 22,195.06878
Overall Steps per Second: 10,473.39318

Timestep Collection Time: 2.25320
Timestep Consumption Time: 2.52175
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.77496

Cumulative Model Updates: 84,250
Cumulative Timesteps: 702,719,962

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 702719962...
Checkpoint 702719962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.16768
Policy Entropy: 3.26505
Value Function Loss: 0.00431

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.55157
Value Function Update Magnitude: 0.67550

Collected Steps per Second: 22,112.72556
Overall Steps per Second: 10,605.32564

Timestep Collection Time: 2.26186
Timestep Consumption Time: 2.45426
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.71612

Cumulative Model Updates: 84,256
Cumulative Timesteps: 702,769,978

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.03121
Policy Entropy: 3.25739
Value Function Loss: 0.00442

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.65699

Collected Steps per Second: 22,046.93958
Overall Steps per Second: 10,576.47966

Timestep Collection Time: 2.26925
Timestep Consumption Time: 2.46106
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.73031

Cumulative Model Updates: 84,262
Cumulative Timesteps: 702,820,008

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 702820008...
Checkpoint 702820008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.23820
Policy Entropy: 3.24269
Value Function Loss: 0.00446

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.56369
Value Function Update Magnitude: 0.64953

Collected Steps per Second: 22,447.66915
Overall Steps per Second: 10,660.09846

Timestep Collection Time: 2.22856
Timestep Consumption Time: 2.46427
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.69283

Cumulative Model Updates: 84,268
Cumulative Timesteps: 702,870,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.36525
Policy Entropy: 3.25406
Value Function Loss: 0.00440

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11268
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.66558

Collected Steps per Second: 22,355.59212
Overall Steps per Second: 10,589.31976

Timestep Collection Time: 2.23720
Timestep Consumption Time: 2.48586
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.72306

Cumulative Model Updates: 84,274
Cumulative Timesteps: 702,920,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 702920048...
Checkpoint 702920048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.24661
Policy Entropy: 3.25896
Value Function Loss: 0.00413

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.54772
Value Function Update Magnitude: 0.65170

Collected Steps per Second: 22,764.78257
Overall Steps per Second: 10,570.54221

Timestep Collection Time: 2.19761
Timestep Consumption Time: 2.53517
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.73278

Cumulative Model Updates: 84,280
Cumulative Timesteps: 702,970,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.07429
Policy Entropy: 3.26774
Value Function Loss: 0.00422

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.54319
Value Function Update Magnitude: 0.64097

Collected Steps per Second: 22,812.72925
Overall Steps per Second: 10,811.82006

Timestep Collection Time: 2.19264
Timestep Consumption Time: 2.43378
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.62642

Cumulative Model Updates: 84,286
Cumulative Timesteps: 703,020,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 703020096...
Checkpoint 703020096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.14691
Policy Entropy: 3.26708
Value Function Loss: 0.00428

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.54719
Value Function Update Magnitude: 0.65034

Collected Steps per Second: 22,621.08257
Overall Steps per Second: 10,654.43060

Timestep Collection Time: 2.21059
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.69345

Cumulative Model Updates: 84,292
Cumulative Timesteps: 703,070,102

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.03476
Policy Entropy: 3.26917
Value Function Loss: 0.00424

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.54458
Value Function Update Magnitude: 0.67085

Collected Steps per Second: 22,000.52564
Overall Steps per Second: 10,430.98721

Timestep Collection Time: 2.27304
Timestep Consumption Time: 2.52114
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.79418

Cumulative Model Updates: 84,298
Cumulative Timesteps: 703,120,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 703120110...
Checkpoint 703120110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 914.47533
Policy Entropy: 3.27371
Value Function Loss: 0.00417

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.54042
Value Function Update Magnitude: 0.68600

Collected Steps per Second: 22,282.51504
Overall Steps per Second: 10,717.70568

Timestep Collection Time: 2.24571
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.66891

Cumulative Model Updates: 84,304
Cumulative Timesteps: 703,170,150

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.41460
Policy Entropy: 3.27807
Value Function Loss: 0.00410

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08944
Policy Update Magnitude: 0.54707
Value Function Update Magnitude: 0.67562

Collected Steps per Second: 23,011.26745
Overall Steps per Second: 10,847.36635

Timestep Collection Time: 2.17354
Timestep Consumption Time: 2.43734
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.61089

Cumulative Model Updates: 84,310
Cumulative Timesteps: 703,220,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 703220166...
Checkpoint 703220166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.16603
Policy Entropy: 3.27525
Value Function Loss: 0.00421

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08013
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.66420

Collected Steps per Second: 22,774.41873
Overall Steps per Second: 10,665.91308

Timestep Collection Time: 2.19685
Timestep Consumption Time: 2.49398
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.69083

Cumulative Model Updates: 84,316
Cumulative Timesteps: 703,270,198

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.09597
Policy Entropy: 3.28125
Value Function Loss: 0.00453

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08957
Policy Update Magnitude: 0.55724
Value Function Update Magnitude: 0.66581

Collected Steps per Second: 22,461.39339
Overall Steps per Second: 10,605.87307

Timestep Collection Time: 2.22631
Timestep Consumption Time: 2.48863
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.71493

Cumulative Model Updates: 84,322
Cumulative Timesteps: 703,320,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 703320204...
Checkpoint 703320204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.80058
Policy Entropy: 3.27521
Value Function Loss: 0.00470

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.57199
Value Function Update Magnitude: 0.67972

Collected Steps per Second: 22,404.53144
Overall Steps per Second: 10,562.73894

Timestep Collection Time: 2.23223
Timestep Consumption Time: 2.50253
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.73476

Cumulative Model Updates: 84,328
Cumulative Timesteps: 703,370,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.82290
Policy Entropy: 3.26414
Value Function Loss: 0.00452

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.56593
Value Function Update Magnitude: 0.66918

Collected Steps per Second: 22,513.03484
Overall Steps per Second: 10,728.98761

Timestep Collection Time: 2.22218
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.66288

Cumulative Model Updates: 84,334
Cumulative Timesteps: 703,420,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 703420244...
Checkpoint 703420244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.91032
Policy Entropy: 3.26205
Value Function Loss: 0.00422

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11118
Policy Update Magnitude: 0.55056
Value Function Update Magnitude: 0.65065

Collected Steps per Second: 22,464.77775
Overall Steps per Second: 10,773.60864

Timestep Collection Time: 2.22660
Timestep Consumption Time: 2.41623
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.64283

Cumulative Model Updates: 84,340
Cumulative Timesteps: 703,470,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.58721
Policy Entropy: 3.25494
Value Function Loss: 0.00421

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.55012
Value Function Update Magnitude: 0.65006

Collected Steps per Second: 22,770.77499
Overall Steps per Second: 10,654.68227

Timestep Collection Time: 2.19738
Timestep Consumption Time: 2.49877
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.69615

Cumulative Model Updates: 84,346
Cumulative Timesteps: 703,520,300

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 703520300...
Checkpoint 703520300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.35958
Policy Entropy: 3.26593
Value Function Loss: 0.00424

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10865
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.67135

Collected Steps per Second: 22,513.74820
Overall Steps per Second: 10,595.34464

Timestep Collection Time: 2.22291
Timestep Consumption Time: 2.50049
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.72340

Cumulative Model Updates: 84,352
Cumulative Timesteps: 703,570,346

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.26735
Policy Entropy: 3.25086
Value Function Loss: 0.00442

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11677
Policy Update Magnitude: 0.55859
Value Function Update Magnitude: 0.65226

Collected Steps per Second: 22,990.69119
Overall Steps per Second: 10,727.42089

Timestep Collection Time: 2.17532
Timestep Consumption Time: 2.48676
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.66207

Cumulative Model Updates: 84,358
Cumulative Timesteps: 703,620,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 703620358...
Checkpoint 703620358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.74110
Policy Entropy: 3.25050
Value Function Loss: 0.00438

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.56226
Value Function Update Magnitude: 0.64672

Collected Steps per Second: 22,745.04585
Overall Steps per Second: 10,620.12473

Timestep Collection Time: 2.19854
Timestep Consumption Time: 2.51006
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.70861

Cumulative Model Updates: 84,364
Cumulative Timesteps: 703,670,364

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.36456
Policy Entropy: 3.24076
Value Function Loss: 0.00444

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11100
Policy Update Magnitude: 0.56707
Value Function Update Magnitude: 0.63743

Collected Steps per Second: 23,006.94316
Overall Steps per Second: 10,794.68538

Timestep Collection Time: 2.17387
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.63321

Cumulative Model Updates: 84,370
Cumulative Timesteps: 703,720,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 703720378...
Checkpoint 703720378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.19620
Policy Entropy: 3.24960
Value Function Loss: 0.00444

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10231
Policy Update Magnitude: 0.56743
Value Function Update Magnitude: 0.64378

Collected Steps per Second: 22,513.34209
Overall Steps per Second: 10,711.08808

Timestep Collection Time: 2.22197
Timestep Consumption Time: 2.44833
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.67030

Cumulative Model Updates: 84,376
Cumulative Timesteps: 703,770,402

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.06982
Policy Entropy: 3.24690
Value Function Loss: 0.00455

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.65581

Collected Steps per Second: 22,705.54314
Overall Steps per Second: 10,663.32920

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.69178

Cumulative Model Updates: 84,382
Cumulative Timesteps: 703,820,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 703820432...
Checkpoint 703820432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.55899
Policy Entropy: 3.24695
Value Function Loss: 0.00464

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.57650
Value Function Update Magnitude: 0.66706

Collected Steps per Second: 22,472.30597
Overall Steps per Second: 10,631.32393

Timestep Collection Time: 2.22532
Timestep Consumption Time: 2.47852
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.70384

Cumulative Model Updates: 84,388
Cumulative Timesteps: 703,870,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.19385
Policy Entropy: 3.24669
Value Function Loss: 0.00448

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.57902
Value Function Update Magnitude: 0.66942

Collected Steps per Second: 22,209.47698
Overall Steps per Second: 10,639.55505

Timestep Collection Time: 2.25147
Timestep Consumption Time: 2.44835
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.69982

Cumulative Model Updates: 84,394
Cumulative Timesteps: 703,920,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 703920444...
Checkpoint 703920444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.02011
Policy Entropy: 3.24527
Value Function Loss: 0.00420

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.56974
Value Function Update Magnitude: 0.63741

Collected Steps per Second: 22,430.04866
Overall Steps per Second: 10,705.12959

Timestep Collection Time: 2.23058
Timestep Consumption Time: 2.44307
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.67365

Cumulative Model Updates: 84,400
Cumulative Timesteps: 703,970,476

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.55564
Policy Entropy: 3.25978
Value Function Loss: 0.00422

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.55777
Value Function Update Magnitude: 0.61717

Collected Steps per Second: 22,345.53704
Overall Steps per Second: 10,531.67192

Timestep Collection Time: 2.23821
Timestep Consumption Time: 2.51070
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.74891

Cumulative Model Updates: 84,406
Cumulative Timesteps: 704,020,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 704020490...
Checkpoint 704020490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.42013
Policy Entropy: 3.25018
Value Function Loss: 0.00462

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10482
Policy Update Magnitude: 0.56091
Value Function Update Magnitude: 0.62931

Collected Steps per Second: 22,533.72624
Overall Steps per Second: 10,605.23511

Timestep Collection Time: 2.21934
Timestep Consumption Time: 2.49626
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.71560

Cumulative Model Updates: 84,412
Cumulative Timesteps: 704,070,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.60658
Policy Entropy: 3.24980
Value Function Loss: 0.00446

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.56655
Value Function Update Magnitude: 0.65374

Collected Steps per Second: 22,417.07207
Overall Steps per Second: 10,475.59165

Timestep Collection Time: 2.23178
Timestep Consumption Time: 2.54408
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.77586

Cumulative Model Updates: 84,418
Cumulative Timesteps: 704,120,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 704120530...
Checkpoint 704120530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679.50049
Policy Entropy: 3.24348
Value Function Loss: 0.00434

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.56212
Value Function Update Magnitude: 0.65904

Collected Steps per Second: 22,412.72220
Overall Steps per Second: 10,586.22468

Timestep Collection Time: 2.23159
Timestep Consumption Time: 2.49304
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.72463

Cumulative Model Updates: 84,424
Cumulative Timesteps: 704,170,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.60536
Policy Entropy: 3.24391
Value Function Loss: 0.00422

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.55350
Value Function Update Magnitude: 0.63233

Collected Steps per Second: 22,709.56584
Overall Steps per Second: 10,909.89231

Timestep Collection Time: 2.20189
Timestep Consumption Time: 2.38147
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.58336

Cumulative Model Updates: 84,430
Cumulative Timesteps: 704,220,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 704220550...
Checkpoint 704220550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.37688
Policy Entropy: 3.25153
Value Function Loss: 0.00429

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.55866
Value Function Update Magnitude: 0.62206

Collected Steps per Second: 22,180.89918
Overall Steps per Second: 10,700.12454

Timestep Collection Time: 2.25545
Timestep Consumption Time: 2.42001
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.67546

Cumulative Model Updates: 84,436
Cumulative Timesteps: 704,270,578

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.06652
Policy Entropy: 3.25724
Value Function Loss: 0.00432

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11358
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.61574

Collected Steps per Second: 22,334.62154
Overall Steps per Second: 10,792.91416

Timestep Collection Time: 2.23993
Timestep Consumption Time: 2.39533
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.63526

Cumulative Model Updates: 84,442
Cumulative Timesteps: 704,320,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 704320606...
Checkpoint 704320606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.32885
Policy Entropy: 3.25962
Value Function Loss: 0.00438

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.54829
Value Function Update Magnitude: 0.62288

Collected Steps per Second: 21,400.07107
Overall Steps per Second: 10,483.35528

Timestep Collection Time: 2.33719
Timestep Consumption Time: 2.43380
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.77099

Cumulative Model Updates: 84,448
Cumulative Timesteps: 704,370,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.36348
Policy Entropy: 3.24500
Value Function Loss: 0.00468

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11938
Policy Update Magnitude: 0.55460
Value Function Update Magnitude: 0.64506

Collected Steps per Second: 22,136.32441
Overall Steps per Second: 10,683.55570

Timestep Collection Time: 2.25891
Timestep Consumption Time: 2.42155
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.68046

Cumulative Model Updates: 84,454
Cumulative Timesteps: 704,420,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 704420626...
Checkpoint 704420626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.62516
Policy Entropy: 3.24990
Value Function Loss: 0.00448

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.55768
Value Function Update Magnitude: 0.65663

Collected Steps per Second: 21,489.41351
Overall Steps per Second: 10,649.02339

Timestep Collection Time: 2.32812
Timestep Consumption Time: 2.36996
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.69808

Cumulative Model Updates: 84,460
Cumulative Timesteps: 704,470,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.89327
Policy Entropy: 3.24357
Value Function Loss: 0.00427

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11310
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.65536

Collected Steps per Second: 21,543.82786
Overall Steps per Second: 10,470.62804

Timestep Collection Time: 2.32131
Timestep Consumption Time: 2.45490
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.77622

Cumulative Model Updates: 84,466
Cumulative Timesteps: 704,520,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 704520666...
Checkpoint 704520666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.12887
Policy Entropy: 3.23157
Value Function Loss: 0.00405

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.54945
Value Function Update Magnitude: 0.64528

Collected Steps per Second: 21,640.91912
Overall Steps per Second: 10,644.95439

Timestep Collection Time: 2.31090
Timestep Consumption Time: 2.38710
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.69800

Cumulative Model Updates: 84,472
Cumulative Timesteps: 704,570,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.32596
Policy Entropy: 3.21635
Value Function Loss: 0.00414

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.62415

Collected Steps per Second: 21,973.24558
Overall Steps per Second: 10,627.65186

Timestep Collection Time: 2.27722
Timestep Consumption Time: 2.43106
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.70828

Cumulative Model Updates: 84,478
Cumulative Timesteps: 704,620,714

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 704620714...
Checkpoint 704620714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.49142
Policy Entropy: 3.21661
Value Function Loss: 0.00445

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11597
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.62450

Collected Steps per Second: 21,817.76345
Overall Steps per Second: 10,556.35667

Timestep Collection Time: 2.29290
Timestep Consumption Time: 2.44604
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.73895

Cumulative Model Updates: 84,484
Cumulative Timesteps: 704,670,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.02227
Policy Entropy: 3.22891
Value Function Loss: 0.00444

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.56376
Value Function Update Magnitude: 0.64366

Collected Steps per Second: 22,126.18597
Overall Steps per Second: 10,739.74618

Timestep Collection Time: 2.26049
Timestep Consumption Time: 2.39660
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.65709

Cumulative Model Updates: 84,490
Cumulative Timesteps: 704,720,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 704720756...
Checkpoint 704720756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.30005
Policy Entropy: 3.23333
Value Function Loss: 0.00456

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08659
Policy Update Magnitude: 0.56898
Value Function Update Magnitude: 0.65947

Collected Steps per Second: 21,798.18647
Overall Steps per Second: 10,649.33400

Timestep Collection Time: 2.29395
Timestep Consumption Time: 2.40155
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.69550

Cumulative Model Updates: 84,496
Cumulative Timesteps: 704,770,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.60557
Policy Entropy: 3.23000
Value Function Loss: 0.00437

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08826
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.64063

Collected Steps per Second: 22,188.22887
Overall Steps per Second: 10,648.72093

Timestep Collection Time: 2.25345
Timestep Consumption Time: 2.44195
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.69540

Cumulative Model Updates: 84,502
Cumulative Timesteps: 704,820,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 704820760...
Checkpoint 704820760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.85949
Policy Entropy: 3.24160
Value Function Loss: 0.00448

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.55858
Value Function Update Magnitude: 0.62111

Collected Steps per Second: 22,885.60359
Overall Steps per Second: 10,684.63718

Timestep Collection Time: 2.18583
Timestep Consumption Time: 2.49603
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.68186

Cumulative Model Updates: 84,508
Cumulative Timesteps: 704,870,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.30488
Policy Entropy: 3.25721
Value Function Loss: 0.00437

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.56077
Value Function Update Magnitude: 0.62846

Collected Steps per Second: 22,613.95440
Overall Steps per Second: 10,685.41400

Timestep Collection Time: 2.21279
Timestep Consumption Time: 2.47023
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.68302

Cumulative Model Updates: 84,514
Cumulative Timesteps: 704,920,824

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 704920824...
Checkpoint 704920824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.51775
Policy Entropy: 3.25810
Value Function Loss: 0.00450

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.55687
Value Function Update Magnitude: 0.62533

Collected Steps per Second: 22,538.23054
Overall Steps per Second: 10,681.18983

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.46326
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.68225

Cumulative Model Updates: 84,520
Cumulative Timesteps: 704,970,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.95539
Policy Entropy: 3.24244
Value Function Loss: 0.00482

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.56830
Value Function Update Magnitude: 0.63304

Collected Steps per Second: 21,869.57687
Overall Steps per Second: 10,449.35310

Timestep Collection Time: 2.28720
Timestep Consumption Time: 2.49970
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.78690

Cumulative Model Updates: 84,526
Cumulative Timesteps: 705,020,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 705020856...
Checkpoint 705020856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.78869
Policy Entropy: 3.24392
Value Function Loss: 0.00474

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.57275
Value Function Update Magnitude: 0.64626

Collected Steps per Second: 21,566.19034
Overall Steps per Second: 10,652.42560

Timestep Collection Time: 2.31872
Timestep Consumption Time: 2.37561
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.69433

Cumulative Model Updates: 84,532
Cumulative Timesteps: 705,070,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.81865
Policy Entropy: 3.24811
Value Function Loss: 0.00455

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.56839
Value Function Update Magnitude: 0.65656

Collected Steps per Second: 22,229.81737
Overall Steps per Second: 10,446.66436

Timestep Collection Time: 2.24968
Timestep Consumption Time: 2.53749
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.78717

Cumulative Model Updates: 84,538
Cumulative Timesteps: 705,120,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 705120872...
Checkpoint 705120872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.22314
Policy Entropy: 3.24759
Value Function Loss: 0.00438

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.56092
Value Function Update Magnitude: 0.65098

Collected Steps per Second: 22,521.31163
Overall Steps per Second: 10,552.01294

Timestep Collection Time: 2.22083
Timestep Consumption Time: 2.51912
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.73995

Cumulative Model Updates: 84,544
Cumulative Timesteps: 705,170,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.78485
Policy Entropy: 3.24360
Value Function Loss: 0.00446

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.56231
Value Function Update Magnitude: 0.65091

Collected Steps per Second: 22,790.44823
Overall Steps per Second: 10,540.20023

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.55045
PPO Batch Consumption Time: 0.29486
Total Iteration Time: 4.74488

Cumulative Model Updates: 84,550
Cumulative Timesteps: 705,220,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 705220900...
Checkpoint 705220900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.88252
Policy Entropy: 3.24378
Value Function Loss: 0.00443

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.11068
Policy Update Magnitude: 0.55524
Value Function Update Magnitude: 0.64798

Collected Steps per Second: 22,826.83693
Overall Steps per Second: 10,598.23074

Timestep Collection Time: 2.19137
Timestep Consumption Time: 2.52848
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71984

Cumulative Model Updates: 84,556
Cumulative Timesteps: 705,270,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.75519
Policy Entropy: 3.24825
Value Function Loss: 0.00445

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.62976

Collected Steps per Second: 23,040.37064
Overall Steps per Second: 10,713.08303

Timestep Collection Time: 2.17054
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.66812

Cumulative Model Updates: 84,562
Cumulative Timesteps: 705,320,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 705320932...
Checkpoint 705320932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.25114
Policy Entropy: 3.24378
Value Function Loss: 0.00446

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.55784
Value Function Update Magnitude: 0.62996

Collected Steps per Second: 22,866.52488
Overall Steps per Second: 10,775.09844

Timestep Collection Time: 2.18704
Timestep Consumption Time: 2.45422
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.64126

Cumulative Model Updates: 84,568
Cumulative Timesteps: 705,370,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.00204
Policy Entropy: 3.23845
Value Function Loss: 0.00462

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11169
Policy Update Magnitude: 0.55541
Value Function Update Magnitude: 0.62152

Collected Steps per Second: 22,994.31973
Overall Steps per Second: 10,667.58199

Timestep Collection Time: 2.17549
Timestep Consumption Time: 2.51385
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.68935

Cumulative Model Updates: 84,574
Cumulative Timesteps: 705,420,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 705420966...
Checkpoint 705420966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.25579
Policy Entropy: 3.23282
Value Function Loss: 0.00452

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.55099
Value Function Update Magnitude: 0.62404

Collected Steps per Second: 22,666.36214
Overall Steps per Second: 10,563.69144

Timestep Collection Time: 2.20715
Timestep Consumption Time: 2.52870
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.73584

Cumulative Model Updates: 84,580
Cumulative Timesteps: 705,470,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.38139
Policy Entropy: 3.23928
Value Function Loss: 0.00444

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.55353
Value Function Update Magnitude: 0.61807

Collected Steps per Second: 23,034.54164
Overall Steps per Second: 10,798.64795

Timestep Collection Time: 2.17187
Timestep Consumption Time: 2.46093
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.63280

Cumulative Model Updates: 84,586
Cumulative Timesteps: 705,521,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 705521022...
Checkpoint 705521022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.98571
Policy Entropy: 3.24207
Value Function Loss: 0.00428

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.55462
Value Function Update Magnitude: 0.62741

Collected Steps per Second: 22,250.97054
Overall Steps per Second: 10,650.26899

Timestep Collection Time: 2.24871
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.69810

Cumulative Model Updates: 84,592
Cumulative Timesteps: 705,571,058

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.24017
Policy Entropy: 3.24717
Value Function Loss: 0.00443

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.56059
Value Function Update Magnitude: 0.64621

Collected Steps per Second: 22,218.56371
Overall Steps per Second: 10,477.75148

Timestep Collection Time: 2.25046
Timestep Consumption Time: 2.52175
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.77221

Cumulative Model Updates: 84,598
Cumulative Timesteps: 705,621,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 705621060...
Checkpoint 705621060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.99265
Policy Entropy: 3.24824
Value Function Loss: 0.00429

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08149
Policy Update Magnitude: 0.56497
Value Function Update Magnitude: 0.66010

Collected Steps per Second: 22,066.42720
Overall Steps per Second: 10,604.95303

Timestep Collection Time: 2.26661
Timestep Consumption Time: 2.44968
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.71629

Cumulative Model Updates: 84,604
Cumulative Timesteps: 705,671,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.32218
Policy Entropy: 3.24153
Value Function Loss: 0.00438

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08280
Policy Update Magnitude: 0.56522
Value Function Update Magnitude: 0.65314

Collected Steps per Second: 22,103.92237
Overall Steps per Second: 10,487.93757

Timestep Collection Time: 2.26286
Timestep Consumption Time: 2.50624
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.76910

Cumulative Model Updates: 84,610
Cumulative Timesteps: 705,721,094

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 705721094...
Checkpoint 705721094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.14136
Policy Entropy: 3.23689
Value Function Loss: 0.00416

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.55938
Value Function Update Magnitude: 0.64333

Collected Steps per Second: 22,424.51094
Overall Steps per Second: 10,629.86848

Timestep Collection Time: 2.23068
Timestep Consumption Time: 2.47511
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.70580

Cumulative Model Updates: 84,616
Cumulative Timesteps: 705,771,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846.11765
Policy Entropy: 3.23387
Value Function Loss: 0.00423

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08351
Policy Update Magnitude: 0.55488
Value Function Update Magnitude: 0.64258

Collected Steps per Second: 22,808.48739
Overall Steps per Second: 10,670.94284

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.49355
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.68581

Cumulative Model Updates: 84,622
Cumulative Timesteps: 705,821,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 705821118...
Checkpoint 705821118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.82721
Policy Entropy: 3.21257
Value Function Loss: 0.00426

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.56196
Value Function Update Magnitude: 0.65312

Collected Steps per Second: 22,325.50185
Overall Steps per Second: 10,559.78023

Timestep Collection Time: 2.24076
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.73741

Cumulative Model Updates: 84,628
Cumulative Timesteps: 705,871,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.27928
Policy Entropy: 3.20231
Value Function Loss: 0.00445

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.67134

Collected Steps per Second: 22,868.65356
Overall Steps per Second: 10,753.64694

Timestep Collection Time: 2.18649
Timestep Consumption Time: 2.46328
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.64977

Cumulative Model Updates: 84,634
Cumulative Timesteps: 705,921,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 705921146...
Checkpoint 705921146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.18102
Policy Entropy: 3.21210
Value Function Loss: 0.00434

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.57548
Value Function Update Magnitude: 0.67390

Collected Steps per Second: 22,502.99779
Overall Steps per Second: 10,628.22441

Timestep Collection Time: 2.22264
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.70596

Cumulative Model Updates: 84,640
Cumulative Timesteps: 705,971,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.57129
Policy Entropy: 3.20981
Value Function Loss: 0.00439

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.56416
Value Function Update Magnitude: 0.66214

Collected Steps per Second: 22,905.49396
Overall Steps per Second: 10,683.08190

Timestep Collection Time: 2.18393
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.68254

Cumulative Model Updates: 84,646
Cumulative Timesteps: 706,021,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 706021186...
Checkpoint 706021186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.41743
Policy Entropy: 3.22872
Value Function Loss: 0.00423

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08016
Policy Update Magnitude: 0.55510
Value Function Update Magnitude: 0.64871

Collected Steps per Second: 22,494.17998
Overall Steps per Second: 10,653.02770

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.47080
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.69369

Cumulative Model Updates: 84,652
Cumulative Timesteps: 706,071,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.83913
Policy Entropy: 3.22380
Value Function Loss: 0.00435

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.55605
Value Function Update Magnitude: 0.63852

Collected Steps per Second: 22,387.20017
Overall Steps per Second: 10,684.01197

Timestep Collection Time: 2.23396
Timestep Consumption Time: 2.44706
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.68101

Cumulative Model Updates: 84,658
Cumulative Timesteps: 706,121,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 706121200...
Checkpoint 706121200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.81369
Policy Entropy: 3.24526
Value Function Loss: 0.00413

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.55643
Value Function Update Magnitude: 0.63563

Collected Steps per Second: 22,110.53393
Overall Steps per Second: 10,653.50735

Timestep Collection Time: 2.26209
Timestep Consumption Time: 2.43270
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.69479

Cumulative Model Updates: 84,664
Cumulative Timesteps: 706,171,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.07373
Policy Entropy: 3.23615
Value Function Loss: 0.00420

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.61279

Collected Steps per Second: 22,613.40005
Overall Steps per Second: 10,622.12543

Timestep Collection Time: 2.21214
Timestep Consumption Time: 2.49728
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.70942

Cumulative Model Updates: 84,670
Cumulative Timesteps: 706,221,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 706221240...
Checkpoint 706221240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.60353
Policy Entropy: 3.22359
Value Function Loss: 0.00435

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.55103
Value Function Update Magnitude: 0.60345

Collected Steps per Second: 22,445.85889
Overall Steps per Second: 10,546.31609

Timestep Collection Time: 2.22785
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.74156

Cumulative Model Updates: 84,676
Cumulative Timesteps: 706,271,246

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.62894
Policy Entropy: 3.20815
Value Function Loss: 0.00446

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12327
Policy Update Magnitude: 0.56067
Value Function Update Magnitude: 0.59602

Collected Steps per Second: 23,004.20278
Overall Steps per Second: 10,797.22941

Timestep Collection Time: 2.17378
Timestep Consumption Time: 2.45760
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.63137

Cumulative Model Updates: 84,682
Cumulative Timesteps: 706,321,252

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 706321252...
Checkpoint 706321252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.97320
Policy Entropy: 3.21349
Value Function Loss: 0.00443

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.12313
Policy Update Magnitude: 0.56647
Value Function Update Magnitude: 0.60471

Collected Steps per Second: 22,559.90136
Overall Steps per Second: 10,680.32144

Timestep Collection Time: 2.21641
Timestep Consumption Time: 2.46528
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.68169

Cumulative Model Updates: 84,688
Cumulative Timesteps: 706,371,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.29075
Policy Entropy: 3.21926
Value Function Loss: 0.00454

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.56759
Value Function Update Magnitude: 0.61429

Collected Steps per Second: 22,898.10841
Overall Steps per Second: 10,831.19936

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.61722

Cumulative Model Updates: 84,694
Cumulative Timesteps: 706,421,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 706421264...
Checkpoint 706421264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.14385
Policy Entropy: 3.23046
Value Function Loss: 0.00445

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.61452

Collected Steps per Second: 22,580.31908
Overall Steps per Second: 10,647.21185

Timestep Collection Time: 2.21494
Timestep Consumption Time: 2.48244
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.69738

Cumulative Model Updates: 84,700
Cumulative Timesteps: 706,471,278

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.16025
Policy Entropy: 3.21686
Value Function Loss: 0.00440

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10793
Policy Update Magnitude: 0.56122
Value Function Update Magnitude: 0.61283

Collected Steps per Second: 22,837.43796
Overall Steps per Second: 10,694.87612

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.48635
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.67626

Cumulative Model Updates: 84,706
Cumulative Timesteps: 706,521,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 706521290...
Checkpoint 706521290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.53210
Policy Entropy: 3.22021
Value Function Loss: 0.00420

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.55929
Value Function Update Magnitude: 0.59967

Collected Steps per Second: 22,679.14251
Overall Steps per Second: 10,659.83946

Timestep Collection Time: 2.20529
Timestep Consumption Time: 2.48653
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.69182

Cumulative Model Updates: 84,712
Cumulative Timesteps: 706,571,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426.73902
Policy Entropy: 3.19815
Value Function Loss: 0.00423

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.55953
Value Function Update Magnitude: 0.59859

Collected Steps per Second: 22,648.33266
Overall Steps per Second: 10,732.84266

Timestep Collection Time: 2.20855
Timestep Consumption Time: 2.45191
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.66046

Cumulative Model Updates: 84,718
Cumulative Timesteps: 706,621,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 706621324...
Checkpoint 706621324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.92939
Policy Entropy: 3.20963
Value Function Loss: 0.00435

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08761
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.61279

Collected Steps per Second: 21,740.56998
Overall Steps per Second: 10,552.93389

Timestep Collection Time: 2.29994
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.73821

Cumulative Model Updates: 84,724
Cumulative Timesteps: 706,671,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.41661
Policy Entropy: 3.20188
Value Function Loss: 0.00476

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.57259
Value Function Update Magnitude: 0.63613

Collected Steps per Second: 22,513.53121
Overall Steps per Second: 10,869.79386

Timestep Collection Time: 2.22186
Timestep Consumption Time: 2.38006
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.60193

Cumulative Model Updates: 84,730
Cumulative Timesteps: 706,721,348

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 706721348...
Checkpoint 706721348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.09921
Policy Entropy: 3.21729
Value Function Loss: 0.00477

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08569
Policy Update Magnitude: 0.58360
Value Function Update Magnitude: 0.64037

Collected Steps per Second: 21,488.56259
Overall Steps per Second: 10,649.13914

Timestep Collection Time: 2.32784
Timestep Consumption Time: 2.36944
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.69728

Cumulative Model Updates: 84,736
Cumulative Timesteps: 706,771,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.68277
Policy Entropy: 3.22842
Value Function Loss: 0.00459

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.57727
Value Function Update Magnitude: 0.63960

Collected Steps per Second: 21,963.16641
Overall Steps per Second: 10,570.17149

Timestep Collection Time: 2.27790
Timestep Consumption Time: 2.45523
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.73313

Cumulative Model Updates: 84,742
Cumulative Timesteps: 706,821,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 706821400...
Checkpoint 706821400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,291.45488
Policy Entropy: 3.22223
Value Function Loss: 0.00429

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11038
Policy Update Magnitude: 0.56487
Value Function Update Magnitude: 0.63161

Collected Steps per Second: 22,115.32119
Overall Steps per Second: 10,625.67442

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.44569
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.70747

Cumulative Model Updates: 84,748
Cumulative Timesteps: 706,871,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.31065
Policy Entropy: 3.21703
Value Function Loss: 0.00444

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.56043
Value Function Update Magnitude: 0.62733

Collected Steps per Second: 22,743.78431
Overall Steps per Second: 10,558.15400

Timestep Collection Time: 2.19928
Timestep Consumption Time: 2.53829
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.73757

Cumulative Model Updates: 84,754
Cumulative Timesteps: 706,921,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 706921440...
Checkpoint 706921440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.56119
Policy Entropy: 3.21036
Value Function Loss: 0.00446

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.56661
Value Function Update Magnitude: 0.60872

Collected Steps per Second: 22,845.76586
Overall Steps per Second: 10,615.88547

Timestep Collection Time: 2.18868
Timestep Consumption Time: 2.52143
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.71011

Cumulative Model Updates: 84,760
Cumulative Timesteps: 706,971,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700.74105
Policy Entropy: 3.21955
Value Function Loss: 0.00449

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.57216
Value Function Update Magnitude: 0.60172

Collected Steps per Second: 23,145.43618
Overall Steps per Second: 10,884.72475

Timestep Collection Time: 2.16120
Timestep Consumption Time: 2.43441
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.59561

Cumulative Model Updates: 84,766
Cumulative Timesteps: 707,021,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 707021464...
Checkpoint 707021464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.81830
Policy Entropy: 3.22165
Value Function Loss: 0.00438

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.57049
Value Function Update Magnitude: 0.60496

Collected Steps per Second: 22,719.28596
Overall Steps per Second: 10,588.26715

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.52244
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.72410

Cumulative Model Updates: 84,772
Cumulative Timesteps: 707,071,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.55198
Policy Entropy: 3.22259
Value Function Loss: 0.00441

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.56983
Value Function Update Magnitude: 0.60523

Collected Steps per Second: 22,960.42034
Overall Steps per Second: 10,809.68440

Timestep Collection Time: 2.17792
Timestep Consumption Time: 2.44812
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.62604

Cumulative Model Updates: 84,778
Cumulative Timesteps: 707,121,490

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 707121490...
Checkpoint 707121490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.54532
Policy Entropy: 3.23018
Value Function Loss: 0.00427

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.57263
Value Function Update Magnitude: 0.60883

Collected Steps per Second: 22,529.92154
Overall Steps per Second: 10,661.94781

Timestep Collection Time: 2.21998
Timestep Consumption Time: 2.47109
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.69108

Cumulative Model Updates: 84,784
Cumulative Timesteps: 707,171,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.33696
Policy Entropy: 3.24074
Value Function Loss: 0.00414

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.56787
Value Function Update Magnitude: 0.61174

Collected Steps per Second: 22,265.62954
Overall Steps per Second: 10,540.43915

Timestep Collection Time: 2.24606
Timestep Consumption Time: 2.49852
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.74458

Cumulative Model Updates: 84,790
Cumulative Timesteps: 707,221,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 707221516...
Checkpoint 707221516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.93538
Policy Entropy: 3.24907
Value Function Loss: 0.00418

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.55972
Value Function Update Magnitude: 0.60130

Collected Steps per Second: 22,031.26132
Overall Steps per Second: 10,619.09236

Timestep Collection Time: 2.26987
Timestep Consumption Time: 2.43939
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.70925

Cumulative Model Updates: 84,796
Cumulative Timesteps: 707,271,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.56025
Policy Entropy: 3.25153
Value Function Loss: 0.00456

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.55937
Value Function Update Magnitude: 0.61336

Collected Steps per Second: 22,643.83046
Overall Steps per Second: 10,549.15791

Timestep Collection Time: 2.20820
Timestep Consumption Time: 2.53171
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.73990

Cumulative Model Updates: 84,802
Cumulative Timesteps: 707,321,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 707321526...
Checkpoint 707321526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.03423
Policy Entropy: 3.25425
Value Function Loss: 0.00447

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.56529
Value Function Update Magnitude: 0.65366

Collected Steps per Second: 22,812.61359
Overall Steps per Second: 10,561.02233

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.54404
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.73704

Cumulative Model Updates: 84,808
Cumulative Timesteps: 707,371,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.60657
Policy Entropy: 3.23857
Value Function Loss: 0.00444

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.65655

Collected Steps per Second: 23,013.80934
Overall Steps per Second: 10,804.76599

Timestep Collection Time: 2.17270
Timestep Consumption Time: 2.45508
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.62777

Cumulative Model Updates: 84,814
Cumulative Timesteps: 707,421,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 707421556...
Checkpoint 707421556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743.60600
Policy Entropy: 3.24457
Value Function Loss: 0.00435

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08634
Policy Update Magnitude: 0.55809
Value Function Update Magnitude: 0.64959

Collected Steps per Second: 22,866.06416
Overall Steps per Second: 10,718.13107

Timestep Collection Time: 2.18700
Timestep Consumption Time: 2.47874
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.66574

Cumulative Model Updates: 84,820
Cumulative Timesteps: 707,471,564

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.34154
Policy Entropy: 3.24641
Value Function Loss: 0.00417

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.63570

Collected Steps per Second: 21,988.75421
Overall Steps per Second: 10,614.93884

Timestep Collection Time: 2.27434
Timestep Consumption Time: 2.43694
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.71128

Cumulative Model Updates: 84,826
Cumulative Timesteps: 707,521,574

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 707521574...
Checkpoint 707521574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.17551
Policy Entropy: 3.25873
Value Function Loss: 0.00416

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08454
Policy Update Magnitude: 0.54787
Value Function Update Magnitude: 0.63077

Collected Steps per Second: 22,045.35898
Overall Steps per Second: 10,631.98739

Timestep Collection Time: 2.26941
Timestep Consumption Time: 2.43620
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.70561

Cumulative Model Updates: 84,832
Cumulative Timesteps: 707,571,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.48693
Policy Entropy: 3.25078
Value Function Loss: 0.00428

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.55223
Value Function Update Magnitude: 0.63218

Collected Steps per Second: 22,220.69139
Overall Steps per Second: 10,826.74196

Timestep Collection Time: 2.25151
Timestep Consumption Time: 2.36946
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.62097

Cumulative Model Updates: 84,838
Cumulative Timesteps: 707,621,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 707621634...
Checkpoint 707621634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.09159
Policy Entropy: 3.23426
Value Function Loss: 0.00435

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.55362
Value Function Update Magnitude: 0.64325

Collected Steps per Second: 21,784.54821
Overall Steps per Second: 10,595.17316

Timestep Collection Time: 2.29612
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.72102

Cumulative Model Updates: 84,844
Cumulative Timesteps: 707,671,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.39241
Policy Entropy: 3.23890
Value Function Loss: 0.00430

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.55094
Value Function Update Magnitude: 0.62369

Collected Steps per Second: 22,693.74571
Overall Steps per Second: 10,625.09698

Timestep Collection Time: 2.20351
Timestep Consumption Time: 2.50289
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.70640

Cumulative Model Updates: 84,850
Cumulative Timesteps: 707,721,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 707721660...
Checkpoint 707721660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676.94557
Policy Entropy: 3.25321
Value Function Loss: 0.00423

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.54787
Value Function Update Magnitude: 0.61942

Collected Steps per Second: 22,366.80423
Overall Steps per Second: 10,506.93294

Timestep Collection Time: 2.23644
Timestep Consumption Time: 2.52442
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.76086

Cumulative Model Updates: 84,856
Cumulative Timesteps: 707,771,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.75094
Policy Entropy: 3.26014
Value Function Loss: 0.00418

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.55129
Value Function Update Magnitude: 0.63268

Collected Steps per Second: 22,927.31211
Overall Steps per Second: 10,766.11881

Timestep Collection Time: 2.18098
Timestep Consumption Time: 2.46359
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.64457

Cumulative Model Updates: 84,862
Cumulative Timesteps: 707,821,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 707821686...
Checkpoint 707821686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.16125
Policy Entropy: 3.24908
Value Function Loss: 0.00434

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.55163
Value Function Update Magnitude: 0.64963

Collected Steps per Second: 22,177.47775
Overall Steps per Second: 10,519.75261

Timestep Collection Time: 2.25463
Timestep Consumption Time: 2.49852
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.75315

Cumulative Model Updates: 84,868
Cumulative Timesteps: 707,871,688

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.26644
Policy Entropy: 3.25677
Value Function Loss: 0.00423

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.55090
Value Function Update Magnitude: 0.65858

Collected Steps per Second: 22,909.72787
Overall Steps per Second: 10,682.95379

Timestep Collection Time: 2.18257
Timestep Consumption Time: 2.49797
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.68054

Cumulative Model Updates: 84,874
Cumulative Timesteps: 707,921,690

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 707921690...
Checkpoint 707921690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.23172
Policy Entropy: 3.24800
Value Function Loss: 0.00433

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.54659
Value Function Update Magnitude: 0.64379

Collected Steps per Second: 22,841.11265
Overall Steps per Second: 10,627.02935

Timestep Collection Time: 2.19044
Timestep Consumption Time: 2.51756
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.70799

Cumulative Model Updates: 84,880
Cumulative Timesteps: 707,971,722

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.18658
Policy Entropy: 3.24548
Value Function Loss: 0.00440

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.62846

Collected Steps per Second: 22,863.36000
Overall Steps per Second: 10,613.86985

Timestep Collection Time: 2.18787
Timestep Consumption Time: 2.52502
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.71289

Cumulative Model Updates: 84,886
Cumulative Timesteps: 708,021,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 708021744...
Checkpoint 708021744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.43379
Policy Entropy: 3.23936
Value Function Loss: 0.00454

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.55632
Value Function Update Magnitude: 0.64326

Collected Steps per Second: 22,958.71658
Overall Steps per Second: 10,664.87311

Timestep Collection Time: 2.17861
Timestep Consumption Time: 2.51137
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.68998

Cumulative Model Updates: 84,892
Cumulative Timesteps: 708,071,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.79499
Policy Entropy: 3.24154
Value Function Loss: 0.00453

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.64919

Collected Steps per Second: 22,839.50930
Overall Steps per Second: 10,740.15154

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.46742
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.65766

Cumulative Model Updates: 84,898
Cumulative Timesteps: 708,121,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 708121786...
Checkpoint 708121786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.68471
Policy Entropy: 3.24233
Value Function Loss: 0.00426

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.62939

Collected Steps per Second: 22,529.64692
Overall Steps per Second: 10,623.59748

Timestep Collection Time: 2.21956
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.70707

Cumulative Model Updates: 84,904
Cumulative Timesteps: 708,171,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.17902
Policy Entropy: 3.25035
Value Function Loss: 0.00419

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.55580
Value Function Update Magnitude: 0.62522

Collected Steps per Second: 23,094.78632
Overall Steps per Second: 10,841.79369

Timestep Collection Time: 2.16594
Timestep Consumption Time: 2.44787
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.61381

Cumulative Model Updates: 84,910
Cumulative Timesteps: 708,221,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 708221814...
Checkpoint 708221814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.99884
Policy Entropy: 3.25469
Value Function Loss: 0.00400

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09088
Policy Update Magnitude: 0.54343
Value Function Update Magnitude: 0.59627

Collected Steps per Second: 21,768.45470
Overall Steps per Second: 10,423.87174

Timestep Collection Time: 2.29718
Timestep Consumption Time: 2.50008
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.79726

Cumulative Model Updates: 84,916
Cumulative Timesteps: 708,271,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.69930
Policy Entropy: 3.24267
Value Function Loss: 0.00423

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.54360
Value Function Update Magnitude: 0.57566

Collected Steps per Second: 22,801.73426
Overall Steps per Second: 10,732.58119

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.46619
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.65927

Cumulative Model Updates: 84,922
Cumulative Timesteps: 708,321,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 708321826...
Checkpoint 708321826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 828.69862
Policy Entropy: 3.23194
Value Function Loss: 0.00441

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.59672

Collected Steps per Second: 21,903.09492
Overall Steps per Second: 10,351.10226

Timestep Collection Time: 2.28424
Timestep Consumption Time: 2.54925
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.83349

Cumulative Model Updates: 84,928
Cumulative Timesteps: 708,371,858

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.64361
Policy Entropy: 3.23101
Value Function Loss: 0.00420

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08553
Policy Update Magnitude: 0.54714
Value Function Update Magnitude: 0.61275

Collected Steps per Second: 22,719.97975
Overall Steps per Second: 10,694.98542

Timestep Collection Time: 2.20106
Timestep Consumption Time: 2.47478
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.67584

Cumulative Model Updates: 84,934
Cumulative Timesteps: 708,421,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 708421866...
Checkpoint 708421866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.51614
Policy Entropy: 3.24331
Value Function Loss: 0.00420

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.54410
Value Function Update Magnitude: 0.61283

Collected Steps per Second: 22,084.05728
Overall Steps per Second: 10,634.36772

Timestep Collection Time: 2.26462
Timestep Consumption Time: 2.43825
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.70287

Cumulative Model Updates: 84,940
Cumulative Timesteps: 708,471,878

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.24046
Policy Entropy: 3.25057
Value Function Loss: 0.00418

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.07991
Policy Update Magnitude: 0.54660
Value Function Update Magnitude: 0.63217

Collected Steps per Second: 22,608.40789
Overall Steps per Second: 10,513.97715

Timestep Collection Time: 2.21254
Timestep Consumption Time: 2.54513
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.75767

Cumulative Model Updates: 84,946
Cumulative Timesteps: 708,521,900

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 708521900...
Checkpoint 708521900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.35544
Policy Entropy: 3.24955
Value Function Loss: 0.00440

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08038
Policy Update Magnitude: 0.55838
Value Function Update Magnitude: 0.64317

Collected Steps per Second: 22,705.25550
Overall Steps per Second: 10,645.13175

Timestep Collection Time: 2.20354
Timestep Consumption Time: 2.49645
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.69999

Cumulative Model Updates: 84,952
Cumulative Timesteps: 708,571,932

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.84549
Policy Entropy: 3.25166
Value Function Loss: 0.00442

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.56517
Value Function Update Magnitude: 0.65542

Collected Steps per Second: 22,883.85633
Overall Steps per Second: 10,621.83632

Timestep Collection Time: 2.18582
Timestep Consumption Time: 2.52335
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.70917

Cumulative Model Updates: 84,958
Cumulative Timesteps: 708,621,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 708621952...
Checkpoint 708621952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.50721
Policy Entropy: 3.25405
Value Function Loss: 0.00431

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.56027
Value Function Update Magnitude: 0.64857

Collected Steps per Second: 22,815.71664
Overall Steps per Second: 10,644.41157

Timestep Collection Time: 2.19279
Timestep Consumption Time: 2.50733
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.70012

Cumulative Model Updates: 84,964
Cumulative Timesteps: 708,671,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.04563
Policy Entropy: 3.23679
Value Function Loss: 0.00440

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.55517
Value Function Update Magnitude: 0.65563

Collected Steps per Second: 22,918.19452
Overall Steps per Second: 10,806.85931

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.44629
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.62910

Cumulative Model Updates: 84,970
Cumulative Timesteps: 708,722,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 708722008...
Checkpoint 708722008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.39838
Policy Entropy: 3.21928
Value Function Loss: 0.00451

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.55870
Value Function Update Magnitude: 0.65530

Collected Steps per Second: 22,817.85234
Overall Steps per Second: 10,590.89214

Timestep Collection Time: 2.19127
Timestep Consumption Time: 2.52977
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.72104

Cumulative Model Updates: 84,976
Cumulative Timesteps: 708,772,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.42894
Policy Entropy: 3.22438
Value Function Loss: 0.00455

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.56804
Value Function Update Magnitude: 0.66060

Collected Steps per Second: 22,327.27758
Overall Steps per Second: 10,449.40573

Timestep Collection Time: 2.23977
Timestep Consumption Time: 2.54596
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.78573

Cumulative Model Updates: 84,982
Cumulative Timesteps: 708,822,016

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 708822016...
Checkpoint 708822016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.84748
Policy Entropy: 3.22377
Value Function Loss: 0.00456

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09983
Policy Update Magnitude: 0.56671
Value Function Update Magnitude: 0.65082

Collected Steps per Second: 22,487.35884
Overall Steps per Second: 10,644.98356

Timestep Collection Time: 2.22454
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.69930

Cumulative Model Updates: 84,988
Cumulative Timesteps: 708,872,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.96963
Policy Entropy: 3.25412
Value Function Loss: 0.00467

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.57177
Value Function Update Magnitude: 0.65878

Collected Steps per Second: 22,555.69505
Overall Steps per Second: 10,535.40893

Timestep Collection Time: 2.21807
Timestep Consumption Time: 2.53068
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.74875

Cumulative Model Updates: 84,994
Cumulative Timesteps: 708,922,070

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 708922070...
Checkpoint 708922070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.38385
Policy Entropy: 3.25682
Value Function Loss: 0.00451

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.57537
Value Function Update Magnitude: 0.67203

Collected Steps per Second: 22,355.67818
Overall Steps per Second: 10,559.00034

Timestep Collection Time: 2.23693
Timestep Consumption Time: 2.49913
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.73605

Cumulative Model Updates: 85,000
Cumulative Timesteps: 708,972,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.45175
Policy Entropy: 3.26744
Value Function Loss: 0.00446

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.57758
Value Function Update Magnitude: 0.68239

Collected Steps per Second: 22,178.40733
Overall Steps per Second: 10,437.71830

Timestep Collection Time: 2.25535
Timestep Consumption Time: 2.53689
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.79224

Cumulative Model Updates: 85,006
Cumulative Timesteps: 709,022,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 709022098...
Checkpoint 709022098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.76869
Policy Entropy: 3.26089
Value Function Loss: 0.00444

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.57984
Value Function Update Magnitude: 0.70765

Collected Steps per Second: 21,789.10634
Overall Steps per Second: 10,562.22308

Timestep Collection Time: 2.29537
Timestep Consumption Time: 2.43981
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.73518

Cumulative Model Updates: 85,012
Cumulative Timesteps: 709,072,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.96874
Policy Entropy: 3.23758
Value Function Loss: 0.00442

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11461
Policy Update Magnitude: 0.57348
Value Function Update Magnitude: 0.69560

Collected Steps per Second: 22,065.15954
Overall Steps per Second: 10,519.00258

Timestep Collection Time: 2.26692
Timestep Consumption Time: 2.48828
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.75520

Cumulative Model Updates: 85,018
Cumulative Timesteps: 709,122,132

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 709122132...
Checkpoint 709122132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.66688
Policy Entropy: 3.22667
Value Function Loss: 0.00438

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.57280
Value Function Update Magnitude: 0.66291

Collected Steps per Second: 23,137.47599
Overall Steps per Second: 10,640.94339

Timestep Collection Time: 2.16100
Timestep Consumption Time: 2.53784
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.69883

Cumulative Model Updates: 85,024
Cumulative Timesteps: 709,172,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.81117
Policy Entropy: 3.22722
Value Function Loss: 0.00451

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.57131
Value Function Update Magnitude: 0.64024

Collected Steps per Second: 22,511.58575
Overall Steps per Second: 10,566.80520

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.51203
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.73426

Cumulative Model Updates: 85,030
Cumulative Timesteps: 709,222,158

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 709222158...
Checkpoint 709222158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.88202
Policy Entropy: 3.25609
Value Function Loss: 0.00424

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.56076
Value Function Update Magnitude: 0.63344

Collected Steps per Second: 22,914.26354
Overall Steps per Second: 10,587.49574

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.54162
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.72463

Cumulative Model Updates: 85,036
Cumulative Timesteps: 709,272,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.47022
Policy Entropy: 3.25944
Value Function Loss: 0.00417

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10905
Policy Update Magnitude: 0.54635
Value Function Update Magnitude: 0.62034

Collected Steps per Second: 22,508.28451
Overall Steps per Second: 10,534.28570

Timestep Collection Time: 2.22140
Timestep Consumption Time: 2.52500
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.74641

Cumulative Model Updates: 85,042
Cumulative Timesteps: 709,322,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 709322180...
Checkpoint 709322180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.31625
Policy Entropy: 3.25936
Value Function Loss: 0.00401

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11654
Policy Update Magnitude: 0.53353
Value Function Update Magnitude: 0.60915

Collected Steps per Second: 22,897.56772
Overall Steps per Second: 10,605.93114

Timestep Collection Time: 2.18451
Timestep Consumption Time: 2.53172
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.71623

Cumulative Model Updates: 85,048
Cumulative Timesteps: 709,372,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.75593
Policy Entropy: 3.26112
Value Function Loss: 0.00419

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.54270
Value Function Update Magnitude: 0.61266

Collected Steps per Second: 22,841.89448
Overall Steps per Second: 10,827.40827

Timestep Collection Time: 2.18957
Timestep Consumption Time: 2.42963
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.61920

Cumulative Model Updates: 85,054
Cumulative Timesteps: 709,422,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 709422214...
Checkpoint 709422214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563.80692
Policy Entropy: 3.25729
Value Function Loss: 0.00441

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.55321
Value Function Update Magnitude: 0.62288

Collected Steps per Second: 22,754.31952
Overall Steps per Second: 10,643.51850

Timestep Collection Time: 2.19897
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.70108

Cumulative Model Updates: 85,060
Cumulative Timesteps: 709,472,250

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.14104
Policy Entropy: 3.23094
Value Function Loss: 0.00473

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.56805
Value Function Update Magnitude: 0.63103

Collected Steps per Second: 21,984.79816
Overall Steps per Second: 10,424.82115

Timestep Collection Time: 2.27494
Timestep Consumption Time: 2.52265
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.79759

Cumulative Model Updates: 85,066
Cumulative Timesteps: 709,522,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 709522264...
Checkpoint 709522264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 665.40974
Policy Entropy: 3.23134
Value Function Loss: 0.00486

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10466
Policy Update Magnitude: 0.57454
Value Function Update Magnitude: 0.65629

Collected Steps per Second: 22,378.92601
Overall Steps per Second: 10,741.60869

Timestep Collection Time: 2.23496
Timestep Consumption Time: 2.42133
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.65629

Cumulative Model Updates: 85,072
Cumulative Timesteps: 709,572,280

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.94344
Policy Entropy: 3.23790
Value Function Loss: 0.00479

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.57355
Value Function Update Magnitude: 0.67219

Collected Steps per Second: 22,392.02588
Overall Steps per Second: 10,540.68923

Timestep Collection Time: 2.23419
Timestep Consumption Time: 2.51199
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.74618

Cumulative Model Updates: 85,078
Cumulative Timesteps: 709,622,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 709622308...
Checkpoint 709622308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.24011
Policy Entropy: 3.25389
Value Function Loss: 0.00441

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.55869
Value Function Update Magnitude: 0.66365

Collected Steps per Second: 22,562.72984
Overall Steps per Second: 10,661.83193

Timestep Collection Time: 2.21666
Timestep Consumption Time: 2.47427
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.69094

Cumulative Model Updates: 85,084
Cumulative Timesteps: 709,672,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,848.76893
Policy Entropy: 3.23679
Value Function Loss: 0.00445

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09322
Policy Update Magnitude: 0.55031
Value Function Update Magnitude: 0.68890

Collected Steps per Second: 22,860.40210
Overall Steps per Second: 10,715.05048

Timestep Collection Time: 2.18736
Timestep Consumption Time: 2.47934
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.66671

Cumulative Model Updates: 85,090
Cumulative Timesteps: 709,722,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 709722326...
Checkpoint 709722326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.74596
Policy Entropy: 3.23744
Value Function Loss: 0.00432

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.55510
Value Function Update Magnitude: 0.68474

Collected Steps per Second: 22,775.92322
Overall Steps per Second: 10,614.50938

Timestep Collection Time: 2.19609
Timestep Consumption Time: 2.51614
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.71223

Cumulative Model Updates: 85,096
Cumulative Timesteps: 709,772,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.46255
Policy Entropy: 3.22240
Value Function Loss: 0.00450

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11478
Policy Update Magnitude: 0.56912
Value Function Update Magnitude: 0.66059

Collected Steps per Second: 22,703.11995
Overall Steps per Second: 10,654.02995

Timestep Collection Time: 2.20340
Timestep Consumption Time: 2.49191
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.69531

Cumulative Model Updates: 85,102
Cumulative Timesteps: 709,822,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 709822368...
Checkpoint 709822368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.50659
Policy Entropy: 3.22224
Value Function Loss: 0.00442

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.55955
Value Function Update Magnitude: 0.64657

Collected Steps per Second: 22,932.33376
Overall Steps per Second: 10,848.44902

Timestep Collection Time: 2.18172
Timestep Consumption Time: 2.43018
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.61190

Cumulative Model Updates: 85,108
Cumulative Timesteps: 709,872,400

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.10307
Policy Entropy: 3.22535
Value Function Loss: 0.00448

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.64008

Collected Steps per Second: 22,689.98862
Overall Steps per Second: 10,648.28039

Timestep Collection Time: 2.20414
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.69672

Cumulative Model Updates: 85,114
Cumulative Timesteps: 709,922,412

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 709922412...
Checkpoint 709922412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.71733
Policy Entropy: 3.22355
Value Function Loss: 0.00445

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.56452
Value Function Update Magnitude: 0.64600

Collected Steps per Second: 22,815.06363
Overall Steps per Second: 10,687.96774

Timestep Collection Time: 2.19276
Timestep Consumption Time: 2.48802
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.68078

Cumulative Model Updates: 85,120
Cumulative Timesteps: 709,972,440

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.53697
Policy Entropy: 3.23370
Value Function Loss: 0.00435

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.56012
Value Function Update Magnitude: 0.63514

Collected Steps per Second: 22,308.68092
Overall Steps per Second: 10,699.27440

Timestep Collection Time: 2.24254
Timestep Consumption Time: 2.43330
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.67583

Cumulative Model Updates: 85,126
Cumulative Timesteps: 710,022,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 710022468...
Checkpoint 710022468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.64669
Policy Entropy: 3.24054
Value Function Loss: 0.00444

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.55717
Value Function Update Magnitude: 0.61687

Collected Steps per Second: 22,200.03856
Overall Steps per Second: 10,668.37834

Timestep Collection Time: 2.25261
Timestep Consumption Time: 2.43489
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.68750

Cumulative Model Updates: 85,132
Cumulative Timesteps: 710,072,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.57162
Policy Entropy: 3.25149
Value Function Loss: 0.00438

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11565
Policy Update Magnitude: 0.55380
Value Function Update Magnitude: 0.59974

Collected Steps per Second: 22,803.07307
Overall Steps per Second: 10,673.03034

Timestep Collection Time: 2.19365
Timestep Consumption Time: 2.49311
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.68677

Cumulative Model Updates: 85,138
Cumulative Timesteps: 710,122,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 710122498...
Checkpoint 710122498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.97155
Policy Entropy: 3.25884
Value Function Loss: 0.00442

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.53761
Value Function Update Magnitude: 0.59088

Collected Steps per Second: 22,389.51489
Overall Steps per Second: 10,548.63378

Timestep Collection Time: 2.23390
Timestep Consumption Time: 2.50756
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.74147

Cumulative Model Updates: 85,144
Cumulative Timesteps: 710,172,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.85650
Policy Entropy: 3.23441
Value Function Loss: 0.00437

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.53723
Value Function Update Magnitude: 0.61173

Collected Steps per Second: 22,759.69852
Overall Steps per Second: 10,757.57146

Timestep Collection Time: 2.19810
Timestep Consumption Time: 2.45240
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.65049

Cumulative Model Updates: 85,150
Cumulative Timesteps: 710,222,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 710222542...
Checkpoint 710222542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.73632
Policy Entropy: 3.24917
Value Function Loss: 0.00449

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.61201

Collected Steps per Second: 22,644.71345
Overall Steps per Second: 10,695.36648

Timestep Collection Time: 2.20855
Timestep Consumption Time: 2.46749
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.67604

Cumulative Model Updates: 85,156
Cumulative Timesteps: 710,272,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.63059
Policy Entropy: 3.26118
Value Function Loss: 0.00430

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.08239
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.62295

Collected Steps per Second: 23,023.04532
Overall Steps per Second: 10,824.01152

Timestep Collection Time: 2.17295
Timestep Consumption Time: 2.44899
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.62195

Cumulative Model Updates: 85,162
Cumulative Timesteps: 710,322,582

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 710322582...
Checkpoint 710322582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.00760
Policy Entropy: 3.26717
Value Function Loss: 0.00449

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.54271
Value Function Update Magnitude: 0.65075

Collected Steps per Second: 22,740.05269
Overall Steps per Second: 10,699.35012

Timestep Collection Time: 2.19964
Timestep Consumption Time: 2.47541
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.67505

Cumulative Model Updates: 85,168
Cumulative Timesteps: 710,372,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.74703
Policy Entropy: 3.26584
Value Function Loss: 0.00427

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.54669
Value Function Update Magnitude: 0.66021

Collected Steps per Second: 22,783.21729
Overall Steps per Second: 10,840.06775

Timestep Collection Time: 2.19495
Timestep Consumption Time: 2.41831
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.61326

Cumulative Model Updates: 85,174
Cumulative Timesteps: 710,422,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 710422610...
Checkpoint 710422610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.04163
Policy Entropy: 3.24977
Value Function Loss: 0.00430

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.55134
Value Function Update Magnitude: 0.64015

Collected Steps per Second: 22,729.36188
Overall Steps per Second: 10,720.99679

Timestep Collection Time: 2.20077
Timestep Consumption Time: 2.46503
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.66580

Cumulative Model Updates: 85,180
Cumulative Timesteps: 710,472,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.64232
Policy Entropy: 3.25987
Value Function Loss: 0.00406

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.54903
Value Function Update Magnitude: 0.63137

Collected Steps per Second: 22,494.19081
Overall Steps per Second: 10,640.26305

Timestep Collection Time: 2.22342
Timestep Consumption Time: 2.47703
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.70045

Cumulative Model Updates: 85,186
Cumulative Timesteps: 710,522,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 710522646...
Checkpoint 710522646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.22298
Policy Entropy: 3.25953
Value Function Loss: 0.00434

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.54623
Value Function Update Magnitude: 0.63884

Collected Steps per Second: 22,189.99029
Overall Steps per Second: 10,519.95782

Timestep Collection Time: 2.25408
Timestep Consumption Time: 2.50050
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.75458

Cumulative Model Updates: 85,192
Cumulative Timesteps: 710,572,664

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,812.06433
Policy Entropy: 3.26397
Value Function Loss: 0.00440

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.55225
Value Function Update Magnitude: 0.65865

Collected Steps per Second: 22,347.96659
Overall Steps per Second: 10,596.67754

Timestep Collection Time: 2.23761
Timestep Consumption Time: 2.48142
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.71903

Cumulative Model Updates: 85,198
Cumulative Timesteps: 710,622,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 710622670...
Checkpoint 710622670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.96981
Policy Entropy: 3.25227
Value Function Loss: 0.00442

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11060
Policy Update Magnitude: 0.55309
Value Function Update Magnitude: 0.65614

Collected Steps per Second: 22,390.58950
Overall Steps per Second: 10,614.19484

Timestep Collection Time: 2.23308
Timestep Consumption Time: 2.47759
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.71067

Cumulative Model Updates: 85,204
Cumulative Timesteps: 710,672,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.64099
Policy Entropy: 3.24745
Value Function Loss: 0.00434

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.55264
Value Function Update Magnitude: 0.63824

Collected Steps per Second: 22,728.83050
Overall Steps per Second: 10,691.79159

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.47693
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.67705

Cumulative Model Updates: 85,210
Cumulative Timesteps: 710,722,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 710722676...
Checkpoint 710722676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.79909
Policy Entropy: 3.26418
Value Function Loss: 0.00414

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08114
Policy Update Magnitude: 0.54750
Value Function Update Magnitude: 0.63847

Collected Steps per Second: 22,863.13509
Overall Steps per Second: 10,679.09493

Timestep Collection Time: 2.18798
Timestep Consumption Time: 2.49632
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.68429

Cumulative Model Updates: 85,216
Cumulative Timesteps: 710,772,700

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.05492
Policy Entropy: 3.26422
Value Function Loss: 0.00416

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.54106
Value Function Update Magnitude: 0.62350

Collected Steps per Second: 22,350.87249
Overall Steps per Second: 10,480.38471

Timestep Collection Time: 2.23723
Timestep Consumption Time: 2.53397
PPO Batch Consumption Time: 0.29706
Total Iteration Time: 4.77120

Cumulative Model Updates: 85,222
Cumulative Timesteps: 710,822,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 710822704...
Checkpoint 710822704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.34162
Policy Entropy: 3.25961
Value Function Loss: 0.00412

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.54014
Value Function Update Magnitude: 0.61451

Collected Steps per Second: 22,594.98170
Overall Steps per Second: 10,581.79052

Timestep Collection Time: 2.21377
Timestep Consumption Time: 2.51322
PPO Batch Consumption Time: 0.29796
Total Iteration Time: 4.72699

Cumulative Model Updates: 85,228
Cumulative Timesteps: 710,872,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 827.42043
Policy Entropy: 3.24514
Value Function Loss: 0.00442

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.54785
Value Function Update Magnitude: 0.61938

Collected Steps per Second: 22,897.98633
Overall Steps per Second: 10,908.03693

Timestep Collection Time: 2.18395
Timestep Consumption Time: 2.40056
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.58451

Cumulative Model Updates: 85,234
Cumulative Timesteps: 710,922,732

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 710922732...
Checkpoint 710922732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.05354
Policy Entropy: 3.25885
Value Function Loss: 0.00444

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11504
Policy Update Magnitude: 0.55204
Value Function Update Magnitude: 0.62309

Collected Steps per Second: 21,931.39184
Overall Steps per Second: 10,567.87921

Timestep Collection Time: 2.28075
Timestep Consumption Time: 2.45246
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.73321

Cumulative Model Updates: 85,240
Cumulative Timesteps: 710,972,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,709.70593
Policy Entropy: 3.24786
Value Function Loss: 0.00455

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.55583
Value Function Update Magnitude: 0.61696

Collected Steps per Second: 22,455.97537
Overall Steps per Second: 10,542.75211

Timestep Collection Time: 2.22720
Timestep Consumption Time: 2.51672
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.74392

Cumulative Model Updates: 85,246
Cumulative Timesteps: 711,022,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 711022766...
Checkpoint 711022766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.96712
Policy Entropy: 3.25156
Value Function Loss: 0.00446

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.60618

Collected Steps per Second: 22,886.75911
Overall Steps per Second: 10,861.68860

Timestep Collection Time: 2.18467
Timestep Consumption Time: 2.41867
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.60334

Cumulative Model Updates: 85,252
Cumulative Timesteps: 711,072,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.51043
Policy Entropy: 3.23661
Value Function Loss: 0.00439

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08110
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.59774

Collected Steps per Second: 22,036.15112
Overall Steps per Second: 10,669.44061

Timestep Collection Time: 2.26918
Timestep Consumption Time: 2.41748
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.68666

Cumulative Model Updates: 85,258
Cumulative Timesteps: 711,122,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 711122770...
Checkpoint 711122770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.34288
Policy Entropy: 3.24511
Value Function Loss: 0.00422

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08660
Policy Update Magnitude: 0.56285
Value Function Update Magnitude: 0.61815

Collected Steps per Second: 21,730.50533
Overall Steps per Second: 10,677.88564

Timestep Collection Time: 2.30193
Timestep Consumption Time: 2.38271
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.68464

Cumulative Model Updates: 85,264
Cumulative Timesteps: 711,172,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.35499
Policy Entropy: 3.23949
Value Function Loss: 0.00443

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.07480
Policy Update Magnitude: 0.56536
Value Function Update Magnitude: 0.64082

Collected Steps per Second: 21,742.95140
Overall Steps per Second: 10,535.03680

Timestep Collection Time: 2.30024
Timestep Consumption Time: 2.44716
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.74740

Cumulative Model Updates: 85,270
Cumulative Timesteps: 711,222,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 711222806...
Checkpoint 711222806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.60230
Policy Entropy: 3.24307
Value Function Loss: 0.00440

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.56863
Value Function Update Magnitude: 0.63877

Collected Steps per Second: 21,439.62703
Overall Steps per Second: 10,533.71045

Timestep Collection Time: 2.33353
Timestep Consumption Time: 2.41598
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.74951

Cumulative Model Updates: 85,276
Cumulative Timesteps: 711,272,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.39703
Policy Entropy: 3.24835
Value Function Loss: 0.00458

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09760
Policy Update Magnitude: 0.56005
Value Function Update Magnitude: 0.63340

Collected Steps per Second: 21,980.81389
Overall Steps per Second: 10,561.39837

Timestep Collection Time: 2.27580
Timestep Consumption Time: 2.46069
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.73649

Cumulative Model Updates: 85,282
Cumulative Timesteps: 711,322,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 711322860...
Checkpoint 711322860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.46061
Policy Entropy: 3.24112
Value Function Loss: 0.00442

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.55848
Value Function Update Magnitude: 0.62860

Collected Steps per Second: 22,191.65148
Overall Steps per Second: 10,596.15201

Timestep Collection Time: 2.25328
Timestep Consumption Time: 2.46579
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.71907

Cumulative Model Updates: 85,288
Cumulative Timesteps: 711,372,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.81968
Policy Entropy: 3.23351
Value Function Loss: 0.00426

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.55791
Value Function Update Magnitude: 0.63860

Collected Steps per Second: 22,094.32075
Overall Steps per Second: 10,744.90597

Timestep Collection Time: 2.26393
Timestep Consumption Time: 2.39130
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.65523

Cumulative Model Updates: 85,294
Cumulative Timesteps: 711,422,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 711422884...
Checkpoint 711422884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.89299
Policy Entropy: 3.24457
Value Function Loss: 0.00432

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08353
Policy Update Magnitude: 0.56636
Value Function Update Magnitude: 0.62683

Collected Steps per Second: 22,930.63574
Overall Steps per Second: 10,736.37733

Timestep Collection Time: 2.18119
Timestep Consumption Time: 2.47737
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.65855

Cumulative Model Updates: 85,300
Cumulative Timesteps: 711,472,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.05579
Policy Entropy: 3.24898
Value Function Loss: 0.00435

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.57280
Value Function Update Magnitude: 0.61448

Collected Steps per Second: 22,431.37986
Overall Steps per Second: 10,504.49641

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.53176
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.76158

Cumulative Model Updates: 85,306
Cumulative Timesteps: 711,522,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 711522918...
Checkpoint 711522918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.84648
Policy Entropy: 3.26828
Value Function Loss: 0.00473

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09685
Policy Update Magnitude: 0.56916
Value Function Update Magnitude: 0.61996

Collected Steps per Second: 23,194.14405
Overall Steps per Second: 10,717.95836

Timestep Collection Time: 2.15649
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.66675

Cumulative Model Updates: 85,312
Cumulative Timesteps: 711,572,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.59599
Policy Entropy: 3.27383
Value Function Loss: 0.00475

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.56921
Value Function Update Magnitude: 0.63173

Collected Steps per Second: 22,952.91522
Overall Steps per Second: 10,779.51334

Timestep Collection Time: 2.17855
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.63880

Cumulative Model Updates: 85,318
Cumulative Timesteps: 711,622,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 711622940...
Checkpoint 711622940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 839.44681
Policy Entropy: 3.27493
Value Function Loss: 0.00458

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.55729
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 22,220.84119
Overall Steps per Second: 10,624.41064

Timestep Collection Time: 2.25113
Timestep Consumption Time: 2.45708
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.70821

Cumulative Model Updates: 85,324
Cumulative Timesteps: 711,672,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.28653
Policy Entropy: 3.27006
Value Function Loss: 0.00444

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.55342
Value Function Update Magnitude: 0.65996

Collected Steps per Second: 22,449.80790
Overall Steps per Second: 10,497.21708

Timestep Collection Time: 2.22755
Timestep Consumption Time: 2.53638
PPO Batch Consumption Time: 0.29643
Total Iteration Time: 4.76393

Cumulative Model Updates: 85,330
Cumulative Timesteps: 711,722,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 711722970...
Checkpoint 711722970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.02613
Policy Entropy: 3.25265
Value Function Loss: 0.00438

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.55764
Value Function Update Magnitude: 0.67019

Collected Steps per Second: 22,235.46210
Overall Steps per Second: 10,642.51180

Timestep Collection Time: 2.24893
Timestep Consumption Time: 2.44977
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.69870

Cumulative Model Updates: 85,336
Cumulative Timesteps: 711,772,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.05387
Policy Entropy: 3.24222
Value Function Loss: 0.00439

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.65378

Collected Steps per Second: 22,588.28282
Overall Steps per Second: 10,577.23638

Timestep Collection Time: 2.21416
Timestep Consumption Time: 2.51430
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.72846

Cumulative Model Updates: 85,342
Cumulative Timesteps: 711,822,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 711822990...
Checkpoint 711822990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.20064
Policy Entropy: 3.23587
Value Function Loss: 0.00445

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.55779
Value Function Update Magnitude: 0.64276

Collected Steps per Second: 22,410.80937
Overall Steps per Second: 10,521.43555

Timestep Collection Time: 2.23205
Timestep Consumption Time: 2.52225
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.75429

Cumulative Model Updates: 85,348
Cumulative Timesteps: 711,873,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.97438
Policy Entropy: 3.24660
Value Function Loss: 0.00441

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08704
Policy Update Magnitude: 0.55650
Value Function Update Magnitude: 0.63089

Collected Steps per Second: 22,565.17502
Overall Steps per Second: 10,515.24755

Timestep Collection Time: 2.21642
Timestep Consumption Time: 2.53991
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.75633

Cumulative Model Updates: 85,354
Cumulative Timesteps: 711,923,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 711923026...
Checkpoint 711923026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693.42516
Policy Entropy: 3.25036
Value Function Loss: 0.00454

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08184
Policy Update Magnitude: 0.55406
Value Function Update Magnitude: 0.63480

Collected Steps per Second: 22,372.12632
Overall Steps per Second: 10,539.73537

Timestep Collection Time: 2.23519
Timestep Consumption Time: 2.50933
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.74452

Cumulative Model Updates: 85,360
Cumulative Timesteps: 711,973,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.47982
Policy Entropy: 3.26196
Value Function Loss: 0.00435

Mean KL Divergence: 0.00727
SB3 Clip Fraction: 0.07833
Policy Update Magnitude: 0.54556
Value Function Update Magnitude: 0.64360

Collected Steps per Second: 22,863.89172
Overall Steps per Second: 10,608.01863

Timestep Collection Time: 2.18720
Timestep Consumption Time: 2.52697
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.71417

Cumulative Model Updates: 85,366
Cumulative Timesteps: 712,023,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 712023040...
Checkpoint 712023040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,998.14677
Policy Entropy: 3.25504
Value Function Loss: 0.00442

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.54464
Value Function Update Magnitude: 0.62515

Collected Steps per Second: 22,573.43779
Overall Steps per Second: 10,533.78328

Timestep Collection Time: 2.21597
Timestep Consumption Time: 2.53275
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.74872

Cumulative Model Updates: 85,372
Cumulative Timesteps: 712,073,062

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.91271
Policy Entropy: 3.24220
Value Function Loss: 0.00439

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.64251

Collected Steps per Second: 22,811.97205
Overall Steps per Second: 10,738.45477

Timestep Collection Time: 2.19297
Timestep Consumption Time: 2.46561
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.65858

Cumulative Model Updates: 85,378
Cumulative Timesteps: 712,123,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 712123088...
Checkpoint 712123088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.52065
Policy Entropy: 3.25509
Value Function Loss: 0.00429

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.54915
Value Function Update Magnitude: 0.65155

Collected Steps per Second: 22,465.94549
Overall Steps per Second: 10,705.84249

Timestep Collection Time: 2.22586
Timestep Consumption Time: 2.44505
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.67091

Cumulative Model Updates: 85,384
Cumulative Timesteps: 712,173,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.79863
Policy Entropy: 3.25546
Value Function Loss: 0.00407

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.55058
Value Function Update Magnitude: 0.65759

Collected Steps per Second: 22,632.21853
Overall Steps per Second: 10,624.17371

Timestep Collection Time: 2.20950
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.70681

Cumulative Model Updates: 85,390
Cumulative Timesteps: 712,223,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 712223100...
Checkpoint 712223100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 956.78808
Policy Entropy: 3.26725
Value Function Loss: 0.00437

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.54764
Value Function Update Magnitude: 0.67547

Collected Steps per Second: 22,865.49933
Overall Steps per Second: 10,718.67676

Timestep Collection Time: 2.18766
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.66681

Cumulative Model Updates: 85,396
Cumulative Timesteps: 712,273,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.06669
Policy Entropy: 3.25973
Value Function Loss: 0.00435

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.54915
Value Function Update Magnitude: 0.68828

Collected Steps per Second: 22,645.63472
Overall Steps per Second: 10,703.10881

Timestep Collection Time: 2.20820
Timestep Consumption Time: 2.46390
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.67210

Cumulative Model Updates: 85,402
Cumulative Timesteps: 712,323,128

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 712323128...
Checkpoint 712323128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.94388
Policy Entropy: 3.26891
Value Function Loss: 0.00440

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.55497
Value Function Update Magnitude: 0.67949

Collected Steps per Second: 22,187.21805
Overall Steps per Second: 10,640.34424

Timestep Collection Time: 2.25427
Timestep Consumption Time: 2.44633
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.70060

Cumulative Model Updates: 85,408
Cumulative Timesteps: 712,373,144

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.48427
Policy Entropy: 3.26810
Value Function Loss: 0.00435

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.55026
Value Function Update Magnitude: 0.67489

Collected Steps per Second: 22,508.32865
Overall Steps per Second: 10,625.41022

Timestep Collection Time: 2.22149
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.70589

Cumulative Model Updates: 85,414
Cumulative Timesteps: 712,423,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 712423146...
Checkpoint 712423146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.46000
Policy Entropy: 3.26010
Value Function Loss: 0.00438

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.67522

Collected Steps per Second: 22,389.03158
Overall Steps per Second: 10,598.57479

Timestep Collection Time: 2.23449
Timestep Consumption Time: 2.48577
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.72026

Cumulative Model Updates: 85,420
Cumulative Timesteps: 712,473,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.43354
Policy Entropy: 3.26083
Value Function Loss: 0.00430

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.65478

Collected Steps per Second: 23,063.45050
Overall Steps per Second: 10,708.69835

Timestep Collection Time: 2.16828
Timestep Consumption Time: 2.50157
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.66985

Cumulative Model Updates: 85,426
Cumulative Timesteps: 712,523,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 712523182...
Checkpoint 712523182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.95289
Policy Entropy: 3.25596
Value Function Loss: 0.00426

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.64486

Collected Steps per Second: 22,548.46629
Overall Steps per Second: 10,636.75061

Timestep Collection Time: 2.21816
Timestep Consumption Time: 2.48403
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.70219

Cumulative Model Updates: 85,432
Cumulative Timesteps: 712,573,198

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.73069
Policy Entropy: 3.25242
Value Function Loss: 0.00410

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11470
Policy Update Magnitude: 0.54768
Value Function Update Magnitude: 0.64583

Collected Steps per Second: 22,291.22219
Overall Steps per Second: 10,519.58552

Timestep Collection Time: 2.24438
Timestep Consumption Time: 2.51151
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.75589

Cumulative Model Updates: 85,438
Cumulative Timesteps: 712,623,228

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 712623228...
Checkpoint 712623228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.93602
Policy Entropy: 3.24895
Value Function Loss: 0.00417

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.65991

Collected Steps per Second: 22,883.95163
Overall Steps per Second: 10,610.59725

Timestep Collection Time: 2.18572
Timestep Consumption Time: 2.52824
PPO Batch Consumption Time: 0.29458
Total Iteration Time: 4.71397

Cumulative Model Updates: 85,444
Cumulative Timesteps: 712,673,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.80124
Policy Entropy: 3.26330
Value Function Loss: 0.00407

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.55234
Value Function Update Magnitude: 0.68308

Collected Steps per Second: 22,858.70078
Overall Steps per Second: 10,604.73207

Timestep Collection Time: 2.18753
Timestep Consumption Time: 2.52773
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.71525

Cumulative Model Updates: 85,450
Cumulative Timesteps: 712,723,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 712723250...
Checkpoint 712723250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.53062
Policy Entropy: 3.26649
Value Function Loss: 0.00409

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.54841
Value Function Update Magnitude: 0.66344

Collected Steps per Second: 22,310.90371
Overall Steps per Second: 10,523.77375

Timestep Collection Time: 2.24150
Timestep Consumption Time: 2.51059
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 4.75210

Cumulative Model Updates: 85,456
Cumulative Timesteps: 712,773,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,688.06200
Policy Entropy: 3.24594
Value Function Loss: 0.00392

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.07963
Policy Update Magnitude: 0.53811
Value Function Update Magnitude: 0.63003

Collected Steps per Second: 22,920.32937
Overall Steps per Second: 10,825.59645

Timestep Collection Time: 2.18173
Timestep Consumption Time: 2.43751
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.61924

Cumulative Model Updates: 85,462
Cumulative Timesteps: 712,823,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 712823266...
Checkpoint 712823266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.27931
Policy Entropy: 3.23598
Value Function Loss: 0.00403

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.53413
Value Function Update Magnitude: 0.61484

Collected Steps per Second: 22,585.53023
Overall Steps per Second: 10,693.61759

Timestep Collection Time: 2.21452
Timestep Consumption Time: 2.46267
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.67718

Cumulative Model Updates: 85,468
Cumulative Timesteps: 712,873,282

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.19204
Policy Entropy: 3.23977
Value Function Loss: 0.00404

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.53365
Value Function Update Magnitude: 0.61618

Collected Steps per Second: 22,298.18279
Overall Steps per Second: 10,539.57802

Timestep Collection Time: 2.24359
Timestep Consumption Time: 2.50309
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.74668

Cumulative Model Updates: 85,474
Cumulative Timesteps: 712,923,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 712923310...
Checkpoint 712923310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,101.39472
Policy Entropy: 3.26636
Value Function Loss: 0.00404

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08638
Policy Update Magnitude: 0.53439
Value Function Update Magnitude: 0.61117

Collected Steps per Second: 22,230.03081
Overall Steps per Second: 10,580.12042

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.47713
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.72679

Cumulative Model Updates: 85,480
Cumulative Timesteps: 712,973,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.53143
Policy Entropy: 3.26552
Value Function Loss: 0.00422

Mean KL Divergence: 0.00732
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.53670
Value Function Update Magnitude: 0.61677

Collected Steps per Second: 22,648.57432
Overall Steps per Second: 10,647.37433

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.48875
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.69674

Cumulative Model Updates: 85,486
Cumulative Timesteps: 713,023,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 713023328...
Checkpoint 713023328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.42411
Policy Entropy: 3.24582
Value Function Loss: 0.00430

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08296
Policy Update Magnitude: 0.54723
Value Function Update Magnitude: 0.61398

Collected Steps per Second: 22,417.33808
Overall Steps per Second: 10,603.23405

Timestep Collection Time: 2.23113
Timestep Consumption Time: 2.48592
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.71705

Cumulative Model Updates: 85,492
Cumulative Timesteps: 713,073,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.95391
Policy Entropy: 3.22978
Value Function Loss: 0.00437

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.55502
Value Function Update Magnitude: 0.62367

Collected Steps per Second: 22,646.49030
Overall Steps per Second: 10,719.02561

Timestep Collection Time: 2.20891
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.66684

Cumulative Model Updates: 85,498
Cumulative Timesteps: 713,123,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 713123368...
Checkpoint 713123368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.15336
Policy Entropy: 3.22908
Value Function Loss: 0.00430

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.55793
Value Function Update Magnitude: 0.62581

Collected Steps per Second: 22,767.17513
Overall Steps per Second: 10,682.51664

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.48480
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.68129

Cumulative Model Updates: 85,504
Cumulative Timesteps: 713,173,376

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.81736
Policy Entropy: 3.25030
Value Function Loss: 0.00409

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.62159

Collected Steps per Second: 22,873.73706
Overall Steps per Second: 10,787.47372

Timestep Collection Time: 2.18679
Timestep Consumption Time: 2.45007
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.63686

Cumulative Model Updates: 85,510
Cumulative Timesteps: 713,223,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 713223396...
Checkpoint 713223396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.28465
Policy Entropy: 3.25566
Value Function Loss: 0.00417

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08803
Policy Update Magnitude: 0.54238
Value Function Update Magnitude: 0.63006

Collected Steps per Second: 22,930.20660
Overall Steps per Second: 10,739.44356

Timestep Collection Time: 2.18114
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.65704

Cumulative Model Updates: 85,516
Cumulative Timesteps: 713,273,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.35497
Policy Entropy: 3.26662
Value Function Loss: 0.00408

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.53995
Value Function Update Magnitude: 0.61896

Collected Steps per Second: 22,886.50193
Overall Steps per Second: 10,681.41526

Timestep Collection Time: 2.18504
Timestep Consumption Time: 2.49673
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.68178

Cumulative Model Updates: 85,522
Cumulative Timesteps: 713,323,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 713323418...
Checkpoint 713323418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,724.25107
Policy Entropy: 3.26630
Value Function Loss: 0.00405

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08896
Policy Update Magnitude: 0.53652
Value Function Update Magnitude: 0.61065

Collected Steps per Second: 22,289.12643
Overall Steps per Second: 10,568.62824

Timestep Collection Time: 2.24450
Timestep Consumption Time: 2.48913
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.73363

Cumulative Model Updates: 85,528
Cumulative Timesteps: 713,373,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.91041
Policy Entropy: 3.27679
Value Function Loss: 0.00367

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08993
Policy Update Magnitude: 0.52538
Value Function Update Magnitude: 0.58952

Collected Steps per Second: 23,022.07626
Overall Steps per Second: 10,748.95859

Timestep Collection Time: 2.17261
Timestep Consumption Time: 2.48068
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.65329

Cumulative Model Updates: 85,534
Cumulative Timesteps: 713,423,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 713423464...
Checkpoint 713423464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,912.53326
Policy Entropy: 3.27849
Value Function Loss: 0.00371

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08236
Policy Update Magnitude: 0.52094
Value Function Update Magnitude: 0.58196

Collected Steps per Second: 22,261.40014
Overall Steps per Second: 10,583.73610

Timestep Collection Time: 2.24622
Timestep Consumption Time: 2.47839
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.72461

Cumulative Model Updates: 85,540
Cumulative Timesteps: 713,473,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.42346
Policy Entropy: 3.27659
Value Function Loss: 0.00379

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.07898
Policy Update Magnitude: 0.52639
Value Function Update Magnitude: 0.59878

Collected Steps per Second: 22,716.63539
Overall Steps per Second: 10,555.08929

Timestep Collection Time: 2.20129
Timestep Consumption Time: 2.53633
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.73762

Cumulative Model Updates: 85,546
Cumulative Timesteps: 713,523,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 713523474...
Checkpoint 713523474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.97978
Policy Entropy: 3.26736
Value Function Loss: 0.00392

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.60294

Collected Steps per Second: 21,942.25974
Overall Steps per Second: 10,570.01867

Timestep Collection Time: 2.27989
Timestep Consumption Time: 2.45293
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.73282

Cumulative Model Updates: 85,552
Cumulative Timesteps: 713,573,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.48445
Policy Entropy: 3.24923
Value Function Loss: 0.00431

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.55299
Value Function Update Magnitude: 0.60827

Collected Steps per Second: 22,297.34215
Overall Steps per Second: 10,487.09979

Timestep Collection Time: 2.24332
Timestep Consumption Time: 2.52635
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.76967

Cumulative Model Updates: 85,558
Cumulative Timesteps: 713,623,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 713623520...
Checkpoint 713623520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 849.83686
Policy Entropy: 3.25829
Value Function Loss: 0.00428

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.56676
Value Function Update Magnitude: 0.61155

Collected Steps per Second: 22,217.41095
Overall Steps per Second: 10,587.42584

Timestep Collection Time: 2.25166
Timestep Consumption Time: 2.47338
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.72504

Cumulative Model Updates: 85,564
Cumulative Timesteps: 713,673,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.47256
Policy Entropy: 3.26393
Value Function Loss: 0.00410

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.56160
Value Function Update Magnitude: 0.60420

Collected Steps per Second: 22,724.90887
Overall Steps per Second: 10,525.16627

Timestep Collection Time: 2.20076
Timestep Consumption Time: 2.55090
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.75166

Cumulative Model Updates: 85,570
Cumulative Timesteps: 713,723,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 713723558...
Checkpoint 713723558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.32397
Policy Entropy: 3.27251
Value Function Loss: 0.00405

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.55336
Value Function Update Magnitude: 0.59278

Collected Steps per Second: 22,717.30112
Overall Steps per Second: 10,629.86961

Timestep Collection Time: 2.20193
Timestep Consumption Time: 2.50386
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.70580

Cumulative Model Updates: 85,576
Cumulative Timesteps: 713,773,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 972.68429
Policy Entropy: 3.27317
Value Function Loss: 0.00386

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.59802

Collected Steps per Second: 22,728.92464
Overall Steps per Second: 10,590.31104

Timestep Collection Time: 2.19993
Timestep Consumption Time: 2.52156
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.72149

Cumulative Model Updates: 85,582
Cumulative Timesteps: 713,823,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 713823582...
Checkpoint 713823582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.34828
Policy Entropy: 3.26547
Value Function Loss: 0.00406

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08709
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.59112

Collected Steps per Second: 22,653.55343
Overall Steps per Second: 10,650.22473

Timestep Collection Time: 2.20813
Timestep Consumption Time: 2.48867
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.69680

Cumulative Model Updates: 85,588
Cumulative Timesteps: 713,873,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.60976
Policy Entropy: 3.26613
Value Function Loss: 0.00419

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08512
Policy Update Magnitude: 0.55393
Value Function Update Magnitude: 0.59382

Collected Steps per Second: 23,049.60683
Overall Steps per Second: 10,806.92864

Timestep Collection Time: 2.17036
Timestep Consumption Time: 2.45870
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.62907

Cumulative Model Updates: 85,594
Cumulative Timesteps: 713,923,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 713923630...
Checkpoint 713923630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.19048
Policy Entropy: 3.26625
Value Function Loss: 0.00409

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08146
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.58918

Collected Steps per Second: 22,580.63249
Overall Steps per Second: 10,536.55029

Timestep Collection Time: 2.21446
Timestep Consumption Time: 2.53130
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.74577

Cumulative Model Updates: 85,600
Cumulative Timesteps: 713,973,634

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.68750
Policy Entropy: 3.26550
Value Function Loss: 0.00413

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.55164
Value Function Update Magnitude: 0.59595

Collected Steps per Second: 22,986.94805
Overall Steps per Second: 10,860.38950

Timestep Collection Time: 2.17680
Timestep Consumption Time: 2.43058
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.60739

Cumulative Model Updates: 85,606
Cumulative Timesteps: 714,023,672

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 714023672...
Checkpoint 714023672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.62273
Policy Entropy: 3.26416
Value Function Loss: 0.00420

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.55385
Value Function Update Magnitude: 0.60127

Collected Steps per Second: 22,252.23569
Overall Steps per Second: 10,676.11557

Timestep Collection Time: 2.24795
Timestep Consumption Time: 2.43746
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.68541

Cumulative Model Updates: 85,612
Cumulative Timesteps: 714,073,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.81306
Policy Entropy: 3.25729
Value Function Loss: 0.00425

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.56278
Value Function Update Magnitude: 0.60108

Collected Steps per Second: 22,529.73668
Overall Steps per Second: 10,576.89932

Timestep Collection Time: 2.21973
Timestep Consumption Time: 2.50850
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.72823

Cumulative Model Updates: 85,618
Cumulative Timesteps: 714,123,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 714123704...
Checkpoint 714123704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.38230
Policy Entropy: 3.25454
Value Function Loss: 0.00420

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.56300
Value Function Update Magnitude: 0.60850

Collected Steps per Second: 21,882.10318
Overall Steps per Second: 10,640.84222

Timestep Collection Time: 2.28634
Timestep Consumption Time: 2.41535
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.70170

Cumulative Model Updates: 85,624
Cumulative Timesteps: 714,173,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.42002
Policy Entropy: 3.25271
Value Function Loss: 0.00422

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12196
Policy Update Magnitude: 0.56504
Value Function Update Magnitude: 0.62975

Collected Steps per Second: 22,538.86267
Overall Steps per Second: 10,621.05811

Timestep Collection Time: 2.22025
Timestep Consumption Time: 2.49133
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.71158

Cumulative Model Updates: 85,630
Cumulative Timesteps: 714,223,776

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 714223776...
Checkpoint 714223776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.70392
Policy Entropy: 3.24444
Value Function Loss: 0.00436

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.13912
Policy Update Magnitude: 0.57028
Value Function Update Magnitude: 0.62673

Collected Steps per Second: 22,642.67925
Overall Steps per Second: 10,773.92346

Timestep Collection Time: 2.20901
Timestep Consumption Time: 2.43349
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.64251

Cumulative Model Updates: 85,636
Cumulative Timesteps: 714,273,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.77548
Policy Entropy: 3.24319
Value Function Loss: 0.00431

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.55852
Value Function Update Magnitude: 0.63579

Collected Steps per Second: 22,898.78114
Overall Steps per Second: 10,569.68506

Timestep Collection Time: 2.18431
Timestep Consumption Time: 2.54790
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.73221

Cumulative Model Updates: 85,642
Cumulative Timesteps: 714,323,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 714323812...
Checkpoint 714323812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.51374
Policy Entropy: 3.25246
Value Function Loss: 0.00417

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.55666
Value Function Update Magnitude: 0.63399

Collected Steps per Second: 22,726.93408
Overall Steps per Second: 10,614.14863

Timestep Collection Time: 2.20126
Timestep Consumption Time: 2.51207
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.71333

Cumulative Model Updates: 85,648
Cumulative Timesteps: 714,373,840

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.48518
Policy Entropy: 3.24139
Value Function Loss: 0.00396

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.54655
Value Function Update Magnitude: 0.61144

Collected Steps per Second: 22,642.04069
Overall Steps per Second: 10,666.20651

Timestep Collection Time: 2.20908
Timestep Consumption Time: 2.48031
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.68939

Cumulative Model Updates: 85,654
Cumulative Timesteps: 714,423,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 714423858...
Checkpoint 714423858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,879.68738
Policy Entropy: 3.23764
Value Function Loss: 0.00423

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.55065
Value Function Update Magnitude: 0.60319

Collected Steps per Second: 23,144.62637
Overall Steps per Second: 10,804.35628

Timestep Collection Time: 2.16050
Timestep Consumption Time: 2.46763
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.62813

Cumulative Model Updates: 85,660
Cumulative Timesteps: 714,473,862

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.91438
Policy Entropy: 3.24462
Value Function Loss: 0.00422

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10807
Policy Update Magnitude: 0.55645
Value Function Update Magnitude: 0.61613

Collected Steps per Second: 22,836.27274
Overall Steps per Second: 10,723.08341

Timestep Collection Time: 2.19064
Timestep Consumption Time: 2.47462
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.66526

Cumulative Model Updates: 85,666
Cumulative Timesteps: 714,523,888

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 714523888...
Checkpoint 714523888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 718.30950
Policy Entropy: 3.25715
Value Function Loss: 0.00458

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.56247
Value Function Update Magnitude: 0.63326

Collected Steps per Second: 21,603.60117
Overall Steps per Second: 10,474.93119

Timestep Collection Time: 2.31545
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.77540

Cumulative Model Updates: 85,672
Cumulative Timesteps: 714,573,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.57553
Policy Entropy: 3.26530
Value Function Loss: 0.00423

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.56390
Value Function Update Magnitude: 0.63468

Collected Steps per Second: 22,436.18038
Overall Steps per Second: 10,598.14311

Timestep Collection Time: 2.22935
Timestep Consumption Time: 2.49016
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.71951

Cumulative Model Updates: 85,678
Cumulative Timesteps: 714,623,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 714623928...
Checkpoint 714623928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.61091
Policy Entropy: 3.26267
Value Function Loss: 0.00412

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09900
Policy Update Magnitude: 0.56053
Value Function Update Magnitude: 0.63380

Collected Steps per Second: 22,299.88780
Overall Steps per Second: 10,522.14554

Timestep Collection Time: 2.24315
Timestep Consumption Time: 2.51082
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.75397

Cumulative Model Updates: 85,684
Cumulative Timesteps: 714,673,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,655.30997
Policy Entropy: 3.26801
Value Function Loss: 0.00387

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.55776
Value Function Update Magnitude: 0.62519

Collected Steps per Second: 22,786.94101
Overall Steps per Second: 10,778.08732

Timestep Collection Time: 2.19520
Timestep Consumption Time: 2.44588
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.64108

Cumulative Model Updates: 85,690
Cumulative Timesteps: 714,723,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 714723972...
Checkpoint 714723972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.77930
Policy Entropy: 3.25920
Value Function Loss: 0.00396

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.54749
Value Function Update Magnitude: 0.61573

Collected Steps per Second: 22,571.50174
Overall Steps per Second: 10,670.78981

Timestep Collection Time: 2.21527
Timestep Consumption Time: 2.47060
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.68588

Cumulative Model Updates: 85,696
Cumulative Timesteps: 714,773,974

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.37435
Policy Entropy: 3.26283
Value Function Loss: 0.00416

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08437
Policy Update Magnitude: 0.54702
Value Function Update Magnitude: 0.60392

Collected Steps per Second: 22,563.06877
Overall Steps per Second: 10,498.78289

Timestep Collection Time: 2.21619
Timestep Consumption Time: 2.54665
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.76284

Cumulative Model Updates: 85,702
Cumulative Timesteps: 714,823,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 714823978...
Checkpoint 714823978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.61985
Policy Entropy: 3.27029
Value Function Loss: 0.00406

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.59355

Collected Steps per Second: 22,431.42147
Overall Steps per Second: 10,629.90126

Timestep Collection Time: 2.22928
Timestep Consumption Time: 2.47499
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.70428

Cumulative Model Updates: 85,708
Cumulative Timesteps: 714,873,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.14190
Policy Entropy: 3.28299
Value Function Loss: 0.00417

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09210
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.57795

Collected Steps per Second: 22,911.74654
Overall Steps per Second: 10,679.79753

Timestep Collection Time: 2.18342
Timestep Consumption Time: 2.50075
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.68417

Cumulative Model Updates: 85,714
Cumulative Timesteps: 714,924,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 714924010...
Checkpoint 714924010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.98906
Policy Entropy: 3.28966
Value Function Loss: 0.00417

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.54944
Value Function Update Magnitude: 0.58316

Collected Steps per Second: 22,380.35978
Overall Steps per Second: 10,599.69368

Timestep Collection Time: 2.23437
Timestep Consumption Time: 2.48331
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.71768

Cumulative Model Updates: 85,720
Cumulative Timesteps: 714,974,016

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.00601
Policy Entropy: 3.27703
Value Function Loss: 0.00428

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.58388

Collected Steps per Second: 23,020.88127
Overall Steps per Second: 10,779.88024

Timestep Collection Time: 2.17264
Timestep Consumption Time: 2.46712
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.63975

Cumulative Model Updates: 85,726
Cumulative Timesteps: 715,024,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 715024032...
Checkpoint 715024032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.12519
Policy Entropy: 3.26292
Value Function Loss: 0.00433

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.56680
Value Function Update Magnitude: 0.59571

Collected Steps per Second: 22,853.50986
Overall Steps per Second: 10,667.19249

Timestep Collection Time: 2.18820
Timestep Consumption Time: 2.49982
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.68802

Cumulative Model Updates: 85,732
Cumulative Timesteps: 715,074,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.83524
Policy Entropy: 3.24810
Value Function Loss: 0.00436

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08157
Policy Update Magnitude: 0.57159
Value Function Update Magnitude: 0.63163

Collected Steps per Second: 22,409.35214
Overall Steps per Second: 10,592.52801

Timestep Collection Time: 2.23193
Timestep Consumption Time: 2.48989
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.72182

Cumulative Model Updates: 85,738
Cumulative Timesteps: 715,124,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 715124056...
Checkpoint 715124056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.56297
Policy Entropy: 3.26810
Value Function Loss: 0.00414

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.65625

Collected Steps per Second: 22,219.61720
Overall Steps per Second: 10,517.77725

Timestep Collection Time: 2.25035
Timestep Consumption Time: 2.50369
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.75405

Cumulative Model Updates: 85,744
Cumulative Timesteps: 715,174,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.22089
Policy Entropy: 3.26049
Value Function Loss: 0.00413

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08285
Policy Update Magnitude: 0.55647
Value Function Update Magnitude: 0.64813

Collected Steps per Second: 22,815.31458
Overall Steps per Second: 10,801.04792

Timestep Collection Time: 2.19247
Timestep Consumption Time: 2.43874
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.63122

Cumulative Model Updates: 85,750
Cumulative Timesteps: 715,224,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 715224080...
Checkpoint 715224080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.24783
Policy Entropy: 3.28452
Value Function Loss: 0.00406

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.55933
Value Function Update Magnitude: 0.64297

Collected Steps per Second: 22,259.55927
Overall Steps per Second: 10,662.36381

Timestep Collection Time: 2.24757
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.69221

Cumulative Model Updates: 85,756
Cumulative Timesteps: 715,274,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.83171
Policy Entropy: 3.27828
Value Function Loss: 0.00427

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09484
Policy Update Magnitude: 0.56299
Value Function Update Magnitude: 0.65451

Collected Steps per Second: 22,742.35375
Overall Steps per Second: 10,576.78048

Timestep Collection Time: 2.19933
Timestep Consumption Time: 2.52971
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.72904

Cumulative Model Updates: 85,762
Cumulative Timesteps: 715,324,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 715324128...
Checkpoint 715324128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.65559
Policy Entropy: 3.28215
Value Function Loss: 0.00438

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.65509

Collected Steps per Second: 22,578.01089
Overall Steps per Second: 10,579.48607

Timestep Collection Time: 2.21534
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.72783

Cumulative Model Updates: 85,768
Cumulative Timesteps: 715,374,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.44511
Policy Entropy: 3.26695
Value Function Loss: 0.00444

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.56572
Value Function Update Magnitude: 0.66449

Collected Steps per Second: 23,002.86745
Overall Steps per Second: 10,815.00408

Timestep Collection Time: 2.17469
Timestep Consumption Time: 2.45074
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.62543

Cumulative Model Updates: 85,774
Cumulative Timesteps: 715,424,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 715424170...
Checkpoint 715424170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.17713
Policy Entropy: 3.26002
Value Function Loss: 0.00410

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.56573
Value Function Update Magnitude: 0.65282

Collected Steps per Second: 22,414.55649
Overall Steps per Second: 10,657.73149

Timestep Collection Time: 2.23212
Timestep Consumption Time: 2.46231
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.69443

Cumulative Model Updates: 85,780
Cumulative Timesteps: 715,474,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.37078
Policy Entropy: 3.26432
Value Function Loss: 0.00404

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.55191
Value Function Update Magnitude: 0.63172

Collected Steps per Second: 22,355.75437
Overall Steps per Second: 10,522.19273

Timestep Collection Time: 2.23781
Timestep Consumption Time: 2.51671
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.75452

Cumulative Model Updates: 85,786
Cumulative Timesteps: 715,524,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 715524230...
Checkpoint 715524230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.75167
Policy Entropy: 3.26502
Value Function Loss: 0.00393

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10251
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.61266

Collected Steps per Second: 22,788.07017
Overall Steps per Second: 10,595.29490

Timestep Collection Time: 2.19466
Timestep Consumption Time: 2.52555
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 4.72021

Cumulative Model Updates: 85,792
Cumulative Timesteps: 715,574,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.72758
Policy Entropy: 3.27162
Value Function Loss: 0.00427

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.55096
Value Function Update Magnitude: 0.61210

Collected Steps per Second: 22,748.70839
Overall Steps per Second: 10,698.89101

Timestep Collection Time: 2.19801
Timestep Consumption Time: 2.47555
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.67357

Cumulative Model Updates: 85,798
Cumulative Timesteps: 715,624,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 715624244...
Checkpoint 715624244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.02849
Policy Entropy: 3.26500
Value Function Loss: 0.00423

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08987
Policy Update Magnitude: 0.55608
Value Function Update Magnitude: 0.62981

Collected Steps per Second: 22,495.19904
Overall Steps per Second: 10,669.25882

Timestep Collection Time: 2.22279
Timestep Consumption Time: 2.46376
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.68655

Cumulative Model Updates: 85,804
Cumulative Timesteps: 715,674,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.14142
Policy Entropy: 3.26576
Value Function Loss: 0.00432

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08202
Policy Update Magnitude: 0.55647
Value Function Update Magnitude: 0.64041

Collected Steps per Second: 22,690.27717
Overall Steps per Second: 10,681.71158

Timestep Collection Time: 2.20438
Timestep Consumption Time: 2.47820
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.68258

Cumulative Model Updates: 85,810
Cumulative Timesteps: 715,724,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 715724264...
Checkpoint 715724264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.83016
Policy Entropy: 3.26782
Value Function Loss: 0.00435

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.64409

Collected Steps per Second: 22,188.28696
Overall Steps per Second: 10,615.52013

Timestep Collection Time: 2.25344
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.71008

Cumulative Model Updates: 85,816
Cumulative Timesteps: 715,774,264

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 917.30335
Policy Entropy: 3.26495
Value Function Loss: 0.00447

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.57067
Value Function Update Magnitude: 0.64382

Collected Steps per Second: 22,711.35152
Overall Steps per Second: 10,653.63756

Timestep Collection Time: 2.20189
Timestep Consumption Time: 2.49209
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.69398

Cumulative Model Updates: 85,822
Cumulative Timesteps: 715,824,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 715824272...
Checkpoint 715824272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,718.32573
Policy Entropy: 3.26288
Value Function Loss: 0.00446

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10215
Policy Update Magnitude: 0.58037
Value Function Update Magnitude: 0.63057

Collected Steps per Second: 22,745.41713
Overall Steps per Second: 10,637.48112

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.50372
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.70337

Cumulative Model Updates: 85,828
Cumulative Timesteps: 715,874,304

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.87021
Policy Entropy: 3.25588
Value Function Loss: 0.00431

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.56857
Value Function Update Magnitude: 0.62360

Collected Steps per Second: 22,467.82450
Overall Steps per Second: 10,688.23330

Timestep Collection Time: 2.22540
Timestep Consumption Time: 2.45264
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.67804

Cumulative Model Updates: 85,834
Cumulative Timesteps: 715,924,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 715924304...
Checkpoint 715924304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.27840
Policy Entropy: 3.26384
Value Function Loss: 0.00426

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.56193
Value Function Update Magnitude: 0.60152

Collected Steps per Second: 22,702.43084
Overall Steps per Second: 10,670.35763

Timestep Collection Time: 2.20302
Timestep Consumption Time: 2.48417
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.68719

Cumulative Model Updates: 85,840
Cumulative Timesteps: 715,974,318

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.85077
Policy Entropy: 3.24552
Value Function Loss: 0.00404

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.54598
Value Function Update Magnitude: 0.56611

Collected Steps per Second: 23,073.11312
Overall Steps per Second: 10,841.40997

Timestep Collection Time: 2.16720
Timestep Consumption Time: 2.44512
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.61232

Cumulative Model Updates: 85,846
Cumulative Timesteps: 716,024,322

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 716024322...
Checkpoint 716024322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.60657
Policy Entropy: 3.22735
Value Function Loss: 0.00427

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.53456
Value Function Update Magnitude: 0.56324

Collected Steps per Second: 22,478.47255
Overall Steps per Second: 10,688.93388

Timestep Collection Time: 2.22444
Timestep Consumption Time: 2.45348
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.67792

Cumulative Model Updates: 85,852
Cumulative Timesteps: 716,074,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.97173
Policy Entropy: 3.22979
Value Function Loss: 0.00418

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.54326
Value Function Update Magnitude: 0.57350

Collected Steps per Second: 22,793.46022
Overall Steps per Second: 10,645.33778

Timestep Collection Time: 2.19370
Timestep Consumption Time: 2.50338
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69708

Cumulative Model Updates: 85,858
Cumulative Timesteps: 716,124,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 716124326...
Checkpoint 716124326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.21859
Policy Entropy: 3.20448
Value Function Loss: 0.00440

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.59126

Collected Steps per Second: 22,402.83956
Overall Steps per Second: 10,633.42600

Timestep Collection Time: 2.23302
Timestep Consumption Time: 2.47158
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.70460

Cumulative Model Updates: 85,864
Cumulative Timesteps: 716,174,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.82150
Policy Entropy: 3.23302
Value Function Loss: 0.00445

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.55923
Value Function Update Magnitude: 0.60099

Collected Steps per Second: 22,632.49510
Overall Steps per Second: 10,751.79623

Timestep Collection Time: 2.20948
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.65094

Cumulative Model Updates: 85,870
Cumulative Timesteps: 716,224,358

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 716224358...
Checkpoint 716224358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.86868
Policy Entropy: 3.23091
Value Function Loss: 0.00434

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.59886

Collected Steps per Second: 22,418.64885
Overall Steps per Second: 10,587.49579

Timestep Collection Time: 2.23216
Timestep Consumption Time: 2.49436
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.72652

Cumulative Model Updates: 85,876
Cumulative Timesteps: 716,274,400

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.80428
Policy Entropy: 3.24964
Value Function Loss: 0.00440

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.59556

Collected Steps per Second: 22,235.02008
Overall Steps per Second: 10,471.45697

Timestep Collection Time: 2.24933
Timestep Consumption Time: 2.52689
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.77622

Cumulative Model Updates: 85,882
Cumulative Timesteps: 716,324,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 716324414...
Checkpoint 716324414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.11712
Policy Entropy: 3.23958
Value Function Loss: 0.00429

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.57959

Collected Steps per Second: 22,467.73497
Overall Steps per Second: 10,646.47333

Timestep Collection Time: 2.22613
Timestep Consumption Time: 2.47177
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.69789

Cumulative Model Updates: 85,888
Cumulative Timesteps: 716,374,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.14033
Policy Entropy: 3.23447
Value Function Loss: 0.00420

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.55208
Value Function Update Magnitude: 0.57288

Collected Steps per Second: 22,763.93257
Overall Steps per Second: 10,583.11566

Timestep Collection Time: 2.19654
Timestep Consumption Time: 2.52815
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.72470

Cumulative Model Updates: 85,894
Cumulative Timesteps: 716,424,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 716424432...
Checkpoint 716424432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.93166
Policy Entropy: 3.24537
Value Function Loss: 0.00401

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 0.58577

Collected Steps per Second: 21,917.61757
Overall Steps per Second: 10,537.59183

Timestep Collection Time: 2.28209
Timestep Consumption Time: 2.46453
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.74663

Cumulative Model Updates: 85,900
Cumulative Timesteps: 716,474,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,597.36491
Policy Entropy: 3.23638
Value Function Loss: 0.00432

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.56465
Value Function Update Magnitude: 0.61442

Collected Steps per Second: 22,235.72536
Overall Steps per Second: 10,435.38480

Timestep Collection Time: 2.24935
Timestep Consumption Time: 2.54357
PPO Batch Consumption Time: 0.29768
Total Iteration Time: 4.79292

Cumulative Model Updates: 85,906
Cumulative Timesteps: 716,524,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 716524466...
Checkpoint 716524466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.14080
Policy Entropy: 3.24617
Value Function Loss: 0.00462

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.57573
Value Function Update Magnitude: 0.64485

Collected Steps per Second: 14,965.19126
Overall Steps per Second: 8,158.65823

Timestep Collection Time: 3.34109
Timestep Consumption Time: 2.78737
PPO Batch Consumption Time: 0.30206
Total Iteration Time: 6.12846

Cumulative Model Updates: 85,912
Cumulative Timesteps: 716,574,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.49954
Policy Entropy: 3.23596
Value Function Loss: 0.00464

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.57854
Value Function Update Magnitude: 0.63166

Collected Steps per Second: 17,924.60398
Overall Steps per Second: 9,592.19220

Timestep Collection Time: 2.79002
Timestep Consumption Time: 2.42360
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 5.21362

Cumulative Model Updates: 85,918
Cumulative Timesteps: 716,624,476

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 716624476...
Checkpoint 716624476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.49253
Policy Entropy: 3.22654
Value Function Loss: 0.00464

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09523
Policy Update Magnitude: 0.57568
Value Function Update Magnitude: 0.61525

Collected Steps per Second: 19,768.21061
Overall Steps per Second: 10,028.16148

Timestep Collection Time: 2.52931
Timestep Consumption Time: 2.45665
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.98596

Cumulative Model Updates: 85,924
Cumulative Timesteps: 716,674,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.77480
Policy Entropy: 3.21263
Value Function Loss: 0.00437

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.56782
Value Function Update Magnitude: 0.61989

Collected Steps per Second: 21,687.23910
Overall Steps per Second: 10,570.46909

Timestep Collection Time: 2.30624
Timestep Consumption Time: 2.42543
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.73167

Cumulative Model Updates: 85,930
Cumulative Timesteps: 716,724,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 716724492...
Checkpoint 716724492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.75852
Policy Entropy: 3.20575
Value Function Loss: 0.00444

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.56433
Value Function Update Magnitude: 0.61132

Collected Steps per Second: 21,829.64610
Overall Steps per Second: 10,595.94545

Timestep Collection Time: 2.29120
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.72030

Cumulative Model Updates: 85,936
Cumulative Timesteps: 716,774,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.27590
Policy Entropy: 3.22406
Value Function Loss: 0.00440

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.55918
Value Function Update Magnitude: 0.60049

Collected Steps per Second: 22,538.38188
Overall Steps per Second: 10,673.70382

Timestep Collection Time: 2.21897
Timestep Consumption Time: 2.46656
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.68553

Cumulative Model Updates: 85,942
Cumulative Timesteps: 716,824,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 716824520...
Checkpoint 716824520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.99413
Policy Entropy: 3.22107
Value Function Loss: 0.00444

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.60256

Collected Steps per Second: 21,838.36771
Overall Steps per Second: 10,684.86267

Timestep Collection Time: 2.29111
Timestep Consumption Time: 2.39159
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.68270

Cumulative Model Updates: 85,948
Cumulative Timesteps: 716,874,554

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.99860
Policy Entropy: 3.22234
Value Function Loss: 0.00452

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.56098
Value Function Update Magnitude: 0.60881

Collected Steps per Second: 22,846.86685
Overall Steps per Second: 10,653.73481

Timestep Collection Time: 2.18962
Timestep Consumption Time: 2.50601
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.69563

Cumulative Model Updates: 85,954
Cumulative Timesteps: 716,924,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 716924580...
Checkpoint 716924580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.42773
Policy Entropy: 3.22478
Value Function Loss: 0.00452

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09854
Policy Update Magnitude: 0.56330
Value Function Update Magnitude: 0.63106

Collected Steps per Second: 22,091.23141
Overall Steps per Second: 10,683.47138

Timestep Collection Time: 2.26452
Timestep Consumption Time: 2.41804
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.68256

Cumulative Model Updates: 85,960
Cumulative Timesteps: 716,974,606

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.75839
Policy Entropy: 3.20583
Value Function Loss: 0.00472

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.57098
Value Function Update Magnitude: 0.66639

Collected Steps per Second: 23,046.87818
Overall Steps per Second: 10,689.33202

Timestep Collection Time: 2.17088
Timestep Consumption Time: 2.50967
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.68055

Cumulative Model Updates: 85,966
Cumulative Timesteps: 717,024,638

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 717024638...
Checkpoint 717024638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.10789
Policy Entropy: 3.21203
Value Function Loss: 0.00473

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.58004
Value Function Update Magnitude: 0.67911

Collected Steps per Second: 22,978.73091
Overall Steps per Second: 10,619.44851

Timestep Collection Time: 2.17636
Timestep Consumption Time: 2.53292
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.70928

Cumulative Model Updates: 85,972
Cumulative Timesteps: 717,074,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.88922
Policy Entropy: 3.18834
Value Function Loss: 0.00476

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.58345
Value Function Update Magnitude: 0.68095

Collected Steps per Second: 22,534.95441
Overall Steps per Second: 10,509.19310

Timestep Collection Time: 2.21966
Timestep Consumption Time: 2.53998
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.75964

Cumulative Model Updates: 85,978
Cumulative Timesteps: 717,124,668

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 717124668...
Checkpoint 717124668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.31790
Policy Entropy: 3.18765
Value Function Loss: 0.00484

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.15211
Policy Update Magnitude: 0.58116
Value Function Update Magnitude: 0.66903

Collected Steps per Second: 22,331.73342
Overall Steps per Second: 10,607.78978

Timestep Collection Time: 2.23932
Timestep Consumption Time: 2.47495
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.71427

Cumulative Model Updates: 85,984
Cumulative Timesteps: 717,174,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,532.77916
Policy Entropy: 3.18949
Value Function Loss: 0.00453

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.57765
Value Function Update Magnitude: 0.66456

Collected Steps per Second: 22,325.55564
Overall Steps per Second: 10,459.22595

Timestep Collection Time: 2.23968
Timestep Consumption Time: 2.54098
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.78066

Cumulative Model Updates: 85,990
Cumulative Timesteps: 717,224,678

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 717224678...
Checkpoint 717224678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.58928
Policy Entropy: 3.19795
Value Function Loss: 0.00449

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.12380
Policy Update Magnitude: 0.56968
Value Function Update Magnitude: 0.64325

Collected Steps per Second: 22,326.30927
Overall Steps per Second: 10,607.77016

Timestep Collection Time: 2.23960
Timestep Consumption Time: 2.47411
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.71371

Cumulative Model Updates: 85,996
Cumulative Timesteps: 717,274,680

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.08518
Policy Entropy: 3.22092
Value Function Loss: 0.00435

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.56588
Value Function Update Magnitude: 0.61017

Collected Steps per Second: 22,001.46169
Overall Steps per Second: 10,477.21414

Timestep Collection Time: 2.27312
Timestep Consumption Time: 2.50028
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.77341

Cumulative Model Updates: 86,002
Cumulative Timesteps: 717,324,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 717324692...
Checkpoint 717324692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.24790
Policy Entropy: 3.22863
Value Function Loss: 0.00433

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.55136
Value Function Update Magnitude: 0.59577

Collected Steps per Second: 22,540.10404
Overall Steps per Second: 10,659.08452

Timestep Collection Time: 2.21862
Timestep Consumption Time: 2.47296
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.69158

Cumulative Model Updates: 86,008
Cumulative Timesteps: 717,374,700

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.84700
Policy Entropy: 3.23517
Value Function Loss: 0.00401

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.53950
Value Function Update Magnitude: 0.58553

Collected Steps per Second: 22,988.01986
Overall Steps per Second: 10,589.42366

Timestep Collection Time: 2.17635
Timestep Consumption Time: 2.54817
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.72453

Cumulative Model Updates: 86,014
Cumulative Timesteps: 717,424,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 717424730...
Checkpoint 717424730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.19879
Policy Entropy: 3.22755
Value Function Loss: 0.00384

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.52992
Value Function Update Magnitude: 0.58712

Collected Steps per Second: 22,741.51398
Overall Steps per Second: 10,621.92086

Timestep Collection Time: 2.19880
Timestep Consumption Time: 2.50882
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.70762

Cumulative Model Updates: 86,020
Cumulative Timesteps: 717,474,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.82281
Policy Entropy: 3.22442
Value Function Loss: 0.00386

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.53694
Value Function Update Magnitude: 0.59938

Collected Steps per Second: 22,895.56378
Overall Steps per Second: 10,742.36115

Timestep Collection Time: 2.18470
Timestep Consumption Time: 2.47163
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.65633

Cumulative Model Updates: 86,026
Cumulative Timesteps: 717,524,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 717524754...
Checkpoint 717524754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 873.14218
Policy Entropy: 3.24066
Value Function Loss: 0.00394

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07694
Policy Update Magnitude: 0.54164
Value Function Update Magnitude: 0.60742

Collected Steps per Second: 22,836.68646
Overall Steps per Second: 10,711.40148

Timestep Collection Time: 2.19025
Timestep Consumption Time: 2.47936
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.66960

Cumulative Model Updates: 86,032
Cumulative Timesteps: 717,574,772

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,240.31171
Policy Entropy: 3.23527
Value Function Loss: 0.00398

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.07727
Policy Update Magnitude: 0.53981
Value Function Update Magnitude: 0.61238

Collected Steps per Second: 22,194.53860
Overall Steps per Second: 10,777.83065

Timestep Collection Time: 2.25308
Timestep Consumption Time: 2.38663
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.63971

Cumulative Model Updates: 86,038
Cumulative Timesteps: 717,624,778

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 717624778...
Checkpoint 717624778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.21012
Policy Entropy: 3.22980
Value Function Loss: 0.00399

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.60324

Collected Steps per Second: 22,672.54391
Overall Steps per Second: 10,747.50891

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.44742
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.65317

Cumulative Model Updates: 86,044
Cumulative Timesteps: 717,674,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.96271
Policy Entropy: 3.22298
Value Function Loss: 0.00404

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.54371
Value Function Update Magnitude: 0.60519

Collected Steps per Second: 22,594.64199
Overall Steps per Second: 10,588.74493

Timestep Collection Time: 2.21442
Timestep Consumption Time: 2.51079
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.72521

Cumulative Model Updates: 86,050
Cumulative Timesteps: 717,724,822

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 717724822...
Checkpoint 717724822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.08369
Policy Entropy: 3.23690
Value Function Loss: 0.00411

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11306
Policy Update Magnitude: 0.54169
Value Function Update Magnitude: 0.61239

Collected Steps per Second: 22,478.33637
Overall Steps per Second: 10,503.03440

Timestep Collection Time: 2.22472
Timestep Consumption Time: 2.53657
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.76129

Cumulative Model Updates: 86,056
Cumulative Timesteps: 717,774,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 730.14001
Policy Entropy: 3.22951
Value Function Loss: 0.00425

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11031
Policy Update Magnitude: 0.54409
Value Function Update Magnitude: 0.62153

Collected Steps per Second: 22,004.14874
Overall Steps per Second: 10,444.31654

Timestep Collection Time: 2.27303
Timestep Consumption Time: 2.51580
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.78882

Cumulative Model Updates: 86,062
Cumulative Timesteps: 717,824,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 717824846...
Checkpoint 717824846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.45699
Policy Entropy: 3.23279
Value Function Loss: 0.00440

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.55625
Value Function Update Magnitude: 0.63213

Collected Steps per Second: 22,275.92766
Overall Steps per Second: 10,619.04415

Timestep Collection Time: 2.24476
Timestep Consumption Time: 2.46414
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.70890

Cumulative Model Updates: 86,068
Cumulative Timesteps: 717,874,850

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 964.69963
Policy Entropy: 3.23389
Value Function Loss: 0.00435

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.55581
Value Function Update Magnitude: 0.63265

Collected Steps per Second: 22,250.43621
Overall Steps per Second: 10,508.63403

Timestep Collection Time: 2.24751
Timestep Consumption Time: 2.51125
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.75875

Cumulative Model Updates: 86,074
Cumulative Timesteps: 717,924,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 717924858...
Checkpoint 717924858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.90464
Policy Entropy: 3.25260
Value Function Loss: 0.00425

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.54982
Value Function Update Magnitude: 0.62251

Collected Steps per Second: 22,331.10406
Overall Steps per Second: 10,662.88557

Timestep Collection Time: 2.24010
Timestep Consumption Time: 2.45131
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.69141

Cumulative Model Updates: 86,080
Cumulative Timesteps: 717,974,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.47253
Policy Entropy: 3.24947
Value Function Loss: 0.00417

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.54538
Value Function Update Magnitude: 0.60660

Collected Steps per Second: 23,073.51194
Overall Steps per Second: 10,635.85043

Timestep Collection Time: 2.16733
Timestep Consumption Time: 2.53450
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.70183

Cumulative Model Updates: 86,086
Cumulative Timesteps: 718,024,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 718024890...
Checkpoint 718024890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.79204
Policy Entropy: 3.22390
Value Function Loss: 0.00464

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.55517
Value Function Update Magnitude: 0.62184

Collected Steps per Second: 23,027.78533
Overall Steps per Second: 10,801.45407

Timestep Collection Time: 2.17129
Timestep Consumption Time: 2.45772
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.62901

Cumulative Model Updates: 86,092
Cumulative Timesteps: 718,074,890

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,903.33754
Policy Entropy: 3.22511
Value Function Loss: 0.00448

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.57134
Value Function Update Magnitude: 0.64279

Collected Steps per Second: 22,285.24526
Overall Steps per Second: 10,523.51810

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.50903
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.75392

Cumulative Model Updates: 86,098
Cumulative Timesteps: 718,124,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 718124918...
Checkpoint 718124918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.72182
Policy Entropy: 3.22141
Value Function Loss: 0.00439

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.62499

Collected Steps per Second: 22,827.30510
Overall Steps per Second: 10,640.77058

Timestep Collection Time: 2.19159
Timestep Consumption Time: 2.50995
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.70154

Cumulative Model Updates: 86,104
Cumulative Timesteps: 718,174,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.26063
Policy Entropy: 3.22720
Value Function Loss: 0.00431

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.54959
Value Function Update Magnitude: 0.59332

Collected Steps per Second: 22,845.04944
Overall Steps per Second: 10,652.63681

Timestep Collection Time: 2.18962
Timestep Consumption Time: 2.50612
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.69574

Cumulative Model Updates: 86,110
Cumulative Timesteps: 718,224,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 718224968...
Checkpoint 718224968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685.59222
Policy Entropy: 3.22578
Value Function Loss: 0.00440

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.55585
Value Function Update Magnitude: 0.59344

Collected Steps per Second: 23,018.62264
Overall Steps per Second: 10,818.41383

Timestep Collection Time: 2.17337
Timestep Consumption Time: 2.45097
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.62434

Cumulative Model Updates: 86,116
Cumulative Timesteps: 718,274,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 625.27668
Policy Entropy: 3.21004
Value Function Loss: 0.00440

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11502
Policy Update Magnitude: 0.56524
Value Function Update Magnitude: 0.62792

Collected Steps per Second: 22,575.88033
Overall Steps per Second: 10,516.35001

Timestep Collection Time: 2.21617
Timestep Consumption Time: 2.54137
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.75754

Cumulative Model Updates: 86,122
Cumulative Timesteps: 718,325,028

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 718325028...
Checkpoint 718325028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.03807
Policy Entropy: 3.21405
Value Function Loss: 0.00440

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.56452
Value Function Update Magnitude: 0.61825

Collected Steps per Second: 22,457.67152
Overall Steps per Second: 10,709.65408

Timestep Collection Time: 2.22721
Timestep Consumption Time: 2.44315
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.67037

Cumulative Model Updates: 86,128
Cumulative Timesteps: 718,375,046

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.39876
Policy Entropy: 3.22362
Value Function Loss: 0.00450

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.55883
Value Function Update Magnitude: 0.60695

Collected Steps per Second: 22,419.82619
Overall Steps per Second: 10,589.54852

Timestep Collection Time: 2.23097
Timestep Consumption Time: 2.49236
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.72334

Cumulative Model Updates: 86,134
Cumulative Timesteps: 718,425,064

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 718425064...
Checkpoint 718425064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.38225
Policy Entropy: 3.23218
Value Function Loss: 0.00445

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.59199

Collected Steps per Second: 22,306.85120
Overall Steps per Second: 10,475.52748

Timestep Collection Time: 2.24173
Timestep Consumption Time: 2.53187
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.77360

Cumulative Model Updates: 86,140
Cumulative Timesteps: 718,475,070

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.68096
Policy Entropy: 3.22540
Value Function Loss: 0.00451

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09738
Policy Update Magnitude: 0.56021
Value Function Update Magnitude: 0.60418

Collected Steps per Second: 22,124.80186
Overall Steps per Second: 10,405.44501

Timestep Collection Time: 2.26099
Timestep Consumption Time: 2.54649
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.80748

Cumulative Model Updates: 86,146
Cumulative Timesteps: 718,525,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 718525094...
Checkpoint 718525094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.78918
Policy Entropy: 3.22353
Value Function Loss: 0.00433

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.56027
Value Function Update Magnitude: 0.61862

Collected Steps per Second: 22,349.40941
Overall Steps per Second: 10,615.15423

Timestep Collection Time: 2.23854
Timestep Consumption Time: 2.47454
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.71307

Cumulative Model Updates: 86,152
Cumulative Timesteps: 718,575,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.68382
Policy Entropy: 3.21229
Value Function Loss: 0.00440

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.55652
Value Function Update Magnitude: 0.61135

Collected Steps per Second: 22,881.61928
Overall Steps per Second: 10,544.20070

Timestep Collection Time: 2.18603
Timestep Consumption Time: 2.55781
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.74384

Cumulative Model Updates: 86,158
Cumulative Timesteps: 718,625,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 718625144...
Checkpoint 718625144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.36236
Policy Entropy: 3.22354
Value Function Loss: 0.00430

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.55351
Value Function Update Magnitude: 0.62366

Collected Steps per Second: 22,841.02546
Overall Steps per Second: 10,591.56707

Timestep Collection Time: 2.19036
Timestep Consumption Time: 2.53321
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.72357

Cumulative Model Updates: 86,164
Cumulative Timesteps: 718,675,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.91106
Policy Entropy: 3.22952
Value Function Loss: 0.00443

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.55685
Value Function Update Magnitude: 0.64777

Collected Steps per Second: 22,781.93637
Overall Steps per Second: 10,647.07338

Timestep Collection Time: 2.19516
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.69707

Cumulative Model Updates: 86,170
Cumulative Timesteps: 718,725,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 718725184...
Checkpoint 718725184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.60230
Policy Entropy: 3.24769
Value Function Loss: 0.00436

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.65359

Collected Steps per Second: 22,716.84635
Overall Steps per Second: 10,648.49365

Timestep Collection Time: 2.20180
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.69719

Cumulative Model Updates: 86,176
Cumulative Timesteps: 718,775,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.86420
Policy Entropy: 3.24312
Value Function Loss: 0.00430

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08308
Policy Update Magnitude: 0.54973
Value Function Update Magnitude: 0.63100

Collected Steps per Second: 22,999.18324
Overall Steps per Second: 10,737.29950

Timestep Collection Time: 2.17495
Timestep Consumption Time: 2.48377
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.65871

Cumulative Model Updates: 86,182
Cumulative Timesteps: 718,825,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 718825224...
Checkpoint 718825224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.64321
Policy Entropy: 3.23490
Value Function Loss: 0.00446

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.55578
Value Function Update Magnitude: 0.63268

Collected Steps per Second: 22,923.35935
Overall Steps per Second: 10,590.65637

Timestep Collection Time: 2.18214
Timestep Consumption Time: 2.54108
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.72322

Cumulative Model Updates: 86,188
Cumulative Timesteps: 718,875,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.92666
Policy Entropy: 3.22021
Value Function Loss: 0.00457

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.65865

Collected Steps per Second: 22,767.66607
Overall Steps per Second: 10,618.99957

Timestep Collection Time: 2.19698
Timestep Consumption Time: 2.51345
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.71042

Cumulative Model Updates: 86,194
Cumulative Timesteps: 718,925,266

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 718925266...
Checkpoint 718925266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.60406
Policy Entropy: 3.21442
Value Function Loss: 0.00475

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.57615
Value Function Update Magnitude: 0.66192

Collected Steps per Second: 22,281.01390
Overall Steps per Second: 10,483.30786

Timestep Collection Time: 2.24514
Timestep Consumption Time: 2.52664
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.77178

Cumulative Model Updates: 86,200
Cumulative Timesteps: 718,975,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.05532
Policy Entropy: 3.19980
Value Function Loss: 0.00485

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11496
Policy Update Magnitude: 0.57691
Value Function Update Magnitude: 0.64349

Collected Steps per Second: 21,967.90534
Overall Steps per Second: 10,469.47188

Timestep Collection Time: 2.27696
Timestep Consumption Time: 2.50074
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.77770

Cumulative Model Updates: 86,206
Cumulative Timesteps: 719,025,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 719025310...
Checkpoint 719025310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.01041
Policy Entropy: 3.22164
Value Function Loss: 0.00447

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.56894
Value Function Update Magnitude: 0.61859

Collected Steps per Second: 21,892.76109
Overall Steps per Second: 10,517.27378

Timestep Collection Time: 2.28514
Timestep Consumption Time: 2.47161
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.75675

Cumulative Model Updates: 86,212
Cumulative Timesteps: 719,075,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.95639
Policy Entropy: 3.22346
Value Function Loss: 0.00404

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.55521
Value Function Update Magnitude: 0.60561

Collected Steps per Second: 22,748.06171
Overall Steps per Second: 10,601.49272

Timestep Collection Time: 2.19904
Timestep Consumption Time: 2.51954
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.71858

Cumulative Model Updates: 86,218
Cumulative Timesteps: 719,125,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 719125362...
Checkpoint 719125362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.12880
Policy Entropy: 3.22495
Value Function Loss: 0.00402

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08260
Policy Update Magnitude: 0.54826
Value Function Update Magnitude: 0.59338

Collected Steps per Second: 22,165.66712
Overall Steps per Second: 10,618.30834

Timestep Collection Time: 2.25691
Timestep Consumption Time: 2.45438
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.71130

Cumulative Model Updates: 86,224
Cumulative Timesteps: 719,175,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.91076
Policy Entropy: 3.21700
Value Function Loss: 0.00424

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08387
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.60511

Collected Steps per Second: 23,218.11786
Overall Steps per Second: 10,628.74515

Timestep Collection Time: 2.15401
Timestep Consumption Time: 2.55135
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.70535

Cumulative Model Updates: 86,230
Cumulative Timesteps: 719,225,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 719225400...
Checkpoint 719225400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.45734
Policy Entropy: 3.21185
Value Function Loss: 0.00458

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10235
Policy Update Magnitude: 0.56385
Value Function Update Magnitude: 0.61185

Collected Steps per Second: 22,946.88489
Overall Steps per Second: 10,673.17485

Timestep Collection Time: 2.17956
Timestep Consumption Time: 2.50640
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.68595

Cumulative Model Updates: 86,236
Cumulative Timesteps: 719,275,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.12045
Policy Entropy: 3.20779
Value Function Loss: 0.00453

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.61922

Collected Steps per Second: 23,176.38330
Overall Steps per Second: 10,700.48143

Timestep Collection Time: 2.15789
Timestep Consumption Time: 2.51592
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.67381

Cumulative Model Updates: 86,242
Cumulative Timesteps: 719,325,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 719325426...
Checkpoint 719325426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.76140
Policy Entropy: 3.20698
Value Function Loss: 0.00440

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.56446
Value Function Update Magnitude: 0.61382

Collected Steps per Second: 22,858.13431
Overall Steps per Second: 10,641.58524

Timestep Collection Time: 2.18784
Timestep Consumption Time: 2.51165
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.69949

Cumulative Model Updates: 86,248
Cumulative Timesteps: 719,375,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.53422
Policy Entropy: 3.21358
Value Function Loss: 0.00444

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.57183
Value Function Update Magnitude: 0.60500

Collected Steps per Second: 23,015.16413
Overall Steps per Second: 10,800.01242

Timestep Collection Time: 2.17309
Timestep Consumption Time: 2.45783
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.63092

Cumulative Model Updates: 86,254
Cumulative Timesteps: 719,425,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 719425450...
Checkpoint 719425450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.25067
Policy Entropy: 3.22778
Value Function Loss: 0.00436

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.56436
Value Function Update Magnitude: 0.62507

Collected Steps per Second: 22,632.84886
Overall Steps per Second: 10,699.99204

Timestep Collection Time: 2.20989
Timestep Consumption Time: 2.46451
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.67440

Cumulative Model Updates: 86,260
Cumulative Timesteps: 719,475,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 968.34071
Policy Entropy: 3.22258
Value Function Loss: 0.00436

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10898
Policy Update Magnitude: 0.56168
Value Function Update Magnitude: 0.64092

Collected Steps per Second: 22,999.74763
Overall Steps per Second: 10,685.29387

Timestep Collection Time: 2.17455
Timestep Consumption Time: 2.50609
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.68064

Cumulative Model Updates: 86,266
Cumulative Timesteps: 719,525,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 719525480...
Checkpoint 719525480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.75567
Policy Entropy: 3.24543
Value Function Loss: 0.00434

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.56115
Value Function Update Magnitude: 0.66139

Collected Steps per Second: 22,258.33690
Overall Steps per Second: 10,490.92336

Timestep Collection Time: 2.24698
Timestep Consumption Time: 2.52038
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.76736

Cumulative Model Updates: 86,272
Cumulative Timesteps: 719,575,494

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.68897
Policy Entropy: 3.25528
Value Function Loss: 0.00422

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.63971

Collected Steps per Second: 22,749.63665
Overall Steps per Second: 10,753.69393

Timestep Collection Time: 2.19784
Timestep Consumption Time: 2.45173
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.64957

Cumulative Model Updates: 86,278
Cumulative Timesteps: 719,625,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 719625494...
Checkpoint 719625494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.53954
Policy Entropy: 3.26275
Value Function Loss: 0.00433

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.55624
Value Function Update Magnitude: 0.62090

Collected Steps per Second: 22,180.78891
Overall Steps per Second: 10,516.30162

Timestep Collection Time: 2.25465
Timestep Consumption Time: 2.50082
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.75547

Cumulative Model Updates: 86,284
Cumulative Timesteps: 719,675,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.94609
Policy Entropy: 3.24535
Value Function Loss: 0.00443

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.55551
Value Function Update Magnitude: 0.63655

Collected Steps per Second: 22,759.44815
Overall Steps per Second: 10,712.56669

Timestep Collection Time: 2.19733
Timestep Consumption Time: 2.47102
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.66835

Cumulative Model Updates: 86,290
Cumulative Timesteps: 719,725,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 719725514...
Checkpoint 719725514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.21735
Policy Entropy: 3.24816
Value Function Loss: 0.00432

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.55390
Value Function Update Magnitude: 0.63911

Collected Steps per Second: 22,355.45650
Overall Steps per Second: 10,697.51781

Timestep Collection Time: 2.23740
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.67566

Cumulative Model Updates: 86,296
Cumulative Timesteps: 719,775,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.92864
Policy Entropy: 3.24571
Value Function Loss: 0.00419

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.62535

Collected Steps per Second: 22,934.96167
Overall Steps per Second: 10,707.12373

Timestep Collection Time: 2.18104
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.67184

Cumulative Model Updates: 86,302
Cumulative Timesteps: 719,825,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 719825554...
Checkpoint 719825554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.96963
Policy Entropy: 3.24171
Value Function Loss: 0.00418

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10404
Policy Update Magnitude: 0.54486
Value Function Update Magnitude: 0.61548

Collected Steps per Second: 22,583.85613
Overall Steps per Second: 10,677.01645

Timestep Collection Time: 2.21610
Timestep Consumption Time: 2.47136
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.68745

Cumulative Model Updates: 86,308
Cumulative Timesteps: 719,875,602

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.85496
Policy Entropy: 3.23655
Value Function Loss: 0.00413

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.54655
Value Function Update Magnitude: 0.60103

Collected Steps per Second: 22,949.19188
Overall Steps per Second: 10,597.31430

Timestep Collection Time: 2.17916
Timestep Consumption Time: 2.53996
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.71912

Cumulative Model Updates: 86,314
Cumulative Timesteps: 719,925,612

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 719925612...
Checkpoint 719925612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.11927
Policy Entropy: 3.23367
Value Function Loss: 0.00426

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.59703

Collected Steps per Second: 23,083.65755
Overall Steps per Second: 10,653.12235

Timestep Collection Time: 2.16612
Timestep Consumption Time: 2.52753
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.69365

Cumulative Model Updates: 86,320
Cumulative Timesteps: 719,975,614

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.82519
Policy Entropy: 3.21907
Value Function Loss: 0.00437

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08727
Policy Update Magnitude: 0.56596
Value Function Update Magnitude: 0.59129

Collected Steps per Second: 23,310.86653
Overall Steps per Second: 10,818.11362

Timestep Collection Time: 2.14518
Timestep Consumption Time: 2.47725
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.62243

Cumulative Model Updates: 86,326
Cumulative Timesteps: 720,025,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 720025620...
Checkpoint 720025620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.46314
Policy Entropy: 3.22396
Value Function Loss: 0.00460

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.57428
Value Function Update Magnitude: 0.59807

Collected Steps per Second: 22,764.15378
Overall Steps per Second: 10,648.50058

Timestep Collection Time: 2.19705
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.69681

Cumulative Model Updates: 86,332
Cumulative Timesteps: 720,075,634

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.07680
Policy Entropy: 3.22711
Value Function Loss: 0.00446

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.57299
Value Function Update Magnitude: 0.60901

Collected Steps per Second: 22,351.64524
Overall Steps per Second: 10,525.74727

Timestep Collection Time: 2.23822
Timestep Consumption Time: 2.51469
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.75292

Cumulative Model Updates: 86,338
Cumulative Timesteps: 720,125,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 720125662...
Checkpoint 720125662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.33657
Policy Entropy: 3.23692
Value Function Loss: 0.00440

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.56014
Value Function Update Magnitude: 0.60875

Collected Steps per Second: 22,394.28540
Overall Steps per Second: 10,577.47180

Timestep Collection Time: 2.23316
Timestep Consumption Time: 2.49481
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.72797

Cumulative Model Updates: 86,344
Cumulative Timesteps: 720,175,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.88829
Policy Entropy: 3.22202
Value Function Loss: 0.00443

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.55688
Value Function Update Magnitude: 0.61861

Collected Steps per Second: 22,698.89622
Overall Steps per Second: 10,499.01422

Timestep Collection Time: 2.20381
Timestep Consumption Time: 2.56083
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.76464

Cumulative Model Updates: 86,350
Cumulative Timesteps: 720,225,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 720225696...
Checkpoint 720225696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.00806
Policy Entropy: 3.22603
Value Function Loss: 0.00430

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.56316
Value Function Update Magnitude: 0.62695

Collected Steps per Second: 22,168.63671
Overall Steps per Second: 10,631.16250

Timestep Collection Time: 2.25571
Timestep Consumption Time: 2.44801
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.70372

Cumulative Model Updates: 86,356
Cumulative Timesteps: 720,275,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.07106
Policy Entropy: 3.24452
Value Function Loss: 0.00406

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.56183
Value Function Update Magnitude: 0.62402

Collected Steps per Second: 23,211.32873
Overall Steps per Second: 10,743.08793

Timestep Collection Time: 2.15447
Timestep Consumption Time: 2.50043
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.65490

Cumulative Model Updates: 86,362
Cumulative Timesteps: 720,325,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 720325710...
Checkpoint 720325710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.03823
Policy Entropy: 3.25022
Value Function Loss: 0.00387

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.55326
Value Function Update Magnitude: 0.60545

Collected Steps per Second: 22,277.41081
Overall Steps per Second: 10,644.51217

Timestep Collection Time: 2.24559
Timestep Consumption Time: 2.45411
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.69970

Cumulative Model Updates: 86,368
Cumulative Timesteps: 720,375,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.99097
Policy Entropy: 3.24053
Value Function Loss: 0.00393

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08154
Policy Update Magnitude: 0.55337
Value Function Update Magnitude: 0.59598

Collected Steps per Second: 22,867.37476
Overall Steps per Second: 10,564.70900

Timestep Collection Time: 2.18722
Timestep Consumption Time: 2.54703
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.73425

Cumulative Model Updates: 86,374
Cumulative Timesteps: 720,425,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 720425752...
Checkpoint 720425752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.10192
Policy Entropy: 3.23333
Value Function Loss: 0.00420

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 0.55942
Value Function Update Magnitude: 0.60196

Collected Steps per Second: 22,645.62054
Overall Steps per Second: 10,595.92142

Timestep Collection Time: 2.20829
Timestep Consumption Time: 2.51127
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.71955

Cumulative Model Updates: 86,380
Cumulative Timesteps: 720,475,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.73887
Policy Entropy: 3.23913
Value Function Loss: 0.00434

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.56339
Value Function Update Magnitude: 0.61126

Collected Steps per Second: 22,709.01931
Overall Steps per Second: 10,574.28153

Timestep Collection Time: 2.20283
Timestep Consumption Time: 2.52790
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.73072

Cumulative Model Updates: 86,386
Cumulative Timesteps: 720,525,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 720525784...
Checkpoint 720525784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.24676
Policy Entropy: 3.23222
Value Function Loss: 0.00439

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.55958
Value Function Update Magnitude: 0.61129

Collected Steps per Second: 22,969.06921
Overall Steps per Second: 10,619.74569

Timestep Collection Time: 2.17815
Timestep Consumption Time: 2.53289
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.71104

Cumulative Model Updates: 86,392
Cumulative Timesteps: 720,575,814

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.73619
Policy Entropy: 3.22884
Value Function Loss: 0.00437

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.55936
Value Function Update Magnitude: 0.62565

Collected Steps per Second: 23,043.19911
Overall Steps per Second: 10,801.55664

Timestep Collection Time: 2.16992
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.62915

Cumulative Model Updates: 86,398
Cumulative Timesteps: 720,625,816

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 720625816...
Checkpoint 720625816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.15032
Policy Entropy: 3.22105
Value Function Loss: 0.00435

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.56159
Value Function Update Magnitude: 0.63861

Collected Steps per Second: 21,967.73403
Overall Steps per Second: 10,431.49331

Timestep Collection Time: 2.27643
Timestep Consumption Time: 2.51751
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.79394

Cumulative Model Updates: 86,404
Cumulative Timesteps: 720,675,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.70374
Policy Entropy: 3.21412
Value Function Loss: 0.00424

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11564
Policy Update Magnitude: 0.55253
Value Function Update Magnitude: 0.63826

Collected Steps per Second: 22,841.05722
Overall Steps per Second: 10,777.00755

Timestep Collection Time: 2.18957
Timestep Consumption Time: 2.45105
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.64062

Cumulative Model Updates: 86,410
Cumulative Timesteps: 720,725,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 720725836...
Checkpoint 720725836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.35769
Policy Entropy: 3.18842
Value Function Loss: 0.00444

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.55250
Value Function Update Magnitude: 0.63355

Collected Steps per Second: 22,262.66120
Overall Steps per Second: 10,595.88628

Timestep Collection Time: 2.24618
Timestep Consumption Time: 2.47320
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.71938

Cumulative Model Updates: 86,416
Cumulative Timesteps: 720,775,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.67557
Policy Entropy: 3.20006
Value Function Loss: 0.00407

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.56026
Value Function Update Magnitude: 0.63623

Collected Steps per Second: 22,669.80430
Overall Steps per Second: 10,583.98002

Timestep Collection Time: 2.20655
Timestep Consumption Time: 2.51965
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.72620

Cumulative Model Updates: 86,422
Cumulative Timesteps: 720,825,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 720825864...
Checkpoint 720825864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.47284
Policy Entropy: 3.21959
Value Function Loss: 0.00420

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.55511
Value Function Update Magnitude: 0.61044

Collected Steps per Second: 22,367.41252
Overall Steps per Second: 10,500.42949

Timestep Collection Time: 2.23593
Timestep Consumption Time: 2.52692
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.76285

Cumulative Model Updates: 86,428
Cumulative Timesteps: 720,875,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.42211
Policy Entropy: 3.23400
Value Function Loss: 0.00419

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.54652
Value Function Update Magnitude: 0.58713

Collected Steps per Second: 23,105.20507
Overall Steps per Second: 10,673.98805

Timestep Collection Time: 2.16523
Timestep Consumption Time: 2.52168
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.68691

Cumulative Model Updates: 86,434
Cumulative Timesteps: 720,925,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 720925904...
Checkpoint 720925904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,964.83895
Policy Entropy: 3.23523
Value Function Loss: 0.00413

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.54424
Value Function Update Magnitude: 0.58513

Collected Steps per Second: 22,739.26256
Overall Steps per Second: 10,760.88768

Timestep Collection Time: 2.20016
Timestep Consumption Time: 2.44909
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.64924

Cumulative Model Updates: 86,440
Cumulative Timesteps: 720,975,934

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.15781
Policy Entropy: 3.23553
Value Function Loss: 0.00403

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07728
Policy Update Magnitude: 0.54667
Value Function Update Magnitude: 0.59272

Collected Steps per Second: 22,762.65609
Overall Steps per Second: 10,525.32807

Timestep Collection Time: 2.19781
Timestep Consumption Time: 2.55530
PPO Batch Consumption Time: 0.29849
Total Iteration Time: 4.75311

Cumulative Model Updates: 86,446
Cumulative Timesteps: 721,025,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 721025962...
Checkpoint 721025962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,520.68371
Policy Entropy: 3.23358
Value Function Loss: 0.00419

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.55661
Value Function Update Magnitude: 0.61627

Collected Steps per Second: 22,220.67104
Overall Steps per Second: 10,612.66191

Timestep Collection Time: 2.25061
Timestep Consumption Time: 2.46169
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.71230

Cumulative Model Updates: 86,452
Cumulative Timesteps: 721,075,972

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,483.77248
Policy Entropy: 3.20178
Value Function Loss: 0.00443

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.57203
Value Function Update Magnitude: 0.62616

Collected Steps per Second: 23,039.65202
Overall Steps per Second: 10,661.96065

Timestep Collection Time: 2.17061
Timestep Consumption Time: 2.51990
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.69051

Cumulative Model Updates: 86,458
Cumulative Timesteps: 721,125,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 721125982...
Checkpoint 721125982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.11903
Policy Entropy: 3.21564
Value Function Loss: 0.00441

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08561
Policy Update Magnitude: 0.57573
Value Function Update Magnitude: 0.62554

Collected Steps per Second: 22,992.21112
Overall Steps per Second: 10,721.85776

Timestep Collection Time: 2.17578
Timestep Consumption Time: 2.49002
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.66580

Cumulative Model Updates: 86,464
Cumulative Timesteps: 721,176,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.34310
Policy Entropy: 3.22451
Value Function Loss: 0.00446

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08402
Policy Update Magnitude: 0.56679
Value Function Update Magnitude: 0.62097

Collected Steps per Second: 22,951.51782
Overall Steps per Second: 10,688.79198

Timestep Collection Time: 2.17859
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.67798

Cumulative Model Updates: 86,470
Cumulative Timesteps: 721,226,010

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 721226010...
Checkpoint 721226010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.53854
Policy Entropy: 3.23584
Value Function Loss: 0.00428

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.56093
Value Function Update Magnitude: 0.60600

Collected Steps per Second: 21,885.77322
Overall Steps per Second: 10,530.68101

Timestep Collection Time: 2.28541
Timestep Consumption Time: 2.46433
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.74974

Cumulative Model Updates: 86,476
Cumulative Timesteps: 721,276,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.59162
Policy Entropy: 3.21840
Value Function Loss: 0.00427

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.55479
Value Function Update Magnitude: 0.60384

Collected Steps per Second: 22,182.17907
Overall Steps per Second: 10,553.72489

Timestep Collection Time: 2.25451
Timestep Consumption Time: 2.48410
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.73861

Cumulative Model Updates: 86,482
Cumulative Timesteps: 721,326,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 721326038...
Checkpoint 721326038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.88410
Policy Entropy: 3.20887
Value Function Loss: 0.00404

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.55043
Value Function Update Magnitude: 0.59728

Collected Steps per Second: 21,982.96544
Overall Steps per Second: 10,540.92633

Timestep Collection Time: 2.27540
Timestep Consumption Time: 2.46992
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.74531

Cumulative Model Updates: 86,488
Cumulative Timesteps: 721,376,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.78613
Policy Entropy: 3.21668
Value Function Loss: 0.00397

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.60559

Collected Steps per Second: 22,771.48365
Overall Steps per Second: 10,547.78172

Timestep Collection Time: 2.19696
Timestep Consumption Time: 2.54603
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.74299

Cumulative Model Updates: 86,494
Cumulative Timesteps: 721,426,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 721426086...
Checkpoint 721426086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.38459
Policy Entropy: 3.21555
Value Function Loss: 0.00397

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.54193
Value Function Update Magnitude: 0.60565

Collected Steps per Second: 21,652.97101
Overall Steps per Second: 10,366.66191

Timestep Collection Time: 2.31008
Timestep Consumption Time: 2.51501
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.82508

Cumulative Model Updates: 86,500
Cumulative Timesteps: 721,476,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.68156
Policy Entropy: 3.23279
Value Function Loss: 0.00401

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08518
Policy Update Magnitude: 0.54644
Value Function Update Magnitude: 0.59181

Collected Steps per Second: 23,065.74165
Overall Steps per Second: 10,707.33889

Timestep Collection Time: 2.16884
Timestep Consumption Time: 2.50328
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.67212

Cumulative Model Updates: 86,506
Cumulative Timesteps: 721,526,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 721526132...
Checkpoint 721526132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.27295
Policy Entropy: 3.24237
Value Function Loss: 0.00401

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.58296

Collected Steps per Second: 22,720.96711
Overall Steps per Second: 10,631.69898

Timestep Collection Time: 2.20114
Timestep Consumption Time: 2.50291
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.70405

Cumulative Model Updates: 86,512
Cumulative Timesteps: 721,576,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.36248
Policy Entropy: 3.24273
Value Function Loss: 0.00397

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.54159
Value Function Update Magnitude: 0.58974

Collected Steps per Second: 22,893.56220
Overall Steps per Second: 10,606.87669

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.52990
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.71392

Cumulative Model Updates: 86,518
Cumulative Timesteps: 721,626,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 721626144...
Checkpoint 721626144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.83687
Policy Entropy: 3.23390
Value Function Loss: 0.00410

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.54571
Value Function Update Magnitude: 0.60104

Collected Steps per Second: 22,820.73375
Overall Steps per Second: 10,692.07618

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.48656
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.67860

Cumulative Model Updates: 86,524
Cumulative Timesteps: 721,676,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.52867
Policy Entropy: 3.23507
Value Function Loss: 0.00396

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.54998
Value Function Update Magnitude: 0.60829

Collected Steps per Second: 22,506.56888
Overall Steps per Second: 10,714.70979

Timestep Collection Time: 2.22237
Timestep Consumption Time: 2.44579
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.66816

Cumulative Model Updates: 86,530
Cumulative Timesteps: 721,726,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 721726186...
Checkpoint 721726186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.14053
Policy Entropy: 3.23319
Value Function Loss: 0.00411

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08327
Policy Update Magnitude: 0.54918
Value Function Update Magnitude: 0.60907

Collected Steps per Second: 22,642.99320
Overall Steps per Second: 10,668.21251

Timestep Collection Time: 2.20907
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.68870

Cumulative Model Updates: 86,536
Cumulative Timesteps: 721,776,206

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.90587
Policy Entropy: 3.23651
Value Function Loss: 0.00417

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.61312

Collected Steps per Second: 22,909.41825
Overall Steps per Second: 10,846.20337

Timestep Collection Time: 2.18321
Timestep Consumption Time: 2.42818
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.61138

Cumulative Model Updates: 86,542
Cumulative Timesteps: 721,826,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 721826222...
Checkpoint 721826222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.56093
Policy Entropy: 3.21628
Value Function Loss: 0.00437

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.56206
Value Function Update Magnitude: 0.63751

Collected Steps per Second: 22,047.06918
Overall Steps per Second: 10,625.66906

Timestep Collection Time: 2.26887
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.70766

Cumulative Model Updates: 86,548
Cumulative Timesteps: 721,876,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.57814
Policy Entropy: 3.22092
Value Function Loss: 0.00452

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.56738
Value Function Update Magnitude: 0.63899

Collected Steps per Second: 22,410.66422
Overall Steps per Second: 10,579.35012

Timestep Collection Time: 2.23215
Timestep Consumption Time: 2.49631
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.72846

Cumulative Model Updates: 86,554
Cumulative Timesteps: 721,926,268

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 721926268...
Checkpoint 721926268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.84891
Policy Entropy: 3.22466
Value Function Loss: 0.00444

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.57321
Value Function Update Magnitude: 0.63327

Collected Steps per Second: 21,892.22527
Overall Steps per Second: 10,611.37660

Timestep Collection Time: 2.28547
Timestep Consumption Time: 2.42966
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.71513

Cumulative Model Updates: 86,560
Cumulative Timesteps: 721,976,302

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.92193
Policy Entropy: 3.23649
Value Function Loss: 0.00422

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.10936
Policy Update Magnitude: 0.56152
Value Function Update Magnitude: 0.60451

Collected Steps per Second: 22,630.25188
Overall Steps per Second: 10,647.45878

Timestep Collection Time: 2.21014
Timestep Consumption Time: 2.48732
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.69746

Cumulative Model Updates: 86,566
Cumulative Timesteps: 722,026,318

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 722026318...
Checkpoint 722026318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.35490
Policy Entropy: 3.21813
Value Function Loss: 0.00427

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11473
Policy Update Magnitude: 0.55242
Value Function Update Magnitude: 0.58034

Collected Steps per Second: 22,511.01830
Overall Steps per Second: 10,606.57783

Timestep Collection Time: 2.22167
Timestep Consumption Time: 2.49352
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.71519

Cumulative Model Updates: 86,572
Cumulative Timesteps: 722,076,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.38310
Policy Entropy: 3.21138
Value Function Loss: 0.00438

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.55639
Value Function Update Magnitude: 0.58576

Collected Steps per Second: 22,983.77744
Overall Steps per Second: 10,781.04569

Timestep Collection Time: 2.17667
Timestep Consumption Time: 2.46370
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.64037

Cumulative Model Updates: 86,578
Cumulative Timesteps: 722,126,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 722126358...
Checkpoint 722126358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,506.95847
Policy Entropy: 3.20919
Value Function Loss: 0.00443

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.56502
Value Function Update Magnitude: 0.61305

Collected Steps per Second: 22,123.85368
Overall Steps per Second: 10,626.23609

Timestep Collection Time: 2.26037
Timestep Consumption Time: 2.44572
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.70609

Cumulative Model Updates: 86,584
Cumulative Timesteps: 722,176,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.34520
Policy Entropy: 3.21004
Value Function Loss: 0.00431

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.56150
Value Function Update Magnitude: 0.63462

Collected Steps per Second: 21,895.25545
Overall Steps per Second: 10,596.46515

Timestep Collection Time: 2.28369
Timestep Consumption Time: 2.43505
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.71874

Cumulative Model Updates: 86,590
Cumulative Timesteps: 722,226,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 722226368...
Checkpoint 722226368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.65005
Policy Entropy: 3.20034
Value Function Loss: 0.00430

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11032
Policy Update Magnitude: 0.55784
Value Function Update Magnitude: 0.62229

Collected Steps per Second: 22,095.36374
Overall Steps per Second: 10,646.59707

Timestep Collection Time: 2.26364
Timestep Consumption Time: 2.43420
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.69784

Cumulative Model Updates: 86,596
Cumulative Timesteps: 722,276,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.80089
Policy Entropy: 3.18746
Value Function Loss: 0.00436

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.56343
Value Function Update Magnitude: 0.62556

Collected Steps per Second: 21,770.50523
Overall Steps per Second: 10,667.29602

Timestep Collection Time: 2.29705
Timestep Consumption Time: 2.39092
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.68797

Cumulative Model Updates: 86,602
Cumulative Timesteps: 722,326,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 722326392...
Checkpoint 722326392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 813.30409
Policy Entropy: 3.19798
Value Function Loss: 0.00430

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.57171
Value Function Update Magnitude: 0.63344

Collected Steps per Second: 22,494.92414
Overall Steps per Second: 10,673.72574

Timestep Collection Time: 2.22317
Timestep Consumption Time: 2.46217
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.68534

Cumulative Model Updates: 86,608
Cumulative Timesteps: 722,376,402

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.73373
Policy Entropy: 3.20688
Value Function Loss: 0.00445

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11587
Policy Update Magnitude: 0.56951
Value Function Update Magnitude: 0.61845

Collected Steps per Second: 21,743.97420
Overall Steps per Second: 10,492.77591

Timestep Collection Time: 2.30013
Timestep Consumption Time: 2.46639
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.76652

Cumulative Model Updates: 86,614
Cumulative Timesteps: 722,426,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 722426416...
Checkpoint 722426416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.43885
Policy Entropy: 3.20320
Value Function Loss: 0.00458

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09966
Policy Update Magnitude: 0.56720
Value Function Update Magnitude: 0.60879

Collected Steps per Second: 22,117.77814
Overall Steps per Second: 10,590.33876

Timestep Collection Time: 2.26135
Timestep Consumption Time: 2.46145
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.72280

Cumulative Model Updates: 86,620
Cumulative Timesteps: 722,476,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.48316
Policy Entropy: 3.19796
Value Function Loss: 0.00469

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.57152
Value Function Update Magnitude: 0.62681

Collected Steps per Second: 23,205.07355
Overall Steps per Second: 10,611.72394

Timestep Collection Time: 2.15548
Timestep Consumption Time: 2.55799
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.71347

Cumulative Model Updates: 86,626
Cumulative Timesteps: 722,526,450

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 722526450...
Checkpoint 722526450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 826.74265
Policy Entropy: 3.20629
Value Function Loss: 0.00443

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.56781
Value Function Update Magnitude: 0.63079

Collected Steps per Second: 22,881.34833
Overall Steps per Second: 10,624.17315

Timestep Collection Time: 2.18623
Timestep Consumption Time: 2.52227
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.70851

Cumulative Model Updates: 86,632
Cumulative Timesteps: 722,576,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.38114
Policy Entropy: 3.22052
Value Function Loss: 0.00430

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.55516
Value Function Update Magnitude: 0.63357

Collected Steps per Second: 23,036.36623
Overall Steps per Second: 10,742.88557

Timestep Collection Time: 2.17135
Timestep Consumption Time: 2.48476
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.65610

Cumulative Model Updates: 86,638
Cumulative Timesteps: 722,626,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 722626494...
Checkpoint 722626494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.08334
Policy Entropy: 3.24244
Value Function Loss: 0.00410

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.11081
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.62288

Collected Steps per Second: 22,541.18891
Overall Steps per Second: 10,720.63852

Timestep Collection Time: 2.21878
Timestep Consumption Time: 2.44642
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.66521

Cumulative Model Updates: 86,644
Cumulative Timesteps: 722,676,508

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.15881
Policy Entropy: 3.25096
Value Function Loss: 0.00411

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.54667
Value Function Update Magnitude: 0.60764

Collected Steps per Second: 23,344.09123
Overall Steps per Second: 10,827.48630

Timestep Collection Time: 2.14298
Timestep Consumption Time: 2.47729
PPO Batch Consumption Time: 0.28445
Total Iteration Time: 4.62028

Cumulative Model Updates: 86,650
Cumulative Timesteps: 722,726,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 722726534...
Checkpoint 722726534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.83488
Policy Entropy: 3.25683
Value Function Loss: 0.00399

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.60994

Collected Steps per Second: 22,819.37871
Overall Steps per Second: 10,669.09856

Timestep Collection Time: 2.19243
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.68924

Cumulative Model Updates: 86,656
Cumulative Timesteps: 722,776,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.92862
Policy Entropy: 3.22073
Value Function Loss: 0.00435

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11028
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.64134

Collected Steps per Second: 22,142.29641
Overall Steps per Second: 10,629.56376

Timestep Collection Time: 2.25812
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.70386

Cumulative Model Updates: 86,662
Cumulative Timesteps: 722,826,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 722826564...
Checkpoint 722826564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.24436
Policy Entropy: 3.21937
Value Function Loss: 0.00424

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.66373

Collected Steps per Second: 21,868.22465
Overall Steps per Second: 10,555.27039

Timestep Collection Time: 2.28761
Timestep Consumption Time: 2.45182
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.73943

Cumulative Model Updates: 86,668
Cumulative Timesteps: 722,876,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.91542
Policy Entropy: 3.21510
Value Function Loss: 0.00429

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.55778
Value Function Update Magnitude: 0.64422

Collected Steps per Second: 21,704.07587
Overall Steps per Second: 10,533.09688

Timestep Collection Time: 2.30454
Timestep Consumption Time: 2.44411
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.74865

Cumulative Model Updates: 86,674
Cumulative Timesteps: 722,926,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 722926608...
Checkpoint 722926608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,726.12824
Policy Entropy: 3.22553
Value Function Loss: 0.00398

Mean KL Divergence: 0.00748
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.63349

Collected Steps per Second: 22,078.65803
Overall Steps per Second: 10,513.14800

Timestep Collection Time: 2.26581
Timestep Consumption Time: 2.49261
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.75842

Cumulative Model Updates: 86,680
Cumulative Timesteps: 722,976,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.07327
Policy Entropy: 3.22973
Value Function Loss: 0.00391

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08903
Policy Update Magnitude: 0.55209
Value Function Update Magnitude: 0.60914

Collected Steps per Second: 21,739.37038
Overall Steps per Second: 10,515.26855

Timestep Collection Time: 2.30126
Timestep Consumption Time: 2.45639
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.75765

Cumulative Model Updates: 86,686
Cumulative Timesteps: 723,026,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 723026662...
Checkpoint 723026662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.48427
Policy Entropy: 3.22419
Value Function Loss: 0.00404

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.60867

Collected Steps per Second: 22,343.18716
Overall Steps per Second: 10,584.30326

Timestep Collection Time: 2.23916
Timestep Consumption Time: 2.48765
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.72681

Cumulative Model Updates: 86,692
Cumulative Timesteps: 723,076,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.57460
Policy Entropy: 3.23630
Value Function Loss: 0.00399

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.56128
Value Function Update Magnitude: 0.61379

Collected Steps per Second: 23,031.85617
Overall Steps per Second: 10,605.43156

Timestep Collection Time: 2.17108
Timestep Consumption Time: 2.54386
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.71494

Cumulative Model Updates: 86,698
Cumulative Timesteps: 723,126,696

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 723126696...
Checkpoint 723126696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.51357
Policy Entropy: 3.22811
Value Function Loss: 0.00407

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.64195

Collected Steps per Second: 22,801.04718
Overall Steps per Second: 10,647.75451

Timestep Collection Time: 2.19323
Timestep Consumption Time: 2.50334
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.69658

Cumulative Model Updates: 86,704
Cumulative Timesteps: 723,176,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.83128
Policy Entropy: 3.22488
Value Function Loss: 0.00415

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.55719
Value Function Update Magnitude: 0.63873

Collected Steps per Second: 23,088.02309
Overall Steps per Second: 10,729.07693

Timestep Collection Time: 2.16701
Timestep Consumption Time: 2.49620
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.66322

Cumulative Model Updates: 86,710
Cumulative Timesteps: 723,226,736

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 723226736...
Checkpoint 723226736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.12355
Policy Entropy: 3.23366
Value Function Loss: 0.00403

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08106
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.61376

Collected Steps per Second: 22,660.13106
Overall Steps per Second: 10,682.15639

Timestep Collection Time: 2.20758
Timestep Consumption Time: 2.47537
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.68295

Cumulative Model Updates: 86,716
Cumulative Timesteps: 723,276,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.74201
Policy Entropy: 3.23543
Value Function Loss: 0.00411

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.07679
Policy Update Magnitude: 0.54872
Value Function Update Magnitude: 0.59822

Collected Steps per Second: 22,224.29525
Overall Steps per Second: 10,797.48283

Timestep Collection Time: 2.25006
Timestep Consumption Time: 2.38120
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.63126

Cumulative Model Updates: 86,722
Cumulative Timesteps: 723,326,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 723326766...
Checkpoint 723326766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.61452
Policy Entropy: 3.24006
Value Function Loss: 0.00399

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.54943
Value Function Update Magnitude: 0.60348

Collected Steps per Second: 22,827.45721
Overall Steps per Second: 10,742.02467

Timestep Collection Time: 2.19096
Timestep Consumption Time: 2.46496
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.65592

Cumulative Model Updates: 86,728
Cumulative Timesteps: 723,376,780

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.03671
Policy Entropy: 3.22715
Value Function Loss: 0.00413

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09951
Policy Update Magnitude: 0.55391
Value Function Update Magnitude: 0.61303

Collected Steps per Second: 22,759.70738
Overall Steps per Second: 10,622.16213

Timestep Collection Time: 2.19686
Timestep Consumption Time: 2.51027
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.70714

Cumulative Model Updates: 86,734
Cumulative Timesteps: 723,426,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 723426780...
Checkpoint 723426780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.07400
Policy Entropy: 3.22646
Value Function Loss: 0.00414

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.56346
Value Function Update Magnitude: 0.61857

Collected Steps per Second: 22,682.28595
Overall Steps per Second: 10,505.04316

Timestep Collection Time: 2.20560
Timestep Consumption Time: 2.55669
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.76228

Cumulative Model Updates: 86,740
Cumulative Timesteps: 723,476,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.18026
Policy Entropy: 3.23068
Value Function Loss: 0.00427

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.56575
Value Function Update Magnitude: 0.61398

Collected Steps per Second: 22,455.76675
Overall Steps per Second: 10,567.51673

Timestep Collection Time: 2.22696
Timestep Consumption Time: 2.50528
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.73224

Cumulative Model Updates: 86,746
Cumulative Timesteps: 723,526,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 723526816...
Checkpoint 723526816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.72305
Policy Entropy: 3.23667
Value Function Loss: 0.00425

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.56307
Value Function Update Magnitude: 0.61499

Collected Steps per Second: 22,496.55653
Overall Steps per Second: 10,550.59271

Timestep Collection Time: 2.22363
Timestep Consumption Time: 2.51772
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.74134

Cumulative Model Updates: 86,752
Cumulative Timesteps: 723,576,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,245.05910
Policy Entropy: 3.23765
Value Function Loss: 0.00429

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.55933
Value Function Update Magnitude: 0.61253

Collected Steps per Second: 22,501.71397
Overall Steps per Second: 10,546.77675

Timestep Collection Time: 2.22232
Timestep Consumption Time: 2.51903
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.74135

Cumulative Model Updates: 86,758
Cumulative Timesteps: 723,626,846

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 723626846...
Checkpoint 723626846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.07469
Policy Entropy: 3.23371
Value Function Loss: 0.00417

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.55751
Value Function Update Magnitude: 0.61035

Collected Steps per Second: 22,841.79250
Overall Steps per Second: 10,596.06937

Timestep Collection Time: 2.18932
Timestep Consumption Time: 2.53017
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.71949

Cumulative Model Updates: 86,764
Cumulative Timesteps: 723,676,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.32095
Policy Entropy: 3.24451
Value Function Loss: 0.00426

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.55446
Value Function Update Magnitude: 0.61908

Collected Steps per Second: 23,057.54643
Overall Steps per Second: 10,515.35474

Timestep Collection Time: 2.16970
Timestep Consumption Time: 2.58791
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.75761

Cumulative Model Updates: 86,770
Cumulative Timesteps: 723,726,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 723726882...
Checkpoint 723726882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.58448
Policy Entropy: 3.25625
Value Function Loss: 0.00389

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.55888
Value Function Update Magnitude: 0.63947

Collected Steps per Second: 21,804.24764
Overall Steps per Second: 10,426.22474

Timestep Collection Time: 2.29322
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.79579

Cumulative Model Updates: 86,776
Cumulative Timesteps: 723,776,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.51049
Policy Entropy: 3.23907
Value Function Loss: 0.00401

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.55962
Value Function Update Magnitude: 0.65566

Collected Steps per Second: 22,562.55174
Overall Steps per Second: 10,467.43460

Timestep Collection Time: 2.21606
Timestep Consumption Time: 2.56066
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.77672

Cumulative Model Updates: 86,782
Cumulative Timesteps: 723,826,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 723826884...
Checkpoint 723826884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.83333
Policy Entropy: 3.23463
Value Function Loss: 0.00393

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.56843
Value Function Update Magnitude: 0.66292

Collected Steps per Second: 22,863.74903
Overall Steps per Second: 10,667.30530

Timestep Collection Time: 2.18739
Timestep Consumption Time: 2.50095
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.68834

Cumulative Model Updates: 86,788
Cumulative Timesteps: 723,876,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.94279
Policy Entropy: 3.22262
Value Function Loss: 0.00420

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.56574
Value Function Update Magnitude: 0.66006

Collected Steps per Second: 22,903.72194
Overall Steps per Second: 10,601.92943

Timestep Collection Time: 2.18384
Timestep Consumption Time: 2.53398
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.71782

Cumulative Model Updates: 86,794
Cumulative Timesteps: 723,926,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 723926914...
Checkpoint 723926914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,661.09387
Policy Entropy: 3.24155
Value Function Loss: 0.00426

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.63238

Collected Steps per Second: 22,909.94920
Overall Steps per Second: 10,618.52437

Timestep Collection Time: 2.18333
Timestep Consumption Time: 2.52730
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.71064

Cumulative Model Updates: 86,800
Cumulative Timesteps: 723,976,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.69788
Policy Entropy: 3.23707
Value Function Loss: 0.00441

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.57055
Value Function Update Magnitude: 0.63651

Collected Steps per Second: 23,028.19419
Overall Steps per Second: 10,764.73911

Timestep Collection Time: 2.17238
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.64721

Cumulative Model Updates: 86,806
Cumulative Timesteps: 724,026,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 724026960...
Checkpoint 724026960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,442.98534
Policy Entropy: 3.23771
Value Function Loss: 0.00421

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.57060
Value Function Update Magnitude: 0.63082

Collected Steps per Second: 22,406.91159
Overall Steps per Second: 10,616.90150

Timestep Collection Time: 2.23217
Timestep Consumption Time: 2.47881
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.71098

Cumulative Model Updates: 86,812
Cumulative Timesteps: 724,076,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685.91844
Policy Entropy: 3.24111
Value Function Loss: 0.00427

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08997
Policy Update Magnitude: 0.56998
Value Function Update Magnitude: 0.65261

Collected Steps per Second: 21,989.11113
Overall Steps per Second: 10,495.96487

Timestep Collection Time: 2.27467
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.76545

Cumulative Model Updates: 86,818
Cumulative Timesteps: 724,126,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 724126994...
Checkpoint 724126994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.26856
Policy Entropy: 3.24809
Value Function Loss: 0.00408

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.57002
Value Function Update Magnitude: 0.69715

Collected Steps per Second: 22,396.39050
Overall Steps per Second: 10,691.24854

Timestep Collection Time: 2.23295
Timestep Consumption Time: 2.44471
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.67766

Cumulative Model Updates: 86,824
Cumulative Timesteps: 724,177,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.16471
Policy Entropy: 3.27147
Value Function Loss: 0.00387

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09651
Policy Update Magnitude: 0.55533
Value Function Update Magnitude: 0.66981

Collected Steps per Second: 22,264.53035
Overall Steps per Second: 10,409.98074

Timestep Collection Time: 2.24590
Timestep Consumption Time: 2.55756
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.80347

Cumulative Model Updates: 86,830
Cumulative Timesteps: 724,227,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 724227008...
Checkpoint 724227008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.88784
Policy Entropy: 3.25833
Value Function Loss: 0.00407

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.55114
Value Function Update Magnitude: 0.64017

Collected Steps per Second: 22,532.09799
Overall Steps per Second: 10,577.11402

Timestep Collection Time: 2.22039
Timestep Consumption Time: 2.50964
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.73002

Cumulative Model Updates: 86,836
Cumulative Timesteps: 724,277,038

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.77502
Policy Entropy: 3.24856
Value Function Loss: 0.00424

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.56422
Value Function Update Magnitude: 0.65046

Collected Steps per Second: 22,747.14467
Overall Steps per Second: 10,553.54980

Timestep Collection Time: 2.19931
Timestep Consumption Time: 2.54109
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.74040

Cumulative Model Updates: 86,842
Cumulative Timesteps: 724,327,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 724327066...
Checkpoint 724327066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.48475
Policy Entropy: 3.22364
Value Function Loss: 0.00418

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.57456
Value Function Update Magnitude: 0.66295

Collected Steps per Second: 22,815.16491
Overall Steps per Second: 10,634.99507

Timestep Collection Time: 2.19223
Timestep Consumption Time: 2.51074
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.70296

Cumulative Model Updates: 86,848
Cumulative Timesteps: 724,377,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.55359
Policy Entropy: 3.22918
Value Function Loss: 0.00408

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11874
Policy Update Magnitude: 0.56561
Value Function Update Magnitude: 0.63910

Collected Steps per Second: 22,527.44049
Overall Steps per Second: 10,495.53546

Timestep Collection Time: 2.22067
Timestep Consumption Time: 2.54574
PPO Batch Consumption Time: 0.29653
Total Iteration Time: 4.76641

Cumulative Model Updates: 86,854
Cumulative Timesteps: 724,427,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 724427108...
Checkpoint 724427108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.06063
Policy Entropy: 3.22947
Value Function Loss: 0.00408

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.56183
Value Function Update Magnitude: 0.63228

Collected Steps per Second: 22,919.99446
Overall Steps per Second: 10,623.89842

Timestep Collection Time: 2.18150
Timestep Consumption Time: 2.52487
PPO Batch Consumption Time: 0.29648
Total Iteration Time: 4.70637

Cumulative Model Updates: 86,860
Cumulative Timesteps: 724,477,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.56747
Policy Entropy: 3.22607
Value Function Loss: 0.00391

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11254
Policy Update Magnitude: 0.56038
Value Function Update Magnitude: 0.62517

Collected Steps per Second: 22,737.93140
Overall Steps per Second: 10,616.54876

Timestep Collection Time: 2.19923
Timestep Consumption Time: 2.51096
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.71019

Cumulative Model Updates: 86,866
Cumulative Timesteps: 724,527,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 724527114...
Checkpoint 724527114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.75744
Policy Entropy: 3.23113
Value Function Loss: 0.00403

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.55807
Value Function Update Magnitude: 0.61097

Collected Steps per Second: 23,175.55625
Overall Steps per Second: 10,842.04106

Timestep Collection Time: 2.15822
Timestep Consumption Time: 2.45512
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.61334

Cumulative Model Updates: 86,872
Cumulative Timesteps: 724,577,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.24135
Policy Entropy: 3.24683
Value Function Loss: 0.00410

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.55868
Value Function Update Magnitude: 0.61389

Collected Steps per Second: 21,782.17641
Overall Steps per Second: 10,508.52363

Timestep Collection Time: 2.29628
Timestep Consumption Time: 2.46347
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.75976

Cumulative Model Updates: 86,878
Cumulative Timesteps: 724,627,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 724627150...
Checkpoint 724627150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.78999
Policy Entropy: 3.24158
Value Function Loss: 0.00422

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09950
Policy Update Magnitude: 0.56514
Value Function Update Magnitude: 0.63020

Collected Steps per Second: 22,409.38220
Overall Steps per Second: 10,656.75377

Timestep Collection Time: 2.23228
Timestep Consumption Time: 2.46183
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.69411

Cumulative Model Updates: 86,884
Cumulative Timesteps: 724,677,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.98917
Policy Entropy: 3.23987
Value Function Loss: 0.00433

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.56069
Value Function Update Magnitude: 0.63896

Collected Steps per Second: 22,602.57943
Overall Steps per Second: 10,579.80976

Timestep Collection Time: 2.21214
Timestep Consumption Time: 2.51385
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.72598

Cumulative Model Updates: 86,890
Cumulative Timesteps: 724,727,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 724727174...
Checkpoint 724727174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.37511
Policy Entropy: 3.24437
Value Function Loss: 0.00429

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.55723
Value Function Update Magnitude: 0.63316

Collected Steps per Second: 22,365.42046
Overall Steps per Second: 10,477.93951

Timestep Collection Time: 2.23631
Timestep Consumption Time: 2.53715
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.77346

Cumulative Model Updates: 86,896
Cumulative Timesteps: 724,777,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,560.88883
Policy Entropy: 3.25680
Value Function Loss: 0.00446

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.55455
Value Function Update Magnitude: 0.61082

Collected Steps per Second: 22,883.07008
Overall Steps per Second: 10,525.86273

Timestep Collection Time: 2.18555
Timestep Consumption Time: 2.56580
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.75134

Cumulative Model Updates: 86,902
Cumulative Timesteps: 724,827,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 724827202...
Checkpoint 724827202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.44975
Policy Entropy: 3.24787
Value Function Loss: 0.00447

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.56978
Value Function Update Magnitude: 0.59836

Collected Steps per Second: 22,796.25701
Overall Steps per Second: 10,655.07178

Timestep Collection Time: 2.19431
Timestep Consumption Time: 2.50036
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.69467

Cumulative Model Updates: 86,908
Cumulative Timesteps: 724,877,224

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.89129
Policy Entropy: 3.26058
Value Function Loss: 0.00434

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.57502
Value Function Update Magnitude: 0.60585

Collected Steps per Second: 23,117.79106
Overall Steps per Second: 10,877.43835

Timestep Collection Time: 2.16284
Timestep Consumption Time: 2.43383
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.59667

Cumulative Model Updates: 86,914
Cumulative Timesteps: 724,927,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 724927224...
Checkpoint 724927224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 919.56990
Policy Entropy: 3.24519
Value Function Loss: 0.00422

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.56885
Value Function Update Magnitude: 0.60137

Collected Steps per Second: 22,681.82808
Overall Steps per Second: 10,640.95425

Timestep Collection Time: 2.20573
Timestep Consumption Time: 2.49592
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.70165

Cumulative Model Updates: 86,920
Cumulative Timesteps: 724,977,254

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,204.80550
Policy Entropy: 3.25905
Value Function Loss: 0.00409

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.59901

Collected Steps per Second: 22,770.50523
Overall Steps per Second: 10,795.33372

Timestep Collection Time: 2.19705
Timestep Consumption Time: 2.43717
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.63422

Cumulative Model Updates: 86,926
Cumulative Timesteps: 725,027,282

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 725027282...
Checkpoint 725027282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.55311
Policy Entropy: 3.24537
Value Function Loss: 0.00431

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.11100
Policy Update Magnitude: 0.55203
Value Function Update Magnitude: 0.62329

Collected Steps per Second: 22,762.59970
Overall Steps per Second: 10,722.76873

Timestep Collection Time: 2.19720
Timestep Consumption Time: 2.46708
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.66428

Cumulative Model Updates: 86,932
Cumulative Timesteps: 725,077,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.18762
Policy Entropy: 3.25536
Value Function Loss: 0.00419

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.55973
Value Function Update Magnitude: 0.63507

Collected Steps per Second: 22,443.28246
Overall Steps per Second: 10,605.93135

Timestep Collection Time: 2.22909
Timestep Consumption Time: 2.48790
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.71698

Cumulative Model Updates: 86,938
Cumulative Timesteps: 725,127,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 725127324...
Checkpoint 725127324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.12136
Policy Entropy: 3.25103
Value Function Loss: 0.00401

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.56043
Value Function Update Magnitude: 0.65275

Collected Steps per Second: 22,379.07390
Overall Steps per Second: 10,591.73332

Timestep Collection Time: 2.23503
Timestep Consumption Time: 2.48733
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.72236

Cumulative Model Updates: 86,944
Cumulative Timesteps: 725,177,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.33013
Policy Entropy: 3.25864
Value Function Loss: 0.00380

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.55340
Value Function Update Magnitude: 0.64901

Collected Steps per Second: 22,331.33773
Overall Steps per Second: 10,717.03182

Timestep Collection Time: 2.23999
Timestep Consumption Time: 2.42753
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.66752

Cumulative Model Updates: 86,950
Cumulative Timesteps: 725,227,364

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 725227364...
Checkpoint 725227364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.29654
Policy Entropy: 3.26201
Value Function Loss: 0.00361

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08580
Policy Update Magnitude: 0.54172
Value Function Update Magnitude: 0.63679

Collected Steps per Second: 22,275.19023
Overall Steps per Second: 10,596.12517

Timestep Collection Time: 2.24492
Timestep Consumption Time: 2.47435
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.71927

Cumulative Model Updates: 86,956
Cumulative Timesteps: 725,277,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.44325
Policy Entropy: 3.26825
Value Function Loss: 0.00389

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08501
Policy Update Magnitude: 0.54257
Value Function Update Magnitude: 0.61813

Collected Steps per Second: 22,852.37940
Overall Steps per Second: 10,652.46259

Timestep Collection Time: 2.18857
Timestep Consumption Time: 2.50650
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.69506

Cumulative Model Updates: 86,962
Cumulative Timesteps: 725,327,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 725327384...
Checkpoint 725327384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.01120
Policy Entropy: 3.26750
Value Function Loss: 0.00408

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08350
Policy Update Magnitude: 0.55040
Value Function Update Magnitude: 0.61492

Collected Steps per Second: 22,658.40292
Overall Steps per Second: 10,615.88655

Timestep Collection Time: 2.20739
Timestep Consumption Time: 2.50404
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.71143

Cumulative Model Updates: 86,968
Cumulative Timesteps: 725,377,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.22236
Policy Entropy: 3.28142
Value Function Loss: 0.00417

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08109
Policy Update Magnitude: 0.54549
Value Function Update Magnitude: 0.63227

Collected Steps per Second: 23,122.32913
Overall Steps per Second: 10,906.81861

Timestep Collection Time: 2.16276
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.58502

Cumulative Model Updates: 86,974
Cumulative Timesteps: 725,427,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 725427408...
Checkpoint 725427408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.18700
Policy Entropy: 3.28446
Value Function Loss: 0.00404

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.54496
Value Function Update Magnitude: 0.63855

Collected Steps per Second: 22,412.21613
Overall Steps per Second: 10,548.66557

Timestep Collection Time: 2.23191
Timestep Consumption Time: 2.51011
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.74202

Cumulative Model Updates: 86,980
Cumulative Timesteps: 725,477,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.19714
Policy Entropy: 3.25570
Value Function Loss: 0.00399

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.54451
Value Function Update Magnitude: 0.61919

Collected Steps per Second: 23,113.11985
Overall Steps per Second: 10,859.71546

Timestep Collection Time: 2.16379
Timestep Consumption Time: 2.44148
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.60528

Cumulative Model Updates: 86,986
Cumulative Timesteps: 725,527,442

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 725527442...
Checkpoint 725527442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.07747
Policy Entropy: 3.26790
Value Function Loss: 0.00403

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.54725
Value Function Update Magnitude: 0.58710

Collected Steps per Second: 22,618.69683
Overall Steps per Second: 10,736.95369

Timestep Collection Time: 2.21136
Timestep Consumption Time: 2.44713
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.65849

Cumulative Model Updates: 86,992
Cumulative Timesteps: 725,577,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.31736
Policy Entropy: 3.27138
Value Function Loss: 0.00404

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.54471
Value Function Update Magnitude: 0.58642

Collected Steps per Second: 22,274.95576
Overall Steps per Second: 10,541.45454

Timestep Collection Time: 2.24584
Timestep Consumption Time: 2.49980
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.74564

Cumulative Model Updates: 86,998
Cumulative Timesteps: 725,627,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 725627486...
Checkpoint 725627486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.04641
Policy Entropy: 3.29545
Value Function Loss: 0.00391

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.53879
Value Function Update Magnitude: 0.60646

Collected Steps per Second: 22,429.45264
Overall Steps per Second: 10,530.09062

Timestep Collection Time: 2.23028
Timestep Consumption Time: 2.52029
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.75058

Cumulative Model Updates: 87,004
Cumulative Timesteps: 725,677,510

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.97800
Policy Entropy: 3.29053
Value Function Loss: 0.00382

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08080
Policy Update Magnitude: 0.53498
Value Function Update Magnitude: 0.61584

Collected Steps per Second: 22,342.75737
Overall Steps per Second: 10,586.07468

Timestep Collection Time: 2.23876
Timestep Consumption Time: 2.48632
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.72508

Cumulative Model Updates: 87,010
Cumulative Timesteps: 725,727,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 725727530...
Checkpoint 725727530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.17791
Policy Entropy: 3.27776
Value Function Loss: 0.00417

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08477
Policy Update Magnitude: 0.53683
Value Function Update Magnitude: 0.61895

Collected Steps per Second: 22,449.73736
Overall Steps per Second: 10,546.85044

Timestep Collection Time: 2.22755
Timestep Consumption Time: 2.51396
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.74151

Cumulative Model Updates: 87,016
Cumulative Timesteps: 725,777,538

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.81428
Policy Entropy: 3.27978
Value Function Loss: 0.00407

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08967
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.60265

Collected Steps per Second: 22,316.96127
Overall Steps per Second: 10,554.53518

Timestep Collection Time: 2.24099
Timestep Consumption Time: 2.49745
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.73844

Cumulative Model Updates: 87,022
Cumulative Timesteps: 725,827,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 725827550...
Checkpoint 725827550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.87324
Policy Entropy: 3.27534
Value Function Loss: 0.00414

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10065
Policy Update Magnitude: 0.54712
Value Function Update Magnitude: 0.59818

Collected Steps per Second: 22,592.38645
Overall Steps per Second: 10,540.79070

Timestep Collection Time: 2.21367
Timestep Consumption Time: 2.53095
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 4.74462

Cumulative Model Updates: 87,028
Cumulative Timesteps: 725,877,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.55310
Policy Entropy: 3.28090
Value Function Loss: 0.00395

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.54551
Value Function Update Magnitude: 0.61400

Collected Steps per Second: 22,820.90378
Overall Steps per Second: 10,781.47727

Timestep Collection Time: 2.19097
Timestep Consumption Time: 2.44661
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.63758

Cumulative Model Updates: 87,034
Cumulative Timesteps: 725,927,562

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 725927562...
Checkpoint 725927562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.24120
Policy Entropy: 3.28672
Value Function Loss: 0.00398

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.54434
Value Function Update Magnitude: 0.61002

Collected Steps per Second: 22,561.20672
Overall Steps per Second: 10,779.91611

Timestep Collection Time: 2.21673
Timestep Consumption Time: 2.42264
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.63937

Cumulative Model Updates: 87,040
Cumulative Timesteps: 725,977,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.54274
Policy Entropy: 3.28957
Value Function Loss: 0.00404

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.60874

Collected Steps per Second: 23,064.41394
Overall Steps per Second: 10,878.43209

Timestep Collection Time: 2.16802
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.59662

Cumulative Model Updates: 87,046
Cumulative Timesteps: 726,027,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 726027578...
Checkpoint 726027578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.02255
Policy Entropy: 3.27714
Value Function Loss: 0.00413

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.53985
Value Function Update Magnitude: 0.59497

Collected Steps per Second: 22,511.24944
Overall Steps per Second: 10,625.97597

Timestep Collection Time: 2.22147
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.70620

Cumulative Model Updates: 87,052
Cumulative Timesteps: 726,077,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.37271
Policy Entropy: 3.26571
Value Function Loss: 0.00419

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.54981
Value Function Update Magnitude: 0.59228

Collected Steps per Second: 22,420.51456
Overall Steps per Second: 10,597.83408

Timestep Collection Time: 2.23081
Timestep Consumption Time: 2.48864
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.71945

Cumulative Model Updates: 87,058
Cumulative Timesteps: 726,127,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 726127602...
Checkpoint 726127602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.01660
Policy Entropy: 3.24275
Value Function Loss: 0.00435

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.55949
Value Function Update Magnitude: 0.60999

Collected Steps per Second: 22,672.68424
Overall Steps per Second: 10,686.73732

Timestep Collection Time: 2.20539
Timestep Consumption Time: 2.47350
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.67888

Cumulative Model Updates: 87,064
Cumulative Timesteps: 726,177,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.05339
Policy Entropy: 3.22953
Value Function Loss: 0.00435

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11764
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.63668

Collected Steps per Second: 22,755.33479
Overall Steps per Second: 10,661.06558

Timestep Collection Time: 2.19773
Timestep Consumption Time: 2.49317
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.69090

Cumulative Model Updates: 87,070
Cumulative Timesteps: 726,227,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 726227614...
Checkpoint 726227614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 962.83257
Policy Entropy: 3.23271
Value Function Loss: 0.00429

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.56694
Value Function Update Magnitude: 0.63076

Collected Steps per Second: 22,309.48598
Overall Steps per Second: 10,698.83546

Timestep Collection Time: 2.24138
Timestep Consumption Time: 2.43240
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.67378

Cumulative Model Updates: 87,076
Cumulative Timesteps: 726,277,618

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.88043
Policy Entropy: 3.24465
Value Function Loss: 0.00427

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.62410

Collected Steps per Second: 22,570.21085
Overall Steps per Second: 10,621.24133

Timestep Collection Time: 2.21611
Timestep Consumption Time: 2.49314
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.70924

Cumulative Model Updates: 87,082
Cumulative Timesteps: 726,327,636

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 726327636...
Checkpoint 726327636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.79271
Policy Entropy: 3.24044
Value Function Loss: 0.00435

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.56697
Value Function Update Magnitude: 0.61555

Collected Steps per Second: 22,271.92420
Overall Steps per Second: 10,513.71188

Timestep Collection Time: 2.24552
Timestep Consumption Time: 2.51132
PPO Batch Consumption Time: 0.29699
Total Iteration Time: 4.75684

Cumulative Model Updates: 87,088
Cumulative Timesteps: 726,377,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.50495
Policy Entropy: 3.23085
Value Function Loss: 0.00433

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.56722
Value Function Update Magnitude: 0.61852

Collected Steps per Second: 22,469.48073
Overall Steps per Second: 10,626.27137

Timestep Collection Time: 2.22649
Timestep Consumption Time: 2.48147
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.70795

Cumulative Model Updates: 87,094
Cumulative Timesteps: 726,427,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 726427676...
Checkpoint 726427676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.22285
Policy Entropy: 3.23685
Value Function Loss: 0.00438

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.56481
Value Function Update Magnitude: 0.62033

Collected Steps per Second: 22,760.00928
Overall Steps per Second: 10,751.99605

Timestep Collection Time: 2.19736
Timestep Consumption Time: 2.45405
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.65142

Cumulative Model Updates: 87,100
Cumulative Timesteps: 726,477,688

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 662.29699
Policy Entropy: 3.24861
Value Function Loss: 0.00417

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11984
Policy Update Magnitude: 0.55776
Value Function Update Magnitude: 0.60691

Collected Steps per Second: 23,057.27734
Overall Steps per Second: 10,772.93655

Timestep Collection Time: 2.16947
Timestep Consumption Time: 2.47384
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.64330

Cumulative Model Updates: 87,106
Cumulative Timesteps: 726,527,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 726527710...
Checkpoint 726527710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.84383
Policy Entropy: 3.25301
Value Function Loss: 0.00426

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.54816
Value Function Update Magnitude: 0.59971

Collected Steps per Second: 22,660.25935
Overall Steps per Second: 10,784.04054

Timestep Collection Time: 2.20712
Timestep Consumption Time: 2.43066
PPO Batch Consumption Time: 0.28201
Total Iteration Time: 4.63778

Cumulative Model Updates: 87,112
Cumulative Timesteps: 726,577,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.34385
Policy Entropy: 3.24384
Value Function Loss: 0.00418

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.59371

Collected Steps per Second: 22,954.92602
Overall Steps per Second: 10,624.34975

Timestep Collection Time: 2.17879
Timestep Consumption Time: 2.52870
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.70749

Cumulative Model Updates: 87,118
Cumulative Timesteps: 726,627,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 726627738...
Checkpoint 726627738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.53915
Policy Entropy: 3.26316
Value Function Loss: 0.00427

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.55643
Value Function Update Magnitude: 0.59908

Collected Steps per Second: 22,554.09449
Overall Steps per Second: 10,616.03370

Timestep Collection Time: 2.21751
Timestep Consumption Time: 2.49366
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.71118

Cumulative Model Updates: 87,124
Cumulative Timesteps: 726,677,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.73266
Policy Entropy: 3.27228
Value Function Loss: 0.00433

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.58985

Collected Steps per Second: 22,931.84737
Overall Steps per Second: 10,796.78257

Timestep Collection Time: 2.18133
Timestep Consumption Time: 2.45171
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.63305

Cumulative Model Updates: 87,130
Cumulative Timesteps: 726,727,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 726727774...
Checkpoint 726727774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.39874
Policy Entropy: 3.27329
Value Function Loss: 0.00429

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.54186
Value Function Update Magnitude: 0.59479

Collected Steps per Second: 21,740.22187
Overall Steps per Second: 10,607.47464

Timestep Collection Time: 2.30053
Timestep Consumption Time: 2.41445
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.71498

Cumulative Model Updates: 87,136
Cumulative Timesteps: 726,777,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,013.29965
Policy Entropy: 3.26707
Value Function Loss: 0.00421

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.61122

Collected Steps per Second: 22,638.11784
Overall Steps per Second: 10,611.96169

Timestep Collection Time: 2.20946
Timestep Consumption Time: 2.50390
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.71336

Cumulative Model Updates: 87,142
Cumulative Timesteps: 726,827,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 726827806...
Checkpoint 726827806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.03886
Policy Entropy: 3.25563
Value Function Loss: 0.00415

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08961
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.59937

Collected Steps per Second: 22,311.65957
Overall Steps per Second: 10,530.86290

Timestep Collection Time: 2.24197
Timestep Consumption Time: 2.50807
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.75004

Cumulative Model Updates: 87,148
Cumulative Timesteps: 726,877,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.34253
Policy Entropy: 3.25766
Value Function Loss: 0.00412

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.54174
Value Function Update Magnitude: 0.58431

Collected Steps per Second: 22,462.55302
Overall Steps per Second: 10,535.16197

Timestep Collection Time: 2.22700
Timestep Consumption Time: 2.52129
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.74829

Cumulative Model Updates: 87,154
Cumulative Timesteps: 726,927,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 726927852...
Checkpoint 726927852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.78024
Policy Entropy: 3.23900
Value Function Loss: 0.00420

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.53871
Value Function Update Magnitude: 0.59738

Collected Steps per Second: 22,190.86809
Overall Steps per Second: 10,595.69983

Timestep Collection Time: 2.25354
Timestep Consumption Time: 2.46611
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.71965

Cumulative Model Updates: 87,160
Cumulative Timesteps: 726,977,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.94428
Policy Entropy: 3.23425
Value Function Loss: 0.00422

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11339
Policy Update Magnitude: 0.54048
Value Function Update Magnitude: 0.62173

Collected Steps per Second: 22,985.37613
Overall Steps per Second: 10,675.49316

Timestep Collection Time: 2.17573
Timestep Consumption Time: 2.50883
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.68456

Cumulative Model Updates: 87,166
Cumulative Timesteps: 727,027,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 727027870...
Checkpoint 727027870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,937.92493
Policy Entropy: 3.23399
Value Function Loss: 0.00429

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.54376
Value Function Update Magnitude: 0.63000

Collected Steps per Second: 22,761.04552
Overall Steps per Second: 10,761.48200

Timestep Collection Time: 2.19744
Timestep Consumption Time: 2.45025
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.64769

Cumulative Model Updates: 87,172
Cumulative Timesteps: 727,077,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.68341
Policy Entropy: 3.24683
Value Function Loss: 0.00430

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.54087
Value Function Update Magnitude: 0.62426

Collected Steps per Second: 23,035.42060
Overall Steps per Second: 10,759.33337

Timestep Collection Time: 2.17092
Timestep Consumption Time: 2.47695
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.64787

Cumulative Model Updates: 87,178
Cumulative Timesteps: 727,127,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 727127894...
Checkpoint 727127894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.02170
Policy Entropy: 3.26058
Value Function Loss: 0.00430

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.54380
Value Function Update Magnitude: 0.60762

Collected Steps per Second: 22,850.91274
Overall Steps per Second: 10,845.26510

Timestep Collection Time: 2.18845
Timestep Consumption Time: 2.42260
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.61104

Cumulative Model Updates: 87,184
Cumulative Timesteps: 727,177,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.81969
Policy Entropy: 3.24661
Value Function Loss: 0.00422

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.61268

Collected Steps per Second: 23,053.25046
Overall Steps per Second: 10,836.25167

Timestep Collection Time: 2.16898
Timestep Consumption Time: 2.44535
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.61433

Cumulative Model Updates: 87,190
Cumulative Timesteps: 727,227,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 727227904...
Checkpoint 727227904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.90119
Policy Entropy: 3.22661
Value Function Loss: 0.00429

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.55704
Value Function Update Magnitude: 0.62219

Collected Steps per Second: 22,535.49207
Overall Steps per Second: 10,759.06996

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.42881
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.64780

Cumulative Model Updates: 87,196
Cumulative Timesteps: 727,277,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.32493
Policy Entropy: 3.23105
Value Function Loss: 0.00427

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.56636
Value Function Update Magnitude: 0.63106

Collected Steps per Second: 22,311.42728
Overall Steps per Second: 10,545.95820

Timestep Collection Time: 2.24145
Timestep Consumption Time: 2.50065
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.74210

Cumulative Model Updates: 87,202
Cumulative Timesteps: 727,327,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 727327920...
Checkpoint 727327920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,977.85463
Policy Entropy: 3.23604
Value Function Loss: 0.00446

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.56479
Value Function Update Magnitude: 0.62924

Collected Steps per Second: 22,234.51943
Overall Steps per Second: 10,530.77355

Timestep Collection Time: 2.25019
Timestep Consumption Time: 2.50083
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.75103

Cumulative Model Updates: 87,208
Cumulative Timesteps: 727,377,952

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.44524
Policy Entropy: 3.24585
Value Function Loss: 0.00435

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.56911
Value Function Update Magnitude: 0.62706

Collected Steps per Second: 22,164.34413
Overall Steps per Second: 10,474.87540

Timestep Collection Time: 2.25624
Timestep Consumption Time: 2.51785
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.77409

Cumulative Model Updates: 87,214
Cumulative Timesteps: 727,427,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 727427960...
Checkpoint 727427960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690.89102
Policy Entropy: 3.24280
Value Function Loss: 0.00444

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.56821
Value Function Update Magnitude: 0.63339

Collected Steps per Second: 22,696.39321
Overall Steps per Second: 10,613.99264

Timestep Collection Time: 2.20431
Timestep Consumption Time: 2.50927
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.71359

Cumulative Model Updates: 87,220
Cumulative Timesteps: 727,477,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.50636
Policy Entropy: 3.23360
Value Function Loss: 0.00419

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.56195
Value Function Update Magnitude: 0.62548

Collected Steps per Second: 22,555.82635
Overall Steps per Second: 10,519.80721

Timestep Collection Time: 2.21717
Timestep Consumption Time: 2.53672
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.75389

Cumulative Model Updates: 87,226
Cumulative Timesteps: 727,528,000

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 727528000...
Checkpoint 727528000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.37803
Policy Entropy: 3.23441
Value Function Loss: 0.00408

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.56054
Value Function Update Magnitude: 0.60207

Collected Steps per Second: 22,629.80272
Overall Steps per Second: 10,581.08452

Timestep Collection Time: 2.21089
Timestep Consumption Time: 2.51755
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.72844

Cumulative Model Updates: 87,232
Cumulative Timesteps: 727,578,032

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.38875
Policy Entropy: 3.24041
Value Function Loss: 0.00397

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.55964
Value Function Update Magnitude: 0.58895

Collected Steps per Second: 22,750.01389
Overall Steps per Second: 10,692.48481

Timestep Collection Time: 2.19886
Timestep Consumption Time: 2.47957
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.67843

Cumulative Model Updates: 87,238
Cumulative Timesteps: 727,628,056

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 727628056...
Checkpoint 727628056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.98496
Policy Entropy: 3.25196
Value Function Loss: 0.00396

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.58754

Collected Steps per Second: 22,992.62626
Overall Steps per Second: 10,840.45205

Timestep Collection Time: 2.17583
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.61494

Cumulative Model Updates: 87,244
Cumulative Timesteps: 727,678,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.66047
Policy Entropy: 3.26584
Value Function Loss: 0.00419

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.54323
Value Function Update Magnitude: 0.59129

Collected Steps per Second: 22,842.20506
Overall Steps per Second: 10,693.29988

Timestep Collection Time: 2.18919
Timestep Consumption Time: 2.48719
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.67639

Cumulative Model Updates: 87,250
Cumulative Timesteps: 727,728,090

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 727728090...
Checkpoint 727728090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.59235
Policy Entropy: 3.27719
Value Function Loss: 0.00433

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.54231
Value Function Update Magnitude: 0.60058

Collected Steps per Second: 22,528.62871
Overall Steps per Second: 10,638.95943

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.48150
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.70196

Cumulative Model Updates: 87,256
Cumulative Timesteps: 727,778,114

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.32488
Policy Entropy: 3.29570
Value Function Loss: 0.00444

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.54685
Value Function Update Magnitude: 0.60621

Collected Steps per Second: 23,131.32537
Overall Steps per Second: 10,704.18228

Timestep Collection Time: 2.16252
Timestep Consumption Time: 2.51060
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.67313

Cumulative Model Updates: 87,262
Cumulative Timesteps: 727,828,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 727828136...
Checkpoint 727828136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.31405
Policy Entropy: 3.28587
Value Function Loss: 0.00425

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.53958
Value Function Update Magnitude: 0.60391

Collected Steps per Second: 21,631.70828
Overall Steps per Second: 10,437.20798

Timestep Collection Time: 2.31272
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.79324

Cumulative Model Updates: 87,268
Cumulative Timesteps: 727,878,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.67257
Policy Entropy: 3.26350
Value Function Loss: 0.00412

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07970
Policy Update Magnitude: 0.53721
Value Function Update Magnitude: 0.60748

Collected Steps per Second: 22,462.59766
Overall Steps per Second: 10,735.48204

Timestep Collection Time: 2.22681
Timestep Consumption Time: 2.43250
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.65932

Cumulative Model Updates: 87,274
Cumulative Timesteps: 727,928,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 727928184...
Checkpoint 727928184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.58601
Policy Entropy: 3.23759
Value Function Loss: 0.00431

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.07668
Policy Update Magnitude: 0.55419
Value Function Update Magnitude: 0.61849

Collected Steps per Second: 21,877.10035
Overall Steps per Second: 10,622.83981

Timestep Collection Time: 2.28623
Timestep Consumption Time: 2.42212
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.70835

Cumulative Model Updates: 87,280
Cumulative Timesteps: 727,978,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.41915
Policy Entropy: 3.24548
Value Function Loss: 0.00427

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08005
Policy Update Magnitude: 0.56494
Value Function Update Magnitude: 0.63875

Collected Steps per Second: 22,365.90221
Overall Steps per Second: 10,484.50934

Timestep Collection Time: 2.23572
Timestep Consumption Time: 2.53360
PPO Batch Consumption Time: 0.29643
Total Iteration Time: 4.76932

Cumulative Model Updates: 87,286
Cumulative Timesteps: 728,028,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 728028204...
Checkpoint 728028204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.45111
Policy Entropy: 3.26402
Value Function Loss: 0.00397

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.08283
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.62877

Collected Steps per Second: 22,872.76852
Overall Steps per Second: 10,575.80647

Timestep Collection Time: 2.18732
Timestep Consumption Time: 2.54329
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.73061

Cumulative Model Updates: 87,292
Cumulative Timesteps: 728,078,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.91065
Policy Entropy: 3.28172
Value Function Loss: 0.00367

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07756
Policy Update Magnitude: 0.53764
Value Function Update Magnitude: 0.60562

Collected Steps per Second: 22,986.75403
Overall Steps per Second: 10,676.96223

Timestep Collection Time: 2.17586
Timestep Consumption Time: 2.50862
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.68448

Cumulative Model Updates: 87,298
Cumulative Timesteps: 728,128,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 728128250...
Checkpoint 728128250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.93506
Policy Entropy: 3.28091
Value Function Loss: 0.00386

Mean KL Divergence: 0.00688
SB3 Clip Fraction: 0.07853
Policy Update Magnitude: 0.53792
Value Function Update Magnitude: 0.59995

Collected Steps per Second: 22,700.68713
Overall Steps per Second: 10,803.88675

Timestep Collection Time: 2.20258
Timestep Consumption Time: 2.42539
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.62796

Cumulative Model Updates: 87,304
Cumulative Timesteps: 728,178,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.24832
Policy Entropy: 3.27202
Value Function Loss: 0.00400

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08915
Policy Update Magnitude: 0.54574
Value Function Update Magnitude: 0.60667

Collected Steps per Second: 23,062.98513
Overall Steps per Second: 10,893.49142

Timestep Collection Time: 2.16945
Timestep Consumption Time: 2.42357
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.59302

Cumulative Model Updates: 87,310
Cumulative Timesteps: 728,228,284

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 728228284...
Checkpoint 728228284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 789.97777
Policy Entropy: 3.28129
Value Function Loss: 0.00406

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09876
Policy Update Magnitude: 0.53686
Value Function Update Magnitude: 0.62176

Collected Steps per Second: 22,381.99300
Overall Steps per Second: 10,698.47265

Timestep Collection Time: 2.23412
Timestep Consumption Time: 2.43982
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.67394

Cumulative Model Updates: 87,316
Cumulative Timesteps: 728,278,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.76445
Policy Entropy: 3.29416
Value Function Loss: 0.00392

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08660
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.62656

Collected Steps per Second: 23,016.48303
Overall Steps per Second: 10,846.27140

Timestep Collection Time: 2.17262
Timestep Consumption Time: 2.43782
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.61043

Cumulative Model Updates: 87,322
Cumulative Timesteps: 728,328,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 728328294...
Checkpoint 728328294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.63679
Policy Entropy: 3.29464
Value Function Loss: 0.00407

Mean KL Divergence: 0.00711
SB3 Clip Fraction: 0.07784
Policy Update Magnitude: 0.54000
Value Function Update Magnitude: 0.64745

Collected Steps per Second: 21,758.59508
Overall Steps per Second: 10,474.70205

Timestep Collection Time: 2.29803
Timestep Consumption Time: 2.47556
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.77360

Cumulative Model Updates: 87,328
Cumulative Timesteps: 728,378,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.87326
Policy Entropy: 3.27474
Value Function Loss: 0.00408

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07693
Policy Update Magnitude: 0.54843
Value Function Update Magnitude: 0.69074

Collected Steps per Second: 22,911.56381
Overall Steps per Second: 10,727.80442

Timestep Collection Time: 2.18248
Timestep Consumption Time: 2.47868
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.66116

Cumulative Model Updates: 87,334
Cumulative Timesteps: 728,428,300

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 728428300...
Checkpoint 728428300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.92623
Policy Entropy: 3.26893
Value Function Loss: 0.00416

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.55195
Value Function Update Magnitude: 0.68029

Collected Steps per Second: 22,006.80407
Overall Steps per Second: 10,661.86319

Timestep Collection Time: 2.27293
Timestep Consumption Time: 2.41855
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.69149

Cumulative Model Updates: 87,340
Cumulative Timesteps: 728,478,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.28399
Policy Entropy: 3.27284
Value Function Loss: 0.00434

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.09235
Policy Update Magnitude: 0.55408
Value Function Update Magnitude: 0.66289

Collected Steps per Second: 22,490.46247
Overall Steps per Second: 10,608.49117

Timestep Collection Time: 2.22316
Timestep Consumption Time: 2.49004
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.71321

Cumulative Model Updates: 87,346
Cumulative Timesteps: 728,528,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 728528320...
Checkpoint 728528320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.26346
Policy Entropy: 3.29217
Value Function Loss: 0.00463

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.56206
Value Function Update Magnitude: 0.67237

Collected Steps per Second: 22,249.40774
Overall Steps per Second: 10,535.54834

Timestep Collection Time: 2.24842
Timestep Consumption Time: 2.49989
PPO Batch Consumption Time: 0.29644
Total Iteration Time: 4.74831

Cumulative Model Updates: 87,352
Cumulative Timesteps: 728,578,346

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472.00905
Policy Entropy: 3.30143
Value Function Loss: 0.00505

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10592
Policy Update Magnitude: 0.56541
Value Function Update Magnitude: 0.66343

Collected Steps per Second: 22,728.06792
Overall Steps per Second: 10,602.78681

Timestep Collection Time: 2.20071
Timestep Consumption Time: 2.51672
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.71744

Cumulative Model Updates: 87,358
Cumulative Timesteps: 728,628,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 728628364...
Checkpoint 728628364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.44714
Policy Entropy: 3.30663
Value Function Loss: 0.00507

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.56232
Value Function Update Magnitude: 0.65871

Collected Steps per Second: 22,740.46616
Overall Steps per Second: 10,783.66408

Timestep Collection Time: 2.20013
Timestep Consumption Time: 2.43948
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.63961

Cumulative Model Updates: 87,364
Cumulative Timesteps: 728,678,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674.23893
Policy Entropy: 3.31338
Value Function Loss: 0.00492

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.65614

Collected Steps per Second: 23,063.59055
Overall Steps per Second: 10,794.46149

Timestep Collection Time: 2.16809
Timestep Consumption Time: 2.46428
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.63238

Cumulative Model Updates: 87,370
Cumulative Timesteps: 728,728,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 728728400...
Checkpoint 728728400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.33657
Policy Entropy: 3.29721
Value Function Loss: 0.00451

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.55779
Value Function Update Magnitude: 0.64431

Collected Steps per Second: 22,292.06735
Overall Steps per Second: 10,572.53138

Timestep Collection Time: 2.24376
Timestep Consumption Time: 2.48718
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.73094

Cumulative Model Updates: 87,376
Cumulative Timesteps: 728,778,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.60039
Policy Entropy: 3.31963
Value Function Loss: 0.00422

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.54887
Value Function Update Magnitude: 0.64135

Collected Steps per Second: 22,964.56865
Overall Steps per Second: 10,728.26078

Timestep Collection Time: 2.17735
Timestep Consumption Time: 2.48342
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.66077

Cumulative Model Updates: 87,382
Cumulative Timesteps: 728,828,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 728828420...
Checkpoint 728828420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.73072
Policy Entropy: 3.30483
Value Function Loss: 0.00434

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11714
Policy Update Magnitude: 0.54251
Value Function Update Magnitude: 0.64396

Collected Steps per Second: 22,632.01120
Overall Steps per Second: 10,611.63348

Timestep Collection Time: 2.20935
Timestep Consumption Time: 2.50265
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.71200

Cumulative Model Updates: 87,388
Cumulative Timesteps: 728,878,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.43265
Policy Entropy: 3.29801
Value Function Loss: 0.00437

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.13472
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.64899

Collected Steps per Second: 23,051.47919
Overall Steps per Second: 10,854.19588

Timestep Collection Time: 2.16975
Timestep Consumption Time: 2.43824
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.60799

Cumulative Model Updates: 87,394
Cumulative Timesteps: 728,928,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 728928438...
Checkpoint 728928438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.87763
Policy Entropy: 3.26354
Value Function Loss: 0.00447

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.54431
Value Function Update Magnitude: 0.64070

Collected Steps per Second: 21,997.73391
Overall Steps per Second: 10,650.03063

Timestep Collection Time: 2.27396
Timestep Consumption Time: 2.42293
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.69689

Cumulative Model Updates: 87,400
Cumulative Timesteps: 728,978,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.87475
Policy Entropy: 3.27316
Value Function Loss: 0.00468

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11501
Policy Update Magnitude: 0.56730
Value Function Update Magnitude: 0.64613

Collected Steps per Second: 22,246.03243
Overall Steps per Second: 10,496.13872

Timestep Collection Time: 2.24768
Timestep Consumption Time: 2.51617
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.76385

Cumulative Model Updates: 87,406
Cumulative Timesteps: 729,028,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 729028462...
Checkpoint 729028462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.86056
Policy Entropy: 3.27478
Value Function Loss: 0.00471

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.66783

Collected Steps per Second: 22,236.07551
Overall Steps per Second: 10,712.31154

Timestep Collection Time: 2.24977
Timestep Consumption Time: 2.42019
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.66995

Cumulative Model Updates: 87,412
Cumulative Timesteps: 729,078,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.79593
Policy Entropy: 3.28155
Value Function Loss: 0.00449

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11425
Policy Update Magnitude: 0.56562
Value Function Update Magnitude: 0.66354

Collected Steps per Second: 22,446.52083
Overall Steps per Second: 10,597.50924

Timestep Collection Time: 2.22761
Timestep Consumption Time: 2.49067
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.71828

Cumulative Model Updates: 87,418
Cumulative Timesteps: 729,128,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 729128490...
Checkpoint 729128490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.39322
Policy Entropy: 3.27181
Value Function Loss: 0.00459

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.56400
Value Function Update Magnitude: 0.66621

Collected Steps per Second: 22,483.82199
Overall Steps per Second: 10,569.56511

Timestep Collection Time: 2.22382
Timestep Consumption Time: 2.50674
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.73056

Cumulative Model Updates: 87,424
Cumulative Timesteps: 729,178,490

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.52122
Policy Entropy: 3.27016
Value Function Loss: 0.00433

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.56886
Value Function Update Magnitude: 0.68720

Collected Steps per Second: 22,896.57676
Overall Steps per Second: 10,756.55961

Timestep Collection Time: 2.18399
Timestep Consumption Time: 2.46489
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.64888

Cumulative Model Updates: 87,430
Cumulative Timesteps: 729,228,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 729228496...
Checkpoint 729228496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 882.50485
Policy Entropy: 3.26927
Value Function Loss: 0.00411

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.55542
Value Function Update Magnitude: 0.67948

Collected Steps per Second: 22,561.22916
Overall Steps per Second: 10,606.98294

Timestep Collection Time: 2.21655
Timestep Consumption Time: 2.49808
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.71463

Cumulative Model Updates: 87,436
Cumulative Timesteps: 729,278,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.53104
Policy Entropy: 3.26088
Value Function Loss: 0.00404

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11762
Policy Update Magnitude: 0.54401
Value Function Update Magnitude: 0.63456

Collected Steps per Second: 22,331.45739
Overall Steps per Second: 10,553.90526

Timestep Collection Time: 2.23908
Timestep Consumption Time: 2.49869
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.73777

Cumulative Model Updates: 87,442
Cumulative Timesteps: 729,328,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 729328506...
Checkpoint 729328506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.27081
Policy Entropy: 3.27056
Value Function Loss: 0.00403

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.54705
Value Function Update Magnitude: 0.61163

Collected Steps per Second: 22,533.98100
Overall Steps per Second: 10,550.05167

Timestep Collection Time: 2.21914
Timestep Consumption Time: 2.52074
PPO Batch Consumption Time: 0.29781
Total Iteration Time: 4.73988

Cumulative Model Updates: 87,448
Cumulative Timesteps: 729,378,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.70823
Policy Entropy: 3.27576
Value Function Loss: 0.00413

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.54912
Value Function Update Magnitude: 0.61446

Collected Steps per Second: 22,852.84145
Overall Steps per Second: 10,826.33788

Timestep Collection Time: 2.18879
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.62021

Cumulative Model Updates: 87,454
Cumulative Timesteps: 729,428,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 729428532...
Checkpoint 729428532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.03548
Policy Entropy: 3.27813
Value Function Loss: 0.00404

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08474
Policy Update Magnitude: 0.54585
Value Function Update Magnitude: 0.61809

Collected Steps per Second: 22,658.44122
Overall Steps per Second: 10,786.65700

Timestep Collection Time: 2.20704
Timestep Consumption Time: 2.42906
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.63610

Cumulative Model Updates: 87,460
Cumulative Timesteps: 729,478,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.95525
Policy Entropy: 3.27197
Value Function Loss: 0.00418

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.54815
Value Function Update Magnitude: 0.60888

Collected Steps per Second: 22,399.16647
Overall Steps per Second: 10,588.80594

Timestep Collection Time: 2.23321
Timestep Consumption Time: 2.49084
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.72405

Cumulative Model Updates: 87,466
Cumulative Timesteps: 729,528,562

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 729528562...
Checkpoint 729528562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.87857
Policy Entropy: 3.27828
Value Function Loss: 0.00432

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.55221
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 22,357.70286
Overall Steps per Second: 10,585.71638

Timestep Collection Time: 2.23717
Timestep Consumption Time: 2.48788
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.72505

Cumulative Model Updates: 87,472
Cumulative Timesteps: 729,578,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.74129
Policy Entropy: 3.27699
Value Function Loss: 0.00438

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.63097

Collected Steps per Second: 22,434.26833
Overall Steps per Second: 10,713.06715

Timestep Collection Time: 2.23007
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.67000

Cumulative Model Updates: 87,478
Cumulative Timesteps: 729,628,610

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 729628610...
Checkpoint 729628610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,270.41963
Policy Entropy: 3.27398
Value Function Loss: 0.00428

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.60740

Collected Steps per Second: 22,295.10874
Overall Steps per Second: 10,694.31330

Timestep Collection Time: 2.24318
Timestep Consumption Time: 2.43332
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.67650

Cumulative Model Updates: 87,484
Cumulative Timesteps: 729,678,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.00517
Policy Entropy: 3.27283
Value Function Loss: 0.00396

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.54430
Value Function Update Magnitude: 0.60110

Collected Steps per Second: 22,821.82740
Overall Steps per Second: 10,632.23798

Timestep Collection Time: 2.19106
Timestep Consumption Time: 2.51199
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.70305

Cumulative Model Updates: 87,490
Cumulative Timesteps: 729,728,626

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 729728626...
Checkpoint 729728626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.27251
Policy Entropy: 3.26815
Value Function Loss: 0.00406

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.59888

Collected Steps per Second: 21,824.43154
Overall Steps per Second: 10,489.64278

Timestep Collection Time: 2.29165
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.76794

Cumulative Model Updates: 87,496
Cumulative Timesteps: 729,778,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.16636
Policy Entropy: 3.28581
Value Function Loss: 0.00410

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.54358
Value Function Update Magnitude: 0.60040

Collected Steps per Second: 22,332.03716
Overall Steps per Second: 10,530.77529

Timestep Collection Time: 2.23938
Timestep Consumption Time: 2.50955
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.74894

Cumulative Model Updates: 87,502
Cumulative Timesteps: 729,828,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 729828650...
Checkpoint 729828650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.84766
Policy Entropy: 3.28019
Value Function Loss: 0.00439

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11058
Policy Update Magnitude: 0.55091
Value Function Update Magnitude: 0.63851

Collected Steps per Second: 22,390.81690
Overall Steps per Second: 10,545.74216

Timestep Collection Time: 2.23377
Timestep Consumption Time: 2.50899
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.74277

Cumulative Model Updates: 87,508
Cumulative Timesteps: 729,878,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.91846
Policy Entropy: 3.29310
Value Function Loss: 0.00456

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.55493
Value Function Update Magnitude: 0.64986

Collected Steps per Second: 22,306.99727
Overall Steps per Second: 10,544.62572

Timestep Collection Time: 2.24261
Timestep Consumption Time: 2.50160
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.74422

Cumulative Model Updates: 87,514
Cumulative Timesteps: 729,928,692

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 729928692...
Checkpoint 729928692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.00202
Policy Entropy: 3.29654
Value Function Loss: 0.00474

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.56304
Value Function Update Magnitude: 0.64878

Collected Steps per Second: 22,790.86885
Overall Steps per Second: 10,770.96640

Timestep Collection Time: 2.19439
Timestep Consumption Time: 2.44884
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.64322

Cumulative Model Updates: 87,520
Cumulative Timesteps: 729,978,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.93441
Policy Entropy: 3.29650
Value Function Loss: 0.00475

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.56029
Value Function Update Magnitude: 0.63988

Collected Steps per Second: 22,481.12934
Overall Steps per Second: 10,666.41416

Timestep Collection Time: 2.22471
Timestep Consumption Time: 2.46421
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.68892

Cumulative Model Updates: 87,526
Cumulative Timesteps: 730,028,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 730028718...
Checkpoint 730028718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.02818
Policy Entropy: 3.28706
Value Function Loss: 0.00440

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.63535

Collected Steps per Second: 22,050.15964
Overall Steps per Second: 10,703.01850

Timestep Collection Time: 2.26837
Timestep Consumption Time: 2.40489
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.67326

Cumulative Model Updates: 87,532
Cumulative Timesteps: 730,078,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.97476
Policy Entropy: 3.28130
Value Function Loss: 0.00417

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09082
Policy Update Magnitude: 0.54495
Value Function Update Magnitude: 0.64189

Collected Steps per Second: 22,143.05735
Overall Steps per Second: 10,674.71250

Timestep Collection Time: 2.25804
Timestep Consumption Time: 2.42592
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.68397

Cumulative Model Updates: 87,538
Cumulative Timesteps: 730,128,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 730128736...
Checkpoint 730128736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.77711
Policy Entropy: 3.26689
Value Function Loss: 0.00415

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.54576
Value Function Update Magnitude: 0.64913

Collected Steps per Second: 22,057.59683
Overall Steps per Second: 10,785.35144

Timestep Collection Time: 2.26815
Timestep Consumption Time: 2.37055
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.63870

Cumulative Model Updates: 87,544
Cumulative Timesteps: 730,178,766

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.47287
Policy Entropy: 3.27363
Value Function Loss: 0.00422

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.55508
Value Function Update Magnitude: 0.66438

Collected Steps per Second: 22,981.61163
Overall Steps per Second: 10,633.62664

Timestep Collection Time: 2.17644
Timestep Consumption Time: 2.52732
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.70376

Cumulative Model Updates: 87,550
Cumulative Timesteps: 730,228,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 730228784...
Checkpoint 730228784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.52940
Policy Entropy: 3.27054
Value Function Loss: 0.00427

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.56077
Value Function Update Magnitude: 0.67558

Collected Steps per Second: 22,837.75181
Overall Steps per Second: 10,636.61303

Timestep Collection Time: 2.19058
Timestep Consumption Time: 2.51279
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.70338

Cumulative Model Updates: 87,556
Cumulative Timesteps: 730,278,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.79907
Policy Entropy: 3.26959
Value Function Loss: 0.00421

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.55927
Value Function Update Magnitude: 0.65882

Collected Steps per Second: 22,654.86027
Overall Steps per Second: 10,722.49861

Timestep Collection Time: 2.20765
Timestep Consumption Time: 2.45675
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.66440

Cumulative Model Updates: 87,562
Cumulative Timesteps: 730,328,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 730328826...
Checkpoint 730328826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.13898
Policy Entropy: 3.25837
Value Function Loss: 0.00442

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.55924
Value Function Update Magnitude: 0.65283

Collected Steps per Second: 21,673.26082
Overall Steps per Second: 10,666.24162

Timestep Collection Time: 2.30828
Timestep Consumption Time: 2.38203
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.69031

Cumulative Model Updates: 87,568
Cumulative Timesteps: 730,378,854

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.24397
Policy Entropy: 3.24820
Value Function Loss: 0.00437

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09988
Policy Update Magnitude: 0.55499
Value Function Update Magnitude: 0.64048

Collected Steps per Second: 22,039.45773
Overall Steps per Second: 10,506.33866

Timestep Collection Time: 2.27011
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.76208

Cumulative Model Updates: 87,574
Cumulative Timesteps: 730,428,886

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 730428886...
Checkpoint 730428886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.31952
Policy Entropy: 3.24269
Value Function Loss: 0.00449

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.56324
Value Function Update Magnitude: 0.63858

Collected Steps per Second: 22,572.75722
Overall Steps per Second: 10,677.80969

Timestep Collection Time: 2.21559
Timestep Consumption Time: 2.46814
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.68373

Cumulative Model Updates: 87,580
Cumulative Timesteps: 730,478,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.36792
Policy Entropy: 3.24745
Value Function Loss: 0.00449

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.64697

Collected Steps per Second: 22,793.10790
Overall Steps per Second: 10,510.50944

Timestep Collection Time: 2.19391
Timestep Consumption Time: 2.56381
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.75771

Cumulative Model Updates: 87,586
Cumulative Timesteps: 730,528,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 730528904...
Checkpoint 730528904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.58964
Policy Entropy: 3.25854
Value Function Loss: 0.00441

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11725
Policy Update Magnitude: 0.56381
Value Function Update Magnitude: 0.62653

Collected Steps per Second: 22,764.41345
Overall Steps per Second: 10,526.96644

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.55340
PPO Batch Consumption Time: 0.29643
Total Iteration Time: 4.74990

Cumulative Model Updates: 87,592
Cumulative Timesteps: 730,578,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.12655
Policy Entropy: 3.26728
Value Function Loss: 0.00436

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.61716

Collected Steps per Second: 23,077.47093
Overall Steps per Second: 10,681.03614

Timestep Collection Time: 2.16792
Timestep Consumption Time: 2.51609
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.68400

Cumulative Model Updates: 87,598
Cumulative Timesteps: 730,628,936

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 730628936...
Checkpoint 730628936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568.53874
Policy Entropy: 3.25139
Value Function Loss: 0.00431

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.61753

Collected Steps per Second: 23,047.67232
Overall Steps per Second: 10,825.99166

Timestep Collection Time: 2.17080
Timestep Consumption Time: 2.45067
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.62147

Cumulative Model Updates: 87,604
Cumulative Timesteps: 730,678,968

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.54290
Policy Entropy: 3.25177
Value Function Loss: 0.00444

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.57191
Value Function Update Magnitude: 0.64963

Collected Steps per Second: 23,154.49803
Overall Steps per Second: 10,717.34578

Timestep Collection Time: 2.15993
Timestep Consumption Time: 2.50653
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.66645

Cumulative Model Updates: 87,610
Cumulative Timesteps: 730,728,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 730728980...
Checkpoint 730728980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 996.24323
Policy Entropy: 3.26524
Value Function Loss: 0.00437

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.56786
Value Function Update Magnitude: 0.66120

Collected Steps per Second: 23,090.37198
Overall Steps per Second: 10,857.71214

Timestep Collection Time: 2.16540
Timestep Consumption Time: 2.43962
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.60502

Cumulative Model Updates: 87,616
Cumulative Timesteps: 730,778,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.41452
Policy Entropy: 3.26585
Value Function Loss: 0.00453

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.66386

Collected Steps per Second: 22,823.13196
Overall Steps per Second: 10,587.65128

Timestep Collection Time: 2.19076
Timestep Consumption Time: 2.53172
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.72248

Cumulative Model Updates: 87,622
Cumulative Timesteps: 730,828,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 730828980...
Checkpoint 730828980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546.66362
Policy Entropy: 3.26107
Value Function Loss: 0.00445

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.65941

Collected Steps per Second: 22,455.78994
Overall Steps per Second: 10,533.92872

Timestep Collection Time: 2.22695
Timestep Consumption Time: 2.52037
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.74733

Cumulative Model Updates: 87,628
Cumulative Timesteps: 730,878,988

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.71592
Policy Entropy: 3.24641
Value Function Loss: 0.00467

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.56304
Value Function Update Magnitude: 0.65865

Collected Steps per Second: 22,319.26003
Overall Steps per Second: 10,475.85044

Timestep Collection Time: 2.24084
Timestep Consumption Time: 2.53337
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.77422

Cumulative Model Updates: 87,634
Cumulative Timesteps: 730,929,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 730929002...
Checkpoint 730929002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.86684
Policy Entropy: 3.23093
Value Function Loss: 0.00469

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.57147
Value Function Update Magnitude: 0.67222

Collected Steps per Second: 22,207.65006
Overall Steps per Second: 10,656.12307

Timestep Collection Time: 2.25148
Timestep Consumption Time: 2.44066
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.69214

Cumulative Model Updates: 87,640
Cumulative Timesteps: 730,979,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.04736
Policy Entropy: 3.22288
Value Function Loss: 0.00447

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.57753
Value Function Update Magnitude: 0.67388

Collected Steps per Second: 22,397.55020
Overall Steps per Second: 10,506.65564

Timestep Collection Time: 2.23248
Timestep Consumption Time: 2.52660
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.75908

Cumulative Model Updates: 87,646
Cumulative Timesteps: 731,029,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 731029004...
Checkpoint 731029004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.23188
Policy Entropy: 3.22940
Value Function Loss: 0.00437

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.57406
Value Function Update Magnitude: 0.65871

Collected Steps per Second: 22,430.21466
Overall Steps per Second: 10,535.82195

Timestep Collection Time: 2.23003
Timestep Consumption Time: 2.51758
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.74761

Cumulative Model Updates: 87,652
Cumulative Timesteps: 731,079,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.31190
Policy Entropy: 3.22628
Value Function Loss: 0.00443

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10038
Policy Update Magnitude: 0.57490
Value Function Update Magnitude: 0.63768

Collected Steps per Second: 22,500.30185
Overall Steps per Second: 10,475.20395

Timestep Collection Time: 2.22299
Timestep Consumption Time: 2.55190
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.77490

Cumulative Model Updates: 87,658
Cumulative Timesteps: 731,129,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 731129042...
Checkpoint 731129042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.48958
Policy Entropy: 3.23720
Value Function Loss: 0.00455

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.56998
Value Function Update Magnitude: 0.61965

Collected Steps per Second: 22,762.40990
Overall Steps per Second: 10,630.87653

Timestep Collection Time: 2.19678
Timestep Consumption Time: 2.50688
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.70366

Cumulative Model Updates: 87,664
Cumulative Timesteps: 731,179,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.87038
Policy Entropy: 3.22921
Value Function Loss: 0.00456

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.56176
Value Function Update Magnitude: 0.63234

Collected Steps per Second: 22,695.91803
Overall Steps per Second: 10,567.11136

Timestep Collection Time: 2.20374
Timestep Consumption Time: 2.52943
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.73318

Cumulative Model Updates: 87,670
Cumulative Timesteps: 731,229,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 731229062...
Checkpoint 731229062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.73023
Policy Entropy: 3.21808
Value Function Loss: 0.00463

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.56432
Value Function Update Magnitude: 0.63742

Collected Steps per Second: 22,730.89376
Overall Steps per Second: 10,609.65131

Timestep Collection Time: 2.20053
Timestep Consumption Time: 2.51405
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.71458

Cumulative Model Updates: 87,676
Cumulative Timesteps: 731,279,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.23951
Policy Entropy: 3.20410
Value Function Loss: 0.00453

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11493
Policy Update Magnitude: 0.57314
Value Function Update Magnitude: 0.64784

Collected Steps per Second: 22,842.15931
Overall Steps per Second: 10,725.23982

Timestep Collection Time: 2.18937
Timestep Consumption Time: 2.47346
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.66283

Cumulative Model Updates: 87,682
Cumulative Timesteps: 731,329,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 731329092...
Checkpoint 731329092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.27767
Policy Entropy: 3.20422
Value Function Loss: 0.00471

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.14466
Policy Update Magnitude: 0.56962
Value Function Update Magnitude: 0.65166

Collected Steps per Second: 22,780.62800
Overall Steps per Second: 10,751.09129

Timestep Collection Time: 2.19494
Timestep Consumption Time: 2.45594
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.65088

Cumulative Model Updates: 87,688
Cumulative Timesteps: 731,379,094

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.84740
Policy Entropy: 3.21046
Value Function Loss: 0.00468

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.57202
Value Function Update Magnitude: 0.66065

Collected Steps per Second: 22,742.11755
Overall Steps per Second: 10,793.70109

Timestep Collection Time: 2.19927
Timestep Consumption Time: 2.43455
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.63381

Cumulative Model Updates: 87,694
Cumulative Timesteps: 731,429,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 731429110...
Checkpoint 731429110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 846.22349
Policy Entropy: 3.22426
Value Function Loss: 0.00466

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.56547
Value Function Update Magnitude: 0.66392

Collected Steps per Second: 22,430.21860
Overall Steps per Second: 10,782.10891

Timestep Collection Time: 2.23056
Timestep Consumption Time: 2.40972
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.64028

Cumulative Model Updates: 87,700
Cumulative Timesteps: 731,479,142

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 954.10714
Policy Entropy: 3.24344
Value Function Loss: 0.00465

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.56658
Value Function Update Magnitude: 0.65579

Collected Steps per Second: 22,320.42913
Overall Steps per Second: 10,581.93892

Timestep Collection Time: 2.24010
Timestep Consumption Time: 2.48493
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.72503

Cumulative Model Updates: 87,706
Cumulative Timesteps: 731,529,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 731529142...
Checkpoint 731529142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827.88460
Policy Entropy: 3.24453
Value Function Loss: 0.00472

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12473
Policy Update Magnitude: 0.55470
Value Function Update Magnitude: 0.63285

Collected Steps per Second: 22,602.23430
Overall Steps per Second: 10,612.43863

Timestep Collection Time: 2.21270
Timestep Consumption Time: 2.49988
PPO Batch Consumption Time: 0.29742
Total Iteration Time: 4.71258

Cumulative Model Updates: 87,712
Cumulative Timesteps: 731,579,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,888.87525
Policy Entropy: 3.24734
Value Function Loss: 0.00450

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11663
Policy Update Magnitude: 0.54556
Value Function Update Magnitude: 0.61578

Collected Steps per Second: 22,421.52366
Overall Steps per Second: 10,619.91425

Timestep Collection Time: 2.23125
Timestep Consumption Time: 2.47952
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.71077

Cumulative Model Updates: 87,718
Cumulative Timesteps: 731,629,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 731629182...
Checkpoint 731629182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.38320
Policy Entropy: 3.25734
Value Function Loss: 0.00410

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.53557
Value Function Update Magnitude: 0.59913

Collected Steps per Second: 21,357.72772
Overall Steps per Second: 10,363.58836

Timestep Collection Time: 2.34192
Timestep Consumption Time: 2.48440
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.82632

Cumulative Model Updates: 87,724
Cumulative Timesteps: 731,679,200

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.01865
Policy Entropy: 3.25289
Value Function Loss: 0.00418

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.53428
Value Function Update Magnitude: 0.59199

Collected Steps per Second: 22,839.86244
Overall Steps per Second: 10,603.43466

Timestep Collection Time: 2.19056
Timestep Consumption Time: 2.52791
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.71847

Cumulative Model Updates: 87,730
Cumulative Timesteps: 731,729,232

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 731729232...
Checkpoint 731729232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 950.94165
Policy Entropy: 3.25628
Value Function Loss: 0.00418

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09889
Policy Update Magnitude: 0.54267
Value Function Update Magnitude: 0.59632

Collected Steps per Second: 22,764.68405
Overall Steps per Second: 10,637.07520

Timestep Collection Time: 2.19744
Timestep Consumption Time: 2.50536
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.70280

Cumulative Model Updates: 87,736
Cumulative Timesteps: 731,779,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.57849
Policy Entropy: 3.24623
Value Function Loss: 0.00413

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08676
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.60045

Collected Steps per Second: 22,914.47067
Overall Steps per Second: 10,814.63285

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.44173
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.62411

Cumulative Model Updates: 87,742
Cumulative Timesteps: 731,829,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 731829264...
Checkpoint 731829264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.05207
Policy Entropy: 3.24081
Value Function Loss: 0.00424

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.54193
Value Function Update Magnitude: 0.60404

Collected Steps per Second: 22,492.40696
Overall Steps per Second: 10,651.57342

Timestep Collection Time: 2.22342
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.69508

Cumulative Model Updates: 87,748
Cumulative Timesteps: 731,879,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.05206
Policy Entropy: 3.24197
Value Function Loss: 0.00427

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.62599

Collected Steps per Second: 22,685.32231
Overall Steps per Second: 10,792.50847

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.42984
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.63488

Cumulative Model Updates: 87,754
Cumulative Timesteps: 731,929,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 731929296...
Checkpoint 731929296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.72389
Policy Entropy: 3.24419
Value Function Loss: 0.00443

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.55334
Value Function Update Magnitude: 0.62986

Collected Steps per Second: 22,568.56896
Overall Steps per Second: 10,767.34174

Timestep Collection Time: 2.21662
Timestep Consumption Time: 2.42946
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.64609

Cumulative Model Updates: 87,760
Cumulative Timesteps: 731,979,322

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 661.39619
Policy Entropy: 3.24877
Value Function Loss: 0.00439

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07968
Policy Update Magnitude: 0.55267
Value Function Update Magnitude: 0.64670

Collected Steps per Second: 22,681.35593
Overall Steps per Second: 10,629.61779

Timestep Collection Time: 2.20463
Timestep Consumption Time: 2.49958
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.70421

Cumulative Model Updates: 87,766
Cumulative Timesteps: 732,029,326

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 732029326...
Checkpoint 732029326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.01492
Policy Entropy: 3.25587
Value Function Loss: 0.00425

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.54937
Value Function Update Magnitude: 0.65431

Collected Steps per Second: 22,408.67901
Overall Steps per Second: 10,592.77442

Timestep Collection Time: 2.23244
Timestep Consumption Time: 2.49021
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.72265

Cumulative Model Updates: 87,772
Cumulative Timesteps: 732,079,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.77988
Policy Entropy: 3.26660
Value Function Loss: 0.00432

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09554
Policy Update Magnitude: 0.55044
Value Function Update Magnitude: 0.66495

Collected Steps per Second: 22,485.50800
Overall Steps per Second: 10,786.37197

Timestep Collection Time: 2.22490
Timestep Consumption Time: 2.41318
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.63807

Cumulative Model Updates: 87,778
Cumulative Timesteps: 732,129,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 732129380...
Checkpoint 732129380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821.92048
Policy Entropy: 3.26197
Value Function Loss: 0.00457

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09933
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.66648

Collected Steps per Second: 21,809.39465
Overall Steps per Second: 10,616.91896

Timestep Collection Time: 2.29268
Timestep Consumption Time: 2.41697
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.70965

Cumulative Model Updates: 87,784
Cumulative Timesteps: 732,179,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.78904
Policy Entropy: 3.24532
Value Function Loss: 0.00469

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.55022
Value Function Update Magnitude: 0.65056

Collected Steps per Second: 22,057.99235
Overall Steps per Second: 10,628.83770

Timestep Collection Time: 2.26820
Timestep Consumption Time: 2.43899
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.70719

Cumulative Model Updates: 87,790
Cumulative Timesteps: 732,229,414

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 732229414...
Checkpoint 732229414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.62474
Policy Entropy: 3.22889
Value Function Loss: 0.00464

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09671
Policy Update Magnitude: 0.55064
Value Function Update Magnitude: 0.62510

Collected Steps per Second: 22,070.81549
Overall Steps per Second: 10,678.02422

Timestep Collection Time: 2.26598
Timestep Consumption Time: 2.41766
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.68364

Cumulative Model Updates: 87,796
Cumulative Timesteps: 732,279,426

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.83939
Policy Entropy: 3.24285
Value Function Loss: 0.00444

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09539
Policy Update Magnitude: 0.54802
Value Function Update Magnitude: 0.62043

Collected Steps per Second: 22,265.12430
Overall Steps per Second: 10,701.79125

Timestep Collection Time: 2.24656
Timestep Consumption Time: 2.42742
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.67398

Cumulative Model Updates: 87,802
Cumulative Timesteps: 732,329,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 732329446...
Checkpoint 732329446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,466.78717
Policy Entropy: 3.25537
Value Function Loss: 0.00426

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08784
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.62081

Collected Steps per Second: 22,010.46322
Overall Steps per Second: 10,644.07642

Timestep Collection Time: 2.27265
Timestep Consumption Time: 2.42687
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.69952

Cumulative Model Updates: 87,808
Cumulative Timesteps: 732,379,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.95137
Policy Entropy: 3.25681
Value Function Loss: 0.00411

Mean KL Divergence: 0.00744
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.53839
Value Function Update Magnitude: 0.60428

Collected Steps per Second: 22,243.16295
Overall Steps per Second: 10,779.79349

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.39138
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.64016

Cumulative Model Updates: 87,814
Cumulative Timesteps: 732,429,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 732429488...
Checkpoint 732429488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.13862
Policy Entropy: 3.23860
Value Function Loss: 0.00423

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09085
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.58407

Collected Steps per Second: 21,785.47209
Overall Steps per Second: 10,708.05493

Timestep Collection Time: 2.29547
Timestep Consumption Time: 2.37465
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.67013

Cumulative Model Updates: 87,820
Cumulative Timesteps: 732,479,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640.01523
Policy Entropy: 3.23361
Value Function Loss: 0.00457

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.55088
Value Function Update Magnitude: 0.58730

Collected Steps per Second: 22,242.73334
Overall Steps per Second: 10,498.61560

Timestep Collection Time: 2.24864
Timestep Consumption Time: 2.51541
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.76406

Cumulative Model Updates: 87,826
Cumulative Timesteps: 732,529,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 732529512...
Checkpoint 732529512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 575.00620
Policy Entropy: 3.22503
Value Function Loss: 0.00456

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.55311
Value Function Update Magnitude: 0.59117

Collected Steps per Second: 22,457.93940
Overall Steps per Second: 10,648.21226

Timestep Collection Time: 2.22745
Timestep Consumption Time: 2.47043
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.69788

Cumulative Model Updates: 87,832
Cumulative Timesteps: 732,579,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.10413
Policy Entropy: 3.24057
Value Function Loss: 0.00455

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.58199

Collected Steps per Second: 22,691.73454
Overall Steps per Second: 10,610.51821

Timestep Collection Time: 2.20442
Timestep Consumption Time: 2.50996
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.71438

Cumulative Model Updates: 87,838
Cumulative Timesteps: 732,629,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 732629558...
Checkpoint 732629558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.94479
Policy Entropy: 3.24701
Value Function Loss: 0.00447

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.58316

Collected Steps per Second: 22,887.43103
Overall Steps per Second: 10,802.45233

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.44436
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.62932

Cumulative Model Updates: 87,844
Cumulative Timesteps: 732,679,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.46029
Policy Entropy: 3.25848
Value Function Loss: 0.00445

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08398
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.59130

Collected Steps per Second: 22,540.37316
Overall Steps per Second: 10,583.59129

Timestep Collection Time: 2.21886
Timestep Consumption Time: 2.50675
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.72562

Cumulative Model Updates: 87,850
Cumulative Timesteps: 732,729,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 732729580...
Checkpoint 732729580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 866.31200
Policy Entropy: 3.25876
Value Function Loss: 0.00457

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08433
Policy Update Magnitude: 0.55338
Value Function Update Magnitude: 0.59438

Collected Steps per Second: 22,930.97062
Overall Steps per Second: 10,624.50546

Timestep Collection Time: 2.18046
Timestep Consumption Time: 2.52564
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.70610

Cumulative Model Updates: 87,856
Cumulative Timesteps: 732,779,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.44906
Policy Entropy: 3.24849
Value Function Loss: 0.00436

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.54900
Value Function Update Magnitude: 0.60353

Collected Steps per Second: 22,537.76556
Overall Steps per Second: 10,557.52328

Timestep Collection Time: 2.21885
Timestep Consumption Time: 2.51786
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.73672

Cumulative Model Updates: 87,862
Cumulative Timesteps: 732,829,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 732829588...
Checkpoint 732829588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.89030
Policy Entropy: 3.25451
Value Function Loss: 0.00431

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11835
Policy Update Magnitude: 0.54537
Value Function Update Magnitude: 0.61341

Collected Steps per Second: 22,875.03214
Overall Steps per Second: 10,678.35662

Timestep Collection Time: 2.18640
Timestep Consumption Time: 2.49728
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.68368

Cumulative Model Updates: 87,868
Cumulative Timesteps: 732,879,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.49423
Policy Entropy: 3.26249
Value Function Loss: 0.00417

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.62321

Collected Steps per Second: 23,123.95471
Overall Steps per Second: 10,752.75685

Timestep Collection Time: 2.16226
Timestep Consumption Time: 2.48771
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.64997

Cumulative Model Updates: 87,874
Cumulative Timesteps: 732,929,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 732929602...
Checkpoint 732929602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.88092
Policy Entropy: 3.25766
Value Function Loss: 0.00422

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.54004
Value Function Update Magnitude: 0.62060

Collected Steps per Second: 22,826.03059
Overall Steps per Second: 10,644.66950

Timestep Collection Time: 2.19048
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.69719

Cumulative Model Updates: 87,880
Cumulative Timesteps: 732,979,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.15462
Policy Entropy: 3.26305
Value Function Loss: 0.00422

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.54155
Value Function Update Magnitude: 0.61112

Collected Steps per Second: 23,251.31275
Overall Steps per Second: 10,865.00392

Timestep Collection Time: 2.15136
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.60396

Cumulative Model Updates: 87,886
Cumulative Timesteps: 733,029,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 733029624...
Checkpoint 733029624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.03061
Policy Entropy: 3.26962
Value Function Loss: 0.00438

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.53609
Value Function Update Magnitude: 0.62299

Collected Steps per Second: 22,396.17390
Overall Steps per Second: 10,683.75407

Timestep Collection Time: 2.23342
Timestep Consumption Time: 2.44846
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.68187

Cumulative Model Updates: 87,892
Cumulative Timesteps: 733,079,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.40453
Policy Entropy: 3.26611
Value Function Loss: 0.00440

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.54477
Value Function Update Magnitude: 0.63732

Collected Steps per Second: 22,493.91463
Overall Steps per Second: 10,522.01227

Timestep Collection Time: 2.22345
Timestep Consumption Time: 2.52983
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.75327

Cumulative Model Updates: 87,898
Cumulative Timesteps: 733,129,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 733129658...
Checkpoint 733129658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.97618
Policy Entropy: 3.24934
Value Function Loss: 0.00430

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11052
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.64087

Collected Steps per Second: 22,353.10569
Overall Steps per Second: 10,612.86911

Timestep Collection Time: 2.23763
Timestep Consumption Time: 2.47533
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.71296

Cumulative Model Updates: 87,904
Cumulative Timesteps: 733,179,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.07993
Policy Entropy: 3.25560
Value Function Loss: 0.00410

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.54225
Value Function Update Magnitude: 0.64257

Collected Steps per Second: 22,708.74123
Overall Steps per Second: 10,587.16980

Timestep Collection Time: 2.20215
Timestep Consumption Time: 2.52131
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.72345

Cumulative Model Updates: 87,910
Cumulative Timesteps: 733,229,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 733229684...
Checkpoint 733229684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.37037
Policy Entropy: 3.24748
Value Function Loss: 0.00436

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.53822
Value Function Update Magnitude: 0.65305

Collected Steps per Second: 22,424.48267
Overall Steps per Second: 10,460.52140

Timestep Collection Time: 2.23078
Timestep Consumption Time: 2.55139
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.78217

Cumulative Model Updates: 87,916
Cumulative Timesteps: 733,279,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.86100
Policy Entropy: 3.25876
Value Function Loss: 0.00442

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.54577
Value Function Update Magnitude: 0.65025

Collected Steps per Second: 22,792.60082
Overall Steps per Second: 10,533.80201

Timestep Collection Time: 2.19431
Timestep Consumption Time: 2.55364
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.74795

Cumulative Model Updates: 87,922
Cumulative Timesteps: 733,329,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 733329722...
Checkpoint 733329722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.87655
Policy Entropy: 3.26298
Value Function Loss: 0.00440

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.64438

Collected Steps per Second: 22,799.17719
Overall Steps per Second: 10,574.46411

Timestep Collection Time: 2.19306
Timestep Consumption Time: 2.53531
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.72837

Cumulative Model Updates: 87,928
Cumulative Timesteps: 733,379,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.93359
Policy Entropy: 3.26948
Value Function Loss: 0.00423

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.54129
Value Function Update Magnitude: 0.64800

Collected Steps per Second: 23,000.92029
Overall Steps per Second: 10,761.68108

Timestep Collection Time: 2.17487
Timestep Consumption Time: 2.47347
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.64834

Cumulative Model Updates: 87,934
Cumulative Timesteps: 733,429,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 733429746...
Checkpoint 733429746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.72811
Policy Entropy: 3.27020
Value Function Loss: 0.00431

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.54165
Value Function Update Magnitude: 0.64771

Collected Steps per Second: 21,691.68134
Overall Steps per Second: 10,321.67728

Timestep Collection Time: 2.30540
Timestep Consumption Time: 2.53955
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.84495

Cumulative Model Updates: 87,940
Cumulative Timesteps: 733,479,754

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.28767
Policy Entropy: 3.24575
Value Function Loss: 0.00449

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.54968
Value Function Update Magnitude: 0.64053

Collected Steps per Second: 23,137.24195
Overall Steps per Second: 10,823.49872

Timestep Collection Time: 2.16110
Timestep Consumption Time: 2.45866
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.61976

Cumulative Model Updates: 87,946
Cumulative Timesteps: 733,529,756

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 733529756...
Checkpoint 733529756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.72220
Policy Entropy: 3.23785
Value Function Loss: 0.00468

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.08048
Policy Update Magnitude: 0.55530
Value Function Update Magnitude: 0.63879

Collected Steps per Second: 21,778.77337
Overall Steps per Second: 10,287.20296

Timestep Collection Time: 2.29719
Timestep Consumption Time: 2.56613
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.86332

Cumulative Model Updates: 87,952
Cumulative Timesteps: 733,579,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.89903
Policy Entropy: 3.23533
Value Function Loss: 0.00451

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.55329
Value Function Update Magnitude: 0.64552

Collected Steps per Second: 23,106.85173
Overall Steps per Second: 10,799.79512

Timestep Collection Time: 2.16507
Timestep Consumption Time: 2.46724
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.63231

Cumulative Model Updates: 87,958
Cumulative Timesteps: 733,629,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 733629814...
Checkpoint 733629814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.48777
Policy Entropy: 3.24324
Value Function Loss: 0.00431

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.54434
Value Function Update Magnitude: 0.64909

Collected Steps per Second: 22,549.04038
Overall Steps per Second: 10,732.33422

Timestep Collection Time: 2.21863
Timestep Consumption Time: 2.44280
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.66143

Cumulative Model Updates: 87,964
Cumulative Timesteps: 733,679,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.90965
Policy Entropy: 3.25264
Value Function Loss: 0.00418

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.65008

Collected Steps per Second: 22,473.13791
Overall Steps per Second: 10,513.70338

Timestep Collection Time: 2.22559
Timestep Consumption Time: 2.53163
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.75722

Cumulative Model Updates: 87,970
Cumulative Timesteps: 733,729,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 733729858...
Checkpoint 733729858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,785.14323
Policy Entropy: 3.25117
Value Function Loss: 0.00413

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.66606

Collected Steps per Second: 22,130.47981
Overall Steps per Second: 10,638.11296

Timestep Collection Time: 2.25942
Timestep Consumption Time: 2.44085
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.70027

Cumulative Model Updates: 87,976
Cumulative Timesteps: 733,779,860

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.90318
Policy Entropy: 3.25899
Value Function Loss: 0.00427

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.53820
Value Function Update Magnitude: 0.66748

Collected Steps per Second: 22,241.38366
Overall Steps per Second: 10,459.79279

Timestep Collection Time: 2.24896
Timestep Consumption Time: 2.53316
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.78212

Cumulative Model Updates: 87,982
Cumulative Timesteps: 733,829,880

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 733829880...
Checkpoint 733829880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556.66504
Policy Entropy: 3.26524
Value Function Loss: 0.00453

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.66820

Collected Steps per Second: 22,073.83338
Overall Steps per Second: 10,577.17825

Timestep Collection Time: 2.26567
Timestep Consumption Time: 2.46262
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.72829

Cumulative Model Updates: 87,988
Cumulative Timesteps: 733,879,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.71069
Policy Entropy: 3.28783
Value Function Loss: 0.00467

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.54808
Value Function Update Magnitude: 0.66536

Collected Steps per Second: 22,510.84089
Overall Steps per Second: 10,508.72546

Timestep Collection Time: 2.22302
Timestep Consumption Time: 2.53893
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.76195

Cumulative Model Updates: 87,994
Cumulative Timesteps: 733,929,934

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 733929934...
Checkpoint 733929934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.49664
Policy Entropy: 3.28908
Value Function Loss: 0.00475

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.55516
Value Function Update Magnitude: 0.66654

Collected Steps per Second: 22,525.06725
Overall Steps per Second: 10,666.66303

Timestep Collection Time: 2.21975
Timestep Consumption Time: 2.46775
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.68750

Cumulative Model Updates: 88,000
Cumulative Timesteps: 733,979,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.94083
Policy Entropy: 3.29370
Value Function Loss: 0.00472

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.54738
Value Function Update Magnitude: 0.66666

Collected Steps per Second: 22,981.39509
Overall Steps per Second: 10,746.18999

Timestep Collection Time: 2.17611
Timestep Consumption Time: 2.47763
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.65374

Cumulative Model Updates: 88,006
Cumulative Timesteps: 734,029,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 734029944...
Checkpoint 734029944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743.48231
Policy Entropy: 3.28387
Value Function Loss: 0.00475

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.65816

Collected Steps per Second: 22,392.57213
Overall Steps per Second: 10,641.13396

Timestep Collection Time: 2.23297
Timestep Consumption Time: 2.46596
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.69894

Cumulative Model Updates: 88,012
Cumulative Timesteps: 734,079,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.36300
Policy Entropy: 3.26613
Value Function Loss: 0.00427

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10725
Policy Update Magnitude: 0.54180
Value Function Update Magnitude: 0.62802

Collected Steps per Second: 23,057.22609
Overall Steps per Second: 10,748.32321

Timestep Collection Time: 2.16921
Timestep Consumption Time: 2.48417
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.65338

Cumulative Model Updates: 88,018
Cumulative Timesteps: 734,129,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 734129962...
Checkpoint 734129962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.20421
Policy Entropy: 3.26140
Value Function Loss: 0.00407

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.53067
Value Function Update Magnitude: 0.61531

Collected Steps per Second: 22,747.70081
Overall Steps per Second: 10,706.57966

Timestep Collection Time: 2.19829
Timestep Consumption Time: 2.47230
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.67059

Cumulative Model Updates: 88,024
Cumulative Timesteps: 734,179,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.25935
Policy Entropy: 3.25942
Value Function Loss: 0.00390

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.52197
Value Function Update Magnitude: 0.61935

Collected Steps per Second: 23,007.42471
Overall Steps per Second: 10,676.19873

Timestep Collection Time: 2.17443
Timestep Consumption Time: 2.51151
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.68594

Cumulative Model Updates: 88,030
Cumulative Timesteps: 734,229,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 734229996...
Checkpoint 734229996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 927.04283
Policy Entropy: 3.26750
Value Function Loss: 0.00420

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.52957
Value Function Update Magnitude: 0.63638

Collected Steps per Second: 22,607.96077
Overall Steps per Second: 10,651.23777

Timestep Collection Time: 2.21223
Timestep Consumption Time: 2.48337
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.69560

Cumulative Model Updates: 88,036
Cumulative Timesteps: 734,280,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.69542
Policy Entropy: 3.26231
Value Function Loss: 0.00421

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.54140
Value Function Update Magnitude: 0.64980

Collected Steps per Second: 22,416.10301
Overall Steps per Second: 10,568.21061

Timestep Collection Time: 2.23072
Timestep Consumption Time: 2.50083
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.73155

Cumulative Model Updates: 88,042
Cumulative Timesteps: 734,330,014

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 734330014...
Checkpoint 734330014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.73738
Policy Entropy: 3.23852
Value Function Loss: 0.00454

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.55069
Value Function Update Magnitude: 0.68499

Collected Steps per Second: 22,513.60613
Overall Steps per Second: 10,604.74504

Timestep Collection Time: 2.22159
Timestep Consumption Time: 2.49479
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.71638

Cumulative Model Updates: 88,048
Cumulative Timesteps: 734,380,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.42415
Policy Entropy: 3.24175
Value Function Loss: 0.00459

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10454
Policy Update Magnitude: 0.56457
Value Function Update Magnitude: 0.70255

Collected Steps per Second: 22,199.55196
Overall Steps per Second: 10,555.29302

Timestep Collection Time: 2.25239
Timestep Consumption Time: 2.48476
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.73715

Cumulative Model Updates: 88,054
Cumulative Timesteps: 734,430,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 734430032...
Checkpoint 734430032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.02887
Policy Entropy: 3.24445
Value Function Loss: 0.00482

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.57216
Value Function Update Magnitude: 0.70288

Collected Steps per Second: 22,176.50188
Overall Steps per Second: 10,501.57209

Timestep Collection Time: 2.25482
Timestep Consumption Time: 2.50675
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.76157

Cumulative Model Updates: 88,060
Cumulative Timesteps: 734,480,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.11494
Policy Entropy: 3.25438
Value Function Loss: 0.00462

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.57101
Value Function Update Magnitude: 0.69223

Collected Steps per Second: 22,533.06074
Overall Steps per Second: 10,774.66681

Timestep Collection Time: 2.22100
Timestep Consumption Time: 2.42378
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.64478

Cumulative Model Updates: 88,066
Cumulative Timesteps: 734,530,082

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 734530082...
Checkpoint 734530082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 756.03071
Policy Entropy: 3.24145
Value Function Loss: 0.00455

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.67178

Collected Steps per Second: 22,583.95853
Overall Steps per Second: 10,731.55324

Timestep Collection Time: 2.21449
Timestep Consumption Time: 2.44578
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.66028

Cumulative Model Updates: 88,072
Cumulative Timesteps: 734,580,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.56980
Policy Entropy: 3.24765
Value Function Loss: 0.00422

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12570
Policy Update Magnitude: 0.55953
Value Function Update Magnitude: 0.64265

Collected Steps per Second: 22,792.90503
Overall Steps per Second: 10,799.92321

Timestep Collection Time: 2.19463
Timestep Consumption Time: 2.43707
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.63170

Cumulative Model Updates: 88,078
Cumulative Timesteps: 734,630,116

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 734630116...
Checkpoint 734630116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.81006
Policy Entropy: 3.25182
Value Function Loss: 0.00407

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11315
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.62464

Collected Steps per Second: 22,438.19870
Overall Steps per Second: 10,727.49963

Timestep Collection Time: 2.22843
Timestep Consumption Time: 2.43267
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.66110

Cumulative Model Updates: 88,084
Cumulative Timesteps: 734,680,118

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.94332
Policy Entropy: 3.24954
Value Function Loss: 0.00385

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09641
Policy Update Magnitude: 0.53767
Value Function Update Magnitude: 0.60909

Collected Steps per Second: 23,085.63426
Overall Steps per Second: 10,838.73956

Timestep Collection Time: 2.16689
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.61530

Cumulative Model Updates: 88,090
Cumulative Timesteps: 734,730,142

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 734730142...
Checkpoint 734730142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.95285
Policy Entropy: 3.24435
Value Function Loss: 0.00410

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.59086

Collected Steps per Second: 22,398.02763
Overall Steps per Second: 10,763.08916

Timestep Collection Time: 2.23261
Timestep Consumption Time: 2.41346
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.64606

Cumulative Model Updates: 88,096
Cumulative Timesteps: 734,780,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.76508
Policy Entropy: 3.24351
Value Function Loss: 0.00419

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10540
Policy Update Magnitude: 0.55007
Value Function Update Magnitude: 0.60760

Collected Steps per Second: 22,632.12020
Overall Steps per Second: 10,720.77269

Timestep Collection Time: 2.20951
Timestep Consumption Time: 2.45489
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.66440

Cumulative Model Updates: 88,102
Cumulative Timesteps: 734,830,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 734830154...
Checkpoint 734830154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.81537
Policy Entropy: 3.24001
Value Function Loss: 0.00460

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10596
Policy Update Magnitude: 0.55526
Value Function Update Magnitude: 0.63150

Collected Steps per Second: 21,963.79422
Overall Steps per Second: 10,529.96996

Timestep Collection Time: 2.27693
Timestep Consumption Time: 2.47237
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.74930

Cumulative Model Updates: 88,108
Cumulative Timesteps: 734,880,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.98988
Policy Entropy: 3.24281
Value Function Loss: 0.00463

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.63856

Collected Steps per Second: 22,593.51098
Overall Steps per Second: 10,667.00635

Timestep Collection Time: 2.21347
Timestep Consumption Time: 2.47482
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.68829

Cumulative Model Updates: 88,114
Cumulative Timesteps: 734,930,174

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 734930174...
Checkpoint 734930174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.70181
Policy Entropy: 3.25006
Value Function Loss: 0.00463

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.55768
Value Function Update Magnitude: 0.63303

Collected Steps per Second: 22,308.30432
Overall Steps per Second: 10,720.72910

Timestep Collection Time: 2.24230
Timestep Consumption Time: 2.42361
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.66591

Cumulative Model Updates: 88,120
Cumulative Timesteps: 734,980,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.52268
Policy Entropy: 3.25597
Value Function Loss: 0.00461

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.62010

Collected Steps per Second: 22,511.44419
Overall Steps per Second: 10,735.22260

Timestep Collection Time: 2.22189
Timestep Consumption Time: 2.43735
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.65924

Cumulative Model Updates: 88,126
Cumulative Timesteps: 735,030,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 735030214...
Checkpoint 735030214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.42271
Policy Entropy: 3.24578
Value Function Loss: 0.00463

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10046
Policy Update Magnitude: 0.55383
Value Function Update Magnitude: 0.63160

Collected Steps per Second: 21,955.02359
Overall Steps per Second: 10,479.15818

Timestep Collection Time: 2.27766
Timestep Consumption Time: 2.49429
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.77195

Cumulative Model Updates: 88,132
Cumulative Timesteps: 735,080,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,524.14159
Policy Entropy: 3.21958
Value Function Loss: 0.00475

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.56078
Value Function Update Magnitude: 0.65387

Collected Steps per Second: 23,131.26535
Overall Steps per Second: 10,758.80986

Timestep Collection Time: 2.16279
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.64996

Cumulative Model Updates: 88,138
Cumulative Timesteps: 735,130,248

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 735130248...
Checkpoint 735130248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.48895
Policy Entropy: 3.22005
Value Function Loss: 0.00468

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.56987
Value Function Update Magnitude: 0.66350

Collected Steps per Second: 22,392.04684
Overall Steps per Second: 10,528.23377

Timestep Collection Time: 2.23311
Timestep Consumption Time: 2.51640
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.74951

Cumulative Model Updates: 88,144
Cumulative Timesteps: 735,180,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.80104
Policy Entropy: 3.21756
Value Function Loss: 0.00453

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09135
Policy Update Magnitude: 0.57293
Value Function Update Magnitude: 0.65238

Collected Steps per Second: 22,989.18947
Overall Steps per Second: 10,723.00890

Timestep Collection Time: 2.17537
Timestep Consumption Time: 2.48843
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.66380

Cumulative Model Updates: 88,150
Cumulative Timesteps: 735,230,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 735230262...
Checkpoint 735230262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.27432
Policy Entropy: 3.23409
Value Function Loss: 0.00422

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.55541
Value Function Update Magnitude: 0.61458

Collected Steps per Second: 22,630.88237
Overall Steps per Second: 10,776.40920

Timestep Collection Time: 2.21052
Timestep Consumption Time: 2.43166
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.64218

Cumulative Model Updates: 88,156
Cumulative Timesteps: 735,280,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.30801
Policy Entropy: 3.24243
Value Function Loss: 0.00415

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.54272
Value Function Update Magnitude: 0.58420

Collected Steps per Second: 22,952.46977
Overall Steps per Second: 10,693.28791

Timestep Collection Time: 2.17911
Timestep Consumption Time: 2.49821
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.67733

Cumulative Model Updates: 88,162
Cumulative Timesteps: 735,330,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 735330304...
Checkpoint 735330304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.70059
Policy Entropy: 3.24290
Value Function Loss: 0.00423

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.53622
Value Function Update Magnitude: 0.56575

Collected Steps per Second: 22,451.20375
Overall Steps per Second: 10,890.38594

Timestep Collection Time: 2.22794
Timestep Consumption Time: 2.36510
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.59304

Cumulative Model Updates: 88,168
Cumulative Timesteps: 735,380,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.86916
Policy Entropy: 3.24373
Value Function Loss: 0.00433

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10122
Policy Update Magnitude: 0.53815
Value Function Update Magnitude: 0.57574

Collected Steps per Second: 21,653.25591
Overall Steps per Second: 10,508.60042

Timestep Collection Time: 2.31032
Timestep Consumption Time: 2.45016
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.76048

Cumulative Model Updates: 88,174
Cumulative Timesteps: 735,430,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 735430350...
Checkpoint 735430350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.67144
Policy Entropy: 3.23109
Value Function Loss: 0.00427

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.54658
Value Function Update Magnitude: 0.58529

Collected Steps per Second: 21,372.07380
Overall Steps per Second: 10,516.48196

Timestep Collection Time: 2.33978
Timestep Consumption Time: 2.41523
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.75501

Cumulative Model Updates: 88,180
Cumulative Timesteps: 735,480,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.74356
Policy Entropy: 3.22949
Value Function Loss: 0.00438

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.54542
Value Function Update Magnitude: 0.59288

Collected Steps per Second: 21,752.75792
Overall Steps per Second: 10,623.64881

Timestep Collection Time: 2.29874
Timestep Consumption Time: 2.40811
PPO Batch Consumption Time: 0.28628
Total Iteration Time: 4.70686

Cumulative Model Updates: 88,186
Cumulative Timesteps: 735,530,360

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 735530360...
Checkpoint 735530360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752.17750
Policy Entropy: 3.21934
Value Function Loss: 0.00448

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.55758
Value Function Update Magnitude: 0.60474

Collected Steps per Second: 21,700.45825
Overall Steps per Second: 10,624.79335

Timestep Collection Time: 2.30438
Timestep Consumption Time: 2.40216
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.70654

Cumulative Model Updates: 88,192
Cumulative Timesteps: 735,580,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.28749
Policy Entropy: 3.23142
Value Function Loss: 0.00435

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09587
Policy Update Magnitude: 0.56158
Value Function Update Magnitude: 0.61413

Collected Steps per Second: 23,027.98105
Overall Steps per Second: 10,655.00475

Timestep Collection Time: 2.17171
Timestep Consumption Time: 2.52186
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.69357

Cumulative Model Updates: 88,198
Cumulative Timesteps: 735,630,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 735630376...
Checkpoint 735630376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 675.56481
Policy Entropy: 3.25580
Value Function Loss: 0.00430

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09196
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.60109

Collected Steps per Second: 22,726.43292
Overall Steps per Second: 10,634.55262

Timestep Collection Time: 2.20017
Timestep Consumption Time: 2.50167
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.70184

Cumulative Model Updates: 88,204
Cumulative Timesteps: 735,680,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.17794
Policy Entropy: 3.25705
Value Function Loss: 0.00414

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.58487

Collected Steps per Second: 23,126.36641
Overall Steps per Second: 10,716.14222

Timestep Collection Time: 2.16255
Timestep Consumption Time: 2.50442
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.66698

Cumulative Model Updates: 88,210
Cumulative Timesteps: 735,730,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 735730390...
Checkpoint 735730390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778.53364
Policy Entropy: 3.26479
Value Function Loss: 0.00421

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.54833
Value Function Update Magnitude: 0.59188

Collected Steps per Second: 22,621.27802
Overall Steps per Second: 10,623.84124

Timestep Collection Time: 2.21057
Timestep Consumption Time: 2.49639
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.70696

Cumulative Model Updates: 88,216
Cumulative Timesteps: 735,780,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.19020
Policy Entropy: 3.25362
Value Function Loss: 0.00436

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09384
Policy Update Magnitude: 0.55066
Value Function Update Magnitude: 0.61405

Collected Steps per Second: 23,110.94603
Overall Steps per Second: 10,832.32234

Timestep Collection Time: 2.16460
Timestep Consumption Time: 2.45361
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.61822

Cumulative Model Updates: 88,222
Cumulative Timesteps: 735,830,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 735830422...
Checkpoint 735830422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.68731
Policy Entropy: 3.26077
Value Function Loss: 0.00432

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.55668
Value Function Update Magnitude: 0.61499

Collected Steps per Second: 22,436.37846
Overall Steps per Second: 10,666.98193

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.45992
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.68942

Cumulative Model Updates: 88,228
Cumulative Timesteps: 735,880,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.50783
Policy Entropy: 3.24773
Value Function Loss: 0.00438

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.55525
Value Function Update Magnitude: 0.62161

Collected Steps per Second: 22,487.25674
Overall Steps per Second: 10,521.02326

Timestep Collection Time: 2.22455
Timestep Consumption Time: 2.53012
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.75467

Cumulative Model Updates: 88,234
Cumulative Timesteps: 735,930,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 735930468...
Checkpoint 735930468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963.61546
Policy Entropy: 3.24243
Value Function Loss: 0.00420

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08837
Policy Update Magnitude: 0.55514
Value Function Update Magnitude: 0.63046

Collected Steps per Second: 22,052.08764
Overall Steps per Second: 10,602.94278

Timestep Collection Time: 2.26781
Timestep Consumption Time: 2.44880
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.71662

Cumulative Model Updates: 88,240
Cumulative Timesteps: 735,980,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.82200
Policy Entropy: 3.22828
Value Function Loss: 0.00428

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.55520
Value Function Update Magnitude: 0.60733

Collected Steps per Second: 22,274.04126
Overall Steps per Second: 10,465.10207

Timestep Collection Time: 2.24503
Timestep Consumption Time: 2.53332
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.77836

Cumulative Model Updates: 88,246
Cumulative Timesteps: 736,030,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 736030484...
Checkpoint 736030484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.80931
Policy Entropy: 3.23822
Value Function Loss: 0.00454

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.56344
Value Function Update Magnitude: 0.63076

Collected Steps per Second: 22,232.07607
Overall Steps per Second: 10,623.99516

Timestep Collection Time: 2.24909
Timestep Consumption Time: 2.45742
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.70652

Cumulative Model Updates: 88,252
Cumulative Timesteps: 736,080,486

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.22947
Policy Entropy: 3.21645
Value Function Loss: 0.00479

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.57238
Value Function Update Magnitude: 0.64193

Collected Steps per Second: 22,830.59069
Overall Steps per Second: 10,568.61636

Timestep Collection Time: 2.19101
Timestep Consumption Time: 2.54206
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.73307

Cumulative Model Updates: 88,258
Cumulative Timesteps: 736,130,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 736130508...
Checkpoint 736130508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.26199
Policy Entropy: 3.21968
Value Function Loss: 0.00472

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11255
Policy Update Magnitude: 0.57362
Value Function Update Magnitude: 0.63418

Collected Steps per Second: 23,021.79097
Overall Steps per Second: 10,697.07924

Timestep Collection Time: 2.17238
Timestep Consumption Time: 2.50292
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.67529

Cumulative Model Updates: 88,264
Cumulative Timesteps: 736,180,520

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.89286
Policy Entropy: 3.22287
Value Function Loss: 0.00474

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.57089
Value Function Update Magnitude: 0.62439

Collected Steps per Second: 22,924.31041
Overall Steps per Second: 10,838.80753

Timestep Collection Time: 2.18231
Timestep Consumption Time: 2.43332
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.61564

Cumulative Model Updates: 88,270
Cumulative Timesteps: 736,230,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 736230548...
Checkpoint 736230548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.71068
Policy Entropy: 3.22829
Value Function Loss: 0.00462

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.57469
Value Function Update Magnitude: 0.64103

Collected Steps per Second: 22,809.02961
Overall Steps per Second: 10,597.08559

Timestep Collection Time: 2.19325
Timestep Consumption Time: 2.52748
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 4.72073

Cumulative Model Updates: 88,276
Cumulative Timesteps: 736,280,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737.13860
Policy Entropy: 3.23841
Value Function Loss: 0.00461

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.57570
Value Function Update Magnitude: 0.64954

Collected Steps per Second: 22,953.33034
Overall Steps per Second: 10,800.61251

Timestep Collection Time: 2.17929
Timestep Consumption Time: 2.45211
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.63140

Cumulative Model Updates: 88,282
Cumulative Timesteps: 736,330,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 736330596...
Checkpoint 736330596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.90992
Policy Entropy: 3.23522
Value Function Loss: 0.00461

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.57496
Value Function Update Magnitude: 0.66056

Collected Steps per Second: 22,636.55991
Overall Steps per Second: 10,771.28431

Timestep Collection Time: 2.20917
Timestep Consumption Time: 2.43355
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.64271

Cumulative Model Updates: 88,288
Cumulative Timesteps: 736,380,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.81830
Policy Entropy: 3.23974
Value Function Loss: 0.00465

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.57278
Value Function Update Magnitude: 0.65568

Collected Steps per Second: 22,240.19302
Overall Steps per Second: 10,479.50810

Timestep Collection Time: 2.24908
Timestep Consumption Time: 2.52404
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.77312

Cumulative Model Updates: 88,294
Cumulative Timesteps: 736,430,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 736430624...
Checkpoint 736430624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.39438
Policy Entropy: 3.23335
Value Function Loss: 0.00462

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.57142
Value Function Update Magnitude: 0.64463

Collected Steps per Second: 22,381.32603
Overall Steps per Second: 10,550.99352

Timestep Collection Time: 2.23526
Timestep Consumption Time: 2.50629
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.74154

Cumulative Model Updates: 88,300
Cumulative Timesteps: 736,480,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.72137
Policy Entropy: 3.25143
Value Function Loss: 0.00452

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08096
Policy Update Magnitude: 0.56432
Value Function Update Magnitude: 0.63694

Collected Steps per Second: 22,586.14779
Overall Steps per Second: 10,522.78833

Timestep Collection Time: 2.21472
Timestep Consumption Time: 2.53896
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.75368

Cumulative Model Updates: 88,306
Cumulative Timesteps: 736,530,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 736530674...
Checkpoint 736530674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.96189
Policy Entropy: 3.25865
Value Function Loss: 0.00463

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08271
Policy Update Magnitude: 0.55596
Value Function Update Magnitude: 0.63287

Collected Steps per Second: 22,529.01074
Overall Steps per Second: 10,585.90974

Timestep Collection Time: 2.21989
Timestep Consumption Time: 2.50450
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.72439

Cumulative Model Updates: 88,312
Cumulative Timesteps: 736,580,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 485.52601
Policy Entropy: 3.26176
Value Function Loss: 0.00460

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.56162
Value Function Update Magnitude: 0.64484

Collected Steps per Second: 22,800.76128
Overall Steps per Second: 10,557.97951

Timestep Collection Time: 2.19379
Timestep Consumption Time: 2.54386
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.73765

Cumulative Model Updates: 88,318
Cumulative Timesteps: 736,630,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 736630706...
Checkpoint 736630706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.63497
Policy Entropy: 3.24856
Value Function Loss: 0.00428

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.55633
Value Function Update Magnitude: 0.64767

Collected Steps per Second: 22,795.19026
Overall Steps per Second: 10,553.89712

Timestep Collection Time: 2.19467
Timestep Consumption Time: 2.54557
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.74024

Cumulative Model Updates: 88,324
Cumulative Timesteps: 736,680,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,531.14618
Policy Entropy: 3.23605
Value Function Loss: 0.00410

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.54457
Value Function Update Magnitude: 0.63288

Collected Steps per Second: 21,813.19739
Overall Steps per Second: 10,412.79667

Timestep Collection Time: 2.29237
Timestep Consumption Time: 2.50979
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.80217

Cumulative Model Updates: 88,330
Cumulative Timesteps: 736,730,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 736730738...
Checkpoint 736730738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.94810
Policy Entropy: 3.22258
Value Function Loss: 0.00429

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08330
Policy Update Magnitude: 0.54862
Value Function Update Magnitude: 0.62492

Collected Steps per Second: 22,816.08363
Overall Steps per Second: 10,676.49747

Timestep Collection Time: 2.19240
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.68524

Cumulative Model Updates: 88,336
Cumulative Timesteps: 736,780,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.41272
Policy Entropy: 3.21201
Value Function Loss: 0.00444

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.55773
Value Function Update Magnitude: 0.62442

Collected Steps per Second: 22,840.87010
Overall Steps per Second: 10,828.57406

Timestep Collection Time: 2.18967
Timestep Consumption Time: 2.42903
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.61871

Cumulative Model Updates: 88,342
Cumulative Timesteps: 736,830,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 736830774...
Checkpoint 736830774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.09255
Policy Entropy: 3.20354
Value Function Loss: 0.00458

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10688
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.63486

Collected Steps per Second: 22,746.73485
Overall Steps per Second: 10,757.01903

Timestep Collection Time: 2.19926
Timestep Consumption Time: 2.45128
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.65054

Cumulative Model Updates: 88,348
Cumulative Timesteps: 736,880,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.86751
Policy Entropy: 3.21111
Value Function Loss: 0.00470

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10244
Policy Update Magnitude: 0.56451
Value Function Update Magnitude: 0.65066

Collected Steps per Second: 23,027.03273
Overall Steps per Second: 10,890.06631

Timestep Collection Time: 2.17206
Timestep Consumption Time: 2.42075
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.59281

Cumulative Model Updates: 88,354
Cumulative Timesteps: 736,930,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 736930816...
Checkpoint 736930816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.96838
Policy Entropy: 3.22439
Value Function Loss: 0.00466

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.56736
Value Function Update Magnitude: 0.65713

Collected Steps per Second: 22,067.68040
Overall Steps per Second: 10,659.02302

Timestep Collection Time: 2.26594
Timestep Consumption Time: 2.42530
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.69124

Cumulative Model Updates: 88,360
Cumulative Timesteps: 736,980,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.34215
Policy Entropy: 3.21283
Value Function Loss: 0.00482

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.66761

Collected Steps per Second: 22,537.74951
Overall Steps per Second: 10,736.24226

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.43882
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.65750

Cumulative Model Updates: 88,366
Cumulative Timesteps: 737,030,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 737030824...
Checkpoint 737030824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.62980
Policy Entropy: 3.21279
Value Function Loss: 0.00472

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10607
Policy Update Magnitude: 0.56944
Value Function Update Magnitude: 0.67278

Collected Steps per Second: 22,123.59340
Overall Steps per Second: 10,674.03820

Timestep Collection Time: 2.26093
Timestep Consumption Time: 2.42520
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.68614

Cumulative Model Updates: 88,372
Cumulative Timesteps: 737,080,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.74192
Policy Entropy: 3.21018
Value Function Loss: 0.00489

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.58152
Value Function Update Magnitude: 0.66913

Collected Steps per Second: 22,630.64303
Overall Steps per Second: 10,613.15410

Timestep Collection Time: 2.21010
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.29707
Total Iteration Time: 4.71264

Cumulative Model Updates: 88,378
Cumulative Timesteps: 737,130,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 737130860...
Checkpoint 737130860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 504.35982
Policy Entropy: 3.22203
Value Function Loss: 0.00500

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.58188
Value Function Update Magnitude: 0.65985

Collected Steps per Second: 22,641.91337
Overall Steps per Second: 10,588.32655

Timestep Collection Time: 2.20847
Timestep Consumption Time: 2.51409
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.72256

Cumulative Model Updates: 88,384
Cumulative Timesteps: 737,180,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.17560
Policy Entropy: 3.21943
Value Function Loss: 0.00498

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.57975
Value Function Update Magnitude: 0.63766

Collected Steps per Second: 22,712.06670
Overall Steps per Second: 10,619.78583

Timestep Collection Time: 2.20218
Timestep Consumption Time: 2.50752
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70970

Cumulative Model Updates: 88,390
Cumulative Timesteps: 737,230,880

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 737230880...
Checkpoint 737230880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.66798
Policy Entropy: 3.21851
Value Function Loss: 0.00480

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.57586
Value Function Update Magnitude: 0.63951

Collected Steps per Second: 22,919.85221
Overall Steps per Second: 10,825.36420

Timestep Collection Time: 2.18160
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.61897

Cumulative Model Updates: 88,396
Cumulative Timesteps: 737,280,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.69076
Policy Entropy: 3.22885
Value Function Loss: 0.00463

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09841
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.62727

Collected Steps per Second: 22,716.95943
Overall Steps per Second: 10,921.38017

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.37841
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.58056

Cumulative Model Updates: 88,402
Cumulative Timesteps: 737,330,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 737330908...
Checkpoint 737330908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.81090
Policy Entropy: 3.22894
Value Function Loss: 0.00474

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.63938

Collected Steps per Second: 21,663.93846
Overall Steps per Second: 10,636.32187

Timestep Collection Time: 2.30835
Timestep Consumption Time: 2.39327
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.70163

Cumulative Model Updates: 88,408
Cumulative Timesteps: 737,380,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 751.60429
Policy Entropy: 3.23016
Value Function Loss: 0.00476

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.56689
Value Function Update Magnitude: 0.66383

Collected Steps per Second: 22,123.01018
Overall Steps per Second: 10,621.41139

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.44826
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.70917

Cumulative Model Updates: 88,414
Cumulative Timesteps: 737,430,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 737430934...
Checkpoint 737430934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.04547
Policy Entropy: 3.21911
Value Function Loss: 0.00478

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.57288
Value Function Update Magnitude: 0.67595

Collected Steps per Second: 21,977.90799
Overall Steps per Second: 10,566.47586

Timestep Collection Time: 2.27519
Timestep Consumption Time: 2.45713
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.73233

Cumulative Model Updates: 88,420
Cumulative Timesteps: 737,480,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.90634
Policy Entropy: 3.22185
Value Function Loss: 0.00477

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.57390
Value Function Update Magnitude: 0.68887

Collected Steps per Second: 22,768.24574
Overall Steps per Second: 10,646.25030

Timestep Collection Time: 2.19657
Timestep Consumption Time: 2.50105
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.69762

Cumulative Model Updates: 88,426
Cumulative Timesteps: 737,530,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 737530950...
Checkpoint 737530950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.31606
Policy Entropy: 3.21070
Value Function Loss: 0.00483

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.70625

Collected Steps per Second: 22,345.16500
Overall Steps per Second: 10,521.06927

Timestep Collection Time: 2.23887
Timestep Consumption Time: 2.51616
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.75503

Cumulative Model Updates: 88,432
Cumulative Timesteps: 737,580,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.09199
Policy Entropy: 3.21775
Value Function Loss: 0.00485

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.58391
Value Function Update Magnitude: 0.74727

Collected Steps per Second: 22,438.01746
Overall Steps per Second: 10,544.94118

Timestep Collection Time: 2.22845
Timestep Consumption Time: 2.51335
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.74180

Cumulative Model Updates: 88,438
Cumulative Timesteps: 737,630,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 737630980...
Checkpoint 737630980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.86781
Policy Entropy: 3.23022
Value Function Loss: 0.00498

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.58282
Value Function Update Magnitude: 0.75084

Collected Steps per Second: 22,528.43942
Overall Steps per Second: 10,566.21716

Timestep Collection Time: 2.22146
Timestep Consumption Time: 2.51496
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.73642

Cumulative Model Updates: 88,444
Cumulative Timesteps: 737,681,026

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.43928
Policy Entropy: 3.21385
Value Function Loss: 0.00506

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.58282
Value Function Update Magnitude: 0.73388

Collected Steps per Second: 22,542.78831
Overall Steps per Second: 10,604.39970

Timestep Collection Time: 2.21916
Timestep Consumption Time: 2.49832
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.71748

Cumulative Model Updates: 88,450
Cumulative Timesteps: 737,731,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 737731052...
Checkpoint 737731052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.75946
Policy Entropy: 3.21431
Value Function Loss: 0.00511

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.58345
Value Function Update Magnitude: 0.72744

Collected Steps per Second: 23,074.09531
Overall Steps per Second: 10,753.63469

Timestep Collection Time: 2.16806
Timestep Consumption Time: 2.48395
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.65201

Cumulative Model Updates: 88,456
Cumulative Timesteps: 737,781,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 913.86594
Policy Entropy: 3.21631
Value Function Loss: 0.00480

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08867
Policy Update Magnitude: 0.58311
Value Function Update Magnitude: 0.72996

Collected Steps per Second: 22,881.02184
Overall Steps per Second: 10,591.34673

Timestep Collection Time: 2.18530
Timestep Consumption Time: 2.53572
PPO Batch Consumption Time: 0.29489
Total Iteration Time: 4.72102

Cumulative Model Updates: 88,462
Cumulative Timesteps: 737,831,080

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 737831080...
Checkpoint 737831080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.54936
Policy Entropy: 3.22803
Value Function Loss: 0.00443

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.57444
Value Function Update Magnitude: 0.70196

Collected Steps per Second: 22,990.53631
Overall Steps per Second: 10,626.04540

Timestep Collection Time: 2.17594
Timestep Consumption Time: 2.53193
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.70787

Cumulative Model Updates: 88,468
Cumulative Timesteps: 737,881,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.71838
Policy Entropy: 3.22025
Value Function Loss: 0.00430

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.56453
Value Function Update Magnitude: 0.67757

Collected Steps per Second: 22,832.53480
Overall Steps per Second: 10,767.16654

Timestep Collection Time: 2.18995
Timestep Consumption Time: 2.45399
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.64393

Cumulative Model Updates: 88,474
Cumulative Timesteps: 737,931,108

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 737931108...
Checkpoint 737931108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.58569
Policy Entropy: 3.21226
Value Function Loss: 0.00438

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09575
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.66380

Collected Steps per Second: 22,549.61246
Overall Steps per Second: 10,718.28570

Timestep Collection Time: 2.21742
Timestep Consumption Time: 2.44769
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.66511

Cumulative Model Updates: 88,480
Cumulative Timesteps: 737,981,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.18460
Policy Entropy: 3.22097
Value Function Loss: 0.00465

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08327
Policy Update Magnitude: 0.56759
Value Function Update Magnitude: 0.66319

Collected Steps per Second: 22,666.73272
Overall Steps per Second: 10,624.52898

Timestep Collection Time: 2.20632
Timestep Consumption Time: 2.50072
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.70703

Cumulative Model Updates: 88,486
Cumulative Timesteps: 738,031,120

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 738031120...
Checkpoint 738031120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.18268
Policy Entropy: 3.20920
Value Function Loss: 0.00459

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.56557
Value Function Update Magnitude: 0.65735

Collected Steps per Second: 22,760.53902
Overall Steps per Second: 10,612.51477

Timestep Collection Time: 2.19810
Timestep Consumption Time: 2.51614
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.71425

Cumulative Model Updates: 88,492
Cumulative Timesteps: 738,081,150

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.57694
Policy Entropy: 3.22109
Value Function Loss: 0.00439

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.55901
Value Function Update Magnitude: 0.63936

Collected Steps per Second: 22,769.28247
Overall Steps per Second: 10,772.94955

Timestep Collection Time: 2.19743
Timestep Consumption Time: 2.44698
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.64441

Cumulative Model Updates: 88,498
Cumulative Timesteps: 738,131,184

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 738131184...
Checkpoint 738131184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 768.55428
Policy Entropy: 3.21468
Value Function Loss: 0.00431

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09272
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.63286

Collected Steps per Second: 22,334.89438
Overall Steps per Second: 10,503.01774

Timestep Collection Time: 2.23963
Timestep Consumption Time: 2.52300
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.76263

Cumulative Model Updates: 88,504
Cumulative Timesteps: 738,181,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.65766
Policy Entropy: 3.23078
Value Function Loss: 0.00437

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.55460
Value Function Update Magnitude: 0.61969

Collected Steps per Second: 21,953.87947
Overall Steps per Second: 10,460.51430

Timestep Collection Time: 2.27759
Timestep Consumption Time: 2.50248
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.78007

Cumulative Model Updates: 88,510
Cumulative Timesteps: 738,231,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 738231208...
Checkpoint 738231208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.68352
Policy Entropy: 3.22676
Value Function Loss: 0.00440

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.55512
Value Function Update Magnitude: 0.62992

Collected Steps per Second: 22,279.95669
Overall Steps per Second: 10,688.73640

Timestep Collection Time: 2.24480
Timestep Consumption Time: 2.43433
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.67913

Cumulative Model Updates: 88,516
Cumulative Timesteps: 738,281,222

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.81772
Policy Entropy: 3.22290
Value Function Loss: 0.00425

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.54940
Value Function Update Magnitude: 0.61812

Collected Steps per Second: 22,660.29446
Overall Steps per Second: 10,606.58677

Timestep Collection Time: 2.20686
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.71481

Cumulative Model Updates: 88,522
Cumulative Timesteps: 738,331,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 738331230...
Checkpoint 738331230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.98279
Policy Entropy: 3.20528
Value Function Loss: 0.00441

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.55137
Value Function Update Magnitude: 0.61352

Collected Steps per Second: 22,924.54903
Overall Steps per Second: 10,619.69498

Timestep Collection Time: 2.18150
Timestep Consumption Time: 2.52767
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70917

Cumulative Model Updates: 88,528
Cumulative Timesteps: 738,381,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.42075
Policy Entropy: 3.21468
Value Function Loss: 0.00467

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.56191
Value Function Update Magnitude: 0.62373

Collected Steps per Second: 22,483.66455
Overall Steps per Second: 10,670.38048

Timestep Collection Time: 2.22455
Timestep Consumption Time: 2.46282
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.68737

Cumulative Model Updates: 88,534
Cumulative Timesteps: 738,431,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 738431256...
Checkpoint 738431256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.38157
Policy Entropy: 3.23219
Value Function Loss: 0.00458

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.56192
Value Function Update Magnitude: 0.64063

Collected Steps per Second: 22,885.14067
Overall Steps per Second: 10,684.06043

Timestep Collection Time: 2.18482
Timestep Consumption Time: 2.49504
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.67987

Cumulative Model Updates: 88,540
Cumulative Timesteps: 738,481,256

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.39834
Policy Entropy: 3.23322
Value Function Loss: 0.00442

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10763
Policy Update Magnitude: 0.55287
Value Function Update Magnitude: 0.62774

Collected Steps per Second: 22,624.57871
Overall Steps per Second: 10,631.89129

Timestep Collection Time: 2.21043
Timestep Consumption Time: 2.49334
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.70377

Cumulative Model Updates: 88,546
Cumulative Timesteps: 738,531,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 738531266...
Checkpoint 738531266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 531.52016
Policy Entropy: 3.23562
Value Function Loss: 0.00433

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.54466
Value Function Update Magnitude: 0.60991

Collected Steps per Second: 22,857.90775
Overall Steps per Second: 10,679.95789

Timestep Collection Time: 2.18743
Timestep Consumption Time: 2.49424
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.68167

Cumulative Model Updates: 88,552
Cumulative Timesteps: 738,581,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.73582
Policy Entropy: 3.21264
Value Function Loss: 0.00457

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.54877
Value Function Update Magnitude: 0.62266

Collected Steps per Second: 22,852.38576
Overall Steps per Second: 10,712.68170

Timestep Collection Time: 2.18813
Timestep Consumption Time: 2.47961
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.66774

Cumulative Model Updates: 88,558
Cumulative Timesteps: 738,631,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 738631270...
Checkpoint 738631270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.48801
Policy Entropy: 3.20768
Value Function Loss: 0.00462

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.55867
Value Function Update Magnitude: 0.64688

Collected Steps per Second: 22,827.10354
Overall Steps per Second: 10,629.68129

Timestep Collection Time: 2.19073
Timestep Consumption Time: 2.51383
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.70456

Cumulative Model Updates: 88,564
Cumulative Timesteps: 738,681,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.34045
Policy Entropy: 3.21312
Value Function Loss: 0.00455

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.65234

Collected Steps per Second: 22,447.56061
Overall Steps per Second: 10,526.86128

Timestep Collection Time: 2.22795
Timestep Consumption Time: 2.52295
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.75089

Cumulative Model Updates: 88,570
Cumulative Timesteps: 738,731,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 738731290...
Checkpoint 738731290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.74983
Policy Entropy: 3.22918
Value Function Loss: 0.00439

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.55294
Value Function Update Magnitude: 0.64015

Collected Steps per Second: 22,261.73476
Overall Steps per Second: 10,535.30741

Timestep Collection Time: 2.24744
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.74898

Cumulative Model Updates: 88,576
Cumulative Timesteps: 738,781,322

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.43890
Policy Entropy: 3.23602
Value Function Loss: 0.00445

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.54959
Value Function Update Magnitude: 0.63498

Collected Steps per Second: 22,457.68520
Overall Steps per Second: 10,529.44079

Timestep Collection Time: 2.22730
Timestep Consumption Time: 2.52319
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.75049

Cumulative Model Updates: 88,582
Cumulative Timesteps: 738,831,342

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 738831342...
Checkpoint 738831342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.46480
Policy Entropy: 3.21892
Value Function Loss: 0.00421

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.53912
Value Function Update Magnitude: 0.64225

Collected Steps per Second: 22,494.31164
Overall Steps per Second: 10,545.49106

Timestep Collection Time: 2.22296
Timestep Consumption Time: 2.51878
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.74174

Cumulative Model Updates: 88,588
Cumulative Timesteps: 738,881,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.53274
Policy Entropy: 3.22263
Value Function Loss: 0.00433

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.53719
Value Function Update Magnitude: 0.64970

Collected Steps per Second: 22,597.42598
Overall Steps per Second: 10,521.78691

Timestep Collection Time: 2.21282
Timestep Consumption Time: 2.53961
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.75242

Cumulative Model Updates: 88,594
Cumulative Timesteps: 738,931,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 738931350...
Checkpoint 738931350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 698.38514
Policy Entropy: 3.21498
Value Function Loss: 0.00431

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.54498
Value Function Update Magnitude: 0.63741

Collected Steps per Second: 22,842.29480
Overall Steps per Second: 10,548.80737

Timestep Collection Time: 2.18918
Timestep Consumption Time: 2.55126
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.74044

Cumulative Model Updates: 88,600
Cumulative Timesteps: 738,981,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.79937
Policy Entropy: 3.23444
Value Function Loss: 0.00453

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.55378
Value Function Update Magnitude: 0.62015

Collected Steps per Second: 22,423.28550
Overall Steps per Second: 10,460.76837

Timestep Collection Time: 2.23090
Timestep Consumption Time: 2.55116
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.78206

Cumulative Model Updates: 88,606
Cumulative Timesteps: 739,031,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 739031380...
Checkpoint 739031380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.18260
Policy Entropy: 3.21755
Value Function Loss: 0.00467

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.55234
Value Function Update Magnitude: 0.61753

Collected Steps per Second: 22,720.82982
Overall Steps per Second: 10,634.64428

Timestep Collection Time: 2.20115
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.70274

Cumulative Model Updates: 88,612
Cumulative Timesteps: 739,081,392

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.18204
Policy Entropy: 3.22988
Value Function Loss: 0.00469

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09029
Policy Update Magnitude: 0.56005
Value Function Update Magnitude: 0.62103

Collected Steps per Second: 22,798.29356
Overall Steps per Second: 10,627.76553

Timestep Collection Time: 2.19315
Timestep Consumption Time: 2.51151
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.70466

Cumulative Model Updates: 88,618
Cumulative Timesteps: 739,131,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 739131392...
Checkpoint 739131392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,484.25278
Policy Entropy: 3.23256
Value Function Loss: 0.00474

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.55786
Value Function Update Magnitude: 0.64100

Collected Steps per Second: 22,578.88675
Overall Steps per Second: 10,537.99360

Timestep Collection Time: 2.21552
Timestep Consumption Time: 2.53149
PPO Batch Consumption Time: 0.29827
Total Iteration Time: 4.74701

Cumulative Model Updates: 88,624
Cumulative Timesteps: 739,181,416

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.68983
Policy Entropy: 3.25745
Value Function Loss: 0.00452

Mean KL Divergence: 0.00692
SB3 Clip Fraction: 0.07822
Policy Update Magnitude: 0.54780
Value Function Update Magnitude: 0.64650

Collected Steps per Second: 22,978.30168
Overall Steps per Second: 10,815.70680

Timestep Collection Time: 2.17605
Timestep Consumption Time: 2.44704
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.62309

Cumulative Model Updates: 88,630
Cumulative Timesteps: 739,231,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 739231418...
Checkpoint 739231418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.51524
Policy Entropy: 3.23528
Value Function Loss: 0.00446

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.07209
Policy Update Magnitude: 0.54425
Value Function Update Magnitude: 0.63803

Collected Steps per Second: 22,413.43164
Overall Steps per Second: 10,625.46810

Timestep Collection Time: 2.23134
Timestep Consumption Time: 2.47546
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.70680

Cumulative Model Updates: 88,636
Cumulative Timesteps: 739,281,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.88655
Policy Entropy: 3.22828
Value Function Loss: 0.00451

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.07905
Policy Update Magnitude: 0.55430
Value Function Update Magnitude: 0.62790

Collected Steps per Second: 22,349.77632
Overall Steps per Second: 10,467.95318

Timestep Collection Time: 2.23752
Timestep Consumption Time: 2.53973
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.77725

Cumulative Model Updates: 88,642
Cumulative Timesteps: 739,331,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 739331438...
Checkpoint 739331438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.29082
Policy Entropy: 3.20648
Value Function Loss: 0.00452

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.56373
Value Function Update Magnitude: 0.63980

Collected Steps per Second: 21,972.30709
Overall Steps per Second: 10,641.25019

Timestep Collection Time: 2.27668
Timestep Consumption Time: 2.42427
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.70095

Cumulative Model Updates: 88,648
Cumulative Timesteps: 739,381,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.18996
Policy Entropy: 3.22404
Value Function Loss: 0.00458

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.08219
Policy Update Magnitude: 0.56120
Value Function Update Magnitude: 0.63873

Collected Steps per Second: 22,546.08500
Overall Steps per Second: 10,612.81912

Timestep Collection Time: 2.21866
Timestep Consumption Time: 2.49470
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.71336

Cumulative Model Updates: 88,654
Cumulative Timesteps: 739,431,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 739431484...
Checkpoint 739431484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.33160
Policy Entropy: 3.23867
Value Function Loss: 0.00454

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08262
Policy Update Magnitude: 0.55237
Value Function Update Magnitude: 0.61415

Collected Steps per Second: 22,433.56058
Overall Steps per Second: 10,584.51248

Timestep Collection Time: 2.22987
Timestep Consumption Time: 2.49628
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.72615

Cumulative Model Updates: 88,660
Cumulative Timesteps: 739,481,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.73150
Policy Entropy: 3.24536
Value Function Loss: 0.00436

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.53923
Value Function Update Magnitude: 0.57855

Collected Steps per Second: 22,795.47756
Overall Steps per Second: 10,739.86326

Timestep Collection Time: 2.19359
Timestep Consumption Time: 2.46233
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.65593

Cumulative Model Updates: 88,666
Cumulative Timesteps: 739,531,512

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 739531512...
Checkpoint 739531512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.28031
Policy Entropy: 3.23849
Value Function Loss: 0.00421

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.53266
Value Function Update Magnitude: 0.56860

Collected Steps per Second: 22,840.01933
Overall Steps per Second: 10,730.42164

Timestep Collection Time: 2.18940
Timestep Consumption Time: 2.47081
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.66021

Cumulative Model Updates: 88,672
Cumulative Timesteps: 739,581,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735.09715
Policy Entropy: 3.22527
Value Function Loss: 0.00430

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.52966
Value Function Update Magnitude: 0.58062

Collected Steps per Second: 22,876.06843
Overall Steps per Second: 10,795.34284

Timestep Collection Time: 2.18613
Timestep Consumption Time: 2.44643
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.63255

Cumulative Model Updates: 88,678
Cumulative Timesteps: 739,631,528

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 739631528...
Checkpoint 739631528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685.79578
Policy Entropy: 3.22975
Value Function Loss: 0.00467

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.60050

Collected Steps per Second: 22,780.12413
Overall Steps per Second: 10,700.19500

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.47920
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.67524

Cumulative Model Updates: 88,684
Cumulative Timesteps: 739,681,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.21122
Policy Entropy: 3.22803
Value Function Loss: 0.00471

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.55970
Value Function Update Magnitude: 0.61713

Collected Steps per Second: 22,661.89854
Overall Steps per Second: 10,655.00590

Timestep Collection Time: 2.20688
Timestep Consumption Time: 2.48688
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.69376

Cumulative Model Updates: 88,690
Cumulative Timesteps: 739,731,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 739731566...
Checkpoint 739731566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.76247
Policy Entropy: 3.23552
Value Function Loss: 0.00441

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.55217
Value Function Update Magnitude: 0.60675

Collected Steps per Second: 22,259.88336
Overall Steps per Second: 10,516.30317

Timestep Collection Time: 2.24664
Timestep Consumption Time: 2.50883
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.75547

Cumulative Model Updates: 88,696
Cumulative Timesteps: 739,781,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.49227
Policy Entropy: 3.22001
Value Function Loss: 0.00442

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.54346
Value Function Update Magnitude: 0.60382

Collected Steps per Second: 22,214.94514
Overall Steps per Second: 10,550.52084

Timestep Collection Time: 2.25182
Timestep Consumption Time: 2.48956
PPO Batch Consumption Time: 0.29550
Total Iteration Time: 4.74138

Cumulative Model Updates: 88,702
Cumulative Timesteps: 739,831,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 739831600...
Checkpoint 739831600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.33887
Policy Entropy: 3.21717
Value Function Loss: 0.00464

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.60743

Collected Steps per Second: 22,059.65225
Overall Steps per Second: 10,523.49840

Timestep Collection Time: 2.26785
Timestep Consumption Time: 2.48608
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.75393

Cumulative Model Updates: 88,708
Cumulative Timesteps: 739,881,628

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.42018
Policy Entropy: 3.22970
Value Function Loss: 0.00457

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.55665
Value Function Update Magnitude: 0.59927

Collected Steps per Second: 22,587.95679
Overall Steps per Second: 10,627.52531

Timestep Collection Time: 2.21490
Timestep Consumption Time: 2.49269
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.70759

Cumulative Model Updates: 88,714
Cumulative Timesteps: 739,931,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 739931658...
Checkpoint 739931658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.79705
Policy Entropy: 3.24705
Value Function Loss: 0.00447

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.55459
Value Function Update Magnitude: 0.57904

Collected Steps per Second: 22,260.26155
Overall Steps per Second: 10,837.99884

Timestep Collection Time: 2.24616
Timestep Consumption Time: 2.36724
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.61340

Cumulative Model Updates: 88,720
Cumulative Timesteps: 739,981,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.81024
Policy Entropy: 3.25406
Value Function Loss: 0.00424

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08196
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.57813

Collected Steps per Second: 22,207.52808
Overall Steps per Second: 10,634.25256

Timestep Collection Time: 2.25275
Timestep Consumption Time: 2.45167
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.70442

Cumulative Model Updates: 88,726
Cumulative Timesteps: 740,031,686

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 740031686...
Checkpoint 740031686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.65900
Policy Entropy: 3.23750
Value Function Loss: 0.00450

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.08091
Policy Update Magnitude: 0.54904
Value Function Update Magnitude: 0.58137

Collected Steps per Second: 22,114.43655
Overall Steps per Second: 10,624.97728

Timestep Collection Time: 2.26169
Timestep Consumption Time: 2.44571
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.70740

Cumulative Model Updates: 88,732
Cumulative Timesteps: 740,081,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.89912
Policy Entropy: 3.23503
Value Function Loss: 0.00462

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.57763

Collected Steps per Second: 22,232.46019
Overall Steps per Second: 10,796.68591

Timestep Collection Time: 2.24914
Timestep Consumption Time: 2.38228
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.63142

Cumulative Model Updates: 88,738
Cumulative Timesteps: 740,131,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 740131706...
Checkpoint 740131706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.35969
Policy Entropy: 3.23304
Value Function Loss: 0.00460

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09883
Policy Update Magnitude: 0.56532
Value Function Update Magnitude: 0.58696

Collected Steps per Second: 21,719.98002
Overall Steps per Second: 10,672.85203

Timestep Collection Time: 2.30203
Timestep Consumption Time: 2.38276
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.68478

Cumulative Model Updates: 88,744
Cumulative Timesteps: 740,181,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.72856
Policy Entropy: 3.22359
Value Function Loss: 0.00446

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.56458
Value Function Update Magnitude: 0.60341

Collected Steps per Second: 22,229.58804
Overall Steps per Second: 10,804.95838

Timestep Collection Time: 2.25033
Timestep Consumption Time: 2.37939
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.62973

Cumulative Model Updates: 88,750
Cumulative Timesteps: 740,231,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 740231730...
Checkpoint 740231730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.47327
Policy Entropy: 3.21905
Value Function Loss: 0.00466

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.56766
Value Function Update Magnitude: 0.61720

Collected Steps per Second: 22,001.38406
Overall Steps per Second: 10,742.96890

Timestep Collection Time: 2.27258
Timestep Consumption Time: 2.38162
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.65421

Cumulative Model Updates: 88,756
Cumulative Timesteps: 740,281,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 654.49016
Policy Entropy: 3.23016
Value Function Loss: 0.00472

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.56522
Value Function Update Magnitude: 0.62429

Collected Steps per Second: 22,642.65260
Overall Steps per Second: 10,633.42499

Timestep Collection Time: 2.20902
Timestep Consumption Time: 2.49483
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.70385

Cumulative Model Updates: 88,762
Cumulative Timesteps: 740,331,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 740331748...
Checkpoint 740331748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.99443
Policy Entropy: 3.23655
Value Function Loss: 0.00457

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.55859
Value Function Update Magnitude: 0.62480

Collected Steps per Second: 22,195.51501
Overall Steps per Second: 10,457.97897

Timestep Collection Time: 2.25316
Timestep Consumption Time: 2.52884
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 4.78199

Cumulative Model Updates: 88,768
Cumulative Timesteps: 740,381,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.53536
Policy Entropy: 3.23596
Value Function Loss: 0.00421

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.61502

Collected Steps per Second: 22,238.75728
Overall Steps per Second: 10,434.70107

Timestep Collection Time: 2.24977
Timestep Consumption Time: 2.54500
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.79477

Cumulative Model Updates: 88,774
Cumulative Timesteps: 740,431,790

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 740431790...
Checkpoint 740431790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.49128
Policy Entropy: 3.24555
Value Function Loss: 0.00412

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.54564
Value Function Update Magnitude: 0.61184

Collected Steps per Second: 22,033.37396
Overall Steps per Second: 10,537.31522

Timestep Collection Time: 2.26983
Timestep Consumption Time: 2.47635
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.74618

Cumulative Model Updates: 88,780
Cumulative Timesteps: 740,481,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.73183
Policy Entropy: 3.24975
Value Function Loss: 0.00425

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.54469
Value Function Update Magnitude: 0.61495

Collected Steps per Second: 22,631.46221
Overall Steps per Second: 10,571.82775

Timestep Collection Time: 2.21099
Timestep Consumption Time: 2.52215
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.73315

Cumulative Model Updates: 88,786
Cumulative Timesteps: 740,531,840

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 740531840...
Checkpoint 740531840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.74915
Policy Entropy: 3.25357
Value Function Loss: 0.00418

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.54525
Value Function Update Magnitude: 0.61341

Collected Steps per Second: 22,501.73884
Overall Steps per Second: 10,636.69651

Timestep Collection Time: 2.22303
Timestep Consumption Time: 2.47975
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.70278

Cumulative Model Updates: 88,792
Cumulative Timesteps: 740,581,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.61153
Policy Entropy: 3.24506
Value Function Loss: 0.00416

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.54883
Value Function Update Magnitude: 0.59587

Collected Steps per Second: 22,967.47888
Overall Steps per Second: 10,765.43300

Timestep Collection Time: 2.17838
Timestep Consumption Time: 2.46908
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.64747

Cumulative Model Updates: 88,798
Cumulative Timesteps: 740,631,894

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 740631894...
Checkpoint 740631894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.99304
Policy Entropy: 3.24370
Value Function Loss: 0.00418

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.55214
Value Function Update Magnitude: 0.59499

Collected Steps per Second: 22,582.43886
Overall Steps per Second: 10,709.11510

Timestep Collection Time: 2.21420
Timestep Consumption Time: 2.45491
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.66911

Cumulative Model Updates: 88,804
Cumulative Timesteps: 740,681,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.64014
Policy Entropy: 3.25929
Value Function Loss: 0.00435

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09871
Policy Update Magnitude: 0.55194
Value Function Update Magnitude: 0.61197

Collected Steps per Second: 22,914.48517
Overall Steps per Second: 10,674.57372

Timestep Collection Time: 2.18246
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.68496

Cumulative Model Updates: 88,810
Cumulative Timesteps: 740,731,906

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 740731906...
Checkpoint 740731906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.05196
Policy Entropy: 3.26603
Value Function Loss: 0.00442

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.54995
Value Function Update Magnitude: 0.61433

Collected Steps per Second: 22,815.28498
Overall Steps per Second: 10,653.61973

Timestep Collection Time: 2.19169
Timestep Consumption Time: 2.50193
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.69362

Cumulative Model Updates: 88,816
Cumulative Timesteps: 740,781,910

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.38310
Policy Entropy: 3.27463
Value Function Loss: 0.00431

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.54162
Value Function Update Magnitude: 0.58881

Collected Steps per Second: 23,058.70065
Overall Steps per Second: 10,765.74497

Timestep Collection Time: 2.16985
Timestep Consumption Time: 2.47767
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.64752

Cumulative Model Updates: 88,822
Cumulative Timesteps: 740,831,944

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 740831944...
Checkpoint 740831944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.96790
Policy Entropy: 3.27094
Value Function Loss: 0.00428

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.53645
Value Function Update Magnitude: 0.58148

Collected Steps per Second: 22,763.46085
Overall Steps per Second: 10,633.07122

Timestep Collection Time: 2.19729
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.70400

Cumulative Model Updates: 88,828
Cumulative Timesteps: 740,881,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.03949
Policy Entropy: 3.25715
Value Function Loss: 0.00414

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.53211
Value Function Update Magnitude: 0.56271

Collected Steps per Second: 22,682.78605
Overall Steps per Second: 10,642.82823

Timestep Collection Time: 2.20546
Timestep Consumption Time: 2.49498
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.70044

Cumulative Model Updates: 88,834
Cumulative Timesteps: 740,931,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 740931988...
Checkpoint 740931988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.77236
Policy Entropy: 3.23560
Value Function Loss: 0.00413

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.53340
Value Function Update Magnitude: 0.56958

Collected Steps per Second: 22,182.33688
Overall Steps per Second: 10,480.35147

Timestep Collection Time: 2.25441
Timestep Consumption Time: 2.51719
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.77160

Cumulative Model Updates: 88,840
Cumulative Timesteps: 740,981,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.80526
Policy Entropy: 3.23912
Value Function Loss: 0.00403

Mean KL Divergence: 0.00788
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.53914
Value Function Update Magnitude: 0.59439

Collected Steps per Second: 22,506.01924
Overall Steps per Second: 10,557.89667

Timestep Collection Time: 2.22287
Timestep Consumption Time: 2.51557
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.73844

Cumulative Model Updates: 88,846
Cumulative Timesteps: 741,032,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 741032024...
Checkpoint 741032024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.91064
Policy Entropy: 3.22479
Value Function Loss: 0.00411

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.54750
Value Function Update Magnitude: 0.60560

Collected Steps per Second: 22,385.24463
Overall Steps per Second: 10,502.93462

Timestep Collection Time: 2.23424
Timestep Consumption Time: 2.52767
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.76191

Cumulative Model Updates: 88,852
Cumulative Timesteps: 741,082,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.26908
Policy Entropy: 3.23462
Value Function Loss: 0.00406

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.55184
Value Function Update Magnitude: 0.58890

Collected Steps per Second: 22,582.66499
Overall Steps per Second: 10,551.39297

Timestep Collection Time: 2.21497
Timestep Consumption Time: 2.52563
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.74061

Cumulative Model Updates: 88,858
Cumulative Timesteps: 741,132,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 741132058...
Checkpoint 741132058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827.67464
Policy Entropy: 3.20271
Value Function Loss: 0.00406

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.59311

Collected Steps per Second: 22,370.22321
Overall Steps per Second: 10,538.75615

Timestep Collection Time: 2.23628
Timestep Consumption Time: 2.51058
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.74686

Cumulative Model Updates: 88,864
Cumulative Timesteps: 741,182,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.11642
Policy Entropy: 3.21493
Value Function Loss: 0.00424

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10209
Policy Update Magnitude: 0.56085
Value Function Update Magnitude: 0.61294

Collected Steps per Second: 23,087.14247
Overall Steps per Second: 10,772.62420

Timestep Collection Time: 2.16692
Timestep Consumption Time: 2.47707
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.64399

Cumulative Model Updates: 88,870
Cumulative Timesteps: 741,232,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 741232112...
Checkpoint 741232112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.01472
Policy Entropy: 3.21311
Value Function Loss: 0.00437

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.55865
Value Function Update Magnitude: 0.60977

Collected Steps per Second: 22,619.86553
Overall Steps per Second: 10,718.48841

Timestep Collection Time: 2.21151
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.66708

Cumulative Model Updates: 88,876
Cumulative Timesteps: 741,282,136

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.64896
Policy Entropy: 3.23874
Value Function Loss: 0.00429

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.55317
Value Function Update Magnitude: 0.61590

Collected Steps per Second: 23,151.73688
Overall Steps per Second: 10,733.48653

Timestep Collection Time: 2.16018
Timestep Consumption Time: 2.49925
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.65944

Cumulative Model Updates: 88,882
Cumulative Timesteps: 741,332,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 741332148...
Checkpoint 741332148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.40698
Policy Entropy: 3.21805
Value Function Loss: 0.00436

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.14594
Policy Update Magnitude: 0.54883
Value Function Update Magnitude: 0.61980

Collected Steps per Second: 22,755.04296
Overall Steps per Second: 10,605.61439

Timestep Collection Time: 2.19758
Timestep Consumption Time: 2.51747
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.71505

Cumulative Model Updates: 88,888
Cumulative Timesteps: 741,382,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.10818
Policy Entropy: 3.21363
Value Function Loss: 0.00439

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.62280

Collected Steps per Second: 23,108.54618
Overall Steps per Second: 10,755.19592

Timestep Collection Time: 2.16465
Timestep Consumption Time: 2.48631
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.65096

Cumulative Model Updates: 88,894
Cumulative Timesteps: 741,432,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 741432176...
Checkpoint 741432176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.44973
Policy Entropy: 3.20155
Value Function Loss: 0.00435

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.64205

Collected Steps per Second: 22,680.68857
Overall Steps per Second: 10,620.17654

Timestep Collection Time: 2.20593
Timestep Consumption Time: 2.50510
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.71103

Cumulative Model Updates: 88,900
Cumulative Timesteps: 741,482,208

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 612.61185
Policy Entropy: 3.22193
Value Function Loss: 0.00440

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.63323

Collected Steps per Second: 22,725.84163
Overall Steps per Second: 10,641.80654

Timestep Collection Time: 2.20111
Timestep Consumption Time: 2.49941
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.70052

Cumulative Model Updates: 88,906
Cumulative Timesteps: 741,532,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 741532230...
Checkpoint 741532230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.16804
Policy Entropy: 3.22222
Value Function Loss: 0.00423

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.55442
Value Function Update Magnitude: 0.62047

Collected Steps per Second: 22,101.73425
Overall Steps per Second: 10,484.09157

Timestep Collection Time: 2.26335
Timestep Consumption Time: 2.50807
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.77142

Cumulative Model Updates: 88,912
Cumulative Timesteps: 741,582,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803.09141
Policy Entropy: 3.21786
Value Function Loss: 0.00424

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11047
Policy Update Magnitude: 0.55158
Value Function Update Magnitude: 0.60537

Collected Steps per Second: 22,529.66782
Overall Steps per Second: 10,538.35939

Timestep Collection Time: 2.22001
Timestep Consumption Time: 2.52608
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.74609

Cumulative Model Updates: 88,918
Cumulative Timesteps: 741,632,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 741632270...
Checkpoint 741632270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.15079
Policy Entropy: 3.22330
Value Function Loss: 0.00426

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.54580
Value Function Update Magnitude: 0.59981

Collected Steps per Second: 22,253.66599
Overall Steps per Second: 10,555.23878

Timestep Collection Time: 2.24754
Timestep Consumption Time: 2.49096
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.73850

Cumulative Model Updates: 88,924
Cumulative Timesteps: 741,682,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.07145
Policy Entropy: 3.22544
Value Function Loss: 0.00434

Mean KL Divergence: 0.01259
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.54081
Value Function Update Magnitude: 0.60638

Collected Steps per Second: 22,719.74565
Overall Steps per Second: 10,589.43823

Timestep Collection Time: 2.20205
Timestep Consumption Time: 2.52247
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.72452

Cumulative Model Updates: 88,930
Cumulative Timesteps: 741,732,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 741732316...
Checkpoint 741732316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.66975
Policy Entropy: 3.22004
Value Function Loss: 0.00426

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10572
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.62118

Collected Steps per Second: 22,050.09364
Overall Steps per Second: 10,553.67268

Timestep Collection Time: 2.26874
Timestep Consumption Time: 2.47141
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.74015

Cumulative Model Updates: 88,936
Cumulative Timesteps: 741,782,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.15217
Policy Entropy: 3.21671
Value Function Loss: 0.00428

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.55578
Value Function Update Magnitude: 0.63709

Collected Steps per Second: 22,776.85778
Overall Steps per Second: 10,603.08265

Timestep Collection Time: 2.19609
Timestep Consumption Time: 2.52141
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.71750

Cumulative Model Updates: 88,942
Cumulative Timesteps: 741,832,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 741832362...
Checkpoint 741832362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.49463
Policy Entropy: 3.20203
Value Function Loss: 0.00428

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.55496
Value Function Update Magnitude: 0.64295

Collected Steps per Second: 22,766.64814
Overall Steps per Second: 10,638.29561

Timestep Collection Time: 2.19628
Timestep Consumption Time: 2.50391
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.70019

Cumulative Model Updates: 88,948
Cumulative Timesteps: 741,882,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.91769
Policy Entropy: 3.22080
Value Function Loss: 0.00448

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08911
Policy Update Magnitude: 0.55682
Value Function Update Magnitude: 0.65853

Collected Steps per Second: 22,587.67118
Overall Steps per Second: 10,746.88671

Timestep Collection Time: 2.21431
Timestep Consumption Time: 2.43969
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.65400

Cumulative Model Updates: 88,954
Cumulative Timesteps: 741,932,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 741932380...
Checkpoint 741932380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 943.35866
Policy Entropy: 3.21363
Value Function Loss: 0.00456

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.08480
Policy Update Magnitude: 0.56456
Value Function Update Magnitude: 0.66676

Collected Steps per Second: 22,708.07427
Overall Steps per Second: 10,630.12396

Timestep Collection Time: 2.20283
Timestep Consumption Time: 2.50285
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.70568

Cumulative Model Updates: 88,960
Cumulative Timesteps: 741,982,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717.03509
Policy Entropy: 3.21713
Value Function Loss: 0.00455

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.56469
Value Function Update Magnitude: 0.68001

Collected Steps per Second: 22,536.98202
Overall Steps per Second: 10,638.30353

Timestep Collection Time: 2.21884
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.70056

Cumulative Model Updates: 88,966
Cumulative Timesteps: 742,032,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 742032408...
Checkpoint 742032408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.93723
Policy Entropy: 3.19020
Value Function Loss: 0.00446

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09567
Policy Update Magnitude: 0.56998
Value Function Update Magnitude: 0.66471

Collected Steps per Second: 22,690.92524
Overall Steps per Second: 10,804.69883

Timestep Collection Time: 2.20423
Timestep Consumption Time: 2.42487
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.62910

Cumulative Model Updates: 88,972
Cumulative Timesteps: 742,082,424

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,540.96884
Policy Entropy: 3.19310
Value Function Loss: 0.00441

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09334
Policy Update Magnitude: 0.57789
Value Function Update Magnitude: 0.64912

Collected Steps per Second: 22,493.75189
Overall Steps per Second: 10,599.02729

Timestep Collection Time: 2.22355
Timestep Consumption Time: 2.49537
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.71892

Cumulative Model Updates: 88,978
Cumulative Timesteps: 742,132,440

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 742132440...
Checkpoint 742132440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.18118
Policy Entropy: 3.19246
Value Function Loss: 0.00445

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.57794
Value Function Update Magnitude: 0.63379

Collected Steps per Second: 22,172.30133
Overall Steps per Second: 10,605.27741

Timestep Collection Time: 2.25606
Timestep Consumption Time: 2.46065
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.71671

Cumulative Model Updates: 88,984
Cumulative Timesteps: 742,182,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.46239
Policy Entropy: 3.19907
Value Function Loss: 0.00443

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.57436
Value Function Update Magnitude: 0.64167

Collected Steps per Second: 22,781.29650
Overall Steps per Second: 10,785.95484

Timestep Collection Time: 2.19478
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.63566

Cumulative Model Updates: 88,990
Cumulative Timesteps: 742,232,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 742232462...
Checkpoint 742232462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.83709
Policy Entropy: 3.21557
Value Function Loss: 0.00438

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.57914
Value Function Update Magnitude: 0.64882

Collected Steps per Second: 22,439.67929
Overall Steps per Second: 10,751.11701

Timestep Collection Time: 2.22935
Timestep Consumption Time: 2.42374
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.65310

Cumulative Model Updates: 88,996
Cumulative Timesteps: 742,282,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755.00709
Policy Entropy: 3.23435
Value Function Loss: 0.00411

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.13177
Policy Update Magnitude: 0.55908
Value Function Update Magnitude: 0.63772

Collected Steps per Second: 22,984.71995
Overall Steps per Second: 10,806.40928

Timestep Collection Time: 2.17571
Timestep Consumption Time: 2.45192
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.62762

Cumulative Model Updates: 89,002
Cumulative Timesteps: 742,332,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 742332496...
Checkpoint 742332496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.33798
Policy Entropy: 3.24243
Value Function Loss: 0.00383

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.54318
Value Function Update Magnitude: 0.59994

Collected Steps per Second: 22,176.68445
Overall Steps per Second: 10,680.90868

Timestep Collection Time: 2.25561
Timestep Consumption Time: 2.42770
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.68331

Cumulative Model Updates: 89,008
Cumulative Timesteps: 742,382,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.61417
Policy Entropy: 3.24467
Value Function Loss: 0.00387

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.54580
Value Function Update Magnitude: 0.59540

Collected Steps per Second: 21,755.96009
Overall Steps per Second: 10,466.59582

Timestep Collection Time: 2.29822
Timestep Consumption Time: 2.47888
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.77710

Cumulative Model Updates: 89,014
Cumulative Timesteps: 742,432,518

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 742432518...
Checkpoint 742432518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,011.95708
Policy Entropy: 3.24371
Value Function Loss: 0.00392

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.61403

Collected Steps per Second: 22,885.23273
Overall Steps per Second: 10,678.24234

Timestep Collection Time: 2.18613
Timestep Consumption Time: 2.49910
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.68523

Cumulative Model Updates: 89,020
Cumulative Timesteps: 742,482,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.13920
Policy Entropy: 3.25776
Value Function Loss: 0.00414

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.55435
Value Function Update Magnitude: 0.60204

Collected Steps per Second: 22,756.73980
Overall Steps per Second: 10,815.44957

Timestep Collection Time: 2.19829
Timestep Consumption Time: 2.42713
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.62542

Cumulative Model Updates: 89,026
Cumulative Timesteps: 742,532,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 742532574...
Checkpoint 742532574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 910.18714
Policy Entropy: 3.25483
Value Function Loss: 0.00418

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.59820

Collected Steps per Second: 22,674.79763
Overall Steps per Second: 10,755.42095

Timestep Collection Time: 2.20641
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.65161

Cumulative Model Updates: 89,032
Cumulative Timesteps: 742,582,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.10016
Policy Entropy: 3.24813
Value Function Loss: 0.00438

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.55273
Value Function Update Magnitude: 0.60035

Collected Steps per Second: 22,785.13326
Overall Steps per Second: 10,821.59079

Timestep Collection Time: 2.19450
Timestep Consumption Time: 2.42608
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.62058

Cumulative Model Updates: 89,038
Cumulative Timesteps: 742,632,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 742632606...
Checkpoint 742632606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.04054
Policy Entropy: 3.24464
Value Function Loss: 0.00429

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.55167
Value Function Update Magnitude: 0.60068

Collected Steps per Second: 22,379.57824
Overall Steps per Second: 10,736.45040

Timestep Collection Time: 2.23534
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.65945

Cumulative Model Updates: 89,044
Cumulative Timesteps: 742,682,632

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.49101
Policy Entropy: 3.24613
Value Function Loss: 0.00421

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.54865
Value Function Update Magnitude: 0.58695

Collected Steps per Second: 22,364.93916
Overall Steps per Second: 10,564.02704

Timestep Collection Time: 2.23627
Timestep Consumption Time: 2.49810
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.73437

Cumulative Model Updates: 89,050
Cumulative Timesteps: 742,732,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 742732646...
Checkpoint 742732646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 611.33993
Policy Entropy: 3.24619
Value Function Loss: 0.00418

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.54961
Value Function Update Magnitude: 0.59215

Collected Steps per Second: 22,256.67994
Overall Steps per Second: 10,533.37313

Timestep Collection Time: 2.24688
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.74758

Cumulative Model Updates: 89,056
Cumulative Timesteps: 742,782,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.67076
Policy Entropy: 3.24082
Value Function Loss: 0.00415

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.55812
Value Function Update Magnitude: 0.60544

Collected Steps per Second: 22,556.74773
Overall Steps per Second: 10,643.25440

Timestep Collection Time: 2.21716
Timestep Consumption Time: 2.48178
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.69894

Cumulative Model Updates: 89,062
Cumulative Timesteps: 742,832,666

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 742832666...
Checkpoint 742832666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,588.02803
Policy Entropy: 3.24405
Value Function Loss: 0.00422

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.55336
Value Function Update Magnitude: 0.60722

Collected Steps per Second: 22,384.72337
Overall Steps per Second: 10,600.82748

Timestep Collection Time: 2.23501
Timestep Consumption Time: 2.48444
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.71944

Cumulative Model Updates: 89,068
Cumulative Timesteps: 742,882,696

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.19221
Policy Entropy: 3.25974
Value Function Loss: 0.00429

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.55388
Value Function Update Magnitude: 0.58287

Collected Steps per Second: 22,721.68440
Overall Steps per Second: 10,696.17814

Timestep Collection Time: 2.20142
Timestep Consumption Time: 2.47502
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.67644

Cumulative Model Updates: 89,074
Cumulative Timesteps: 742,932,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 742932716...
Checkpoint 742932716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 824.25862
Policy Entropy: 3.23306
Value Function Loss: 0.00432

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.55836
Value Function Update Magnitude: 0.59081

Collected Steps per Second: 22,727.70760
Overall Steps per Second: 10,668.42120

Timestep Collection Time: 2.20022
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.68729

Cumulative Model Updates: 89,080
Cumulative Timesteps: 742,982,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.14266
Policy Entropy: 3.23608
Value Function Loss: 0.00449

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.56045
Value Function Update Magnitude: 0.61758

Collected Steps per Second: 22,851.67384
Overall Steps per Second: 10,781.31030

Timestep Collection Time: 2.18916
Timestep Consumption Time: 2.45091
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.64007

Cumulative Model Updates: 89,086
Cumulative Timesteps: 743,032,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 743032748...
Checkpoint 743032748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.42869
Policy Entropy: 3.24134
Value Function Loss: 0.00461

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.57163
Value Function Update Magnitude: 0.63363

Collected Steps per Second: 22,930.82498
Overall Steps per Second: 10,776.15298

Timestep Collection Time: 2.18117
Timestep Consumption Time: 2.46019
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.64136

Cumulative Model Updates: 89,092
Cumulative Timesteps: 743,082,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.43467
Policy Entropy: 3.25344
Value Function Loss: 0.00455

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.57032
Value Function Update Magnitude: 0.62567

Collected Steps per Second: 22,005.43014
Overall Steps per Second: 10,459.95423

Timestep Collection Time: 2.27317
Timestep Consumption Time: 2.50907
PPO Batch Consumption Time: 0.29708
Total Iteration Time: 4.78224

Cumulative Model Updates: 89,098
Cumulative Timesteps: 743,132,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 743132786...
Checkpoint 743132786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.29126
Policy Entropy: 3.25794
Value Function Loss: 0.00457

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08861
Policy Update Magnitude: 0.56484
Value Function Update Magnitude: 0.61385

Collected Steps per Second: 22,377.05303
Overall Steps per Second: 10,627.44615

Timestep Collection Time: 2.23542
Timestep Consumption Time: 2.47145
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.70687

Cumulative Model Updates: 89,104
Cumulative Timesteps: 743,182,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.50054
Policy Entropy: 3.26022
Value Function Loss: 0.00444

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.55941
Value Function Update Magnitude: 0.61211

Collected Steps per Second: 22,155.09140
Overall Steps per Second: 10,476.27899

Timestep Collection Time: 2.25745
Timestep Consumption Time: 2.51657
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.77402

Cumulative Model Updates: 89,110
Cumulative Timesteps: 743,232,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 743232822...
Checkpoint 743232822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.36539
Policy Entropy: 3.26326
Value Function Loss: 0.00452

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.55509
Value Function Update Magnitude: 0.61016

Collected Steps per Second: 22,179.49932
Overall Steps per Second: 10,553.11073

Timestep Collection Time: 2.25442
Timestep Consumption Time: 2.48370
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.73813

Cumulative Model Updates: 89,116
Cumulative Timesteps: 743,282,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.68342
Policy Entropy: 3.28426
Value Function Loss: 0.00436

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.54907
Value Function Update Magnitude: 0.62449

Collected Steps per Second: 22,778.76417
Overall Steps per Second: 10,569.74225

Timestep Collection Time: 2.19538
Timestep Consumption Time: 2.53586
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.73124

Cumulative Model Updates: 89,122
Cumulative Timesteps: 743,332,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 743332832...
Checkpoint 743332832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.58087
Policy Entropy: 3.27343
Value Function Loss: 0.00433

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10485
Policy Update Magnitude: 0.54278
Value Function Update Magnitude: 0.62495

Collected Steps per Second: 22,503.84748
Overall Steps per Second: 10,572.24568

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.50863
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.73145

Cumulative Model Updates: 89,128
Cumulative Timesteps: 743,382,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.35380
Policy Entropy: 3.26281
Value Function Loss: 0.00404

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.63143

Collected Steps per Second: 22,854.15257
Overall Steps per Second: 10,707.88512

Timestep Collection Time: 2.18919
Timestep Consumption Time: 2.48326
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.67244

Cumulative Model Updates: 89,134
Cumulative Timesteps: 743,432,886

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 743432886...
Checkpoint 743432886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,817.96679
Policy Entropy: 3.24367
Value Function Loss: 0.00406

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.54105
Value Function Update Magnitude: 0.62582

Collected Steps per Second: 22,589.98211
Overall Steps per Second: 10,798.94085

Timestep Collection Time: 2.21337
Timestep Consumption Time: 2.41671
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.63008

Cumulative Model Updates: 89,140
Cumulative Timesteps: 743,482,886

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.31163
Policy Entropy: 3.24146
Value Function Loss: 0.00418

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.54792
Value Function Update Magnitude: 0.61410

Collected Steps per Second: 22,637.59063
Overall Steps per Second: 10,625.16551

Timestep Collection Time: 2.20995
Timestep Consumption Time: 2.49849
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.70844

Cumulative Model Updates: 89,146
Cumulative Timesteps: 743,532,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 743532914...
Checkpoint 743532914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 711.96575
Policy Entropy: 3.23600
Value Function Loss: 0.00428

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11685
Policy Update Magnitude: 0.55066
Value Function Update Magnitude: 0.60684

Collected Steps per Second: 22,498.80502
Overall Steps per Second: 10,595.30102

Timestep Collection Time: 2.22305
Timestep Consumption Time: 2.49753
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.72058

Cumulative Model Updates: 89,152
Cumulative Timesteps: 743,582,930

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.37688
Policy Entropy: 3.24140
Value Function Loss: 0.00415

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.61128

Collected Steps per Second: 22,632.01868
Overall Steps per Second: 10,756.05123

Timestep Collection Time: 2.20926
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.64855

Cumulative Model Updates: 89,158
Cumulative Timesteps: 743,632,930

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 743632930...
Checkpoint 743632930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.93929
Policy Entropy: 3.25225
Value Function Loss: 0.00407

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10913
Policy Update Magnitude: 0.54383
Value Function Update Magnitude: 0.62144

Collected Steps per Second: 22,171.95712
Overall Steps per Second: 10,660.70901

Timestep Collection Time: 2.25555
Timestep Consumption Time: 2.43551
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.69106

Cumulative Model Updates: 89,164
Cumulative Timesteps: 743,682,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.94979
Policy Entropy: 3.25327
Value Function Loss: 0.00401

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.54468
Value Function Update Magnitude: 0.62612

Collected Steps per Second: 21,950.45840
Overall Steps per Second: 10,552.60347

Timestep Collection Time: 2.27877
Timestep Consumption Time: 2.46129
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.74006

Cumulative Model Updates: 89,170
Cumulative Timesteps: 743,732,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 743732960...
Checkpoint 743732960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.63941
Policy Entropy: 3.25065
Value Function Loss: 0.00427

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.54681
Value Function Update Magnitude: 0.61992

Collected Steps per Second: 22,419.77938
Overall Steps per Second: 10,606.36434

Timestep Collection Time: 2.23151
Timestep Consumption Time: 2.48547
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.71698

Cumulative Model Updates: 89,176
Cumulative Timesteps: 743,782,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.00590
Policy Entropy: 3.25359
Value Function Loss: 0.00396

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.54374
Value Function Update Magnitude: 0.61044

Collected Steps per Second: 22,381.68396
Overall Steps per Second: 10,596.05320

Timestep Collection Time: 2.23468
Timestep Consumption Time: 2.48556
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.72025

Cumulative Model Updates: 89,182
Cumulative Timesteps: 743,833,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 743833006...
Checkpoint 743833006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,941.59193
Policy Entropy: 3.26856
Value Function Loss: 0.00391

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.53417
Value Function Update Magnitude: 0.59778

Collected Steps per Second: 22,357.47856
Overall Steps per Second: 10,522.67042

Timestep Collection Time: 2.23728
Timestep Consumption Time: 2.51626
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.75355

Cumulative Model Updates: 89,188
Cumulative Timesteps: 743,883,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.03129
Policy Entropy: 3.26748
Value Function Loss: 0.00390

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.53016
Value Function Update Magnitude: 0.57689

Collected Steps per Second: 22,942.12338
Overall Steps per Second: 10,749.93052

Timestep Collection Time: 2.17948
Timestep Consumption Time: 2.47189
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.65138

Cumulative Model Updates: 89,194
Cumulative Timesteps: 743,933,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 743933028...
Checkpoint 743933028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632.73843
Policy Entropy: 3.26858
Value Function Loss: 0.00428

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.53293
Value Function Update Magnitude: 0.58395

Collected Steps per Second: 22,642.48306
Overall Steps per Second: 10,782.29050

Timestep Collection Time: 2.20921
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.63927

Cumulative Model Updates: 89,200
Cumulative Timesteps: 743,983,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.76311
Policy Entropy: 3.25972
Value Function Loss: 0.00448

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.54120
Value Function Update Magnitude: 0.61082

Collected Steps per Second: 22,910.79313
Overall Steps per Second: 10,793.34472

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.45060
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.63341

Cumulative Model Updates: 89,206
Cumulative Timesteps: 744,033,060

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 744033060...
Checkpoint 744033060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.08793
Policy Entropy: 3.26718
Value Function Loss: 0.00449

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.55587
Value Function Update Magnitude: 0.66155

Collected Steps per Second: 22,638.81024
Overall Steps per Second: 10,752.81506

Timestep Collection Time: 2.20975
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.65236

Cumulative Model Updates: 89,212
Cumulative Timesteps: 744,083,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.30793
Policy Entropy: 3.26058
Value Function Loss: 0.00445

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.68024

Collected Steps per Second: 22,077.65797
Overall Steps per Second: 10,764.67921

Timestep Collection Time: 2.26537
Timestep Consumption Time: 2.38075
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.64612

Cumulative Model Updates: 89,218
Cumulative Timesteps: 744,133,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 744133100...
Checkpoint 744133100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.54141
Policy Entropy: 3.25576
Value Function Loss: 0.00415

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08905
Policy Update Magnitude: 0.55717
Value Function Update Magnitude: 0.65492

Collected Steps per Second: 22,030.97567
Overall Steps per Second: 10,803.33912

Timestep Collection Time: 2.27053
Timestep Consumption Time: 2.35970
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.63024

Cumulative Model Updates: 89,224
Cumulative Timesteps: 744,183,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.08869
Policy Entropy: 3.26001
Value Function Loss: 0.00403

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08391
Policy Update Magnitude: 0.55056
Value Function Update Magnitude: 0.61794

Collected Steps per Second: 21,870.96185
Overall Steps per Second: 10,609.62213

Timestep Collection Time: 2.28632
Timestep Consumption Time: 2.42676
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.71308

Cumulative Model Updates: 89,230
Cumulative Timesteps: 744,233,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 744233126...
Checkpoint 744233126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.40057
Policy Entropy: 3.26350
Value Function Loss: 0.00409

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07924
Policy Update Magnitude: 0.53989
Value Function Update Magnitude: 0.60820

Collected Steps per Second: 21,794.45201
Overall Steps per Second: 10,608.10391

Timestep Collection Time: 2.29453
Timestep Consumption Time: 2.41960
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.71413

Cumulative Model Updates: 89,236
Cumulative Timesteps: 744,283,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.89076
Policy Entropy: 3.25563
Value Function Loss: 0.00419

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08419
Policy Update Magnitude: 0.54317
Value Function Update Magnitude: 0.61841

Collected Steps per Second: 21,432.12772
Overall Steps per Second: 10,514.10187

Timestep Collection Time: 2.33369
Timestep Consumption Time: 2.42335
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.75704

Cumulative Model Updates: 89,242
Cumulative Timesteps: 744,333,150

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 744333150...
Checkpoint 744333150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883.37809
Policy Entropy: 3.25059
Value Function Loss: 0.00446

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.54446
Value Function Update Magnitude: 0.62476

Collected Steps per Second: 21,605.54827
Overall Steps per Second: 10,495.62188

Timestep Collection Time: 2.31533
Timestep Consumption Time: 2.45085
PPO Batch Consumption Time: 0.29689
Total Iteration Time: 4.76618

Cumulative Model Updates: 89,248
Cumulative Timesteps: 744,383,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.94190
Policy Entropy: 3.23942
Value Function Loss: 0.00431

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08094
Policy Update Magnitude: 0.55560
Value Function Update Magnitude: 0.62916

Collected Steps per Second: 21,837.52365
Overall Steps per Second: 10,619.51923

Timestep Collection Time: 2.29028
Timestep Consumption Time: 2.41935
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.70963

Cumulative Model Updates: 89,254
Cumulative Timesteps: 744,433,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 744433188...
Checkpoint 744433188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.10413
Policy Entropy: 3.24398
Value Function Loss: 0.00426

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08603
Policy Update Magnitude: 0.56144
Value Function Update Magnitude: 0.62322

Collected Steps per Second: 22,187.52039
Overall Steps per Second: 10,726.93126

Timestep Collection Time: 2.25406
Timestep Consumption Time: 2.40822
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.66228

Cumulative Model Updates: 89,260
Cumulative Timesteps: 744,483,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.47637
Policy Entropy: 3.24362
Value Function Loss: 0.00400

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.55357
Value Function Update Magnitude: 0.62794

Collected Steps per Second: 22,138.09296
Overall Steps per Second: 10,591.07528

Timestep Collection Time: 2.25864
Timestep Consumption Time: 2.46250
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.72114

Cumulative Model Updates: 89,266
Cumulative Timesteps: 744,533,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 744533202...
Checkpoint 744533202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,151.25816
Policy Entropy: 3.24656
Value Function Loss: 0.00394

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.55207
Value Function Update Magnitude: 0.61981

Collected Steps per Second: 22,067.14638
Overall Steps per Second: 10,595.45603

Timestep Collection Time: 2.26617
Timestep Consumption Time: 2.45358
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.71976

Cumulative Model Updates: 89,272
Cumulative Timesteps: 744,583,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.00296
Policy Entropy: 3.24374
Value Function Loss: 0.00403

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.54597
Value Function Update Magnitude: 0.59646

Collected Steps per Second: 22,189.33337
Overall Steps per Second: 10,649.96642

Timestep Collection Time: 2.25460
Timestep Consumption Time: 2.44288
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.69748

Cumulative Model Updates: 89,278
Cumulative Timesteps: 744,633,238

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 744633238...
Checkpoint 744633238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.20254
Policy Entropy: 3.25329
Value Function Loss: 0.00384

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.53774
Value Function Update Magnitude: 0.56506

Collected Steps per Second: 22,090.86886
Overall Steps per Second: 10,693.56951

Timestep Collection Time: 2.26465
Timestep Consumption Time: 2.41368
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.67833

Cumulative Model Updates: 89,284
Cumulative Timesteps: 744,683,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.96982
Policy Entropy: 3.24046
Value Function Loss: 0.00400

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.54015
Value Function Update Magnitude: 0.55663

Collected Steps per Second: 22,968.26312
Overall Steps per Second: 10,663.69041

Timestep Collection Time: 2.17727
Timestep Consumption Time: 2.51229
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.68956

Cumulative Model Updates: 89,290
Cumulative Timesteps: 744,733,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 744733274...
Checkpoint 744733274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781.83436
Policy Entropy: 3.24251
Value Function Loss: 0.00408

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.54192
Value Function Update Magnitude: 0.58125

Collected Steps per Second: 22,663.51344
Overall Steps per Second: 10,661.32490

Timestep Collection Time: 2.20663
Timestep Consumption Time: 2.48416
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.69079

Cumulative Model Updates: 89,296
Cumulative Timesteps: 744,783,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.77957
Policy Entropy: 3.23580
Value Function Loss: 0.00431

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09415
Policy Update Magnitude: 0.55370
Value Function Update Magnitude: 0.61489

Collected Steps per Second: 21,595.26213
Overall Steps per Second: 10,476.85767

Timestep Collection Time: 2.31625
Timestep Consumption Time: 2.45808
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.77433

Cumulative Model Updates: 89,302
Cumulative Timesteps: 744,833,304

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 744833304...
Checkpoint 744833304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.03891
Policy Entropy: 3.25771
Value Function Loss: 0.00418

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.62204

Collected Steps per Second: 22,601.08666
Overall Steps per Second: 10,581.01254

Timestep Collection Time: 2.21237
Timestep Consumption Time: 2.51326
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.72563

Cumulative Model Updates: 89,308
Cumulative Timesteps: 744,883,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.24733
Policy Entropy: 3.24442
Value Function Loss: 0.00413

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09566
Policy Update Magnitude: 0.55527
Value Function Update Magnitude: 0.61985

Collected Steps per Second: 21,496.85522
Overall Steps per Second: 10,483.68995

Timestep Collection Time: 2.32667
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.77084

Cumulative Model Updates: 89,314
Cumulative Timesteps: 744,933,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 744933322...
Checkpoint 744933322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.22269
Policy Entropy: 3.24699
Value Function Loss: 0.00408

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.07761
Policy Update Magnitude: 0.56386
Value Function Update Magnitude: 0.61828

Collected Steps per Second: 22,187.59813
Overall Steps per Second: 10,601.97291

Timestep Collection Time: 2.25360
Timestep Consumption Time: 2.46269
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.71629

Cumulative Model Updates: 89,320
Cumulative Timesteps: 744,983,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.34252
Policy Entropy: 3.23949
Value Function Loss: 0.00407

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07789
Policy Update Magnitude: 0.56223
Value Function Update Magnitude: 0.61727

Collected Steps per Second: 22,152.74022
Overall Steps per Second: 10,509.36939

Timestep Collection Time: 2.25715
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.75785

Cumulative Model Updates: 89,326
Cumulative Timesteps: 745,033,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 745033326...
Checkpoint 745033326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.36150
Policy Entropy: 3.25128
Value Function Loss: 0.00425

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08383
Policy Update Magnitude: 0.55930
Value Function Update Magnitude: 0.60845

Collected Steps per Second: 22,224.73953
Overall Steps per Second: 10,649.15444

Timestep Collection Time: 2.25020
Timestep Consumption Time: 2.44595
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.69615

Cumulative Model Updates: 89,332
Cumulative Timesteps: 745,083,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.36383
Policy Entropy: 3.26019
Value Function Loss: 0.00446

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.56236
Value Function Update Magnitude: 0.60425

Collected Steps per Second: 22,698.96669
Overall Steps per Second: 10,588.79676

Timestep Collection Time: 2.20327
Timestep Consumption Time: 2.51983
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.72311

Cumulative Model Updates: 89,338
Cumulative Timesteps: 745,133,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 745133348...
Checkpoint 745133348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.05358
Policy Entropy: 3.26152
Value Function Loss: 0.00447

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.56414
Value Function Update Magnitude: 0.60556

Collected Steps per Second: 22,574.13786
Overall Steps per Second: 10,568.81342

Timestep Collection Time: 2.21528
Timestep Consumption Time: 2.51638
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.73166

Cumulative Model Updates: 89,344
Cumulative Timesteps: 745,183,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.79929
Policy Entropy: 3.26759
Value Function Loss: 0.00445

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.59461

Collected Steps per Second: 22,967.63725
Overall Steps per Second: 10,739.54831

Timestep Collection Time: 2.17828
Timestep Consumption Time: 2.48020
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.65848

Cumulative Model Updates: 89,350
Cumulative Timesteps: 745,233,386

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 745233386...
Checkpoint 745233386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.23512
Policy Entropy: 3.25917
Value Function Loss: 0.00437

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.55440
Value Function Update Magnitude: 0.61307

Collected Steps per Second: 22,612.18435
Overall Steps per Second: 10,746.01466

Timestep Collection Time: 2.21146
Timestep Consumption Time: 2.44198
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.65345

Cumulative Model Updates: 89,356
Cumulative Timesteps: 745,283,392

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.49603
Policy Entropy: 3.25422
Value Function Loss: 0.00423

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08317
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.60651

Collected Steps per Second: 22,710.67823
Overall Steps per Second: 10,633.14243

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.50157
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.70397

Cumulative Model Updates: 89,362
Cumulative Timesteps: 745,333,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 745333410...
Checkpoint 745333410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.47103
Policy Entropy: 3.25604
Value Function Loss: 0.00420

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.59799

Collected Steps per Second: 23,372.86308
Overall Steps per Second: 10,878.84629

Timestep Collection Time: 2.13923
Timestep Consumption Time: 2.45684
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.59608

Cumulative Model Updates: 89,368
Cumulative Timesteps: 745,383,410

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.80060
Policy Entropy: 3.25264
Value Function Loss: 0.00440

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09009
Policy Update Magnitude: 0.54309
Value Function Update Magnitude: 0.61740

Collected Steps per Second: 22,808.74750
Overall Steps per Second: 10,681.88823

Timestep Collection Time: 2.19223
Timestep Consumption Time: 2.48878
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.68101

Cumulative Model Updates: 89,374
Cumulative Timesteps: 745,433,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 745433412...
Checkpoint 745433412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.78759
Policy Entropy: 3.25290
Value Function Loss: 0.00424

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.65811

Collected Steps per Second: 22,921.35056
Overall Steps per Second: 10,805.11200

Timestep Collection Time: 2.18163
Timestep Consumption Time: 2.44636
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.62799

Cumulative Model Updates: 89,380
Cumulative Timesteps: 745,483,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.51545
Policy Entropy: 3.24702
Value Function Loss: 0.00411

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.54663
Value Function Update Magnitude: 0.64404

Collected Steps per Second: 22,190.33485
Overall Steps per Second: 10,525.78858

Timestep Collection Time: 2.25404
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.75195

Cumulative Model Updates: 89,386
Cumulative Timesteps: 745,533,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 745533436...
Checkpoint 745533436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,826.23029
Policy Entropy: 3.24842
Value Function Loss: 0.00414

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.08086
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.63287

Collected Steps per Second: 22,301.12938
Overall Steps per Second: 10,663.36394

Timestep Collection Time: 2.24213
Timestep Consumption Time: 2.44701
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.68914

Cumulative Model Updates: 89,392
Cumulative Timesteps: 745,583,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.27134
Policy Entropy: 3.24309
Value Function Loss: 0.00420

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.62328

Collected Steps per Second: 22,342.89085
Overall Steps per Second: 10,511.01679

Timestep Collection Time: 2.23794
Timestep Consumption Time: 2.51917
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.75710

Cumulative Model Updates: 89,398
Cumulative Timesteps: 745,633,440

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 745633440...
Checkpoint 745633440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.29952
Policy Entropy: 3.24189
Value Function Loss: 0.00419

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.56084
Value Function Update Magnitude: 0.62478

Collected Steps per Second: 22,397.86311
Overall Steps per Second: 10,572.27362

Timestep Collection Time: 2.23262
Timestep Consumption Time: 2.49730
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.72992

Cumulative Model Updates: 89,404
Cumulative Timesteps: 745,683,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.56303
Policy Entropy: 3.23951
Value Function Loss: 0.00422

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.56143
Value Function Update Magnitude: 0.63532

Collected Steps per Second: 22,603.70364
Overall Steps per Second: 10,522.11695

Timestep Collection Time: 2.21380
Timestep Consumption Time: 2.54190
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.75570

Cumulative Model Updates: 89,410
Cumulative Timesteps: 745,733,486

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 745733486...
Checkpoint 745733486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.85814
Policy Entropy: 3.23176
Value Function Loss: 0.00408

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.56351
Value Function Update Magnitude: 0.65310

Collected Steps per Second: 22,799.39590
Overall Steps per Second: 10,598.69602

Timestep Collection Time: 2.19401
Timestep Consumption Time: 2.52563
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.71964

Cumulative Model Updates: 89,416
Cumulative Timesteps: 745,783,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.80008
Policy Entropy: 3.23282
Value Function Loss: 0.00416

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.56278
Value Function Update Magnitude: 0.65839

Collected Steps per Second: 22,714.03161
Overall Steps per Second: 10,599.30824

Timestep Collection Time: 2.20216
Timestep Consumption Time: 2.51701
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.71918

Cumulative Model Updates: 89,422
Cumulative Timesteps: 745,833,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 745833528...
Checkpoint 745833528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.77249
Policy Entropy: 3.23939
Value Function Loss: 0.00408

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.56322
Value Function Update Magnitude: 0.65387

Collected Steps per Second: 22,730.48639
Overall Steps per Second: 10,645.51880

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.49842
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.69925

Cumulative Model Updates: 89,428
Cumulative Timesteps: 745,883,554

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.00007
Policy Entropy: 3.23865
Value Function Loss: 0.00437

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.56383
Value Function Update Magnitude: 0.64529

Collected Steps per Second: 22,628.29579
Overall Steps per Second: 10,694.43127

Timestep Collection Time: 2.21006
Timestep Consumption Time: 2.46620
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.67627

Cumulative Model Updates: 89,434
Cumulative Timesteps: 745,933,564

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 745933564...
Checkpoint 745933564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.86787
Policy Entropy: 3.25032
Value Function Loss: 0.00431

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.56253
Value Function Update Magnitude: 0.64807

Collected Steps per Second: 23,047.98761
Overall Steps per Second: 10,655.88784

Timestep Collection Time: 2.17008
Timestep Consumption Time: 2.52366
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.69374

Cumulative Model Updates: 89,440
Cumulative Timesteps: 745,983,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.88810
Policy Entropy: 3.25594
Value Function Loss: 0.00415

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.55836
Value Function Update Magnitude: 0.65561

Collected Steps per Second: 22,735.68363
Overall Steps per Second: 10,650.95657

Timestep Collection Time: 2.20007
Timestep Consumption Time: 2.49623
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.69629

Cumulative Model Updates: 89,446
Cumulative Timesteps: 746,033,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 746033600...
Checkpoint 746033600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.16658
Policy Entropy: 3.25234
Value Function Loss: 0.00391

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10808
Policy Update Magnitude: 0.55180
Value Function Update Magnitude: 0.65236

Collected Steps per Second: 22,558.22403
Overall Steps per Second: 10,560.34127

Timestep Collection Time: 2.21702
Timestep Consumption Time: 2.51881
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.73583

Cumulative Model Updates: 89,452
Cumulative Timesteps: 746,083,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.51041
Policy Entropy: 3.24217
Value Function Loss: 0.00418

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.54834
Value Function Update Magnitude: 0.64100

Collected Steps per Second: 22,369.72173
Overall Steps per Second: 10,598.65490

Timestep Collection Time: 2.23588
Timestep Consumption Time: 2.48321
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.71909

Cumulative Model Updates: 89,458
Cumulative Timesteps: 746,133,628

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 746133628...
Checkpoint 746133628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.48813
Policy Entropy: 3.23834
Value Function Loss: 0.00429

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12219
Policy Update Magnitude: 0.55166
Value Function Update Magnitude: 0.63349

Collected Steps per Second: 22,619.53890
Overall Steps per Second: 10,712.51506

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.45745
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.66837

Cumulative Model Updates: 89,464
Cumulative Timesteps: 746,183,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.22674
Policy Entropy: 3.23087
Value Function Loss: 0.00439

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.55567
Value Function Update Magnitude: 0.61864

Collected Steps per Second: 22,980.95290
Overall Steps per Second: 10,602.73472

Timestep Collection Time: 2.17685
Timestep Consumption Time: 2.54137
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.71822

Cumulative Model Updates: 89,470
Cumulative Timesteps: 746,233,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 746233664...
Checkpoint 746233664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.02768
Policy Entropy: 3.25127
Value Function Loss: 0.00415

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.55854
Value Function Update Magnitude: 0.61809

Collected Steps per Second: 22,022.75797
Overall Steps per Second: 10,561.99660

Timestep Collection Time: 2.27174
Timestep Consumption Time: 2.46505
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.73679

Cumulative Model Updates: 89,476
Cumulative Timesteps: 746,283,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.94180
Policy Entropy: 3.24836
Value Function Loss: 0.00418

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10648
Policy Update Magnitude: 0.54388
Value Function Update Magnitude: 0.62114

Collected Steps per Second: 23,094.19665
Overall Steps per Second: 10,681.80511

Timestep Collection Time: 2.16583
Timestep Consumption Time: 2.51672
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.68254

Cumulative Model Updates: 89,482
Cumulative Timesteps: 746,333,712

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 746333712...
Checkpoint 746333712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.97103
Policy Entropy: 3.24911
Value Function Loss: 0.00401

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09739
Policy Update Magnitude: 0.53565
Value Function Update Magnitude: 0.60171

Collected Steps per Second: 22,698.22893
Overall Steps per Second: 10,630.98047

Timestep Collection Time: 2.20326
Timestep Consumption Time: 2.50092
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.70418

Cumulative Model Updates: 89,488
Cumulative Timesteps: 746,383,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.88586
Policy Entropy: 3.24588
Value Function Loss: 0.00433

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.53650
Value Function Update Magnitude: 0.58564

Collected Steps per Second: 23,002.69137
Overall Steps per Second: 10,753.05130

Timestep Collection Time: 2.17462
Timestep Consumption Time: 2.47727
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.65189

Cumulative Model Updates: 89,494
Cumulative Timesteps: 746,433,744

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 746433744...
Checkpoint 746433744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.27114
Policy Entropy: 3.25536
Value Function Loss: 0.00444

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.54448
Value Function Update Magnitude: 0.59497

Collected Steps per Second: 22,563.42166
Overall Steps per Second: 10,644.35313

Timestep Collection Time: 2.21606
Timestep Consumption Time: 2.48145
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.69751

Cumulative Model Updates: 89,500
Cumulative Timesteps: 746,483,746

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 719.62300
Policy Entropy: 3.25978
Value Function Loss: 0.00459

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.54898
Value Function Update Magnitude: 0.60841

Collected Steps per Second: 22,885.36022
Overall Steps per Second: 10,770.45054

Timestep Collection Time: 2.18524
Timestep Consumption Time: 2.45802
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.64326

Cumulative Model Updates: 89,506
Cumulative Timesteps: 746,533,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 746533756...
Checkpoint 746533756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.48984
Policy Entropy: 3.25414
Value Function Loss: 0.00457

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08771
Policy Update Magnitude: 0.55257
Value Function Update Magnitude: 0.62022

Collected Steps per Second: 22,700.45936
Overall Steps per Second: 10,753.81790

Timestep Collection Time: 2.20260
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.64951

Cumulative Model Updates: 89,512
Cumulative Timesteps: 746,583,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.25115
Policy Entropy: 3.25295
Value Function Loss: 0.00451

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.55505
Value Function Update Magnitude: 0.62667

Collected Steps per Second: 22,520.58720
Overall Steps per Second: 10,591.91177

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.72115

Cumulative Model Updates: 89,518
Cumulative Timesteps: 746,633,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 746633762...
Checkpoint 746633762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.27582
Policy Entropy: 3.26643
Value Function Loss: 0.00451

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.55654
Value Function Update Magnitude: 0.63988

Collected Steps per Second: 22,192.94578
Overall Steps per Second: 10,520.88204

Timestep Collection Time: 2.25513
Timestep Consumption Time: 2.50188
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.75702

Cumulative Model Updates: 89,524
Cumulative Timesteps: 746,683,810

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.57426
Policy Entropy: 3.27315
Value Function Loss: 0.00433

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.55603
Value Function Update Magnitude: 0.64897

Collected Steps per Second: 22,443.34013
Overall Steps per Second: 10,488.71668

Timestep Collection Time: 2.22792
Timestep Consumption Time: 2.53930
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.76722

Cumulative Model Updates: 89,530
Cumulative Timesteps: 746,733,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 746733812...
Checkpoint 746733812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.03675
Policy Entropy: 3.26016
Value Function Loss: 0.00455

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.56184
Value Function Update Magnitude: 0.64485

Collected Steps per Second: 22,185.10609
Overall Steps per Second: 10,557.75784

Timestep Collection Time: 2.25449
Timestep Consumption Time: 2.48288
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.73737

Cumulative Model Updates: 89,536
Cumulative Timesteps: 746,783,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.42386
Policy Entropy: 3.26173
Value Function Loss: 0.00461

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.65365

Collected Steps per Second: 22,720.64019
Overall Steps per Second: 10,568.40670

Timestep Collection Time: 2.20161
Timestep Consumption Time: 2.53155
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.73316

Cumulative Model Updates: 89,542
Cumulative Timesteps: 746,833,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 746833850...
Checkpoint 746833850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.61748
Policy Entropy: 3.25785
Value Function Loss: 0.00453

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.66281

Collected Steps per Second: 22,330.31947
Overall Steps per Second: 10,624.35069

Timestep Collection Time: 2.23920
Timestep Consumption Time: 2.46716
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.70636

Cumulative Model Updates: 89,548
Cumulative Timesteps: 746,883,852

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.15407
Policy Entropy: 3.25413
Value Function Loss: 0.00444

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.56160
Value Function Update Magnitude: 0.66250

Collected Steps per Second: 22,241.28751
Overall Steps per Second: 10,456.72809

Timestep Collection Time: 2.24888
Timestep Consumption Time: 2.53445
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.78333

Cumulative Model Updates: 89,554
Cumulative Timesteps: 746,933,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 746933870...
Checkpoint 746933870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.67488
Policy Entropy: 3.23315
Value Function Loss: 0.00437

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.11055
Policy Update Magnitude: 0.55600
Value Function Update Magnitude: 0.64896

Collected Steps per Second: 22,207.70750
Overall Steps per Second: 10,580.45204

Timestep Collection Time: 2.25273
Timestep Consumption Time: 2.47561
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.72834

Cumulative Model Updates: 89,560
Cumulative Timesteps: 746,983,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.63595
Policy Entropy: 3.22099
Value Function Loss: 0.00443

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.55847
Value Function Update Magnitude: 0.62865

Collected Steps per Second: 22,596.91586
Overall Steps per Second: 10,529.44015

Timestep Collection Time: 2.21340
Timestep Consumption Time: 2.53671
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.75011

Cumulative Model Updates: 89,566
Cumulative Timesteps: 747,033,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 747033914...
Checkpoint 747033914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.30837
Policy Entropy: 3.23306
Value Function Loss: 0.00453

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.56399
Value Function Update Magnitude: 0.63258

Collected Steps per Second: 22,478.26310
Overall Steps per Second: 10,565.60072

Timestep Collection Time: 2.22562
Timestep Consumption Time: 2.50937
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.73499

Cumulative Model Updates: 89,572
Cumulative Timesteps: 747,083,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.69734
Policy Entropy: 3.22673
Value Function Loss: 0.00496

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.56972
Value Function Update Magnitude: 0.66679

Collected Steps per Second: 23,138.01192
Overall Steps per Second: 10,827.09256

Timestep Collection Time: 2.16198
Timestep Consumption Time: 2.45828
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.62026

Cumulative Model Updates: 89,578
Cumulative Timesteps: 747,133,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 747133966...
Checkpoint 747133966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.90182
Policy Entropy: 3.22555
Value Function Loss: 0.00481

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10829
Policy Update Magnitude: 0.57876
Value Function Update Magnitude: 0.69144

Collected Steps per Second: 22,600.54422
Overall Steps per Second: 10,629.88545

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.49148
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.70391

Cumulative Model Updates: 89,584
Cumulative Timesteps: 747,183,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 964.86632
Policy Entropy: 3.23359
Value Function Loss: 0.00447

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.56663
Value Function Update Magnitude: 0.66893

Collected Steps per Second: 22,679.66488
Overall Steps per Second: 10,546.37308

Timestep Collection Time: 2.20585
Timestep Consumption Time: 2.53777
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.74362

Cumulative Model Updates: 89,590
Cumulative Timesteps: 747,233,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 747233996...
Checkpoint 747233996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.16548
Policy Entropy: 3.22716
Value Function Loss: 0.00442

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.55231
Value Function Update Magnitude: 0.64355

Collected Steps per Second: 22,624.70978
Overall Steps per Second: 10,644.14989

Timestep Collection Time: 2.20997
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.69742

Cumulative Model Updates: 89,596
Cumulative Timesteps: 747,283,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.77366
Policy Entropy: 3.23497
Value Function Loss: 0.00442

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.65957

Collected Steps per Second: 22,894.44172
Overall Steps per Second: 10,679.13800

Timestep Collection Time: 2.18455
Timestep Consumption Time: 2.49879
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.68334

Cumulative Model Updates: 89,602
Cumulative Timesteps: 747,334,010

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 747334010...
Checkpoint 747334010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,900.59251
Policy Entropy: 3.24105
Value Function Loss: 0.00452

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08669
Policy Update Magnitude: 0.55448
Value Function Update Magnitude: 0.66876

Collected Steps per Second: 22,690.91131
Overall Steps per Second: 10,742.83546

Timestep Collection Time: 2.20476
Timestep Consumption Time: 2.45211
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.65687

Cumulative Model Updates: 89,608
Cumulative Timesteps: 747,384,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.56215
Policy Entropy: 3.24726
Value Function Loss: 0.00439

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.55278
Value Function Update Magnitude: 0.64999

Collected Steps per Second: 22,305.48091
Overall Steps per Second: 10,584.92739

Timestep Collection Time: 2.24241
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.72540

Cumulative Model Updates: 89,614
Cumulative Timesteps: 747,434,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 747434056...
Checkpoint 747434056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.17475
Policy Entropy: 3.25585
Value Function Loss: 0.00436

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10407
Policy Update Magnitude: 0.54772
Value Function Update Magnitude: 0.64840

Collected Steps per Second: 22,027.90498
Overall Steps per Second: 10,688.81332

Timestep Collection Time: 2.27103
Timestep Consumption Time: 2.40919
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.68022

Cumulative Model Updates: 89,620
Cumulative Timesteps: 747,484,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.54324
Policy Entropy: 3.24639
Value Function Loss: 0.00421

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09021
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.63903

Collected Steps per Second: 22,259.77485
Overall Steps per Second: 10,463.81358

Timestep Collection Time: 2.24674
Timestep Consumption Time: 2.53278
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.77952

Cumulative Model Updates: 89,626
Cumulative Timesteps: 747,534,094

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 747534094...
Checkpoint 747534094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.67735
Policy Entropy: 3.24061
Value Function Loss: 0.00447

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.54758
Value Function Update Magnitude: 0.62129

Collected Steps per Second: 22,230.60925
Overall Steps per Second: 10,563.91024

Timestep Collection Time: 2.24924
Timestep Consumption Time: 2.48404
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.73329

Cumulative Model Updates: 89,632
Cumulative Timesteps: 747,584,096

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.30872
Policy Entropy: 3.22586
Value Function Loss: 0.00454

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08783
Policy Update Magnitude: 0.55676
Value Function Update Magnitude: 0.61511

Collected Steps per Second: 22,559.28758
Overall Steps per Second: 10,610.18468

Timestep Collection Time: 2.21727
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.71434

Cumulative Model Updates: 89,638
Cumulative Timesteps: 747,634,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 747634116...
Checkpoint 747634116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.94242
Policy Entropy: 3.24468
Value Function Loss: 0.00440

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.56249
Value Function Update Magnitude: 0.60362

Collected Steps per Second: 22,519.47477
Overall Steps per Second: 10,519.96253

Timestep Collection Time: 2.22066
Timestep Consumption Time: 2.53297
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.75363

Cumulative Model Updates: 89,644
Cumulative Timesteps: 747,684,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.29708
Policy Entropy: 3.23993
Value Function Loss: 0.00404

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.55135
Value Function Update Magnitude: 0.58743

Collected Steps per Second: 22,896.00604
Overall Steps per Second: 10,650.92595

Timestep Collection Time: 2.18466
Timestep Consumption Time: 2.51164
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.69631

Cumulative Model Updates: 89,650
Cumulative Timesteps: 747,734,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 747734144...
Checkpoint 747734144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.37095
Policy Entropy: 3.25808
Value Function Loss: 0.00403

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.54234
Value Function Update Magnitude: 0.58364

Collected Steps per Second: 22,906.29884
Overall Steps per Second: 10,815.23318

Timestep Collection Time: 2.18342
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.62440

Cumulative Model Updates: 89,656
Cumulative Timesteps: 747,784,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.44488
Policy Entropy: 3.25290
Value Function Loss: 0.00404

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.53554
Value Function Update Magnitude: 0.59648

Collected Steps per Second: 22,827.46418
Overall Steps per Second: 10,767.08415

Timestep Collection Time: 2.19140
Timestep Consumption Time: 2.45462
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.64601

Cumulative Model Updates: 89,662
Cumulative Timesteps: 747,834,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 747834182...
Checkpoint 747834182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938.60600
Policy Entropy: 3.25485
Value Function Loss: 0.00413

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.53431
Value Function Update Magnitude: 0.58680

Collected Steps per Second: 22,539.58187
Overall Steps per Second: 10,736.63166

Timestep Collection Time: 2.21841
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.65714

Cumulative Model Updates: 89,668
Cumulative Timesteps: 747,884,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.95070
Policy Entropy: 3.25765
Value Function Loss: 0.00415

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.53424
Value Function Update Magnitude: 0.57976

Collected Steps per Second: 23,112.35256
Overall Steps per Second: 10,878.86621

Timestep Collection Time: 2.16378
Timestep Consumption Time: 2.43321
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.59699

Cumulative Model Updates: 89,674
Cumulative Timesteps: 747,934,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 747934194...
Checkpoint 747934194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.44658
Policy Entropy: 3.23836
Value Function Loss: 0.00421

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08581
Policy Update Magnitude: 0.53925
Value Function Update Magnitude: 0.60444

Collected Steps per Second: 22,551.12334
Overall Steps per Second: 10,764.87438

Timestep Collection Time: 2.21754
Timestep Consumption Time: 2.42794
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.64548

Cumulative Model Updates: 89,680
Cumulative Timesteps: 747,984,202

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.17217
Policy Entropy: 3.23786
Value Function Loss: 0.00410

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.54282
Value Function Update Magnitude: 0.62377

Collected Steps per Second: 22,739.69922
Overall Steps per Second: 10,801.16966

Timestep Collection Time: 2.20003
Timestep Consumption Time: 2.43169
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.63172

Cumulative Model Updates: 89,686
Cumulative Timesteps: 748,034,230

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 748034230...
Checkpoint 748034230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.36301
Policy Entropy: 3.22879
Value Function Loss: 0.00420

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.53853
Value Function Update Magnitude: 0.62247

Collected Steps per Second: 22,130.54838
Overall Steps per Second: 10,531.81940

Timestep Collection Time: 2.26040
Timestep Consumption Time: 2.48939
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.74980

Cumulative Model Updates: 89,692
Cumulative Timesteps: 748,084,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.81706
Policy Entropy: 3.24925
Value Function Loss: 0.00409

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08237
Policy Update Magnitude: 0.53982
Value Function Update Magnitude: 0.63525

Collected Steps per Second: 22,411.61769
Overall Steps per Second: 10,626.69811

Timestep Collection Time: 2.23152
Timestep Consumption Time: 2.47474
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.70626

Cumulative Model Updates: 89,698
Cumulative Timesteps: 748,134,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 748134266...
Checkpoint 748134266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.42226
Policy Entropy: 3.24833
Value Function Loss: 0.00401

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.53733
Value Function Update Magnitude: 0.63123

Collected Steps per Second: 22,360.13305
Overall Steps per Second: 10,644.54576

Timestep Collection Time: 2.23702
Timestep Consumption Time: 2.46210
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.69912

Cumulative Model Updates: 89,704
Cumulative Timesteps: 748,184,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.02818
Policy Entropy: 3.26098
Value Function Loss: 0.00414

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.53713
Value Function Update Magnitude: 0.62441

Collected Steps per Second: 22,422.12153
Overall Steps per Second: 10,494.16919

Timestep Collection Time: 2.23137
Timestep Consumption Time: 2.53623
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.76760

Cumulative Model Updates: 89,710
Cumulative Timesteps: 748,234,318

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 748234318...
Checkpoint 748234318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.04219
Policy Entropy: 3.25449
Value Function Loss: 0.00406

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.53184
Value Function Update Magnitude: 0.61996

Collected Steps per Second: 22,655.93372
Overall Steps per Second: 10,672.50275

Timestep Collection Time: 2.20755
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.68625

Cumulative Model Updates: 89,716
Cumulative Timesteps: 748,284,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.04700
Policy Entropy: 3.24522
Value Function Loss: 0.00413

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.52641
Value Function Update Magnitude: 0.61486

Collected Steps per Second: 23,235.90871
Overall Steps per Second: 10,869.98918

Timestep Collection Time: 2.15287
Timestep Consumption Time: 2.44915
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.60203

Cumulative Model Updates: 89,722
Cumulative Timesteps: 748,334,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 748334356...
Checkpoint 748334356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.39792
Policy Entropy: 3.24770
Value Function Loss: 0.00420

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08320
Policy Update Magnitude: 0.52903
Value Function Update Magnitude: 0.61961

Collected Steps per Second: 22,550.55740
Overall Steps per Second: 10,642.02826

Timestep Collection Time: 2.21804
Timestep Consumption Time: 2.48201
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.70004

Cumulative Model Updates: 89,728
Cumulative Timesteps: 748,384,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.73958
Policy Entropy: 3.25441
Value Function Loss: 0.00434

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.53872
Value Function Update Magnitude: 0.62266

Collected Steps per Second: 22,869.96365
Overall Steps per Second: 10,842.05758

Timestep Collection Time: 2.18645
Timestep Consumption Time: 2.42559
PPO Batch Consumption Time: 0.28201
Total Iteration Time: 4.61204

Cumulative Model Updates: 89,734
Cumulative Timesteps: 748,434,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 748434378...
Checkpoint 748434378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.83151
Policy Entropy: 3.26169
Value Function Loss: 0.00446

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09089
Policy Update Magnitude: 0.54119
Value Function Update Magnitude: 0.64535

Collected Steps per Second: 22,294.22150
Overall Steps per Second: 10,647.03164

Timestep Collection Time: 2.24354
Timestep Consumption Time: 2.45429
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.69784

Cumulative Model Updates: 89,740
Cumulative Timesteps: 748,484,396

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,681.19624
Policy Entropy: 3.26146
Value Function Loss: 0.00436

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.53844
Value Function Update Magnitude: 0.66940

Collected Steps per Second: 23,122.26609
Overall Steps per Second: 10,879.77064

Timestep Collection Time: 2.16268
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.59624

Cumulative Model Updates: 89,746
Cumulative Timesteps: 748,534,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 748534402...
Checkpoint 748534402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 872.58165
Policy Entropy: 3.25030
Value Function Loss: 0.00441

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.54337
Value Function Update Magnitude: 0.65691

Collected Steps per Second: 22,223.55345
Overall Steps per Second: 10,670.77542

Timestep Collection Time: 2.25023
Timestep Consumption Time: 2.43622
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.68644

Cumulative Model Updates: 89,752
Cumulative Timesteps: 748,584,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.32979
Policy Entropy: 3.24889
Value Function Loss: 0.00473

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10872
Policy Update Magnitude: 0.55245
Value Function Update Magnitude: 0.67219

Collected Steps per Second: 22,639.68459
Overall Steps per Second: 10,627.80664

Timestep Collection Time: 2.20975
Timestep Consumption Time: 2.49753
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.70727

Cumulative Model Updates: 89,758
Cumulative Timesteps: 748,634,438

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 748634438...
Checkpoint 748634438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.79380
Policy Entropy: 3.26298
Value Function Loss: 0.00471

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.68549

Collected Steps per Second: 22,172.97063
Overall Steps per Second: 10,570.69312

Timestep Collection Time: 2.25509
Timestep Consumption Time: 2.47516
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.73025

Cumulative Model Updates: 89,764
Cumulative Timesteps: 748,684,440

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.79533
Policy Entropy: 3.27439
Value Function Loss: 0.00451

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.56195
Value Function Update Magnitude: 0.67550

Collected Steps per Second: 22,154.10943
Overall Steps per Second: 10,490.94109

Timestep Collection Time: 2.25701
Timestep Consumption Time: 2.50920
PPO Batch Consumption Time: 0.29687
Total Iteration Time: 4.76621

Cumulative Model Updates: 89,770
Cumulative Timesteps: 748,734,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 748734442...
Checkpoint 748734442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.51628
Policy Entropy: 3.28065
Value Function Loss: 0.00437

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.55334
Value Function Update Magnitude: 0.65024

Collected Steps per Second: 22,259.38497
Overall Steps per Second: 10,559.43719

Timestep Collection Time: 2.24741
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.73756

Cumulative Model Updates: 89,776
Cumulative Timesteps: 748,784,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.73026
Policy Entropy: 3.27608
Value Function Loss: 0.00427

Mean KL Divergence: 0.00714
SB3 Clip Fraction: 0.07882
Policy Update Magnitude: 0.55070
Value Function Update Magnitude: 0.63532

Collected Steps per Second: 21,721.45507
Overall Steps per Second: 10,487.50278

Timestep Collection Time: 2.30215
Timestep Consumption Time: 2.46600
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.76815

Cumulative Model Updates: 89,782
Cumulative Timesteps: 748,834,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 748834474...
Checkpoint 748834474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.18715
Policy Entropy: 3.27131
Value Function Loss: 0.00428

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.55112
Value Function Update Magnitude: 0.64798

Collected Steps per Second: 22,528.61247
Overall Steps per Second: 10,559.83864

Timestep Collection Time: 2.22047
Timestep Consumption Time: 2.51673
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.73719

Cumulative Model Updates: 89,788
Cumulative Timesteps: 748,884,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.13132
Policy Entropy: 3.28229
Value Function Loss: 0.00407

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.54583
Value Function Update Magnitude: 0.66335

Collected Steps per Second: 22,835.62019
Overall Steps per Second: 10,700.73058

Timestep Collection Time: 2.19070
Timestep Consumption Time: 2.48431
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.67501

Cumulative Model Updates: 89,794
Cumulative Timesteps: 748,934,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 748934524...
Checkpoint 748934524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.78145
Policy Entropy: 3.29158
Value Function Loss: 0.00403

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10134
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.65129

Collected Steps per Second: 22,788.52168
Overall Steps per Second: 10,818.45336

Timestep Collection Time: 2.19417
Timestep Consumption Time: 2.42774
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.62192

Cumulative Model Updates: 89,800
Cumulative Timesteps: 748,984,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.23408
Policy Entropy: 3.29760
Value Function Loss: 0.00399

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.53248
Value Function Update Magnitude: 0.62999

Collected Steps per Second: 22,965.79325
Overall Steps per Second: 10,732.41478

Timestep Collection Time: 2.17785
Timestep Consumption Time: 2.48243
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.66027

Cumulative Model Updates: 89,806
Cumulative Timesteps: 749,034,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 749034542...
Checkpoint 749034542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.27170
Policy Entropy: 3.30224
Value Function Loss: 0.00388

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.52439
Value Function Update Magnitude: 0.61333

Collected Steps per Second: 22,596.14841
Overall Steps per Second: 10,646.47925

Timestep Collection Time: 2.21285
Timestep Consumption Time: 2.48372
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.69658

Cumulative Model Updates: 89,812
Cumulative Timesteps: 749,084,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.66180
Policy Entropy: 3.29231
Value Function Loss: 0.00399

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.07532
Policy Update Magnitude: 0.52580
Value Function Update Magnitude: 0.61071

Collected Steps per Second: 22,808.08237
Overall Steps per Second: 10,708.55992

Timestep Collection Time: 2.19326
Timestep Consumption Time: 2.47815
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.67140

Cumulative Model Updates: 89,818
Cumulative Timesteps: 749,134,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 749134568...
Checkpoint 749134568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.30148
Policy Entropy: 3.27461
Value Function Loss: 0.00416

Mean KL Divergence: 0.00696
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.53274
Value Function Update Magnitude: 0.60320

Collected Steps per Second: 22,198.96740
Overall Steps per Second: 10,697.08152

Timestep Collection Time: 2.25263
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.67473

Cumulative Model Updates: 89,824
Cumulative Timesteps: 749,184,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.48008
Policy Entropy: 3.27130
Value Function Loss: 0.00410

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08142
Policy Update Magnitude: 0.54160
Value Function Update Magnitude: 0.60554

Collected Steps per Second: 22,531.12221
Overall Steps per Second: 10,753.91387

Timestep Collection Time: 2.21960
Timestep Consumption Time: 2.43080
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.65040

Cumulative Model Updates: 89,830
Cumulative Timesteps: 749,234,584

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 749234584...
Checkpoint 749234584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.60438
Policy Entropy: 3.26960
Value Function Loss: 0.00390

Mean KL Divergence: 0.00668
SB3 Clip Fraction: 0.07305
Policy Update Magnitude: 0.53595
Value Function Update Magnitude: 0.57364

Collected Steps per Second: 22,018.91204
Overall Steps per Second: 10,665.93457

Timestep Collection Time: 2.27187
Timestep Consumption Time: 2.41821
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.69007

Cumulative Model Updates: 89,836
Cumulative Timesteps: 749,284,608

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.63772
Policy Entropy: 3.28335
Value Function Loss: 0.00393

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.52890
Value Function Update Magnitude: 0.55276

Collected Steps per Second: 22,198.43604
Overall Steps per Second: 10,522.10824

Timestep Collection Time: 2.25322
Timestep Consumption Time: 2.50039
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.75361

Cumulative Model Updates: 89,842
Cumulative Timesteps: 749,334,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 749334626...
Checkpoint 749334626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003.60093
Policy Entropy: 3.26534
Value Function Loss: 0.00416

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.52516
Value Function Update Magnitude: 0.54289

Collected Steps per Second: 22,670.45254
Overall Steps per Second: 10,639.32328

Timestep Collection Time: 2.20560
Timestep Consumption Time: 2.49413
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.69973

Cumulative Model Updates: 89,848
Cumulative Timesteps: 749,384,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.25168
Policy Entropy: 3.25519
Value Function Loss: 0.00438

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.53653
Value Function Update Magnitude: 0.55125

Collected Steps per Second: 22,739.91465
Overall Steps per Second: 10,677.54618

Timestep Collection Time: 2.19939
Timestep Consumption Time: 2.48464
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.68404

Cumulative Model Updates: 89,854
Cumulative Timesteps: 749,434,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 749434642...
Checkpoint 749434642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 790.12785
Policy Entropy: 3.24018
Value Function Loss: 0.00453

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.55788

Collected Steps per Second: 23,033.45247
Overall Steps per Second: 10,902.24868

Timestep Collection Time: 2.17197
Timestep Consumption Time: 2.41681
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.58878

Cumulative Model Updates: 89,860
Cumulative Timesteps: 749,484,670

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.87027
Policy Entropy: 3.25253
Value Function Loss: 0.00446

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.54975
Value Function Update Magnitude: 0.57054

Collected Steps per Second: 22,712.39471
Overall Steps per Second: 10,812.13412

Timestep Collection Time: 2.20276
Timestep Consumption Time: 2.42445
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.62721

Cumulative Model Updates: 89,866
Cumulative Timesteps: 749,534,700

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 749534700...
Checkpoint 749534700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.16252
Policy Entropy: 3.26455
Value Function Loss: 0.00443

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10059
Policy Update Magnitude: 0.55094
Value Function Update Magnitude: 0.59100

Collected Steps per Second: 22,839.51657
Overall Steps per Second: 10,731.92303

Timestep Collection Time: 2.18998
Timestep Consumption Time: 2.47070
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.66067

Cumulative Model Updates: 89,872
Cumulative Timesteps: 749,584,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.35634
Policy Entropy: 3.27101
Value Function Loss: 0.00427

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.62731

Collected Steps per Second: 22,823.12530
Overall Steps per Second: 10,828.45709

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.42690
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.61783

Cumulative Model Updates: 89,878
Cumulative Timesteps: 749,634,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 749634722...
Checkpoint 749634722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.76769
Policy Entropy: 3.25753
Value Function Loss: 0.00428

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.55894
Value Function Update Magnitude: 0.65698

Collected Steps per Second: 22,101.64512
Overall Steps per Second: 10,646.46966

Timestep Collection Time: 2.26264
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.69714

Cumulative Model Updates: 89,884
Cumulative Timesteps: 749,684,730

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.15029
Policy Entropy: 3.23990
Value Function Loss: 0.00439

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.65435

Collected Steps per Second: 22,589.79597
Overall Steps per Second: 10,591.48778

Timestep Collection Time: 2.21454
Timestep Consumption Time: 2.50869
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.72323

Cumulative Model Updates: 89,890
Cumulative Timesteps: 749,734,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 749734756...
Checkpoint 749734756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.89546
Policy Entropy: 3.23206
Value Function Loss: 0.00448

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.57053
Value Function Update Magnitude: 0.67451

Collected Steps per Second: 21,810.37066
Overall Steps per Second: 10,572.35860

Timestep Collection Time: 2.29304
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.73045

Cumulative Model Updates: 89,896
Cumulative Timesteps: 749,784,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.55385
Policy Entropy: 3.23183
Value Function Loss: 0.00427

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09286
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.67706

Collected Steps per Second: 22,657.72639
Overall Steps per Second: 10,630.57529

Timestep Collection Time: 2.20719
Timestep Consumption Time: 2.49716
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.70436

Cumulative Model Updates: 89,902
Cumulative Timesteps: 749,834,778

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 749834778...
Checkpoint 749834778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.56260
Policy Entropy: 3.23806
Value Function Loss: 0.00449

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.56769
Value Function Update Magnitude: 0.66107

Collected Steps per Second: 22,129.15654
Overall Steps per Second: 10,479.52129

Timestep Collection Time: 2.26000
Timestep Consumption Time: 2.51235
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.77236

Cumulative Model Updates: 89,908
Cumulative Timesteps: 749,884,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.69561
Policy Entropy: 3.24701
Value Function Loss: 0.00458

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.64840

Collected Steps per Second: 22,702.65100
Overall Steps per Second: 10,599.02746

Timestep Collection Time: 2.20371
Timestep Consumption Time: 2.51654
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.72024

Cumulative Model Updates: 89,914
Cumulative Timesteps: 749,934,820

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 749934820...
Checkpoint 749934820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.90101
Policy Entropy: 3.24556
Value Function Loss: 0.00464

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.57155
Value Function Update Magnitude: 0.64082

Collected Steps per Second: 22,809.56539
Overall Steps per Second: 10,611.83945

Timestep Collection Time: 2.19312
Timestep Consumption Time: 2.52087
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.71398

Cumulative Model Updates: 89,920
Cumulative Timesteps: 749,984,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.09923
Policy Entropy: 3.22455
Value Function Loss: 0.00492

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.14004
Policy Update Magnitude: 0.57833
Value Function Update Magnitude: 0.65086

Collected Steps per Second: 23,214.08935
Overall Steps per Second: 10,809.07383

Timestep Collection Time: 2.15438
Timestep Consumption Time: 2.47247
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.62685

Cumulative Model Updates: 89,926
Cumulative Timesteps: 750,034,856

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 750034856...
Checkpoint 750034856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.82908
Policy Entropy: 3.19703
Value Function Loss: 0.00506

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12602
Policy Update Magnitude: 0.59455
Value Function Update Magnitude: 0.66480

Collected Steps per Second: 22,309.95755
Overall Steps per Second: 10,646.81101

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.69774

Cumulative Model Updates: 89,932
Cumulative Timesteps: 750,084,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.94325
Policy Entropy: 3.18700
Value Function Loss: 0.00502

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.59771
Value Function Update Magnitude: 0.66766

Collected Steps per Second: 22,310.20256
Overall Steps per Second: 10,566.36971

Timestep Collection Time: 2.24149
Timestep Consumption Time: 2.49127
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.73275

Cumulative Model Updates: 89,938
Cumulative Timesteps: 750,134,880

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 750134880...
Checkpoint 750134880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.57373
Policy Entropy: 3.20746
Value Function Loss: 0.00494

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09944
Policy Update Magnitude: 0.59053
Value Function Update Magnitude: 0.67019

Collected Steps per Second: 22,616.92668
Overall Steps per Second: 10,786.09531

Timestep Collection Time: 2.21100
Timestep Consumption Time: 2.42516
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.63615

Cumulative Model Updates: 89,944
Cumulative Timesteps: 750,184,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.69105
Policy Entropy: 3.21242
Value Function Loss: 0.00459

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11893
Policy Update Magnitude: 0.58566
Value Function Update Magnitude: 0.64624

Collected Steps per Second: 22,349.94756
Overall Steps per Second: 10,712.97756

Timestep Collection Time: 2.23723
Timestep Consumption Time: 2.43019
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.66742

Cumulative Model Updates: 89,950
Cumulative Timesteps: 750,234,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 750234888...
Checkpoint 750234888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 793.54994
Policy Entropy: 3.22643
Value Function Loss: 0.00456

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.57659
Value Function Update Magnitude: 0.63079

Collected Steps per Second: 21,600.94662
Overall Steps per Second: 10,678.15551

Timestep Collection Time: 2.31610
Timestep Consumption Time: 2.36916
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.68527

Cumulative Model Updates: 89,956
Cumulative Timesteps: 750,284,918

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 550.40973
Policy Entropy: 3.22536
Value Function Loss: 0.00448

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.57010
Value Function Update Magnitude: 0.62824

Collected Steps per Second: 22,244.88028
Overall Steps per Second: 10,782.09319

Timestep Collection Time: 2.24870
Timestep Consumption Time: 2.39066
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.63936

Cumulative Model Updates: 89,962
Cumulative Timesteps: 750,334,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 750334940...
Checkpoint 750334940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.17023
Policy Entropy: 3.25188
Value Function Loss: 0.00439

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.55785
Value Function Update Magnitude: 0.60411

Collected Steps per Second: 21,633.32513
Overall Steps per Second: 10,676.09673

Timestep Collection Time: 2.31208
Timestep Consumption Time: 2.37296
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.68505

Cumulative Model Updates: 89,968
Cumulative Timesteps: 750,384,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.93552
Policy Entropy: 3.25285
Value Function Loss: 0.00425

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.55095
Value Function Update Magnitude: 0.58891

Collected Steps per Second: 22,737.11632
Overall Steps per Second: 10,537.70423

Timestep Collection Time: 2.19940
Timestep Consumption Time: 2.54623
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.74563

Cumulative Model Updates: 89,974
Cumulative Timesteps: 750,434,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 750434966...
Checkpoint 750434966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.24459
Policy Entropy: 3.24889
Value Function Loss: 0.00450

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.55225
Value Function Update Magnitude: 0.58697

Collected Steps per Second: 22,039.72289
Overall Steps per Second: 10,614.57263

Timestep Collection Time: 2.26890
Timestep Consumption Time: 2.44217
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.71107

Cumulative Model Updates: 89,980
Cumulative Timesteps: 750,484,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.95256
Policy Entropy: 3.23609
Value Function Loss: 0.00468

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.56002
Value Function Update Magnitude: 0.58065

Collected Steps per Second: 22,972.87992
Overall Steps per Second: 10,764.95314

Timestep Collection Time: 2.17691
Timestep Consumption Time: 2.46872
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.64563

Cumulative Model Updates: 89,986
Cumulative Timesteps: 750,534,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 750534982...
Checkpoint 750534982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.03564
Policy Entropy: 3.23228
Value Function Loss: 0.00468

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.56788
Value Function Update Magnitude: 0.59873

Collected Steps per Second: 22,815.07198
Overall Steps per Second: 10,757.83414

Timestep Collection Time: 2.19162
Timestep Consumption Time: 2.45634
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.64796

Cumulative Model Updates: 89,992
Cumulative Timesteps: 750,584,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.03007
Policy Entropy: 3.23186
Value Function Loss: 0.00447

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10720
Policy Update Magnitude: 0.56729
Value Function Update Magnitude: 0.61847

Collected Steps per Second: 22,792.81980
Overall Steps per Second: 10,655.21522

Timestep Collection Time: 2.19481
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.69498

Cumulative Model Updates: 89,998
Cumulative Timesteps: 750,635,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 750635010...
Checkpoint 750635010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.96403
Policy Entropy: 3.23298
Value Function Loss: 0.00441

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.56675
Value Function Update Magnitude: 0.61017

Collected Steps per Second: 23,110.67612
Overall Steps per Second: 10,849.97807

Timestep Collection Time: 2.16445
Timestep Consumption Time: 2.44588
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.61033

Cumulative Model Updates: 90,004
Cumulative Timesteps: 750,685,032

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073.54956
Policy Entropy: 3.24210
Value Function Loss: 0.00440

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.60616

Collected Steps per Second: 22,415.47900
Overall Steps per Second: 10,381.82825

Timestep Collection Time: 2.23078
Timestep Consumption Time: 2.58571
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.81649

Cumulative Model Updates: 90,010
Cumulative Timesteps: 750,735,036

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 750735036...
Checkpoint 750735036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 849.50084
Policy Entropy: 3.25190
Value Function Loss: 0.00416

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09145
Policy Update Magnitude: 0.56323
Value Function Update Magnitude: 0.60413

Collected Steps per Second: 22,603.37078
Overall Steps per Second: 10,710.94675

Timestep Collection Time: 2.21232
Timestep Consumption Time: 2.45636
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.66868

Cumulative Model Updates: 90,016
Cumulative Timesteps: 750,785,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.61294
Policy Entropy: 3.25292
Value Function Loss: 0.00422

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.56155
Value Function Update Magnitude: 0.59825

Collected Steps per Second: 22,496.73145
Overall Steps per Second: 10,513.20686

Timestep Collection Time: 2.22308
Timestep Consumption Time: 2.53399
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 4.75706

Cumulative Model Updates: 90,022
Cumulative Timesteps: 750,835,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 750835054...
Checkpoint 750835054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.50823
Policy Entropy: 3.24782
Value Function Loss: 0.00440

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.56350
Value Function Update Magnitude: 0.61335

Collected Steps per Second: 22,329.74640
Overall Steps per Second: 10,688.72701

Timestep Collection Time: 2.23970
Timestep Consumption Time: 2.43925
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.67895

Cumulative Model Updates: 90,028
Cumulative Timesteps: 750,885,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.24463
Policy Entropy: 3.23674
Value Function Loss: 0.00453

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11330
Policy Update Magnitude: 0.56897
Value Function Update Magnitude: 0.63105

Collected Steps per Second: 22,506.32988
Overall Steps per Second: 10,540.55906

Timestep Collection Time: 2.22240
Timestep Consumption Time: 2.52289
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.74529

Cumulative Model Updates: 90,034
Cumulative Timesteps: 750,935,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 750935084...
Checkpoint 750935084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.14280
Policy Entropy: 3.22823
Value Function Loss: 0.00450

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.57052
Value Function Update Magnitude: 0.64654

Collected Steps per Second: 22,649.28531
Overall Steps per Second: 10,577.72199

Timestep Collection Time: 2.20828
Timestep Consumption Time: 2.52015
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.72843

Cumulative Model Updates: 90,040
Cumulative Timesteps: 750,985,100

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.91295
Policy Entropy: 3.23028
Value Function Loss: 0.00441

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.56258
Value Function Update Magnitude: 0.63825

Collected Steps per Second: 22,585.02995
Overall Steps per Second: 10,441.73700

Timestep Collection Time: 2.21448
Timestep Consumption Time: 2.57534
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.78982

Cumulative Model Updates: 90,046
Cumulative Timesteps: 751,035,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 751035114...
Checkpoint 751035114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.25715
Policy Entropy: 3.22219
Value Function Loss: 0.00450

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.63355

Collected Steps per Second: 22,890.80583
Overall Steps per Second: 10,590.94580

Timestep Collection Time: 2.18455
Timestep Consumption Time: 2.53704
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.72158

Cumulative Model Updates: 90,052
Cumulative Timesteps: 751,085,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.75975
Policy Entropy: 3.23351
Value Function Loss: 0.00458

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.56318
Value Function Update Magnitude: 0.63155

Collected Steps per Second: 22,896.86643
Overall Steps per Second: 10,651.22054

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.51200
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.69693

Cumulative Model Updates: 90,058
Cumulative Timesteps: 751,135,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 751135148...
Checkpoint 751135148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.98672
Policy Entropy: 3.23851
Value Function Loss: 0.00465

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09118
Policy Update Magnitude: 0.56214
Value Function Update Magnitude: 0.61995

Collected Steps per Second: 23,376.87038
Overall Steps per Second: 10,869.11155

Timestep Collection Time: 2.13998
Timestep Consumption Time: 2.46261
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.60258

Cumulative Model Updates: 90,064
Cumulative Timesteps: 751,185,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.41528
Policy Entropy: 3.22993
Value Function Loss: 0.00469

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.56170
Value Function Update Magnitude: 0.61069

Collected Steps per Second: 22,725.06748
Overall Steps per Second: 10,616.25688

Timestep Collection Time: 2.20136
Timestep Consumption Time: 2.51085
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.71221

Cumulative Model Updates: 90,070
Cumulative Timesteps: 751,235,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 751235200...
Checkpoint 751235200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.08226
Policy Entropy: 3.24061
Value Function Loss: 0.00466

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09842
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.61432

Collected Steps per Second: 23,041.56065
Overall Steps per Second: 10,838.82675

Timestep Collection Time: 2.17034
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.61378

Cumulative Model Updates: 90,076
Cumulative Timesteps: 751,285,208

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.15901
Policy Entropy: 3.23880
Value Function Loss: 0.00445

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.56256
Value Function Update Magnitude: 0.61970

Collected Steps per Second: 22,855.49303
Overall Steps per Second: 10,612.33446

Timestep Collection Time: 2.18897
Timestep Consumption Time: 2.52536
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.71433

Cumulative Model Updates: 90,082
Cumulative Timesteps: 751,335,238

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 751335238...
Checkpoint 751335238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.65343
Policy Entropy: 3.24712
Value Function Loss: 0.00438

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.56512
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 22,476.60186
Overall Steps per Second: 10,591.68114

Timestep Collection Time: 2.22480
Timestep Consumption Time: 2.49645
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.72125

Cumulative Model Updates: 90,088
Cumulative Timesteps: 751,385,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.80627
Policy Entropy: 3.22784
Value Function Loss: 0.00429

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.56007
Value Function Update Magnitude: 0.61299

Collected Steps per Second: 22,573.47343
Overall Steps per Second: 10,589.45751

Timestep Collection Time: 2.21632
Timestep Consumption Time: 2.50819
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.72451

Cumulative Model Updates: 90,094
Cumulative Timesteps: 751,435,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 751435274...
Checkpoint 751435274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 871.10052
Policy Entropy: 3.24232
Value Function Loss: 0.00459

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11212
Policy Update Magnitude: 0.56144
Value Function Update Magnitude: 0.60487

Collected Steps per Second: 22,411.13556
Overall Steps per Second: 10,516.89502

Timestep Collection Time: 2.23112
Timestep Consumption Time: 2.52332
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.75445

Cumulative Model Updates: 90,100
Cumulative Timesteps: 751,485,276

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.27702
Policy Entropy: 3.26005
Value Function Loss: 0.00453

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.56315
Value Function Update Magnitude: 0.58889

Collected Steps per Second: 22,218.73364
Overall Steps per Second: 10,439.58080

Timestep Collection Time: 2.25179
Timestep Consumption Time: 2.54074
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.79253

Cumulative Model Updates: 90,106
Cumulative Timesteps: 751,535,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 751535308...
Checkpoint 751535308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.35195
Policy Entropy: 3.25997
Value Function Loss: 0.00461

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.55721
Value Function Update Magnitude: 0.58532

Collected Steps per Second: 22,766.47189
Overall Steps per Second: 10,662.67277

Timestep Collection Time: 2.19648
Timestep Consumption Time: 2.49334
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.68982

Cumulative Model Updates: 90,112
Cumulative Timesteps: 751,585,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834.63100
Policy Entropy: 3.26495
Value Function Loss: 0.00460

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.56269
Value Function Update Magnitude: 0.59055

Collected Steps per Second: 22,625.45866
Overall Steps per Second: 10,493.51333

Timestep Collection Time: 2.21105
Timestep Consumption Time: 2.55628
PPO Batch Consumption Time: 0.29673
Total Iteration Time: 4.76733

Cumulative Model Updates: 90,118
Cumulative Timesteps: 751,635,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 751635340...
Checkpoint 751635340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.05736
Policy Entropy: 3.24671
Value Function Loss: 0.00438

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.56481
Value Function Update Magnitude: 0.59707

Collected Steps per Second: 22,475.71522
Overall Steps per Second: 10,597.69132

Timestep Collection Time: 2.22587
Timestep Consumption Time: 2.49478
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.72065

Cumulative Model Updates: 90,124
Cumulative Timesteps: 751,685,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 652.09888
Policy Entropy: 3.24336
Value Function Loss: 0.00447

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.56046
Value Function Update Magnitude: 0.59362

Collected Steps per Second: 22,923.79570
Overall Steps per Second: 10,645.03580

Timestep Collection Time: 2.18236
Timestep Consumption Time: 2.51729
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.69966

Cumulative Model Updates: 90,130
Cumulative Timesteps: 751,735,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 751735396...
Checkpoint 751735396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.35599
Policy Entropy: 3.23161
Value Function Loss: 0.00454

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.56670
Value Function Update Magnitude: 0.60982

Collected Steps per Second: 23,027.73665
Overall Steps per Second: 10,857.74161

Timestep Collection Time: 2.17182
Timestep Consumption Time: 2.43430
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.60611

Cumulative Model Updates: 90,136
Cumulative Timesteps: 751,785,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.92497
Policy Entropy: 3.22525
Value Function Loss: 0.00489

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.58298
Value Function Update Magnitude: 0.64917

Collected Steps per Second: 22,596.30731
Overall Steps per Second: 10,659.27739

Timestep Collection Time: 2.21337
Timestep Consumption Time: 2.47869
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.69206

Cumulative Model Updates: 90,142
Cumulative Timesteps: 751,835,422

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 751835422...
Checkpoint 751835422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.57519
Policy Entropy: 3.21430
Value Function Loss: 0.00470

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.58905
Value Function Update Magnitude: 0.69366

Collected Steps per Second: 22,610.42144
Overall Steps per Second: 10,675.64614

Timestep Collection Time: 2.21208
Timestep Consumption Time: 2.47298
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.68506

Cumulative Model Updates: 90,148
Cumulative Timesteps: 751,885,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.46981
Policy Entropy: 3.22883
Value Function Loss: 0.00457

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.58376
Value Function Update Magnitude: 0.68183

Collected Steps per Second: 22,888.57580
Overall Steps per Second: 10,716.31620

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.48178
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.66672

Cumulative Model Updates: 90,154
Cumulative Timesteps: 751,935,448

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 751935448...
Checkpoint 751935448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.99583
Policy Entropy: 3.23095
Value Function Loss: 0.00469

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.57618
Value Function Update Magnitude: 0.65853

Collected Steps per Second: 22,196.61946
Overall Steps per Second: 10,551.00190

Timestep Collection Time: 2.25332
Timestep Consumption Time: 2.48709
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.74040

Cumulative Model Updates: 90,160
Cumulative Timesteps: 751,985,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.97850
Policy Entropy: 3.23298
Value Function Loss: 0.00452

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.58091
Value Function Update Magnitude: 0.64954

Collected Steps per Second: 22,373.19753
Overall Steps per Second: 10,530.49062

Timestep Collection Time: 2.23607
Timestep Consumption Time: 2.51471
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.75078

Cumulative Model Updates: 90,166
Cumulative Timesteps: 752,035,492

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 752035492...
Checkpoint 752035492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.22540
Policy Entropy: 3.24263
Value Function Loss: 0.00458

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.57758
Value Function Update Magnitude: 0.65963

Collected Steps per Second: 22,266.39479
Overall Steps per Second: 10,632.90767

Timestep Collection Time: 2.24554
Timestep Consumption Time: 2.45685
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.70238

Cumulative Model Updates: 90,172
Cumulative Timesteps: 752,085,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.35319
Policy Entropy: 3.24383
Value Function Loss: 0.00446

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.08297
Policy Update Magnitude: 0.57836
Value Function Update Magnitude: 0.65954

Collected Steps per Second: 22,681.81574
Overall Steps per Second: 10,862.06757

Timestep Collection Time: 2.20573
Timestep Consumption Time: 2.40021
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.60594

Cumulative Model Updates: 90,178
Cumulative Timesteps: 752,135,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 752135522...
Checkpoint 752135522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.59150
Policy Entropy: 3.23732
Value Function Loss: 0.00467

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.57850
Value Function Update Magnitude: 0.66994

Collected Steps per Second: 22,002.87970
Overall Steps per Second: 10,672.81839

Timestep Collection Time: 2.27316
Timestep Consumption Time: 2.41314
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.68630

Cumulative Model Updates: 90,184
Cumulative Timesteps: 752,185,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.23205
Policy Entropy: 3.22466
Value Function Loss: 0.00464

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.58071
Value Function Update Magnitude: 0.67406

Collected Steps per Second: 22,083.10913
Overall Steps per Second: 10,535.50595

Timestep Collection Time: 2.26508
Timestep Consumption Time: 2.48268
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.74775

Cumulative Model Updates: 90,190
Cumulative Timesteps: 752,235,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 752235558...
Checkpoint 752235558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.39196
Policy Entropy: 3.22996
Value Function Loss: 0.00451

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11645
Policy Update Magnitude: 0.57263
Value Function Update Magnitude: 0.67692

Collected Steps per Second: 22,198.02046
Overall Steps per Second: 10,650.02740

Timestep Collection Time: 2.25245
Timestep Consumption Time: 2.44237
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.69482

Cumulative Model Updates: 90,196
Cumulative Timesteps: 752,285,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.02963
Policy Entropy: 3.22825
Value Function Loss: 0.00449

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.56940
Value Function Update Magnitude: 0.67846

Collected Steps per Second: 22,245.16179
Overall Steps per Second: 10,781.80063

Timestep Collection Time: 2.24813
Timestep Consumption Time: 2.39024
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.63837

Cumulative Model Updates: 90,202
Cumulative Timesteps: 752,335,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 752335568...
Checkpoint 752335568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.89415
Policy Entropy: 3.22143
Value Function Loss: 0.00448

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.57199
Value Function Update Magnitude: 0.67232

Collected Steps per Second: 22,171.78944
Overall Steps per Second: 10,661.82896

Timestep Collection Time: 2.25638
Timestep Consumption Time: 2.43587
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.69225

Cumulative Model Updates: 90,208
Cumulative Timesteps: 752,385,596

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.07316
Policy Entropy: 3.23654
Value Function Loss: 0.00449

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08458
Policy Update Magnitude: 0.57713
Value Function Update Magnitude: 0.68138

Collected Steps per Second: 22,144.09841
Overall Steps per Second: 10,688.20017

Timestep Collection Time: 2.25875
Timestep Consumption Time: 2.42099
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.67974

Cumulative Model Updates: 90,214
Cumulative Timesteps: 752,435,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 752435614...
Checkpoint 752435614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.21993
Policy Entropy: 3.23050
Value Function Loss: 0.00458

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08578
Policy Update Magnitude: 0.57928
Value Function Update Magnitude: 0.67487

Collected Steps per Second: 22,246.39486
Overall Steps per Second: 10,808.07928

Timestep Collection Time: 2.24836
Timestep Consumption Time: 2.37947
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.62783

Cumulative Model Updates: 90,220
Cumulative Timesteps: 752,485,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.00395
Policy Entropy: 3.22989
Value Function Loss: 0.00436

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08133
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.66699

Collected Steps per Second: 22,258.25091
Overall Steps per Second: 10,525.71017

Timestep Collection Time: 2.24636
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.75027

Cumulative Model Updates: 90,226
Cumulative Timesteps: 752,535,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 752535632...
Checkpoint 752535632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 827.37551
Policy Entropy: 3.24024
Value Function Loss: 0.00434

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.56696
Value Function Update Magnitude: 0.65752

Collected Steps per Second: 22,483.98148
Overall Steps per Second: 10,658.19454

Timestep Collection Time: 2.22478
Timestep Consumption Time: 2.46851
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.69329

Cumulative Model Updates: 90,232
Cumulative Timesteps: 752,585,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 722.55886
Policy Entropy: 3.23416
Value Function Loss: 0.00440

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.56795
Value Function Update Magnitude: 0.64928

Collected Steps per Second: 22,370.77846
Overall Steps per Second: 10,424.99124

Timestep Collection Time: 2.23640
Timestep Consumption Time: 2.56265
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.79904

Cumulative Model Updates: 90,238
Cumulative Timesteps: 752,635,684

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 752635684...
Checkpoint 752635684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.51079
Policy Entropy: 3.24060
Value Function Loss: 0.00453

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.57176
Value Function Update Magnitude: 0.66428

Collected Steps per Second: 22,065.74448
Overall Steps per Second: 10,601.73609

Timestep Collection Time: 2.26614
Timestep Consumption Time: 2.45045
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.71659

Cumulative Model Updates: 90,244
Cumulative Timesteps: 752,685,688

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.90431
Policy Entropy: 3.22022
Value Function Loss: 0.00436

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.56685
Value Function Update Magnitude: 0.68746

Collected Steps per Second: 22,988.15078
Overall Steps per Second: 10,602.61884

Timestep Collection Time: 2.17599
Timestep Consumption Time: 2.54190
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.71789

Cumulative Model Updates: 90,250
Cumulative Timesteps: 752,735,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 752735710...
Checkpoint 752735710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.88608
Policy Entropy: 3.23148
Value Function Loss: 0.00428

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.68814

Collected Steps per Second: 22,774.52100
Overall Steps per Second: 10,615.41347

Timestep Collection Time: 2.19667
Timestep Consumption Time: 2.51610
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.71277

Cumulative Model Updates: 90,256
Cumulative Timesteps: 752,785,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.37552
Policy Entropy: 3.21728
Value Function Loss: 0.00438

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10902
Policy Update Magnitude: 0.56589
Value Function Update Magnitude: 0.68748

Collected Steps per Second: 22,793.92555
Overall Steps per Second: 10,766.98008

Timestep Collection Time: 2.19444
Timestep Consumption Time: 2.45124
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.64569

Cumulative Model Updates: 90,262
Cumulative Timesteps: 752,835,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 752835758...
Checkpoint 752835758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.38984
Policy Entropy: 3.22804
Value Function Loss: 0.00434

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.56386
Value Function Update Magnitude: 0.68068

Collected Steps per Second: 22,792.93203
Overall Steps per Second: 10,711.77040

Timestep Collection Time: 2.19463
Timestep Consumption Time: 2.47519
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.66982

Cumulative Model Updates: 90,268
Cumulative Timesteps: 752,885,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.47237
Policy Entropy: 3.21626
Value Function Loss: 0.00452

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10482
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.65284

Collected Steps per Second: 22,794.93730
Overall Steps per Second: 10,632.92044

Timestep Collection Time: 2.19435
Timestep Consumption Time: 2.50991
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.70426

Cumulative Model Updates: 90,274
Cumulative Timesteps: 752,935,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 752935800...
Checkpoint 752935800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677.92910
Policy Entropy: 3.22001
Value Function Loss: 0.00433

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.54895
Value Function Update Magnitude: 0.64103

Collected Steps per Second: 23,183.08484
Overall Steps per Second: 10,820.89448

Timestep Collection Time: 2.15674
Timestep Consumption Time: 2.46395
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.62069

Cumulative Model Updates: 90,280
Cumulative Timesteps: 752,985,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.59169
Policy Entropy: 3.21667
Value Function Loss: 0.00455

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.55744
Value Function Update Magnitude: 0.63895

Collected Steps per Second: 22,211.44035
Overall Steps per Second: 10,568.58184

Timestep Collection Time: 2.25172
Timestep Consumption Time: 2.48061
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.73233

Cumulative Model Updates: 90,286
Cumulative Timesteps: 753,035,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 753035814...
Checkpoint 753035814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.37645
Policy Entropy: 3.23206
Value Function Loss: 0.00438

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08913
Policy Update Magnitude: 0.55882
Value Function Update Magnitude: 0.64187

Collected Steps per Second: 21,695.19860
Overall Steps per Second: 10,495.53757

Timestep Collection Time: 2.30466
Timestep Consumption Time: 2.45927
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.76393

Cumulative Model Updates: 90,292
Cumulative Timesteps: 753,085,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.31426
Policy Entropy: 3.21868
Value Function Loss: 0.00449

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.56343
Value Function Update Magnitude: 0.63189

Collected Steps per Second: 22,552.79555
Overall Steps per Second: 10,565.79744

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.51604
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.73376

Cumulative Model Updates: 90,298
Cumulative Timesteps: 753,135,830

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 753135830...
Checkpoint 753135830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 866.46759
Policy Entropy: 3.23173
Value Function Loss: 0.00436

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.56036
Value Function Update Magnitude: 0.62577

Collected Steps per Second: 22,415.87895
Overall Steps per Second: 10,669.16995

Timestep Collection Time: 2.23154
Timestep Consumption Time: 2.45692
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.68846

Cumulative Model Updates: 90,304
Cumulative Timesteps: 753,185,852

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.29161
Policy Entropy: 3.22766
Value Function Loss: 0.00454

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.56194
Value Function Update Magnitude: 0.64455

Collected Steps per Second: 23,162.26031
Overall Steps per Second: 10,772.74395

Timestep Collection Time: 2.15929
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.64264

Cumulative Model Updates: 90,310
Cumulative Timesteps: 753,235,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 753235866...
Checkpoint 753235866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.70005
Policy Entropy: 3.24302
Value Function Loss: 0.00442

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.65051

Collected Steps per Second: 22,572.17694
Overall Steps per Second: 10,729.08611

Timestep Collection Time: 2.21645
Timestep Consumption Time: 2.44658
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.66303

Cumulative Model Updates: 90,316
Cumulative Timesteps: 753,285,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.80131
Policy Entropy: 3.23160
Value Function Loss: 0.00444

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.55019
Value Function Update Magnitude: 0.65570

Collected Steps per Second: 23,268.47583
Overall Steps per Second: 10,848.20219

Timestep Collection Time: 2.14892
Timestep Consumption Time: 2.46033
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.60924

Cumulative Model Updates: 90,322
Cumulative Timesteps: 753,335,898

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 753335898...
Checkpoint 753335898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.62476
Policy Entropy: 3.23747
Value Function Loss: 0.00447

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.55016
Value Function Update Magnitude: 0.65306

Collected Steps per Second: 22,784.79386
Overall Steps per Second: 10,734.16240

Timestep Collection Time: 2.19488
Timestep Consumption Time: 2.46407
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.65896

Cumulative Model Updates: 90,328
Cumulative Timesteps: 753,385,908

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.47607
Policy Entropy: 3.23708
Value Function Loss: 0.00427

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.55447
Value Function Update Magnitude: 0.63989

Collected Steps per Second: 22,782.48913
Overall Steps per Second: 10,683.04300

Timestep Collection Time: 2.19537
Timestep Consumption Time: 2.48644
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.68181

Cumulative Model Updates: 90,334
Cumulative Timesteps: 753,435,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 753435924...
Checkpoint 753435924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.30839
Policy Entropy: 3.23092
Value Function Loss: 0.00409

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.54729
Value Function Update Magnitude: 0.61761

Collected Steps per Second: 22,938.56534
Overall Steps per Second: 10,796.50624

Timestep Collection Time: 2.18035
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.63242

Cumulative Model Updates: 90,340
Cumulative Timesteps: 753,485,938

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.09087
Policy Entropy: 3.23242
Value Function Loss: 0.00411

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.54421
Value Function Update Magnitude: 0.62782

Collected Steps per Second: 22,344.82642
Overall Steps per Second: 10,516.41263

Timestep Collection Time: 2.23855
Timestep Consumption Time: 2.51783
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.75637

Cumulative Model Updates: 90,346
Cumulative Timesteps: 753,535,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 753535958...
Checkpoint 753535958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.54278
Policy Entropy: 3.22560
Value Function Loss: 0.00420

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11018
Policy Update Magnitude: 0.54793
Value Function Update Magnitude: 0.65471

Collected Steps per Second: 22,370.73127
Overall Steps per Second: 10,617.46178

Timestep Collection Time: 2.23578
Timestep Consumption Time: 2.47495
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.71073

Cumulative Model Updates: 90,352
Cumulative Timesteps: 753,585,974

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.47590
Policy Entropy: 3.24134
Value Function Loss: 0.00407

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.54670
Value Function Update Magnitude: 0.64899

Collected Steps per Second: 22,740.18812
Overall Steps per Second: 10,660.11921

Timestep Collection Time: 2.19893
Timestep Consumption Time: 2.49183
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.69075

Cumulative Model Updates: 90,358
Cumulative Timesteps: 753,635,978

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 753635978...
Checkpoint 753635978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.41349
Policy Entropy: 3.23773
Value Function Loss: 0.00416

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.54721
Value Function Update Magnitude: 0.62803

Collected Steps per Second: 22,183.99552
Overall Steps per Second: 10,462.60037

Timestep Collection Time: 2.25613
Timestep Consumption Time: 2.52757
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.78371

Cumulative Model Updates: 90,364
Cumulative Timesteps: 753,686,028

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 873.39380
Policy Entropy: 3.26500
Value Function Loss: 0.00396

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.54787
Value Function Update Magnitude: 0.60355

Collected Steps per Second: 22,772.09907
Overall Steps per Second: 10,616.98711

Timestep Collection Time: 2.19681
Timestep Consumption Time: 2.51507
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.71188

Cumulative Model Updates: 90,370
Cumulative Timesteps: 753,736,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 753736054...
Checkpoint 753736054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.09693
Policy Entropy: 3.27322
Value Function Loss: 0.00408

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.54223
Value Function Update Magnitude: 0.58376

Collected Steps per Second: 22,733.73195
Overall Steps per Second: 10,451.20884

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.58528
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.78509

Cumulative Model Updates: 90,376
Cumulative Timesteps: 753,786,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.04230
Policy Entropy: 3.28293
Value Function Loss: 0.00417

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.57824

Collected Steps per Second: 23,304.69219
Overall Steps per Second: 10,886.10269

Timestep Collection Time: 2.14643
Timestep Consumption Time: 2.44860
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.59503

Cumulative Model Updates: 90,382
Cumulative Timesteps: 753,836,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 753836086...
Checkpoint 753836086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.71417
Policy Entropy: 3.26998
Value Function Loss: 0.00433

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.55103
Value Function Update Magnitude: 0.59779

Collected Steps per Second: 22,148.57271
Overall Steps per Second: 10,628.33729

Timestep Collection Time: 2.25866
Timestep Consumption Time: 2.44820
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.70685

Cumulative Model Updates: 90,388
Cumulative Timesteps: 753,886,112

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.58449
Policy Entropy: 3.27172
Value Function Loss: 0.00425

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.60058

Collected Steps per Second: 22,236.70092
Overall Steps per Second: 10,568.30054

Timestep Collection Time: 2.24943
Timestep Consumption Time: 2.48359
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.73302

Cumulative Model Updates: 90,394
Cumulative Timesteps: 753,936,132

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 753936132...
Checkpoint 753936132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.76458
Policy Entropy: 3.27305
Value Function Loss: 0.00422

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.54783
Value Function Update Magnitude: 0.60669

Collected Steps per Second: 21,999.97501
Overall Steps per Second: 10,541.81804

Timestep Collection Time: 2.27318
Timestep Consumption Time: 2.47078
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.74396

Cumulative Model Updates: 90,400
Cumulative Timesteps: 753,986,142

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.15386
Policy Entropy: 3.27845
Value Function Loss: 0.00418

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.57709

Collected Steps per Second: 22,310.76309
Overall Steps per Second: 10,716.67060

Timestep Collection Time: 2.24125
Timestep Consumption Time: 2.42475
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.66600

Cumulative Model Updates: 90,406
Cumulative Timesteps: 754,036,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 754036146...
Checkpoint 754036146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.79683
Policy Entropy: 3.28009
Value Function Loss: 0.00418

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08694
Policy Update Magnitude: 0.54230
Value Function Update Magnitude: 0.57015

Collected Steps per Second: 22,430.05240
Overall Steps per Second: 10,866.61092

Timestep Collection Time: 2.22987
Timestep Consumption Time: 2.37286
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.60272

Cumulative Model Updates: 90,412
Cumulative Timesteps: 754,086,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.11360
Policy Entropy: 3.27124
Value Function Loss: 0.00402

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09084
Policy Update Magnitude: 0.54285
Value Function Update Magnitude: 0.54918

Collected Steps per Second: 22,421.29242
Overall Steps per Second: 10,823.45795

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.38967
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.61978

Cumulative Model Updates: 90,418
Cumulative Timesteps: 754,136,164

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 754136164...
Checkpoint 754136164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.03223
Policy Entropy: 3.26595
Value Function Loss: 0.00409

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10365
Policy Update Magnitude: 0.53968
Value Function Update Magnitude: 0.55899

Collected Steps per Second: 21,960.07790
Overall Steps per Second: 10,747.55669

Timestep Collection Time: 2.27741
Timestep Consumption Time: 2.37593
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.65334

Cumulative Model Updates: 90,424
Cumulative Timesteps: 754,186,176

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,897.28403
Policy Entropy: 3.28007
Value Function Loss: 0.00385

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.53510
Value Function Update Magnitude: 0.56726

Collected Steps per Second: 21,636.15950
Overall Steps per Second: 10,538.11654

Timestep Collection Time: 2.31150
Timestep Consumption Time: 2.43432
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.74582

Cumulative Model Updates: 90,430
Cumulative Timesteps: 754,236,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 754236188...
Checkpoint 754236188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.14100
Policy Entropy: 3.26997
Value Function Loss: 0.00387

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08824
Policy Update Magnitude: 0.53420
Value Function Update Magnitude: 0.56392

Collected Steps per Second: 21,518.86266
Overall Steps per Second: 10,497.55285

Timestep Collection Time: 2.32382
Timestep Consumption Time: 2.43976
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.76359

Cumulative Model Updates: 90,436
Cumulative Timesteps: 754,286,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.15650
Policy Entropy: 3.26894
Value Function Loss: 0.00400

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08113
Policy Update Magnitude: 0.54180
Value Function Update Magnitude: 0.57419

Collected Steps per Second: 21,861.69249
Overall Steps per Second: 10,557.44019

Timestep Collection Time: 2.28729
Timestep Consumption Time: 2.44909
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.73638

Cumulative Model Updates: 90,442
Cumulative Timesteps: 754,336,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 754336198...
Checkpoint 754336198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 980.23324
Policy Entropy: 3.26321
Value Function Loss: 0.00396

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.54133
Value Function Update Magnitude: 0.58378

Collected Steps per Second: 21,647.52567
Overall Steps per Second: 10,559.62664

Timestep Collection Time: 2.31056
Timestep Consumption Time: 2.42616
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.73672

Cumulative Model Updates: 90,448
Cumulative Timesteps: 754,386,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,667.37976
Policy Entropy: 3.26750
Value Function Loss: 0.00396

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.54061
Value Function Update Magnitude: 0.56605

Collected Steps per Second: 21,982.41363
Overall Steps per Second: 10,629.10957

Timestep Collection Time: 2.27455
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.70406

Cumulative Model Updates: 90,454
Cumulative Timesteps: 754,436,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 754436216...
Checkpoint 754436216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.99105
Policy Entropy: 3.27502
Value Function Loss: 0.00404

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08680
Policy Update Magnitude: 0.54252
Value Function Update Magnitude: 0.54689

Collected Steps per Second: 22,499.09767
Overall Steps per Second: 10,572.75733

Timestep Collection Time: 2.22284
Timestep Consumption Time: 2.50743
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.73027

Cumulative Model Updates: 90,460
Cumulative Timesteps: 754,486,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.40249
Policy Entropy: 3.27107
Value Function Loss: 0.00405

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.53909
Value Function Update Magnitude: 0.55457

Collected Steps per Second: 22,293.82205
Overall Steps per Second: 10,676.61990

Timestep Collection Time: 2.24277
Timestep Consumption Time: 2.44036
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.68313

Cumulative Model Updates: 90,466
Cumulative Timesteps: 754,536,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 754536228...
Checkpoint 754536228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.76073
Policy Entropy: 3.28071
Value Function Loss: 0.00384

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.53142
Value Function Update Magnitude: 0.54577

Collected Steps per Second: 21,887.35394
Overall Steps per Second: 10,664.76116

Timestep Collection Time: 2.28543
Timestep Consumption Time: 2.40497
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.69040

Cumulative Model Updates: 90,472
Cumulative Timesteps: 754,586,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.59706
Policy Entropy: 3.27482
Value Function Loss: 0.00377

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07548
Policy Update Magnitude: 0.52741
Value Function Update Magnitude: 0.52301

Collected Steps per Second: 22,111.93955
Overall Steps per Second: 10,641.85672

Timestep Collection Time: 2.26213
Timestep Consumption Time: 2.43818
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.70031

Cumulative Model Updates: 90,478
Cumulative Timesteps: 754,636,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 754636270...
Checkpoint 754636270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.76292
Policy Entropy: 3.26712
Value Function Loss: 0.00399

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.07312
Policy Update Magnitude: 0.53207
Value Function Update Magnitude: 0.52596

Collected Steps per Second: 22,118.99494
Overall Steps per Second: 10,651.74338

Timestep Collection Time: 2.26213
Timestep Consumption Time: 2.43532
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.69745

Cumulative Model Updates: 90,484
Cumulative Timesteps: 754,686,306

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.96276
Policy Entropy: 3.25818
Value Function Loss: 0.00402

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08325
Policy Update Magnitude: 0.54471
Value Function Update Magnitude: 0.55365

Collected Steps per Second: 22,183.79464
Overall Steps per Second: 10,765.98987

Timestep Collection Time: 2.25417
Timestep Consumption Time: 2.39064
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.64481

Cumulative Model Updates: 90,490
Cumulative Timesteps: 754,736,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 754736312...
Checkpoint 754736312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.36907
Policy Entropy: 3.25155
Value Function Loss: 0.00417

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.54622
Value Function Update Magnitude: 0.57520

Collected Steps per Second: 21,930.38320
Overall Steps per Second: 10,666.25587

Timestep Collection Time: 2.28076
Timestep Consumption Time: 2.40861
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.68937

Cumulative Model Updates: 90,496
Cumulative Timesteps: 754,786,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.40236
Policy Entropy: 3.25619
Value Function Loss: 0.00413

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10728
Policy Update Magnitude: 0.55088
Value Function Update Magnitude: 0.58225

Collected Steps per Second: 21,864.95750
Overall Steps per Second: 10,610.63579

Timestep Collection Time: 2.28740
Timestep Consumption Time: 2.42617
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.71357

Cumulative Model Updates: 90,502
Cumulative Timesteps: 754,836,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 754836344...
Checkpoint 754836344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.85058
Policy Entropy: 3.23252
Value Function Loss: 0.00414

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.55042
Value Function Update Magnitude: 0.57422

Collected Steps per Second: 21,657.23808
Overall Steps per Second: 10,495.57793

Timestep Collection Time: 2.30971
Timestep Consumption Time: 2.45629
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.76601

Cumulative Model Updates: 90,508
Cumulative Timesteps: 754,886,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.16145
Policy Entropy: 3.22887
Value Function Loss: 0.00407

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.56385

Collected Steps per Second: 22,808.58566
Overall Steps per Second: 10,768.04195

Timestep Collection Time: 2.19260
Timestep Consumption Time: 2.45170
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.64430

Cumulative Model Updates: 90,514
Cumulative Timesteps: 754,936,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 754936376...
Checkpoint 754936376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.41407
Policy Entropy: 3.23881
Value Function Loss: 0.00395

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.56245
Value Function Update Magnitude: 0.57050

Collected Steps per Second: 22,235.42710
Overall Steps per Second: 10,664.92069

Timestep Collection Time: 2.24866
Timestep Consumption Time: 2.43960
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.68827

Cumulative Model Updates: 90,520
Cumulative Timesteps: 754,986,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.93719
Policy Entropy: 3.23317
Value Function Loss: 0.00412

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.56044
Value Function Update Magnitude: 0.57444

Collected Steps per Second: 22,752.12346
Overall Steps per Second: 10,575.47282

Timestep Collection Time: 2.19812
Timestep Consumption Time: 2.53093
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.72906

Cumulative Model Updates: 90,526
Cumulative Timesteps: 755,036,388

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 755036388...
Checkpoint 755036388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.64771
Policy Entropy: 3.23698
Value Function Loss: 0.00409

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.55783
Value Function Update Magnitude: 0.58556

Collected Steps per Second: 22,214.96777
Overall Steps per Second: 10,613.07856

Timestep Collection Time: 2.25118
Timestep Consumption Time: 2.46093
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.71211

Cumulative Model Updates: 90,532
Cumulative Timesteps: 755,086,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 624.94108
Policy Entropy: 3.22308
Value Function Loss: 0.00407

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.60355

Collected Steps per Second: 22,979.35355
Overall Steps per Second: 10,630.08357

Timestep Collection Time: 2.17648
Timestep Consumption Time: 2.52847
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.70495

Cumulative Model Updates: 90,538
Cumulative Timesteps: 755,136,412

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 755136412...
Checkpoint 755136412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524.25874
Policy Entropy: 3.23547
Value Function Loss: 0.00421

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.61230

Collected Steps per Second: 22,621.05514
Overall Steps per Second: 10,605.91820

Timestep Collection Time: 2.21139
Timestep Consumption Time: 2.50522
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.71661

Cumulative Model Updates: 90,544
Cumulative Timesteps: 755,186,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.92157
Policy Entropy: 3.23708
Value Function Loss: 0.00420

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10339
Policy Update Magnitude: 0.56484
Value Function Update Magnitude: 0.59968

Collected Steps per Second: 23,296.43644
Overall Steps per Second: 10,754.30579

Timestep Collection Time: 2.14677
Timestep Consumption Time: 2.50365
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.65042

Cumulative Model Updates: 90,550
Cumulative Timesteps: 755,236,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 755236448...
Checkpoint 755236448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 653.43019
Policy Entropy: 3.22931
Value Function Loss: 0.00441

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.56744
Value Function Update Magnitude: 0.59123

Collected Steps per Second: 22,760.80199
Overall Steps per Second: 10,638.65408

Timestep Collection Time: 2.19720
Timestep Consumption Time: 2.50358
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.70078

Cumulative Model Updates: 90,556
Cumulative Timesteps: 755,286,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 794.62367
Policy Entropy: 3.23300
Value Function Loss: 0.00438

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.58339

Collected Steps per Second: 22,925.10538
Overall Steps per Second: 10,789.62158

Timestep Collection Time: 2.18154
Timestep Consumption Time: 2.45366
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.63519

Cumulative Model Updates: 90,562
Cumulative Timesteps: 755,336,470

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 755336470...
Checkpoint 755336470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.54252
Policy Entropy: 3.21653
Value Function Loss: 0.00475

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10780
Policy Update Magnitude: 0.57219
Value Function Update Magnitude: 0.59868

Collected Steps per Second: 22,354.53664
Overall Steps per Second: 10,654.44495

Timestep Collection Time: 2.23767
Timestep Consumption Time: 2.45728
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.69494

Cumulative Model Updates: 90,568
Cumulative Timesteps: 755,386,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.27836
Policy Entropy: 3.20852
Value Function Loss: 0.00472

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.57577
Value Function Update Magnitude: 0.62785

Collected Steps per Second: 21,931.48332
Overall Steps per Second: 10,579.06036

Timestep Collection Time: 2.28056
Timestep Consumption Time: 2.44727
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.72783

Cumulative Model Updates: 90,574
Cumulative Timesteps: 755,436,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 755436508...
Checkpoint 755436508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.92367
Policy Entropy: 3.19030
Value Function Loss: 0.00478

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.58922
Value Function Update Magnitude: 0.63019

Collected Steps per Second: 22,205.15606
Overall Steps per Second: 10,653.10489

Timestep Collection Time: 2.25254
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.69516

Cumulative Model Updates: 90,580
Cumulative Timesteps: 755,486,526

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.91317
Policy Entropy: 3.19615
Value Function Loss: 0.00451

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09676
Policy Update Magnitude: 0.58788
Value Function Update Magnitude: 0.62220

Collected Steps per Second: 22,771.92433
Overall Steps per Second: 10,558.95608

Timestep Collection Time: 2.19569
Timestep Consumption Time: 2.53963
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.73532

Cumulative Model Updates: 90,586
Cumulative Timesteps: 755,536,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 755536526...
Checkpoint 755536526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.42090
Policy Entropy: 3.19874
Value Function Loss: 0.00447

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.57231
Value Function Update Magnitude: 0.61146

Collected Steps per Second: 22,282.83615
Overall Steps per Second: 10,498.48731

Timestep Collection Time: 2.24415
Timestep Consumption Time: 2.51901
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.76316

Cumulative Model Updates: 90,592
Cumulative Timesteps: 755,586,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.59652
Policy Entropy: 3.21383
Value Function Loss: 0.00437

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.56979
Value Function Update Magnitude: 0.60332

Collected Steps per Second: 23,112.84576
Overall Steps per Second: 10,663.23910

Timestep Collection Time: 2.16339
Timestep Consumption Time: 2.52581
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.68919

Cumulative Model Updates: 90,598
Cumulative Timesteps: 755,636,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 755636534...
Checkpoint 755636534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.61977
Policy Entropy: 3.21322
Value Function Loss: 0.00426

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12941
Policy Update Magnitude: 0.57056
Value Function Update Magnitude: 0.60402

Collected Steps per Second: 23,095.48042
Overall Steps per Second: 10,820.48783

Timestep Collection Time: 2.16605
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.62327

Cumulative Model Updates: 90,604
Cumulative Timesteps: 755,686,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 753.07359
Policy Entropy: 3.22664
Value Function Loss: 0.00414

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12180
Policy Update Magnitude: 0.56794
Value Function Update Magnitude: 0.60183

Collected Steps per Second: 23,087.79766
Overall Steps per Second: 10,711.17035

Timestep Collection Time: 2.16617
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.66914

Cumulative Model Updates: 90,610
Cumulative Timesteps: 755,736,572

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 755736572...
Checkpoint 755736572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.16894
Policy Entropy: 3.22895
Value Function Loss: 0.00425

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.14649
Policy Update Magnitude: 0.56008
Value Function Update Magnitude: 0.61527

Collected Steps per Second: 22,717.56460
Overall Steps per Second: 10,652.83042

Timestep Collection Time: 2.20200
Timestep Consumption Time: 2.49384
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.69584

Cumulative Model Updates: 90,616
Cumulative Timesteps: 755,786,596

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 990.36394
Policy Entropy: 3.21844
Value Function Loss: 0.00424

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.56563
Value Function Update Magnitude: 0.62158

Collected Steps per Second: 22,961.36711
Overall Steps per Second: 10,700.43469

Timestep Collection Time: 2.17792
Timestep Consumption Time: 2.49554
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.67346

Cumulative Model Updates: 90,622
Cumulative Timesteps: 755,836,604

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 755836604...
Checkpoint 755836604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.12729
Policy Entropy: 3.18929
Value Function Loss: 0.00451

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11226
Policy Update Magnitude: 0.57571
Value Function Update Magnitude: 0.60869

Collected Steps per Second: 22,692.94242
Overall Steps per Second: 10,626.32917

Timestep Collection Time: 2.20386
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.70642

Cumulative Model Updates: 90,628
Cumulative Timesteps: 755,886,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.85745
Policy Entropy: 3.19191
Value Function Loss: 0.00464

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.58601
Value Function Update Magnitude: 0.62289

Collected Steps per Second: 22,556.21393
Overall Steps per Second: 10,623.95758

Timestep Collection Time: 2.21686
Timestep Consumption Time: 2.48986
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.70672

Cumulative Model Updates: 90,634
Cumulative Timesteps: 755,936,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 755936620...
Checkpoint 755936620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 956.57409
Policy Entropy: 3.18649
Value Function Loss: 0.00465

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11100
Policy Update Magnitude: 0.58511
Value Function Update Magnitude: 0.61289

Collected Steps per Second: 22,294.84629
Overall Steps per Second: 10,540.28942

Timestep Collection Time: 2.24312
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.74465

Cumulative Model Updates: 90,640
Cumulative Timesteps: 755,986,630

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.99625
Policy Entropy: 3.19861
Value Function Loss: 0.00451

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.57907
Value Function Update Magnitude: 0.60388

Collected Steps per Second: 22,694.84515
Overall Steps per Second: 10,794.13250

Timestep Collection Time: 2.20323
Timestep Consumption Time: 2.42910
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.63233

Cumulative Model Updates: 90,646
Cumulative Timesteps: 756,036,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 756036632...
Checkpoint 756036632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.13997
Policy Entropy: 3.19299
Value Function Loss: 0.00453

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.57815
Value Function Update Magnitude: 0.61645

Collected Steps per Second: 22,498.12081
Overall Steps per Second: 10,734.35776

Timestep Collection Time: 2.22330
Timestep Consumption Time: 2.43651
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.65980

Cumulative Model Updates: 90,652
Cumulative Timesteps: 756,086,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.50936
Policy Entropy: 3.19060
Value Function Loss: 0.00439

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.57826
Value Function Update Magnitude: 0.62074

Collected Steps per Second: 23,306.22054
Overall Steps per Second: 10,796.22517

Timestep Collection Time: 2.14664
Timestep Consumption Time: 2.48739
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.63403

Cumulative Model Updates: 90,658
Cumulative Timesteps: 756,136,682

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 756136682...
Checkpoint 756136682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.67281
Policy Entropy: 3.18989
Value Function Loss: 0.00433

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.56938
Value Function Update Magnitude: 0.62204

Collected Steps per Second: 22,609.45316
Overall Steps per Second: 10,695.39166

Timestep Collection Time: 2.21182
Timestep Consumption Time: 2.46384
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.67566

Cumulative Model Updates: 90,664
Cumulative Timesteps: 756,186,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 648.03786
Policy Entropy: 3.19554
Value Function Loss: 0.00442

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09825
Policy Update Magnitude: 0.57025
Value Function Update Magnitude: 0.61059

Collected Steps per Second: 22,864.72715
Overall Steps per Second: 10,809.54101

Timestep Collection Time: 2.18677
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.62554

Cumulative Model Updates: 90,670
Cumulative Timesteps: 756,236,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 756236690...
Checkpoint 756236690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.43393
Policy Entropy: 3.20606
Value Function Loss: 0.00444

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.57673
Value Function Update Magnitude: 0.60955

Collected Steps per Second: 22,558.34655
Overall Steps per Second: 10,669.19285

Timestep Collection Time: 2.21692
Timestep Consumption Time: 2.47041
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.68733

Cumulative Model Updates: 90,676
Cumulative Timesteps: 756,286,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.66700
Policy Entropy: 3.20725
Value Function Loss: 0.00452

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.57180
Value Function Update Magnitude: 0.60067

Collected Steps per Second: 22,813.60014
Overall Steps per Second: 10,651.34671

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.50417
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.69725

Cumulative Model Updates: 90,682
Cumulative Timesteps: 756,336,732

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 756336732...
Checkpoint 756336732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.79846
Policy Entropy: 3.20966
Value Function Loss: 0.00424

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.56816
Value Function Update Magnitude: 0.59685

Collected Steps per Second: 22,649.78789
Overall Steps per Second: 10,681.29200

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.47435
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.68258

Cumulative Model Updates: 90,688
Cumulative Timesteps: 756,386,748

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.05862
Policy Entropy: 3.20353
Value Function Loss: 0.00428

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.56106
Value Function Update Magnitude: 0.59181

Collected Steps per Second: 22,665.25917
Overall Steps per Second: 10,767.01875

Timestep Collection Time: 2.20637
Timestep Consumption Time: 2.43818
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.64455

Cumulative Model Updates: 90,694
Cumulative Timesteps: 756,436,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 756436756...
Checkpoint 756436756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.75529
Policy Entropy: 3.21740
Value Function Loss: 0.00428

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.55632
Value Function Update Magnitude: 0.58967

Collected Steps per Second: 22,277.26444
Overall Steps per Second: 10,636.90930

Timestep Collection Time: 2.24462
Timestep Consumption Time: 2.45637
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.70099

Cumulative Model Updates: 90,700
Cumulative Timesteps: 756,486,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.86611
Policy Entropy: 3.22559
Value Function Loss: 0.00425

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.55555
Value Function Update Magnitude: 0.60493

Collected Steps per Second: 22,480.16972
Overall Steps per Second: 10,634.79692

Timestep Collection Time: 2.22472
Timestep Consumption Time: 2.47796
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.70268

Cumulative Model Updates: 90,706
Cumulative Timesteps: 756,536,772

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 756536772...
Checkpoint 756536772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.71096
Policy Entropy: 3.24152
Value Function Loss: 0.00429

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.55160
Value Function Update Magnitude: 0.61934

Collected Steps per Second: 22,088.33842
Overall Steps per Second: 10,507.83881

Timestep Collection Time: 2.26364
Timestep Consumption Time: 2.49471
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.75835

Cumulative Model Updates: 90,712
Cumulative Timesteps: 756,586,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.85649
Policy Entropy: 3.23164
Value Function Loss: 0.00438

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11165
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.61404

Collected Steps per Second: 23,122.98785
Overall Steps per Second: 10,859.99549

Timestep Collection Time: 2.16252
Timestep Consumption Time: 2.44190
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.60442

Cumulative Model Updates: 90,718
Cumulative Timesteps: 756,636,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 756636776...
Checkpoint 756636776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.33675
Policy Entropy: 3.22495
Value Function Loss: 0.00455

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.56399
Value Function Update Magnitude: 0.61959

Collected Steps per Second: 22,731.12297
Overall Steps per Second: 10,624.08083

Timestep Collection Time: 2.19998
Timestep Consumption Time: 2.50706
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.70704

Cumulative Model Updates: 90,724
Cumulative Timesteps: 756,686,784

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.18425
Policy Entropy: 3.22536
Value Function Loss: 0.00438

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11833
Policy Update Magnitude: 0.55969
Value Function Update Magnitude: 0.61470

Collected Steps per Second: 23,186.48728
Overall Steps per Second: 10,863.90807

Timestep Collection Time: 2.15746
Timestep Consumption Time: 2.44714
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.60460

Cumulative Model Updates: 90,730
Cumulative Timesteps: 756,736,808

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 756736808...
Checkpoint 756736808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.06978
Policy Entropy: 3.21809
Value Function Loss: 0.00442

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.62124

Collected Steps per Second: 22,432.09454
Overall Steps per Second: 10,702.52641

Timestep Collection Time: 2.22966
Timestep Consumption Time: 2.44363
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.67329

Cumulative Model Updates: 90,736
Cumulative Timesteps: 756,786,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.60201
Policy Entropy: 3.22276
Value Function Loss: 0.00442

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.55971
Value Function Update Magnitude: 0.62129

Collected Steps per Second: 22,817.20834
Overall Steps per Second: 10,793.97801

Timestep Collection Time: 2.19142
Timestep Consumption Time: 2.44098
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.63240

Cumulative Model Updates: 90,742
Cumulative Timesteps: 756,836,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 756836826...
Checkpoint 756836826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.97480
Policy Entropy: 3.22352
Value Function Loss: 0.00449

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10935
Policy Update Magnitude: 0.56297
Value Function Update Magnitude: 0.61878

Collected Steps per Second: 22,513.86755
Overall Steps per Second: 10,764.67374

Timestep Collection Time: 2.22103
Timestep Consumption Time: 2.42416
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.64519

Cumulative Model Updates: 90,748
Cumulative Timesteps: 756,886,830

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.32151
Policy Entropy: 3.23430
Value Function Loss: 0.00439

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.56873
Value Function Update Magnitude: 0.65098

Collected Steps per Second: 22,837.08765
Overall Steps per Second: 10,799.06496

Timestep Collection Time: 2.19030
Timestep Consumption Time: 2.44159
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.63188

Cumulative Model Updates: 90,754
Cumulative Timesteps: 756,936,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 756936850...
Checkpoint 756936850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.44808
Policy Entropy: 3.24292
Value Function Loss: 0.00441

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.57195
Value Function Update Magnitude: 0.64076

Collected Steps per Second: 22,237.19263
Overall Steps per Second: 10,718.29550

Timestep Collection Time: 2.24947
Timestep Consumption Time: 2.41750
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.66697

Cumulative Model Updates: 90,760
Cumulative Timesteps: 756,986,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.75546
Policy Entropy: 3.24598
Value Function Loss: 0.00431

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.63659

Collected Steps per Second: 22,500.26842
Overall Steps per Second: 10,620.88912

Timestep Collection Time: 2.22228
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.70789

Cumulative Model Updates: 90,766
Cumulative Timesteps: 757,036,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 757036874...
Checkpoint 757036874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.90902
Policy Entropy: 3.24401
Value Function Loss: 0.00454

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.57426
Value Function Update Magnitude: 0.63623

Collected Steps per Second: 22,616.48246
Overall Steps per Second: 10,684.23776

Timestep Collection Time: 2.21210
Timestep Consumption Time: 2.47050
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.68260

Cumulative Model Updates: 90,772
Cumulative Timesteps: 757,086,904

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.17119
Policy Entropy: 3.24194
Value Function Loss: 0.00441

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.56855
Value Function Update Magnitude: 0.65145

Collected Steps per Second: 22,477.24909
Overall Steps per Second: 10,695.19929

Timestep Collection Time: 2.22447
Timestep Consumption Time: 2.45052
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.67499

Cumulative Model Updates: 90,778
Cumulative Timesteps: 757,136,904

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 757136904...
Checkpoint 757136904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.81582
Policy Entropy: 3.23646
Value Function Loss: 0.00465

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.57036
Value Function Update Magnitude: 0.66657

Collected Steps per Second: 22,368.49786
Overall Steps per Second: 10,652.41448

Timestep Collection Time: 2.23573
Timestep Consumption Time: 2.45898
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.69471

Cumulative Model Updates: 90,784
Cumulative Timesteps: 757,186,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.79091
Policy Entropy: 3.23074
Value Function Loss: 0.00451

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.57605
Value Function Update Magnitude: 0.66970

Collected Steps per Second: 22,915.85469
Overall Steps per Second: 10,813.49010

Timestep Collection Time: 2.18294
Timestep Consumption Time: 2.44313
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.62607

Cumulative Model Updates: 90,790
Cumulative Timesteps: 757,236,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 757236938...
Checkpoint 757236938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.55712
Policy Entropy: 3.23594
Value Function Loss: 0.00462

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.65159

Collected Steps per Second: 22,612.17645
Overall Steps per Second: 10,778.38011

Timestep Collection Time: 2.21244
Timestep Consumption Time: 2.42908
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.64151

Cumulative Model Updates: 90,796
Cumulative Timesteps: 757,286,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.62703
Policy Entropy: 3.22747
Value Function Loss: 0.00439

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.57527
Value Function Update Magnitude: 0.64624

Collected Steps per Second: 22,999.72407
Overall Steps per Second: 10,820.76989

Timestep Collection Time: 2.17481
Timestep Consumption Time: 2.44778
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.62259

Cumulative Model Updates: 90,802
Cumulative Timesteps: 757,336,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 757336986...
Checkpoint 757336986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.81089
Policy Entropy: 3.24153
Value Function Loss: 0.00432

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.56649
Value Function Update Magnitude: 0.64080

Collected Steps per Second: 22,731.19642
Overall Steps per Second: 10,690.79324

Timestep Collection Time: 2.20050
Timestep Consumption Time: 2.47829
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.67879

Cumulative Model Updates: 90,808
Cumulative Timesteps: 757,387,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.08011
Policy Entropy: 3.22921
Value Function Loss: 0.00421

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10301
Policy Update Magnitude: 0.56553
Value Function Update Magnitude: 0.64495

Collected Steps per Second: 23,052.54713
Overall Steps per Second: 10,837.48519

Timestep Collection Time: 2.16983
Timestep Consumption Time: 2.44564
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.61546

Cumulative Model Updates: 90,814
Cumulative Timesteps: 757,437,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 757437026...
Checkpoint 757437026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.57207
Policy Entropy: 3.22308
Value Function Loss: 0.00433

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.56883
Value Function Update Magnitude: 0.65175

Collected Steps per Second: 22,065.50394
Overall Steps per Second: 10,667.53189

Timestep Collection Time: 2.26661
Timestep Consumption Time: 2.42182
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.68843

Cumulative Model Updates: 90,820
Cumulative Timesteps: 757,487,040

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.62955
Policy Entropy: 3.21957
Value Function Loss: 0.00438

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.57177
Value Function Update Magnitude: 0.67599

Collected Steps per Second: 22,278.48255
Overall Steps per Second: 10,518.92546

Timestep Collection Time: 2.24638
Timestep Consumption Time: 2.51133
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.75771

Cumulative Model Updates: 90,826
Cumulative Timesteps: 757,537,086

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 757537086...
Checkpoint 757537086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.89017
Policy Entropy: 3.20527
Value Function Loss: 0.00421

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.57640
Value Function Update Magnitude: 0.66612

Collected Steps per Second: 22,270.99611
Overall Steps per Second: 10,617.22049

Timestep Collection Time: 2.24633
Timestep Consumption Time: 2.46564
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.71197

Cumulative Model Updates: 90,832
Cumulative Timesteps: 757,587,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.51552
Policy Entropy: 3.20841
Value Function Loss: 0.00423

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09613
Policy Update Magnitude: 0.57615
Value Function Update Magnitude: 0.66256

Collected Steps per Second: 22,667.09575
Overall Steps per Second: 10,662.81558

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.48484
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.69201

Cumulative Model Updates: 90,838
Cumulative Timesteps: 757,637,144

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 757637144...
Checkpoint 757637144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,761.43110
Policy Entropy: 3.20421
Value Function Loss: 0.00431

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.57366
Value Function Update Magnitude: 0.67301

Collected Steps per Second: 22,942.68760
Overall Steps per Second: 10,736.88388

Timestep Collection Time: 2.17943
Timestep Consumption Time: 2.47760
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.65703

Cumulative Model Updates: 90,844
Cumulative Timesteps: 757,687,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.69405
Policy Entropy: 3.21786
Value Function Loss: 0.00430

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.57519
Value Function Update Magnitude: 0.68868

Collected Steps per Second: 22,788.22354
Overall Steps per Second: 10,675.85041

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.48975
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.68422

Cumulative Model Updates: 90,850
Cumulative Timesteps: 757,737,154

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 757737154...
Checkpoint 757737154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.05190
Policy Entropy: 3.22253
Value Function Loss: 0.00423

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.56028
Value Function Update Magnitude: 0.66890

Collected Steps per Second: 22,664.86648
Overall Steps per Second: 10,671.42952

Timestep Collection Time: 2.20615
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.68560

Cumulative Model Updates: 90,856
Cumulative Timesteps: 757,787,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.20955
Policy Entropy: 3.22593
Value Function Loss: 0.00418

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08723
Policy Update Magnitude: 0.55526
Value Function Update Magnitude: 0.62910

Collected Steps per Second: 22,903.54880
Overall Steps per Second: 10,802.44858

Timestep Collection Time: 2.18420
Timestep Consumption Time: 2.44678
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.63099

Cumulative Model Updates: 90,862
Cumulative Timesteps: 757,837,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 757837182...
Checkpoint 757837182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.58723
Policy Entropy: 3.23833
Value Function Loss: 0.00435

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09235
Policy Update Magnitude: 0.56395
Value Function Update Magnitude: 0.65036

Collected Steps per Second: 22,644.85308
Overall Steps per Second: 10,603.18541

Timestep Collection Time: 2.20818
Timestep Consumption Time: 2.50776
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.71594

Cumulative Model Updates: 90,868
Cumulative Timesteps: 757,887,186

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.86057
Policy Entropy: 3.25044
Value Function Loss: 0.00399

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.67405

Collected Steps per Second: 22,402.93688
Overall Steps per Second: 10,549.95138

Timestep Collection Time: 2.23301
Timestep Consumption Time: 2.50881
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.74182

Cumulative Model Updates: 90,874
Cumulative Timesteps: 757,937,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 757937212...
Checkpoint 757937212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.79361
Policy Entropy: 3.25276
Value Function Loss: 0.00401

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.55102
Value Function Update Magnitude: 0.67516

Collected Steps per Second: 22,527.22080
Overall Steps per Second: 10,594.12363

Timestep Collection Time: 2.22096
Timestep Consumption Time: 2.50166
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.72262

Cumulative Model Updates: 90,880
Cumulative Timesteps: 757,987,244

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.44528
Policy Entropy: 3.25291
Value Function Loss: 0.00416

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.55393
Value Function Update Magnitude: 0.67058

Collected Steps per Second: 22,531.09611
Overall Steps per Second: 10,598.57526

Timestep Collection Time: 2.22058
Timestep Consumption Time: 2.50006
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.72063

Cumulative Model Updates: 90,886
Cumulative Timesteps: 758,037,276

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 758037276...
Checkpoint 758037276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883.55934
Policy Entropy: 3.24482
Value Function Loss: 0.00439

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09195
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.68447

Collected Steps per Second: 22,249.76718
Overall Steps per Second: 10,522.84256

Timestep Collection Time: 2.24820
Timestep Consumption Time: 2.50546
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.75366

Cumulative Model Updates: 90,892
Cumulative Timesteps: 758,087,298

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.72393
Policy Entropy: 3.22988
Value Function Loss: 0.00446

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.56216
Value Function Update Magnitude: 0.68811

Collected Steps per Second: 22,084.50024
Overall Steps per Second: 10,473.81972

Timestep Collection Time: 2.26476
Timestep Consumption Time: 2.51058
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.77534

Cumulative Model Updates: 90,898
Cumulative Timesteps: 758,137,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 758137314...
Checkpoint 758137314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.88545
Policy Entropy: 3.23267
Value Function Loss: 0.00427

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.66592

Collected Steps per Second: 22,534.66238
Overall Steps per Second: 10,610.30695

Timestep Collection Time: 2.21907
Timestep Consumption Time: 2.49389
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.71296

Cumulative Model Updates: 90,904
Cumulative Timesteps: 758,187,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.54493
Policy Entropy: 3.22829
Value Function Loss: 0.00402

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11423
Policy Update Magnitude: 0.55233
Value Function Update Magnitude: 0.64749

Collected Steps per Second: 22,327.41993
Overall Steps per Second: 10,444.72655

Timestep Collection Time: 2.24021
Timestep Consumption Time: 2.54862
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.78883

Cumulative Model Updates: 90,910
Cumulative Timesteps: 758,237,338

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 758237338...
Checkpoint 758237338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.23153
Policy Entropy: 3.23534
Value Function Loss: 0.00384

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.53606
Value Function Update Magnitude: 0.63016

Collected Steps per Second: 23,071.46887
Overall Steps per Second: 10,619.43843

Timestep Collection Time: 2.16770
Timestep Consumption Time: 2.54178
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.70948

Cumulative Model Updates: 90,916
Cumulative Timesteps: 758,287,350

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.35031
Policy Entropy: 3.24863
Value Function Loss: 0.00398

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.53660
Value Function Update Magnitude: 0.62102

Collected Steps per Second: 22,750.78820
Overall Steps per Second: 10,804.02467

Timestep Collection Time: 2.19817
Timestep Consumption Time: 2.43066
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.62883

Cumulative Model Updates: 90,922
Cumulative Timesteps: 758,337,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 758337360...
Checkpoint 758337360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.32036
Policy Entropy: 3.26264
Value Function Loss: 0.00404

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.53978
Value Function Update Magnitude: 0.61989

Collected Steps per Second: 19,560.28174
Overall Steps per Second: 9,881.57427

Timestep Collection Time: 2.55620
Timestep Consumption Time: 2.50372
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 5.05992

Cumulative Model Updates: 90,928
Cumulative Timesteps: 758,387,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,332.36290
Policy Entropy: 3.26484
Value Function Loss: 0.00433

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.09041
Policy Update Magnitude: 0.54996
Value Function Update Magnitude: 0.64122

Collected Steps per Second: 22,563.88454
Overall Steps per Second: 10,621.94982

Timestep Collection Time: 2.21664
Timestep Consumption Time: 2.49210
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.70874

Cumulative Model Updates: 90,934
Cumulative Timesteps: 758,437,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 758437376...
Checkpoint 758437376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.98818
Policy Entropy: 3.24622
Value Function Loss: 0.00454

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.56301
Value Function Update Magnitude: 0.65754

Collected Steps per Second: 22,417.77244
Overall Steps per Second: 10,582.57140

Timestep Collection Time: 2.23127
Timestep Consumption Time: 2.49537
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.72664

Cumulative Model Updates: 90,940
Cumulative Timesteps: 758,487,396

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 893.03833
Policy Entropy: 3.22754
Value Function Loss: 0.00466

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.56734
Value Function Update Magnitude: 0.64809

Collected Steps per Second: 22,341.48079
Overall Steps per Second: 10,607.16162

Timestep Collection Time: 2.23924
Timestep Consumption Time: 2.47719
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.71644

Cumulative Model Updates: 90,946
Cumulative Timesteps: 758,537,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 758537424...
Checkpoint 758537424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.74297
Policy Entropy: 3.22905
Value Function Loss: 0.00461

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10427
Policy Update Magnitude: 0.56735
Value Function Update Magnitude: 0.64426

Collected Steps per Second: 22,890.37860
Overall Steps per Second: 10,641.82094

Timestep Collection Time: 2.18450
Timestep Consumption Time: 2.51432
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.69882

Cumulative Model Updates: 90,952
Cumulative Timesteps: 758,587,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 692.05382
Policy Entropy: 3.23898
Value Function Loss: 0.00426

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.56533
Value Function Update Magnitude: 0.63786

Collected Steps per Second: 23,008.54875
Overall Steps per Second: 10,631.60336

Timestep Collection Time: 2.17406
Timestep Consumption Time: 2.53097
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.70503

Cumulative Model Updates: 90,958
Cumulative Timesteps: 758,637,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 758637450...
Checkpoint 758637450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,158.92401
Policy Entropy: 3.23513
Value Function Loss: 0.00424

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.55202
Value Function Update Magnitude: 0.62441

Collected Steps per Second: 22,673.27950
Overall Steps per Second: 10,655.64230

Timestep Collection Time: 2.20533
Timestep Consumption Time: 2.48721
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.69254

Cumulative Model Updates: 90,964
Cumulative Timesteps: 758,687,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.24384
Policy Entropy: 3.22212
Value Function Loss: 0.00413

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.55456
Value Function Update Magnitude: 0.61791

Collected Steps per Second: 22,391.53947
Overall Steps per Second: 10,551.11648

Timestep Collection Time: 2.23316
Timestep Consumption Time: 2.50605
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.73921

Cumulative Model Updates: 90,970
Cumulative Timesteps: 758,737,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 758737456...
Checkpoint 758737456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.28430
Policy Entropy: 3.21365
Value Function Loss: 0.00415

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08139
Policy Update Magnitude: 0.55826
Value Function Update Magnitude: 0.61563

Collected Steps per Second: 22,885.43302
Overall Steps per Second: 10,712.69489

Timestep Collection Time: 2.18576
Timestep Consumption Time: 2.48366
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.66941

Cumulative Model Updates: 90,976
Cumulative Timesteps: 758,787,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.29824
Policy Entropy: 3.21306
Value Function Loss: 0.00420

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08712
Policy Update Magnitude: 0.56530
Value Function Update Magnitude: 0.60514

Collected Steps per Second: 22,622.20853
Overall Steps per Second: 10,772.79975

Timestep Collection Time: 2.21075
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.64243

Cumulative Model Updates: 90,982
Cumulative Timesteps: 758,837,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 758837490...
Checkpoint 758837490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.68720
Policy Entropy: 3.21943
Value Function Loss: 0.00448

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.57309
Value Function Update Magnitude: 0.61648

Collected Steps per Second: 22,653.55609
Overall Steps per Second: 10,632.50482

Timestep Collection Time: 2.20839
Timestep Consumption Time: 2.49680
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.70519

Cumulative Model Updates: 90,988
Cumulative Timesteps: 758,887,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.79165
Policy Entropy: 3.22181
Value Function Loss: 0.00488

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.57792
Value Function Update Magnitude: 0.63293

Collected Steps per Second: 22,071.26489
Overall Steps per Second: 10,487.92401

Timestep Collection Time: 2.26557
Timestep Consumption Time: 2.50220
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.76777

Cumulative Model Updates: 90,994
Cumulative Timesteps: 758,937,522

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 758937522...
Checkpoint 758937522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.07216
Policy Entropy: 3.19731
Value Function Loss: 0.00494

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.58159
Value Function Update Magnitude: 0.65171

Collected Steps per Second: 22,306.17104
Overall Steps per Second: 10,626.94876

Timestep Collection Time: 2.24216
Timestep Consumption Time: 2.46418
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.70634

Cumulative Model Updates: 91,000
Cumulative Timesteps: 758,987,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.23298
Policy Entropy: 3.21144
Value Function Loss: 0.00490

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.58468
Value Function Update Magnitude: 0.65437

Collected Steps per Second: 22,310.38869
Overall Steps per Second: 10,522.33610

Timestep Collection Time: 2.24147
Timestep Consumption Time: 2.51109
PPO Batch Consumption Time: 0.29606
Total Iteration Time: 4.75256

Cumulative Model Updates: 91,006
Cumulative Timesteps: 759,037,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 759037544...
Checkpoint 759037544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.46851
Policy Entropy: 3.21404
Value Function Loss: 0.00464

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.58069
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 22,299.63541
Overall Steps per Second: 10,545.96917

Timestep Collection Time: 2.24309
Timestep Consumption Time: 2.49996
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.74304

Cumulative Model Updates: 91,012
Cumulative Timesteps: 759,087,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.80887
Policy Entropy: 3.23158
Value Function Loss: 0.00450

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09952
Policy Update Magnitude: 0.57081
Value Function Update Magnitude: 0.62781

Collected Steps per Second: 22,449.11270
Overall Steps per Second: 10,554.00090

Timestep Collection Time: 2.22931
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.29545
Total Iteration Time: 4.74190

Cumulative Model Updates: 91,018
Cumulative Timesteps: 759,137,610

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 759137610...
Checkpoint 759137610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.89067
Policy Entropy: 3.24769
Value Function Loss: 0.00428

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.56595
Value Function Update Magnitude: 0.61706

Collected Steps per Second: 22,547.07696
Overall Steps per Second: 10,579.03780

Timestep Collection Time: 2.21882
Timestep Consumption Time: 2.51015
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.72897

Cumulative Model Updates: 91,024
Cumulative Timesteps: 759,187,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.75786
Policy Entropy: 3.24781
Value Function Loss: 0.00421

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.56066
Value Function Update Magnitude: 0.61875

Collected Steps per Second: 22,981.08444
Overall Steps per Second: 10,815.15513

Timestep Collection Time: 2.17640
Timestep Consumption Time: 2.44822
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.62462

Cumulative Model Updates: 91,030
Cumulative Timesteps: 759,237,654

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 759237654...
Checkpoint 759237654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.59676
Policy Entropy: 3.25034
Value Function Loss: 0.00426

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09338
Policy Update Magnitude: 0.55722
Value Function Update Magnitude: 0.61796

Collected Steps per Second: 22,725.98897
Overall Steps per Second: 10,705.76555

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.47075
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.67131

Cumulative Model Updates: 91,036
Cumulative Timesteps: 759,287,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.76657
Policy Entropy: 3.23584
Value Function Loss: 0.00419

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09799
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.60829

Collected Steps per Second: 22,634.06167
Overall Steps per Second: 10,665.52856

Timestep Collection Time: 2.20950
Timestep Consumption Time: 2.47944
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.68894

Cumulative Model Updates: 91,042
Cumulative Timesteps: 759,337,674

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 759337674...
Checkpoint 759337674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.42913
Policy Entropy: 3.24683
Value Function Loss: 0.00417

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08182
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.61962

Collected Steps per Second: 22,936.33921
Overall Steps per Second: 10,828.79853

Timestep Collection Time: 2.18125
Timestep Consumption Time: 2.43883
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.62009

Cumulative Model Updates: 91,048
Cumulative Timesteps: 759,387,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.95362
Policy Entropy: 3.24197
Value Function Loss: 0.00434

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.55460
Value Function Update Magnitude: 0.62364

Collected Steps per Second: 22,903.60912
Overall Steps per Second: 10,754.22301

Timestep Collection Time: 2.18324
Timestep Consumption Time: 2.46647
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.64971

Cumulative Model Updates: 91,054
Cumulative Timesteps: 759,437,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 759437708...
Checkpoint 759437708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767.47033
Policy Entropy: 3.23263
Value Function Loss: 0.00452

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.56265
Value Function Update Magnitude: 0.62003

Collected Steps per Second: 22,491.88082
Overall Steps per Second: 10,650.33553

Timestep Collection Time: 2.22427
Timestep Consumption Time: 2.47305
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.69732

Cumulative Model Updates: 91,060
Cumulative Timesteps: 759,487,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.93845
Policy Entropy: 3.21822
Value Function Loss: 0.00463

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.56465
Value Function Update Magnitude: 0.62563

Collected Steps per Second: 22,442.52520
Overall Steps per Second: 10,686.17754

Timestep Collection Time: 2.22800
Timestep Consumption Time: 2.45113
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.67913

Cumulative Model Updates: 91,066
Cumulative Timesteps: 759,537,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 759537738...
Checkpoint 759537738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.31488
Policy Entropy: 3.23853
Value Function Loss: 0.00434

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.56124
Value Function Update Magnitude: 0.61298

Collected Steps per Second: 22,380.23386
Overall Steps per Second: 10,609.55354

Timestep Collection Time: 2.23456
Timestep Consumption Time: 2.47912
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.71368

Cumulative Model Updates: 91,072
Cumulative Timesteps: 759,587,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.55277
Policy Entropy: 3.23683
Value Function Loss: 0.00425

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10690
Policy Update Magnitude: 0.55127
Value Function Update Magnitude: 0.58949

Collected Steps per Second: 22,237.28900
Overall Steps per Second: 10,445.25042

Timestep Collection Time: 2.24866
Timestep Consumption Time: 2.53859
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.78725

Cumulative Model Updates: 91,078
Cumulative Timesteps: 759,637,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 759637752...
Checkpoint 759637752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.60886
Policy Entropy: 3.24258
Value Function Loss: 0.00413

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.59422

Collected Steps per Second: 22,554.37239
Overall Steps per Second: 10,713.84012

Timestep Collection Time: 2.21811
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.66947

Cumulative Model Updates: 91,084
Cumulative Timesteps: 759,687,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.91198
Policy Entropy: 3.21838
Value Function Loss: 0.00456

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.60540

Collected Steps per Second: 22,812.93738
Overall Steps per Second: 10,783.80513

Timestep Collection Time: 2.19174
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.63658

Cumulative Model Updates: 91,090
Cumulative Timesteps: 759,737,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 759737780...
Checkpoint 759737780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.22248
Policy Entropy: 3.23117
Value Function Loss: 0.00448

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10067
Policy Update Magnitude: 0.56977
Value Function Update Magnitude: 0.62214

Collected Steps per Second: 22,670.85361
Overall Steps per Second: 10,707.76452

Timestep Collection Time: 2.20565
Timestep Consumption Time: 2.46423
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.66988

Cumulative Model Updates: 91,096
Cumulative Timesteps: 759,787,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.25007
Policy Entropy: 3.21803
Value Function Loss: 0.00454

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.57616
Value Function Update Magnitude: 0.61218

Collected Steps per Second: 22,668.88386
Overall Steps per Second: 10,787.95015

Timestep Collection Time: 2.20567
Timestep Consumption Time: 2.42913
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.63480

Cumulative Model Updates: 91,102
Cumulative Timesteps: 759,837,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 759837784...
Checkpoint 759837784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.35519
Policy Entropy: 3.21050
Value Function Loss: 0.00475

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.57995
Value Function Update Magnitude: 0.60568

Collected Steps per Second: 22,773.56103
Overall Steps per Second: 10,749.30087

Timestep Collection Time: 2.19553
Timestep Consumption Time: 2.45594
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.65147

Cumulative Model Updates: 91,108
Cumulative Timesteps: 759,887,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.02698
Policy Entropy: 3.20435
Value Function Loss: 0.00485

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.58277
Value Function Update Magnitude: 0.60687

Collected Steps per Second: 22,731.17122
Overall Steps per Second: 10,795.34951

Timestep Collection Time: 2.20015
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.63274

Cumulative Model Updates: 91,114
Cumulative Timesteps: 759,937,796

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 759937796...
Checkpoint 759937796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.21294
Policy Entropy: 3.20732
Value Function Loss: 0.00459

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.57313
Value Function Update Magnitude: 0.60838

Collected Steps per Second: 22,294.23775
Overall Steps per Second: 10,706.16658

Timestep Collection Time: 2.24291
Timestep Consumption Time: 2.42767
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.67058

Cumulative Model Updates: 91,120
Cumulative Timesteps: 759,987,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.18945
Policy Entropy: 3.22308
Value Function Loss: 0.00451

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.58189

Collected Steps per Second: 22,601.30873
Overall Steps per Second: 10,659.76979

Timestep Collection Time: 2.21385
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.69391

Cumulative Model Updates: 91,126
Cumulative Timesteps: 760,037,836

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 760037836...
Checkpoint 760037836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.22221
Policy Entropy: 3.22745
Value Function Loss: 0.00457

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.56671
Value Function Update Magnitude: 0.56343

Collected Steps per Second: 22,570.75410
Overall Steps per Second: 10,617.40645

Timestep Collection Time: 2.21552
Timestep Consumption Time: 2.49429
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.70981

Cumulative Model Updates: 91,132
Cumulative Timesteps: 760,087,842

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.52236
Policy Entropy: 3.20822
Value Function Loss: 0.00461

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.57525
Value Function Update Magnitude: 0.58516

Collected Steps per Second: 22,488.97740
Overall Steps per Second: 10,742.82519

Timestep Collection Time: 2.22411
Timestep Consumption Time: 2.43183
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.65594

Cumulative Model Updates: 91,138
Cumulative Timesteps: 760,137,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 760137860...
Checkpoint 760137860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.50397
Policy Entropy: 3.20055
Value Function Loss: 0.00433

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09910
Policy Update Magnitude: 0.57138
Value Function Update Magnitude: 0.58573

Collected Steps per Second: 22,856.62380
Overall Steps per Second: 10,720.00278

Timestep Collection Time: 2.18860
Timestep Consumption Time: 2.47782
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.66642

Cumulative Model Updates: 91,144
Cumulative Timesteps: 760,187,884

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.73805
Policy Entropy: 3.21376
Value Function Loss: 0.00435

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10541
Policy Update Magnitude: 0.56307
Value Function Update Magnitude: 0.59781

Collected Steps per Second: 23,049.19529
Overall Steps per Second: 10,827.42515

Timestep Collection Time: 2.16936
Timestep Consumption Time: 2.44873
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.61809

Cumulative Model Updates: 91,150
Cumulative Timesteps: 760,237,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 760237886...
Checkpoint 760237886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.82290
Policy Entropy: 3.22211
Value Function Loss: 0.00449

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.56912
Value Function Update Magnitude: 0.60903

Collected Steps per Second: 21,737.99003
Overall Steps per Second: 10,468.29088

Timestep Collection Time: 2.30086
Timestep Consumption Time: 2.47700
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.77786

Cumulative Model Updates: 91,156
Cumulative Timesteps: 760,287,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.98807
Policy Entropy: 3.22458
Value Function Loss: 0.00507

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.58041
Value Function Update Magnitude: 0.61176

Collected Steps per Second: 22,782.42813
Overall Steps per Second: 10,711.45741

Timestep Collection Time: 2.19590
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.67051

Cumulative Model Updates: 91,162
Cumulative Timesteps: 760,337,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 760337930...
Checkpoint 760337930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,659.69083
Policy Entropy: 3.21784
Value Function Loss: 0.00513

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.59172
Value Function Update Magnitude: 0.62494

Collected Steps per Second: 22,416.50015
Overall Steps per Second: 10,639.74555

Timestep Collection Time: 2.23121
Timestep Consumption Time: 2.46965
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.70086

Cumulative Model Updates: 91,168
Cumulative Timesteps: 760,387,946

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,367.94188
Policy Entropy: 3.21817
Value Function Loss: 0.00479

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.58662
Value Function Update Magnitude: 0.61970

Collected Steps per Second: 22,794.79376
Overall Steps per Second: 10,778.08373

Timestep Collection Time: 2.19410
Timestep Consumption Time: 2.44624
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.64034

Cumulative Model Updates: 91,174
Cumulative Timesteps: 760,437,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 760437960...
Checkpoint 760437960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.52618
Policy Entropy: 3.21499
Value Function Loss: 0.00438

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.61099

Collected Steps per Second: 22,531.47929
Overall Steps per Second: 10,752.36236

Timestep Collection Time: 2.21912
Timestep Consumption Time: 2.43102
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.65014

Cumulative Model Updates: 91,180
Cumulative Timesteps: 760,487,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.69184
Policy Entropy: 3.22193
Value Function Loss: 0.00429

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.56493
Value Function Update Magnitude: 0.61376

Collected Steps per Second: 22,200.52530
Overall Steps per Second: 10,503.84317

Timestep Collection Time: 2.25265
Timestep Consumption Time: 2.50847
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.76111

Cumulative Model Updates: 91,186
Cumulative Timesteps: 760,537,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 760537970...
Checkpoint 760537970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883.82065
Policy Entropy: 3.22642
Value Function Loss: 0.00455

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.56051
Value Function Update Magnitude: 0.61689

Collected Steps per Second: 22,429.47265
Overall Steps per Second: 10,575.42630

Timestep Collection Time: 2.22974
Timestep Consumption Time: 2.49933
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.72908

Cumulative Model Updates: 91,192
Cumulative Timesteps: 760,587,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.68864
Policy Entropy: 3.23703
Value Function Loss: 0.00457

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.56354
Value Function Update Magnitude: 0.63150

Collected Steps per Second: 22,106.47495
Overall Steps per Second: 10,461.35863

Timestep Collection Time: 2.26232
Timestep Consumption Time: 2.51832
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.78064

Cumulative Model Updates: 91,198
Cumulative Timesteps: 760,637,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 760637994...
Checkpoint 760637994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,573.40028
Policy Entropy: 3.23774
Value Function Loss: 0.00463

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.56836
Value Function Update Magnitude: 0.63256

Collected Steps per Second: 22,214.14579
Overall Steps per Second: 10,625.10820

Timestep Collection Time: 2.25127
Timestep Consumption Time: 2.45551
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.70678

Cumulative Model Updates: 91,204
Cumulative Timesteps: 760,688,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.34416
Policy Entropy: 3.23809
Value Function Loss: 0.00456

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09867
Policy Update Magnitude: 0.57497
Value Function Update Magnitude: 0.63123

Collected Steps per Second: 22,772.91514
Overall Steps per Second: 10,626.44382

Timestep Collection Time: 2.19682
Timestep Consumption Time: 2.51106
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.70788

Cumulative Model Updates: 91,210
Cumulative Timesteps: 760,738,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 760738032...
Checkpoint 760738032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.58355
Policy Entropy: 3.23293
Value Function Loss: 0.00457

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.57673
Value Function Update Magnitude: 0.64031

Collected Steps per Second: 22,832.30201
Overall Steps per Second: 10,680.93103

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.49206
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.68255

Cumulative Model Updates: 91,216
Cumulative Timesteps: 760,788,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.40623
Policy Entropy: 3.22768
Value Function Loss: 0.00472

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.57912
Value Function Update Magnitude: 0.64322

Collected Steps per Second: 22,939.31926
Overall Steps per Second: 10,696.49150

Timestep Collection Time: 2.18054
Timestep Consumption Time: 2.49576
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.67630

Cumulative Model Updates: 91,222
Cumulative Timesteps: 760,838,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 760838066...
Checkpoint 760838066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.62216
Policy Entropy: 3.22785
Value Function Loss: 0.00467

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.57737
Value Function Update Magnitude: 0.63159

Collected Steps per Second: 22,782.47502
Overall Steps per Second: 10,623.74851

Timestep Collection Time: 2.19511
Timestep Consumption Time: 2.51227
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.70738

Cumulative Model Updates: 91,228
Cumulative Timesteps: 760,888,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.31099
Policy Entropy: 3.23180
Value Function Loss: 0.00460

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.09144
Policy Update Magnitude: 0.56867
Value Function Update Magnitude: 0.61045

Collected Steps per Second: 22,852.17803
Overall Steps per Second: 10,826.35171

Timestep Collection Time: 2.18911
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.62076

Cumulative Model Updates: 91,234
Cumulative Timesteps: 760,938,102

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 760938102...
Checkpoint 760938102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.34706
Policy Entropy: 3.23843
Value Function Loss: 0.00428

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.56284
Value Function Update Magnitude: 0.59167

Collected Steps per Second: 22,642.03358
Overall Steps per Second: 10,822.58389

Timestep Collection Time: 2.20881
Timestep Consumption Time: 2.41227
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.62108

Cumulative Model Updates: 91,240
Cumulative Timesteps: 760,988,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.49358
Policy Entropy: 3.25036
Value Function Loss: 0.00428

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.59778

Collected Steps per Second: 22,702.87998
Overall Steps per Second: 10,786.65068

Timestep Collection Time: 2.20324
Timestep Consumption Time: 2.43397
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.63721

Cumulative Model Updates: 91,246
Cumulative Timesteps: 761,038,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 761038134...
Checkpoint 761038134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.44437
Policy Entropy: 3.25419
Value Function Loss: 0.00422

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.54332
Value Function Update Magnitude: 0.60149

Collected Steps per Second: 22,115.75077
Overall Steps per Second: 10,650.35039

Timestep Collection Time: 2.26101
Timestep Consumption Time: 2.43404
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.69506

Cumulative Model Updates: 91,252
Cumulative Timesteps: 761,088,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 850.59969
Policy Entropy: 3.25526
Value Function Loss: 0.00438

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.54975
Value Function Update Magnitude: 0.61893

Collected Steps per Second: 22,345.59395
Overall Steps per Second: 10,547.85648

Timestep Collection Time: 2.23820
Timestep Consumption Time: 2.50342
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.74163

Cumulative Model Updates: 91,258
Cumulative Timesteps: 761,138,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 761138152...
Checkpoint 761138152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.84161
Policy Entropy: 3.26910
Value Function Loss: 0.00422

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08327
Policy Update Magnitude: 0.55705
Value Function Update Magnitude: 0.61739

Collected Steps per Second: 22,635.04711
Overall Steps per Second: 10,620.08922

Timestep Collection Time: 2.20985
Timestep Consumption Time: 2.50009
PPO Batch Consumption Time: 0.29677
Total Iteration Time: 4.70994

Cumulative Model Updates: 91,264
Cumulative Timesteps: 761,188,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.23773
Policy Entropy: 3.25662
Value Function Loss: 0.00432

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10139
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.59738

Collected Steps per Second: 22,340.50289
Overall Steps per Second: 10,530.25513

Timestep Collection Time: 2.23889
Timestep Consumption Time: 2.51104
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.74993

Cumulative Model Updates: 91,270
Cumulative Timesteps: 761,238,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 761238190...
Checkpoint 761238190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.86871
Policy Entropy: 3.26189
Value Function Loss: 0.00431

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.55992
Value Function Update Magnitude: 0.60020

Collected Steps per Second: 22,241.90032
Overall Steps per Second: 10,525.05228

Timestep Collection Time: 2.24909
Timestep Consumption Time: 2.50376
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.75285

Cumulative Model Updates: 91,276
Cumulative Timesteps: 761,288,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.68652
Policy Entropy: 3.26089
Value Function Loss: 0.00425

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.55970
Value Function Update Magnitude: 0.58648

Collected Steps per Second: 23,043.02864
Overall Steps per Second: 10,686.01138

Timestep Collection Time: 2.17072
Timestep Consumption Time: 2.51016
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.68089

Cumulative Model Updates: 91,282
Cumulative Timesteps: 761,338,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 761338234...
Checkpoint 761338234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.42827
Policy Entropy: 3.25894
Value Function Loss: 0.00428

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10613
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.59132

Collected Steps per Second: 22,893.76011
Overall Steps per Second: 10,789.39665

Timestep Collection Time: 2.18514
Timestep Consumption Time: 2.45145
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.63659

Cumulative Model Updates: 91,288
Cumulative Timesteps: 761,388,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.56418
Policy Entropy: 3.25360
Value Function Loss: 0.00390

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11537
Policy Update Magnitude: 0.55303
Value Function Update Magnitude: 0.58155

Collected Steps per Second: 22,996.52933
Overall Steps per Second: 10,725.41794

Timestep Collection Time: 2.17520
Timestep Consumption Time: 2.48868
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.66387

Cumulative Model Updates: 91,294
Cumulative Timesteps: 761,438,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 761438282...
Checkpoint 761438282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.94467
Policy Entropy: 3.24371
Value Function Loss: 0.00424

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.58055

Collected Steps per Second: 22,666.18140
Overall Steps per Second: 10,806.79200

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.42215
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.62931

Cumulative Model Updates: 91,300
Cumulative Timesteps: 761,488,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.33061
Policy Entropy: 3.22404
Value Function Loss: 0.00420

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.54897
Value Function Update Magnitude: 0.59676

Collected Steps per Second: 22,924.06822
Overall Steps per Second: 10,679.91798

Timestep Collection Time: 2.18164
Timestep Consumption Time: 2.50117
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.68281

Cumulative Model Updates: 91,306
Cumulative Timesteps: 761,538,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 761538322...
Checkpoint 761538322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.85474
Policy Entropy: 3.22070
Value Function Loss: 0.00450

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.55542
Value Function Update Magnitude: 0.62142

Collected Steps per Second: 22,763.43557
Overall Steps per Second: 10,682.68577

Timestep Collection Time: 2.19738
Timestep Consumption Time: 2.48496
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.68234

Cumulative Model Updates: 91,312
Cumulative Timesteps: 761,588,342

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.71155
Policy Entropy: 3.22446
Value Function Loss: 0.00460

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10832
Policy Update Magnitude: 0.57742
Value Function Update Magnitude: 0.64235

Collected Steps per Second: 22,367.05540
Overall Steps per Second: 10,708.27033

Timestep Collection Time: 2.23597
Timestep Consumption Time: 2.43444
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.67041

Cumulative Model Updates: 91,318
Cumulative Timesteps: 761,638,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 761638354...
Checkpoint 761638354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.65440
Policy Entropy: 3.23488
Value Function Loss: 0.00464

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.58599
Value Function Update Magnitude: 0.64977

Collected Steps per Second: 22,393.95167
Overall Steps per Second: 10,664.14347

Timestep Collection Time: 2.23337
Timestep Consumption Time: 2.45655
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.68992

Cumulative Model Updates: 91,324
Cumulative Timesteps: 761,688,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.74142
Policy Entropy: 3.22032
Value Function Loss: 0.00456

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11915
Policy Update Magnitude: 0.58868
Value Function Update Magnitude: 0.64583

Collected Steps per Second: 22,449.18751
Overall Steps per Second: 10,841.53973

Timestep Collection Time: 2.22814
Timestep Consumption Time: 2.38559
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.61374

Cumulative Model Updates: 91,330
Cumulative Timesteps: 761,738,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 761738388...
Checkpoint 761738388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.55085
Policy Entropy: 3.22599
Value Function Loss: 0.00449

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10391
Policy Update Magnitude: 0.58281
Value Function Update Magnitude: 0.64347

Collected Steps per Second: 21,899.59124
Overall Steps per Second: 10,671.54974

Timestep Collection Time: 2.28443
Timestep Consumption Time: 2.40355
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.68798

Cumulative Model Updates: 91,336
Cumulative Timesteps: 761,788,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.19237
Policy Entropy: 3.24587
Value Function Loss: 0.00433

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.57590
Value Function Update Magnitude: 0.63244

Collected Steps per Second: 22,100.54835
Overall Steps per Second: 10,616.08472

Timestep Collection Time: 2.26248
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.71002

Cumulative Model Updates: 91,342
Cumulative Timesteps: 761,838,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 761838418...
Checkpoint 761838418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.47916
Policy Entropy: 3.24260
Value Function Loss: 0.00416

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.56586
Value Function Update Magnitude: 0.62301

Collected Steps per Second: 21,941.23223
Overall Steps per Second: 10,570.92976

Timestep Collection Time: 2.27936
Timestep Consumption Time: 2.45173
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.73109

Cumulative Model Updates: 91,348
Cumulative Timesteps: 761,888,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.44618
Policy Entropy: 3.23989
Value Function Loss: 0.00450

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.57055
Value Function Update Magnitude: 0.62488

Collected Steps per Second: 23,227.50043
Overall Steps per Second: 10,855.31386

Timestep Collection Time: 2.15305
Timestep Consumption Time: 2.45391
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.60696

Cumulative Model Updates: 91,354
Cumulative Timesteps: 761,938,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 761938440...
Checkpoint 761938440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.54770
Policy Entropy: 3.23138
Value Function Loss: 0.00468

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.58236
Value Function Update Magnitude: 0.64741

Collected Steps per Second: 22,844.31188
Overall Steps per Second: 10,627.22652

Timestep Collection Time: 2.18917
Timestep Consumption Time: 2.51667
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.70584

Cumulative Model Updates: 91,360
Cumulative Timesteps: 761,988,450

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.84955
Policy Entropy: 3.23234
Value Function Loss: 0.00476

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.58365
Value Function Update Magnitude: 0.66308

Collected Steps per Second: 23,181.00054
Overall Steps per Second: 10,814.49484

Timestep Collection Time: 2.15703
Timestep Consumption Time: 2.46658
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.62361

Cumulative Model Updates: 91,366
Cumulative Timesteps: 762,038,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 762038452...
Checkpoint 762038452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.74978
Policy Entropy: 3.23275
Value Function Loss: 0.00464

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.58106
Value Function Update Magnitude: 0.65113

Collected Steps per Second: 21,692.23183
Overall Steps per Second: 10,356.65953

Timestep Collection Time: 2.30497
Timestep Consumption Time: 2.52284
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.82781

Cumulative Model Updates: 91,372
Cumulative Timesteps: 762,088,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.59222
Policy Entropy: 3.23261
Value Function Loss: 0.00453

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11122
Policy Update Magnitude: 0.57751
Value Function Update Magnitude: 0.64503

Collected Steps per Second: 22,000.98869
Overall Steps per Second: 10,439.80387

Timestep Collection Time: 2.27372
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.79166

Cumulative Model Updates: 91,378
Cumulative Timesteps: 762,138,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 762138476...
Checkpoint 762138476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.69732
Policy Entropy: 3.23085
Value Function Loss: 0.00439

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.57443
Value Function Update Magnitude: 0.63385

Collected Steps per Second: 22,022.20384
Overall Steps per Second: 10,534.63460

Timestep Collection Time: 2.27044
Timestep Consumption Time: 2.47581
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.74625

Cumulative Model Updates: 91,384
Cumulative Timesteps: 762,188,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.63761
Policy Entropy: 3.25352
Value Function Loss: 0.00405

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.56114
Value Function Update Magnitude: 0.63493

Collected Steps per Second: 21,780.68369
Overall Steps per Second: 10,589.94654

Timestep Collection Time: 2.29616
Timestep Consumption Time: 2.42643
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.72259

Cumulative Model Updates: 91,390
Cumulative Timesteps: 762,238,488

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 762238488...
Checkpoint 762238488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.58167
Policy Entropy: 3.24938
Value Function Loss: 0.00409

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10088
Policy Update Magnitude: 0.54829
Value Function Update Magnitude: 0.62244

Collected Steps per Second: 21,599.96933
Overall Steps per Second: 10,557.95839

Timestep Collection Time: 2.31611
Timestep Consumption Time: 2.42230
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.73842

Cumulative Model Updates: 91,396
Cumulative Timesteps: 762,288,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,203.66421
Policy Entropy: 3.25167
Value Function Loss: 0.00401

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.54306
Value Function Update Magnitude: 0.62422

Collected Steps per Second: 21,671.82233
Overall Steps per Second: 10,434.89407

Timestep Collection Time: 2.30788
Timestep Consumption Time: 2.48527
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.79315

Cumulative Model Updates: 91,402
Cumulative Timesteps: 762,338,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 762338532...
Checkpoint 762338532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.75871
Policy Entropy: 3.24656
Value Function Loss: 0.00414

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.62741

Collected Steps per Second: 22,020.46848
Overall Steps per Second: 10,403.94633

Timestep Collection Time: 2.27089
Timestep Consumption Time: 2.53556
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.80645

Cumulative Model Updates: 91,408
Cumulative Timesteps: 762,388,538

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.74541
Policy Entropy: 3.25468
Value Function Loss: 0.00420

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11348
Policy Update Magnitude: 0.55183
Value Function Update Magnitude: 0.61619

Collected Steps per Second: 21,683.34096
Overall Steps per Second: 10,534.21228

Timestep Collection Time: 2.30739
Timestep Consumption Time: 2.44208
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.74948

Cumulative Model Updates: 91,414
Cumulative Timesteps: 762,438,570

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 762438570...
Checkpoint 762438570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.36853
Policy Entropy: 3.25776
Value Function Loss: 0.00426

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10946
Policy Update Magnitude: 0.55131
Value Function Update Magnitude: 0.60230

Collected Steps per Second: 21,310.24109
Overall Steps per Second: 10,459.83539

Timestep Collection Time: 2.34695
Timestep Consumption Time: 2.43458
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.78153

Cumulative Model Updates: 91,420
Cumulative Timesteps: 762,488,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,442.39681
Policy Entropy: 3.25022
Value Function Loss: 0.00444

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11657
Policy Update Magnitude: 0.55838
Value Function Update Magnitude: 0.59735

Collected Steps per Second: 21,690.93450
Overall Steps per Second: 10,396.88591

Timestep Collection Time: 2.30594
Timestep Consumption Time: 2.50492
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 4.81086

Cumulative Model Updates: 91,426
Cumulative Timesteps: 762,538,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 762538602...
Checkpoint 762538602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.23197
Policy Entropy: 3.26540
Value Function Loss: 0.00460

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11147
Policy Update Magnitude: 0.56549
Value Function Update Magnitude: 0.59687

Collected Steps per Second: 20,645.16321
Overall Steps per Second: 10,239.75545

Timestep Collection Time: 2.42294
Timestep Consumption Time: 2.46214
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.88508

Cumulative Model Updates: 91,432
Cumulative Timesteps: 762,588,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.60334
Policy Entropy: 3.26483
Value Function Loss: 0.00454

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.60890

Collected Steps per Second: 19,979.46435
Overall Steps per Second: 9,688.90222

Timestep Collection Time: 2.50277
Timestep Consumption Time: 2.65819
PPO Batch Consumption Time: 0.29853
Total Iteration Time: 5.16096

Cumulative Model Updates: 91,438
Cumulative Timesteps: 762,638,628

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 762638628...
Checkpoint 762638628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.52935
Policy Entropy: 3.26294
Value Function Loss: 0.00425

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.56398
Value Function Update Magnitude: 0.61300

Collected Steps per Second: 18,519.18716
Overall Steps per Second: 9,724.47616

Timestep Collection Time: 2.70033
Timestep Consumption Time: 2.44215
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 5.14249

Cumulative Model Updates: 91,444
Cumulative Timesteps: 762,688,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.69018
Policy Entropy: 3.25472
Value Function Loss: 0.00439

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08525
Policy Update Magnitude: 0.56758
Value Function Update Magnitude: 0.60709

Collected Steps per Second: 21,957.22752
Overall Steps per Second: 10,489.51856

Timestep Collection Time: 2.27797
Timestep Consumption Time: 2.49040
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.76838

Cumulative Model Updates: 91,450
Cumulative Timesteps: 762,738,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 762738654...
Checkpoint 762738654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.32004
Policy Entropy: 3.23863
Value Function Loss: 0.00448

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.57263
Value Function Update Magnitude: 0.61898

Collected Steps per Second: 21,932.24865
Overall Steps per Second: 9,975.75134

Timestep Collection Time: 2.27975
Timestep Consumption Time: 2.73241
PPO Batch Consumption Time: 0.30365
Total Iteration Time: 5.01215

Cumulative Model Updates: 91,456
Cumulative Timesteps: 762,788,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.62887
Policy Entropy: 3.24837
Value Function Loss: 0.00457

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10489
Policy Update Magnitude: 0.57211
Value Function Update Magnitude: 0.62358

Collected Steps per Second: 12,281.21358
Overall Steps per Second: 7,218.42558

Timestep Collection Time: 4.07452
Timestep Consumption Time: 2.85774
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 6.93226

Cumulative Model Updates: 91,462
Cumulative Timesteps: 762,838,694

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 762838694...
Checkpoint 762838694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.68883
Policy Entropy: 3.25572
Value Function Loss: 0.00443

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10876
Policy Update Magnitude: 0.57127
Value Function Update Magnitude: 0.62276

Collected Steps per Second: 10,535.37279
Overall Steps per Second: 6,718.17798

Timestep Collection Time: 4.74725
Timestep Consumption Time: 2.69733
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 7.44458

Cumulative Model Updates: 91,468
Cumulative Timesteps: 762,888,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.75180
Policy Entropy: 3.25232
Value Function Loss: 0.00439

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.56867
Value Function Update Magnitude: 0.61462

Collected Steps per Second: 20,844.18273
Overall Steps per Second: 10,146.24007

Timestep Collection Time: 2.39952
Timestep Consumption Time: 2.52999
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.92951

Cumulative Model Updates: 91,474
Cumulative Timesteps: 762,938,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 762938724...
Checkpoint 762938724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.37698
Policy Entropy: 3.26480
Value Function Loss: 0.00436

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.60789

Collected Steps per Second: 21,971.45643
Overall Steps per Second: 10,590.94792

Timestep Collection Time: 2.27695
Timestep Consumption Time: 2.44670
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.72366

Cumulative Model Updates: 91,480
Cumulative Timesteps: 762,988,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.27375
Policy Entropy: 3.24683
Value Function Loss: 0.00455

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.56409
Value Function Update Magnitude: 0.60563

Collected Steps per Second: 22,492.03754
Overall Steps per Second: 10,584.15934

Timestep Collection Time: 2.22381
Timestep Consumption Time: 2.50193
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.72574

Cumulative Model Updates: 91,486
Cumulative Timesteps: 763,038,770

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 763038770...
Checkpoint 763038770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.30525
Policy Entropy: 3.26538
Value Function Loss: 0.00446

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.56801
Value Function Update Magnitude: 0.61464

Collected Steps per Second: 22,743.37365
Overall Steps per Second: 10,633.57307

Timestep Collection Time: 2.19976
Timestep Consumption Time: 2.50515
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.70491

Cumulative Model Updates: 91,492
Cumulative Timesteps: 763,088,800

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.66893
Policy Entropy: 3.25892
Value Function Loss: 0.00451

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.56830
Value Function Update Magnitude: 0.62166

Collected Steps per Second: 22,790.37677
Overall Steps per Second: 10,580.16674

Timestep Collection Time: 2.19540
Timestep Consumption Time: 2.53364
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.72904

Cumulative Model Updates: 91,498
Cumulative Timesteps: 763,138,834

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 763138834...
Checkpoint 763138834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.92266
Policy Entropy: 3.27604
Value Function Loss: 0.00429

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.56307
Value Function Update Magnitude: 0.63390

Collected Steps per Second: 22,879.12945
Overall Steps per Second: 10,683.39938

Timestep Collection Time: 2.18575
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.68091

Cumulative Model Updates: 91,504
Cumulative Timesteps: 763,188,842

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.40445
Policy Entropy: 3.26443
Value Function Loss: 0.00437

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08865
Policy Update Magnitude: 0.56489
Value Function Update Magnitude: 0.66242

Collected Steps per Second: 23,067.38783
Overall Steps per Second: 10,729.76591

Timestep Collection Time: 2.16791
Timestep Consumption Time: 2.49277
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.66068

Cumulative Model Updates: 91,510
Cumulative Timesteps: 763,238,850

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 763238850...
Checkpoint 763238850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.47202
Policy Entropy: 3.26680
Value Function Loss: 0.00431

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.56599
Value Function Update Magnitude: 0.67591

Collected Steps per Second: 22,746.96742
Overall Steps per Second: 10,638.98432

Timestep Collection Time: 2.19845
Timestep Consumption Time: 2.50200
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.70045

Cumulative Model Updates: 91,516
Cumulative Timesteps: 763,288,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.84041
Policy Entropy: 3.26230
Value Function Loss: 0.00431

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.55957
Value Function Update Magnitude: 0.66172

Collected Steps per Second: 23,021.03500
Overall Steps per Second: 10,807.61936

Timestep Collection Time: 2.17297
Timestep Consumption Time: 2.45562
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.62859

Cumulative Model Updates: 91,522
Cumulative Timesteps: 763,338,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 763338882...
Checkpoint 763338882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.56671
Policy Entropy: 3.26051
Value Function Loss: 0.00458

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.64730

Collected Steps per Second: 22,247.01032
Overall Steps per Second: 10,646.12333

Timestep Collection Time: 2.24785
Timestep Consumption Time: 2.44944
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.69730

Cumulative Model Updates: 91,528
Cumulative Timesteps: 763,388,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.21429
Policy Entropy: 3.24521
Value Function Loss: 0.00465

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.56982
Value Function Update Magnitude: 0.66772

Collected Steps per Second: 21,974.10392
Overall Steps per Second: 10,583.32163

Timestep Collection Time: 2.27686
Timestep Consumption Time: 2.45058
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.72744

Cumulative Model Updates: 91,534
Cumulative Timesteps: 763,438,922

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 763438922...
Checkpoint 763438922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.98898
Policy Entropy: 3.23376
Value Function Loss: 0.00483

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10766
Policy Update Magnitude: 0.58375
Value Function Update Magnitude: 0.67499

Collected Steps per Second: 22,725.70284
Overall Steps per Second: 10,582.81811

Timestep Collection Time: 2.20050
Timestep Consumption Time: 2.52489
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.72540

Cumulative Model Updates: 91,540
Cumulative Timesteps: 763,488,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.89629
Policy Entropy: 3.23350
Value Function Loss: 0.00485

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11605
Policy Update Magnitude: 0.58628
Value Function Update Magnitude: 0.65257

Collected Steps per Second: 22,601.75048
Overall Steps per Second: 10,566.73169

Timestep Collection Time: 2.21248
Timestep Consumption Time: 2.51992
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.73240

Cumulative Model Updates: 91,546
Cumulative Timesteps: 763,538,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 763538936...
Checkpoint 763538936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.16181
Policy Entropy: 3.26621
Value Function Loss: 0.00459

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11029
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.61513

Collected Steps per Second: 22,585.56735
Overall Steps per Second: 10,514.76201

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.54172
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.75579

Cumulative Model Updates: 91,552
Cumulative Timesteps: 763,588,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.65665
Policy Entropy: 3.26820
Value Function Loss: 0.00453

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.56691
Value Function Update Magnitude: 0.60531

Collected Steps per Second: 22,588.14756
Overall Steps per Second: 10,549.96035

Timestep Collection Time: 2.21426
Timestep Consumption Time: 2.52661
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.74087

Cumulative Model Updates: 91,558
Cumulative Timesteps: 763,638,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 763638958...
Checkpoint 763638958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.23860
Policy Entropy: 3.25844
Value Function Loss: 0.00465

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10720
Policy Update Magnitude: 0.56255
Value Function Update Magnitude: 0.59942

Collected Steps per Second: 22,765.83401
Overall Steps per Second: 10,542.72303

Timestep Collection Time: 2.19715
Timestep Consumption Time: 2.54735
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.74450

Cumulative Model Updates: 91,564
Cumulative Timesteps: 763,688,978

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.26333
Policy Entropy: 3.23549
Value Function Loss: 0.00479

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09508
Policy Update Magnitude: 0.56837
Value Function Update Magnitude: 0.61084

Collected Steps per Second: 22,892.65476
Overall Steps per Second: 10,813.19427

Timestep Collection Time: 2.18550
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.62694

Cumulative Model Updates: 91,570
Cumulative Timesteps: 763,739,010

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 763739010...
Checkpoint 763739010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.17738
Policy Entropy: 3.22632
Value Function Loss: 0.00472

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.57082
Value Function Update Magnitude: 0.62322

Collected Steps per Second: 22,762.24114
Overall Steps per Second: 10,737.87299

Timestep Collection Time: 2.19776
Timestep Consumption Time: 2.46107
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.65884

Cumulative Model Updates: 91,576
Cumulative Timesteps: 763,789,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.79244
Policy Entropy: 3.21909
Value Function Loss: 0.00479

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.57833
Value Function Update Magnitude: 0.64382

Collected Steps per Second: 22,744.45066
Overall Steps per Second: 10,813.16890

Timestep Collection Time: 2.19878
Timestep Consumption Time: 2.42614
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.62492

Cumulative Model Updates: 91,582
Cumulative Timesteps: 763,839,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 763839046...
Checkpoint 763839046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.60829
Policy Entropy: 3.21162
Value Function Loss: 0.00475

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.58248
Value Function Update Magnitude: 0.64583

Collected Steps per Second: 22,636.89559
Overall Steps per Second: 10,785.58969

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.42810
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.63785

Cumulative Model Updates: 91,588
Cumulative Timesteps: 763,889,068

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.50345
Policy Entropy: 3.19416
Value Function Loss: 0.00483

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.58857
Value Function Update Magnitude: 0.64333

Collected Steps per Second: 22,560.23036
Overall Steps per Second: 10,746.85417

Timestep Collection Time: 2.21762
Timestep Consumption Time: 2.43770
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.65532

Cumulative Model Updates: 91,594
Cumulative Timesteps: 763,939,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 763939098...
Checkpoint 763939098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.76434
Policy Entropy: 3.19222
Value Function Loss: 0.00473

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.59422
Value Function Update Magnitude: 0.65291

Collected Steps per Second: 22,622.31453
Overall Steps per Second: 10,820.34520

Timestep Collection Time: 2.21030
Timestep Consumption Time: 2.41081
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.62111

Cumulative Model Updates: 91,600
Cumulative Timesteps: 763,989,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.49485
Policy Entropy: 3.18157
Value Function Loss: 0.00475

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.58513
Value Function Update Magnitude: 0.63741

Collected Steps per Second: 21,369.28275
Overall Steps per Second: 10,402.31385

Timestep Collection Time: 2.34009
Timestep Consumption Time: 2.46711
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.80720

Cumulative Model Updates: 91,606
Cumulative Timesteps: 764,039,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 764039106...
Checkpoint 764039106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.68907
Policy Entropy: 3.19220
Value Function Loss: 0.00480

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10588
Policy Update Magnitude: 0.58462
Value Function Update Magnitude: 0.62757

Collected Steps per Second: 22,071.08772
Overall Steps per Second: 10,615.33163

Timestep Collection Time: 2.26622
Timestep Consumption Time: 2.44564
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.71186

Cumulative Model Updates: 91,612
Cumulative Timesteps: 764,089,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.69915
Policy Entropy: 3.20684
Value Function Loss: 0.00467

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.59558
Value Function Update Magnitude: 0.61770

Collected Steps per Second: 22,556.48221
Overall Steps per Second: 10,565.19505

Timestep Collection Time: 2.21692
Timestep Consumption Time: 2.51616
PPO Batch Consumption Time: 0.29441
Total Iteration Time: 4.73309

Cumulative Model Updates: 91,618
Cumulative Timesteps: 764,139,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 764139130...
Checkpoint 764139130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.46590
Policy Entropy: 3.21218
Value Function Loss: 0.00483

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.59353
Value Function Update Magnitude: 0.61569

Collected Steps per Second: 22,808.87058
Overall Steps per Second: 10,590.54385

Timestep Collection Time: 2.19441
Timestep Consumption Time: 2.53169
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.72610

Cumulative Model Updates: 91,624
Cumulative Timesteps: 764,189,182

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.78403
Policy Entropy: 3.22422
Value Function Loss: 0.00468

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.58967
Value Function Update Magnitude: 0.63204

Collected Steps per Second: 22,696.36686
Overall Steps per Second: 10,817.67914

Timestep Collection Time: 2.20405
Timestep Consumption Time: 2.42023
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.62428

Cumulative Model Updates: 91,630
Cumulative Timesteps: 764,239,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 764239206...
Checkpoint 764239206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.63303
Policy Entropy: 3.23059
Value Function Loss: 0.00448

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.61789

Collected Steps per Second: 22,717.12349
Overall Steps per Second: 10,717.65059

Timestep Collection Time: 2.20169
Timestep Consumption Time: 2.46501
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.66669

Cumulative Model Updates: 91,636
Cumulative Timesteps: 764,289,222

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.12999
Policy Entropy: 3.23847
Value Function Loss: 0.00426

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.55346
Value Function Update Magnitude: 0.60623

Collected Steps per Second: 22,920.18397
Overall Steps per Second: 10,819.16889

Timestep Collection Time: 2.18183
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.62217

Cumulative Model Updates: 91,642
Cumulative Timesteps: 764,339,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 764339230...
Checkpoint 764339230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.72306
Policy Entropy: 3.23422
Value Function Loss: 0.00432

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.55950
Value Function Update Magnitude: 0.61224

Collected Steps per Second: 22,825.56085
Overall Steps per Second: 10,709.01648

Timestep Collection Time: 2.19061
Timestep Consumption Time: 2.47854
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.66915

Cumulative Model Updates: 91,648
Cumulative Timesteps: 764,389,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.46800
Policy Entropy: 3.23573
Value Function Loss: 0.00430

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10460
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.62781

Collected Steps per Second: 22,879.31859
Overall Steps per Second: 10,830.34391

Timestep Collection Time: 2.18555
Timestep Consumption Time: 2.43147
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.61703

Cumulative Model Updates: 91,654
Cumulative Timesteps: 764,439,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 764439236...
Checkpoint 764439236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.67729
Policy Entropy: 3.22392
Value Function Loss: 0.00446

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.57127
Value Function Update Magnitude: 0.65197

Collected Steps per Second: 22,236.61912
Overall Steps per Second: 10,740.96736

Timestep Collection Time: 2.24863
Timestep Consumption Time: 2.40663
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.65526

Cumulative Model Updates: 91,660
Cumulative Timesteps: 764,489,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.41979
Policy Entropy: 3.23567
Value Function Loss: 0.00454

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.58010
Value Function Update Magnitude: 0.65339

Collected Steps per Second: 21,469.07114
Overall Steps per Second: 10,434.92806

Timestep Collection Time: 2.33042
Timestep Consumption Time: 2.46424
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.79467

Cumulative Model Updates: 91,666
Cumulative Timesteps: 764,539,270

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 764539270...
Checkpoint 764539270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.56453
Policy Entropy: 3.23024
Value Function Loss: 0.00473

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.58970
Value Function Update Magnitude: 0.65413

Collected Steps per Second: 21,784.48622
Overall Steps per Second: 10,600.32939

Timestep Collection Time: 2.29576
Timestep Consumption Time: 2.42220
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.71797

Cumulative Model Updates: 91,672
Cumulative Timesteps: 764,589,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.44446
Policy Entropy: 3.23593
Value Function Loss: 0.00443

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.58094
Value Function Update Magnitude: 0.65477

Collected Steps per Second: 21,565.75247
Overall Steps per Second: 10,491.20545

Timestep Collection Time: 2.31858
Timestep Consumption Time: 2.44750
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.76609

Cumulative Model Updates: 91,678
Cumulative Timesteps: 764,639,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 764639284...
Checkpoint 764639284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.51920
Policy Entropy: 3.23638
Value Function Loss: 0.00442

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.57264
Value Function Update Magnitude: 0.63543

Collected Steps per Second: 21,911.77787
Overall Steps per Second: 10,629.88406

Timestep Collection Time: 2.28306
Timestep Consumption Time: 2.42310
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.70617

Cumulative Model Updates: 91,684
Cumulative Timesteps: 764,689,310

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.17547
Policy Entropy: 3.23745
Value Function Loss: 0.00435

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.57093
Value Function Update Magnitude: 0.64039

Collected Steps per Second: 22,214.75554
Overall Steps per Second: 10,657.27797

Timestep Collection Time: 2.25238
Timestep Consumption Time: 2.44263
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.69501

Cumulative Model Updates: 91,690
Cumulative Timesteps: 764,739,346

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 764739346...
Checkpoint 764739346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.59445
Policy Entropy: 3.25689
Value Function Loss: 0.00417

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.56359
Value Function Update Magnitude: 0.62818

Collected Steps per Second: 22,173.88781
Overall Steps per Second: 10,771.95717

Timestep Collection Time: 2.25554
Timestep Consumption Time: 2.38745
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.64298

Cumulative Model Updates: 91,696
Cumulative Timesteps: 764,789,360

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.28728
Policy Entropy: 3.24691
Value Function Loss: 0.00440

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08361
Policy Update Magnitude: 0.55764
Value Function Update Magnitude: 0.62388

Collected Steps per Second: 22,140.62618
Overall Steps per Second: 10,634.24865

Timestep Collection Time: 2.25901
Timestep Consumption Time: 2.44428
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.70329

Cumulative Model Updates: 91,702
Cumulative Timesteps: 764,839,376

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 764839376...
Checkpoint 764839376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.15543
Policy Entropy: 3.23849
Value Function Loss: 0.00455

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08423
Policy Update Magnitude: 0.56017
Value Function Update Magnitude: 0.62571

Collected Steps per Second: 22,153.67081
Overall Steps per Second: 10,633.24560

Timestep Collection Time: 2.25741
Timestep Consumption Time: 2.44576
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.70317

Cumulative Model Updates: 91,708
Cumulative Timesteps: 764,889,386

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.34854
Policy Entropy: 3.22235
Value Function Loss: 0.00436

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10196
Policy Update Magnitude: 0.56604
Value Function Update Magnitude: 0.63823

Collected Steps per Second: 22,042.15224
Overall Steps per Second: 10,749.88025

Timestep Collection Time: 2.26856
Timestep Consumption Time: 2.38302
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.65159

Cumulative Model Updates: 91,714
Cumulative Timesteps: 764,939,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 764939390...
Checkpoint 764939390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.83173
Policy Entropy: 3.21585
Value Function Loss: 0.00434

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.55736
Value Function Update Magnitude: 0.62562

Collected Steps per Second: 21,617.06731
Overall Steps per Second: 10,671.23020

Timestep Collection Time: 2.31299
Timestep Consumption Time: 2.37251
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.68550

Cumulative Model Updates: 91,720
Cumulative Timesteps: 764,989,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.14288
Policy Entropy: 3.22734
Value Function Loss: 0.00443

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.56276
Value Function Update Magnitude: 0.62050

Collected Steps per Second: 21,771.69639
Overall Steps per Second: 10,513.57215

Timestep Collection Time: 2.29674
Timestep Consumption Time: 2.45939
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.75614

Cumulative Model Updates: 91,726
Cumulative Timesteps: 765,039,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 765039394...
Checkpoint 765039394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.35149
Policy Entropy: 3.22590
Value Function Loss: 0.00435

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.56754
Value Function Update Magnitude: 0.61298

Collected Steps per Second: 21,598.40083
Overall Steps per Second: 10,709.02653

Timestep Collection Time: 2.31600
Timestep Consumption Time: 2.35501
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.67101

Cumulative Model Updates: 91,732
Cumulative Timesteps: 765,089,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,140.25895
Policy Entropy: 3.22186
Value Function Loss: 0.00426

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.55548
Value Function Update Magnitude: 0.60712

Collected Steps per Second: 21,787.75816
Overall Steps per Second: 10,596.01538

Timestep Collection Time: 2.29606
Timestep Consumption Time: 2.42515
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.72121

Cumulative Model Updates: 91,738
Cumulative Timesteps: 765,139,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 765139442...
Checkpoint 765139442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.69085
Policy Entropy: 3.21357
Value Function Loss: 0.00428

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.54850
Value Function Update Magnitude: 0.61202

Collected Steps per Second: 21,971.30252
Overall Steps per Second: 10,760.46910

Timestep Collection Time: 2.27615
Timestep Consumption Time: 2.37142
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.64757

Cumulative Model Updates: 91,744
Cumulative Timesteps: 765,189,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.51684
Policy Entropy: 3.19910
Value Function Loss: 0.00453

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.55694
Value Function Update Magnitude: 0.62230

Collected Steps per Second: 21,455.17308
Overall Steps per Second: 10,608.85626

Timestep Collection Time: 2.33044
Timestep Consumption Time: 2.38260
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.71304

Cumulative Model Updates: 91,750
Cumulative Timesteps: 765,239,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 765239452...
Checkpoint 765239452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.31097
Policy Entropy: 3.19431
Value Function Loss: 0.00465

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.57543
Value Function Update Magnitude: 0.63518

Collected Steps per Second: 22,288.88627
Overall Steps per Second: 10,621.83523

Timestep Collection Time: 2.24399
Timestep Consumption Time: 2.46480
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.70879

Cumulative Model Updates: 91,756
Cumulative Timesteps: 765,289,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.30819
Policy Entropy: 3.19940
Value Function Loss: 0.00461

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.57728
Value Function Update Magnitude: 0.65139

Collected Steps per Second: 22,104.61522
Overall Steps per Second: 10,621.93911

Timestep Collection Time: 2.26224
Timestep Consumption Time: 2.44556
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.70780

Cumulative Model Updates: 91,762
Cumulative Timesteps: 765,339,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 765339474...
Checkpoint 765339474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,253.32154
Policy Entropy: 3.20623
Value Function Loss: 0.00453

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11913
Policy Update Magnitude: 0.57261
Value Function Update Magnitude: 0.65596

Collected Steps per Second: 21,908.01822
Overall Steps per Second: 10,597.90145

Timestep Collection Time: 2.28245
Timestep Consumption Time: 2.43584
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.71829

Cumulative Model Updates: 91,768
Cumulative Timesteps: 765,389,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.06241
Policy Entropy: 3.20977
Value Function Loss: 0.00458

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12478
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.63371

Collected Steps per Second: 23,037.33407
Overall Steps per Second: 10,763.50275

Timestep Collection Time: 2.17082
Timestep Consumption Time: 2.47543
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.64626

Cumulative Model Updates: 91,774
Cumulative Timesteps: 765,439,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 765439488...
Checkpoint 765439488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 741.98111
Policy Entropy: 3.20744
Value Function Loss: 0.00493

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.57412
Value Function Update Magnitude: 0.61004

Collected Steps per Second: 22,671.81311
Overall Steps per Second: 10,599.22881

Timestep Collection Time: 2.20582
Timestep Consumption Time: 2.51245
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.71827

Cumulative Model Updates: 91,780
Cumulative Timesteps: 765,489,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,128.67629
Policy Entropy: 3.21023
Value Function Loss: 0.00471

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.57333
Value Function Update Magnitude: 0.60137

Collected Steps per Second: 23,151.13326
Overall Steps per Second: 10,849.97690

Timestep Collection Time: 2.16041
Timestep Consumption Time: 2.44937
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.60978

Cumulative Model Updates: 91,786
Cumulative Timesteps: 765,539,514

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 765539514...
Checkpoint 765539514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.00091
Policy Entropy: 3.20683
Value Function Loss: 0.00469

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08539
Policy Update Magnitude: 0.57744
Value Function Update Magnitude: 0.59800

Collected Steps per Second: 22,602.63995
Overall Steps per Second: 10,691.63148

Timestep Collection Time: 2.21319
Timestep Consumption Time: 2.46561
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.67880

Cumulative Model Updates: 91,792
Cumulative Timesteps: 765,589,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.21171
Policy Entropy: 3.21753
Value Function Loss: 0.00442

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.57914
Value Function Update Magnitude: 0.59669

Collected Steps per Second: 22,584.99609
Overall Steps per Second: 10,526.23561

Timestep Collection Time: 2.21510
Timestep Consumption Time: 2.53760
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.75270

Cumulative Model Updates: 91,798
Cumulative Timesteps: 765,639,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 765639566...
Checkpoint 765639566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.87144
Policy Entropy: 3.22686
Value Function Loss: 0.00443

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.56899
Value Function Update Magnitude: 0.60584

Collected Steps per Second: 22,392.98716
Overall Steps per Second: 10,664.66979

Timestep Collection Time: 2.23284
Timestep Consumption Time: 2.45554
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.68838

Cumulative Model Updates: 91,804
Cumulative Timesteps: 765,689,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 823.27845
Policy Entropy: 3.22749
Value Function Loss: 0.00440

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.56409
Value Function Update Magnitude: 0.59811

Collected Steps per Second: 22,335.35887
Overall Steps per Second: 10,546.54458

Timestep Collection Time: 2.23995
Timestep Consumption Time: 2.50379
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.74373

Cumulative Model Updates: 91,810
Cumulative Timesteps: 765,739,596

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 765739596...
Checkpoint 765739596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.12871
Policy Entropy: 3.23362
Value Function Loss: 0.00440

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.55805
Value Function Update Magnitude: 0.57564

Collected Steps per Second: 22,533.76776
Overall Steps per Second: 10,562.16258

Timestep Collection Time: 2.21916
Timestep Consumption Time: 2.51529
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.73445

Cumulative Model Updates: 91,816
Cumulative Timesteps: 765,789,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.64908
Policy Entropy: 3.23114
Value Function Loss: 0.00452

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10661
Policy Update Magnitude: 0.56204
Value Function Update Magnitude: 0.58183

Collected Steps per Second: 22,736.74592
Overall Steps per Second: 10,730.06596

Timestep Collection Time: 2.20023
Timestep Consumption Time: 2.46200
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.66223

Cumulative Model Updates: 91,822
Cumulative Timesteps: 765,839,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 765839628...
Checkpoint 765839628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.80185
Policy Entropy: 3.22768
Value Function Loss: 0.00456

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.56884
Value Function Update Magnitude: 0.60379

Collected Steps per Second: 22,992.75722
Overall Steps per Second: 10,772.33325

Timestep Collection Time: 2.17477
Timestep Consumption Time: 2.46712
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.64189

Cumulative Model Updates: 91,828
Cumulative Timesteps: 765,889,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.84403
Policy Entropy: 3.22031
Value Function Loss: 0.00454

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11099
Policy Update Magnitude: 0.56801
Value Function Update Magnitude: 0.61239

Collected Steps per Second: 21,776.67057
Overall Steps per Second: 10,397.47423

Timestep Collection Time: 2.29604
Timestep Consumption Time: 2.51283
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.80886

Cumulative Model Updates: 91,834
Cumulative Timesteps: 765,939,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 765939632...
Checkpoint 765939632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 850.79612
Policy Entropy: 3.22222
Value Function Loss: 0.00488

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.57046
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 22,484.71932
Overall Steps per Second: 10,701.85822

Timestep Collection Time: 2.22382
Timestep Consumption Time: 2.44845
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.67227

Cumulative Model Updates: 91,840
Cumulative Timesteps: 765,989,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.06363
Policy Entropy: 3.22427
Value Function Loss: 0.00478

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.57469
Value Function Update Magnitude: 0.62030

Collected Steps per Second: 22,848.75913
Overall Steps per Second: 10,776.96125

Timestep Collection Time: 2.18900
Timestep Consumption Time: 2.45201
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.64101

Cumulative Model Updates: 91,846
Cumulative Timesteps: 766,039,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 766039650...
Checkpoint 766039650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,472.45029
Policy Entropy: 3.21642
Value Function Loss: 0.00476

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.57092
Value Function Update Magnitude: 0.61995

Collected Steps per Second: 22,622.08583
Overall Steps per Second: 10,666.01380

Timestep Collection Time: 2.21085
Timestep Consumption Time: 2.47825
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.68910

Cumulative Model Updates: 91,852
Cumulative Timesteps: 766,089,664

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 972.66992
Policy Entropy: 3.19416
Value Function Loss: 0.00466

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.13156
Policy Update Magnitude: 0.56854
Value Function Update Magnitude: 0.62371

Collected Steps per Second: 22,976.11740
Overall Steps per Second: 10,687.05663

Timestep Collection Time: 2.17687
Timestep Consumption Time: 2.50318
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.68005

Cumulative Model Updates: 91,858
Cumulative Timesteps: 766,139,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 766139680...
Checkpoint 766139680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.57412
Policy Entropy: 3.19001
Value Function Loss: 0.00460

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.57254
Value Function Update Magnitude: 0.64947

Collected Steps per Second: 22,717.53452
Overall Steps per Second: 10,676.07011

Timestep Collection Time: 2.20103
Timestep Consumption Time: 2.48253
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.68356

Cumulative Model Updates: 91,864
Cumulative Timesteps: 766,189,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.05394
Policy Entropy: 3.18055
Value Function Loss: 0.00456

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.56960
Value Function Update Magnitude: 0.65012

Collected Steps per Second: 22,478.22776
Overall Steps per Second: 10,679.94534

Timestep Collection Time: 2.22491
Timestep Consumption Time: 2.45789
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.68280

Cumulative Model Updates: 91,870
Cumulative Timesteps: 766,239,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 766239694...
Checkpoint 766239694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702.23670
Policy Entropy: 3.18813
Value Function Loss: 0.00451

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.56720
Value Function Update Magnitude: 0.63937

Collected Steps per Second: 22,453.11910
Overall Steps per Second: 10,674.41887

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.45763
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.68485

Cumulative Model Updates: 91,876
Cumulative Timesteps: 766,289,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.44041
Policy Entropy: 3.18843
Value Function Loss: 0.00459

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.62917

Collected Steps per Second: 22,187.99934
Overall Steps per Second: 10,454.56105

Timestep Collection Time: 2.25437
Timestep Consumption Time: 2.53014
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.78451

Cumulative Model Updates: 91,882
Cumulative Timesteps: 766,339,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 766339722...
Checkpoint 766339722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.70438
Policy Entropy: 3.21267
Value Function Loss: 0.00467

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.57010
Value Function Update Magnitude: 0.63604

Collected Steps per Second: 22,590.94846
Overall Steps per Second: 10,637.92817

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.48778
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.70186

Cumulative Model Updates: 91,888
Cumulative Timesteps: 766,389,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.05638
Policy Entropy: 3.23083
Value Function Loss: 0.00458

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.56830
Value Function Update Magnitude: 0.63042

Collected Steps per Second: 22,753.12442
Overall Steps per Second: 10,510.04785

Timestep Collection Time: 2.19856
Timestep Consumption Time: 2.56108
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.75964

Cumulative Model Updates: 91,894
Cumulative Timesteps: 766,439,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 766439764...
Checkpoint 766439764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 727.25997
Policy Entropy: 3.22353
Value Function Loss: 0.00459

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.56811
Value Function Update Magnitude: 0.62973

Collected Steps per Second: 23,014.41874
Overall Steps per Second: 10,611.62197

Timestep Collection Time: 2.17394
Timestep Consumption Time: 2.54089
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.71483

Cumulative Model Updates: 91,900
Cumulative Timesteps: 766,489,796

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.61358
Policy Entropy: 3.20473
Value Function Loss: 0.00465

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.56164
Value Function Update Magnitude: 0.62601

Collected Steps per Second: 23,020.76895
Overall Steps per Second: 10,802.04796

Timestep Collection Time: 2.17265
Timestep Consumption Time: 2.45759
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.63023

Cumulative Model Updates: 91,906
Cumulative Timesteps: 766,539,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 766539812...
Checkpoint 766539812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.21884
Policy Entropy: 3.19608
Value Function Loss: 0.00469

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.62832

Collected Steps per Second: 22,460.91150
Overall Steps per Second: 10,669.48149

Timestep Collection Time: 2.22725
Timestep Consumption Time: 2.46145
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.68870

Cumulative Model Updates: 91,912
Cumulative Timesteps: 766,589,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.00705
Policy Entropy: 3.18785
Value Function Loss: 0.00471

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.56260
Value Function Update Magnitude: 0.62883

Collected Steps per Second: 22,654.10495
Overall Steps per Second: 10,575.30845

Timestep Collection Time: 2.20719
Timestep Consumption Time: 2.52099
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.72818

Cumulative Model Updates: 91,918
Cumulative Timesteps: 766,639,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 766639840...
Checkpoint 766639840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.38105
Policy Entropy: 3.19370
Value Function Loss: 0.00461

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.56457
Value Function Update Magnitude: 0.64149

Collected Steps per Second: 22,640.76637
Overall Steps per Second: 10,569.31759

Timestep Collection Time: 2.20911
Timestep Consumption Time: 2.52308
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.73219

Cumulative Model Updates: 91,924
Cumulative Timesteps: 766,689,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995.76688
Policy Entropy: 3.19685
Value Function Loss: 0.00468

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.57275
Value Function Update Magnitude: 0.66168

Collected Steps per Second: 23,202.22111
Overall Steps per Second: 10,831.31255

Timestep Collection Time: 2.15514
Timestep Consumption Time: 2.46148
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.61661

Cumulative Model Updates: 91,930
Cumulative Timesteps: 766,739,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 766739860...
Checkpoint 766739860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.24821
Policy Entropy: 3.20558
Value Function Loss: 0.00467

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.57253
Value Function Update Magnitude: 0.65107

Collected Steps per Second: 21,872.75520
Overall Steps per Second: 10,474.87744

Timestep Collection Time: 2.28723
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.77600

Cumulative Model Updates: 91,936
Cumulative Timesteps: 766,789,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.38509
Policy Entropy: 3.20673
Value Function Loss: 0.00450

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.57096
Value Function Update Magnitude: 0.64736

Collected Steps per Second: 22,419.21119
Overall Steps per Second: 10,645.50115

Timestep Collection Time: 2.23103
Timestep Consumption Time: 2.46748
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.69851

Cumulative Model Updates: 91,942
Cumulative Timesteps: 766,839,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 766839906...
Checkpoint 766839906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.01911
Policy Entropy: 3.19609
Value Function Loss: 0.00442

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.56237
Value Function Update Magnitude: 0.64452

Collected Steps per Second: 22,256.76356
Overall Steps per Second: 10,668.99273

Timestep Collection Time: 2.24723
Timestep Consumption Time: 2.44075
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.68798

Cumulative Model Updates: 91,948
Cumulative Timesteps: 766,889,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.80877
Policy Entropy: 3.18664
Value Function Loss: 0.00422

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.55758
Value Function Update Magnitude: 0.63847

Collected Steps per Second: 22,711.42475
Overall Steps per Second: 10,579.27675

Timestep Collection Time: 2.20189
Timestep Consumption Time: 2.52509
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.72698

Cumulative Model Updates: 91,954
Cumulative Timesteps: 766,939,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 766939930...
Checkpoint 766939930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.58830
Policy Entropy: 3.20147
Value Function Loss: 0.00418

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09079
Policy Update Magnitude: 0.55331
Value Function Update Magnitude: 0.61947

Collected Steps per Second: 22,649.14413
Overall Steps per Second: 10,546.57883

Timestep Collection Time: 2.20918
Timestep Consumption Time: 2.53511
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.74429

Cumulative Model Updates: 91,960
Cumulative Timesteps: 766,989,966

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.66042
Policy Entropy: 3.20034
Value Function Loss: 0.00424

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.54891
Value Function Update Magnitude: 0.62955

Collected Steps per Second: 23,010.60561
Overall Steps per Second: 10,798.59396

Timestep Collection Time: 2.17352
Timestep Consumption Time: 2.45801
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.63153

Cumulative Model Updates: 91,966
Cumulative Timesteps: 767,039,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 767039980...
Checkpoint 767039980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.86980
Policy Entropy: 3.19328
Value Function Loss: 0.00444

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.55654
Value Function Update Magnitude: 0.63109

Collected Steps per Second: 22,606.43108
Overall Steps per Second: 10,730.46181

Timestep Collection Time: 2.21176
Timestep Consumption Time: 2.44787
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.65963

Cumulative Model Updates: 91,972
Cumulative Timesteps: 767,089,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.24687
Policy Entropy: 3.18974
Value Function Loss: 0.00475

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.56397
Value Function Update Magnitude: 0.63252

Collected Steps per Second: 22,965.55873
Overall Steps per Second: 10,830.81431

Timestep Collection Time: 2.17813
Timestep Consumption Time: 2.44036
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.61849

Cumulative Model Updates: 91,978
Cumulative Timesteps: 767,140,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 767140002...
Checkpoint 767140002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681.92465
Policy Entropy: 3.20235
Value Function Loss: 0.00461

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.55948
Value Function Update Magnitude: 0.64470

Collected Steps per Second: 21,757.15671
Overall Steps per Second: 10,388.76353

Timestep Collection Time: 2.29809
Timestep Consumption Time: 2.51480
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.81289

Cumulative Model Updates: 91,984
Cumulative Timesteps: 767,190,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.56643
Policy Entropy: 3.21549
Value Function Loss: 0.00473

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.55625
Value Function Update Magnitude: 0.63781

Collected Steps per Second: 23,293.77347
Overall Steps per Second: 10,857.19813

Timestep Collection Time: 2.14727
Timestep Consumption Time: 2.45963
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.60690

Cumulative Model Updates: 91,990
Cumulative Timesteps: 767,240,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 767240020...
Checkpoint 767240020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.48545
Policy Entropy: 3.20056
Value Function Loss: 0.00456

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.55896
Value Function Update Magnitude: 0.62434

Collected Steps per Second: 22,351.62049
Overall Steps per Second: 10,610.07800

Timestep Collection Time: 2.23814
Timestep Consumption Time: 2.47681
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.71495

Cumulative Model Updates: 91,996
Cumulative Timesteps: 767,290,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.90421
Policy Entropy: 3.18895
Value Function Loss: 0.00475

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.56109
Value Function Update Magnitude: 0.60347

Collected Steps per Second: 23,034.58300
Overall Steps per Second: 10,826.44223

Timestep Collection Time: 2.17186
Timestep Consumption Time: 2.44904
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.62091

Cumulative Model Updates: 92,002
Cumulative Timesteps: 767,340,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 767340074...
Checkpoint 767340074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.43346
Policy Entropy: 3.19098
Value Function Loss: 0.00473

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.56271
Value Function Update Magnitude: 0.61633

Collected Steps per Second: 21,987.44494
Overall Steps per Second: 10,499.82367

Timestep Collection Time: 2.27548
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.76503

Cumulative Model Updates: 92,008
Cumulative Timesteps: 767,390,106

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.99915
Policy Entropy: 3.20288
Value Function Loss: 0.00465

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.56411
Value Function Update Magnitude: 0.62149

Collected Steps per Second: 22,961.42013
Overall Steps per Second: 10,707.54966

Timestep Collection Time: 2.17887
Timestep Consumption Time: 2.49353
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.67240

Cumulative Model Updates: 92,014
Cumulative Timesteps: 767,440,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 767440136...
Checkpoint 767440136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.56978
Policy Entropy: 3.21457
Value Function Loss: 0.00461

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.55694
Value Function Update Magnitude: 0.59898

Collected Steps per Second: 22,763.26455
Overall Steps per Second: 10,624.69374

Timestep Collection Time: 2.19652
Timestep Consumption Time: 2.50950
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.70602

Cumulative Model Updates: 92,020
Cumulative Timesteps: 767,490,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 890.31593
Policy Entropy: 3.19823
Value Function Loss: 0.00450

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09314
Policy Update Magnitude: 0.54894
Value Function Update Magnitude: 0.59252

Collected Steps per Second: 22,792.30119
Overall Steps per Second: 10,553.74670

Timestep Collection Time: 2.19407
Timestep Consumption Time: 2.54434
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.73841

Cumulative Model Updates: 92,026
Cumulative Timesteps: 767,540,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 767540144...
Checkpoint 767540144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.07923
Policy Entropy: 3.20029
Value Function Loss: 0.00472

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08933
Policy Update Magnitude: 0.55273
Value Function Update Magnitude: 0.59702

Collected Steps per Second: 22,607.60306
Overall Steps per Second: 10,539.00278

Timestep Collection Time: 2.21253
Timestep Consumption Time: 2.53365
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.74618

Cumulative Model Updates: 92,032
Cumulative Timesteps: 767,590,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.06595
Policy Entropy: 3.20739
Value Function Loss: 0.00443

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.60010

Collected Steps per Second: 22,960.23118
Overall Steps per Second: 10,732.57356

Timestep Collection Time: 2.17864
Timestep Consumption Time: 2.48213
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.66076

Cumulative Model Updates: 92,038
Cumulative Timesteps: 767,640,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 767640186...
Checkpoint 767640186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 907.00927
Policy Entropy: 3.20953
Value Function Loss: 0.00464

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.55248
Value Function Update Magnitude: 0.60262

Collected Steps per Second: 22,897.81754
Overall Steps per Second: 10,774.75591

Timestep Collection Time: 2.18475
Timestep Consumption Time: 2.45814
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.64289

Cumulative Model Updates: 92,044
Cumulative Timesteps: 767,690,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.10270
Policy Entropy: 3.22472
Value Function Loss: 0.00424

Mean KL Divergence: 0.00738
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.59906

Collected Steps per Second: 22,483.96372
Overall Steps per Second: 10,560.94148

Timestep Collection Time: 2.22452
Timestep Consumption Time: 2.51142
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.73594

Cumulative Model Updates: 92,050
Cumulative Timesteps: 767,740,228

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 767740228...
Checkpoint 767740228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.79218
Policy Entropy: 3.21562
Value Function Loss: 0.00425

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08549
Policy Update Magnitude: 0.54019
Value Function Update Magnitude: 0.60118

Collected Steps per Second: 21,799.15172
Overall Steps per Second: 10,597.55597

Timestep Collection Time: 2.29458
Timestep Consumption Time: 2.42537
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.71996

Cumulative Model Updates: 92,056
Cumulative Timesteps: 767,790,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.81131
Policy Entropy: 3.21897
Value Function Loss: 0.00417

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08604
Policy Update Magnitude: 0.53332
Value Function Update Magnitude: 0.60337

Collected Steps per Second: 21,878.15293
Overall Steps per Second: 10,518.80168

Timestep Collection Time: 2.28548
Timestep Consumption Time: 2.46811
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.75358

Cumulative Model Updates: 92,062
Cumulative Timesteps: 767,840,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 767840250...
Checkpoint 767840250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.53103
Policy Entropy: 3.21891
Value Function Loss: 0.00416

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.52999
Value Function Update Magnitude: 0.60183

Collected Steps per Second: 21,537.55288
Overall Steps per Second: 10,555.94785

Timestep Collection Time: 2.32227
Timestep Consumption Time: 2.41591
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.73818

Cumulative Model Updates: 92,068
Cumulative Timesteps: 767,890,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.87113
Policy Entropy: 3.20391
Value Function Loss: 0.00415

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09201
Policy Update Magnitude: 0.52902
Value Function Update Magnitude: 0.58654

Collected Steps per Second: 22,453.66266
Overall Steps per Second: 10,513.85008

Timestep Collection Time: 2.22743
Timestep Consumption Time: 2.52953
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.75696

Cumulative Model Updates: 92,074
Cumulative Timesteps: 767,940,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 767940280...
Checkpoint 767940280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770.43839
Policy Entropy: 3.20687
Value Function Loss: 0.00403

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.53291
Value Function Update Magnitude: 0.57481

Collected Steps per Second: 22,194.39811
Overall Steps per Second: 10,641.37521

Timestep Collection Time: 2.25336
Timestep Consumption Time: 2.44641
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.69977

Cumulative Model Updates: 92,080
Cumulative Timesteps: 767,990,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.35934
Policy Entropy: 3.21376
Value Function Loss: 0.00416

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.58999

Collected Steps per Second: 22,348.31316
Overall Steps per Second: 10,502.96001

Timestep Collection Time: 2.23757
Timestep Consumption Time: 2.52356
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.76113

Cumulative Model Updates: 92,086
Cumulative Timesteps: 768,040,298

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 768040298...
Checkpoint 768040298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.12107
Policy Entropy: 3.21664
Value Function Loss: 0.00414

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.54297
Value Function Update Magnitude: 0.61743

Collected Steps per Second: 23,078.69112
Overall Steps per Second: 10,576.96113

Timestep Collection Time: 2.16667
Timestep Consumption Time: 2.56096
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.72763

Cumulative Model Updates: 92,092
Cumulative Timesteps: 768,090,302

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.17799
Policy Entropy: 3.22073
Value Function Loss: 0.00393

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08535
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.62784

Collected Steps per Second: 22,825.96384
Overall Steps per Second: 10,760.89974

Timestep Collection Time: 2.19136
Timestep Consumption Time: 2.45695
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.64831

Cumulative Model Updates: 92,098
Cumulative Timesteps: 768,140,322

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 768140322...
Checkpoint 768140322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784.58167
Policy Entropy: 3.21895
Value Function Loss: 0.00390

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09449
Policy Update Magnitude: 0.52277
Value Function Update Magnitude: 0.62180

Collected Steps per Second: 22,498.09540
Overall Steps per Second: 10,683.85400

Timestep Collection Time: 2.22357
Timestep Consumption Time: 2.45883
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.68239

Cumulative Model Updates: 92,104
Cumulative Timesteps: 768,190,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.65440
Policy Entropy: 3.22673
Value Function Loss: 0.00403

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10006
Policy Update Magnitude: 0.52328
Value Function Update Magnitude: 0.61386

Collected Steps per Second: 22,340.53805
Overall Steps per Second: 10,551.05601

Timestep Collection Time: 2.23898
Timestep Consumption Time: 2.50178
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.74076

Cumulative Model Updates: 92,110
Cumulative Timesteps: 768,240,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 768240368...
Checkpoint 768240368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.14807
Policy Entropy: 3.22209
Value Function Loss: 0.00437

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.53589
Value Function Update Magnitude: 0.64321

Collected Steps per Second: 22,704.34008
Overall Steps per Second: 10,565.57946

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.53033
PPO Batch Consumption Time: 0.29681
Total Iteration Time: 4.73273

Cumulative Model Updates: 92,116
Cumulative Timesteps: 768,290,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.34119
Policy Entropy: 3.22246
Value Function Loss: 0.00429

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.66502

Collected Steps per Second: 22,844.07188
Overall Steps per Second: 10,691.74811

Timestep Collection Time: 2.18971
Timestep Consumption Time: 2.48885
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.67856

Cumulative Model Updates: 92,122
Cumulative Timesteps: 768,340,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 768340394...
Checkpoint 768340394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.35278
Policy Entropy: 3.22649
Value Function Loss: 0.00453

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.54840
Value Function Update Magnitude: 0.66994

Collected Steps per Second: 21,978.13109
Overall Steps per Second: 10,606.78804

Timestep Collection Time: 2.27608
Timestep Consumption Time: 2.44014
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.71623

Cumulative Model Updates: 92,128
Cumulative Timesteps: 768,390,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.00277
Policy Entropy: 3.21713
Value Function Loss: 0.00451

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.54949
Value Function Update Magnitude: 0.66598

Collected Steps per Second: 22,112.90266
Overall Steps per Second: 10,774.76760

Timestep Collection Time: 2.26248
Timestep Consumption Time: 2.38078
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.64326

Cumulative Model Updates: 92,134
Cumulative Timesteps: 768,440,448

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 768440448...
Checkpoint 768440448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.95909
Policy Entropy: 3.21823
Value Function Loss: 0.00456

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10973
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.64965

Collected Steps per Second: 21,548.56341
Overall Steps per Second: 10,678.55322

Timestep Collection Time: 2.32173
Timestep Consumption Time: 2.36336
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.68509

Cumulative Model Updates: 92,140
Cumulative Timesteps: 768,490,478

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.47255
Policy Entropy: 3.21013
Value Function Loss: 0.00429

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.54567
Value Function Update Magnitude: 0.64105

Collected Steps per Second: 21,960.72301
Overall Steps per Second: 10,627.77890

Timestep Collection Time: 2.27734
Timestep Consumption Time: 2.42844
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.70578

Cumulative Model Updates: 92,146
Cumulative Timesteps: 768,540,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 768540490...
Checkpoint 768540490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.56932
Policy Entropy: 3.21043
Value Function Loss: 0.00421

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09443
Policy Update Magnitude: 0.54399
Value Function Update Magnitude: 0.64407

Collected Steps per Second: 21,574.49098
Overall Steps per Second: 10,538.32360

Timestep Collection Time: 2.31839
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.74630

Cumulative Model Updates: 92,152
Cumulative Timesteps: 768,590,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.27197
Policy Entropy: 3.21677
Value Function Loss: 0.00417

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.54480
Value Function Update Magnitude: 0.66634

Collected Steps per Second: 22,636.78340
Overall Steps per Second: 10,670.35833

Timestep Collection Time: 2.20968
Timestep Consumption Time: 2.47807
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.68775

Cumulative Model Updates: 92,158
Cumulative Timesteps: 768,640,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 768640528...
Checkpoint 768640528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.37783
Policy Entropy: 3.21836
Value Function Loss: 0.00437

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09316
Policy Update Magnitude: 0.54682
Value Function Update Magnitude: 0.68677

Collected Steps per Second: 22,799.76396
Overall Steps per Second: 10,697.92150

Timestep Collection Time: 2.19318
Timestep Consumption Time: 2.48100
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.67418

Cumulative Model Updates: 92,164
Cumulative Timesteps: 768,690,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593.00275
Policy Entropy: 3.21819
Value Function Loss: 0.00452

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08606
Policy Update Magnitude: 0.55491
Value Function Update Magnitude: 0.70053

Collected Steps per Second: 22,906.03300
Overall Steps per Second: 10,649.09864

Timestep Collection Time: 2.18318
Timestep Consumption Time: 2.51280
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.69598

Cumulative Model Updates: 92,170
Cumulative Timesteps: 768,740,540

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 768740540...
Checkpoint 768740540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.17622
Policy Entropy: 3.21956
Value Function Loss: 0.00462

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.67823

Collected Steps per Second: 22,889.85154
Overall Steps per Second: 10,689.23193

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.67948

Cumulative Model Updates: 92,176
Cumulative Timesteps: 768,790,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740.83499
Policy Entropy: 3.21629
Value Function Loss: 0.00464

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.67409

Collected Steps per Second: 23,112.73914
Overall Steps per Second: 10,697.90280

Timestep Collection Time: 2.16452
Timestep Consumption Time: 2.51191
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.67643

Cumulative Model Updates: 92,182
Cumulative Timesteps: 768,840,588

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 768840588...
Checkpoint 768840588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.99942
Policy Entropy: 3.21338
Value Function Loss: 0.00484

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.56199
Value Function Update Magnitude: 0.67915

Collected Steps per Second: 22,599.26325
Overall Steps per Second: 10,614.96359

Timestep Collection Time: 2.21282
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.71109

Cumulative Model Updates: 92,188
Cumulative Timesteps: 768,890,596

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.97123
Policy Entropy: 3.22135
Value Function Loss: 0.00467

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.69774

Collected Steps per Second: 22,825.86114
Overall Steps per Second: 10,702.13804

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.48266
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.67421

Cumulative Model Updates: 92,194
Cumulative Timesteps: 768,940,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 768940620...
Checkpoint 768940620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.92687
Policy Entropy: 3.21696
Value Function Loss: 0.00443

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.55546
Value Function Update Magnitude: 0.69486

Collected Steps per Second: 22,480.82708
Overall Steps per Second: 10,572.68015

Timestep Collection Time: 2.22527
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.73163

Cumulative Model Updates: 92,200
Cumulative Timesteps: 768,990,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.90648
Policy Entropy: 3.22318
Value Function Loss: 0.00431

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11287
Policy Update Magnitude: 0.54465
Value Function Update Magnitude: 0.68131

Collected Steps per Second: 22,979.26866
Overall Steps per Second: 10,800.66361

Timestep Collection Time: 2.17614
Timestep Consumption Time: 2.45377
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.62990

Cumulative Model Updates: 92,206
Cumulative Timesteps: 769,040,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 769040652...
Checkpoint 769040652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.18729
Policy Entropy: 3.21227
Value Function Loss: 0.00424

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.53982
Value Function Update Magnitude: 0.64664

Collected Steps per Second: 22,357.92650
Overall Steps per Second: 10,628.11284

Timestep Collection Time: 2.23661
Timestep Consumption Time: 2.46846
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.70507

Cumulative Model Updates: 92,212
Cumulative Timesteps: 769,090,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.67205
Policy Entropy: 3.21816
Value Function Loss: 0.00436

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.54395
Value Function Update Magnitude: 0.62561

Collected Steps per Second: 22,305.77234
Overall Steps per Second: 10,493.32543

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.52346
PPO Batch Consumption Time: 0.29663
Total Iteration Time: 4.76512

Cumulative Model Updates: 92,218
Cumulative Timesteps: 769,140,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 769140660...
Checkpoint 769140660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694.49308
Policy Entropy: 3.22437
Value Function Loss: 0.00427

Mean KL Divergence: 0.00749
SB3 Clip Fraction: 0.08162
Policy Update Magnitude: 0.54956
Value Function Update Magnitude: 0.61800

Collected Steps per Second: 22,124.07882
Overall Steps per Second: 10,616.55017

Timestep Collection Time: 2.26007
Timestep Consumption Time: 2.44974
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.70982

Cumulative Model Updates: 92,224
Cumulative Timesteps: 769,190,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.65756
Policy Entropy: 3.21731
Value Function Loss: 0.00437

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.54319
Value Function Update Magnitude: 0.61106

Collected Steps per Second: 23,091.26896
Overall Steps per Second: 10,769.57179

Timestep Collection Time: 2.16610
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.64438

Cumulative Model Updates: 92,230
Cumulative Timesteps: 769,240,680

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 769240680...
Checkpoint 769240680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.82684
Policy Entropy: 3.20701
Value Function Loss: 0.00441

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.55277
Value Function Update Magnitude: 0.59103

Collected Steps per Second: 22,973.29031
Overall Steps per Second: 10,649.80548

Timestep Collection Time: 2.17731
Timestep Consumption Time: 2.51949
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.69680

Cumulative Model Updates: 92,236
Cumulative Timesteps: 769,290,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.43513
Policy Entropy: 3.18463
Value Function Loss: 0.00445

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.55758
Value Function Update Magnitude: 0.59829

Collected Steps per Second: 22,876.36205
Overall Steps per Second: 10,641.56951

Timestep Collection Time: 2.18662
Timestep Consumption Time: 2.51400
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 4.70062

Cumulative Model Updates: 92,242
Cumulative Timesteps: 769,340,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 769340722...
Checkpoint 769340722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.53759
Policy Entropy: 3.17607
Value Function Loss: 0.00424

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.55610
Value Function Update Magnitude: 0.62995

Collected Steps per Second: 22,870.71767
Overall Steps per Second: 10,673.30161

Timestep Collection Time: 2.18708
Timestep Consumption Time: 2.49938
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.68646

Cumulative Model Updates: 92,248
Cumulative Timesteps: 769,390,742

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.45080
Policy Entropy: 3.16612
Value Function Loss: 0.00428

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.56277
Value Function Update Magnitude: 0.62702

Collected Steps per Second: 22,213.42302
Overall Steps per Second: 10,779.01342

Timestep Collection Time: 2.25197
Timestep Consumption Time: 2.38890
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.64087

Cumulative Model Updates: 92,254
Cumulative Timesteps: 769,440,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 769440766...
Checkpoint 769440766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 853.16959
Policy Entropy: 3.16759
Value Function Loss: 0.00435

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.56076
Value Function Update Magnitude: 0.62641

Collected Steps per Second: 21,905.82998
Overall Steps per Second: 10,604.89588

Timestep Collection Time: 2.28341
Timestep Consumption Time: 2.43328
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.71669

Cumulative Model Updates: 92,260
Cumulative Timesteps: 769,490,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.81318
Policy Entropy: 3.17085
Value Function Loss: 0.00437

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.55358
Value Function Update Magnitude: 0.63018

Collected Steps per Second: 22,107.88572
Overall Steps per Second: 10,688.22565

Timestep Collection Time: 2.26227
Timestep Consumption Time: 2.41709
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.67935

Cumulative Model Updates: 92,266
Cumulative Timesteps: 769,540,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 769540800...
Checkpoint 769540800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.22739
Policy Entropy: 3.16393
Value Function Loss: 0.00460

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10227
Policy Update Magnitude: 0.55680
Value Function Update Magnitude: 0.63915

Collected Steps per Second: 22,426.40792
Overall Steps per Second: 10,568.87491

Timestep Collection Time: 2.23148
Timestep Consumption Time: 2.50356
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.73504

Cumulative Model Updates: 92,272
Cumulative Timesteps: 769,590,844

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.32118
Policy Entropy: 3.16568
Value Function Loss: 0.00471

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.65800

Collected Steps per Second: 22,812.30730
Overall Steps per Second: 10,771.40893

Timestep Collection Time: 2.19285
Timestep Consumption Time: 2.45129
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.64415

Cumulative Model Updates: 92,278
Cumulative Timesteps: 769,640,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 769640868...
Checkpoint 769640868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.16587
Policy Entropy: 3.15788
Value Function Loss: 0.00464

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.58080
Value Function Update Magnitude: 0.67054

Collected Steps per Second: 22,447.96947
Overall Steps per Second: 10,702.54093

Timestep Collection Time: 2.22826
Timestep Consumption Time: 2.44539
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.67366

Cumulative Model Updates: 92,284
Cumulative Timesteps: 769,690,888

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.95613
Policy Entropy: 3.14927
Value Function Loss: 0.00448

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10705
Policy Update Magnitude: 0.57164
Value Function Update Magnitude: 0.68086

Collected Steps per Second: 22,586.14677
Overall Steps per Second: 10,533.99291

Timestep Collection Time: 2.21472
Timestep Consumption Time: 2.53391
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.74863

Cumulative Model Updates: 92,290
Cumulative Timesteps: 769,740,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 769740910...
Checkpoint 769740910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.87752
Policy Entropy: 3.13642
Value Function Loss: 0.00478

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.56923
Value Function Update Magnitude: 0.66282

Collected Steps per Second: 22,733.90448
Overall Steps per Second: 10,551.40153

Timestep Collection Time: 2.20050
Timestep Consumption Time: 2.54067
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.74117

Cumulative Model Updates: 92,296
Cumulative Timesteps: 769,790,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.58285
Policy Entropy: 3.13488
Value Function Loss: 0.00495

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.57718
Value Function Update Magnitude: 0.66274

Collected Steps per Second: 22,671.15870
Overall Steps per Second: 10,523.80214

Timestep Collection Time: 2.20553
Timestep Consumption Time: 2.54579
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.75132

Cumulative Model Updates: 92,302
Cumulative Timesteps: 769,840,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 769840938...
Checkpoint 769840938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.96005
Policy Entropy: 3.14173
Value Function Loss: 0.00481

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.57943
Value Function Update Magnitude: 0.67484

Collected Steps per Second: 23,247.92394
Overall Steps per Second: 10,850.55068

Timestep Collection Time: 2.15168
Timestep Consumption Time: 2.45841
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.61009

Cumulative Model Updates: 92,308
Cumulative Timesteps: 769,890,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.44140
Policy Entropy: 3.14631
Value Function Loss: 0.00474

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.57693
Value Function Update Magnitude: 0.67306

Collected Steps per Second: 22,479.24025
Overall Steps per Second: 10,629.21158

Timestep Collection Time: 2.22508
Timestep Consumption Time: 2.48064
PPO Batch Consumption Time: 0.28678
Total Iteration Time: 4.70571

Cumulative Model Updates: 92,314
Cumulative Timesteps: 769,940,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 769940978...
Checkpoint 769940978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.82938
Policy Entropy: 3.15721
Value Function Loss: 0.00465

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10496
Policy Update Magnitude: 0.57987
Value Function Update Magnitude: 0.66636

Collected Steps per Second: 22,825.47369
Overall Steps per Second: 10,591.03317

Timestep Collection Time: 2.19159
Timestep Consumption Time: 2.53165
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.72324

Cumulative Model Updates: 92,320
Cumulative Timesteps: 769,991,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 717.61469
Policy Entropy: 3.16614
Value Function Loss: 0.00497

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.58569
Value Function Update Magnitude: 0.66708

Collected Steps per Second: 22,721.94571
Overall Steps per Second: 10,652.87521

Timestep Collection Time: 2.20104
Timestep Consumption Time: 2.49365
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.69470

Cumulative Model Updates: 92,326
Cumulative Timesteps: 770,041,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 770041014...
Checkpoint 770041014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 913.94325
Policy Entropy: 3.19463
Value Function Loss: 0.00491

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11585
Policy Update Magnitude: 0.58907
Value Function Update Magnitude: 0.67515

Collected Steps per Second: 22,789.20600
Overall Steps per Second: 10,790.92673

Timestep Collection Time: 2.19481
Timestep Consumption Time: 2.44038
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.63519

Cumulative Model Updates: 92,332
Cumulative Timesteps: 770,091,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.07734
Policy Entropy: 3.19854
Value Function Loss: 0.00487

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.58250
Value Function Update Magnitude: 0.69049

Collected Steps per Second: 22,496.33166
Overall Steps per Second: 10,576.89644

Timestep Collection Time: 2.22294
Timestep Consumption Time: 2.50510
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.72804

Cumulative Model Updates: 92,338
Cumulative Timesteps: 770,141,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 770141040...
Checkpoint 770141040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 684.16448
Policy Entropy: 3.20211
Value Function Loss: 0.00474

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.57736
Value Function Update Magnitude: 0.68275

Collected Steps per Second: 22,448.90943
Overall Steps per Second: 10,658.52351

Timestep Collection Time: 2.22817
Timestep Consumption Time: 2.46479
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.69296

Cumulative Model Updates: 92,344
Cumulative Timesteps: 770,191,060

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.92660
Policy Entropy: 3.19607
Value Function Loss: 0.00484

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.57634
Value Function Update Magnitude: 0.67767

Collected Steps per Second: 22,354.05620
Overall Steps per Second: 10,438.05578

Timestep Collection Time: 2.23682
Timestep Consumption Time: 2.55354
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.79036

Cumulative Model Updates: 92,350
Cumulative Timesteps: 770,241,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 770241062...
Checkpoint 770241062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.15971
Policy Entropy: 3.19572
Value Function Loss: 0.00496

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11217
Policy Update Magnitude: 0.58297
Value Function Update Magnitude: 0.69395

Collected Steps per Second: 22,392.64268
Overall Steps per Second: 10,605.85625

Timestep Collection Time: 2.23377
Timestep Consumption Time: 2.48249
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.71626

Cumulative Model Updates: 92,356
Cumulative Timesteps: 770,291,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.08622
Policy Entropy: 3.20043
Value Function Loss: 0.00511

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.58244
Value Function Update Magnitude: 0.70294

Collected Steps per Second: 22,549.90730
Overall Steps per Second: 10,481.68196

Timestep Collection Time: 2.21748
Timestep Consumption Time: 2.55313
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.77061

Cumulative Model Updates: 92,362
Cumulative Timesteps: 770,341,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 770341086...
Checkpoint 770341086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689.30561
Policy Entropy: 3.20929
Value Function Loss: 0.00497

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.57655
Value Function Update Magnitude: 0.71178

Collected Steps per Second: 22,963.00126
Overall Steps per Second: 10,591.29537

Timestep Collection Time: 2.17803
Timestep Consumption Time: 2.54415
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.72218

Cumulative Model Updates: 92,368
Cumulative Timesteps: 770,391,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.62475
Policy Entropy: 3.20502
Value Function Loss: 0.00464

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.57306
Value Function Update Magnitude: 0.70746

Collected Steps per Second: 22,809.40245
Overall Steps per Second: 10,612.59812

Timestep Collection Time: 2.19296
Timestep Consumption Time: 2.52031
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.71327

Cumulative Model Updates: 92,374
Cumulative Timesteps: 770,441,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 770441120...
Checkpoint 770441120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 839.89836
Policy Entropy: 3.20642
Value Function Loss: 0.00485

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.72222

Collected Steps per Second: 22,924.42654
Overall Steps per Second: 10,686.59834

Timestep Collection Time: 2.18160
Timestep Consumption Time: 2.49828
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.67988

Cumulative Model Updates: 92,380
Cumulative Timesteps: 770,491,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.24310
Policy Entropy: 3.20259
Value Function Loss: 0.00475

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.57604
Value Function Update Magnitude: 0.73672

Collected Steps per Second: 22,810.70463
Overall Steps per Second: 10,797.37533

Timestep Collection Time: 2.19248
Timestep Consumption Time: 2.43939
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.63187

Cumulative Model Updates: 92,386
Cumulative Timesteps: 770,541,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 770541144...
Checkpoint 770541144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.03908
Policy Entropy: 3.21311
Value Function Loss: 0.00443

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09993
Policy Update Magnitude: 0.57387
Value Function Update Magnitude: 0.71071

Collected Steps per Second: 22,419.05484
Overall Steps per Second: 10,585.78024

Timestep Collection Time: 2.23051
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.72388

Cumulative Model Updates: 92,392
Cumulative Timesteps: 770,591,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.56683
Policy Entropy: 3.19314
Value Function Loss: 0.00451

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.56137
Value Function Update Magnitude: 0.67219

Collected Steps per Second: 22,937.69726
Overall Steps per Second: 10,806.17108

Timestep Collection Time: 2.18060
Timestep Consumption Time: 2.44805
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.62865

Cumulative Model Updates: 92,398
Cumulative Timesteps: 770,641,168

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 770641168...
Checkpoint 770641168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.81768
Policy Entropy: 3.18962
Value Function Loss: 0.00459

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.56112
Value Function Update Magnitude: 0.67023

Collected Steps per Second: 22,287.37806
Overall Steps per Second: 10,627.91012

Timestep Collection Time: 2.24450
Timestep Consumption Time: 2.46235
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.70685

Cumulative Model Updates: 92,404
Cumulative Timesteps: 770,691,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548.00392
Policy Entropy: 3.18476
Value Function Loss: 0.00486

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.56696
Value Function Update Magnitude: 0.66512

Collected Steps per Second: 22,182.49190
Overall Steps per Second: 10,518.53606

Timestep Collection Time: 2.25403
Timestep Consumption Time: 2.49948
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.75351

Cumulative Model Updates: 92,410
Cumulative Timesteps: 770,741,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 770741192...
Checkpoint 770741192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.79737
Policy Entropy: 3.20811
Value Function Loss: 0.00476

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.56376
Value Function Update Magnitude: 0.66314

Collected Steps per Second: 22,019.92599
Overall Steps per Second: 10,591.51213

Timestep Collection Time: 2.27112
Timestep Consumption Time: 2.45058
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.72171

Cumulative Model Updates: 92,416
Cumulative Timesteps: 770,791,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.56509
Policy Entropy: 3.23650
Value Function Loss: 0.00471

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.56319
Value Function Update Magnitude: 0.67361

Collected Steps per Second: 22,712.35743
Overall Steps per Second: 10,558.15151

Timestep Collection Time: 2.20259
Timestep Consumption Time: 2.53555
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.73814

Cumulative Model Updates: 92,422
Cumulative Timesteps: 770,841,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 770841228...
Checkpoint 770841228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.92134
Policy Entropy: 3.23189
Value Function Loss: 0.00469

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.56423
Value Function Update Magnitude: 0.66642

Collected Steps per Second: 22,252.02499
Overall Steps per Second: 10,689.90269

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.43227
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.68105

Cumulative Model Updates: 92,428
Cumulative Timesteps: 770,891,268

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995.76080
Policy Entropy: 3.21959
Value Function Loss: 0.00476

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12133
Policy Update Magnitude: 0.56900
Value Function Update Magnitude: 0.66674

Collected Steps per Second: 22,977.23715
Overall Steps per Second: 10,772.57195

Timestep Collection Time: 2.17694
Timestep Consumption Time: 2.46634
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.64327

Cumulative Model Updates: 92,434
Cumulative Timesteps: 770,941,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 770941288...
Checkpoint 770941288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.04953
Policy Entropy: 3.19575
Value Function Loss: 0.00491

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.56801
Value Function Update Magnitude: 0.66148

Collected Steps per Second: 22,942.06708
Overall Steps per Second: 10,703.21693

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.49239
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.67205

Cumulative Model Updates: 92,440
Cumulative Timesteps: 770,991,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.11871
Policy Entropy: 3.19752
Value Function Loss: 0.00497

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09739
Policy Update Magnitude: 0.57249
Value Function Update Magnitude: 0.67904

Collected Steps per Second: 22,787.24674
Overall Steps per Second: 10,631.84647

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.50894
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.70342

Cumulative Model Updates: 92,446
Cumulative Timesteps: 771,041,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 771041300...
Checkpoint 771041300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.37217
Policy Entropy: 3.19137
Value Function Loss: 0.00479

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09297
Policy Update Magnitude: 0.57702
Value Function Update Magnitude: 0.68843

Collected Steps per Second: 23,036.63851
Overall Steps per Second: 10,814.57705

Timestep Collection Time: 2.17115
Timestep Consumption Time: 2.45372
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.62487

Cumulative Model Updates: 92,452
Cumulative Timesteps: 771,091,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.76576
Policy Entropy: 3.18544
Value Function Loss: 0.00462

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.57301
Value Function Update Magnitude: 0.65794

Collected Steps per Second: 22,745.14541
Overall Steps per Second: 10,609.56663

Timestep Collection Time: 2.19889
Timestep Consumption Time: 2.51516
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.71405

Cumulative Model Updates: 92,458
Cumulative Timesteps: 771,141,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 771141330...
Checkpoint 771141330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.56662
Policy Entropy: 3.17956
Value Function Loss: 0.00465

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.56867
Value Function Update Magnitude: 0.62516

Collected Steps per Second: 22,824.67831
Overall Steps per Second: 10,603.57473

Timestep Collection Time: 2.19105
Timestep Consumption Time: 2.52528
PPO Batch Consumption Time: 0.29835
Total Iteration Time: 4.71633

Cumulative Model Updates: 92,464
Cumulative Timesteps: 771,191,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.34830
Policy Entropy: 3.19528
Value Function Loss: 0.00478

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.56566
Value Function Update Magnitude: 0.60970

Collected Steps per Second: 22,361.42215
Overall Steps per Second: 10,496.69814

Timestep Collection Time: 2.23680
Timestep Consumption Time: 2.52832
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.76512

Cumulative Model Updates: 92,470
Cumulative Timesteps: 771,241,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 771241358...
Checkpoint 771241358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 649.49270
Policy Entropy: 3.18876
Value Function Loss: 0.00478

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.57028
Value Function Update Magnitude: 0.62386

Collected Steps per Second: 22,366.42258
Overall Steps per Second: 10,588.87059

Timestep Collection Time: 2.23710
Timestep Consumption Time: 2.48824
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.72534

Cumulative Model Updates: 92,476
Cumulative Timesteps: 771,291,394

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.45165
Policy Entropy: 3.18238
Value Function Loss: 0.00471

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.58054
Value Function Update Magnitude: 0.63125

Collected Steps per Second: 22,583.99269
Overall Steps per Second: 10,522.44486

Timestep Collection Time: 2.21396
Timestep Consumption Time: 2.53779
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.75175

Cumulative Model Updates: 92,482
Cumulative Timesteps: 771,341,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 771341394...
Checkpoint 771341394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.11272
Policy Entropy: 3.16085
Value Function Loss: 0.00474

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11090
Policy Update Magnitude: 0.58639
Value Function Update Magnitude: 0.62134

Collected Steps per Second: 22,455.96375
Overall Steps per Second: 10,604.80155

Timestep Collection Time: 2.22685
Timestep Consumption Time: 2.48856
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.71541

Cumulative Model Updates: 92,488
Cumulative Timesteps: 771,391,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,675.27483
Policy Entropy: 3.17630
Value Function Loss: 0.00475

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.58463
Value Function Update Magnitude: 0.62920

Collected Steps per Second: 22,735.71322
Overall Steps per Second: 10,530.48370

Timestep Collection Time: 2.19962
Timestep Consumption Time: 2.54945
PPO Batch Consumption Time: 0.29503
Total Iteration Time: 4.74907

Cumulative Model Updates: 92,494
Cumulative Timesteps: 771,441,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 771441410...
Checkpoint 771441410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.70420
Policy Entropy: 3.16631
Value Function Loss: 0.00486

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.57726
Value Function Update Magnitude: 0.63728

Collected Steps per Second: 22,884.72670
Overall Steps per Second: 10,610.62077

Timestep Collection Time: 2.18521
Timestep Consumption Time: 2.52780
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.71301

Cumulative Model Updates: 92,500
Cumulative Timesteps: 771,491,418

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.48738
Policy Entropy: 3.19767
Value Function Loss: 0.00468

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.57649
Value Function Update Magnitude: 0.64247

Collected Steps per Second: 22,468.67628
Overall Steps per Second: 10,559.01753

Timestep Collection Time: 2.22577
Timestep Consumption Time: 2.51047
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.73624

Cumulative Model Updates: 92,506
Cumulative Timesteps: 771,541,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 771541428...
Checkpoint 771541428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883.29770
Policy Entropy: 3.18412
Value Function Loss: 0.00457

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.65487

Collected Steps per Second: 23,305.54959
Overall Steps per Second: 10,867.32175

Timestep Collection Time: 2.14670
Timestep Consumption Time: 2.45701
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.60371

Cumulative Model Updates: 92,512
Cumulative Timesteps: 771,591,458

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.25479
Policy Entropy: 3.20102
Value Function Loss: 0.00416

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.56502
Value Function Update Magnitude: 0.65486

Collected Steps per Second: 22,635.22620
Overall Steps per Second: 10,458.65891

Timestep Collection Time: 2.20965
Timestep Consumption Time: 2.57260
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.78226

Cumulative Model Updates: 92,518
Cumulative Timesteps: 771,641,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 771641474...
Checkpoint 771641474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,744.56130
Policy Entropy: 3.20493
Value Function Loss: 0.00424

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09350
Policy Update Magnitude: 0.55363
Value Function Update Magnitude: 0.63296

Collected Steps per Second: 22,770.00659
Overall Steps per Second: 10,622.72942

Timestep Collection Time: 2.19631
Timestep Consumption Time: 2.51152
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.70783

Cumulative Model Updates: 92,524
Cumulative Timesteps: 771,691,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.28263
Policy Entropy: 3.20865
Value Function Loss: 0.00441

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08980
Policy Update Magnitude: 0.55466
Value Function Update Magnitude: 0.62429

Collected Steps per Second: 22,414.24245
Overall Steps per Second: 10,489.83327

Timestep Collection Time: 2.23162
Timestep Consumption Time: 2.53681
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.76843

Cumulative Model Updates: 92,530
Cumulative Timesteps: 771,741,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 771741504...
Checkpoint 771741504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.72180
Policy Entropy: 3.19428
Value Function Loss: 0.00454

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.61930

Collected Steps per Second: 22,081.82256
Overall Steps per Second: 10,582.98969

Timestep Collection Time: 2.26512
Timestep Consumption Time: 2.46114
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.72626

Cumulative Model Updates: 92,536
Cumulative Timesteps: 771,791,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.78502
Policy Entropy: 3.18758
Value Function Loss: 0.00458

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08738
Policy Update Magnitude: 0.56313
Value Function Update Magnitude: 0.59595

Collected Steps per Second: 22,682.15201
Overall Steps per Second: 10,536.10450

Timestep Collection Time: 2.20570
Timestep Consumption Time: 2.54274
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.74843

Cumulative Model Updates: 92,542
Cumulative Timesteps: 771,841,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 771841552...
Checkpoint 771841552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.10537
Policy Entropy: 3.18998
Value Function Loss: 0.00455

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.56456
Value Function Update Magnitude: 0.59455

Collected Steps per Second: 22,343.49300
Overall Steps per Second: 10,616.20258

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.47219
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.71016

Cumulative Model Updates: 92,548
Cumulative Timesteps: 771,891,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.27923
Policy Entropy: 3.20599
Value Function Loss: 0.00440

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.55816
Value Function Update Magnitude: 0.58582

Collected Steps per Second: 22,377.34105
Overall Steps per Second: 10,430.35560

Timestep Collection Time: 2.23512
Timestep Consumption Time: 2.56012
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.79523

Cumulative Model Updates: 92,554
Cumulative Timesteps: 771,941,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 771941572...
Checkpoint 771941572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.55753
Policy Entropy: 3.20341
Value Function Loss: 0.00435

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.55742
Value Function Update Magnitude: 0.58801

Collected Steps per Second: 22,725.08140
Overall Steps per Second: 10,683.22599

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.48072
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.68154

Cumulative Model Updates: 92,560
Cumulative Timesteps: 771,991,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.86471
Policy Entropy: 3.21402
Value Function Loss: 0.00438

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10176
Policy Update Magnitude: 0.55091
Value Function Update Magnitude: 0.60425

Collected Steps per Second: 22,962.03872
Overall Steps per Second: 10,786.08367

Timestep Collection Time: 2.17812
Timestep Consumption Time: 2.45878
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.63690

Cumulative Model Updates: 92,566
Cumulative Timesteps: 772,041,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 772041600...
Checkpoint 772041600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 965.15097
Policy Entropy: 3.20980
Value Function Loss: 0.00457

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.55016
Value Function Update Magnitude: 0.61619

Collected Steps per Second: 22,736.17344
Overall Steps per Second: 10,741.06084

Timestep Collection Time: 2.20028
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.65745

Cumulative Model Updates: 92,572
Cumulative Timesteps: 772,091,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.35419
Policy Entropy: 3.21719
Value Function Loss: 0.00457

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.55298
Value Function Update Magnitude: 0.62645

Collected Steps per Second: 22,683.99513
Overall Steps per Second: 10,772.76700

Timestep Collection Time: 2.20437
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.64170

Cumulative Model Updates: 92,578
Cumulative Timesteps: 772,141,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 772141630...
Checkpoint 772141630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.25451
Policy Entropy: 3.20026
Value Function Loss: 0.00482

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.55118
Value Function Update Magnitude: 0.61488

Collected Steps per Second: 22,719.81223
Overall Steps per Second: 10,770.05645

Timestep Collection Time: 2.20099
Timestep Consumption Time: 2.44207
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.64306

Cumulative Model Updates: 92,584
Cumulative Timesteps: 772,191,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.16219
Policy Entropy: 3.20896
Value Function Loss: 0.00476

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.55585
Value Function Update Magnitude: 0.60830

Collected Steps per Second: 22,876.63144
Overall Steps per Second: 10,827.98472

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.61933

Cumulative Model Updates: 92,590
Cumulative Timesteps: 772,241,654

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 772241654...
Checkpoint 772241654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.11011
Policy Entropy: 3.21472
Value Function Loss: 0.00455

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.55464
Value Function Update Magnitude: 0.62179

Collected Steps per Second: 22,247.54680
Overall Steps per Second: 10,672.11214

Timestep Collection Time: 2.24762
Timestep Consumption Time: 2.43786
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.68548

Cumulative Model Updates: 92,596
Cumulative Timesteps: 772,291,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.14209
Policy Entropy: 3.22295
Value Function Loss: 0.00438

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.62536

Collected Steps per Second: 22,271.86963
Overall Steps per Second: 10,555.61051

Timestep Collection Time: 2.24579
Timestep Consumption Time: 2.49273
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.73852

Cumulative Model Updates: 92,602
Cumulative Timesteps: 772,341,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 772341676...
Checkpoint 772341676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.42412
Policy Entropy: 3.20917
Value Function Loss: 0.00471

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.55741
Value Function Update Magnitude: 0.64554

Collected Steps per Second: 22,182.42740
Overall Steps per Second: 10,590.27662

Timestep Collection Time: 2.25440
Timestep Consumption Time: 2.46767
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.72207

Cumulative Model Updates: 92,608
Cumulative Timesteps: 772,391,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.62917
Policy Entropy: 3.20288
Value Function Loss: 0.00458

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.66982

Collected Steps per Second: 22,535.52038
Overall Steps per Second: 10,604.24886

Timestep Collection Time: 2.21987
Timestep Consumption Time: 2.49767
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.71754

Cumulative Model Updates: 92,614
Cumulative Timesteps: 772,441,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 772441710...
Checkpoint 772441710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.19816
Policy Entropy: 3.19732
Value Function Loss: 0.00459

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.57455
Value Function Update Magnitude: 0.67348

Collected Steps per Second: 22,566.81659
Overall Steps per Second: 10,555.86202

Timestep Collection Time: 2.21671
Timestep Consumption Time: 2.52227
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.73898

Cumulative Model Updates: 92,620
Cumulative Timesteps: 772,491,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.81573
Policy Entropy: 3.20971
Value Function Loss: 0.00435

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.56290
Value Function Update Magnitude: 0.64706

Collected Steps per Second: 22,953.86342
Overall Steps per Second: 10,811.77141

Timestep Collection Time: 2.17872
Timestep Consumption Time: 2.44680
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.62551

Cumulative Model Updates: 92,626
Cumulative Timesteps: 772,541,744

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 772541744...
Checkpoint 772541744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.04190
Policy Entropy: 3.19150
Value Function Loss: 0.00454

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12879
Policy Update Magnitude: 0.56134
Value Function Update Magnitude: 0.61447

Collected Steps per Second: 22,642.17425
Overall Steps per Second: 10,681.52645

Timestep Collection Time: 2.20915
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.68285

Cumulative Model Updates: 92,632
Cumulative Timesteps: 772,591,764

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.77820
Policy Entropy: 3.18490
Value Function Loss: 0.00459

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.56630
Value Function Update Magnitude: 0.60989

Collected Steps per Second: 22,346.00222
Overall Steps per Second: 10,540.09936

Timestep Collection Time: 2.23772
Timestep Consumption Time: 2.50645
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.74417

Cumulative Model Updates: 92,638
Cumulative Timesteps: 772,641,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 772641768...
Checkpoint 772641768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.08849
Policy Entropy: 3.17912
Value Function Loss: 0.00457

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10984
Policy Update Magnitude: 0.57484
Value Function Update Magnitude: 0.62739

Collected Steps per Second: 22,768.09309
Overall Steps per Second: 10,666.50626

Timestep Collection Time: 2.19632
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.68813

Cumulative Model Updates: 92,644
Cumulative Timesteps: 772,691,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.76848
Policy Entropy: 3.18590
Value Function Loss: 0.00441

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.56712
Value Function Update Magnitude: 0.61849

Collected Steps per Second: 22,752.51477
Overall Steps per Second: 10,805.09330

Timestep Collection Time: 2.19826
Timestep Consumption Time: 2.43067
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.62893

Cumulative Model Updates: 92,650
Cumulative Timesteps: 772,741,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 772741790...
Checkpoint 772741790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.74030
Policy Entropy: 3.17968
Value Function Loss: 0.00442

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.56710
Value Function Update Magnitude: 0.60957

Collected Steps per Second: 22,694.01265
Overall Steps per Second: 10,627.33299

Timestep Collection Time: 2.20446
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.70748

Cumulative Model Updates: 92,656
Cumulative Timesteps: 772,791,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.15444
Policy Entropy: 3.17224
Value Function Loss: 0.00438

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.57413
Value Function Update Magnitude: 0.61716

Collected Steps per Second: 22,416.03609
Overall Steps per Second: 10,593.23896

Timestep Collection Time: 2.23171
Timestep Consumption Time: 2.49074
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.72245

Cumulative Model Updates: 92,662
Cumulative Timesteps: 772,841,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 772841844...
Checkpoint 772841844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.71348
Policy Entropy: 3.18723
Value Function Loss: 0.00423

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.57148
Value Function Update Magnitude: 0.61317

Collected Steps per Second: 22,071.88551
Overall Steps per Second: 10,481.58130

Timestep Collection Time: 2.26623
Timestep Consumption Time: 2.50595
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.77218

Cumulative Model Updates: 92,668
Cumulative Timesteps: 772,891,864

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.44363
Policy Entropy: 3.19665
Value Function Loss: 0.00437

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.56919
Value Function Update Magnitude: 0.61132

Collected Steps per Second: 22,763.53979
Overall Steps per Second: 10,733.19329

Timestep Collection Time: 2.19702
Timestep Consumption Time: 2.46254
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.65956

Cumulative Model Updates: 92,674
Cumulative Timesteps: 772,941,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 772941876...
Checkpoint 772941876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.04489
Policy Entropy: 3.20130
Value Function Loss: 0.00431

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.56821
Value Function Update Magnitude: 0.60194

Collected Steps per Second: 22,485.06034
Overall Steps per Second: 10,768.06013

Timestep Collection Time: 2.22477
Timestep Consumption Time: 2.42082
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.64559

Cumulative Model Updates: 92,680
Cumulative Timesteps: 772,991,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,850.05745
Policy Entropy: 3.19982
Value Function Loss: 0.00439

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.56656
Value Function Update Magnitude: 0.60498

Collected Steps per Second: 22,756.95999
Overall Steps per Second: 10,558.56007

Timestep Collection Time: 2.19845
Timestep Consumption Time: 2.53989
PPO Batch Consumption Time: 0.29738
Total Iteration Time: 4.73834

Cumulative Model Updates: 92,686
Cumulative Timesteps: 773,041,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 773041930...
Checkpoint 773041930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.62626
Policy Entropy: 3.20300
Value Function Loss: 0.00410

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.56380
Value Function Update Magnitude: 0.60724

Collected Steps per Second: 22,495.06428
Overall Steps per Second: 10,649.08949

Timestep Collection Time: 2.22369
Timestep Consumption Time: 2.47362
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.69730

Cumulative Model Updates: 92,692
Cumulative Timesteps: 773,091,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.52614
Policy Entropy: 3.19609
Value Function Loss: 0.00411

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.55517
Value Function Update Magnitude: 0.61172

Collected Steps per Second: 23,066.12877
Overall Steps per Second: 10,867.22903

Timestep Collection Time: 2.16881
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.60338

Cumulative Model Updates: 92,698
Cumulative Timesteps: 773,141,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 773141978...
Checkpoint 773141978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 629.23018
Policy Entropy: 3.18829
Value Function Loss: 0.00429

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.54954
Value Function Update Magnitude: 0.60998

Collected Steps per Second: 22,905.59386
Overall Steps per Second: 10,705.82773

Timestep Collection Time: 2.18348
Timestep Consumption Time: 2.48818
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.67166

Cumulative Model Updates: 92,704
Cumulative Timesteps: 773,191,992

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.53152
Policy Entropy: 3.19681
Value Function Loss: 0.00433

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.55698
Value Function Update Magnitude: 0.60626

Collected Steps per Second: 22,910.32266
Overall Steps per Second: 10,819.25316

Timestep Collection Time: 2.18356
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.62379

Cumulative Model Updates: 92,710
Cumulative Timesteps: 773,242,018

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 773242018...
Checkpoint 773242018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.69850
Policy Entropy: 3.19240
Value Function Loss: 0.00427

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.55484
Value Function Update Magnitude: 0.59045

Collected Steps per Second: 22,433.79349
Overall Steps per Second: 10,657.02886

Timestep Collection Time: 2.22994
Timestep Consumption Time: 2.46424
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.69418

Cumulative Model Updates: 92,716
Cumulative Timesteps: 773,292,044

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.09747
Policy Entropy: 3.18712
Value Function Loss: 0.00426

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.55013
Value Function Update Magnitude: 0.58509

Collected Steps per Second: 22,572.37329
Overall Steps per Second: 10,642.77918

Timestep Collection Time: 2.21598
Timestep Consumption Time: 2.48392
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.69990

Cumulative Model Updates: 92,722
Cumulative Timesteps: 773,342,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 773342064...
Checkpoint 773342064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.09733
Policy Entropy: 3.18033
Value Function Loss: 0.00439

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.55749
Value Function Update Magnitude: 0.59310

Collected Steps per Second: 22,347.94150
Overall Steps per Second: 10,577.74049

Timestep Collection Time: 2.23779
Timestep Consumption Time: 2.49006
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.72785

Cumulative Model Updates: 92,728
Cumulative Timesteps: 773,392,074

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.78959
Policy Entropy: 3.18406
Value Function Loss: 0.00473

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08860
Policy Update Magnitude: 0.57197
Value Function Update Magnitude: 0.60875

Collected Steps per Second: 22,632.18625
Overall Steps per Second: 10,771.75317

Timestep Collection Time: 2.20995
Timestep Consumption Time: 2.43331
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.64326

Cumulative Model Updates: 92,734
Cumulative Timesteps: 773,442,090

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 773442090...
Checkpoint 773442090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.59545
Policy Entropy: 3.18388
Value Function Loss: 0.00462

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.58048
Value Function Update Magnitude: 0.62429

Collected Steps per Second: 22,072.44262
Overall Steps per Second: 10,620.50638

Timestep Collection Time: 2.26617
Timestep Consumption Time: 2.44358
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.70976

Cumulative Model Updates: 92,740
Cumulative Timesteps: 773,492,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.65693
Policy Entropy: 3.17792
Value Function Loss: 0.00440

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.57236
Value Function Update Magnitude: 0.64340

Collected Steps per Second: 22,673.50470
Overall Steps per Second: 10,662.59300

Timestep Collection Time: 2.20636
Timestep Consumption Time: 2.48537
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.69173

Cumulative Model Updates: 92,746
Cumulative Timesteps: 773,542,136

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 773542136...
Checkpoint 773542136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.64318
Policy Entropy: 3.17513
Value Function Loss: 0.00470

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10820
Policy Update Magnitude: 0.56556
Value Function Update Magnitude: 0.61902

Collected Steps per Second: 22,625.29118
Overall Steps per Second: 10,668.04134

Timestep Collection Time: 2.21018
Timestep Consumption Time: 2.47728
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.68746

Cumulative Model Updates: 92,752
Cumulative Timesteps: 773,592,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.19706
Policy Entropy: 3.20034
Value Function Loss: 0.00434

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.56479
Value Function Update Magnitude: 0.60136

Collected Steps per Second: 23,268.20568
Overall Steps per Second: 10,693.98663

Timestep Collection Time: 2.14997
Timestep Consumption Time: 2.52798
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.67796

Cumulative Model Updates: 92,758
Cumulative Timesteps: 773,642,168

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 773642168...
Checkpoint 773642168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.44312
Policy Entropy: 3.20550
Value Function Loss: 0.00453

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08702
Policy Update Magnitude: 0.56220
Value Function Update Magnitude: 0.58372

Collected Steps per Second: 22,179.34584
Overall Steps per Second: 10,685.21021

Timestep Collection Time: 2.25444
Timestep Consumption Time: 2.42511
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.67955

Cumulative Model Updates: 92,764
Cumulative Timesteps: 773,692,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.46098
Policy Entropy: 3.20928
Value Function Loss: 0.00433

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.56115
Value Function Update Magnitude: 0.58110

Collected Steps per Second: 22,884.28042
Overall Steps per Second: 10,820.44412

Timestep Collection Time: 2.18561
Timestep Consumption Time: 2.43676
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.62236

Cumulative Model Updates: 92,770
Cumulative Timesteps: 773,742,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 773742186...
Checkpoint 773742186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.66867
Policy Entropy: 3.20956
Value Function Loss: 0.00447

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08227
Policy Update Magnitude: 0.56440
Value Function Update Magnitude: 0.58033

Collected Steps per Second: 22,691.38581
Overall Steps per Second: 10,766.08933

Timestep Collection Time: 2.20427
Timestep Consumption Time: 2.44161
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.64588

Cumulative Model Updates: 92,776
Cumulative Timesteps: 773,792,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.46000
Policy Entropy: 3.20722
Value Function Loss: 0.00439

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08259
Policy Update Magnitude: 0.56166
Value Function Update Magnitude: 0.57884

Collected Steps per Second: 22,878.70700
Overall Steps per Second: 10,817.79751

Timestep Collection Time: 2.18649
Timestep Consumption Time: 2.43774
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.62423

Cumulative Model Updates: 92,782
Cumulative Timesteps: 773,842,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 773842228...
Checkpoint 773842228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.27357
Policy Entropy: 3.19383
Value Function Loss: 0.00450

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.56793
Value Function Update Magnitude: 0.58211

Collected Steps per Second: 22,535.56775
Overall Steps per Second: 10,655.56236

Timestep Collection Time: 2.21889
Timestep Consumption Time: 2.47387
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.69276

Cumulative Model Updates: 92,788
Cumulative Timesteps: 773,892,232

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.50274
Policy Entropy: 3.18515
Value Function Loss: 0.00435

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.56974
Value Function Update Magnitude: 0.61399

Collected Steps per Second: 22,500.56676
Overall Steps per Second: 10,628.24458

Timestep Collection Time: 2.22314
Timestep Consumption Time: 2.48337
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.70652

Cumulative Model Updates: 92,794
Cumulative Timesteps: 773,942,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 773942254...
Checkpoint 773942254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.27803
Policy Entropy: 3.18209
Value Function Loss: 0.00439

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.57189
Value Function Update Magnitude: 0.61388

Collected Steps per Second: 22,203.74377
Overall Steps per Second: 10,517.16785

Timestep Collection Time: 2.25187
Timestep Consumption Time: 2.50226
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.75413

Cumulative Model Updates: 92,800
Cumulative Timesteps: 773,992,254

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.10918
Policy Entropy: 3.18904
Value Function Loss: 0.00422

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.56374
Value Function Update Magnitude: 0.57903

Collected Steps per Second: 22,430.91762
Overall Steps per Second: 10,645.16376

Timestep Collection Time: 2.22951
Timestep Consumption Time: 2.46840
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.69791

Cumulative Model Updates: 92,806
Cumulative Timesteps: 774,042,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 774042264...
Checkpoint 774042264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.73488
Policy Entropy: 3.18575
Value Function Loss: 0.00437

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.56058
Value Function Update Magnitude: 0.54870

Collected Steps per Second: 21,921.86567
Overall Steps per Second: 10,447.75649

Timestep Collection Time: 2.28229
Timestep Consumption Time: 2.50649
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.78878

Cumulative Model Updates: 92,812
Cumulative Timesteps: 774,092,296

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.57727
Policy Entropy: 3.20194
Value Function Loss: 0.00435

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.55353
Value Function Update Magnitude: 0.53787

Collected Steps per Second: 22,610.10617
Overall Steps per Second: 10,777.51085

Timestep Collection Time: 2.21220
Timestep Consumption Time: 2.42876
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.64096

Cumulative Model Updates: 92,818
Cumulative Timesteps: 774,142,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 774142314...
Checkpoint 774142314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.09391
Policy Entropy: 3.21578
Value Function Loss: 0.00447

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.55374
Value Function Update Magnitude: 0.56258

Collected Steps per Second: 22,542.97875
Overall Steps per Second: 10,671.00086

Timestep Collection Time: 2.21799
Timestep Consumption Time: 2.46761
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.68560

Cumulative Model Updates: 92,824
Cumulative Timesteps: 774,192,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.31743
Policy Entropy: 3.21979
Value Function Loss: 0.00426

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.56053
Value Function Update Magnitude: 0.57030

Collected Steps per Second: 23,107.42935
Overall Steps per Second: 10,833.74745

Timestep Collection Time: 2.16389
Timestep Consumption Time: 2.45150
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.61539

Cumulative Model Updates: 92,830
Cumulative Timesteps: 774,242,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 774242316...
Checkpoint 774242316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.84526
Policy Entropy: 3.20553
Value Function Loss: 0.00420

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.57438

Collected Steps per Second: 22,602.54046
Overall Steps per Second: 10,800.55315

Timestep Collection Time: 2.21223
Timestep Consumption Time: 2.41735
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.62958

Cumulative Model Updates: 92,836
Cumulative Timesteps: 774,292,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.12950
Policy Entropy: 3.19848
Value Function Loss: 0.00423

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.07960
Policy Update Magnitude: 0.55704
Value Function Update Magnitude: 0.57478

Collected Steps per Second: 23,119.11940
Overall Steps per Second: 10,893.43409

Timestep Collection Time: 2.16340
Timestep Consumption Time: 2.42799
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.59139

Cumulative Model Updates: 92,842
Cumulative Timesteps: 774,342,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 774342334...
Checkpoint 774342334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.25035
Policy Entropy: 3.19006
Value Function Loss: 0.00437

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.56894
Value Function Update Magnitude: 0.60224

Collected Steps per Second: 22,566.85729
Overall Steps per Second: 10,618.41369

Timestep Collection Time: 2.21635
Timestep Consumption Time: 2.49396
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.71031

Cumulative Model Updates: 92,848
Cumulative Timesteps: 774,392,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.00516
Policy Entropy: 3.16490
Value Function Loss: 0.00467

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.57623
Value Function Update Magnitude: 0.63349

Collected Steps per Second: 22,904.38669
Overall Steps per Second: 10,826.03519

Timestep Collection Time: 2.18369
Timestep Consumption Time: 2.43629
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.61997

Cumulative Model Updates: 92,854
Cumulative Timesteps: 774,442,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 774442366...
Checkpoint 774442366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.00242
Policy Entropy: 3.15982
Value Function Loss: 0.00473

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.58472
Value Function Update Magnitude: 0.64415

Collected Steps per Second: 21,980.28453
Overall Steps per Second: 10,596.35788

Timestep Collection Time: 2.27595
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.72106

Cumulative Model Updates: 92,860
Cumulative Timesteps: 774,492,392

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.32400
Policy Entropy: 3.16136
Value Function Loss: 0.00491

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.58400
Value Function Update Magnitude: 0.62393

Collected Steps per Second: 22,392.76655
Overall Steps per Second: 10,598.75619

Timestep Collection Time: 2.23349
Timestep Consumption Time: 2.48537
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.71886

Cumulative Model Updates: 92,866
Cumulative Timesteps: 774,542,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 774542406...
Checkpoint 774542406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 809.89570
Policy Entropy: 3.18265
Value Function Loss: 0.00476

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.58376
Value Function Update Magnitude: 0.60276

Collected Steps per Second: 22,579.77164
Overall Steps per Second: 10,662.49222

Timestep Collection Time: 2.21535
Timestep Consumption Time: 2.47605
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.69140

Cumulative Model Updates: 92,872
Cumulative Timesteps: 774,592,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.42527
Policy Entropy: 3.18093
Value Function Loss: 0.00473

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09209
Policy Update Magnitude: 0.57893
Value Function Update Magnitude: 0.61297

Collected Steps per Second: 22,244.71707
Overall Steps per Second: 10,584.34250

Timestep Collection Time: 2.24772
Timestep Consumption Time: 2.47623
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.72396

Cumulative Model Updates: 92,878
Cumulative Timesteps: 774,642,428

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 774642428...
Checkpoint 774642428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.19846
Policy Entropy: 3.20936
Value Function Loss: 0.00450

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.57812
Value Function Update Magnitude: 0.63651

Collected Steps per Second: 22,219.32099
Overall Steps per Second: 10,476.81295

Timestep Collection Time: 2.25038
Timestep Consumption Time: 2.52225
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.77263

Cumulative Model Updates: 92,884
Cumulative Timesteps: 774,692,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.66005
Policy Entropy: 3.20220
Value Function Loss: 0.00468

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09078
Policy Update Magnitude: 0.57159
Value Function Update Magnitude: 0.64662

Collected Steps per Second: 22,979.75863
Overall Steps per Second: 10,707.07335

Timestep Collection Time: 2.17661
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.67149

Cumulative Model Updates: 92,890
Cumulative Timesteps: 774,742,448

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 774742448...
Checkpoint 774742448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 506.41411
Policy Entropy: 3.19204
Value Function Loss: 0.00466

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.57411
Value Function Update Magnitude: 0.64438

Collected Steps per Second: 22,906.21281
Overall Steps per Second: 10,814.58445

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.44126
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.62468

Cumulative Model Updates: 92,896
Cumulative Timesteps: 774,792,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.22870
Policy Entropy: 3.18890
Value Function Loss: 0.00463

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.57378
Value Function Update Magnitude: 0.62288

Collected Steps per Second: 22,940.14494
Overall Steps per Second: 10,822.26023

Timestep Collection Time: 2.18002
Timestep Consumption Time: 2.44101
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.62103

Cumulative Model Updates: 92,902
Cumulative Timesteps: 774,842,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 774842472...
Checkpoint 774842472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,488.43400
Policy Entropy: 3.19662
Value Function Loss: 0.00440

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11196
Policy Update Magnitude: 0.56259
Value Function Update Magnitude: 0.63016

Collected Steps per Second: 22,392.74366
Overall Steps per Second: 10,739.16978

Timestep Collection Time: 2.23421
Timestep Consumption Time: 2.42444
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.65865

Cumulative Model Updates: 92,908
Cumulative Timesteps: 774,892,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.74406
Policy Entropy: 3.20443
Value Function Loss: 0.00437

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10666
Policy Update Magnitude: 0.55862
Value Function Update Magnitude: 0.62501

Collected Steps per Second: 22,911.08283
Overall Steps per Second: 10,825.41951

Timestep Collection Time: 2.18279
Timestep Consumption Time: 2.43690
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.61968

Cumulative Model Updates: 92,914
Cumulative Timesteps: 774,942,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 774942512...
Checkpoint 774942512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 662.19619
Policy Entropy: 3.20377
Value Function Loss: 0.00433

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12193
Policy Update Magnitude: 0.55847
Value Function Update Magnitude: 0.60846

Collected Steps per Second: 22,440.61869
Overall Steps per Second: 10,736.91789

Timestep Collection Time: 2.22935
Timestep Consumption Time: 2.43009
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.65944

Cumulative Model Updates: 92,920
Cumulative Timesteps: 774,992,540

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 589.22616
Policy Entropy: 3.20419
Value Function Loss: 0.00456

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.55585
Value Function Update Magnitude: 0.60457

Collected Steps per Second: 22,217.62002
Overall Steps per Second: 10,487.81839

Timestep Collection Time: 2.25110
Timestep Consumption Time: 2.51767
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.76877

Cumulative Model Updates: 92,926
Cumulative Timesteps: 775,042,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 775042554...
Checkpoint 775042554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,524.03505
Policy Entropy: 3.20707
Value Function Loss: 0.00441

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.60060

Collected Steps per Second: 22,386.46083
Overall Steps per Second: 10,608.14509

Timestep Collection Time: 2.23385
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.71411

Cumulative Model Updates: 92,932
Cumulative Timesteps: 775,092,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.71696
Policy Entropy: 3.20328
Value Function Loss: 0.00447

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.55436
Value Function Update Magnitude: 0.61312

Collected Steps per Second: 22,439.37184
Overall Steps per Second: 10,576.40297

Timestep Collection Time: 2.22894
Timestep Consumption Time: 2.50008
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.72902

Cumulative Model Updates: 92,938
Cumulative Timesteps: 775,142,578

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 775142578...
Checkpoint 775142578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.96618
Policy Entropy: 3.20665
Value Function Loss: 0.00444

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.55280
Value Function Update Magnitude: 0.61747

Collected Steps per Second: 22,830.00993
Overall Steps per Second: 10,663.56260

Timestep Collection Time: 2.19027
Timestep Consumption Time: 2.49896
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.68924

Cumulative Model Updates: 92,944
Cumulative Timesteps: 775,192,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.08441
Policy Entropy: 3.19312
Value Function Loss: 0.00450

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.54999
Value Function Update Magnitude: 0.63724

Collected Steps per Second: 23,041.31968
Overall Steps per Second: 10,762.40016

Timestep Collection Time: 2.17071
Timestep Consumption Time: 2.47658
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.64729

Cumulative Model Updates: 92,950
Cumulative Timesteps: 775,242,598

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 775242598...
Checkpoint 775242598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.97523
Policy Entropy: 3.19447
Value Function Loss: 0.00434

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.63842

Collected Steps per Second: 22,497.77972
Overall Steps per Second: 10,631.72839

Timestep Collection Time: 2.22360
Timestep Consumption Time: 2.48175
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.70535

Cumulative Model Updates: 92,956
Cumulative Timesteps: 775,292,624

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.25011
Policy Entropy: 3.18798
Value Function Loss: 0.00421

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.55253
Value Function Update Magnitude: 0.61012

Collected Steps per Second: 22,682.83826
Overall Steps per Second: 10,707.99399

Timestep Collection Time: 2.20457
Timestep Consumption Time: 2.46539
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.66997

Cumulative Model Updates: 92,962
Cumulative Timesteps: 775,342,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 775342630...
Checkpoint 775342630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.76415
Policy Entropy: 3.20880
Value Function Loss: 0.00414

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.54563
Value Function Update Magnitude: 0.59205

Collected Steps per Second: 22,636.21602
Overall Steps per Second: 10,766.94698

Timestep Collection Time: 2.20894
Timestep Consumption Time: 2.43509
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.64403

Cumulative Model Updates: 92,968
Cumulative Timesteps: 775,392,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,224.12755
Policy Entropy: 3.21225
Value Function Loss: 0.00397

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.08323
Policy Update Magnitude: 0.53399
Value Function Update Magnitude: 0.57922

Collected Steps per Second: 23,157.07506
Overall Steps per Second: 10,853.01142

Timestep Collection Time: 2.16029
Timestep Consumption Time: 2.44912
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.60941

Cumulative Model Updates: 92,974
Cumulative Timesteps: 775,442,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 775442658...
Checkpoint 775442658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.36385
Policy Entropy: 3.22019
Value Function Loss: 0.00410

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07925
Policy Update Magnitude: 0.53859
Value Function Update Magnitude: 0.56214

Collected Steps per Second: 21,401.66480
Overall Steps per Second: 10,342.15892

Timestep Collection Time: 2.33636
Timestep Consumption Time: 2.49841
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.83477

Cumulative Model Updates: 92,980
Cumulative Timesteps: 775,492,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.51727
Policy Entropy: 3.19004
Value Function Loss: 0.00423

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.53981
Value Function Update Magnitude: 0.56607

Collected Steps per Second: 22,493.58772
Overall Steps per Second: 10,642.96086

Timestep Collection Time: 2.22339
Timestep Consumption Time: 2.47568
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69907

Cumulative Model Updates: 92,986
Cumulative Timesteps: 775,542,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 775542672...
Checkpoint 775542672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.27210
Policy Entropy: 3.19179
Value Function Loss: 0.00436

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.54219
Value Function Update Magnitude: 0.56957

Collected Steps per Second: 22,089.32716
Overall Steps per Second: 10,533.09947

Timestep Collection Time: 2.26489
Timestep Consumption Time: 2.48489
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.74979

Cumulative Model Updates: 92,992
Cumulative Timesteps: 775,592,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.71058
Policy Entropy: 3.18030
Value Function Loss: 0.00454

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10569
Policy Update Magnitude: 0.55184
Value Function Update Magnitude: 0.56201

Collected Steps per Second: 23,178.16986
Overall Steps per Second: 10,810.02585

Timestep Collection Time: 2.15824
Timestep Consumption Time: 2.46932
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.62756

Cumulative Model Updates: 92,998
Cumulative Timesteps: 775,642,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 775642726...
Checkpoint 775642726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.29637
Policy Entropy: 3.20290
Value Function Loss: 0.00437

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 0.55917
Value Function Update Magnitude: 0.57953

Collected Steps per Second: 22,340.38191
Overall Steps per Second: 10,653.34351

Timestep Collection Time: 2.23882
Timestep Consumption Time: 2.45605
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.69486

Cumulative Model Updates: 93,004
Cumulative Timesteps: 775,692,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.56217
Policy Entropy: 3.18932
Value Function Loss: 0.00427

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.55415
Value Function Update Magnitude: 0.58399

Collected Steps per Second: 22,897.94044
Overall Steps per Second: 10,826.96089

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.43450
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.61810

Cumulative Model Updates: 93,010
Cumulative Timesteps: 775,742,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 775742742...
Checkpoint 775742742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 899.40892
Policy Entropy: 3.19426
Value Function Loss: 0.00449

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08514
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.57531

Collected Steps per Second: 22,837.47421
Overall Steps per Second: 10,723.78379

Timestep Collection Time: 2.19000
Timestep Consumption Time: 2.47384
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.66384

Cumulative Model Updates: 93,016
Cumulative Timesteps: 775,792,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,981.30966
Policy Entropy: 3.19747
Value Function Loss: 0.00462

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09229
Policy Update Magnitude: 0.55735
Value Function Update Magnitude: 0.58091

Collected Steps per Second: 23,100.89470
Overall Steps per Second: 10,888.72692

Timestep Collection Time: 2.16528
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.59374

Cumulative Model Updates: 93,022
Cumulative Timesteps: 775,842,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 775842776...
Checkpoint 775842776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.32683
Policy Entropy: 3.20976
Value Function Loss: 0.00466

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.55354
Value Function Update Magnitude: 0.57350

Collected Steps per Second: 22,302.34444
Overall Steps per Second: 10,627.88899

Timestep Collection Time: 2.24219
Timestep Consumption Time: 2.46298
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.70517

Cumulative Model Updates: 93,028
Cumulative Timesteps: 775,892,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.94692
Policy Entropy: 3.19918
Value Function Loss: 0.00457

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.55284
Value Function Update Magnitude: 0.57270

Collected Steps per Second: 22,973.21740
Overall Steps per Second: 10,899.59763

Timestep Collection Time: 2.17775
Timestep Consumption Time: 2.41232
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.59008

Cumulative Model Updates: 93,034
Cumulative Timesteps: 775,942,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 775942812...
Checkpoint 775942812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,663.80112
Policy Entropy: 3.20097
Value Function Loss: 0.00447

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.55915
Value Function Update Magnitude: 0.57745

Collected Steps per Second: 22,149.45094
Overall Steps per Second: 10,697.51179

Timestep Collection Time: 2.25739
Timestep Consumption Time: 2.41659
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.67398

Cumulative Model Updates: 93,040
Cumulative Timesteps: 775,992,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.37386
Policy Entropy: 3.19466
Value Function Loss: 0.00436

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.57951

Collected Steps per Second: 22,683.49399
Overall Steps per Second: 10,768.24646

Timestep Collection Time: 2.20442
Timestep Consumption Time: 2.43923
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.64365

Cumulative Model Updates: 93,046
Cumulative Timesteps: 776,042,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 776042816...
Checkpoint 776042816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 898.65678
Policy Entropy: 3.20296
Value Function Loss: 0.00420

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.54917
Value Function Update Magnitude: 0.56159

Collected Steps per Second: 21,881.75669
Overall Steps per Second: 10,638.90553

Timestep Collection Time: 2.28547
Timestep Consumption Time: 2.41521
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.70067

Cumulative Model Updates: 93,052
Cumulative Timesteps: 776,092,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834.14755
Policy Entropy: 3.18373
Value Function Loss: 0.00424

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.54219
Value Function Update Magnitude: 0.55869

Collected Steps per Second: 22,402.76006
Overall Steps per Second: 10,566.45627

Timestep Collection Time: 2.23276
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.73385

Cumulative Model Updates: 93,058
Cumulative Timesteps: 776,142,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 776142846...
Checkpoint 776142846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,762.96106
Policy Entropy: 3.18360
Value Function Loss: 0.00424

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.54893
Value Function Update Magnitude: 0.57432

Collected Steps per Second: 22,270.20734
Overall Steps per Second: 10,677.88012

Timestep Collection Time: 2.24551
Timestep Consumption Time: 2.43782
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.68333

Cumulative Model Updates: 93,064
Cumulative Timesteps: 776,192,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.42320
Policy Entropy: 3.18308
Value Function Loss: 0.00427

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.55348
Value Function Update Magnitude: 0.58841

Collected Steps per Second: 22,729.49682
Overall Steps per Second: 10,775.82400

Timestep Collection Time: 2.20110
Timestep Consumption Time: 2.44170
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.64280

Cumulative Model Updates: 93,070
Cumulative Timesteps: 776,242,884

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 776242884...
Checkpoint 776242884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 719.87070
Policy Entropy: 3.18425
Value Function Loss: 0.00445

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.56399
Value Function Update Magnitude: 0.61635

Collected Steps per Second: 22,463.87158
Overall Steps per Second: 10,742.16639

Timestep Collection Time: 2.22580
Timestep Consumption Time: 2.42876
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.65455

Cumulative Model Updates: 93,076
Cumulative Timesteps: 776,292,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.60758
Policy Entropy: 3.18653
Value Function Loss: 0.00448

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.57185
Value Function Update Magnitude: 0.63378

Collected Steps per Second: 22,833.56509
Overall Steps per Second: 10,805.83674

Timestep Collection Time: 2.19063
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.62898

Cumulative Model Updates: 93,082
Cumulative Timesteps: 776,342,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 776342904...
Checkpoint 776342904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.68683
Policy Entropy: 3.20163
Value Function Loss: 0.00440

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10403
Policy Update Magnitude: 0.56381
Value Function Update Magnitude: 0.64814

Collected Steps per Second: 22,900.25593
Overall Steps per Second: 10,727.18116

Timestep Collection Time: 2.18434
Timestep Consumption Time: 2.47877
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.66311

Cumulative Model Updates: 93,088
Cumulative Timesteps: 776,392,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.78073
Policy Entropy: 3.21181
Value Function Loss: 0.00410

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.55657
Value Function Update Magnitude: 0.64963

Collected Steps per Second: 22,925.07786
Overall Steps per Second: 10,856.74232

Timestep Collection Time: 2.18172
Timestep Consumption Time: 2.42519
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.60691

Cumulative Model Updates: 93,094
Cumulative Timesteps: 776,442,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 776442942...
Checkpoint 776442942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.73636
Policy Entropy: 3.22630
Value Function Loss: 0.00421

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.07358
Policy Update Magnitude: 0.55545
Value Function Update Magnitude: 0.63136

Collected Steps per Second: 22,135.20061
Overall Steps per Second: 10,635.06039

Timestep Collection Time: 2.25939
Timestep Consumption Time: 2.44317
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.70256

Cumulative Model Updates: 93,100
Cumulative Timesteps: 776,492,954

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.49972
Policy Entropy: 3.22085
Value Function Loss: 0.00431

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.62060

Collected Steps per Second: 22,661.84103
Overall Steps per Second: 10,683.65524

Timestep Collection Time: 2.20688
Timestep Consumption Time: 2.47429
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.68117

Cumulative Model Updates: 93,106
Cumulative Timesteps: 776,542,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 776542966...
Checkpoint 776542966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.89860
Policy Entropy: 3.22281
Value Function Loss: 0.00445

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.56022
Value Function Update Magnitude: 0.60672

Collected Steps per Second: 22,491.30567
Overall Steps per Second: 10,629.33060

Timestep Collection Time: 2.22326
Timestep Consumption Time: 2.48108
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.70434

Cumulative Model Updates: 93,112
Cumulative Timesteps: 776,592,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.10606
Policy Entropy: 3.21606
Value Function Loss: 0.00433

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.55557
Value Function Update Magnitude: 0.60616

Collected Steps per Second: 22,790.92134
Overall Steps per Second: 10,696.96500

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.48106
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.67553

Cumulative Model Updates: 93,118
Cumulative Timesteps: 776,642,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 776642984...
Checkpoint 776642984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.12284
Policy Entropy: 3.20792
Value Function Loss: 0.00429

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.55341
Value Function Update Magnitude: 0.61155

Collected Steps per Second: 22,032.31909
Overall Steps per Second: 10,606.70029

Timestep Collection Time: 2.26985
Timestep Consumption Time: 2.44510
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.71494

Cumulative Model Updates: 93,124
Cumulative Timesteps: 776,692,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.56435
Policy Entropy: 3.20361
Value Function Loss: 0.00457

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.55714
Value Function Update Magnitude: 0.64177

Collected Steps per Second: 22,563.81876
Overall Steps per Second: 10,537.06616

Timestep Collection Time: 2.21673
Timestep Consumption Time: 2.53013
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.74686

Cumulative Model Updates: 93,130
Cumulative Timesteps: 776,743,012

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 776743012...
Checkpoint 776743012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.68207
Policy Entropy: 3.19193
Value Function Loss: 0.00445

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.56701
Value Function Update Magnitude: 0.64830

Collected Steps per Second: 22,724.98838
Overall Steps per Second: 10,650.91142

Timestep Collection Time: 2.20075
Timestep Consumption Time: 2.49481
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.69556

Cumulative Model Updates: 93,136
Cumulative Timesteps: 776,793,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.39429
Policy Entropy: 3.21152
Value Function Loss: 0.00448

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.56826
Value Function Update Magnitude: 0.62973

Collected Steps per Second: 23,071.65407
Overall Steps per Second: 10,852.53036

Timestep Collection Time: 2.16768
Timestep Consumption Time: 2.44064
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.60833

Cumulative Model Updates: 93,142
Cumulative Timesteps: 776,843,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 776843036...
Checkpoint 776843036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.92466
Policy Entropy: 3.22164
Value Function Loss: 0.00445

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.56235
Value Function Update Magnitude: 0.63696

Collected Steps per Second: 22,671.03807
Overall Steps per Second: 10,657.93690

Timestep Collection Time: 2.20634
Timestep Consumption Time: 2.48688
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.69322

Cumulative Model Updates: 93,148
Cumulative Timesteps: 776,893,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.71421
Policy Entropy: 3.20160
Value Function Loss: 0.00468

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09239
Policy Update Magnitude: 0.56314
Value Function Update Magnitude: 0.65835

Collected Steps per Second: 22,992.47837
Overall Steps per Second: 10,839.22905

Timestep Collection Time: 2.17523
Timestep Consumption Time: 2.43893
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.61417

Cumulative Model Updates: 93,154
Cumulative Timesteps: 776,943,070

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 776943070...
Checkpoint 776943070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.24894
Policy Entropy: 3.19836
Value Function Loss: 0.00490

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.56597
Value Function Update Magnitude: 0.65856

Collected Steps per Second: 22,870.84794
Overall Steps per Second: 10,719.03728

Timestep Collection Time: 2.18680
Timestep Consumption Time: 2.47910
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.66590

Cumulative Model Updates: 93,160
Cumulative Timesteps: 776,993,084

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.58857
Policy Entropy: 3.19709
Value Function Loss: 0.00483

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.56704
Value Function Update Magnitude: 0.64957

Collected Steps per Second: 22,143.50550
Overall Steps per Second: 10,491.80278

Timestep Collection Time: 2.25935
Timestep Consumption Time: 2.50913
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.76848

Cumulative Model Updates: 93,166
Cumulative Timesteps: 777,043,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 777043114...
Checkpoint 777043114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.98432
Policy Entropy: 3.21702
Value Function Loss: 0.00460

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07816
Policy Update Magnitude: 0.56834
Value Function Update Magnitude: 0.62428

Collected Steps per Second: 22,081.43664
Overall Steps per Second: 10,595.42184

Timestep Collection Time: 2.26616
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.72279

Cumulative Model Updates: 93,172
Cumulative Timesteps: 777,093,154

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,068.71629
Policy Entropy: 3.20751
Value Function Loss: 0.00431

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.07873
Policy Update Magnitude: 0.55685
Value Function Update Magnitude: 0.60695

Collected Steps per Second: 22,379.80990
Overall Steps per Second: 10,574.12777

Timestep Collection Time: 2.23416
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.72852

Cumulative Model Updates: 93,178
Cumulative Timesteps: 777,143,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 777143154...
Checkpoint 777143154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.96565
Policy Entropy: 3.20476
Value Function Loss: 0.00402

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08411
Policy Update Magnitude: 0.55179
Value Function Update Magnitude: 0.60068

Collected Steps per Second: 22,108.85452
Overall Steps per Second: 10,537.41801

Timestep Collection Time: 2.26163
Timestep Consumption Time: 2.48356
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.74519

Cumulative Model Updates: 93,184
Cumulative Timesteps: 777,193,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.28822
Policy Entropy: 3.20815
Value Function Loss: 0.00418

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08517
Policy Update Magnitude: 0.55554
Value Function Update Magnitude: 0.58005

Collected Steps per Second: 22,770.96301
Overall Steps per Second: 10,794.41835

Timestep Collection Time: 2.19692
Timestep Consumption Time: 2.43751
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.63443

Cumulative Model Updates: 93,190
Cumulative Timesteps: 777,243,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 777243182...
Checkpoint 777243182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.31382
Policy Entropy: 3.20996
Value Function Loss: 0.00425

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.57125

Collected Steps per Second: 22,664.71532
Overall Steps per Second: 10,753.03860

Timestep Collection Time: 2.20695
Timestep Consumption Time: 2.44475
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.65171

Cumulative Model Updates: 93,196
Cumulative Timesteps: 777,293,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.57325
Policy Entropy: 3.19393
Value Function Loss: 0.00444

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.55516
Value Function Update Magnitude: 0.58276

Collected Steps per Second: 22,907.51909
Overall Steps per Second: 10,802.39371

Timestep Collection Time: 2.18339
Timestep Consumption Time: 2.44670
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.63008

Cumulative Model Updates: 93,202
Cumulative Timesteps: 777,343,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 777343218...
Checkpoint 777343218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,037.61749
Policy Entropy: 3.19802
Value Function Loss: 0.00436

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.55617
Value Function Update Magnitude: 0.58176

Collected Steps per Second: 21,579.11521
Overall Steps per Second: 10,403.31434

Timestep Collection Time: 2.31835
Timestep Consumption Time: 2.49050
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 4.80885

Cumulative Model Updates: 93,208
Cumulative Timesteps: 777,393,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.18329
Policy Entropy: 3.19896
Value Function Loss: 0.00421

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.55265
Value Function Update Magnitude: 0.57581

Collected Steps per Second: 23,028.00493
Overall Steps per Second: 10,825.13238

Timestep Collection Time: 2.17196
Timestep Consumption Time: 2.44840
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.62036

Cumulative Model Updates: 93,214
Cumulative Timesteps: 777,443,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 777443262...
Checkpoint 777443262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828.29991
Policy Entropy: 3.20681
Value Function Loss: 0.00432

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.55988
Value Function Update Magnitude: 0.56409

Collected Steps per Second: 22,750.10489
Overall Steps per Second: 10,627.53008

Timestep Collection Time: 2.19806
Timestep Consumption Time: 2.50727
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.70533

Cumulative Model Updates: 93,220
Cumulative Timesteps: 777,493,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.47561
Policy Entropy: 3.20630
Value Function Loss: 0.00429

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.55232
Value Function Update Magnitude: 0.55520

Collected Steps per Second: 22,717.66841
Overall Steps per Second: 10,808.89059

Timestep Collection Time: 2.20190
Timestep Consumption Time: 2.42596
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.62786

Cumulative Model Updates: 93,226
Cumulative Timesteps: 777,543,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 777543290...
Checkpoint 777543290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 716.45827
Policy Entropy: 3.20836
Value Function Loss: 0.00434

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08610
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.56575

Collected Steps per Second: 22,242.65933
Overall Steps per Second: 10,656.69604

Timestep Collection Time: 2.24874
Timestep Consumption Time: 2.44483
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.69357

Cumulative Model Updates: 93,232
Cumulative Timesteps: 777,593,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 663.07183
Policy Entropy: 3.20563
Value Function Loss: 0.00442

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.55806
Value Function Update Magnitude: 0.56721

Collected Steps per Second: 22,330.27353
Overall Steps per Second: 10,528.17975

Timestep Collection Time: 2.23947
Timestep Consumption Time: 2.51045
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.74992

Cumulative Model Updates: 93,238
Cumulative Timesteps: 777,643,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 777643316...
Checkpoint 777643316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.09330
Policy Entropy: 3.20742
Value Function Loss: 0.00460

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.56515
Value Function Update Magnitude: 0.58237

Collected Steps per Second: 22,267.13292
Overall Steps per Second: 10,633.44262

Timestep Collection Time: 2.24564
Timestep Consumption Time: 2.45688
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.70252

Cumulative Model Updates: 93,244
Cumulative Timesteps: 777,693,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.87225
Policy Entropy: 3.20770
Value Function Loss: 0.00464

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.59491

Collected Steps per Second: 22,530.21219
Overall Steps per Second: 10,622.65966

Timestep Collection Time: 2.22013
Timestep Consumption Time: 2.48867
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.70880

Cumulative Model Updates: 93,250
Cumulative Timesteps: 777,743,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 777743340...
Checkpoint 777743340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.76106
Policy Entropy: 3.21358
Value Function Loss: 0.00435

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.55094
Value Function Update Magnitude: 0.56661

Collected Steps per Second: 22,624.29111
Overall Steps per Second: 10,653.79639

Timestep Collection Time: 2.21063
Timestep Consumption Time: 2.48384
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.69448

Cumulative Model Updates: 93,256
Cumulative Timesteps: 777,793,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.04973
Policy Entropy: 3.19964
Value Function Loss: 0.00465

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.55432
Value Function Update Magnitude: 0.55904

Collected Steps per Second: 22,342.87669
Overall Steps per Second: 10,618.31613

Timestep Collection Time: 2.23910
Timestep Consumption Time: 2.47238
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.71148

Cumulative Model Updates: 93,262
Cumulative Timesteps: 777,843,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 777843382...
Checkpoint 777843382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,087.73807
Policy Entropy: 3.20619
Value Function Loss: 0.00447

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08821
Policy Update Magnitude: 0.56032
Value Function Update Magnitude: 0.58288

Collected Steps per Second: 21,956.50689
Overall Steps per Second: 10,360.38913

Timestep Collection Time: 2.27860
Timestep Consumption Time: 2.55037
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.82897

Cumulative Model Updates: 93,268
Cumulative Timesteps: 777,893,412

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.93597
Policy Entropy: 3.19624
Value Function Loss: 0.00442

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10853
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.60160

Collected Steps per Second: 22,874.08380
Overall Steps per Second: 10,776.21299

Timestep Collection Time: 2.18588
Timestep Consumption Time: 2.45397
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.63985

Cumulative Model Updates: 93,274
Cumulative Timesteps: 777,943,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 777943412...
Checkpoint 777943412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.41157
Policy Entropy: 3.19169
Value Function Loss: 0.00439

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.55800
Value Function Update Magnitude: 0.62257

Collected Steps per Second: 22,149.82785
Overall Steps per Second: 10,646.09973

Timestep Collection Time: 2.25871
Timestep Consumption Time: 2.44067
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.69937

Cumulative Model Updates: 93,280
Cumulative Timesteps: 777,993,442

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,049.91388
Policy Entropy: 3.20094
Value Function Loss: 0.00432

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11981
Policy Update Magnitude: 0.56186
Value Function Update Magnitude: 0.63884

Collected Steps per Second: 22,211.19988
Overall Steps per Second: 10,276.98769

Timestep Collection Time: 2.25139
Timestep Consumption Time: 2.61444
PPO Batch Consumption Time: 0.30997
Total Iteration Time: 4.86582

Cumulative Model Updates: 93,286
Cumulative Timesteps: 778,043,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 778043448...
Checkpoint 778043448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.04464
Policy Entropy: 3.20886
Value Function Loss: 0.00430

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10733
Policy Update Magnitude: 0.55694
Value Function Update Magnitude: 0.65694

Collected Steps per Second: 22,226.00149
Overall Steps per Second: 10,480.89628

Timestep Collection Time: 2.25088
Timestep Consumption Time: 2.52238
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.77326

Cumulative Model Updates: 93,292
Cumulative Timesteps: 778,093,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.16596
Policy Entropy: 3.20268
Value Function Loss: 0.00443

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.55637
Value Function Update Magnitude: 0.65202

Collected Steps per Second: 20,858.65328
Overall Steps per Second: 9,231.95250

Timestep Collection Time: 2.39757
Timestep Consumption Time: 3.01949
PPO Batch Consumption Time: 0.35801
Total Iteration Time: 5.41706

Cumulative Model Updates: 93,298
Cumulative Timesteps: 778,143,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 778143486...
Checkpoint 778143486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.35542
Policy Entropy: 3.20929
Value Function Loss: 0.00453

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09189
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.64207

Collected Steps per Second: 11,157.69757
Overall Steps per Second: 6,985.71000

Timestep Collection Time: 4.48247
Timestep Consumption Time: 2.67701
PPO Batch Consumption Time: 0.30697
Total Iteration Time: 7.15947

Cumulative Model Updates: 93,304
Cumulative Timesteps: 778,193,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.35390
Policy Entropy: 3.21992
Value Function Loss: 0.00462

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.57091
Value Function Update Magnitude: 0.65889

Collected Steps per Second: 20,914.33278
Overall Steps per Second: 10,189.60023

Timestep Collection Time: 2.39137
Timestep Consumption Time: 2.51696
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.90834

Cumulative Model Updates: 93,310
Cumulative Timesteps: 778,243,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 778243514...
Checkpoint 778243514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.66728
Policy Entropy: 3.22913
Value Function Loss: 0.00469

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09012
Policy Update Magnitude: 0.57487
Value Function Update Magnitude: 0.66765

Collected Steps per Second: 20,967.24737
Overall Steps per Second: 10,257.97894

Timestep Collection Time: 2.38563
Timestep Consumption Time: 2.49058
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.87620

Cumulative Model Updates: 93,316
Cumulative Timesteps: 778,293,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.71966
Policy Entropy: 3.22716
Value Function Loss: 0.00457

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.57321
Value Function Update Magnitude: 0.65099

Collected Steps per Second: 22,173.40997
Overall Steps per Second: 10,551.94685

Timestep Collection Time: 2.25595
Timestep Consumption Time: 2.48460
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.74055

Cumulative Model Updates: 93,322
Cumulative Timesteps: 778,343,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 778343556...
Checkpoint 778343556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,567.14345
Policy Entropy: 3.22863
Value Function Loss: 0.00453

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.56774
Value Function Update Magnitude: 0.65117

Collected Steps per Second: 22,123.60118
Overall Steps per Second: 10,438.66762

Timestep Collection Time: 2.26057
Timestep Consumption Time: 2.53046
PPO Batch Consumption Time: 0.30094
Total Iteration Time: 4.79103

Cumulative Model Updates: 93,328
Cumulative Timesteps: 778,393,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.48006
Policy Entropy: 3.22800
Value Function Loss: 0.00445

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.56181
Value Function Update Magnitude: 0.63830

Collected Steps per Second: 21,687.68391
Overall Steps per Second: 10,381.67238

Timestep Collection Time: 2.30619
Timestep Consumption Time: 2.51153
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.81772

Cumulative Model Updates: 93,334
Cumulative Timesteps: 778,443,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 778443584...
Checkpoint 778443584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.61376
Policy Entropy: 3.23014
Value Function Loss: 0.00435

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11916
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.62392

Collected Steps per Second: 21,728.79733
Overall Steps per Second: 10,433.91616

Timestep Collection Time: 2.30201
Timestep Consumption Time: 2.49197
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.79398

Cumulative Model Updates: 93,340
Cumulative Timesteps: 778,493,604

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.27724
Policy Entropy: 3.21598
Value Function Loss: 0.00439

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.55405
Value Function Update Magnitude: 0.60768

Collected Steps per Second: 22,267.66541
Overall Steps per Second: 10,601.71496

Timestep Collection Time: 2.24559
Timestep Consumption Time: 2.47101
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.71660

Cumulative Model Updates: 93,346
Cumulative Timesteps: 778,543,608

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 778543608...
Checkpoint 778543608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.06093
Policy Entropy: 3.20298
Value Function Loss: 0.00453

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09098
Policy Update Magnitude: 0.56247
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 20,779.70024
Overall Steps per Second: 10,136.09736

Timestep Collection Time: 2.40745
Timestep Consumption Time: 2.52798
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.93543

Cumulative Model Updates: 93,352
Cumulative Timesteps: 778,593,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.78472
Policy Entropy: 3.19494
Value Function Loss: 0.00431

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.56967
Value Function Update Magnitude: 0.61122

Collected Steps per Second: 22,228.86714
Overall Steps per Second: 10,507.62057

Timestep Collection Time: 2.25068
Timestep Consumption Time: 2.51063
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.76131

Cumulative Model Updates: 93,358
Cumulative Timesteps: 778,643,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 778643664...
Checkpoint 778643664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.84489
Policy Entropy: 3.19550
Value Function Loss: 0.00428

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.56252
Value Function Update Magnitude: 0.61867

Collected Steps per Second: 21,847.42935
Overall Steps per Second: 10,408.63527

Timestep Collection Time: 2.28970
Timestep Consumption Time: 2.51631
PPO Batch Consumption Time: 0.29642
Total Iteration Time: 4.80601

Cumulative Model Updates: 93,364
Cumulative Timesteps: 778,693,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.54515
Policy Entropy: 3.19775
Value Function Loss: 0.00406

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.60623

Collected Steps per Second: 22,003.32136
Overall Steps per Second: 10,395.98291

Timestep Collection Time: 2.27257
Timestep Consumption Time: 2.53737
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.80993

Cumulative Model Updates: 93,370
Cumulative Timesteps: 778,743,692

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 778743692...
Checkpoint 778743692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.29991
Policy Entropy: 3.20177
Value Function Loss: 0.00440

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.56561
Value Function Update Magnitude: 0.60066

Collected Steps per Second: 22,327.76781
Overall Steps per Second: 10,525.25334

Timestep Collection Time: 2.23945
Timestep Consumption Time: 2.51122
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.75067

Cumulative Model Updates: 93,376
Cumulative Timesteps: 778,793,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524.82493
Policy Entropy: 3.21469
Value Function Loss: 0.00449

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.57656
Value Function Update Magnitude: 0.59671

Collected Steps per Second: 21,447.22087
Overall Steps per Second: 10,271.23633

Timestep Collection Time: 2.33205
Timestep Consumption Time: 2.53747
PPO Batch Consumption Time: 0.29777
Total Iteration Time: 4.86952

Cumulative Model Updates: 93,382
Cumulative Timesteps: 778,843,710

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 778843710...
Checkpoint 778843710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.77997
Policy Entropy: 3.21385
Value Function Loss: 0.00462

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.57145
Value Function Update Magnitude: 0.59764

Collected Steps per Second: 21,764.71599
Overall Steps per Second: 10,445.91283

Timestep Collection Time: 2.29877
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.78962

Cumulative Model Updates: 93,388
Cumulative Timesteps: 778,893,742

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.43940
Policy Entropy: 3.20412
Value Function Loss: 0.00462

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.57332
Value Function Update Magnitude: 0.61408

Collected Steps per Second: 21,921.28680
Overall Steps per Second: 10,586.94892

Timestep Collection Time: 2.28089
Timestep Consumption Time: 2.44191
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.72280

Cumulative Model Updates: 93,394
Cumulative Timesteps: 778,943,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 778943742...
Checkpoint 778943742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.79333
Policy Entropy: 3.20932
Value Function Loss: 0.00465

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.13760
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.62303

Collected Steps per Second: 21,822.92096
Overall Steps per Second: 10,360.51355

Timestep Collection Time: 2.29117
Timestep Consumption Time: 2.53485
PPO Batch Consumption Time: 0.29758
Total Iteration Time: 4.82602

Cumulative Model Updates: 93,400
Cumulative Timesteps: 778,993,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 531.58240
Policy Entropy: 3.19861
Value Function Loss: 0.00458

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.57737
Value Function Update Magnitude: 0.62908

Collected Steps per Second: 22,254.71589
Overall Steps per Second: 10,430.25261

Timestep Collection Time: 2.24734
Timestep Consumption Time: 2.54775
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.79509

Cumulative Model Updates: 93,406
Cumulative Timesteps: 779,043,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 779043756...
Checkpoint 779043756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.44722
Policy Entropy: 3.19530
Value Function Loss: 0.00468

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.57540
Value Function Update Magnitude: 0.65076

Collected Steps per Second: 20,778.69037
Overall Steps per Second: 10,232.29281

Timestep Collection Time: 2.40737
Timestep Consumption Time: 2.48127
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.88864

Cumulative Model Updates: 93,412
Cumulative Timesteps: 779,093,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.02284
Policy Entropy: 3.18564
Value Function Loss: 0.00440

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.58340
Value Function Update Magnitude: 0.65548

Collected Steps per Second: 22,293.09497
Overall Steps per Second: 10,491.77616

Timestep Collection Time: 2.24383
Timestep Consumption Time: 2.52390
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.76773

Cumulative Model Updates: 93,418
Cumulative Timesteps: 779,143,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 779143800...
Checkpoint 779143800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917.89799
Policy Entropy: 3.19675
Value Function Loss: 0.00440

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09331
Policy Update Magnitude: 0.57532
Value Function Update Magnitude: 0.63219

Collected Steps per Second: 21,723.21803
Overall Steps per Second: 10,381.31032

Timestep Collection Time: 2.30187
Timestep Consumption Time: 2.51486
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.81673

Cumulative Model Updates: 93,424
Cumulative Timesteps: 779,193,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.25507
Policy Entropy: 3.20652
Value Function Loss: 0.00442

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.08401
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.63030

Collected Steps per Second: 22,342.42305
Overall Steps per Second: 10,580.45045

Timestep Collection Time: 2.23879
Timestep Consumption Time: 2.48880
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.72759

Cumulative Model Updates: 93,430
Cumulative Timesteps: 779,243,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 779243824...
Checkpoint 779243824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.48924
Policy Entropy: 3.21532
Value Function Loss: 0.00478

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.09068
Policy Update Magnitude: 0.57951
Value Function Update Magnitude: 0.63455

Collected Steps per Second: 21,923.78831
Overall Steps per Second: 10,479.05155

Timestep Collection Time: 2.28081
Timestep Consumption Time: 2.49100
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.77181

Cumulative Model Updates: 93,436
Cumulative Timesteps: 779,293,828

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.39638
Policy Entropy: 3.21002
Value Function Loss: 0.00480

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08877
Policy Update Magnitude: 0.59415
Value Function Update Magnitude: 0.63877

Collected Steps per Second: 22,244.37994
Overall Steps per Second: 10,582.81020

Timestep Collection Time: 2.24893
Timestep Consumption Time: 2.47817
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.72710

Cumulative Model Updates: 93,442
Cumulative Timesteps: 779,343,854

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 779343854...
Checkpoint 779343854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.90095
Policy Entropy: 3.19809
Value Function Loss: 0.00468

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.59375
Value Function Update Magnitude: 0.64861

Collected Steps per Second: 21,678.94632
Overall Steps per Second: 10,311.79958

Timestep Collection Time: 2.30712
Timestep Consumption Time: 2.54324
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.85037

Cumulative Model Updates: 93,448
Cumulative Timesteps: 779,393,870

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.02394
Policy Entropy: 3.19763
Value Function Loss: 0.00447

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09924
Policy Update Magnitude: 0.57787
Value Function Update Magnitude: 0.64981

Collected Steps per Second: 22,246.77083
Overall Steps per Second: 10,298.96381

Timestep Collection Time: 2.24806
Timestep Consumption Time: 2.60797
PPO Batch Consumption Time: 0.31009
Total Iteration Time: 4.85602

Cumulative Model Updates: 93,454
Cumulative Timesteps: 779,443,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 779443882...
Checkpoint 779443882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.77393
Policy Entropy: 3.20096
Value Function Loss: 0.00447

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.57587
Value Function Update Magnitude: 0.63913

Collected Steps per Second: 21,281.50585
Overall Steps per Second: 10,275.04054

Timestep Collection Time: 2.35077
Timestep Consumption Time: 2.51811
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.86889

Cumulative Model Updates: 93,460
Cumulative Timesteps: 779,493,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.57287
Policy Entropy: 3.21180
Value Function Loss: 0.00454

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.57519
Value Function Update Magnitude: 0.62389

Collected Steps per Second: 22,447.27325
Overall Steps per Second: 10,493.63876

Timestep Collection Time: 2.22878
Timestep Consumption Time: 2.53887
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.76765

Cumulative Model Updates: 93,466
Cumulative Timesteps: 779,543,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 779543940...
Checkpoint 779543940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.79436
Policy Entropy: 3.22354
Value Function Loss: 0.00440

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10426
Policy Update Magnitude: 0.55768
Value Function Update Magnitude: 0.61930

Collected Steps per Second: 21,243.39966
Overall Steps per Second: 10,270.76326

Timestep Collection Time: 2.35480
Timestep Consumption Time: 2.51572
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.87052

Cumulative Model Updates: 93,472
Cumulative Timesteps: 779,593,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.08358
Policy Entropy: 3.21909
Value Function Loss: 0.00456

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.55639
Value Function Update Magnitude: 0.61646

Collected Steps per Second: 22,358.14318
Overall Steps per Second: 10,466.75089

Timestep Collection Time: 2.23740
Timestep Consumption Time: 2.54193
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.77932

Cumulative Model Updates: 93,478
Cumulative Timesteps: 779,643,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 779643988...
Checkpoint 779643988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.21078
Policy Entropy: 3.19982
Value Function Loss: 0.00488

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09240
Policy Update Magnitude: 0.57807
Value Function Update Magnitude: 0.63819

Collected Steps per Second: 22,207.66445
Overall Steps per Second: 10,395.36957

Timestep Collection Time: 2.25157
Timestep Consumption Time: 2.55846
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.81003

Cumulative Model Updates: 93,484
Cumulative Timesteps: 779,693,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.96847
Policy Entropy: 3.18990
Value Function Loss: 0.00476

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.59166
Value Function Update Magnitude: 0.66239

Collected Steps per Second: 22,253.77060
Overall Steps per Second: 10,528.36478

Timestep Collection Time: 2.24699
Timestep Consumption Time: 2.50247
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.74946

Cumulative Model Updates: 93,490
Cumulative Timesteps: 779,743,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 779743994...
Checkpoint 779743994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.78952
Policy Entropy: 3.19183
Value Function Loss: 0.00442

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11249
Policy Update Magnitude: 0.58254
Value Function Update Magnitude: 0.63942

Collected Steps per Second: 21,395.86042
Overall Steps per Second: 10,352.22208

Timestep Collection Time: 2.33746
Timestep Consumption Time: 2.49358
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.83104

Cumulative Model Updates: 93,496
Cumulative Timesteps: 779,794,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.10155
Policy Entropy: 3.21749
Value Function Loss: 0.00419

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.56491
Value Function Update Magnitude: 0.61627

Collected Steps per Second: 22,345.54011
Overall Steps per Second: 10,523.20094

Timestep Collection Time: 2.23839
Timestep Consumption Time: 2.51473
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.75312

Cumulative Model Updates: 93,502
Cumulative Timesteps: 779,844,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 779844024...
Checkpoint 779844024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.31491
Policy Entropy: 3.21145
Value Function Loss: 0.00426

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.55574
Value Function Update Magnitude: 0.60254

Collected Steps per Second: 21,247.49985
Overall Steps per Second: 10,119.84725

Timestep Collection Time: 2.35341
Timestep Consumption Time: 2.58777
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.94118

Cumulative Model Updates: 93,508
Cumulative Timesteps: 779,894,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.55772
Policy Entropy: 3.21105
Value Function Loss: 0.00429

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.55626
Value Function Update Magnitude: 0.60404

Collected Steps per Second: 22,319.13200
Overall Steps per Second: 10,376.17621

Timestep Collection Time: 2.24131
Timestep Consumption Time: 2.57974
PPO Batch Consumption Time: 0.29815
Total Iteration Time: 4.82104

Cumulative Model Updates: 93,514
Cumulative Timesteps: 779,944,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 779944052...
Checkpoint 779944052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,846.19421
Policy Entropy: 3.19716
Value Function Loss: 0.00444

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10675
Policy Update Magnitude: 0.55644
Value Function Update Magnitude: 0.57711

Collected Steps per Second: 21,661.24717
Overall Steps per Second: 10,494.21812

Timestep Collection Time: 2.30864
Timestep Consumption Time: 2.45665
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.76529

Cumulative Model Updates: 93,520
Cumulative Timesteps: 779,994,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.70145
Policy Entropy: 3.19105
Value Function Loss: 0.00461

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.56253
Value Function Update Magnitude: 0.58673

Collected Steps per Second: 22,128.01798
Overall Steps per Second: 10,479.01140

Timestep Collection Time: 2.26057
Timestep Consumption Time: 2.51297
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.77354

Cumulative Model Updates: 93,526
Cumulative Timesteps: 780,044,082

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 780044082...
Checkpoint 780044082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.46619
Policy Entropy: 3.19914
Value Function Loss: 0.00434

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08687
Policy Update Magnitude: 0.56443
Value Function Update Magnitude: 0.59271

Collected Steps per Second: 21,649.46392
Overall Steps per Second: 10,331.80306

Timestep Collection Time: 2.31054
Timestep Consumption Time: 2.53101
PPO Batch Consumption Time: 0.29925
Total Iteration Time: 4.84156

Cumulative Model Updates: 93,532
Cumulative Timesteps: 780,094,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.62079
Policy Entropy: 3.19870
Value Function Loss: 0.00426

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.55396
Value Function Update Magnitude: 0.58234

Collected Steps per Second: 21,612.31818
Overall Steps per Second: 10,311.61421

Timestep Collection Time: 2.31359
Timestep Consumption Time: 2.53551
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.84910

Cumulative Model Updates: 93,538
Cumulative Timesteps: 780,144,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 780144106...
Checkpoint 780144106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.46462
Policy Entropy: 3.20199
Value Function Loss: 0.00429

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.08217
Policy Update Magnitude: 0.55647
Value Function Update Magnitude: 0.58038

Collected Steps per Second: 21,643.29122
Overall Steps per Second: 10,363.32968

Timestep Collection Time: 2.31157
Timestep Consumption Time: 2.51603
PPO Batch Consumption Time: 0.29357
Total Iteration Time: 4.82760

Cumulative Model Updates: 93,544
Cumulative Timesteps: 780,194,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.72512
Policy Entropy: 3.21167
Value Function Loss: 0.00461

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09190
Policy Update Magnitude: 0.56900
Value Function Update Magnitude: 0.59609

Collected Steps per Second: 21,890.70549
Overall Steps per Second: 10,462.79101

Timestep Collection Time: 2.28407
Timestep Consumption Time: 2.49477
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.77884

Cumulative Model Updates: 93,550
Cumulative Timesteps: 780,244,136

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 780244136...
Checkpoint 780244136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.21632
Policy Entropy: 3.19348
Value Function Loss: 0.00474

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.58070
Value Function Update Magnitude: 0.61311

Collected Steps per Second: 21,878.46158
Overall Steps per Second: 10,404.59450

Timestep Collection Time: 2.28572
Timestep Consumption Time: 2.52062
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.80634

Cumulative Model Updates: 93,556
Cumulative Timesteps: 780,294,144

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.71346
Policy Entropy: 3.21246
Value Function Loss: 0.00439

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.57988
Value Function Update Magnitude: 0.61388

Collected Steps per Second: 22,488.40902
Overall Steps per Second: 10,483.13059

Timestep Collection Time: 2.22337
Timestep Consumption Time: 2.54620
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.76957

Cumulative Model Updates: 93,562
Cumulative Timesteps: 780,344,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 780344144...
Checkpoint 780344144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.76471
Policy Entropy: 3.20854
Value Function Loss: 0.00422

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.56519
Value Function Update Magnitude: 0.59843

Collected Steps per Second: 20,870.61956
Overall Steps per Second: 10,310.49622

Timestep Collection Time: 2.39705
Timestep Consumption Time: 2.45509
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.85214

Cumulative Model Updates: 93,568
Cumulative Timesteps: 780,394,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.39373
Policy Entropy: 3.21115
Value Function Loss: 0.00409

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08779
Policy Update Magnitude: 0.55539
Value Function Update Magnitude: 0.58086

Collected Steps per Second: 22,110.12042
Overall Steps per Second: 10,452.70295

Timestep Collection Time: 2.26276
Timestep Consumption Time: 2.52356
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.78632

Cumulative Model Updates: 93,574
Cumulative Timesteps: 780,444,202

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 780444202...
Checkpoint 780444202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 890.87938
Policy Entropy: 3.18646
Value Function Loss: 0.00408

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 0.55720
Value Function Update Magnitude: 0.57278

Collected Steps per Second: 20,788.35426
Overall Steps per Second: 10,043.42899

Timestep Collection Time: 2.40519
Timestep Consumption Time: 2.57319
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 4.97838

Cumulative Model Updates: 93,580
Cumulative Timesteps: 780,494,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.51528
Policy Entropy: 3.17132
Value Function Loss: 0.00434

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.56292
Value Function Update Magnitude: 0.57504

Collected Steps per Second: 22,275.02631
Overall Steps per Second: 10,441.00297

Timestep Collection Time: 2.24574
Timestep Consumption Time: 2.54537
PPO Batch Consumption Time: 0.29893
Total Iteration Time: 4.79111

Cumulative Model Updates: 93,586
Cumulative Timesteps: 780,544,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 780544226...
Checkpoint 780544226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.04365
Policy Entropy: 3.19035
Value Function Loss: 0.00419

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.58387

Collected Steps per Second: 20,816.87380
Overall Steps per Second: 10,029.01756

Timestep Collection Time: 2.40324
Timestep Consumption Time: 2.58508
PPO Batch Consumption Time: 0.30272
Total Iteration Time: 4.98833

Cumulative Model Updates: 93,592
Cumulative Timesteps: 780,594,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.52600
Policy Entropy: 3.20265
Value Function Loss: 0.00449

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.57625
Value Function Update Magnitude: 0.60498

Collected Steps per Second: 22,130.61104
Overall Steps per Second: 10,479.41128

Timestep Collection Time: 2.26040
Timestep Consumption Time: 2.51315
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.77355

Cumulative Model Updates: 93,598
Cumulative Timesteps: 780,644,278

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 780644278...
Checkpoint 780644278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.12280
Policy Entropy: 3.20921
Value Function Loss: 0.00457

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.58472
Value Function Update Magnitude: 0.63459

Collected Steps per Second: 21,943.94960
Overall Steps per Second: 10,409.65023

Timestep Collection Time: 2.27899
Timestep Consumption Time: 2.52521
PPO Batch Consumption Time: 0.29370
Total Iteration Time: 4.80420

Cumulative Model Updates: 93,604
Cumulative Timesteps: 780,694,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.19730
Policy Entropy: 3.20850
Value Function Loss: 0.00471

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.58722
Value Function Update Magnitude: 0.66380

Collected Steps per Second: 22,085.13621
Overall Steps per Second: 10,388.01823

Timestep Collection Time: 2.26487
Timestep Consumption Time: 2.55029
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.81516

Cumulative Model Updates: 93,610
Cumulative Timesteps: 780,744,308

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 780744308...
Checkpoint 780744308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.41260
Policy Entropy: 3.21189
Value Function Loss: 0.00478

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.59021
Value Function Update Magnitude: 0.67931

Collected Steps per Second: 21,511.40907
Overall Steps per Second: 10,397.73454

Timestep Collection Time: 2.32602
Timestep Consumption Time: 2.48618
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.81220

Cumulative Model Updates: 93,616
Cumulative Timesteps: 780,794,344

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.20573
Policy Entropy: 3.21350
Value Function Loss: 0.00462

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.59528
Value Function Update Magnitude: 0.68394

Collected Steps per Second: 22,466.67685
Overall Steps per Second: 10,626.95778

Timestep Collection Time: 2.22561
Timestep Consumption Time: 2.47960
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.70520

Cumulative Model Updates: 93,622
Cumulative Timesteps: 780,844,346

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 780844346...
Checkpoint 780844346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.58817
Policy Entropy: 3.20230
Value Function Loss: 0.00449

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.59594
Value Function Update Magnitude: 0.67592

Collected Steps per Second: 21,828.20349
Overall Steps per Second: 10,326.98413

Timestep Collection Time: 2.29089
Timestep Consumption Time: 2.55138
PPO Batch Consumption Time: 0.29850
Total Iteration Time: 4.84227

Cumulative Model Updates: 93,628
Cumulative Timesteps: 780,894,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.05623
Policy Entropy: 3.19359
Value Function Loss: 0.00436

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.58663
Value Function Update Magnitude: 0.64740

Collected Steps per Second: 22,066.08390
Overall Steps per Second: 10,511.16083

Timestep Collection Time: 2.26674
Timestep Consumption Time: 2.49182
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.75856

Cumulative Model Updates: 93,634
Cumulative Timesteps: 780,944,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 780944370...
Checkpoint 780944370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.96919
Policy Entropy: 3.18555
Value Function Loss: 0.00432

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.57671
Value Function Update Magnitude: 0.62539

Collected Steps per Second: 22,250.70276
Overall Steps per Second: 10,498.30028

Timestep Collection Time: 2.24793
Timestep Consumption Time: 2.51646
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.76439

Cumulative Model Updates: 93,640
Cumulative Timesteps: 780,994,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.03583
Policy Entropy: 3.17091
Value Function Loss: 0.00411

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.56664
Value Function Update Magnitude: 0.60270

Collected Steps per Second: 21,975.58641
Overall Steps per Second: 10,449.72405

Timestep Collection Time: 2.27580
Timestep Consumption Time: 2.51017
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.78596

Cumulative Model Updates: 93,646
Cumulative Timesteps: 781,044,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 781044400...
Checkpoint 781044400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.65424
Policy Entropy: 3.16636
Value Function Loss: 0.00426

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08747
Policy Update Magnitude: 0.56595
Value Function Update Magnitude: 0.59829

Collected Steps per Second: 21,685.96196
Overall Steps per Second: 10,371.72744

Timestep Collection Time: 2.30702
Timestep Consumption Time: 2.51667
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.82369

Cumulative Model Updates: 93,652
Cumulative Timesteps: 781,094,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.66353
Policy Entropy: 3.16215
Value Function Loss: 0.00465

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.57891
Value Function Update Magnitude: 0.59887

Collected Steps per Second: 22,037.17473
Overall Steps per Second: 10,464.33362

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.51035
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.78024

Cumulative Model Updates: 93,658
Cumulative Timesteps: 781,144,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 781144452...
Checkpoint 781144452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 913.10803
Policy Entropy: 3.14539
Value Function Loss: 0.00475

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11800
Policy Update Magnitude: 0.58519
Value Function Update Magnitude: 0.61438

Collected Steps per Second: 22,150.27352
Overall Steps per Second: 10,581.50576

Timestep Collection Time: 2.25812
Timestep Consumption Time: 2.46881
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.72693

Cumulative Model Updates: 93,664
Cumulative Timesteps: 781,194,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.45305
Policy Entropy: 3.14930
Value Function Loss: 0.00440

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.61508

Collected Steps per Second: 21,581.37916
Overall Steps per Second: 10,377.06519

Timestep Collection Time: 2.31709
Timestep Consumption Time: 2.50181
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.81890

Cumulative Model Updates: 93,670
Cumulative Timesteps: 781,244,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 781244476...
Checkpoint 781244476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.04507
Policy Entropy: 3.15911
Value Function Loss: 0.00407

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.12035
Policy Update Magnitude: 0.56580
Value Function Update Magnitude: 0.59966

Collected Steps per Second: 21,190.47414
Overall Steps per Second: 10,267.98876

Timestep Collection Time: 2.36002
Timestep Consumption Time: 2.51045
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.87048

Cumulative Model Updates: 93,676
Cumulative Timesteps: 781,294,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.68352
Policy Entropy: 3.17236
Value Function Loss: 0.00440

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.56782
Value Function Update Magnitude: 0.60399

Collected Steps per Second: 22,019.55328
Overall Steps per Second: 10,477.15214

Timestep Collection Time: 2.27071
Timestep Consumption Time: 2.50158
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.77229

Cumulative Model Updates: 93,682
Cumulative Timesteps: 781,344,486

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 781344486...
Checkpoint 781344486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.07863
Policy Entropy: 3.17245
Value Function Loss: 0.00450

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.57883
Value Function Update Magnitude: 0.62715

Collected Steps per Second: 22,119.04892
Overall Steps per Second: 10,428.65073

Timestep Collection Time: 2.26176
Timestep Consumption Time: 2.53541
PPO Batch Consumption Time: 0.29931
Total Iteration Time: 4.79717

Cumulative Model Updates: 93,688
Cumulative Timesteps: 781,394,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.25101
Policy Entropy: 3.17792
Value Function Loss: 0.00474

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.58037
Value Function Update Magnitude: 0.63237

Collected Steps per Second: 21,775.79506
Overall Steps per Second: 10,471.75918

Timestep Collection Time: 2.29732
Timestep Consumption Time: 2.47991
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.77723

Cumulative Model Updates: 93,694
Cumulative Timesteps: 781,444,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 781444540...
Checkpoint 781444540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.60923
Policy Entropy: 3.17192
Value Function Loss: 0.00449

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.58618
Value Function Update Magnitude: 0.62945

Collected Steps per Second: 21,512.28712
Overall Steps per Second: 10,373.94806

Timestep Collection Time: 2.32518
Timestep Consumption Time: 2.49651
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.82169

Cumulative Model Updates: 93,700
Cumulative Timesteps: 781,494,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.95603
Policy Entropy: 3.17864
Value Function Loss: 0.00461

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.58226
Value Function Update Magnitude: 0.60780

Collected Steps per Second: 21,792.00169
Overall Steps per Second: 10,509.94303

Timestep Collection Time: 2.29479
Timestep Consumption Time: 2.46337
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.75816

Cumulative Model Updates: 93,706
Cumulative Timesteps: 781,544,568

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 781544568...
Checkpoint 781544568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.47231
Policy Entropy: 3.16835
Value Function Loss: 0.00453

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.57910
Value Function Update Magnitude: 0.59363

Collected Steps per Second: 21,908.15348
Overall Steps per Second: 10,413.94245

Timestep Collection Time: 2.28344
Timestep Consumption Time: 2.52031
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.80375

Cumulative Model Updates: 93,712
Cumulative Timesteps: 781,594,594

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.80332
Policy Entropy: 3.17733
Value Function Loss: 0.00482

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.57957
Value Function Update Magnitude: 0.60395

Collected Steps per Second: 22,448.24337
Overall Steps per Second: 10,473.90900

Timestep Collection Time: 2.22841
Timestep Consumption Time: 2.54764
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.77606

Cumulative Model Updates: 93,718
Cumulative Timesteps: 781,644,618

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 781644618...
Checkpoint 781644618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.46648
Policy Entropy: 3.16384
Value Function Loss: 0.00476

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.58426
Value Function Update Magnitude: 0.60955

Collected Steps per Second: 21,611.26098
Overall Steps per Second: 10,325.79545

Timestep Collection Time: 2.31416
Timestep Consumption Time: 2.52924
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.84340

Cumulative Model Updates: 93,724
Cumulative Timesteps: 781,694,630

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.07927
Policy Entropy: 3.17146
Value Function Loss: 0.00480

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.59070
Value Function Update Magnitude: 0.61942

Collected Steps per Second: 21,964.86807
Overall Steps per Second: 10,379.64585

Timestep Collection Time: 2.27718
Timestep Consumption Time: 2.54167
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.81885

Cumulative Model Updates: 93,730
Cumulative Timesteps: 781,744,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 781744648...
Checkpoint 781744648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.87082
Policy Entropy: 3.15426
Value Function Loss: 0.00455

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10274
Policy Update Magnitude: 0.59339
Value Function Update Magnitude: 0.65028

Collected Steps per Second: 21,242.28147
Overall Steps per Second: 10,213.58226

Timestep Collection Time: 2.35464
Timestep Consumption Time: 2.54256
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.89720

Cumulative Model Updates: 93,736
Cumulative Timesteps: 781,794,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.46675
Policy Entropy: 3.15267
Value Function Loss: 0.00447

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.58080
Value Function Update Magnitude: 0.64230

Collected Steps per Second: 22,050.19275
Overall Steps per Second: 10,443.33921

Timestep Collection Time: 2.26864
Timestep Consumption Time: 2.52140
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.79004

Cumulative Model Updates: 93,742
Cumulative Timesteps: 781,844,690

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 781844690...
Checkpoint 781844690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 802.77265
Policy Entropy: 3.15693
Value Function Loss: 0.00436

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.57842
Value Function Update Magnitude: 0.61338

Collected Steps per Second: 21,797.81217
Overall Steps per Second: 10,433.42068

Timestep Collection Time: 2.29436
Timestep Consumption Time: 2.49908
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.79344

Cumulative Model Updates: 93,748
Cumulative Timesteps: 781,894,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.61158
Policy Entropy: 3.15580
Value Function Loss: 0.00438

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.57823
Value Function Update Magnitude: 0.60410

Collected Steps per Second: 21,503.26873
Overall Steps per Second: 10,583.74631

Timestep Collection Time: 2.32644
Timestep Consumption Time: 2.40024
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.72668

Cumulative Model Updates: 93,754
Cumulative Timesteps: 781,944,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 781944728...
Checkpoint 781944728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703.33599
Policy Entropy: 3.14709
Value Function Loss: 0.00442

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08856
Policy Update Magnitude: 0.58008
Value Function Update Magnitude: 0.59865

Collected Steps per Second: 21,125.91943
Overall Steps per Second: 10,277.17513

Timestep Collection Time: 2.36771
Timestep Consumption Time: 2.49939
PPO Batch Consumption Time: 0.29862
Total Iteration Time: 4.86710

Cumulative Model Updates: 93,760
Cumulative Timesteps: 781,994,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.12032
Policy Entropy: 3.15846
Value Function Loss: 0.00456

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.57871
Value Function Update Magnitude: 0.59943

Collected Steps per Second: 21,493.84039
Overall Steps per Second: 10,238.24210

Timestep Collection Time: 2.32690
Timestep Consumption Time: 2.55812
PPO Batch Consumption Time: 0.30766
Total Iteration Time: 4.88502

Cumulative Model Updates: 93,766
Cumulative Timesteps: 782,044,762

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 782044762...
Checkpoint 782044762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.11476
Policy Entropy: 3.15698
Value Function Loss: 0.00476

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.57477
Value Function Update Magnitude: 0.61887

Collected Steps per Second: 20,206.01393
Overall Steps per Second: 10,099.36310

Timestep Collection Time: 2.47560
Timestep Consumption Time: 2.47739
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.95299

Cumulative Model Updates: 93,772
Cumulative Timesteps: 782,094,784

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.37702
Policy Entropy: 3.16984
Value Function Loss: 0.00481

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.58500
Value Function Update Magnitude: 0.61773

Collected Steps per Second: 21,514.78119
Overall Steps per Second: 10,422.06899

Timestep Collection Time: 2.32436
Timestep Consumption Time: 2.47392
PPO Batch Consumption Time: 0.29776
Total Iteration Time: 4.79828

Cumulative Model Updates: 93,778
Cumulative Timesteps: 782,144,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 782144792...
Checkpoint 782144792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.86185
Policy Entropy: 3.16747
Value Function Loss: 0.00459

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.58625
Value Function Update Magnitude: 0.62075

Collected Steps per Second: 21,457.81135
Overall Steps per Second: 10,447.20579

Timestep Collection Time: 2.33062
Timestep Consumption Time: 2.45631
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.78693

Cumulative Model Updates: 93,784
Cumulative Timesteps: 782,194,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.04963
Policy Entropy: 3.17123
Value Function Loss: 0.00452

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.58103
Value Function Update Magnitude: 0.63404

Collected Steps per Second: 21,917.05415
Overall Steps per Second: 10,622.37477

Timestep Collection Time: 2.28169
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.70780

Cumulative Model Updates: 93,790
Cumulative Timesteps: 782,244,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 782244810...
Checkpoint 782244810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.45797
Policy Entropy: 3.16999
Value Function Loss: 0.00459

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10121
Policy Update Magnitude: 0.57554
Value Function Update Magnitude: 0.62470

Collected Steps per Second: 20,705.65330
Overall Steps per Second: 10,315.03682

Timestep Collection Time: 2.41528
Timestep Consumption Time: 2.43298
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.84826

Cumulative Model Updates: 93,796
Cumulative Timesteps: 782,294,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.92884
Policy Entropy: 3.16155
Value Function Loss: 0.00437

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.58004
Value Function Update Magnitude: 0.62891

Collected Steps per Second: 21,434.79617
Overall Steps per Second: 10,563.82405

Timestep Collection Time: 2.33378
Timestep Consumption Time: 2.40163
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.73541

Cumulative Model Updates: 93,802
Cumulative Timesteps: 782,344,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 782344844...
Checkpoint 782344844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.51354
Policy Entropy: 3.15351
Value Function Loss: 0.00420

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.57913
Value Function Update Magnitude: 0.61428

Collected Steps per Second: 21,153.68515
Overall Steps per Second: 10,284.98386

Timestep Collection Time: 2.36375
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.30123
Total Iteration Time: 4.86165

Cumulative Model Updates: 93,808
Cumulative Timesteps: 782,394,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.95566
Policy Entropy: 3.16078
Value Function Loss: 0.00442

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.58111

Collected Steps per Second: 21,575.07446
Overall Steps per Second: 10,414.06408

Timestep Collection Time: 2.31851
Timestep Consumption Time: 2.48480
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.80331

Cumulative Model Updates: 93,814
Cumulative Timesteps: 782,444,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 782444868...
Checkpoint 782444868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.17800
Policy Entropy: 3.17406
Value Function Loss: 0.00467

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.57539
Value Function Update Magnitude: 0.56670

Collected Steps per Second: 21,755.22953
Overall Steps per Second: 10,249.80492

Timestep Collection Time: 2.29894
Timestep Consumption Time: 2.58057
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.87951

Cumulative Model Updates: 93,820
Cumulative Timesteps: 782,494,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.89860
Policy Entropy: 3.15897
Value Function Loss: 0.00476

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.57967
Value Function Update Magnitude: 0.57797

Collected Steps per Second: 22,520.02187
Overall Steps per Second: 10,478.55013

Timestep Collection Time: 2.22105
Timestep Consumption Time: 2.55232
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.77337

Cumulative Model Updates: 93,826
Cumulative Timesteps: 782,544,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 782544900...
Checkpoint 782544900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.85766
Policy Entropy: 3.15207
Value Function Loss: 0.00474

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.58575

Collected Steps per Second: 21,983.85497
Overall Steps per Second: 10,377.10072

Timestep Collection Time: 2.27467
Timestep Consumption Time: 2.54421
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.81888

Cumulative Model Updates: 93,832
Cumulative Timesteps: 782,594,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.38587
Policy Entropy: 3.12892
Value Function Loss: 0.00475

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.58671
Value Function Update Magnitude: 0.59596

Collected Steps per Second: 22,373.76472
Overall Steps per Second: 10,403.22795

Timestep Collection Time: 2.23521
Timestep Consumption Time: 2.57195
PPO Batch Consumption Time: 0.29991
Total Iteration Time: 4.80716

Cumulative Model Updates: 93,838
Cumulative Timesteps: 782,644,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 782644916...
Checkpoint 782644916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 604.53236
Policy Entropy: 3.14242
Value Function Loss: 0.00499

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.59437
Value Function Update Magnitude: 0.59161

Collected Steps per Second: 21,400.59106
Overall Steps per Second: 10,222.13564

Timestep Collection Time: 2.33694
Timestep Consumption Time: 2.55557
PPO Batch Consumption Time: 0.29855
Total Iteration Time: 4.89252

Cumulative Model Updates: 93,844
Cumulative Timesteps: 782,694,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 843.43788
Policy Entropy: 3.12536
Value Function Loss: 0.00499

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10651
Policy Update Magnitude: 0.60253
Value Function Update Magnitude: 0.62553

Collected Steps per Second: 22,371.64482
Overall Steps per Second: 10,405.06053

Timestep Collection Time: 2.23578
Timestep Consumption Time: 2.57131
PPO Batch Consumption Time: 0.29889
Total Iteration Time: 4.80708

Cumulative Model Updates: 93,850
Cumulative Timesteps: 782,744,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 782744946...
Checkpoint 782744946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.47669
Policy Entropy: 3.13349
Value Function Loss: 0.00520

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10729
Policy Update Magnitude: 0.59988
Value Function Update Magnitude: 0.65059

Collected Steps per Second: 22,378.18943
Overall Steps per Second: 10,609.66334

Timestep Collection Time: 2.23459
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.71325

Cumulative Model Updates: 93,856
Cumulative Timesteps: 782,794,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.17898
Policy Entropy: 3.11938
Value Function Loss: 0.00496

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11312
Policy Update Magnitude: 0.60182
Value Function Update Magnitude: 0.66756

Collected Steps per Second: 21,901.98644
Overall Steps per Second: 10,479.75354

Timestep Collection Time: 2.28317
Timestep Consumption Time: 2.48851
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.77168

Cumulative Model Updates: 93,862
Cumulative Timesteps: 782,844,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 782844958...
Checkpoint 782844958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 899.35367
Policy Entropy: 3.11152
Value Function Loss: 0.00496

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.59607
Value Function Update Magnitude: 0.64700

Collected Steps per Second: 21,742.41288
Overall Steps per Second: 10,273.07691

Timestep Collection Time: 2.30011
Timestep Consumption Time: 2.56795
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.86806

Cumulative Model Updates: 93,868
Cumulative Timesteps: 782,894,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563.23895
Policy Entropy: 3.10971
Value Function Loss: 0.00491

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09660
Policy Update Magnitude: 0.59988
Value Function Update Magnitude: 0.63025

Collected Steps per Second: 22,395.16731
Overall Steps per Second: 10,523.11444

Timestep Collection Time: 2.23379
Timestep Consumption Time: 2.52013
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.75392

Cumulative Model Updates: 93,874
Cumulative Timesteps: 782,944,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 782944994...
Checkpoint 782944994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.26026
Policy Entropy: 3.10998
Value Function Loss: 0.00489

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.60208
Value Function Update Magnitude: 0.64172

Collected Steps per Second: 22,044.45557
Overall Steps per Second: 10,361.04499

Timestep Collection Time: 2.26914
Timestep Consumption Time: 2.55875
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.82789

Cumulative Model Updates: 93,880
Cumulative Timesteps: 782,995,016

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473.39952
Policy Entropy: 3.11852
Value Function Loss: 0.00479

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.60340
Value Function Update Magnitude: 0.64507

Collected Steps per Second: 22,691.70018
Overall Steps per Second: 10,488.38663

Timestep Collection Time: 2.20433
Timestep Consumption Time: 2.56475
PPO Batch Consumption Time: 0.29751
Total Iteration Time: 4.76908

Cumulative Model Updates: 93,886
Cumulative Timesteps: 783,045,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 783045036...
Checkpoint 783045036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.16657
Policy Entropy: 3.14055
Value Function Loss: 0.00479

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.60038
Value Function Update Magnitude: 0.64050

Collected Steps per Second: 21,816.15355
Overall Steps per Second: 10,286.10415

Timestep Collection Time: 2.29197
Timestep Consumption Time: 2.56915
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.86112

Cumulative Model Updates: 93,892
Cumulative Timesteps: 783,095,038

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.16249
Policy Entropy: 3.14592
Value Function Loss: 0.00458

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.59522
Value Function Update Magnitude: 0.63890

Collected Steps per Second: 21,937.28633
Overall Steps per Second: 10,435.95036

Timestep Collection Time: 2.28005
Timestep Consumption Time: 2.51281
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.79286

Cumulative Model Updates: 93,898
Cumulative Timesteps: 783,145,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 783145056...
Checkpoint 783145056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.77443
Policy Entropy: 3.14874
Value Function Loss: 0.00460

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.59184
Value Function Update Magnitude: 0.63157

Collected Steps per Second: 22,219.34021
Overall Steps per Second: 10,543.20040

Timestep Collection Time: 2.25074
Timestep Consumption Time: 2.49260
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.74334

Cumulative Model Updates: 93,904
Cumulative Timesteps: 783,195,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.54908
Policy Entropy: 3.12883
Value Function Loss: 0.00485

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10701
Policy Update Magnitude: 0.59560
Value Function Update Magnitude: 0.64235

Collected Steps per Second: 22,282.20115
Overall Steps per Second: 10,541.31279

Timestep Collection Time: 2.24475
Timestep Consumption Time: 2.50020
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.74495

Cumulative Model Updates: 93,910
Cumulative Timesteps: 783,245,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 783245084...
Checkpoint 783245084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.57464
Policy Entropy: 3.12891
Value Function Loss: 0.00499

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.60006
Value Function Update Magnitude: 0.64886

Collected Steps per Second: 22,066.13488
Overall Steps per Second: 10,380.46780

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.55184
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.81867

Cumulative Model Updates: 93,916
Cumulative Timesteps: 783,295,104

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.34441
Policy Entropy: 3.13637
Value Function Loss: 0.00477

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.59658
Value Function Update Magnitude: 0.64166

Collected Steps per Second: 21,826.50920
Overall Steps per Second: 10,477.56504

Timestep Collection Time: 2.29098
Timestep Consumption Time: 2.48151
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.77248

Cumulative Model Updates: 93,922
Cumulative Timesteps: 783,345,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 783345108...
Checkpoint 783345108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.49106
Policy Entropy: 3.12811
Value Function Loss: 0.00490

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12088
Policy Update Magnitude: 0.59187
Value Function Update Magnitude: 0.61039

Collected Steps per Second: 22,146.37278
Overall Steps per Second: 10,480.60390

Timestep Collection Time: 2.25816
Timestep Consumption Time: 2.51351
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.77167

Cumulative Model Updates: 93,928
Cumulative Timesteps: 783,395,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.69404
Policy Entropy: 3.14114
Value Function Loss: 0.00489

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11103
Policy Update Magnitude: 0.59818
Value Function Update Magnitude: 0.62118

Collected Steps per Second: 22,288.93348
Overall Steps per Second: 10,444.34960

Timestep Collection Time: 2.24443
Timestep Consumption Time: 2.54533
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.78977

Cumulative Model Updates: 93,934
Cumulative Timesteps: 783,445,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 783445144...
Checkpoint 783445144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.25090
Policy Entropy: 3.12614
Value Function Loss: 0.00494

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.60346
Value Function Update Magnitude: 0.62912

Collected Steps per Second: 21,818.02070
Overall Steps per Second: 10,310.92350

Timestep Collection Time: 2.29306
Timestep Consumption Time: 2.55908
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.85214

Cumulative Model Updates: 93,940
Cumulative Timesteps: 783,495,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.97530
Policy Entropy: 3.14820
Value Function Loss: 0.00488

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.59939
Value Function Update Magnitude: 0.62915

Collected Steps per Second: 22,331.29642
Overall Steps per Second: 10,361.96226

Timestep Collection Time: 2.23919
Timestep Consumption Time: 2.58654
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.82573

Cumulative Model Updates: 93,946
Cumulative Timesteps: 783,545,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 783545178...
Checkpoint 783545178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728.46940
Policy Entropy: 3.14388
Value Function Loss: 0.00470

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.59155
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 21,808.31659
Overall Steps per Second: 10,280.41836

Timestep Collection Time: 2.29353
Timestep Consumption Time: 2.57184
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.86537

Cumulative Model Updates: 93,952
Cumulative Timesteps: 783,595,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 716.88761
Policy Entropy: 3.14150
Value Function Loss: 0.00480

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11113
Policy Update Magnitude: 0.59326
Value Function Update Magnitude: 0.63647

Collected Steps per Second: 21,985.65819
Overall Steps per Second: 10,437.15616

Timestep Collection Time: 2.27430
Timestep Consumption Time: 2.51647
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.79077

Cumulative Model Updates: 93,958
Cumulative Timesteps: 783,645,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 783645198...
Checkpoint 783645198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.13160
Policy Entropy: 3.13423
Value Function Loss: 0.00476

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11110
Policy Update Magnitude: 0.59013
Value Function Update Magnitude: 0.63583

Collected Steps per Second: 19,855.46808
Overall Steps per Second: 9,960.65819

Timestep Collection Time: 2.51820
Timestep Consumption Time: 2.50155
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 5.01975

Cumulative Model Updates: 93,964
Cumulative Timesteps: 783,695,198

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.30269
Policy Entropy: 3.13335
Value Function Loss: 0.00465

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12492
Policy Update Magnitude: 0.58942
Value Function Update Magnitude: 0.63508

Collected Steps per Second: 21,986.66270
Overall Steps per Second: 10,512.12393

Timestep Collection Time: 2.27520
Timestep Consumption Time: 2.48350
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.75870

Cumulative Model Updates: 93,970
Cumulative Timesteps: 783,745,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 783745222...
Checkpoint 783745222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.40460
Policy Entropy: 3.14276
Value Function Loss: 0.00474

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10670
Policy Update Magnitude: 0.57688
Value Function Update Magnitude: 0.63574

Collected Steps per Second: 21,838.61681
Overall Steps per Second: 10,478.05816

Timestep Collection Time: 2.29044
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.77379

Cumulative Model Updates: 93,976
Cumulative Timesteps: 783,795,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.66796
Policy Entropy: 3.13817
Value Function Loss: 0.00464

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.58559
Value Function Update Magnitude: 0.63093

Collected Steps per Second: 22,232.25635
Overall Steps per Second: 10,530.25930

Timestep Collection Time: 2.24943
Timestep Consumption Time: 2.49974
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.74917

Cumulative Model Updates: 93,982
Cumulative Timesteps: 783,845,252

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 783845252...
Checkpoint 783845252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.79551
Policy Entropy: 3.13987
Value Function Loss: 0.00459

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.58347
Value Function Update Magnitude: 0.61912

Collected Steps per Second: 22,117.73634
Overall Steps per Second: 10,479.78744

Timestep Collection Time: 2.26180
Timestep Consumption Time: 2.51177
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.77357

Cumulative Model Updates: 93,988
Cumulative Timesteps: 783,895,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 905.06631
Policy Entropy: 3.14867
Value Function Loss: 0.00454

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.58125
Value Function Update Magnitude: 0.62953

Collected Steps per Second: 22,002.99491
Overall Steps per Second: 10,330.06834

Timestep Collection Time: 2.27305
Timestep Consumption Time: 2.56854
PPO Batch Consumption Time: 0.30288
Total Iteration Time: 4.84159

Cumulative Model Updates: 93,994
Cumulative Timesteps: 783,945,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 783945292...
Checkpoint 783945292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.42690
Policy Entropy: 3.16611
Value Function Loss: 0.00429

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.57607
Value Function Update Magnitude: 0.62133

Collected Steps per Second: 22,221.24188
Overall Steps per Second: 10,632.46433

Timestep Collection Time: 2.25091
Timestep Consumption Time: 2.45336
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.70427

Cumulative Model Updates: 94,000
Cumulative Timesteps: 783,995,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.27050
Policy Entropy: 3.15806
Value Function Loss: 0.00416

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.60288

Collected Steps per Second: 21,861.15369
Overall Steps per Second: 10,458.77500

Timestep Collection Time: 2.28716
Timestep Consumption Time: 2.49351
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.78067

Cumulative Model Updates: 94,006
Cumulative Timesteps: 784,045,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 784045310...
Checkpoint 784045310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.34468
Policy Entropy: 3.14736
Value Function Loss: 0.00410

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.56287
Value Function Update Magnitude: 0.61456

Collected Steps per Second: 21,233.93070
Overall Steps per Second: 10,291.56808

Timestep Collection Time: 2.35491
Timestep Consumption Time: 2.50382
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.85873

Cumulative Model Updates: 94,012
Cumulative Timesteps: 784,095,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.71596
Policy Entropy: 3.14386
Value Function Loss: 0.00442

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.57160
Value Function Update Magnitude: 0.60839

Collected Steps per Second: 21,757.00801
Overall Steps per Second: 10,501.92015

Timestep Collection Time: 2.29921
Timestep Consumption Time: 2.46411
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.76332

Cumulative Model Updates: 94,018
Cumulative Timesteps: 784,145,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 784145338...
Checkpoint 784145338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.87422
Policy Entropy: 3.14071
Value Function Loss: 0.00466

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.57849
Value Function Update Magnitude: 0.62416

Collected Steps per Second: 21,983.42693
Overall Steps per Second: 10,390.62538

Timestep Collection Time: 2.27590
Timestep Consumption Time: 2.53921
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 4.81511

Cumulative Model Updates: 94,024
Cumulative Timesteps: 784,195,370

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.87402
Policy Entropy: 3.15544
Value Function Loss: 0.00451

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09214
Policy Update Magnitude: 0.58009
Value Function Update Magnitude: 0.62287

Collected Steps per Second: 21,845.44492
Overall Steps per Second: 10,337.29656

Timestep Collection Time: 2.29009
Timestep Consumption Time: 2.54947
PPO Batch Consumption Time: 0.29750
Total Iteration Time: 4.83956

Cumulative Model Updates: 94,030
Cumulative Timesteps: 784,245,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 784245398...
Checkpoint 784245398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.15319
Policy Entropy: 3.16427
Value Function Loss: 0.00419

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.56858
Value Function Update Magnitude: 0.60489

Collected Steps per Second: 21,474.68829
Overall Steps per Second: 10,266.48674

Timestep Collection Time: 2.32916
Timestep Consumption Time: 2.54281
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.87197

Cumulative Model Updates: 94,036
Cumulative Timesteps: 784,295,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.71576
Policy Entropy: 3.17073
Value Function Loss: 0.00415

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.55392
Value Function Update Magnitude: 0.58027

Collected Steps per Second: 21,700.67991
Overall Steps per Second: 10,428.89226

Timestep Collection Time: 2.30426
Timestep Consumption Time: 2.49050
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.79476

Cumulative Model Updates: 94,042
Cumulative Timesteps: 784,345,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 784345420...
Checkpoint 784345420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.75046
Policy Entropy: 3.14610
Value Function Loss: 0.00443

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09124
Policy Update Magnitude: 0.55331
Value Function Update Magnitude: 0.56702

Collected Steps per Second: 21,896.67999
Overall Steps per Second: 10,574.66025

Timestep Collection Time: 2.28491
Timestep Consumption Time: 2.44640
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.73131

Cumulative Model Updates: 94,048
Cumulative Timesteps: 784,395,452

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.41218
Policy Entropy: 3.15354
Value Function Loss: 0.00451

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10630
Policy Update Magnitude: 0.55636
Value Function Update Magnitude: 0.59960

Collected Steps per Second: 21,805.52731
Overall Steps per Second: 10,349.03031

Timestep Collection Time: 2.29346
Timestep Consumption Time: 2.53888
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.83234

Cumulative Model Updates: 94,054
Cumulative Timesteps: 784,445,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 784445462...
Checkpoint 784445462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.87364
Policy Entropy: 3.14983
Value Function Loss: 0.00453

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08864
Policy Update Magnitude: 0.55687
Value Function Update Magnitude: 0.62542

Collected Steps per Second: 22,111.06696
Overall Steps per Second: 10,430.57572

Timestep Collection Time: 2.26140
Timestep Consumption Time: 2.53239
PPO Batch Consumption Time: 0.29780
Total Iteration Time: 4.79379

Cumulative Model Updates: 94,060
Cumulative Timesteps: 784,495,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.14020
Policy Entropy: 3.15243
Value Function Loss: 0.00456

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08267
Policy Update Magnitude: 0.56169
Value Function Update Magnitude: 0.62884

Collected Steps per Second: 22,108.68804
Overall Steps per Second: 10,357.57847

Timestep Collection Time: 2.26291
Timestep Consumption Time: 2.56737
PPO Batch Consumption Time: 0.30346
Total Iteration Time: 4.83028

Cumulative Model Updates: 94,066
Cumulative Timesteps: 784,545,494

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 784545494...
Checkpoint 784545494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.63870
Policy Entropy: 3.13955
Value Function Loss: 0.00466

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09362
Policy Update Magnitude: 0.57498
Value Function Update Magnitude: 0.66520

Collected Steps per Second: 21,279.56433
Overall Steps per Second: 10,253.24132

Timestep Collection Time: 2.35014
Timestep Consumption Time: 2.52734
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.87748

Cumulative Model Updates: 94,072
Cumulative Timesteps: 784,595,504

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.34395
Policy Entropy: 3.16347
Value Function Loss: 0.00443

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.58229
Value Function Update Magnitude: 0.66412

Collected Steps per Second: 22,131.18574
Overall Steps per Second: 10,495.54663

Timestep Collection Time: 2.25944
Timestep Consumption Time: 2.50487
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.76431

Cumulative Model Updates: 94,078
Cumulative Timesteps: 784,645,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 784645508...
Checkpoint 784645508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.75603
Policy Entropy: 3.16774
Value Function Loss: 0.00447

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.57345
Value Function Update Magnitude: 0.63690

Collected Steps per Second: 21,440.98841
Overall Steps per Second: 10,227.64161

Timestep Collection Time: 2.33263
Timestep Consumption Time: 2.55745
PPO Batch Consumption Time: 0.29755
Total Iteration Time: 4.89008

Cumulative Model Updates: 94,084
Cumulative Timesteps: 784,695,522

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 689.02725
Policy Entropy: 3.16251
Value Function Loss: 0.00452

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10063
Policy Update Magnitude: 0.57440
Value Function Update Magnitude: 0.62673

Collected Steps per Second: 22,043.47247
Overall Steps per Second: 10,498.90912

Timestep Collection Time: 2.26924
Timestep Consumption Time: 2.49525
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.76449

Cumulative Model Updates: 94,090
Cumulative Timesteps: 784,745,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 784745544...
Checkpoint 784745544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754.37093
Policy Entropy: 3.15561
Value Function Loss: 0.00449

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.57590
Value Function Update Magnitude: 0.63491

Collected Steps per Second: 21,761.82663
Overall Steps per Second: 10,502.35105

Timestep Collection Time: 2.29880
Timestep Consumption Time: 2.46452
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.76331

Cumulative Model Updates: 94,096
Cumulative Timesteps: 784,795,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,302.15103
Policy Entropy: 3.15455
Value Function Loss: 0.00445

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.57584
Value Function Update Magnitude: 0.64393

Collected Steps per Second: 21,880.96031
Overall Steps per Second: 10,491.38044

Timestep Collection Time: 2.28601
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.76772

Cumulative Model Updates: 94,102
Cumulative Timesteps: 784,845,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 784845590...
Checkpoint 784845590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.48893
Policy Entropy: 3.15158
Value Function Loss: 0.00445

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.58159
Value Function Update Magnitude: 0.63130

Collected Steps per Second: 21,805.51800
Overall Steps per Second: 10,410.99095

Timestep Collection Time: 2.29309
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.29681
Total Iteration Time: 4.80281

Cumulative Model Updates: 94,108
Cumulative Timesteps: 784,895,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.90608
Policy Entropy: 3.14322
Value Function Loss: 0.00441

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11348
Policy Update Magnitude: 0.57467
Value Function Update Magnitude: 0.62127

Collected Steps per Second: 22,158.43400
Overall Steps per Second: 10,441.05908

Timestep Collection Time: 2.25747
Timestep Consumption Time: 2.53342
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.79089

Cumulative Model Updates: 94,114
Cumulative Timesteps: 784,945,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 784945614...
Checkpoint 784945614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.54809
Policy Entropy: 3.13776
Value Function Loss: 0.00435

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.57101
Value Function Update Magnitude: 0.60461

Collected Steps per Second: 21,634.22686
Overall Steps per Second: 10,330.78424

Timestep Collection Time: 2.31152
Timestep Consumption Time: 2.52916
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.84068

Cumulative Model Updates: 94,120
Cumulative Timesteps: 784,995,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.58080
Policy Entropy: 3.16968
Value Function Loss: 0.00446

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.57829
Value Function Update Magnitude: 0.60723

Collected Steps per Second: 22,132.79562
Overall Steps per Second: 10,427.80977

Timestep Collection Time: 2.25990
Timestep Consumption Time: 2.53669
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.79660

Cumulative Model Updates: 94,126
Cumulative Timesteps: 785,045,640

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 785045640...
Checkpoint 785045640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.73198
Policy Entropy: 3.16754
Value Function Loss: 0.00447

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.57499
Value Function Update Magnitude: 0.61577

Collected Steps per Second: 21,726.87036
Overall Steps per Second: 10,304.62998

Timestep Collection Time: 2.30139
Timestep Consumption Time: 2.55099
PPO Batch Consumption Time: 0.29744
Total Iteration Time: 4.85238

Cumulative Model Updates: 94,132
Cumulative Timesteps: 785,095,642

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.60763
Policy Entropy: 3.16561
Value Function Loss: 0.00459

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.57083
Value Function Update Magnitude: 0.61165

Collected Steps per Second: 22,159.06418
Overall Steps per Second: 10,530.33284

Timestep Collection Time: 2.25741
Timestep Consumption Time: 2.49287
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.75028

Cumulative Model Updates: 94,138
Cumulative Timesteps: 785,145,664

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 785145664...
Checkpoint 785145664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.31148
Policy Entropy: 3.12730
Value Function Loss: 0.00483

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.12047
Policy Update Magnitude: 0.57681
Value Function Update Magnitude: 0.60848

Collected Steps per Second: 21,432.65678
Overall Steps per Second: 10,094.00644

Timestep Collection Time: 2.33308
Timestep Consumption Time: 2.62076
PPO Batch Consumption Time: 0.31330
Total Iteration Time: 4.95383

Cumulative Model Updates: 94,144
Cumulative Timesteps: 785,195,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.67816
Policy Entropy: 3.11006
Value Function Loss: 0.00478

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.12180
Policy Update Magnitude: 0.58272
Value Function Update Magnitude: 0.61167

Collected Steps per Second: 22,233.67716
Overall Steps per Second: 10,540.73521

Timestep Collection Time: 2.24920
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.74426

Cumulative Model Updates: 94,150
Cumulative Timesteps: 785,245,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 785245676...
Checkpoint 785245676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.32612
Policy Entropy: 3.10906
Value Function Loss: 0.00476

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.58474
Value Function Update Magnitude: 0.61791

Collected Steps per Second: 21,585.60456
Overall Steps per Second: 10,305.92628

Timestep Collection Time: 2.31710
Timestep Consumption Time: 2.53603
PPO Batch Consumption Time: 0.29769
Total Iteration Time: 4.85313

Cumulative Model Updates: 94,156
Cumulative Timesteps: 785,295,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.75923
Policy Entropy: 3.12976
Value Function Loss: 0.00452

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.57695
Value Function Update Magnitude: 0.61040

Collected Steps per Second: 22,345.66181
Overall Steps per Second: 10,482.44570

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.53292
PPO Batch Consumption Time: 0.29754
Total Iteration Time: 4.77102

Cumulative Model Updates: 94,162
Cumulative Timesteps: 785,345,704

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 785345704...
Checkpoint 785345704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.28564
Policy Entropy: 3.13346
Value Function Loss: 0.00453

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.57027
Value Function Update Magnitude: 0.61225

Collected Steps per Second: 21,151.42695
Overall Steps per Second: 10,347.41464

Timestep Collection Time: 2.36457
Timestep Consumption Time: 2.46891
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.83348

Cumulative Model Updates: 94,168
Cumulative Timesteps: 785,395,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.58198
Policy Entropy: 3.14027
Value Function Loss: 0.00453

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.57206
Value Function Update Magnitude: 0.60598

Collected Steps per Second: 22,083.87368
Overall Steps per Second: 10,387.89636

Timestep Collection Time: 2.26446
Timestep Consumption Time: 2.54961
PPO Batch Consumption Time: 0.29625
Total Iteration Time: 4.81406

Cumulative Model Updates: 94,174
Cumulative Timesteps: 785,445,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 785445726...
Checkpoint 785445726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.84683
Policy Entropy: 3.13371
Value Function Loss: 0.00464

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11314
Policy Update Magnitude: 0.57289
Value Function Update Magnitude: 0.60728

Collected Steps per Second: 21,840.38984
Overall Steps per Second: 10,364.42325

Timestep Collection Time: 2.29080
Timestep Consumption Time: 2.53648
PPO Batch Consumption Time: 0.29776
Total Iteration Time: 4.82728

Cumulative Model Updates: 94,180
Cumulative Timesteps: 785,495,758

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 741.31330
Policy Entropy: 3.12886
Value Function Loss: 0.00489

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.57442
Value Function Update Magnitude: 0.61876

Collected Steps per Second: 22,451.07153
Overall Steps per Second: 10,565.73588

Timestep Collection Time: 2.22858
Timestep Consumption Time: 2.50692
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.73550

Cumulative Model Updates: 94,186
Cumulative Timesteps: 785,545,792

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 785545792...
Checkpoint 785545792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 872.08586
Policy Entropy: 3.12245
Value Function Loss: 0.00494

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.58576
Value Function Update Magnitude: 0.62924

Collected Steps per Second: 21,753.10418
Overall Steps per Second: 10,466.91132

Timestep Collection Time: 2.29981
Timestep Consumption Time: 2.47982
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.77963

Cumulative Model Updates: 94,192
Cumulative Timesteps: 785,595,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.30787
Policy Entropy: 3.11977
Value Function Loss: 0.00478

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.58567
Value Function Update Magnitude: 0.62293

Collected Steps per Second: 22,315.75422
Overall Steps per Second: 10,565.72861

Timestep Collection Time: 2.24066
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.73247

Cumulative Model Updates: 94,198
Cumulative Timesteps: 785,645,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 785645822...
Checkpoint 785645822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.52505
Policy Entropy: 3.11665
Value Function Loss: 0.00486

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.57968
Value Function Update Magnitude: 0.61237

Collected Steps per Second: 22,129.30463
Overall Steps per Second: 10,425.78605

Timestep Collection Time: 2.26153
Timestep Consumption Time: 2.53869
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.80021

Cumulative Model Updates: 94,204
Cumulative Timesteps: 785,695,868

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.64703
Policy Entropy: 3.11629
Value Function Loss: 0.00489

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.58504
Value Function Update Magnitude: 0.60904

Collected Steps per Second: 22,562.47843
Overall Steps per Second: 10,634.13272

Timestep Collection Time: 2.21669
Timestep Consumption Time: 2.48647
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.70316

Cumulative Model Updates: 94,210
Cumulative Timesteps: 785,745,882

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 785745882...
Checkpoint 785745882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.26471
Policy Entropy: 3.12407
Value Function Loss: 0.00480

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.59030
Value Function Update Magnitude: 0.62449

Collected Steps per Second: 21,570.04586
Overall Steps per Second: 10,353.69778

Timestep Collection Time: 2.31812
Timestep Consumption Time: 2.51126
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.82939

Cumulative Model Updates: 94,216
Cumulative Timesteps: 785,795,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.63125
Policy Entropy: 3.12566
Value Function Loss: 0.00460

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.58555
Value Function Update Magnitude: 0.64068

Collected Steps per Second: 22,165.13370
Overall Steps per Second: 10,363.33758

Timestep Collection Time: 2.25580
Timestep Consumption Time: 2.56891
PPO Batch Consumption Time: 0.29785
Total Iteration Time: 4.82470

Cumulative Model Updates: 94,222
Cumulative Timesteps: 785,845,884

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 785845884...
Checkpoint 785845884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 952.25029
Policy Entropy: 3.12301
Value Function Loss: 0.00427

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.57895
Value Function Update Magnitude: 0.64718

Collected Steps per Second: 21,655.31499
Overall Steps per Second: 10,408.32025

Timestep Collection Time: 2.30973
Timestep Consumption Time: 2.49585
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.80558

Cumulative Model Updates: 94,228
Cumulative Timesteps: 785,895,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.42118
Policy Entropy: 3.11782
Value Function Loss: 0.00426

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.57573
Value Function Update Magnitude: 0.62605

Collected Steps per Second: 22,277.31615
Overall Steps per Second: 10,517.41156

Timestep Collection Time: 2.24497
Timestep Consumption Time: 2.51019
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.75516

Cumulative Model Updates: 94,234
Cumulative Timesteps: 785,945,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 785945914...
Checkpoint 785945914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.96465
Policy Entropy: 3.13483
Value Function Loss: 0.00399

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.56686
Value Function Update Magnitude: 0.62071

Collected Steps per Second: 21,590.46850
Overall Steps per Second: 10,356.39427

Timestep Collection Time: 2.31713
Timestep Consumption Time: 2.51351
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.83064

Cumulative Model Updates: 94,240
Cumulative Timesteps: 785,995,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.99865
Policy Entropy: 3.13031
Value Function Loss: 0.00416

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.55776
Value Function Update Magnitude: 0.61449

Collected Steps per Second: 22,133.49274
Overall Steps per Second: 10,593.77927

Timestep Collection Time: 2.25965
Timestep Consumption Time: 2.46142
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.72107

Cumulative Model Updates: 94,246
Cumulative Timesteps: 786,045,956

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 786045956...
Checkpoint 786045956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.11764
Policy Entropy: 3.14500
Value Function Loss: 0.00438

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.08245
Policy Update Magnitude: 0.56619
Value Function Update Magnitude: 0.62336

Collected Steps per Second: 21,886.67976
Overall Steps per Second: 10,496.60207

Timestep Collection Time: 2.28504
Timestep Consumption Time: 2.47955
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.76459

Cumulative Model Updates: 94,252
Cumulative Timesteps: 786,095,968

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.41863
Policy Entropy: 3.13389
Value Function Loss: 0.00453

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.57670
Value Function Update Magnitude: 0.64708

Collected Steps per Second: 22,093.92765
Overall Steps per Second: 10,552.82080

Timestep Collection Time: 2.26325
Timestep Consumption Time: 2.47520
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.73845

Cumulative Model Updates: 94,258
Cumulative Timesteps: 786,145,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 786145972...
Checkpoint 786145972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.78684
Policy Entropy: 3.14824
Value Function Loss: 0.00440

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10010
Policy Update Magnitude: 0.57632
Value Function Update Magnitude: 0.64774

Collected Steps per Second: 21,746.40843
Overall Steps per Second: 10,341.28686

Timestep Collection Time: 2.29997
Timestep Consumption Time: 2.53657
PPO Batch Consumption Time: 0.29759
Total Iteration Time: 4.83654

Cumulative Model Updates: 94,264
Cumulative Timesteps: 786,195,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.00665
Policy Entropy: 3.15381
Value Function Loss: 0.00416

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.55884
Value Function Update Magnitude: 0.61902

Collected Steps per Second: 22,201.11324
Overall Steps per Second: 10,452.13998

Timestep Collection Time: 2.25349
Timestep Consumption Time: 2.53309
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.78658

Cumulative Model Updates: 94,270
Cumulative Timesteps: 786,246,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 786246018...
Checkpoint 786246018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760.84774
Policy Entropy: 3.15226
Value Function Loss: 0.00436

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.55656
Value Function Update Magnitude: 0.60253

Collected Steps per Second: 21,829.76018
Overall Steps per Second: 10,404.67511

Timestep Collection Time: 2.29054
Timestep Consumption Time: 2.51518
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.80572

Cumulative Model Updates: 94,276
Cumulative Timesteps: 786,296,020

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.24112
Policy Entropy: 3.14382
Value Function Loss: 0.00457

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.61432

Collected Steps per Second: 22,217.35529
Overall Steps per Second: 10,459.53553

Timestep Collection Time: 2.25193
Timestep Consumption Time: 2.53145
PPO Batch Consumption Time: 0.29729
Total Iteration Time: 4.78339

Cumulative Model Updates: 94,282
Cumulative Timesteps: 786,346,052

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 786346052...
Checkpoint 786346052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,552.19010
Policy Entropy: 3.14163
Value Function Loss: 0.00458

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.57621
Value Function Update Magnitude: 0.62982

Collected Steps per Second: 20,934.98432
Overall Steps per Second: 10,148.08941

Timestep Collection Time: 2.38844
Timestep Consumption Time: 2.53879
PPO Batch Consumption Time: 0.29783
Total Iteration Time: 4.92723

Cumulative Model Updates: 94,288
Cumulative Timesteps: 786,396,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.22642
Policy Entropy: 3.16275
Value Function Loss: 0.00449

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.58027
Value Function Update Magnitude: 0.64710

Collected Steps per Second: 22,099.75014
Overall Steps per Second: 10,406.61600

Timestep Collection Time: 2.26383
Timestep Consumption Time: 2.54369
PPO Batch Consumption Time: 0.29838
Total Iteration Time: 4.80752

Cumulative Model Updates: 94,294
Cumulative Timesteps: 786,446,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 786446084...
Checkpoint 786446084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.81421
Policy Entropy: 3.16256
Value Function Loss: 0.00454

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.65429

Collected Steps per Second: 21,764.34788
Overall Steps per Second: 10,394.58856

Timestep Collection Time: 2.29853
Timestep Consumption Time: 2.51417
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.81270

Cumulative Model Updates: 94,300
Cumulative Timesteps: 786,496,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.02865
Policy Entropy: 3.17662
Value Function Loss: 0.00448

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.57364
Value Function Update Magnitude: 0.65274

Collected Steps per Second: 21,928.94655
Overall Steps per Second: 10,559.28637

Timestep Collection Time: 2.28036
Timestep Consumption Time: 2.45537
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.73574

Cumulative Model Updates: 94,306
Cumulative Timesteps: 786,546,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 786546116...
Checkpoint 786546116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.29468
Policy Entropy: 3.16946
Value Function Loss: 0.00444

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11268
Policy Update Magnitude: 0.56627
Value Function Update Magnitude: 0.64377

Collected Steps per Second: 22,138.72046
Overall Steps per Second: 10,482.93881

Timestep Collection Time: 2.25885
Timestep Consumption Time: 2.51157
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.77042

Cumulative Model Updates: 94,312
Cumulative Timesteps: 786,596,124

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.17853
Policy Entropy: 3.17956
Value Function Loss: 0.00446

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.55455
Value Function Update Magnitude: 0.62627

Collected Steps per Second: 22,271.36688
Overall Steps per Second: 10,585.84003

Timestep Collection Time: 2.24611
Timestep Consumption Time: 2.47945
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.72556

Cumulative Model Updates: 94,318
Cumulative Timesteps: 786,646,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 786646148...
Checkpoint 786646148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.78657
Policy Entropy: 3.17034
Value Function Loss: 0.00442

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.60939

Collected Steps per Second: 21,857.01133
Overall Steps per Second: 10,408.02743

Timestep Collection Time: 2.28842
Timestep Consumption Time: 2.51729
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.80571

Cumulative Model Updates: 94,324
Cumulative Timesteps: 786,696,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,822.79028
Policy Entropy: 3.16464
Value Function Loss: 0.00435

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.55746
Value Function Update Magnitude: 0.58815

Collected Steps per Second: 21,747.35139
Overall Steps per Second: 10,372.44169

Timestep Collection Time: 2.30033
Timestep Consumption Time: 2.52265
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.82297

Cumulative Model Updates: 94,330
Cumulative Timesteps: 786,746,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 786746192...
Checkpoint 786746192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.84828
Policy Entropy: 3.15729
Value Function Loss: 0.00414

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09909
Policy Update Magnitude: 0.55547
Value Function Update Magnitude: 0.58161

Collected Steps per Second: 21,985.32592
Overall Steps per Second: 10,366.13040

Timestep Collection Time: 2.27515
Timestep Consumption Time: 2.55018
PPO Batch Consumption Time: 0.29813
Total Iteration Time: 4.82533

Cumulative Model Updates: 94,336
Cumulative Timesteps: 786,796,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,179.33527
Policy Entropy: 3.15336
Value Function Loss: 0.00414

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09858
Policy Update Magnitude: 0.54618
Value Function Update Magnitude: 0.58971

Collected Steps per Second: 22,207.93413
Overall Steps per Second: 10,396.08869

Timestep Collection Time: 2.25145
Timestep Consumption Time: 2.55805
PPO Batch Consumption Time: 0.29964
Total Iteration Time: 4.80950

Cumulative Model Updates: 94,342
Cumulative Timesteps: 786,846,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 786846212...
Checkpoint 786846212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.12909
Policy Entropy: 3.15512
Value Function Loss: 0.00416

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10314
Policy Update Magnitude: 0.54913
Value Function Update Magnitude: 0.61205

Collected Steps per Second: 21,668.62630
Overall Steps per Second: 10,238.66608

Timestep Collection Time: 2.30859
Timestep Consumption Time: 2.57720
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.88579

Cumulative Model Updates: 94,348
Cumulative Timesteps: 786,896,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.60412
Policy Entropy: 3.17131
Value Function Loss: 0.00414

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.54892
Value Function Update Magnitude: 0.62214

Collected Steps per Second: 21,828.00605
Overall Steps per Second: 10,421.46079

Timestep Collection Time: 2.29155
Timestep Consumption Time: 2.50816
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.79971

Cumulative Model Updates: 94,354
Cumulative Timesteps: 786,946,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 786946256...
Checkpoint 786946256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.57395
Policy Entropy: 3.18882
Value Function Loss: 0.00414

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09348
Policy Update Magnitude: 0.54986
Value Function Update Magnitude: 0.60326

Collected Steps per Second: 22,163.91572
Overall Steps per Second: 10,571.02610

Timestep Collection Time: 2.25601
Timestep Consumption Time: 2.47409
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.73010

Cumulative Model Updates: 94,360
Cumulative Timesteps: 786,996,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.48467
Policy Entropy: 3.18620
Value Function Loss: 0.00439

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.55679
Value Function Update Magnitude: 0.61198

Collected Steps per Second: 21,757.48874
Overall Steps per Second: 10,484.05508

Timestep Collection Time: 2.29999
Timestep Consumption Time: 2.47316
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.77315

Cumulative Model Updates: 94,366
Cumulative Timesteps: 787,046,300

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 787046300...
Checkpoint 787046300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.80328
Policy Entropy: 3.18141
Value Function Loss: 0.00453

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09269
Policy Update Magnitude: 0.56215
Value Function Update Magnitude: 0.65014

Collected Steps per Second: 22,140.72131
Overall Steps per Second: 10,441.15280

Timestep Collection Time: 2.25873
Timestep Consumption Time: 2.53097
PPO Batch Consumption Time: 0.29870
Total Iteration Time: 4.78970

Cumulative Model Updates: 94,372
Cumulative Timesteps: 787,096,310

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,018.07818
Policy Entropy: 3.17217
Value Function Loss: 0.00456

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08755
Policy Update Magnitude: 0.56688
Value Function Update Magnitude: 0.66068

Collected Steps per Second: 22,072.84303
Overall Steps per Second: 10,357.24478

Timestep Collection Time: 2.26523
Timestep Consumption Time: 2.56231
PPO Batch Consumption Time: 0.30400
Total Iteration Time: 4.82754

Cumulative Model Updates: 94,378
Cumulative Timesteps: 787,146,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 787146310...
Checkpoint 787146310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.75731
Policy Entropy: 3.16176
Value Function Loss: 0.00467

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11058
Policy Update Magnitude: 0.58011
Value Function Update Magnitude: 0.66528

Collected Steps per Second: 22,085.83138
Overall Steps per Second: 10,398.69200

Timestep Collection Time: 2.26462
Timestep Consumption Time: 2.54522
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.80984

Cumulative Model Updates: 94,384
Cumulative Timesteps: 787,196,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.64806
Policy Entropy: 3.16100
Value Function Loss: 0.00457

Mean KL Divergence: 0.05001
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.58004
Value Function Update Magnitude: 0.66039

Collected Steps per Second: 22,078.69102
Overall Steps per Second: 10,326.05870

Timestep Collection Time: 2.26590
Timestep Consumption Time: 2.57893
PPO Batch Consumption Time: 0.30008
Total Iteration Time: 4.84483

Cumulative Model Updates: 94,390
Cumulative Timesteps: 787,246,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 787246354...
Checkpoint 787246354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.28726
Policy Entropy: 3.15936
Value Function Loss: 0.00436

Mean KL Divergence: 0.17451
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.57483
Value Function Update Magnitude: 0.63943

Collected Steps per Second: 22,325.23107
Overall Steps per Second: 10,447.52641

Timestep Collection Time: 2.24007
Timestep Consumption Time: 2.54671
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.78678

Cumulative Model Updates: 94,396
Cumulative Timesteps: 787,296,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.56627
Policy Entropy: 3.17197
Value Function Loss: 0.00420

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.56748
Value Function Update Magnitude: 0.63479

Collected Steps per Second: 21,688.88426
Overall Steps per Second: 10,245.31135

Timestep Collection Time: 2.30561
Timestep Consumption Time: 2.57526
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.88087

Cumulative Model Updates: 94,402
Cumulative Timesteps: 787,346,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 787346370...
Checkpoint 787346370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810.06775
Policy Entropy: 3.16031
Value Function Loss: 0.00449

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.57110
Value Function Update Magnitude: 0.64307

Collected Steps per Second: 21,247.87395
Overall Steps per Second: 10,314.52176

Timestep Collection Time: 2.35384
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.84889

Cumulative Model Updates: 94,408
Cumulative Timesteps: 787,396,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.09460
Policy Entropy: 3.14683
Value Function Loss: 0.00453

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.08879
Policy Update Magnitude: 0.58061
Value Function Update Magnitude: 0.65987

Collected Steps per Second: 21,990.31515
Overall Steps per Second: 10,579.93958

Timestep Collection Time: 2.27518
Timestep Consumption Time: 2.45377
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.72895

Cumulative Model Updates: 94,414
Cumulative Timesteps: 787,446,416

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 787446416...
Checkpoint 787446416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.37616
Policy Entropy: 3.14346
Value Function Loss: 0.00471

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10582
Policy Update Magnitude: 0.58451
Value Function Update Magnitude: 0.66254

Collected Steps per Second: 22,199.60576
Overall Steps per Second: 10,603.51114

Timestep Collection Time: 2.25283
Timestep Consumption Time: 2.46372
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.71655

Cumulative Model Updates: 94,420
Cumulative Timesteps: 787,496,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632.65370
Policy Entropy: 3.14967
Value Function Loss: 0.00481

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.58748
Value Function Update Magnitude: 0.66502

Collected Steps per Second: 22,502.48567
Overall Steps per Second: 10,610.29382

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.49162
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.71467

Cumulative Model Updates: 94,426
Cumulative Timesteps: 787,546,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 787546452...
Checkpoint 787546452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.64988
Policy Entropy: 3.15742
Value Function Loss: 0.00466

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11234
Policy Update Magnitude: 0.58354
Value Function Update Magnitude: 0.67279

Collected Steps per Second: 22,288.91140
Overall Steps per Second: 10,637.55962

Timestep Collection Time: 2.24408
Timestep Consumption Time: 2.45794
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.70202

Cumulative Model Updates: 94,432
Cumulative Timesteps: 787,596,470

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.84104
Policy Entropy: 3.15638
Value Function Loss: 0.00443

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.57900
Value Function Update Magnitude: 0.65589

Collected Steps per Second: 22,209.39408
Overall Steps per Second: 10,426.98460

Timestep Collection Time: 2.25130
Timestep Consumption Time: 2.54395
PPO Batch Consumption Time: 0.29498
Total Iteration Time: 4.79525

Cumulative Model Updates: 94,438
Cumulative Timesteps: 787,646,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 787646470...
Checkpoint 787646470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.99019
Policy Entropy: 3.14974
Value Function Loss: 0.00452

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10322
Policy Update Magnitude: 0.57402
Value Function Update Magnitude: 0.62565

Collected Steps per Second: 22,062.87580
Overall Steps per Second: 10,381.64036

Timestep Collection Time: 2.26743
Timestep Consumption Time: 2.55127
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.81870

Cumulative Model Updates: 94,444
Cumulative Timesteps: 787,696,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.60342
Policy Entropy: 3.16282
Value Function Loss: 0.00464

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.57215
Value Function Update Magnitude: 0.59953

Collected Steps per Second: 22,048.69053
Overall Steps per Second: 10,431.58862

Timestep Collection Time: 2.26807
Timestep Consumption Time: 2.52583
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.79390

Cumulative Model Updates: 94,450
Cumulative Timesteps: 787,746,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 787746504...
Checkpoint 787746504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.02105
Policy Entropy: 3.15260
Value Function Loss: 0.00479

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.57371
Value Function Update Magnitude: 0.60799

Collected Steps per Second: 22,324.09938
Overall Steps per Second: 10,478.96929

Timestep Collection Time: 2.23982
Timestep Consumption Time: 2.53183
PPO Batch Consumption Time: 0.29896
Total Iteration Time: 4.77165

Cumulative Model Updates: 94,456
Cumulative Timesteps: 787,796,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.92928
Policy Entropy: 3.15000
Value Function Loss: 0.00465

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.57893
Value Function Update Magnitude: 0.60420

Collected Steps per Second: 22,321.69265
Overall Steps per Second: 10,597.69248

Timestep Collection Time: 2.23997
Timestep Consumption Time: 2.47803
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.71801

Cumulative Model Updates: 94,462
Cumulative Timesteps: 787,846,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 787846506...
Checkpoint 787846506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 778.57998
Policy Entropy: 3.15964
Value Function Loss: 0.00456

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.58228
Value Function Update Magnitude: 0.62148

Collected Steps per Second: 21,799.56337
Overall Steps per Second: 10,403.19430

Timestep Collection Time: 2.29399
Timestep Consumption Time: 2.51299
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.80699

Cumulative Model Updates: 94,468
Cumulative Timesteps: 787,896,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.33173
Policy Entropy: 3.16500
Value Function Loss: 0.00465

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.58157
Value Function Update Magnitude: 0.63194

Collected Steps per Second: 20,487.46304
Overall Steps per Second: 10,113.42080

Timestep Collection Time: 2.44188
Timestep Consumption Time: 2.50481
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.94669

Cumulative Model Updates: 94,474
Cumulative Timesteps: 787,946,542

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 787946542...
Checkpoint 787946542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.77009
Policy Entropy: 3.16058
Value Function Loss: 0.00473

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.58103
Value Function Update Magnitude: 0.63693

Collected Steps per Second: 19,729.84201
Overall Steps per Second: 9,833.30740

Timestep Collection Time: 2.53606
Timestep Consumption Time: 2.55236
PPO Batch Consumption Time: 0.29741
Total Iteration Time: 5.08842

Cumulative Model Updates: 94,480
Cumulative Timesteps: 787,996,578

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.70155
Policy Entropy: 3.15025
Value Function Loss: 0.00476

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.58625
Value Function Update Magnitude: 0.64618

Collected Steps per Second: 22,378.69476
Overall Steps per Second: 10,466.41854

Timestep Collection Time: 2.23436
Timestep Consumption Time: 2.54302
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.77737

Cumulative Model Updates: 94,486
Cumulative Timesteps: 788,046,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 788046580...
Checkpoint 788046580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796.39949
Policy Entropy: 3.15343
Value Function Loss: 0.00455

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.57928
Value Function Update Magnitude: 0.64322

Collected Steps per Second: 21,515.16986
Overall Steps per Second: 10,131.17541

Timestep Collection Time: 2.32478
Timestep Consumption Time: 2.61226
PPO Batch Consumption Time: 0.30312
Total Iteration Time: 4.93704

Cumulative Model Updates: 94,492
Cumulative Timesteps: 788,096,598

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.65114
Policy Entropy: 3.16735
Value Function Loss: 0.00439

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09440
Policy Update Magnitude: 0.57248
Value Function Update Magnitude: 0.63857

Collected Steps per Second: 21,826.78549
Overall Steps per Second: 10,459.56226

Timestep Collection Time: 2.29095
Timestep Consumption Time: 2.48975
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.78070

Cumulative Model Updates: 94,498
Cumulative Timesteps: 788,146,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 788146602...
Checkpoint 788146602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.19177
Policy Entropy: 3.16651
Value Function Loss: 0.00432

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.57104
Value Function Update Magnitude: 0.64604

Collected Steps per Second: 20,714.41710
Overall Steps per Second: 10,064.68449

Timestep Collection Time: 2.41436
Timestep Consumption Time: 2.55470
PPO Batch Consumption Time: 0.29806
Total Iteration Time: 4.96906

Cumulative Model Updates: 94,504
Cumulative Timesteps: 788,196,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.79860
Policy Entropy: 3.16501
Value Function Loss: 0.00440

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.56647
Value Function Update Magnitude: 0.65313

Collected Steps per Second: 22,324.99844
Overall Steps per Second: 10,461.39234

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.53994
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.77967

Cumulative Model Updates: 94,510
Cumulative Timesteps: 788,246,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 788246616...
Checkpoint 788246616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.99691
Policy Entropy: 3.16747
Value Function Loss: 0.00444

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.56379
Value Function Update Magnitude: 0.64862

Collected Steps per Second: 22,180.74447
Overall Steps per Second: 10,494.28502

Timestep Collection Time: 2.25556
Timestep Consumption Time: 2.51180
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.76736

Cumulative Model Updates: 94,516
Cumulative Timesteps: 788,296,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 905.65043
Policy Entropy: 3.17065
Value Function Loss: 0.00470

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.57301
Value Function Update Magnitude: 0.65002

Collected Steps per Second: 22,358.35899
Overall Steps per Second: 10,501.46533

Timestep Collection Time: 2.23719
Timestep Consumption Time: 2.52595
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.76314

Cumulative Model Updates: 94,522
Cumulative Timesteps: 788,346,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 788346666...
Checkpoint 788346666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.79159
Policy Entropy: 3.15003
Value Function Loss: 0.00469

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.57693
Value Function Update Magnitude: 0.68476

Collected Steps per Second: 22,076.83971
Overall Steps per Second: 10,432.19875

Timestep Collection Time: 2.26500
Timestep Consumption Time: 2.52824
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.79324

Cumulative Model Updates: 94,528
Cumulative Timesteps: 788,396,670

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.33952
Policy Entropy: 3.13478
Value Function Loss: 0.00446

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.58044
Value Function Update Magnitude: 0.69287

Collected Steps per Second: 22,335.51165
Overall Steps per Second: 10,605.69172

Timestep Collection Time: 2.23895
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.71520

Cumulative Model Updates: 94,534
Cumulative Timesteps: 788,446,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 788446678...
Checkpoint 788446678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.10858
Policy Entropy: 3.12755
Value Function Loss: 0.00456

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09989
Policy Update Magnitude: 0.57641
Value Function Update Magnitude: 0.67853

Collected Steps per Second: 21,669.79353
Overall Steps per Second: 10,379.29294

Timestep Collection Time: 2.30764
Timestep Consumption Time: 2.51023
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.81786

Cumulative Model Updates: 94,540
Cumulative Timesteps: 788,496,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.91856
Policy Entropy: 3.14021
Value Function Loss: 0.00465

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.57918
Value Function Update Magnitude: 0.68371

Collected Steps per Second: 22,705.28587
Overall Steps per Second: 10,660.17319

Timestep Collection Time: 2.20266
Timestep Consumption Time: 2.48882
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.69148

Cumulative Model Updates: 94,546
Cumulative Timesteps: 788,546,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 788546696...
Checkpoint 788546696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.56241
Policy Entropy: 3.15187
Value Function Loss: 0.00461

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.57244
Value Function Update Magnitude: 0.67576

Collected Steps per Second: 21,843.27331
Overall Steps per Second: 10,422.19128

Timestep Collection Time: 2.28931
Timestep Consumption Time: 2.50872
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.79803

Cumulative Model Updates: 94,552
Cumulative Timesteps: 788,596,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.36577
Policy Entropy: 3.16999
Value Function Loss: 0.00439

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11376
Policy Update Magnitude: 0.56602
Value Function Update Magnitude: 0.66321

Collected Steps per Second: 22,267.90042
Overall Steps per Second: 10,577.65719

Timestep Collection Time: 2.24556
Timestep Consumption Time: 2.48176
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.72732

Cumulative Model Updates: 94,558
Cumulative Timesteps: 788,646,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 788646706...
Checkpoint 788646706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.38795
Policy Entropy: 3.17719
Value Function Loss: 0.00437

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.64844

Collected Steps per Second: 21,940.50666
Overall Steps per Second: 10,426.47710

Timestep Collection Time: 2.27980
Timestep Consumption Time: 2.51760
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.79740

Cumulative Model Updates: 94,564
Cumulative Timesteps: 788,696,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.59820
Policy Entropy: 3.18884
Value Function Loss: 0.00464

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11012
Policy Update Magnitude: 0.56201
Value Function Update Magnitude: 0.63412

Collected Steps per Second: 22,358.56431
Overall Steps per Second: 10,589.91031

Timestep Collection Time: 2.23673
Timestep Consumption Time: 2.48569
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.72242

Cumulative Model Updates: 94,570
Cumulative Timesteps: 788,746,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 788746736...
Checkpoint 788746736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.60741
Policy Entropy: 3.19554
Value Function Loss: 0.00454

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.56878
Value Function Update Magnitude: 0.65180

Collected Steps per Second: 21,912.15198
Overall Steps per Second: 10,411.87218

Timestep Collection Time: 2.28275
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.80413

Cumulative Model Updates: 94,576
Cumulative Timesteps: 788,796,756

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.36186
Policy Entropy: 3.19462
Value Function Loss: 0.00484

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.57509
Value Function Update Magnitude: 0.66125

Collected Steps per Second: 22,427.42193
Overall Steps per Second: 10,485.70265

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.53909
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.76859

Cumulative Model Updates: 94,582
Cumulative Timesteps: 788,846,758

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 788846758...
Checkpoint 788846758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.22524
Policy Entropy: 3.19604
Value Function Loss: 0.00457

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10541
Policy Update Magnitude: 0.57233
Value Function Update Magnitude: 0.67008

Collected Steps per Second: 21,793.84983
Overall Steps per Second: 10,315.68581

Timestep Collection Time: 2.29459
Timestep Consumption Time: 2.55317
PPO Batch Consumption Time: 0.30103
Total Iteration Time: 4.84776

Cumulative Model Updates: 94,588
Cumulative Timesteps: 788,896,766

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.25654
Policy Entropy: 3.18109
Value Function Loss: 0.00451

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11052
Policy Update Magnitude: 0.56471
Value Function Update Magnitude: 0.65508

Collected Steps per Second: 22,208.58537
Overall Steps per Second: 10,436.57015

Timestep Collection Time: 2.25174
Timestep Consumption Time: 2.53987
PPO Batch Consumption Time: 0.30027
Total Iteration Time: 4.79161

Cumulative Model Updates: 94,594
Cumulative Timesteps: 788,946,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 788946774...
Checkpoint 788946774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.34323
Policy Entropy: 3.18114
Value Function Loss: 0.00454

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.63471

Collected Steps per Second: 21,865.69098
Overall Steps per Second: 10,478.42696

Timestep Collection Time: 2.28696
Timestep Consumption Time: 2.48532
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.77228

Cumulative Model Updates: 94,600
Cumulative Timesteps: 788,996,780

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,185.49331
Policy Entropy: 3.17681
Value Function Loss: 0.00477

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.56835
Value Function Update Magnitude: 0.64378

Collected Steps per Second: 22,472.15135
Overall Steps per Second: 10,547.32011

Timestep Collection Time: 2.22631
Timestep Consumption Time: 2.51707
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.74338

Cumulative Model Updates: 94,606
Cumulative Timesteps: 789,046,810

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 789046810...
Checkpoint 789046810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.86924
Policy Entropy: 3.18655
Value Function Loss: 0.00480

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.57691
Value Function Update Magnitude: 0.66090

Collected Steps per Second: 21,416.01825
Overall Steps per Second: 10,413.63818

Timestep Collection Time: 2.33498
Timestep Consumption Time: 2.46699
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.80197

Cumulative Model Updates: 94,612
Cumulative Timesteps: 789,096,816

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.23389
Policy Entropy: 3.18757
Value Function Loss: 0.00493

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.57825
Value Function Update Magnitude: 0.66835

Collected Steps per Second: 22,150.03359
Overall Steps per Second: 10,377.38627

Timestep Collection Time: 2.25760
Timestep Consumption Time: 2.56114
PPO Batch Consumption Time: 0.30146
Total Iteration Time: 4.81875

Cumulative Model Updates: 94,618
Cumulative Timesteps: 789,146,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 789146822...
Checkpoint 789146822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.45273
Policy Entropy: 3.19607
Value Function Loss: 0.00444

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.56602
Value Function Update Magnitude: 0.65181

Collected Steps per Second: 21,404.40635
Overall Steps per Second: 10,244.95478

Timestep Collection Time: 2.33690
Timestep Consumption Time: 2.54550
PPO Batch Consumption Time: 0.29942
Total Iteration Time: 4.88240

Cumulative Model Updates: 94,624
Cumulative Timesteps: 789,196,842

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.69735
Policy Entropy: 3.19231
Value Function Loss: 0.00423

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.55734
Value Function Update Magnitude: 0.62255

Collected Steps per Second: 22,263.43829
Overall Steps per Second: 10,452.67747

Timestep Collection Time: 2.24772
Timestep Consumption Time: 2.53976
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.78748

Cumulative Model Updates: 94,630
Cumulative Timesteps: 789,246,884

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 789246884...
Checkpoint 789246884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.07822
Policy Entropy: 3.20267
Value Function Loss: 0.00411

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.54808
Value Function Update Magnitude: 0.61420

Collected Steps per Second: 21,963.02544
Overall Steps per Second: 10,424.22380

Timestep Collection Time: 2.27701
Timestep Consumption Time: 2.52047
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.79748

Cumulative Model Updates: 94,636
Cumulative Timesteps: 789,296,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 694.96685
Policy Entropy: 3.20993
Value Function Loss: 0.00401

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.61908

Collected Steps per Second: 22,185.09773
Overall Steps per Second: 10,469.07518

Timestep Collection Time: 2.25458
Timestep Consumption Time: 2.52311
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.77769

Cumulative Model Updates: 94,642
Cumulative Timesteps: 789,346,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 789346912...
Checkpoint 789346912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.84017
Policy Entropy: 3.21635
Value Function Loss: 0.00452

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09256
Policy Update Magnitude: 0.55835
Value Function Update Magnitude: 0.62169

Collected Steps per Second: 22,203.88523
Overall Steps per Second: 10,534.41270

Timestep Collection Time: 2.25240
Timestep Consumption Time: 2.49509
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.74749

Cumulative Model Updates: 94,648
Cumulative Timesteps: 789,396,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.46236
Policy Entropy: 3.21317
Value Function Loss: 0.00484

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.57188
Value Function Update Magnitude: 0.63715

Collected Steps per Second: 22,511.03931
Overall Steps per Second: 10,469.33360

Timestep Collection Time: 2.22122
Timestep Consumption Time: 2.55482
PPO Batch Consumption Time: 0.30013
Total Iteration Time: 4.77604

Cumulative Model Updates: 94,654
Cumulative Timesteps: 789,446,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 789446926...
Checkpoint 789446926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.13582
Policy Entropy: 3.21189
Value Function Loss: 0.00483

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.57214
Value Function Update Magnitude: 0.66950

Collected Steps per Second: 21,713.37777
Overall Steps per Second: 10,300.71330

Timestep Collection Time: 2.30411
Timestep Consumption Time: 2.55284
PPO Batch Consumption Time: 0.29848
Total Iteration Time: 4.85695

Cumulative Model Updates: 94,660
Cumulative Timesteps: 789,496,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 684.68843
Policy Entropy: 3.20858
Value Function Loss: 0.00467

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.57665
Value Function Update Magnitude: 0.67623

Collected Steps per Second: 22,373.12077
Overall Steps per Second: 10,442.65914

Timestep Collection Time: 2.23572
Timestep Consumption Time: 2.55425
PPO Batch Consumption Time: 0.30068
Total Iteration Time: 4.78997

Cumulative Model Updates: 94,666
Cumulative Timesteps: 789,546,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 789546976...
Checkpoint 789546976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.28859
Policy Entropy: 3.20948
Value Function Loss: 0.00436

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.65957

Collected Steps per Second: 22,195.09725
Overall Steps per Second: 10,627.43977

Timestep Collection Time: 2.25401
Timestep Consumption Time: 2.45343
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.70744

Cumulative Model Updates: 94,672
Cumulative Timesteps: 789,597,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.42640
Policy Entropy: 3.20606
Value Function Loss: 0.00430

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.55872
Value Function Update Magnitude: 0.63072

Collected Steps per Second: 21,957.19598
Overall Steps per Second: 10,427.53889

Timestep Collection Time: 2.27780
Timestep Consumption Time: 2.51854
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.79634

Cumulative Model Updates: 94,678
Cumulative Timesteps: 789,647,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 789647018...
Checkpoint 789647018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.57073
Policy Entropy: 3.21140
Value Function Loss: 0.00445

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.55158
Value Function Update Magnitude: 0.60748

Collected Steps per Second: 21,573.03014
Overall Steps per Second: 10,319.42797

Timestep Collection Time: 2.31864
Timestep Consumption Time: 2.52853
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.84717

Cumulative Model Updates: 94,684
Cumulative Timesteps: 789,697,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.13859
Policy Entropy: 3.20097
Value Function Loss: 0.00458

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.55608
Value Function Update Magnitude: 0.61923

Collected Steps per Second: 21,768.91088
Overall Steps per Second: 10,502.28499

Timestep Collection Time: 2.29842
Timestep Consumption Time: 2.46569
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.76411

Cumulative Model Updates: 94,690
Cumulative Timesteps: 789,747,072

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 789747072...
Checkpoint 789747072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.05496
Policy Entropy: 3.20503
Value Function Loss: 0.00465

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.56368
Value Function Update Magnitude: 0.63451

Collected Steps per Second: 21,847.29926
Overall Steps per Second: 10,376.25268

Timestep Collection Time: 2.28861
Timestep Consumption Time: 2.53008
PPO Batch Consumption Time: 0.29621
Total Iteration Time: 4.81870

Cumulative Model Updates: 94,696
Cumulative Timesteps: 789,797,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.70189
Policy Entropy: 3.21153
Value Function Loss: 0.00460

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10838
Policy Update Magnitude: 0.56391
Value Function Update Magnitude: 0.65470

Collected Steps per Second: 21,710.30931
Overall Steps per Second: 10,484.00990

Timestep Collection Time: 2.30379
Timestep Consumption Time: 2.46690
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.77069

Cumulative Model Updates: 94,702
Cumulative Timesteps: 789,847,088

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 789847088...
Checkpoint 789847088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.02322
Policy Entropy: 3.21573
Value Function Loss: 0.00450

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.56035
Value Function Update Magnitude: 0.66783

Collected Steps per Second: 22,225.79909
Overall Steps per Second: 10,525.79770

Timestep Collection Time: 2.24964
Timestep Consumption Time: 2.50060
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.75023

Cumulative Model Updates: 94,708
Cumulative Timesteps: 789,897,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.43566
Policy Entropy: 3.19495
Value Function Loss: 0.00461

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.55990
Value Function Update Magnitude: 0.66288

Collected Steps per Second: 22,103.58018
Overall Steps per Second: 10,566.04909

Timestep Collection Time: 2.26253
Timestep Consumption Time: 2.47055
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.73308

Cumulative Model Updates: 94,714
Cumulative Timesteps: 789,947,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 789947098...
Checkpoint 789947098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.70230
Policy Entropy: 3.21101
Value Function Loss: 0.00435

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.55808
Value Function Update Magnitude: 0.65863

Collected Steps per Second: 21,248.00370
Overall Steps per Second: 10,251.02424

Timestep Collection Time: 2.35373
Timestep Consumption Time: 2.52500
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.87873

Cumulative Model Updates: 94,720
Cumulative Timesteps: 789,997,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.51710
Policy Entropy: 3.20271
Value Function Loss: 0.00443

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.55359
Value Function Update Magnitude: 0.65735

Collected Steps per Second: 22,525.17652
Overall Steps per Second: 10,631.43893

Timestep Collection Time: 2.22000
Timestep Consumption Time: 2.48359
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.70360

Cumulative Model Updates: 94,726
Cumulative Timesteps: 790,047,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 790047116...
Checkpoint 790047116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.94144
Policy Entropy: 3.21779
Value Function Loss: 0.00456

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.55013
Value Function Update Magnitude: 0.66274

Collected Steps per Second: 21,799.93548
Overall Steps per Second: 10,363.33428

Timestep Collection Time: 2.29386
Timestep Consumption Time: 2.53142
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.82528

Cumulative Model Updates: 94,732
Cumulative Timesteps: 790,097,122

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.89314
Policy Entropy: 3.21677
Value Function Loss: 0.00453

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.55223
Value Function Update Magnitude: 0.64309

Collected Steps per Second: 22,405.14078
Overall Steps per Second: 10,607.29456

Timestep Collection Time: 2.23163
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.71374

Cumulative Model Updates: 94,738
Cumulative Timesteps: 790,147,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 790147122...
Checkpoint 790147122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.72434
Policy Entropy: 3.22373
Value Function Loss: 0.00436

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.61537

Collected Steps per Second: 22,169.74577
Overall Steps per Second: 10,563.78312

Timestep Collection Time: 2.25659
Timestep Consumption Time: 2.47921
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.73580

Cumulative Model Updates: 94,744
Cumulative Timesteps: 790,197,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.77078
Policy Entropy: 3.22022
Value Function Loss: 0.00441

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.54822
Value Function Update Magnitude: 0.60057

Collected Steps per Second: 22,068.76737
Overall Steps per Second: 10,542.44216

Timestep Collection Time: 2.26655
Timestep Consumption Time: 2.47808
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.74463

Cumulative Model Updates: 94,750
Cumulative Timesteps: 790,247,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 790247170...
Checkpoint 790247170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.91673
Policy Entropy: 3.22007
Value Function Loss: 0.00465

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.55513
Value Function Update Magnitude: 0.62956

Collected Steps per Second: 21,969.83831
Overall Steps per Second: 10,516.91647

Timestep Collection Time: 2.27685
Timestep Consumption Time: 2.47949
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.75634

Cumulative Model Updates: 94,756
Cumulative Timesteps: 790,297,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.92840
Policy Entropy: 3.21132
Value Function Loss: 0.00445

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.65808

Collected Steps per Second: 21,677.55181
Overall Steps per Second: 10,481.68346

Timestep Collection Time: 2.30755
Timestep Consumption Time: 2.46478
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.77232

Cumulative Model Updates: 94,762
Cumulative Timesteps: 790,347,214

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 790347214...
Checkpoint 790347214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.15056
Policy Entropy: 3.21568
Value Function Loss: 0.00439

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.56015
Value Function Update Magnitude: 0.65136

Collected Steps per Second: 21,809.87903
Overall Steps per Second: 10,334.48245

Timestep Collection Time: 2.29373
Timestep Consumption Time: 2.54696
PPO Batch Consumption Time: 0.29762
Total Iteration Time: 4.84069

Cumulative Model Updates: 94,768
Cumulative Timesteps: 790,397,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.95083
Policy Entropy: 3.21487
Value Function Loss: 0.00446

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.55310
Value Function Update Magnitude: 0.62981

Collected Steps per Second: 21,714.31782
Overall Steps per Second: 10,403.56881

Timestep Collection Time: 2.30309
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.80700

Cumulative Model Updates: 94,774
Cumulative Timesteps: 790,447,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 790447250...
Checkpoint 790447250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.61519
Policy Entropy: 3.22362
Value Function Loss: 0.00449

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.60149

Collected Steps per Second: 21,919.55410
Overall Steps per Second: 10,405.61265

Timestep Collection Time: 2.28107
Timestep Consumption Time: 2.52403
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.80510

Cumulative Model Updates: 94,780
Cumulative Timesteps: 790,497,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.18001
Policy Entropy: 3.23028
Value Function Loss: 0.00455

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.59354

Collected Steps per Second: 21,949.85398
Overall Steps per Second: 10,409.63709

Timestep Collection Time: 2.27910
Timestep Consumption Time: 2.52664
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.80574

Cumulative Model Updates: 94,786
Cumulative Timesteps: 790,547,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 790547276...
Checkpoint 790547276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.05784
Policy Entropy: 3.22527
Value Function Loss: 0.00447

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.60676

Collected Steps per Second: 22,113.25320
Overall Steps per Second: 10,468.48643

Timestep Collection Time: 2.26154
Timestep Consumption Time: 2.51566
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.77719

Cumulative Model Updates: 94,792
Cumulative Timesteps: 790,597,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.17551
Policy Entropy: 3.22931
Value Function Loss: 0.00440

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.56083
Value Function Update Magnitude: 0.60938

Collected Steps per Second: 21,879.17534
Overall Steps per Second: 10,354.71288

Timestep Collection Time: 2.28619
Timestep Consumption Time: 2.54446
PPO Batch Consumption Time: 0.30012
Total Iteration Time: 4.83065

Cumulative Model Updates: 94,798
Cumulative Timesteps: 790,647,306

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 790647306...
Checkpoint 790647306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.53895
Policy Entropy: 3.22419
Value Function Loss: 0.00431

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.55272
Value Function Update Magnitude: 0.59841

Collected Steps per Second: 22,401.51778
Overall Steps per Second: 10,612.65460

Timestep Collection Time: 2.23253
Timestep Consumption Time: 2.47996
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.71249

Cumulative Model Updates: 94,804
Cumulative Timesteps: 790,697,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.34717
Policy Entropy: 3.23990
Value Function Loss: 0.00405

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.53906
Value Function Update Magnitude: 0.60383

Collected Steps per Second: 22,144.99085
Overall Steps per Second: 10,430.34287

Timestep Collection Time: 2.25884
Timestep Consumption Time: 2.53698
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.79582

Cumulative Model Updates: 94,810
Cumulative Timesteps: 790,747,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 790747340...
Checkpoint 790747340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.64753
Policy Entropy: 3.24375
Value Function Loss: 0.00417

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.09091
Policy Update Magnitude: 0.53823
Value Function Update Magnitude: 0.60491

Collected Steps per Second: 22,132.06993
Overall Steps per Second: 10,339.20929

Timestep Collection Time: 2.25998
Timestep Consumption Time: 2.57772
PPO Batch Consumption Time: 0.29949
Total Iteration Time: 4.83770

Cumulative Model Updates: 94,816
Cumulative Timesteps: 790,797,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,886.89415
Policy Entropy: 3.23215
Value Function Loss: 0.00443

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.54402
Value Function Update Magnitude: 0.59018

Collected Steps per Second: 22,167.80454
Overall Steps per Second: 10,481.34434

Timestep Collection Time: 2.25588
Timestep Consumption Time: 2.51526
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.77114

Cumulative Model Updates: 94,822
Cumulative Timesteps: 790,847,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 790847366...
Checkpoint 790847366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.14148
Policy Entropy: 3.21575
Value Function Loss: 0.00463

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.60750

Collected Steps per Second: 22,222.16791
Overall Steps per Second: 10,563.24558

Timestep Collection Time: 2.25028
Timestep Consumption Time: 2.48369
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.73396

Cumulative Model Updates: 94,828
Cumulative Timesteps: 790,897,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,475.07995
Policy Entropy: 3.21715
Value Function Loss: 0.00435

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.55418
Value Function Update Magnitude: 0.61044

Collected Steps per Second: 22,185.11842
Overall Steps per Second: 10,496.89933

Timestep Collection Time: 2.25494
Timestep Consumption Time: 2.51085
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.76579

Cumulative Model Updates: 94,834
Cumulative Timesteps: 790,947,398

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 790947398...
Checkpoint 790947398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.99189
Policy Entropy: 3.20306
Value Function Loss: 0.00447

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.55118
Value Function Update Magnitude: 0.60635

Collected Steps per Second: 20,531.87409
Overall Steps per Second: 9,983.36492

Timestep Collection Time: 2.43524
Timestep Consumption Time: 2.57309
PPO Batch Consumption Time: 0.30139
Total Iteration Time: 5.00833

Cumulative Model Updates: 94,840
Cumulative Timesteps: 790,997,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.63697
Policy Entropy: 3.20914
Value Function Loss: 0.00457

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08754
Policy Update Magnitude: 0.55661
Value Function Update Magnitude: 0.62518

Collected Steps per Second: 21,609.88175
Overall Steps per Second: 10,355.05782

Timestep Collection Time: 2.31450
Timestep Consumption Time: 2.51561
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.83010

Cumulative Model Updates: 94,846
Cumulative Timesteps: 791,047,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 791047414...
Checkpoint 791047414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.71548
Policy Entropy: 3.19834
Value Function Loss: 0.00454

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09270
Policy Update Magnitude: 0.55327
Value Function Update Magnitude: 0.63286

Collected Steps per Second: 22,203.77408
Overall Steps per Second: 10,639.95149

Timestep Collection Time: 2.25232
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.70021

Cumulative Model Updates: 94,852
Cumulative Timesteps: 791,097,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.28615
Policy Entropy: 3.20995
Value Function Loss: 0.00429

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.54576
Value Function Update Magnitude: 0.59774

Collected Steps per Second: 21,908.76670
Overall Steps per Second: 10,462.60466

Timestep Collection Time: 2.28329
Timestep Consumption Time: 2.49793
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.78122

Cumulative Model Updates: 94,858
Cumulative Timesteps: 791,147,448

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 791147448...
Checkpoint 791147448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.89529
Policy Entropy: 3.20996
Value Function Loss: 0.00449

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.54242
Value Function Update Magnitude: 0.57347

Collected Steps per Second: 22,105.01384
Overall Steps per Second: 10,526.86270

Timestep Collection Time: 2.26302
Timestep Consumption Time: 2.48902
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.75203

Cumulative Model Updates: 94,864
Cumulative Timesteps: 791,197,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.07687
Policy Entropy: 3.22906
Value Function Loss: 0.00440

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08405
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.59207

Collected Steps per Second: 22,165.45741
Overall Steps per Second: 10,576.46223

Timestep Collection Time: 2.25648
Timestep Consumption Time: 2.47251
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.72899

Cumulative Model Updates: 94,870
Cumulative Timesteps: 791,247,488

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 791247488...
Checkpoint 791247488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.66759
Policy Entropy: 3.22892
Value Function Loss: 0.00446

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.53708
Value Function Update Magnitude: 0.60654

Collected Steps per Second: 22,046.52517
Overall Steps per Second: 10,515.60528

Timestep Collection Time: 2.26848
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.75598

Cumulative Model Updates: 94,876
Cumulative Timesteps: 791,297,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.59192
Policy Entropy: 3.23369
Value Function Loss: 0.00442

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.53406
Value Function Update Magnitude: 0.60248

Collected Steps per Second: 22,378.44284
Overall Steps per Second: 10,488.61751

Timestep Collection Time: 2.23581
Timestep Consumption Time: 2.53450
PPO Batch Consumption Time: 0.29527
Total Iteration Time: 4.77031

Cumulative Model Updates: 94,882
Cumulative Timesteps: 791,347,534

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 791347534...
Checkpoint 791347534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.03579
Policy Entropy: 3.23702
Value Function Loss: 0.00422

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08927
Policy Update Magnitude: 0.53332
Value Function Update Magnitude: 0.59712

Collected Steps per Second: 21,768.42402
Overall Steps per Second: 10,264.47636

Timestep Collection Time: 2.29810
Timestep Consumption Time: 2.57560
PPO Batch Consumption Time: 0.29990
Total Iteration Time: 4.87370

Cumulative Model Updates: 94,888
Cumulative Timesteps: 791,397,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.13900
Policy Entropy: 3.22640
Value Function Loss: 0.00440

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.53555
Value Function Update Magnitude: 0.59480

Collected Steps per Second: 22,595.32740
Overall Steps per Second: 10,476.27057

Timestep Collection Time: 2.21417
Timestep Consumption Time: 2.56138
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 4.77555

Cumulative Model Updates: 94,894
Cumulative Timesteps: 791,447,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 791447590...
Checkpoint 791447590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.35585
Policy Entropy: 3.20999
Value Function Loss: 0.00448

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.59616

Collected Steps per Second: 22,088.38480
Overall Steps per Second: 10,574.71259

Timestep Collection Time: 2.26454
Timestep Consumption Time: 2.46561
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.73015

Cumulative Model Updates: 94,900
Cumulative Timesteps: 791,497,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.20836
Policy Entropy: 3.18917
Value Function Loss: 0.00465

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11689
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.61278

Collected Steps per Second: 22,292.33742
Overall Steps per Second: 10,511.47833

Timestep Collection Time: 2.24364
Timestep Consumption Time: 2.51459
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.75823

Cumulative Model Updates: 94,906
Cumulative Timesteps: 791,547,626

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 791547626...
Checkpoint 791547626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.25596
Policy Entropy: 3.18256
Value Function Loss: 0.00460

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.55470
Value Function Update Magnitude: 0.62723

Collected Steps per Second: 21,727.98631
Overall Steps per Second: 10,438.37152

Timestep Collection Time: 2.30127
Timestep Consumption Time: 2.48894
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.79021

Cumulative Model Updates: 94,912
Cumulative Timesteps: 791,597,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,378.73119
Policy Entropy: 3.20367
Value Function Loss: 0.00449

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.54724
Value Function Update Magnitude: 0.62308

Collected Steps per Second: 22,054.09552
Overall Steps per Second: 10,333.84093

Timestep Collection Time: 2.26715
Timestep Consumption Time: 2.57132
PPO Batch Consumption Time: 0.30274
Total Iteration Time: 4.83847

Cumulative Model Updates: 94,918
Cumulative Timesteps: 791,647,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 791647628...
Checkpoint 791647628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.97076
Policy Entropy: 3.21806
Value Function Loss: 0.00450

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10827
Policy Update Magnitude: 0.54831
Value Function Update Magnitude: 0.63629

Collected Steps per Second: 22,072.06726
Overall Steps per Second: 10,404.74240

Timestep Collection Time: 2.26667
Timestep Consumption Time: 2.54172
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.80838

Cumulative Model Updates: 94,924
Cumulative Timesteps: 791,697,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770.93477
Policy Entropy: 3.19990
Value Function Loss: 0.00469

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.55687
Value Function Update Magnitude: 0.65505

Collected Steps per Second: 22,206.31110
Overall Steps per Second: 10,442.06510

Timestep Collection Time: 2.25251
Timestep Consumption Time: 2.53773
PPO Batch Consumption Time: 0.29826
Total Iteration Time: 4.79024

Cumulative Model Updates: 94,930
Cumulative Timesteps: 791,747,678

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 791747678...
Checkpoint 791747678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.57595
Policy Entropy: 3.21256
Value Function Loss: 0.00470

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10516
Policy Update Magnitude: 0.56119
Value Function Update Magnitude: 0.66846

Collected Steps per Second: 21,555.79319
Overall Steps per Second: 10,327.42424

Timestep Collection Time: 2.32040
Timestep Consumption Time: 2.52282
PPO Batch Consumption Time: 0.29356
Total Iteration Time: 4.84322

Cumulative Model Updates: 94,936
Cumulative Timesteps: 791,797,696

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,727.08932
Policy Entropy: 3.19682
Value Function Loss: 0.00465

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.55620
Value Function Update Magnitude: 0.65331

Collected Steps per Second: 21,984.39106
Overall Steps per Second: 10,462.85257

Timestep Collection Time: 2.27507
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.78034

Cumulative Model Updates: 94,942
Cumulative Timesteps: 791,847,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 791847712...
Checkpoint 791847712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.89438
Policy Entropy: 3.22253
Value Function Loss: 0.00460

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.54785
Value Function Update Magnitude: 0.62037

Collected Steps per Second: 21,674.72572
Overall Steps per Second: 10,281.19056

Timestep Collection Time: 2.30776
Timestep Consumption Time: 2.55744
PPO Batch Consumption Time: 0.29928
Total Iteration Time: 4.86520

Cumulative Model Updates: 94,948
Cumulative Timesteps: 791,897,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.28130
Policy Entropy: 3.21039
Value Function Loss: 0.00454

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.54241
Value Function Update Magnitude: 0.60493

Collected Steps per Second: 22,058.43121
Overall Steps per Second: 10,523.24425

Timestep Collection Time: 2.26780
Timestep Consumption Time: 2.48587
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.75367

Cumulative Model Updates: 94,954
Cumulative Timesteps: 791,947,756

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 791947756...
Checkpoint 791947756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.69669
Policy Entropy: 3.22208
Value Function Loss: 0.00449

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08586
Policy Update Magnitude: 0.53805
Value Function Update Magnitude: 0.59806

Collected Steps per Second: 21,838.17043
Overall Steps per Second: 10,546.23564

Timestep Collection Time: 2.29058
Timestep Consumption Time: 2.45254
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.74311

Cumulative Model Updates: 94,960
Cumulative Timesteps: 791,997,778

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.16362
Policy Entropy: 3.21096
Value Function Loss: 0.00422

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.08582
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.59905

Collected Steps per Second: 22,161.02916
Overall Steps per Second: 10,505.77531

Timestep Collection Time: 2.25657
Timestep Consumption Time: 2.50347
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.76005

Cumulative Model Updates: 94,966
Cumulative Timesteps: 792,047,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 792047786...
Checkpoint 792047786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.19745
Policy Entropy: 3.21481
Value Function Loss: 0.00415

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08952
Policy Update Magnitude: 0.52968
Value Function Update Magnitude: 0.58256

Collected Steps per Second: 21,995.88217
Overall Steps per Second: 10,394.07219

Timestep Collection Time: 2.27333
Timestep Consumption Time: 2.53748
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.81082

Cumulative Model Updates: 94,972
Cumulative Timesteps: 792,097,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.15356
Policy Entropy: 3.21505
Value Function Loss: 0.00426

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08747
Policy Update Magnitude: 0.52687
Value Function Update Magnitude: 0.57890

Collected Steps per Second: 22,393.67048
Overall Steps per Second: 10,480.17436

Timestep Collection Time: 2.23304
Timestep Consumption Time: 2.53844
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.77149

Cumulative Model Updates: 94,978
Cumulative Timesteps: 792,147,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 792147796...
Checkpoint 792147796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 931.50122
Policy Entropy: 3.20998
Value Function Loss: 0.00459

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.54297
Value Function Update Magnitude: 0.59632

Collected Steps per Second: 21,793.27034
Overall Steps per Second: 10,361.88173

Timestep Collection Time: 2.29566
Timestep Consumption Time: 2.53261
PPO Batch Consumption Time: 0.29774
Total Iteration Time: 4.82827

Cumulative Model Updates: 94,984
Cumulative Timesteps: 792,197,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.72907
Policy Entropy: 3.19998
Value Function Loss: 0.00459

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10590
Policy Update Magnitude: 0.55157
Value Function Update Magnitude: 0.62217

Collected Steps per Second: 21,941.35745
Overall Steps per Second: 10,349.52511

Timestep Collection Time: 2.27971
Timestep Consumption Time: 2.55336
PPO Batch Consumption Time: 0.29915
Total Iteration Time: 4.83307

Cumulative Model Updates: 94,990
Cumulative Timesteps: 792,247,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 792247846...
Checkpoint 792247846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.85100
Policy Entropy: 3.20338
Value Function Loss: 0.00466

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.54600
Value Function Update Magnitude: 0.64034

Collected Steps per Second: 21,487.60423
Overall Steps per Second: 10,179.37527

Timestep Collection Time: 2.32804
Timestep Consumption Time: 2.58621
PPO Batch Consumption Time: 0.30539
Total Iteration Time: 4.91425

Cumulative Model Updates: 94,996
Cumulative Timesteps: 792,297,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.36048
Policy Entropy: 3.20650
Value Function Loss: 0.00451

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.54804
Value Function Update Magnitude: 0.63529

Collected Steps per Second: 22,775.48170
Overall Steps per Second: 10,657.19292

Timestep Collection Time: 2.19631
Timestep Consumption Time: 2.49742
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.69373

Cumulative Model Updates: 95,002
Cumulative Timesteps: 792,347,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 792347892...
Checkpoint 792347892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.65428
Policy Entropy: 3.20799
Value Function Loss: 0.00456

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.07658
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.62244

Collected Steps per Second: 21,696.64710
Overall Steps per Second: 10,369.85735

Timestep Collection Time: 2.30561
Timestep Consumption Time: 2.51837
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.82398

Cumulative Model Updates: 95,008
Cumulative Timesteps: 792,397,916

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.37011
Policy Entropy: 3.19548
Value Function Loss: 0.00465

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08417
Policy Update Magnitude: 0.55572
Value Function Update Magnitude: 0.61486

Collected Steps per Second: 22,581.14416
Overall Steps per Second: 10,617.44502

Timestep Collection Time: 2.21477
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.71036

Cumulative Model Updates: 95,014
Cumulative Timesteps: 792,447,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 792447928...
Checkpoint 792447928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.84443
Policy Entropy: 3.17649
Value Function Loss: 0.00468

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.56176
Value Function Update Magnitude: 0.61013

Collected Steps per Second: 21,576.03949
Overall Steps per Second: 10,393.92113

Timestep Collection Time: 2.31841
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.81262

Cumulative Model Updates: 95,020
Cumulative Timesteps: 792,497,950

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.84490
Policy Entropy: 3.18211
Value Function Loss: 0.00477

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09783
Policy Update Magnitude: 0.56668
Value Function Update Magnitude: 0.62196

Collected Steps per Second: 21,947.50737
Overall Steps per Second: 10,425.32774

Timestep Collection Time: 2.27907
Timestep Consumption Time: 2.51886
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.79793

Cumulative Model Updates: 95,026
Cumulative Timesteps: 792,547,970

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 792547970...
Checkpoint 792547970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.95618
Policy Entropy: 3.17862
Value Function Loss: 0.00478

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.63120

Collected Steps per Second: 21,773.69193
Overall Steps per Second: 10,437.24909

Timestep Collection Time: 2.29754
Timestep Consumption Time: 2.49548
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.79303

Cumulative Model Updates: 95,032
Cumulative Timesteps: 792,597,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642.65310
Policy Entropy: 3.17159
Value Function Loss: 0.00490

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.56008
Value Function Update Magnitude: 0.63611

Collected Steps per Second: 22,181.84392
Overall Steps per Second: 10,572.81784

Timestep Collection Time: 2.25446
Timestep Consumption Time: 2.47541
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.72986

Cumulative Model Updates: 95,038
Cumulative Timesteps: 792,648,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 792648004...
Checkpoint 792648004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.52884
Policy Entropy: 3.17600
Value Function Loss: 0.00476

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.56771
Value Function Update Magnitude: 0.61883

Collected Steps per Second: 21,890.28617
Overall Steps per Second: 10,373.41257

Timestep Collection Time: 2.28503
Timestep Consumption Time: 2.53691
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.82194

Cumulative Model Updates: 95,044
Cumulative Timesteps: 792,698,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.72375
Policy Entropy: 3.18008
Value Function Loss: 0.00497

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.56884
Value Function Update Magnitude: 0.64248

Collected Steps per Second: 22,186.57087
Overall Steps per Second: 10,518.78655

Timestep Collection Time: 2.25362
Timestep Consumption Time: 2.49978
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.75340

Cumulative Model Updates: 95,050
Cumulative Timesteps: 792,748,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 792748024...
Checkpoint 792748024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.34964
Policy Entropy: 3.20823
Value Function Loss: 0.00467

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.56307
Value Function Update Magnitude: 0.65126

Collected Steps per Second: 21,817.91431
Overall Steps per Second: 10,508.92723

Timestep Collection Time: 2.29188
Timestep Consumption Time: 2.46636
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.75824

Cumulative Model Updates: 95,056
Cumulative Timesteps: 792,798,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.71373
Policy Entropy: 3.19958
Value Function Loss: 0.00481

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.55744
Value Function Update Magnitude: 0.65217

Collected Steps per Second: 22,224.55057
Overall Steps per Second: 10,554.99425

Timestep Collection Time: 2.25147
Timestep Consumption Time: 2.48922
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.74069

Cumulative Model Updates: 95,062
Cumulative Timesteps: 792,848,066

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 792848066...
Checkpoint 792848066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.85005
Policy Entropy: 3.19678
Value Function Loss: 0.00467

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11289
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.65560

Collected Steps per Second: 21,757.96625
Overall Steps per Second: 10,408.40050

Timestep Collection Time: 2.29893
Timestep Consumption Time: 2.50681
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.80573

Cumulative Model Updates: 95,068
Cumulative Timesteps: 792,898,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.58449
Policy Entropy: 3.19517
Value Function Loss: 0.00476

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11093
Policy Update Magnitude: 0.55528
Value Function Update Magnitude: 0.64237

Collected Steps per Second: 22,351.89590
Overall Steps per Second: 10,441.85572

Timestep Collection Time: 2.23820
Timestep Consumption Time: 2.55290
PPO Batch Consumption Time: 0.30175
Total Iteration Time: 4.79110

Cumulative Model Updates: 95,074
Cumulative Timesteps: 792,948,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 792948114...
Checkpoint 792948114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,459.76879
Policy Entropy: 3.20261
Value Function Loss: 0.00451

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11710
Policy Update Magnitude: 0.54456
Value Function Update Magnitude: 0.62044

Collected Steps per Second: 22,067.50385
Overall Steps per Second: 10,449.44695

Timestep Collection Time: 2.26704
Timestep Consumption Time: 2.52058
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.78762

Cumulative Model Updates: 95,080
Cumulative Timesteps: 792,998,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.36053
Policy Entropy: 3.21221
Value Function Loss: 0.00440

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.53648
Value Function Update Magnitude: 0.59834

Collected Steps per Second: 22,169.10701
Overall Steps per Second: 10,408.03949

Timestep Collection Time: 2.25539
Timestep Consumption Time: 2.54859
PPO Batch Consumption Time: 0.30041
Total Iteration Time: 4.80398

Cumulative Model Updates: 95,086
Cumulative Timesteps: 793,048,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 793048142...
Checkpoint 793048142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.29420
Policy Entropy: 3.21284
Value Function Loss: 0.00452

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09381
Policy Update Magnitude: 0.53300
Value Function Update Magnitude: 0.59164

Collected Steps per Second: 22,160.02662
Overall Steps per Second: 10,391.13840

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.55630
PPO Batch Consumption Time: 0.30080
Total Iteration Time: 4.81333

Cumulative Model Updates: 95,092
Cumulative Timesteps: 793,098,158

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 701.84105
Policy Entropy: 3.20046
Value Function Loss: 0.00481

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.54825
Value Function Update Magnitude: 0.61043

Collected Steps per Second: 21,759.02536
Overall Steps per Second: 10,428.28956

Timestep Collection Time: 2.29882
Timestep Consumption Time: 2.49775
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.79657

Cumulative Model Updates: 95,098
Cumulative Timesteps: 793,148,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 793148178...
Checkpoint 793148178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.37989
Policy Entropy: 3.18893
Value Function Loss: 0.00496

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.56258
Value Function Update Magnitude: 0.62668

Collected Steps per Second: 21,996.01815
Overall Steps per Second: 10,464.10708

Timestep Collection Time: 2.27387
Timestep Consumption Time: 2.50590
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.77977

Cumulative Model Updates: 95,104
Cumulative Timesteps: 793,198,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.65712
Policy Entropy: 3.18013
Value Function Loss: 0.00456

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09228
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.63827

Collected Steps per Second: 22,318.73958
Overall Steps per Second: 10,643.94301

Timestep Collection Time: 2.24045
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.69788

Cumulative Model Updates: 95,110
Cumulative Timesteps: 793,248,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 793248198...
Checkpoint 793248198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.13262
Policy Entropy: 3.18476
Value Function Loss: 0.00453

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.55430
Value Function Update Magnitude: 0.62285

Collected Steps per Second: 21,786.15452
Overall Steps per Second: 10,470.10486

Timestep Collection Time: 2.29568
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.77684

Cumulative Model Updates: 95,116
Cumulative Timesteps: 793,298,212

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.30569
Policy Entropy: 3.17813
Value Function Loss: 0.00423

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10565
Policy Update Magnitude: 0.55201
Value Function Update Magnitude: 0.61790

Collected Steps per Second: 22,382.47935
Overall Steps per Second: 10,497.82931

Timestep Collection Time: 2.23559
Timestep Consumption Time: 2.53092
PPO Batch Consumption Time: 0.30047
Total Iteration Time: 4.76651

Cumulative Model Updates: 95,122
Cumulative Timesteps: 793,348,250

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 793348250...
Checkpoint 793348250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.69163
Policy Entropy: 3.18235
Value Function Loss: 0.00425

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.54469
Value Function Update Magnitude: 0.61022

Collected Steps per Second: 21,791.71312
Overall Steps per Second: 10,397.79183

Timestep Collection Time: 2.29518
Timestep Consumption Time: 2.51507
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 4.81025

Cumulative Model Updates: 95,128
Cumulative Timesteps: 793,398,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.81398
Policy Entropy: 3.17805
Value Function Loss: 0.00436

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.54065
Value Function Update Magnitude: 0.60607

Collected Steps per Second: 22,186.91576
Overall Steps per Second: 10,436.81950

Timestep Collection Time: 2.25448
Timestep Consumption Time: 2.53817
PPO Batch Consumption Time: 0.29710
Total Iteration Time: 4.79265

Cumulative Model Updates: 95,134
Cumulative Timesteps: 793,448,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 793448286...
Checkpoint 793448286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.34809
Policy Entropy: 3.17332
Value Function Loss: 0.00436

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.54556
Value Function Update Magnitude: 0.60591

Collected Steps per Second: 22,089.33768
Overall Steps per Second: 10,487.99200

Timestep Collection Time: 2.26354
Timestep Consumption Time: 2.50382
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.76736

Cumulative Model Updates: 95,140
Cumulative Timesteps: 793,498,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.03385
Policy Entropy: 3.16952
Value Function Loss: 0.00452

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.55928
Value Function Update Magnitude: 0.60498

Collected Steps per Second: 21,757.24542
Overall Steps per Second: 10,338.07678

Timestep Collection Time: 2.29836
Timestep Consumption Time: 2.53871
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.83707

Cumulative Model Updates: 95,146
Cumulative Timesteps: 793,548,292

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 793548292...
Checkpoint 793548292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.95123
Policy Entropy: 3.18308
Value Function Loss: 0.00446

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.61475

Collected Steps per Second: 22,421.33966
Overall Steps per Second: 10,533.62657

Timestep Collection Time: 2.23002
Timestep Consumption Time: 2.51668
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 4.74670

Cumulative Model Updates: 95,152
Cumulative Timesteps: 793,598,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.03477
Policy Entropy: 3.18454
Value Function Loss: 0.00439

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08906
Policy Update Magnitude: 0.55953
Value Function Update Magnitude: 0.65197

Collected Steps per Second: 22,266.17148
Overall Steps per Second: 10,598.12220

Timestep Collection Time: 2.24628
Timestep Consumption Time: 2.47305
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.71933

Cumulative Model Updates: 95,158
Cumulative Timesteps: 793,648,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 793648308...
Checkpoint 793648308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.09172
Policy Entropy: 3.18168
Value Function Loss: 0.00444

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.56385
Value Function Update Magnitude: 0.65316

Collected Steps per Second: 22,051.23888
Overall Steps per Second: 10,437.42998

Timestep Collection Time: 2.26745
Timestep Consumption Time: 2.52301
PPO Batch Consumption Time: 0.29704
Total Iteration Time: 4.79045

Cumulative Model Updates: 95,164
Cumulative Timesteps: 793,698,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.62780
Policy Entropy: 3.18212
Value Function Loss: 0.00447

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.56813
Value Function Update Magnitude: 0.64328

Collected Steps per Second: 21,956.55335
Overall Steps per Second: 10,397.38369

Timestep Collection Time: 2.27759
Timestep Consumption Time: 2.53208
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.80967

Cumulative Model Updates: 95,170
Cumulative Timesteps: 793,748,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 793748316...
Checkpoint 793748316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.01632
Policy Entropy: 3.19279
Value Function Loss: 0.00457

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.56794
Value Function Update Magnitude: 0.62140

Collected Steps per Second: 21,908.81480
Overall Steps per Second: 10,412.90155

Timestep Collection Time: 2.28246
Timestep Consumption Time: 2.51985
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.80231

Cumulative Model Updates: 95,176
Cumulative Timesteps: 793,798,322

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.86280
Policy Entropy: 3.19868
Value Function Loss: 0.00467

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.55801
Value Function Update Magnitude: 0.61097

Collected Steps per Second: 22,084.58007
Overall Steps per Second: 10,450.64435

Timestep Collection Time: 2.26547
Timestep Consumption Time: 2.52198
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.78746

Cumulative Model Updates: 95,182
Cumulative Timesteps: 793,848,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 793848354...
Checkpoint 793848354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.99157
Policy Entropy: 3.20210
Value Function Loss: 0.00465

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11215
Policy Update Magnitude: 0.55027
Value Function Update Magnitude: 0.61026

Collected Steps per Second: 22,041.97634
Overall Steps per Second: 10,546.81413

Timestep Collection Time: 2.26958
Timestep Consumption Time: 2.47365
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.74323

Cumulative Model Updates: 95,188
Cumulative Timesteps: 793,898,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.36580
Policy Entropy: 3.20649
Value Function Loss: 0.00448

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.54643
Value Function Update Magnitude: 0.59427

Collected Steps per Second: 22,324.33671
Overall Steps per Second: 10,591.92642

Timestep Collection Time: 2.23971
Timestep Consumption Time: 2.48087
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.72058

Cumulative Model Updates: 95,194
Cumulative Timesteps: 793,948,380

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 793948380...
Checkpoint 793948380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.33607
Policy Entropy: 3.19771
Value Function Loss: 0.00461

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.55467
Value Function Update Magnitude: 0.61896

Collected Steps per Second: 22,181.09324
Overall Steps per Second: 10,639.91879

Timestep Collection Time: 2.25507
Timestep Consumption Time: 2.44609
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.70116

Cumulative Model Updates: 95,200
Cumulative Timesteps: 793,998,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.03332
Policy Entropy: 3.19566
Value Function Loss: 0.00483

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12650
Policy Update Magnitude: 0.56122
Value Function Update Magnitude: 0.64726

Collected Steps per Second: 21,911.42965
Overall Steps per Second: 10,460.43175

Timestep Collection Time: 2.28264
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.78145

Cumulative Model Updates: 95,206
Cumulative Timesteps: 794,048,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 794048416...
Checkpoint 794048416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.69588
Policy Entropy: 3.20538
Value Function Loss: 0.00492

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.56807
Value Function Update Magnitude: 0.64834

Collected Steps per Second: 22,049.52252
Overall Steps per Second: 10,574.17316

Timestep Collection Time: 2.26762
Timestep Consumption Time: 2.46088
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.72850

Cumulative Model Updates: 95,212
Cumulative Timesteps: 794,098,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.92898
Policy Entropy: 3.20886
Value Function Loss: 0.00461

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.55816
Value Function Update Magnitude: 0.62707

Collected Steps per Second: 21,806.07821
Overall Steps per Second: 10,469.48195

Timestep Collection Time: 2.29413
Timestep Consumption Time: 2.48414
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.77827

Cumulative Model Updates: 95,218
Cumulative Timesteps: 794,148,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 794148442...
Checkpoint 794148442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.52067
Policy Entropy: 3.20464
Value Function Loss: 0.00454

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.55264
Value Function Update Magnitude: 0.61827

Collected Steps per Second: 22,040.84590
Overall Steps per Second: 10,349.97252

Timestep Collection Time: 2.26924
Timestep Consumption Time: 2.56324
PPO Batch Consumption Time: 0.30563
Total Iteration Time: 4.83248

Cumulative Model Updates: 95,224
Cumulative Timesteps: 794,198,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.29735
Policy Entropy: 3.19379
Value Function Loss: 0.00442

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.54877
Value Function Update Magnitude: 0.63105

Collected Steps per Second: 22,143.76154
Overall Steps per Second: 10,308.55962

Timestep Collection Time: 2.25897
Timestep Consumption Time: 2.59351
PPO Batch Consumption Time: 0.30760
Total Iteration Time: 4.85247

Cumulative Model Updates: 95,230
Cumulative Timesteps: 794,248,480

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 794248480...
Checkpoint 794248480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 890.71107
Policy Entropy: 3.18957
Value Function Loss: 0.00469

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.54803
Value Function Update Magnitude: 0.62724

Collected Steps per Second: 21,853.25893
Overall Steps per Second: 10,357.59437

Timestep Collection Time: 2.28909
Timestep Consumption Time: 2.54061
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.82969

Cumulative Model Updates: 95,236
Cumulative Timesteps: 794,298,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.44752
Policy Entropy: 3.19231
Value Function Loss: 0.00469

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.09013
Policy Update Magnitude: 0.55306
Value Function Update Magnitude: 0.61966

Collected Steps per Second: 22,021.93625
Overall Steps per Second: 10,455.66237

Timestep Collection Time: 2.27101
Timestep Consumption Time: 2.51224
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.78325

Cumulative Model Updates: 95,242
Cumulative Timesteps: 794,348,516

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 794348516...
Checkpoint 794348516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,746.16874
Policy Entropy: 3.19367
Value Function Loss: 0.00467

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.55392
Value Function Update Magnitude: 0.59970

Collected Steps per Second: 21,809.06005
Overall Steps per Second: 10,363.59591

Timestep Collection Time: 2.29501
Timestep Consumption Time: 2.53459
PPO Batch Consumption Time: 0.29833
Total Iteration Time: 4.82960

Cumulative Model Updates: 95,248
Cumulative Timesteps: 794,398,568

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.76310
Policy Entropy: 3.18669
Value Function Loss: 0.00462

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.55512
Value Function Update Magnitude: 0.60334

Collected Steps per Second: 22,356.54557
Overall Steps per Second: 10,431.61859

Timestep Collection Time: 2.23818
Timestep Consumption Time: 2.55858
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 4.79676

Cumulative Model Updates: 95,254
Cumulative Timesteps: 794,448,606

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 794448606...
Checkpoint 794448606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 891.38019
Policy Entropy: 3.18449
Value Function Loss: 0.00457

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.55568
Value Function Update Magnitude: 0.61777

Collected Steps per Second: 21,817.39331
Overall Steps per Second: 10,499.78921

Timestep Collection Time: 2.29202
Timestep Consumption Time: 2.47055
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.76257

Cumulative Model Updates: 95,260
Cumulative Timesteps: 794,498,612

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.11220
Policy Entropy: 3.19301
Value Function Loss: 0.00429

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.54305
Value Function Update Magnitude: 0.62259

Collected Steps per Second: 22,146.23527
Overall Steps per Second: 10,510.48016

Timestep Collection Time: 2.25898
Timestep Consumption Time: 2.50084
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.75982

Cumulative Model Updates: 95,266
Cumulative Timesteps: 794,548,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 794548640...
Checkpoint 794548640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.19844
Policy Entropy: 3.18965
Value Function Loss: 0.00438

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.53131
Value Function Update Magnitude: 0.60937

Collected Steps per Second: 22,234.01438
Overall Steps per Second: 10,481.75768

Timestep Collection Time: 2.24971
Timestep Consumption Time: 2.52239
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 4.77210

Cumulative Model Updates: 95,272
Cumulative Timesteps: 794,598,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.45885
Policy Entropy: 3.18482
Value Function Loss: 0.00460

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.53553
Value Function Update Magnitude: 0.60630

Collected Steps per Second: 22,152.93768
Overall Steps per Second: 10,439.68225

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.53238
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.78942

Cumulative Model Updates: 95,278
Cumulative Timesteps: 794,648,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 794648660...
Checkpoint 794648660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.40519
Policy Entropy: 3.18311
Value Function Loss: 0.00471

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.54436
Value Function Update Magnitude: 0.60793

Collected Steps per Second: 22,115.43518
Overall Steps per Second: 10,381.71756

Timestep Collection Time: 2.26114
Timestep Consumption Time: 2.55560
PPO Batch Consumption Time: 0.29926
Total Iteration Time: 4.81674

Cumulative Model Updates: 95,284
Cumulative Timesteps: 794,698,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.03899
Policy Entropy: 3.18060
Value Function Loss: 0.00461

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.54636
Value Function Update Magnitude: 0.59139

Collected Steps per Second: 21,721.00304
Overall Steps per Second: 10,454.47630

Timestep Collection Time: 2.30302
Timestep Consumption Time: 2.48191
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.78494

Cumulative Model Updates: 95,290
Cumulative Timesteps: 794,748,690

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 794748690...
Checkpoint 794748690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.15270
Policy Entropy: 3.18556
Value Function Loss: 0.00461

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09477
Policy Update Magnitude: 0.54612
Value Function Update Magnitude: 0.58627

Collected Steps per Second: 21,441.03016
Overall Steps per Second: 10,276.35737

Timestep Collection Time: 2.33244
Timestep Consumption Time: 2.53407
PPO Batch Consumption Time: 0.29965
Total Iteration Time: 4.86651

Cumulative Model Updates: 95,296
Cumulative Timesteps: 794,798,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.59288
Policy Entropy: 3.19530
Value Function Loss: 0.00443

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.54240
Value Function Update Magnitude: 0.58870

Collected Steps per Second: 22,399.21295
Overall Steps per Second: 10,348.28937

Timestep Collection Time: 2.23294
Timestep Consumption Time: 2.60033
PPO Batch Consumption Time: 0.30877
Total Iteration Time: 4.83326

Cumulative Model Updates: 95,302
Cumulative Timesteps: 794,848,716

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 794848716...
Checkpoint 794848716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.71363
Policy Entropy: 3.20697
Value Function Loss: 0.00449

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08454
Policy Update Magnitude: 0.53722
Value Function Update Magnitude: 0.58228

Collected Steps per Second: 21,817.45793
Overall Steps per Second: 10,397.52425

Timestep Collection Time: 2.29266
Timestep Consumption Time: 2.51810
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.81076

Cumulative Model Updates: 95,308
Cumulative Timesteps: 794,898,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.27301
Policy Entropy: 3.21064
Value Function Loss: 0.00434

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.53611
Value Function Update Magnitude: 0.57600

Collected Steps per Second: 22,639.50590
Overall Steps per Second: 10,665.74244

Timestep Collection Time: 2.20968
Timestep Consumption Time: 2.48067
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.69034

Cumulative Model Updates: 95,314
Cumulative Timesteps: 794,948,762

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 794948762...
Checkpoint 794948762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.27824
Policy Entropy: 3.21080
Value Function Loss: 0.00450

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.53680
Value Function Update Magnitude: 0.60319

Collected Steps per Second: 21,713.96401
Overall Steps per Second: 10,360.52329

Timestep Collection Time: 2.30276
Timestep Consumption Time: 2.52345
PPO Batch Consumption Time: 0.29784
Total Iteration Time: 4.82620

Cumulative Model Updates: 95,320
Cumulative Timesteps: 794,998,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.63195
Policy Entropy: 3.21509
Value Function Loss: 0.00433

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10234
Policy Update Magnitude: 0.54004
Value Function Update Magnitude: 0.62514

Collected Steps per Second: 22,311.71326
Overall Steps per Second: 10,440.69926

Timestep Collection Time: 2.24241
Timestep Consumption Time: 2.54961
PPO Batch Consumption Time: 0.30079
Total Iteration Time: 4.79202

Cumulative Model Updates: 95,326
Cumulative Timesteps: 795,048,796

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 795048796...
Checkpoint 795048796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.22393
Policy Entropy: 3.21667
Value Function Loss: 0.00431

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.54031
Value Function Update Magnitude: 0.61013

Collected Steps per Second: 21,904.67965
Overall Steps per Second: 10,361.80075

Timestep Collection Time: 2.28326
Timestep Consumption Time: 2.54351
PPO Batch Consumption Time: 0.29906
Total Iteration Time: 4.82677

Cumulative Model Updates: 95,332
Cumulative Timesteps: 795,098,810

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,041.69737
Policy Entropy: 3.20613
Value Function Loss: 0.00445

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09644
Policy Update Magnitude: 0.53233
Value Function Update Magnitude: 0.58992

Collected Steps per Second: 22,194.08308
Overall Steps per Second: 10,579.48897

Timestep Collection Time: 2.25285
Timestep Consumption Time: 2.47327
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.72613

Cumulative Model Updates: 95,338
Cumulative Timesteps: 795,148,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 795148810...
Checkpoint 795148810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.84953
Policy Entropy: 3.19765
Value Function Loss: 0.00447

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.53914
Value Function Update Magnitude: 0.59292

Collected Steps per Second: 21,546.11024
Overall Steps per Second: 10,426.96263

Timestep Collection Time: 2.32144
Timestep Consumption Time: 2.47555
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.79699

Cumulative Model Updates: 95,344
Cumulative Timesteps: 795,198,828

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.34532
Policy Entropy: 3.18630
Value Function Loss: 0.00466

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10541
Policy Update Magnitude: 0.54719
Value Function Update Magnitude: 0.60222

Collected Steps per Second: 22,233.91409
Overall Steps per Second: 10,565.87392

Timestep Collection Time: 2.24981
Timestep Consumption Time: 2.48449
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.73430

Cumulative Model Updates: 95,350
Cumulative Timesteps: 795,248,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 795248850...
Checkpoint 795248850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.44459
Policy Entropy: 3.19636
Value Function Loss: 0.00444

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09958
Policy Update Magnitude: 0.55374
Value Function Update Magnitude: 0.60500

Collected Steps per Second: 21,064.87523
Overall Steps per Second: 10,289.51806

Timestep Collection Time: 2.37390
Timestep Consumption Time: 2.48599
PPO Batch Consumption Time: 0.29675
Total Iteration Time: 4.85990

Cumulative Model Updates: 95,356
Cumulative Timesteps: 795,298,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.87373
Policy Entropy: 3.21092
Value Function Loss: 0.00435

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.55210
Value Function Update Magnitude: 0.59827

Collected Steps per Second: 21,704.29598
Overall Steps per Second: 10,460.58916

Timestep Collection Time: 2.30369
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.77985

Cumulative Model Updates: 95,362
Cumulative Timesteps: 795,348,856

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 795348856...
Checkpoint 795348856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.79599
Policy Entropy: 3.21881
Value Function Loss: 0.00410

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09122
Policy Update Magnitude: 0.54585
Value Function Update Magnitude: 0.59655

Collected Steps per Second: 21,261.58807
Overall Steps per Second: 10,447.09122

Timestep Collection Time: 2.35213
Timestep Consumption Time: 2.43485
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.78698

Cumulative Model Updates: 95,368
Cumulative Timesteps: 795,398,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.45581
Policy Entropy: 3.21899
Value Function Loss: 0.00404

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.53991
Value Function Update Magnitude: 0.61391

Collected Steps per Second: 21,943.97509
Overall Steps per Second: 10,447.08302

Timestep Collection Time: 2.27953
Timestep Consumption Time: 2.50860
PPO Batch Consumption Time: 0.30206
Total Iteration Time: 4.78813

Cumulative Model Updates: 95,374
Cumulative Timesteps: 795,448,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 795448888...
Checkpoint 795448888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.60204
Policy Entropy: 3.20105
Value Function Loss: 0.00419

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.53808
Value Function Update Magnitude: 0.60498

Collected Steps per Second: 21,055.91601
Overall Steps per Second: 10,311.92979

Timestep Collection Time: 2.37548
Timestep Consumption Time: 2.47501
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.85050

Cumulative Model Updates: 95,380
Cumulative Timesteps: 795,498,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.52868
Policy Entropy: 3.20262
Value Function Loss: 0.00447

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.54971
Value Function Update Magnitude: 0.62257

Collected Steps per Second: 21,244.75130
Overall Steps per Second: 10,477.52921

Timestep Collection Time: 2.35446
Timestep Consumption Time: 2.41956
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.77403

Cumulative Model Updates: 95,386
Cumulative Timesteps: 795,548,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 795548926...
Checkpoint 795548926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.10942
Policy Entropy: 3.20066
Value Function Loss: 0.00454

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10661
Policy Update Magnitude: 0.56013
Value Function Update Magnitude: 0.62210

Collected Steps per Second: 22,212.86375
Overall Steps per Second: 10,364.46497

Timestep Collection Time: 2.25203
Timestep Consumption Time: 2.57446
PPO Batch Consumption Time: 0.29885
Total Iteration Time: 4.82649

Cumulative Model Updates: 95,392
Cumulative Timesteps: 795,598,950

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.27099
Policy Entropy: 3.20497
Value Function Loss: 0.00454

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.56149
Value Function Update Magnitude: 0.61328

Collected Steps per Second: 22,644.66784
Overall Steps per Second: 10,502.73654

Timestep Collection Time: 2.20962
Timestep Consumption Time: 2.55448
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.76409

Cumulative Model Updates: 95,398
Cumulative Timesteps: 795,648,986

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 795648986...
Checkpoint 795648986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.66808
Policy Entropy: 3.20438
Value Function Loss: 0.00448

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09507
Policy Update Magnitude: 0.55622
Value Function Update Magnitude: 0.59336

Collected Steps per Second: 22,114.08847
Overall Steps per Second: 10,439.86438

Timestep Collection Time: 2.26218
Timestep Consumption Time: 2.52965
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.79182

Cumulative Model Updates: 95,404
Cumulative Timesteps: 795,699,012

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.24731
Policy Entropy: 3.19513
Value Function Loss: 0.00434

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.55478
Value Function Update Magnitude: 0.57428

Collected Steps per Second: 21,974.36102
Overall Steps per Second: 10,437.06721

Timestep Collection Time: 2.27647
Timestep Consumption Time: 2.51645
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.79292

Cumulative Model Updates: 95,410
Cumulative Timesteps: 795,749,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 795749036...
Checkpoint 795749036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 871.00809
Policy Entropy: 3.19545
Value Function Loss: 0.00461

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.57609

Collected Steps per Second: 22,277.20501
Overall Steps per Second: 10,570.29077

Timestep Collection Time: 2.24499
Timestep Consumption Time: 2.48639
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.73137

Cumulative Model Updates: 95,416
Cumulative Timesteps: 795,799,048

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.78576
Policy Entropy: 3.19431
Value Function Loss: 0.00455

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08563
Policy Update Magnitude: 0.56264
Value Function Update Magnitude: 0.59819

Collected Steps per Second: 22,492.51422
Overall Steps per Second: 10,445.22936

Timestep Collection Time: 2.22438
Timestep Consumption Time: 2.56555
PPO Batch Consumption Time: 0.30058
Total Iteration Time: 4.78994

Cumulative Model Updates: 95,422
Cumulative Timesteps: 795,849,080

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 795849080...
Checkpoint 795849080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.53210
Policy Entropy: 3.19740
Value Function Loss: 0.00467

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08846
Policy Update Magnitude: 0.57133
Value Function Update Magnitude: 0.60899

Collected Steps per Second: 22,133.92876
Overall Steps per Second: 10,569.47516

Timestep Collection Time: 2.26024
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.73325

Cumulative Model Updates: 95,428
Cumulative Timesteps: 795,899,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.69750
Policy Entropy: 3.19405
Value Function Loss: 0.00487

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.58742
Value Function Update Magnitude: 0.63109

Collected Steps per Second: 21,990.19728
Overall Steps per Second: 10,543.61721

Timestep Collection Time: 2.27410
Timestep Consumption Time: 2.46886
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.74296

Cumulative Model Updates: 95,434
Cumulative Timesteps: 795,949,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 795949116...
Checkpoint 795949116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.22322
Policy Entropy: 3.18324
Value Function Loss: 0.00499

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10140
Policy Update Magnitude: 0.58810
Value Function Update Magnitude: 0.65770

Collected Steps per Second: 22,317.59703
Overall Steps per Second: 10,632.98769

Timestep Collection Time: 2.24056
Timestep Consumption Time: 2.46216
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.70272

Cumulative Model Updates: 95,440
Cumulative Timesteps: 795,999,120

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.85242
Policy Entropy: 3.17422
Value Function Loss: 0.00515

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.58639
Value Function Update Magnitude: 0.67512

Collected Steps per Second: 22,513.97228
Overall Steps per Second: 10,452.82276

Timestep Collection Time: 2.22084
Timestep Consumption Time: 2.56255
PPO Batch Consumption Time: 0.30036
Total Iteration Time: 4.78340

Cumulative Model Updates: 95,446
Cumulative Timesteps: 796,049,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 796049120...
Checkpoint 796049120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.97476
Policy Entropy: 3.19357
Value Function Loss: 0.00473

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11028
Policy Update Magnitude: 0.57352
Value Function Update Magnitude: 0.67629

Collected Steps per Second: 22,450.24603
Overall Steps per Second: 10,655.62497

Timestep Collection Time: 2.22768
Timestep Consumption Time: 2.46580
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.69348

Cumulative Model Updates: 95,452
Cumulative Timesteps: 796,099,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.33047
Policy Entropy: 3.20526
Value Function Loss: 0.00464

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11139
Policy Update Magnitude: 0.55966
Value Function Update Magnitude: 0.65820

Collected Steps per Second: 22,680.57741
Overall Steps per Second: 10,358.92413

Timestep Collection Time: 2.20506
Timestep Consumption Time: 2.62286
PPO Batch Consumption Time: 0.30992
Total Iteration Time: 4.82791

Cumulative Model Updates: 95,458
Cumulative Timesteps: 796,149,144

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 796149144...
Checkpoint 796149144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.61594
Policy Entropy: 3.19951
Value Function Loss: 0.00441

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10562
Policy Update Magnitude: 0.54860
Value Function Update Magnitude: 0.62831

Collected Steps per Second: 22,726.76454
Overall Steps per Second: 10,664.89338

Timestep Collection Time: 2.20031
Timestep Consumption Time: 2.48853
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.68884

Cumulative Model Updates: 95,464
Cumulative Timesteps: 796,199,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,963.60154
Policy Entropy: 3.19056
Value Function Loss: 0.00458

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.60438

Collected Steps per Second: 22,493.54797
Overall Steps per Second: 10,540.97094

Timestep Collection Time: 2.22322
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.74416

Cumulative Model Updates: 95,470
Cumulative Timesteps: 796,249,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 796249158...
Checkpoint 796249158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.28229
Policy Entropy: 3.18158
Value Function Loss: 0.00451

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.55602
Value Function Update Magnitude: 0.59408

Collected Steps per Second: 22,544.08092
Overall Steps per Second: 10,606.40821

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.49715
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.71583

Cumulative Model Updates: 95,476
Cumulative Timesteps: 796,299,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.49303
Policy Entropy: 3.18809
Value Function Loss: 0.00451

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.55252
Value Function Update Magnitude: 0.60149

Collected Steps per Second: 21,825.97157
Overall Steps per Second: 10,497.41341

Timestep Collection Time: 2.29122
Timestep Consumption Time: 2.47262
PPO Batch Consumption Time: 0.29778
Total Iteration Time: 4.76384

Cumulative Model Updates: 95,482
Cumulative Timesteps: 796,349,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 796349184...
Checkpoint 796349184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 812.10818
Policy Entropy: 3.18461
Value Function Loss: 0.00459

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.55826
Value Function Update Magnitude: 0.62733

Collected Steps per Second: 22,597.29360
Overall Steps per Second: 10,600.21626

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.50503
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.71839

Cumulative Model Updates: 95,488
Cumulative Timesteps: 796,399,200

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 722.04229
Policy Entropy: 3.18732
Value Function Loss: 0.00503

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10150
Policy Update Magnitude: 0.57439
Value Function Update Magnitude: 0.63817

Collected Steps per Second: 22,466.77598
Overall Steps per Second: 10,427.15989

Timestep Collection Time: 2.22569
Timestep Consumption Time: 2.56987
PPO Batch Consumption Time: 0.30151
Total Iteration Time: 4.79555

Cumulative Model Updates: 95,494
Cumulative Timesteps: 796,449,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 796449204...
Checkpoint 796449204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.78710
Policy Entropy: 3.18610
Value Function Loss: 0.00489

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11049
Policy Update Magnitude: 0.57397
Value Function Update Magnitude: 0.64270

Collected Steps per Second: 22,332.96916
Overall Steps per Second: 10,623.74706

Timestep Collection Time: 2.23938
Timestep Consumption Time: 2.46819
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.70757

Cumulative Model Updates: 95,500
Cumulative Timesteps: 796,499,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.58400
Policy Entropy: 3.18461
Value Function Loss: 0.00509

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.57411
Value Function Update Magnitude: 0.65013

Collected Steps per Second: 22,520.73288
Overall Steps per Second: 10,495.89715

Timestep Collection Time: 2.22124
Timestep Consumption Time: 2.54481
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.76605

Cumulative Model Updates: 95,506
Cumulative Timesteps: 796,549,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 796549240...
Checkpoint 796549240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 584.24481
Policy Entropy: 3.18246
Value Function Loss: 0.00470

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.57249
Value Function Update Magnitude: 0.64794

Collected Steps per Second: 22,011.10830
Overall Steps per Second: 10,570.40886

Timestep Collection Time: 2.27158
Timestep Consumption Time: 2.45861
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.73019

Cumulative Model Updates: 95,512
Cumulative Timesteps: 796,599,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.23619
Policy Entropy: 3.17396
Value Function Loss: 0.00481

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.57464
Value Function Update Magnitude: 0.63968

Collected Steps per Second: 22,295.77769
Overall Steps per Second: 10,516.24139

Timestep Collection Time: 2.24321
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.75588

Cumulative Model Updates: 95,518
Cumulative Timesteps: 796,649,254

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 796649254...
Checkpoint 796649254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.80305
Policy Entropy: 3.16430
Value Function Loss: 0.00488

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.58271
Value Function Update Magnitude: 0.63643

Collected Steps per Second: 22,729.69444
Overall Steps per Second: 10,612.16529

Timestep Collection Time: 2.20073
Timestep Consumption Time: 2.51291
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.71365

Cumulative Model Updates: 95,524
Cumulative Timesteps: 796,699,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,272.00723
Policy Entropy: 3.16067
Value Function Loss: 0.00480

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.58079
Value Function Update Magnitude: 0.63685

Collected Steps per Second: 22,338.69833
Overall Steps per Second: 10,507.14573

Timestep Collection Time: 2.23889
Timestep Consumption Time: 2.52110
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.76000

Cumulative Model Updates: 95,530
Cumulative Timesteps: 796,749,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 796749290...
Checkpoint 796749290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.83096
Policy Entropy: 3.15709
Value Function Loss: 0.00476

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.57318
Value Function Update Magnitude: 0.63168

Collected Steps per Second: 22,607.86470
Overall Steps per Second: 10,494.88104

Timestep Collection Time: 2.21224
Timestep Consumption Time: 2.55332
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.76556

Cumulative Model Updates: 95,536
Cumulative Timesteps: 796,799,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.78473
Policy Entropy: 3.15563
Value Function Loss: 0.00463

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09102
Policy Update Magnitude: 0.57299
Value Function Update Magnitude: 0.62275

Collected Steps per Second: 22,222.40587
Overall Steps per Second: 10,528.64176

Timestep Collection Time: 2.25070
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.75047

Cumulative Model Updates: 95,542
Cumulative Timesteps: 796,849,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 796849320...
Checkpoint 796849320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.30782
Policy Entropy: 3.13175
Value Function Loss: 0.00480

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10736
Policy Update Magnitude: 0.57944
Value Function Update Magnitude: 0.63755

Collected Steps per Second: 22,275.40044
Overall Steps per Second: 10,577.12059

Timestep Collection Time: 2.24499
Timestep Consumption Time: 2.48295
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.72794

Cumulative Model Updates: 95,548
Cumulative Timesteps: 796,899,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.55563
Policy Entropy: 3.13249
Value Function Loss: 0.00460

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.58174
Value Function Update Magnitude: 0.64436

Collected Steps per Second: 22,472.21100
Overall Steps per Second: 10,587.72478

Timestep Collection Time: 2.22559
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.72377

Cumulative Model Updates: 95,554
Cumulative Timesteps: 796,949,342

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 796949342...
Checkpoint 796949342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,644.07228
Policy Entropy: 3.13041
Value Function Loss: 0.00460

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10694
Policy Update Magnitude: 0.58440
Value Function Update Magnitude: 0.63959

Collected Steps per Second: 22,188.55006
Overall Steps per Second: 10,580.51467

Timestep Collection Time: 2.25396
Timestep Consumption Time: 2.47285
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.72680

Cumulative Model Updates: 95,560
Cumulative Timesteps: 796,999,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 637.19538
Policy Entropy: 3.13052
Value Function Loss: 0.00474

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.57821
Value Function Update Magnitude: 0.63970

Collected Steps per Second: 22,392.19308
Overall Steps per Second: 10,505.99448

Timestep Collection Time: 2.23355
Timestep Consumption Time: 2.52697
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.76052

Cumulative Model Updates: 95,566
Cumulative Timesteps: 797,049,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 797049368...
Checkpoint 797049368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.79435
Policy Entropy: 3.13745
Value Function Loss: 0.00459

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.57404
Value Function Update Magnitude: 0.63386

Collected Steps per Second: 22,297.99998
Overall Steps per Second: 10,633.02008

Timestep Collection Time: 2.24352
Timestep Consumption Time: 2.46126
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.70478

Cumulative Model Updates: 95,572
Cumulative Timesteps: 797,099,394

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.07077
Policy Entropy: 3.13980
Value Function Loss: 0.00458

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.57127
Value Function Update Magnitude: 0.62475

Collected Steps per Second: 22,728.19285
Overall Steps per Second: 10,495.12394

Timestep Collection Time: 2.20079
Timestep Consumption Time: 2.56523
PPO Batch Consumption Time: 0.30130
Total Iteration Time: 4.76602

Cumulative Model Updates: 95,578
Cumulative Timesteps: 797,149,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 797149414...
Checkpoint 797149414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.52796
Policy Entropy: 3.16278
Value Function Loss: 0.00451

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10610
Policy Update Magnitude: 0.57251
Value Function Update Magnitude: 0.61500

Collected Steps per Second: 22,411.86506
Overall Steps per Second: 10,634.44530

Timestep Collection Time: 2.23203
Timestep Consumption Time: 2.47193
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.70396

Cumulative Model Updates: 95,584
Cumulative Timesteps: 797,199,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.59479
Policy Entropy: 3.17262
Value Function Loss: 0.00482

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.57174
Value Function Update Magnitude: 0.61692

Collected Steps per Second: 22,465.16430
Overall Steps per Second: 10,439.22683

Timestep Collection Time: 2.22594
Timestep Consumption Time: 2.56427
PPO Batch Consumption Time: 0.29978
Total Iteration Time: 4.79020

Cumulative Model Updates: 95,590
Cumulative Timesteps: 797,249,444

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 797249444...
Checkpoint 797249444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 707.92250
Policy Entropy: 3.16822
Value Function Loss: 0.00476

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.56529
Value Function Update Magnitude: 0.61591

Collected Steps per Second: 22,546.53175
Overall Steps per Second: 10,650.34398

Timestep Collection Time: 2.21799
Timestep Consumption Time: 2.47744
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.69544

Cumulative Model Updates: 95,596
Cumulative Timesteps: 797,299,452

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.96038
Policy Entropy: 3.15532
Value Function Loss: 0.00482

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10963
Policy Update Magnitude: 0.56573
Value Function Update Magnitude: 0.61226

Collected Steps per Second: 22,270.07027
Overall Steps per Second: 10,477.71639

Timestep Collection Time: 2.24660
Timestep Consumption Time: 2.52848
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.77509

Cumulative Model Updates: 95,602
Cumulative Timesteps: 797,349,484

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 797349484...
Checkpoint 797349484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.75940
Policy Entropy: 3.14708
Value Function Loss: 0.00476

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10583
Policy Update Magnitude: 0.57173
Value Function Update Magnitude: 0.63937

Collected Steps per Second: 22,451.48241
Overall Steps per Second: 10,613.82458

Timestep Collection Time: 2.22720
Timestep Consumption Time: 2.48401
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.71121

Cumulative Model Updates: 95,608
Cumulative Timesteps: 797,399,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.80665
Policy Entropy: 3.14453
Value Function Loss: 0.00483

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.57932
Value Function Update Magnitude: 0.63931

Collected Steps per Second: 22,438.94267
Overall Steps per Second: 10,352.36950

Timestep Collection Time: 2.22889
Timestep Consumption Time: 2.60227
PPO Batch Consumption Time: 0.30671
Total Iteration Time: 4.83116

Cumulative Model Updates: 95,614
Cumulative Timesteps: 797,449,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 797449502...
Checkpoint 797449502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.03082
Policy Entropy: 3.15022
Value Function Loss: 0.00472

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11092
Policy Update Magnitude: 0.57144
Value Function Update Magnitude: 0.60955

Collected Steps per Second: 22,181.23523
Overall Steps per Second: 10,299.28924

Timestep Collection Time: 2.25443
Timestep Consumption Time: 2.60086
PPO Batch Consumption Time: 0.30573
Total Iteration Time: 4.85529

Cumulative Model Updates: 95,620
Cumulative Timesteps: 797,499,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.71660
Policy Entropy: 3.16659
Value Function Loss: 0.00472

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.56153
Value Function Update Magnitude: 0.58565

Collected Steps per Second: 22,738.39904
Overall Steps per Second: 10,453.65955

Timestep Collection Time: 2.19892
Timestep Consumption Time: 2.58409
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 4.78301

Cumulative Model Updates: 95,626
Cumulative Timesteps: 797,549,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 797549508...
Checkpoint 797549508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.16236
Policy Entropy: 3.15649
Value Function Loss: 0.00481

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.56541
Value Function Update Magnitude: 0.58111

Collected Steps per Second: 22,347.37535
Overall Steps per Second: 10,634.44663

Timestep Collection Time: 2.23767
Timestep Consumption Time: 2.46460
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.70227

Cumulative Model Updates: 95,632
Cumulative Timesteps: 797,599,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.59352
Policy Entropy: 3.15613
Value Function Loss: 0.00471

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.56937
Value Function Update Magnitude: 0.60383

Collected Steps per Second: 22,246.85100
Overall Steps per Second: 10,446.58820

Timestep Collection Time: 2.24832
Timestep Consumption Time: 2.53966
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.78797

Cumulative Model Updates: 95,638
Cumulative Timesteps: 797,649,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 797649532...
Checkpoint 797649532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.71327
Policy Entropy: 3.14000
Value Function Loss: 0.00479

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11221
Policy Update Magnitude: 0.56876
Value Function Update Magnitude: 0.61925

Collected Steps per Second: 22,381.21345
Overall Steps per Second: 10,646.83027

Timestep Collection Time: 2.23491
Timestep Consumption Time: 2.46320
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.69811

Cumulative Model Updates: 95,644
Cumulative Timesteps: 797,699,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.32300
Policy Entropy: 3.14392
Value Function Loss: 0.00478

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.55813
Value Function Update Magnitude: 0.61790

Collected Steps per Second: 22,741.68509
Overall Steps per Second: 10,561.73315

Timestep Collection Time: 2.19887
Timestep Consumption Time: 2.53577
PPO Batch Consumption Time: 0.29746
Total Iteration Time: 4.73464

Cumulative Model Updates: 95,650
Cumulative Timesteps: 797,749,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 797749558...
Checkpoint 797749558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.57155
Policy Entropy: 3.16210
Value Function Loss: 0.00493

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.63536

Collected Steps per Second: 22,691.88497
Overall Steps per Second: 10,590.16473

Timestep Collection Time: 2.20396
Timestep Consumption Time: 2.51854
PPO Batch Consumption Time: 0.29992
Total Iteration Time: 4.72249

Cumulative Model Updates: 95,656
Cumulative Timesteps: 797,799,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.57868
Policy Entropy: 3.15898
Value Function Loss: 0.00496

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.63283

Collected Steps per Second: 22,320.66133
Overall Steps per Second: 10,531.29856

Timestep Collection Time: 2.24017
Timestep Consumption Time: 2.50778
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.74794

Cumulative Model Updates: 95,662
Cumulative Timesteps: 797,849,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 797849572...
Checkpoint 797849572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.85347
Policy Entropy: 3.15712
Value Function Loss: 0.00476

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.11006
Policy Update Magnitude: 0.56308
Value Function Update Magnitude: 0.65088

Collected Steps per Second: 22,511.59487
Overall Steps per Second: 10,524.70867

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.53096
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 4.75320

Cumulative Model Updates: 95,668
Cumulative Timesteps: 797,899,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.76688
Policy Entropy: 3.15372
Value Function Loss: 0.00474

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.55830
Value Function Update Magnitude: 0.64773

Collected Steps per Second: 22,199.65652
Overall Steps per Second: 10,514.88600

Timestep Collection Time: 2.25229
Timestep Consumption Time: 2.50288
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.75516

Cumulative Model Updates: 95,674
Cumulative Timesteps: 797,949,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 797949598...
Checkpoint 797949598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,627.79457
Policy Entropy: 3.15773
Value Function Loss: 0.00480

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.56137
Value Function Update Magnitude: 0.63067

Collected Steps per Second: 22,348.76855
Overall Steps per Second: 10,558.75056

Timestep Collection Time: 2.23851
Timestep Consumption Time: 2.49955
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.73806

Cumulative Model Updates: 95,680
Cumulative Timesteps: 797,999,626

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.28640
Policy Entropy: 3.18835
Value Function Loss: 0.00473

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.56268
Value Function Update Magnitude: 0.63152

Collected Steps per Second: 22,639.83377
Overall Steps per Second: 10,556.81042

Timestep Collection Time: 2.20876
Timestep Consumption Time: 2.52809
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 4.73685

Cumulative Model Updates: 95,686
Cumulative Timesteps: 798,049,632

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 798049632...
Checkpoint 798049632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.09095
Policy Entropy: 3.21209
Value Function Loss: 0.00448

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09344
Policy Update Magnitude: 0.55122
Value Function Update Magnitude: 0.62596

Collected Steps per Second: 22,381.22289
Overall Steps per Second: 10,498.76632

Timestep Collection Time: 2.23527
Timestep Consumption Time: 2.52986
PPO Batch Consumption Time: 0.29975
Total Iteration Time: 4.76513

Cumulative Model Updates: 95,692
Cumulative Timesteps: 798,099,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.37322
Policy Entropy: 3.20995
Value Function Loss: 0.00437

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.54169
Value Function Update Magnitude: 0.60802

Collected Steps per Second: 22,081.73278
Overall Steps per Second: 10,363.53240

Timestep Collection Time: 2.26549
Timestep Consumption Time: 2.56163
PPO Batch Consumption Time: 0.30362
Total Iteration Time: 4.82712

Cumulative Model Updates: 95,698
Cumulative Timesteps: 798,149,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 798149686...
Checkpoint 798149686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.18727
Policy Entropy: 3.20098
Value Function Loss: 0.00447

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.53663
Value Function Update Magnitude: 0.58610

Collected Steps per Second: 22,488.76371
Overall Steps per Second: 10,746.76823

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.42971
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.65349

Cumulative Model Updates: 95,704
Cumulative Timesteps: 798,199,696

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.96535
Policy Entropy: 3.18676
Value Function Loss: 0.00447

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.53886
Value Function Update Magnitude: 0.57056

Collected Steps per Second: 22,365.31945
Overall Steps per Second: 10,486.62788

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.53318
PPO Batch Consumption Time: 0.29812
Total Iteration Time: 4.76950

Cumulative Model Updates: 95,710
Cumulative Timesteps: 798,249,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 798249712...
Checkpoint 798249712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.31059
Policy Entropy: 3.18538
Value Function Loss: 0.00461

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.54283
Value Function Update Magnitude: 0.56747

Collected Steps per Second: 22,287.10047
Overall Steps per Second: 10,650.36496

Timestep Collection Time: 2.24345
Timestep Consumption Time: 2.45122
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.69467

Cumulative Model Updates: 95,716
Cumulative Timesteps: 798,299,712

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.42163
Policy Entropy: 3.17041
Value Function Loss: 0.00463

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11640
Policy Update Magnitude: 0.54644
Value Function Update Magnitude: 0.58485

Collected Steps per Second: 22,485.57339
Overall Steps per Second: 10,552.24832

Timestep Collection Time: 2.22445
Timestep Consumption Time: 2.51558
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.74003

Cumulative Model Updates: 95,722
Cumulative Timesteps: 798,349,730

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 798349730...
Checkpoint 798349730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 914.75623
Policy Entropy: 3.16696
Value Function Loss: 0.00470

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.54760
Value Function Update Magnitude: 0.58921

Collected Steps per Second: 22,592.06912
Overall Steps per Second: 10,556.07647

Timestep Collection Time: 2.21405
Timestep Consumption Time: 2.52445
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 4.73850

Cumulative Model Updates: 95,728
Cumulative Timesteps: 798,399,750

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.79037
Policy Entropy: 3.17567
Value Function Loss: 0.00468

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.58698

Collected Steps per Second: 22,414.57642
Overall Steps per Second: 10,562.28259

Timestep Collection Time: 2.23078
Timestep Consumption Time: 2.50323
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.73401

Cumulative Model Updates: 95,734
Cumulative Timesteps: 798,449,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 798449752...
Checkpoint 798449752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.93112
Policy Entropy: 3.18933
Value Function Loss: 0.00470

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.55097
Value Function Update Magnitude: 0.59621

Collected Steps per Second: 22,574.24574
Overall Steps per Second: 10,529.80392

Timestep Collection Time: 2.21562
Timestep Consumption Time: 2.53432
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.74995

Cumulative Model Updates: 95,740
Cumulative Timesteps: 798,499,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.07530
Policy Entropy: 3.19817
Value Function Loss: 0.00455

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10006
Policy Update Magnitude: 0.55381
Value Function Update Magnitude: 0.60236

Collected Steps per Second: 22,661.29283
Overall Steps per Second: 10,646.66370

Timestep Collection Time: 2.20711
Timestep Consumption Time: 2.49070
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.69781

Cumulative Model Updates: 95,746
Cumulative Timesteps: 798,549,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 798549784...
Checkpoint 798549784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.31389
Policy Entropy: 3.18957
Value Function Loss: 0.00461

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.59100

Collected Steps per Second: 22,224.93312
Overall Steps per Second: 10,476.54495

Timestep Collection Time: 2.25018
Timestep Consumption Time: 2.52334
PPO Batch Consumption Time: 0.29903
Total Iteration Time: 4.77352

Cumulative Model Updates: 95,752
Cumulative Timesteps: 798,599,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.49688
Policy Entropy: 3.18794
Value Function Loss: 0.00480

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.55510
Value Function Update Magnitude: 0.60051

Collected Steps per Second: 22,456.00181
Overall Steps per Second: 10,540.54496

Timestep Collection Time: 2.22667
Timestep Consumption Time: 2.51711
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.74378

Cumulative Model Updates: 95,758
Cumulative Timesteps: 798,649,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 798649796...
Checkpoint 798649796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.52198
Policy Entropy: 3.18075
Value Function Loss: 0.00502

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.56443
Value Function Update Magnitude: 0.61675

Collected Steps per Second: 22,504.49199
Overall Steps per Second: 10,593.50266

Timestep Collection Time: 2.22196
Timestep Consumption Time: 2.49830
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.72025

Cumulative Model Updates: 95,764
Cumulative Timesteps: 798,699,800

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.60444
Policy Entropy: 3.17148
Value Function Loss: 0.00495

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09906
Policy Update Magnitude: 0.56780
Value Function Update Magnitude: 0.63886

Collected Steps per Second: 22,729.67342
Overall Steps per Second: 10,731.92487

Timestep Collection Time: 2.20012
Timestep Consumption Time: 2.45962
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.65974

Cumulative Model Updates: 95,770
Cumulative Timesteps: 798,749,808

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 798749808...
Checkpoint 798749808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.96464
Policy Entropy: 3.16164
Value Function Loss: 0.00480

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.56663
Value Function Update Magnitude: 0.64093

Collected Steps per Second: 21,859.99995
Overall Steps per Second: 10,402.44114

Timestep Collection Time: 2.28847
Timestep Consumption Time: 2.52059
PPO Batch Consumption Time: 0.30004
Total Iteration Time: 4.80906

Cumulative Model Updates: 95,776
Cumulative Timesteps: 798,799,834

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.07276
Policy Entropy: 3.14498
Value Function Loss: 0.00508

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.56841
Value Function Update Magnitude: 0.61345

Collected Steps per Second: 22,665.10734
Overall Steps per Second: 10,773.02887

Timestep Collection Time: 2.20771
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.64475

Cumulative Model Updates: 95,782
Cumulative Timesteps: 798,849,872

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 798849872...
Checkpoint 798849872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.82965
Policy Entropy: 3.16106
Value Function Loss: 0.00509

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.57254
Value Function Update Magnitude: 0.60272

Collected Steps per Second: 21,568.46186
Overall Steps per Second: 10,316.43859

Timestep Collection Time: 2.31848
Timestep Consumption Time: 2.52874
PPO Batch Consumption Time: 0.29740
Total Iteration Time: 4.84722

Cumulative Model Updates: 95,788
Cumulative Timesteps: 798,899,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.76449
Policy Entropy: 3.15786
Value Function Loss: 0.00505

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10824
Policy Update Magnitude: 0.56984
Value Function Update Magnitude: 0.59354

Collected Steps per Second: 22,598.53929
Overall Steps per Second: 10,836.36643

Timestep Collection Time: 2.21368
Timestep Consumption Time: 2.40281
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.61649

Cumulative Model Updates: 95,794
Cumulative Timesteps: 798,949,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 798949904...
Checkpoint 798949904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 913.65602
Policy Entropy: 3.16364
Value Function Loss: 0.00467

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10555
Policy Update Magnitude: 0.56318
Value Function Update Magnitude: 0.58490

Collected Steps per Second: 21,513.59912
Overall Steps per Second: 10,565.11428

Timestep Collection Time: 2.32504
Timestep Consumption Time: 2.40941
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.73445

Cumulative Model Updates: 95,800
Cumulative Timesteps: 798,999,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.45082
Policy Entropy: 3.17032
Value Function Loss: 0.00466

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.56372
Value Function Update Magnitude: 0.59340

Collected Steps per Second: 21,951.83683
Overall Steps per Second: 10,497.63310

Timestep Collection Time: 2.27853
Timestep Consumption Time: 2.48616
PPO Batch Consumption Time: 0.29684
Total Iteration Time: 4.76469

Cumulative Model Updates: 95,806
Cumulative Timesteps: 799,049,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 799049942...
Checkpoint 799049942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.10431
Policy Entropy: 3.17245
Value Function Loss: 0.00478

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.57293
Value Function Update Magnitude: 0.61462

Collected Steps per Second: 21,553.66676
Overall Steps per Second: 10,556.97881

Timestep Collection Time: 2.31979
Timestep Consumption Time: 2.41641
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.73620

Cumulative Model Updates: 95,812
Cumulative Timesteps: 799,099,942

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.56950
Policy Entropy: 3.15966
Value Function Loss: 0.00490

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.56918
Value Function Update Magnitude: 0.61955

Collected Steps per Second: 22,272.78981
Overall Steps per Second: 10,596.63867

Timestep Collection Time: 2.24606
Timestep Consumption Time: 2.47487
PPO Batch Consumption Time: 0.29948
Total Iteration Time: 4.72093

Cumulative Model Updates: 95,818
Cumulative Timesteps: 799,149,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 799149968...
Checkpoint 799149968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.82360
Policy Entropy: 3.15855
Value Function Loss: 0.00480

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.56703
Value Function Update Magnitude: 0.60819

Collected Steps per Second: 19,973.53790
Overall Steps per Second: 10,202.71003

Timestep Collection Time: 2.50471
Timestep Consumption Time: 2.39869
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.90340

Cumulative Model Updates: 95,824
Cumulative Timesteps: 799,199,996

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.37588
Policy Entropy: 3.15883
Value Function Loss: 0.00518

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09442
Policy Update Magnitude: 0.58052
Value Function Update Magnitude: 0.63386

Collected Steps per Second: 21,177.74851
Overall Steps per Second: 10,382.18904

Timestep Collection Time: 2.36210
Timestep Consumption Time: 2.45615
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.81825

Cumulative Model Updates: 95,830
Cumulative Timesteps: 799,250,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 799250020...
Checkpoint 799250020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.68897
Policy Entropy: 3.16149
Value Function Loss: 0.00490

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.58011
Value Function Update Magnitude: 0.64840

Collected Steps per Second: 22,273.39810
Overall Steps per Second: 10,617.36223

Timestep Collection Time: 2.24546
Timestep Consumption Time: 2.46513
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.71059

Cumulative Model Updates: 95,836
Cumulative Timesteps: 799,300,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 986.13708
Policy Entropy: 3.15097
Value Function Loss: 0.00489

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.57860
Value Function Update Magnitude: 0.65582

Collected Steps per Second: 22,782.92665
Overall Steps per Second: 10,550.64413

Timestep Collection Time: 2.19498
Timestep Consumption Time: 2.54483
PPO Batch Consumption Time: 0.30022
Total Iteration Time: 4.73981

Cumulative Model Updates: 95,842
Cumulative Timesteps: 799,350,042

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 799350042...
Checkpoint 799350042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 794.57220
Policy Entropy: 3.16622
Value Function Loss: 0.00477

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.57469
Value Function Update Magnitude: 0.67058

Collected Steps per Second: 22,537.12523
Overall Steps per Second: 10,600.42619

Timestep Collection Time: 2.21883
Timestep Consumption Time: 2.49853
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.71736

Cumulative Model Updates: 95,848
Cumulative Timesteps: 799,400,048

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.70537
Policy Entropy: 3.16700
Value Function Loss: 0.00458

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.56745
Value Function Update Magnitude: 0.65113

Collected Steps per Second: 22,327.60308
Overall Steps per Second: 10,452.27548

Timestep Collection Time: 2.24063
Timestep Consumption Time: 2.54569
PPO Batch Consumption Time: 0.29805
Total Iteration Time: 4.78633

Cumulative Model Updates: 95,854
Cumulative Timesteps: 799,450,076

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 799450076...
Checkpoint 799450076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.41616
Policy Entropy: 3.18319
Value Function Loss: 0.00444

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.56613
Value Function Update Magnitude: 0.62349

Collected Steps per Second: 22,291.58313
Overall Steps per Second: 10,576.93809

Timestep Collection Time: 2.24318
Timestep Consumption Time: 2.48447
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.72764

Cumulative Model Updates: 95,860
Cumulative Timesteps: 799,500,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.50807
Policy Entropy: 3.19396
Value Function Loss: 0.00443

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.56348
Value Function Update Magnitude: 0.61048

Collected Steps per Second: 22,894.42542
Overall Steps per Second: 10,633.12698

Timestep Collection Time: 2.18507
Timestep Consumption Time: 2.51966
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.70473

Cumulative Model Updates: 95,866
Cumulative Timesteps: 799,550,106

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 799550106...
Checkpoint 799550106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.00206
Policy Entropy: 3.21008
Value Function Loss: 0.00434

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.56624
Value Function Update Magnitude: 0.63518

Collected Steps per Second: 21,916.49171
Overall Steps per Second: 10,491.27120

Timestep Collection Time: 2.28166
Timestep Consumption Time: 2.48478
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.76644

Cumulative Model Updates: 95,872
Cumulative Timesteps: 799,600,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.38150
Policy Entropy: 3.19997
Value Function Loss: 0.00445

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.55424
Value Function Update Magnitude: 0.63991

Collected Steps per Second: 22,640.07602
Overall Steps per Second: 10,471.89519

Timestep Collection Time: 2.20927
Timestep Consumption Time: 2.56714
PPO Batch Consumption Time: 0.30119
Total Iteration Time: 4.77640

Cumulative Model Updates: 95,878
Cumulative Timesteps: 799,650,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 799650130...
Checkpoint 799650130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.46308
Policy Entropy: 3.20303
Value Function Loss: 0.00427

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09466
Policy Update Magnitude: 0.54960
Value Function Update Magnitude: 0.61247

Collected Steps per Second: 22,241.88823
Overall Steps per Second: 10,588.32935

Timestep Collection Time: 2.24855
Timestep Consumption Time: 2.47476
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.72331

Cumulative Model Updates: 95,884
Cumulative Timesteps: 799,700,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.10411
Policy Entropy: 3.19893
Value Function Loss: 0.00428

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08984
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.59375

Collected Steps per Second: 22,899.57382
Overall Steps per Second: 10,542.42826

Timestep Collection Time: 2.18380
Timestep Consumption Time: 2.55970
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 4.74350

Cumulative Model Updates: 95,890
Cumulative Timesteps: 799,750,150

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 799750150...
Checkpoint 799750150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.58402
Policy Entropy: 3.20512
Value Function Loss: 0.00421

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08851
Policy Update Magnitude: 0.54732
Value Function Update Magnitude: 0.56796

Collected Steps per Second: 22,201.89800
Overall Steps per Second: 10,607.64251

Timestep Collection Time: 2.25314
Timestep Consumption Time: 2.46270
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.71585

Cumulative Model Updates: 95,896
Cumulative Timesteps: 799,800,174

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.45134
Policy Entropy: 3.19107
Value Function Loss: 0.00442

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.57972

Collected Steps per Second: 22,411.19133
Overall Steps per Second: 10,486.59266

Timestep Collection Time: 2.23210
Timestep Consumption Time: 2.53818
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.77028

Cumulative Model Updates: 95,902
Cumulative Timesteps: 799,850,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 799850198...
Checkpoint 799850198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.42456
Policy Entropy: 3.18155
Value Function Loss: 0.00452

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.56165
Value Function Update Magnitude: 0.60387

Collected Steps per Second: 22,299.21113
Overall Steps per Second: 10,600.54989

Timestep Collection Time: 2.24295
Timestep Consumption Time: 2.47530
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.71825

Cumulative Model Updates: 95,908
Cumulative Timesteps: 799,900,214

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,455.96493
Policy Entropy: 3.17220
Value Function Loss: 0.00445

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.56753
Value Function Update Magnitude: 0.61644

Collected Steps per Second: 22,507.23489
Overall Steps per Second: 10,505.01820

Timestep Collection Time: 2.22284
Timestep Consumption Time: 2.53965
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.76249

Cumulative Model Updates: 95,914
Cumulative Timesteps: 799,950,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 799950244...
Checkpoint 799950244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758.13657
Policy Entropy: 3.17746
Value Function Loss: 0.00468

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.57077
Value Function Update Magnitude: 0.61641

Collected Steps per Second: 22,412.44818
Overall Steps per Second: 10,612.16864

Timestep Collection Time: 2.23215
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.71421

Cumulative Model Updates: 95,920
Cumulative Timesteps: 800,000,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.49005
Policy Entropy: 3.17663
Value Function Loss: 0.00448

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10669
Policy Update Magnitude: 0.56802
Value Function Update Magnitude: 0.61420

Collected Steps per Second: 22,675.52727
Overall Steps per Second: 10,552.69681

Timestep Collection Time: 2.20599
Timestep Consumption Time: 2.53422
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.74021

Cumulative Model Updates: 95,926
Cumulative Timesteps: 800,050,294

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 800050294...
Checkpoint 800050294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.12276
Policy Entropy: 3.18049
Value Function Loss: 0.00454

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09929
Policy Update Magnitude: 0.56072
Value Function Update Magnitude: 0.59897

Collected Steps per Second: 22,120.61356
Overall Steps per Second: 10,527.06871

Timestep Collection Time: 2.26079
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.75061

Cumulative Model Updates: 95,932
Cumulative Timesteps: 800,100,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.76371
Policy Entropy: 3.19930
Value Function Loss: 0.00484

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10428
Policy Update Magnitude: 0.56171
Value Function Update Magnitude: 0.62792

Collected Steps per Second: 22,333.77650
Overall Steps per Second: 10,549.74756

Timestep Collection Time: 2.23957
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.74116

Cumulative Model Updates: 95,938
Cumulative Timesteps: 800,150,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 800150322...
Checkpoint 800150322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.64331
Policy Entropy: 3.20190
Value Function Loss: 0.00501

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.57038
Value Function Update Magnitude: 0.65911

Collected Steps per Second: 22,366.89453
Overall Steps per Second: 10,603.98734

Timestep Collection Time: 2.23607
Timestep Consumption Time: 2.48046
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.71653

Cumulative Model Updates: 95,944
Cumulative Timesteps: 800,200,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.73442
Policy Entropy: 3.19443
Value Function Loss: 0.00472

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.56767
Value Function Update Magnitude: 0.66232

Collected Steps per Second: 22,617.49022
Overall Steps per Second: 10,471.96510

Timestep Collection Time: 2.21156
Timestep Consumption Time: 2.56500
PPO Batch Consumption Time: 0.30109
Total Iteration Time: 4.77656

Cumulative Model Updates: 95,950
Cumulative Timesteps: 800,250,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 800250356...
Checkpoint 800250356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.78168
Policy Entropy: 3.20126
Value Function Loss: 0.00453

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.56420
Value Function Update Magnitude: 0.62586

Collected Steps per Second: 22,281.86619
Overall Steps per Second: 10,577.37298

Timestep Collection Time: 2.24532
Timestep Consumption Time: 2.48458
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.72991

Cumulative Model Updates: 95,956
Cumulative Timesteps: 800,300,386

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.08059
Policy Entropy: 3.20469
Value Function Loss: 0.00440

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.60395

Collected Steps per Second: 22,212.72148
Overall Steps per Second: 10,519.32194

Timestep Collection Time: 2.25105
Timestep Consumption Time: 2.50230
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.75335

Cumulative Model Updates: 95,962
Cumulative Timesteps: 800,350,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 800350388...
Checkpoint 800350388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.28372
Policy Entropy: 3.22808
Value Function Loss: 0.00440

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.56281
Value Function Update Magnitude: 0.61261

Collected Steps per Second: 22,339.91440
Overall Steps per Second: 10,676.95302

Timestep Collection Time: 2.23868
Timestep Consumption Time: 2.44542
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.68411

Cumulative Model Updates: 95,968
Cumulative Timesteps: 800,400,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.71237
Policy Entropy: 3.21023
Value Function Loss: 0.00429

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11729
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.62299

Collected Steps per Second: 22,687.38542
Overall Steps per Second: 10,548.29324

Timestep Collection Time: 2.20519
Timestep Consumption Time: 2.53776
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.74295

Cumulative Model Updates: 95,974
Cumulative Timesteps: 800,450,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 800450430...
Checkpoint 800450430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.03511
Policy Entropy: 3.20553
Value Function Loss: 0.00432

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.54517
Value Function Update Magnitude: 0.60519

Collected Steps per Second: 22,864.77076
Overall Steps per Second: 10,603.78956

Timestep Collection Time: 2.18686
Timestep Consumption Time: 2.52863
PPO Batch Consumption Time: 0.29837
Total Iteration Time: 4.71548

Cumulative Model Updates: 95,980
Cumulative Timesteps: 800,500,432

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.65052
Policy Entropy: 3.18852
Value Function Loss: 0.00440

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.54476
Value Function Update Magnitude: 0.60297

Collected Steps per Second: 22,318.63101
Overall Steps per Second: 10,441.62792

Timestep Collection Time: 2.24127
Timestep Consumption Time: 2.54937
PPO Batch Consumption Time: 0.29804
Total Iteration Time: 4.79063

Cumulative Model Updates: 95,986
Cumulative Timesteps: 800,550,454

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 800550454...
Checkpoint 800550454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.06067
Policy Entropy: 3.19480
Value Function Loss: 0.00451

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.60708

Collected Steps per Second: 22,822.90934
Overall Steps per Second: 10,550.51526

Timestep Collection Time: 2.19087
Timestep Consumption Time: 2.54843
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.73929

Cumulative Model Updates: 95,992
Cumulative Timesteps: 800,600,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546.97984
Policy Entropy: 3.18798
Value Function Loss: 0.00484

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.64060

Collected Steps per Second: 22,565.33106
Overall Steps per Second: 10,525.61432

Timestep Collection Time: 2.21676
Timestep Consumption Time: 2.53564
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.75241

Cumulative Model Updates: 95,998
Cumulative Timesteps: 800,650,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 800650478...
Checkpoint 800650478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.63251
Policy Entropy: 3.19994
Value Function Loss: 0.00482

Mean KL Divergence: 0.00739
SB3 Clip Fraction: 0.07906
Policy Update Magnitude: 0.57617
Value Function Update Magnitude: 0.65372

Collected Steps per Second: 22,562.33026
Overall Steps per Second: 10,546.79644

Timestep Collection Time: 2.21679
Timestep Consumption Time: 2.52550
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.74229

Cumulative Model Updates: 96,004
Cumulative Timesteps: 800,700,494

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.46368
Policy Entropy: 3.19777
Value Function Loss: 0.00471

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08974
Policy Update Magnitude: 0.57158
Value Function Update Magnitude: 0.64684

Collected Steps per Second: 22,585.82235
Overall Steps per Second: 10,448.18388

Timestep Collection Time: 2.21387
Timestep Consumption Time: 2.57185
PPO Batch Consumption Time: 0.29873
Total Iteration Time: 4.78571

Cumulative Model Updates: 96,010
Cumulative Timesteps: 800,750,496

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 800750496...
Checkpoint 800750496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.07225
Policy Entropy: 3.20691
Value Function Loss: 0.00448

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08156
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.64800

Collected Steps per Second: 22,144.61281
Overall Steps per Second: 10,608.77110

Timestep Collection Time: 2.25852
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.71440

Cumulative Model Updates: 96,016
Cumulative Timesteps: 800,800,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.85433
Policy Entropy: 3.20044
Value Function Loss: 0.00436

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08176
Policy Update Magnitude: 0.54981
Value Function Update Magnitude: 0.65125

Collected Steps per Second: 22,421.75987
Overall Steps per Second: 10,507.38996

Timestep Collection Time: 2.23069
Timestep Consumption Time: 2.52939
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.76008

Cumulative Model Updates: 96,022
Cumulative Timesteps: 800,850,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 800850526...
Checkpoint 800850526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.59152
Policy Entropy: 3.18400
Value Function Loss: 0.00444

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08366
Policy Update Magnitude: 0.55250
Value Function Update Magnitude: 0.63557

Collected Steps per Second: 22,696.34421
Overall Steps per Second: 10,665.18226

Timestep Collection Time: 2.20361
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.68947

Cumulative Model Updates: 96,028
Cumulative Timesteps: 800,900,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.45217
Policy Entropy: 3.17146
Value Function Loss: 0.00447

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.56638
Value Function Update Magnitude: 0.62528

Collected Steps per Second: 22,526.29103
Overall Steps per Second: 10,467.78582

Timestep Collection Time: 2.22087
Timestep Consumption Time: 2.55836
PPO Batch Consumption Time: 0.30100
Total Iteration Time: 4.77923

Cumulative Model Updates: 96,034
Cumulative Timesteps: 800,950,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 800950568...
Checkpoint 800950568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.18459
Policy Entropy: 3.17497
Value Function Loss: 0.00462

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.56909
Value Function Update Magnitude: 0.62620

Collected Steps per Second: 22,313.60202
Overall Steps per Second: 10,643.83611

Timestep Collection Time: 2.24168
Timestep Consumption Time: 2.45775
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.69943

Cumulative Model Updates: 96,040
Cumulative Timesteps: 801,000,588

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.53375
Policy Entropy: 3.18823
Value Function Loss: 0.00449

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.56358
Value Function Update Magnitude: 0.62813

Collected Steps per Second: 22,746.57348
Overall Steps per Second: 10,568.38484

Timestep Collection Time: 2.19892
Timestep Consumption Time: 2.53387
PPO Batch Consumption Time: 0.29691
Total Iteration Time: 4.73280

Cumulative Model Updates: 96,046
Cumulative Timesteps: 801,050,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 801050606...
Checkpoint 801050606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.46348
Policy Entropy: 3.18348
Value Function Loss: 0.00466

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.62579

Collected Steps per Second: 22,579.23733
Overall Steps per Second: 10,489.10990

Timestep Collection Time: 2.21549
Timestep Consumption Time: 2.55365
PPO Batch Consumption Time: 0.30046
Total Iteration Time: 4.76914

Cumulative Model Updates: 96,052
Cumulative Timesteps: 801,100,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.86184
Policy Entropy: 3.18696
Value Function Loss: 0.00463

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.56758
Value Function Update Magnitude: 0.62251

Collected Steps per Second: 22,472.26249
Overall Steps per Second: 10,512.77613

Timestep Collection Time: 2.22568
Timestep Consumption Time: 2.53196
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.75764

Cumulative Model Updates: 96,058
Cumulative Timesteps: 801,150,646

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 801150646...
Checkpoint 801150646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.29935
Policy Entropy: 3.16597
Value Function Loss: 0.00477

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.57951
Value Function Update Magnitude: 0.64531

Collected Steps per Second: 22,390.81600
Overall Steps per Second: 10,635.71969

Timestep Collection Time: 2.23342
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.70189

Cumulative Model Updates: 96,064
Cumulative Timesteps: 801,200,654

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.40058
Policy Entropy: 3.17108
Value Function Loss: 0.00488

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.58940
Value Function Update Magnitude: 0.66816

Collected Steps per Second: 22,561.37610
Overall Steps per Second: 10,522.71368

Timestep Collection Time: 2.21848
Timestep Consumption Time: 2.53809
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.75657

Cumulative Model Updates: 96,070
Cumulative Timesteps: 801,250,706

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 801250706...
Checkpoint 801250706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.66209
Policy Entropy: 3.17660
Value Function Loss: 0.00481

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.59169
Value Function Update Magnitude: 0.66510

Collected Steps per Second: 22,494.51211
Overall Steps per Second: 10,537.18043

Timestep Collection Time: 2.22303
Timestep Consumption Time: 2.52264
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.74567

Cumulative Model Updates: 96,076
Cumulative Timesteps: 801,300,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,673.26123
Policy Entropy: 3.18757
Value Function Loss: 0.00501

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10390
Policy Update Magnitude: 0.58549
Value Function Update Magnitude: 0.63976

Collected Steps per Second: 22,719.66292
Overall Steps per Second: 10,547.49784

Timestep Collection Time: 2.20171
Timestep Consumption Time: 2.54084
PPO Batch Consumption Time: 0.29865
Total Iteration Time: 4.74255

Cumulative Model Updates: 96,082
Cumulative Timesteps: 801,350,734

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 801350734...
Checkpoint 801350734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 590.42239
Policy Entropy: 3.19211
Value Function Loss: 0.00466

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.57795
Value Function Update Magnitude: 0.62309

Collected Steps per Second: 22,486.25526
Overall Steps per Second: 10,455.66342

Timestep Collection Time: 2.22367
Timestep Consumption Time: 2.55862
PPO Batch Consumption Time: 0.29971
Total Iteration Time: 4.78229

Cumulative Model Updates: 96,088
Cumulative Timesteps: 801,400,736

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.78244
Policy Entropy: 3.17788
Value Function Loss: 0.00473

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.57976
Value Function Update Magnitude: 0.62489

Collected Steps per Second: 22,439.93925
Overall Steps per Second: 10,569.05179

Timestep Collection Time: 2.22942
Timestep Consumption Time: 2.50402
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.73344

Cumulative Model Updates: 96,094
Cumulative Timesteps: 801,450,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 801450764...
Checkpoint 801450764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.53332
Policy Entropy: 3.17967
Value Function Loss: 0.00464

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.58109
Value Function Update Magnitude: 0.62661

Collected Steps per Second: 22,418.31263
Overall Steps per Second: 10,622.92127

Timestep Collection Time: 2.23166
Timestep Consumption Time: 2.47797
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.70963

Cumulative Model Updates: 96,100
Cumulative Timesteps: 801,500,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.44395
Policy Entropy: 3.18049
Value Function Loss: 0.00464

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.65514

Collected Steps per Second: 22,517.48508
Overall Steps per Second: 10,477.67745

Timestep Collection Time: 2.22165
Timestep Consumption Time: 2.55288
PPO Batch Consumption Time: 0.29868
Total Iteration Time: 4.77453

Cumulative Model Updates: 96,106
Cumulative Timesteps: 801,550,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 801550820...
Checkpoint 801550820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.29502
Policy Entropy: 3.18639
Value Function Loss: 0.00459

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.65775

Collected Steps per Second: 22,643.03056
Overall Steps per Second: 10,668.49662

Timestep Collection Time: 2.20889
Timestep Consumption Time: 2.47930
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.68820

Cumulative Model Updates: 96,112
Cumulative Timesteps: 801,600,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.10134
Policy Entropy: 3.18446
Value Function Loss: 0.00454

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10360
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.64384

Collected Steps per Second: 22,649.69247
Overall Steps per Second: 10,537.84764

Timestep Collection Time: 2.20807
Timestep Consumption Time: 2.53788
PPO Batch Consumption Time: 0.29765
Total Iteration Time: 4.74594

Cumulative Model Updates: 96,118
Cumulative Timesteps: 801,650,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 801650848...
Checkpoint 801650848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.41282
Policy Entropy: 3.19725
Value Function Loss: 0.00450

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.57187
Value Function Update Magnitude: 0.64622

Collected Steps per Second: 22,785.87123
Overall Steps per Second: 10,582.33038

Timestep Collection Time: 2.19452
Timestep Consumption Time: 2.53072
PPO Batch Consumption Time: 0.29884
Total Iteration Time: 4.72524

Cumulative Model Updates: 96,124
Cumulative Timesteps: 801,700,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,197.17337
Policy Entropy: 3.19730
Value Function Loss: 0.00437

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.62409

Collected Steps per Second: 22,182.91054
Overall Steps per Second: 10,420.90925

Timestep Collection Time: 2.25435
Timestep Consumption Time: 2.54447
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.79881

Cumulative Model Updates: 96,130
Cumulative Timesteps: 801,750,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 801750860...
Checkpoint 801750860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.50875
Policy Entropy: 3.20798
Value Function Loss: 0.00430

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.55280
Value Function Update Magnitude: 0.60505

Collected Steps per Second: 22,565.59794
Overall Steps per Second: 10,640.06717

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.48395
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.70016

Cumulative Model Updates: 96,136
Cumulative Timesteps: 801,800,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.75042
Policy Entropy: 3.21687
Value Function Loss: 0.00461

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.55561
Value Function Update Magnitude: 0.61370

Collected Steps per Second: 22,816.32005
Overall Steps per Second: 10,581.50772

Timestep Collection Time: 2.19194
Timestep Consumption Time: 2.53442
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.72636

Cumulative Model Updates: 96,142
Cumulative Timesteps: 801,850,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 801850882...
Checkpoint 801850882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.57241
Policy Entropy: 3.21549
Value Function Loss: 0.00474

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.56237
Value Function Update Magnitude: 0.62287

Collected Steps per Second: 22,441.95798
Overall Steps per Second: 10,484.75529

Timestep Collection Time: 2.22895
Timestep Consumption Time: 2.54198
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.77093

Cumulative Model Updates: 96,148
Cumulative Timesteps: 801,900,904

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.02221
Policy Entropy: 3.20785
Value Function Loss: 0.00462

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09446
Policy Update Magnitude: 0.56272
Value Function Update Magnitude: 0.59889

Collected Steps per Second: 22,693.40084
Overall Steps per Second: 10,542.09254

Timestep Collection Time: 2.20443
Timestep Consumption Time: 2.54093
PPO Batch Consumption Time: 0.29820
Total Iteration Time: 4.74536

Cumulative Model Updates: 96,154
Cumulative Timesteps: 801,950,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 801950930...
Checkpoint 801950930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.92466
Policy Entropy: 3.20902
Value Function Loss: 0.00436

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09624
Policy Update Magnitude: 0.55608
Value Function Update Magnitude: 0.57716

Collected Steps per Second: 22,395.48070
Overall Steps per Second: 10,593.53677

Timestep Collection Time: 2.23277
Timestep Consumption Time: 2.48746
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.72024

Cumulative Model Updates: 96,160
Cumulative Timesteps: 802,000,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 705.76043
Policy Entropy: 3.20123
Value Function Loss: 0.00452

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.55546
Value Function Update Magnitude: 0.57979

Collected Steps per Second: 22,350.78223
Overall Steps per Second: 10,283.01930

Timestep Collection Time: 2.23742
Timestep Consumption Time: 2.62575
PPO Batch Consumption Time: 0.31259
Total Iteration Time: 4.86316

Cumulative Model Updates: 96,166
Cumulative Timesteps: 802,050,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 802050942...
Checkpoint 802050942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.99606
Policy Entropy: 3.20674
Value Function Loss: 0.00451

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.55793
Value Function Update Magnitude: 0.59698

Collected Steps per Second: 22,298.69019
Overall Steps per Second: 10,415.90850

Timestep Collection Time: 2.24300
Timestep Consumption Time: 2.55888
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.80189

Cumulative Model Updates: 96,172
Cumulative Timesteps: 802,100,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.93397
Policy Entropy: 3.19808
Value Function Loss: 0.00453

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.55993
Value Function Update Magnitude: 0.60832

Collected Steps per Second: 22,753.32619
Overall Steps per Second: 10,690.29788

Timestep Collection Time: 2.19898
Timestep Consumption Time: 2.48134
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.68032

Cumulative Model Updates: 96,178
Cumulative Timesteps: 802,150,992

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 802150992...
Checkpoint 802150992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.03299
Policy Entropy: 3.19755
Value Function Loss: 0.00439

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09019
Policy Update Magnitude: 0.55695
Value Function Update Magnitude: 0.62620

Collected Steps per Second: 22,510.05574
Overall Steps per Second: 10,637.30530

Timestep Collection Time: 2.22194
Timestep Consumption Time: 2.48000
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.70194

Cumulative Model Updates: 96,184
Cumulative Timesteps: 802,201,008

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.10868
Policy Entropy: 3.19656
Value Function Loss: 0.00445

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.56082
Value Function Update Magnitude: 0.64170

Collected Steps per Second: 22,534.31109
Overall Steps per Second: 10,631.69374

Timestep Collection Time: 2.21928
Timestep Consumption Time: 2.48458
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.70386

Cumulative Model Updates: 96,190
Cumulative Timesteps: 802,251,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 802251018...
Checkpoint 802251018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.42125
Policy Entropy: 3.20377
Value Function Loss: 0.00439

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09211
Policy Update Magnitude: 0.56181
Value Function Update Magnitude: 0.64467

Collected Steps per Second: 22,343.49611
Overall Steps per Second: 10,569.08675

Timestep Collection Time: 2.23806
Timestep Consumption Time: 2.49329
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.73135

Cumulative Model Updates: 96,196
Cumulative Timesteps: 802,301,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.63960
Policy Entropy: 3.19371
Value Function Loss: 0.00425

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.55623
Value Function Update Magnitude: 0.63482

Collected Steps per Second: 22,834.49716
Overall Steps per Second: 10,580.77587

Timestep Collection Time: 2.18976
Timestep Consumption Time: 2.53598
PPO Batch Consumption Time: 0.29809
Total Iteration Time: 4.72574

Cumulative Model Updates: 96,202
Cumulative Timesteps: 802,351,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 802351026...
Checkpoint 802351026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,007.83484
Policy Entropy: 3.18443
Value Function Loss: 0.00408

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.55055
Value Function Update Magnitude: 0.61237

Collected Steps per Second: 21,831.81819
Overall Steps per Second: 10,540.98529

Timestep Collection Time: 2.29152
Timestep Consumption Time: 2.45453
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.74605

Cumulative Model Updates: 96,208
Cumulative Timesteps: 802,401,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.28404
Policy Entropy: 3.18732
Value Function Loss: 0.00431

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09052
Policy Update Magnitude: 0.55050
Value Function Update Magnitude: 0.60404

Collected Steps per Second: 23,180.33662
Overall Steps per Second: 10,773.46011

Timestep Collection Time: 2.15743
Timestep Consumption Time: 2.48453
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.64196

Cumulative Model Updates: 96,214
Cumulative Timesteps: 802,451,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 802451064...
Checkpoint 802451064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.72668
Policy Entropy: 3.19481
Value Function Loss: 0.00438

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.61219

Collected Steps per Second: 22,423.51415
Overall Steps per Second: 10,667.04206

Timestep Collection Time: 2.23034
Timestep Consumption Time: 2.45812
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.68846

Cumulative Model Updates: 96,220
Cumulative Timesteps: 802,501,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.99414
Policy Entropy: 3.19964
Value Function Loss: 0.00451

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.60988

Collected Steps per Second: 22,538.43051
Overall Steps per Second: 10,577.79989

Timestep Collection Time: 2.21870
Timestep Consumption Time: 2.50875
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.72745

Cumulative Model Updates: 96,226
Cumulative Timesteps: 802,551,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 802551082...
Checkpoint 802551082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.49946
Policy Entropy: 3.20521
Value Function Loss: 0.00460

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11600
Policy Update Magnitude: 0.56040
Value Function Update Magnitude: 0.61029

Collected Steps per Second: 22,483.29327
Overall Steps per Second: 10,701.60553

Timestep Collection Time: 2.22485
Timestep Consumption Time: 2.44940
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.67425

Cumulative Model Updates: 96,232
Cumulative Timesteps: 802,601,104

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.71964
Policy Entropy: 3.18895
Value Function Loss: 0.00489

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.56375
Value Function Update Magnitude: 0.62118

Collected Steps per Second: 22,906.13771
Overall Steps per Second: 10,718.28650

Timestep Collection Time: 2.18439
Timestep Consumption Time: 2.48389
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.66828

Cumulative Model Updates: 96,238
Cumulative Timesteps: 802,651,140

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 802651140...
Checkpoint 802651140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.76609
Policy Entropy: 3.18726
Value Function Loss: 0.00472

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.62827

Collected Steps per Second: 22,232.90697
Overall Steps per Second: 10,404.87114

Timestep Collection Time: 2.24973
Timestep Consumption Time: 2.55744
PPO Batch Consumption Time: 0.29923
Total Iteration Time: 4.80717

Cumulative Model Updates: 96,244
Cumulative Timesteps: 802,701,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.41626
Policy Entropy: 3.18114
Value Function Loss: 0.00448

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.12019
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.61515

Collected Steps per Second: 22,389.08977
Overall Steps per Second: 10,358.04691

Timestep Collection Time: 2.23359
Timestep Consumption Time: 2.59435
PPO Batch Consumption Time: 0.30687
Total Iteration Time: 4.82794

Cumulative Model Updates: 96,250
Cumulative Timesteps: 802,751,166

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 802751166...
Checkpoint 802751166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.89967
Policy Entropy: 3.19061
Value Function Loss: 0.00426

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.56041
Value Function Update Magnitude: 0.59596

Collected Steps per Second: 22,463.69557
Overall Steps per Second: 10,652.67143

Timestep Collection Time: 2.22653
Timestep Consumption Time: 2.46863
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.69516

Cumulative Model Updates: 96,256
Cumulative Timesteps: 802,801,182

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.12620
Policy Entropy: 3.19331
Value Function Loss: 0.00424

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10386
Policy Update Magnitude: 0.55858
Value Function Update Magnitude: 0.59283

Collected Steps per Second: 22,348.85621
Overall Steps per Second: 10,445.68841

Timestep Collection Time: 2.23868
Timestep Consumption Time: 2.55104
PPO Batch Consumption Time: 0.29844
Total Iteration Time: 4.78973

Cumulative Model Updates: 96,262
Cumulative Timesteps: 802,851,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 802851214...
Checkpoint 802851214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.45823
Policy Entropy: 3.18980
Value Function Loss: 0.00434

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.55654
Value Function Update Magnitude: 0.59082

Collected Steps per Second: 22,165.33476
Overall Steps per Second: 10,547.71973

Timestep Collection Time: 2.25596
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.74074

Cumulative Model Updates: 96,268
Cumulative Timesteps: 802,901,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.21923
Policy Entropy: 3.18835
Value Function Loss: 0.00444

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.60462

Collected Steps per Second: 22,844.16840
Overall Steps per Second: 10,547.82169

Timestep Collection Time: 2.18909
Timestep Consumption Time: 2.55198
PPO Batch Consumption Time: 0.29800
Total Iteration Time: 4.74107

Cumulative Model Updates: 96,274
Cumulative Timesteps: 802,951,226

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 802951226...
Checkpoint 802951226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.93935
Policy Entropy: 3.17442
Value Function Loss: 0.00471

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09642
Policy Update Magnitude: 0.57453
Value Function Update Magnitude: 0.62685

Collected Steps per Second: 22,399.05789
Overall Steps per Second: 10,603.92657

Timestep Collection Time: 2.23259
Timestep Consumption Time: 2.48339
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.71599

Cumulative Model Updates: 96,280
Cumulative Timesteps: 803,001,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.04703
Policy Entropy: 3.18026
Value Function Loss: 0.00470

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08921
Policy Update Magnitude: 0.58562
Value Function Update Magnitude: 0.65851

Collected Steps per Second: 22,855.23386
Overall Steps per Second: 10,582.12967

Timestep Collection Time: 2.18873
Timestep Consumption Time: 2.53848
PPO Batch Consumption Time: 0.29880
Total Iteration Time: 4.72721

Cumulative Model Updates: 96,286
Cumulative Timesteps: 803,051,258

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 803051258...
Checkpoint 803051258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.78256
Policy Entropy: 3.17959
Value Function Loss: 0.00470

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08878
Policy Update Magnitude: 0.59008
Value Function Update Magnitude: 0.67250

Collected Steps per Second: 22,421.51562
Overall Steps per Second: 10,594.33360

Timestep Collection Time: 2.23054
Timestep Consumption Time: 2.49010
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.72064

Cumulative Model Updates: 96,292
Cumulative Timesteps: 803,101,270

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.37739
Policy Entropy: 3.19927
Value Function Loss: 0.00466

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08841
Policy Update Magnitude: 0.59178
Value Function Update Magnitude: 0.68672

Collected Steps per Second: 22,444.68452
Overall Steps per Second: 10,434.28176

Timestep Collection Time: 2.22832
Timestep Consumption Time: 2.56492
PPO Batch Consumption Time: 0.30125
Total Iteration Time: 4.79324

Cumulative Model Updates: 96,298
Cumulative Timesteps: 803,151,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 803151284...
Checkpoint 803151284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.56868
Policy Entropy: 3.19743
Value Function Loss: 0.00468

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.58987
Value Function Update Magnitude: 0.67909

Collected Steps per Second: 22,492.95830
Overall Steps per Second: 10,591.00654

Timestep Collection Time: 2.22336
Timestep Consumption Time: 2.49857
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.72193

Cumulative Model Updates: 96,304
Cumulative Timesteps: 803,201,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.66490
Policy Entropy: 3.19935
Value Function Loss: 0.00457

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.58231
Value Function Update Magnitude: 0.67032

Collected Steps per Second: 22,500.80317
Overall Steps per Second: 10,468.25439

Timestep Collection Time: 2.22277
Timestep Consumption Time: 2.55492
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.77768

Cumulative Model Updates: 96,310
Cumulative Timesteps: 803,251,308

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 803251308...
Checkpoint 803251308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.79845
Policy Entropy: 3.19711
Value Function Loss: 0.00484

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.58425
Value Function Update Magnitude: 0.66404

Collected Steps per Second: 22,491.82578
Overall Steps per Second: 10,627.07925

Timestep Collection Time: 2.22410
Timestep Consumption Time: 2.48312
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.70722

Cumulative Model Updates: 96,316
Cumulative Timesteps: 803,301,332

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.81483
Policy Entropy: 3.19159
Value Function Loss: 0.00468

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.58487
Value Function Update Magnitude: 0.67726

Collected Steps per Second: 22,697.84008
Overall Steps per Second: 10,558.78851

Timestep Collection Time: 2.20426
Timestep Consumption Time: 2.53416
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.73842

Cumulative Model Updates: 96,322
Cumulative Timesteps: 803,351,364

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 803351364...
Checkpoint 803351364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.75561
Policy Entropy: 3.19647
Value Function Loss: 0.00483

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08688
Policy Update Magnitude: 0.58373
Value Function Update Magnitude: 0.70471

Collected Steps per Second: 22,086.92810
Overall Steps per Second: 10,436.55600

Timestep Collection Time: 2.26442
Timestep Consumption Time: 2.52778
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.79219

Cumulative Model Updates: 96,328
Cumulative Timesteps: 803,401,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.75421
Policy Entropy: 3.18654
Value Function Loss: 0.00459

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09040
Policy Update Magnitude: 0.58465
Value Function Update Magnitude: 0.71310

Collected Steps per Second: 23,122.78233
Overall Steps per Second: 10,610.28937

Timestep Collection Time: 2.16289
Timestep Consumption Time: 2.55065
PPO Batch Consumption Time: 0.29980
Total Iteration Time: 4.71354

Cumulative Model Updates: 96,334
Cumulative Timesteps: 803,451,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 803451390...
Checkpoint 803451390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.67318
Policy Entropy: 3.18103
Value Function Loss: 0.00462

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.58864
Value Function Update Magnitude: 0.70619

Collected Steps per Second: 22,333.24304
Overall Steps per Second: 10,585.80076

Timestep Collection Time: 2.23980
Timestep Consumption Time: 2.48559
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.72539

Cumulative Model Updates: 96,340
Cumulative Timesteps: 803,501,412

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.30000
Policy Entropy: 3.18459
Value Function Loss: 0.00463

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.58882
Value Function Update Magnitude: 0.68369

Collected Steps per Second: 23,039.55095
Overall Steps per Second: 10,557.91454

Timestep Collection Time: 2.17035
Timestep Consumption Time: 2.56581
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.73616

Cumulative Model Updates: 96,346
Cumulative Timesteps: 803,551,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 803551416...
Checkpoint 803551416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.54593
Policy Entropy: 3.19875
Value Function Loss: 0.00461

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.58720
Value Function Update Magnitude: 0.66553

Collected Steps per Second: 22,298.59823
Overall Steps per Second: 10,651.21850

Timestep Collection Time: 2.24355
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.69693

Cumulative Model Updates: 96,352
Cumulative Timesteps: 803,601,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.49977
Policy Entropy: 3.18957
Value Function Loss: 0.00455

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.57764
Value Function Update Magnitude: 0.64926

Collected Steps per Second: 22,733.53074
Overall Steps per Second: 10,602.47150

Timestep Collection Time: 2.20045
Timestep Consumption Time: 2.51770
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.71815

Cumulative Model Updates: 96,358
Cumulative Timesteps: 803,651,468

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 803651468...
Checkpoint 803651468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.17637
Policy Entropy: 3.17029
Value Function Loss: 0.00456

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.57436
Value Function Update Magnitude: 0.64724

Collected Steps per Second: 22,435.23129
Overall Steps per Second: 10,514.04366

Timestep Collection Time: 2.22962
Timestep Consumption Time: 2.52802
PPO Batch Consumption Time: 0.29642
Total Iteration Time: 4.75764

Cumulative Model Updates: 96,364
Cumulative Timesteps: 803,701,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.79123
Policy Entropy: 3.16202
Value Function Loss: 0.00471

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.57998
Value Function Update Magnitude: 0.66073

Collected Steps per Second: 22,881.32426
Overall Steps per Second: 10,711.40022

Timestep Collection Time: 2.18624
Timestep Consumption Time: 2.48393
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.67016

Cumulative Model Updates: 96,370
Cumulative Timesteps: 803,751,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 803751514...
Checkpoint 803751514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.37141
Policy Entropy: 3.16007
Value Function Loss: 0.00496

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.59147
Value Function Update Magnitude: 0.65355

Collected Steps per Second: 22,520.76092
Overall Steps per Second: 10,661.26420

Timestep Collection Time: 2.22080
Timestep Consumption Time: 2.47039
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.69119

Cumulative Model Updates: 96,376
Cumulative Timesteps: 803,801,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.86002
Policy Entropy: 3.16259
Value Function Loss: 0.00501

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11455
Policy Update Magnitude: 0.60042
Value Function Update Magnitude: 0.66200

Collected Steps per Second: 22,729.56008
Overall Steps per Second: 10,592.71900

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.52165
PPO Batch Consumption Time: 0.29782
Total Iteration Time: 4.72249

Cumulative Model Updates: 96,382
Cumulative Timesteps: 803,851,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 803851552...
Checkpoint 803851552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.84523
Policy Entropy: 3.14660
Value Function Loss: 0.00488

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.60294
Value Function Update Magnitude: 0.68479

Collected Steps per Second: 22,231.55836
Overall Steps per Second: 10,556.30944

Timestep Collection Time: 2.24932
Timestep Consumption Time: 2.48775
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.73707

Cumulative Model Updates: 96,388
Cumulative Timesteps: 803,901,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,336.39200
Policy Entropy: 3.16619
Value Function Loss: 0.00472

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.59041
Value Function Update Magnitude: 0.66969

Collected Steps per Second: 22,607.24301
Overall Steps per Second: 10,578.09443

Timestep Collection Time: 2.21186
Timestep Consumption Time: 2.51527
PPO Batch Consumption Time: 0.29732
Total Iteration Time: 4.72713

Cumulative Model Updates: 96,394
Cumulative Timesteps: 803,951,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 803951562...
Checkpoint 803951562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.84567
Policy Entropy: 3.16524
Value Function Loss: 0.00464

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.58093
Value Function Update Magnitude: 0.64779

Collected Steps per Second: 22,101.50095
Overall Steps per Second: 10,523.67872

Timestep Collection Time: 2.26329
Timestep Consumption Time: 2.49000
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.75328

Cumulative Model Updates: 96,400
Cumulative Timesteps: 804,001,584

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.37054
Policy Entropy: 3.18480
Value Function Loss: 0.00428

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.56999
Value Function Update Magnitude: 0.63921

Collected Steps per Second: 22,283.73984
Overall Steps per Second: 10,480.05714

Timestep Collection Time: 2.24460
Timestep Consumption Time: 2.52809
PPO Batch Consumption Time: 0.30157
Total Iteration Time: 4.77268

Cumulative Model Updates: 96,406
Cumulative Timesteps: 804,051,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 804051602...
Checkpoint 804051602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.90430
Policy Entropy: 3.19351
Value Function Loss: 0.00414

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.56441
Value Function Update Magnitude: 0.63738

Collected Steps per Second: 21,908.36158
Overall Steps per Second: 10,548.60328

Timestep Collection Time: 2.28351
Timestep Consumption Time: 2.45911
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.74262

Cumulative Model Updates: 96,412
Cumulative Timesteps: 804,101,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 868.58534
Policy Entropy: 3.19860
Value Function Loss: 0.00428

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.56129
Value Function Update Magnitude: 0.63640

Collected Steps per Second: 22,733.43221
Overall Steps per Second: 10,564.27315

Timestep Collection Time: 2.19949
Timestep Consumption Time: 2.53363
PPO Batch Consumption Time: 0.29969
Total Iteration Time: 4.73312

Cumulative Model Updates: 96,418
Cumulative Timesteps: 804,151,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 804151632...
Checkpoint 804151632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764.22470
Policy Entropy: 3.18449
Value Function Loss: 0.00449

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10859
Policy Update Magnitude: 0.56889
Value Function Update Magnitude: 0.65809

Collected Steps per Second: 22,310.20590
Overall Steps per Second: 10,712.38725

Timestep Collection Time: 2.24175
Timestep Consumption Time: 2.42705
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.66880

Cumulative Model Updates: 96,424
Cumulative Timesteps: 804,201,646

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.29775
Policy Entropy: 3.16755
Value Function Loss: 0.00463

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.57345
Value Function Update Magnitude: 0.65920

Collected Steps per Second: 22,456.93210
Overall Steps per Second: 10,665.61114

Timestep Collection Time: 2.22648
Timestep Consumption Time: 2.46148
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.68796

Cumulative Model Updates: 96,430
Cumulative Timesteps: 804,251,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 804251646...
Checkpoint 804251646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.43698
Policy Entropy: 3.16299
Value Function Loss: 0.00476

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.57477
Value Function Update Magnitude: 0.64875

Collected Steps per Second: 22,279.19814
Overall Steps per Second: 10,679.36461

Timestep Collection Time: 2.24496
Timestep Consumption Time: 2.43846
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.68342

Cumulative Model Updates: 96,436
Cumulative Timesteps: 804,301,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.76407
Policy Entropy: 3.15468
Value Function Loss: 0.00506

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11290
Policy Update Magnitude: 0.58468
Value Function Update Magnitude: 0.65645

Collected Steps per Second: 22,318.65900
Overall Steps per Second: 10,570.56407

Timestep Collection Time: 2.24135
Timestep Consumption Time: 2.49103
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.73239

Cumulative Model Updates: 96,442
Cumulative Timesteps: 804,351,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 804351686...
Checkpoint 804351686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.53116
Policy Entropy: 3.16551
Value Function Loss: 0.00530

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.60146
Value Function Update Magnitude: 0.67077

Collected Steps per Second: 22,312.01596
Overall Steps per Second: 10,594.48284

Timestep Collection Time: 2.24148
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.29829
Total Iteration Time: 4.72057

Cumulative Model Updates: 96,448
Cumulative Timesteps: 804,401,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.46912
Policy Entropy: 3.16823
Value Function Loss: 0.00501

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09031
Policy Update Magnitude: 0.60446
Value Function Update Magnitude: 0.70541

Collected Steps per Second: 21,977.86650
Overall Steps per Second: 10,553.54437

Timestep Collection Time: 2.27593
Timestep Consumption Time: 2.46371
PPO Batch Consumption Time: 0.29757
Total Iteration Time: 4.73964

Cumulative Model Updates: 96,454
Cumulative Timesteps: 804,451,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 804451718...
Checkpoint 804451718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.04786
Policy Entropy: 3.17059
Value Function Loss: 0.00478

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.59243
Value Function Update Magnitude: 0.71724

Collected Steps per Second: 21,682.11857
Overall Steps per Second: 10,563.49989

Timestep Collection Time: 2.30623
Timestep Consumption Time: 2.42743
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.73366

Cumulative Model Updates: 96,460
Cumulative Timesteps: 804,501,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.41361
Policy Entropy: 3.17501
Value Function Loss: 0.00447

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11409
Policy Update Magnitude: 0.57881
Value Function Update Magnitude: 0.68411

Collected Steps per Second: 22,078.60696
Overall Steps per Second: 10,610.08543

Timestep Collection Time: 2.26545
Timestep Consumption Time: 2.44874
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.71419

Cumulative Model Updates: 96,466
Cumulative Timesteps: 804,551,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 804551740...
Checkpoint 804551740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.46716
Policy Entropy: 3.15300
Value Function Loss: 0.00479

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.57689
Value Function Update Magnitude: 0.67480

Collected Steps per Second: 21,642.90548
Overall Steps per Second: 10,502.88528

Timestep Collection Time: 2.31060
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.76136

Cumulative Model Updates: 96,472
Cumulative Timesteps: 804,601,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.72523
Policy Entropy: 3.15578
Value Function Loss: 0.00470

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.68937

Collected Steps per Second: 22,785.28721
Overall Steps per Second: 10,517.40797

Timestep Collection Time: 2.19475
Timestep Consumption Time: 2.56003
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 4.75478

Cumulative Model Updates: 96,478
Cumulative Timesteps: 804,651,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 804651756...
Checkpoint 804651756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 913.87234
Policy Entropy: 3.14578
Value Function Loss: 0.00514

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.58619
Value Function Update Magnitude: 0.68020

Collected Steps per Second: 22,258.61234
Overall Steps per Second: 10,568.79551

Timestep Collection Time: 2.24713
Timestep Consumption Time: 2.48548
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.73261

Cumulative Model Updates: 96,484
Cumulative Timesteps: 804,701,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.94810
Policy Entropy: 3.16566
Value Function Loss: 0.00495

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.59260
Value Function Update Magnitude: 0.67348

Collected Steps per Second: 22,265.25780
Overall Steps per Second: 10,481.64072

Timestep Collection Time: 2.24610
Timestep Consumption Time: 2.52510
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.77120

Cumulative Model Updates: 96,490
Cumulative Timesteps: 804,751,784

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 804751784...
Checkpoint 804751784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.64143
Policy Entropy: 3.16301
Value Function Loss: 0.00493

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.57751
Value Function Update Magnitude: 0.68128

Collected Steps per Second: 22,335.29318
Overall Steps per Second: 10,668.62369

Timestep Collection Time: 2.23897
Timestep Consumption Time: 2.44842
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.68739

Cumulative Model Updates: 96,496
Cumulative Timesteps: 804,801,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 714.99262
Policy Entropy: 3.15687
Value Function Loss: 0.00460

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11791
Policy Update Magnitude: 0.56756
Value Function Update Magnitude: 0.69814

Collected Steps per Second: 22,450.98142
Overall Steps per Second: 10,471.17524

Timestep Collection Time: 2.22725
Timestep Consumption Time: 2.54814
PPO Batch Consumption Time: 0.29914
Total Iteration Time: 4.77540

Cumulative Model Updates: 96,502
Cumulative Timesteps: 804,851,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 804851796...
Checkpoint 804851796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.66966
Policy Entropy: 3.16218
Value Function Loss: 0.00491

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.57380
Value Function Update Magnitude: 0.68550

Collected Steps per Second: 22,811.63271
Overall Steps per Second: 10,576.81386

Timestep Collection Time: 2.19239
Timestep Consumption Time: 2.53607
PPO Batch Consumption Time: 0.29793
Total Iteration Time: 4.72846

Cumulative Model Updates: 96,508
Cumulative Timesteps: 804,901,808

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.67571
Policy Entropy: 3.18584
Value Function Loss: 0.00467

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.58071
Value Function Update Magnitude: 0.66810

Collected Steps per Second: 22,524.25369
Overall Steps per Second: 10,472.00629

Timestep Collection Time: 2.22081
Timestep Consumption Time: 2.55593
PPO Batch Consumption Time: 0.29786
Total Iteration Time: 4.77674

Cumulative Model Updates: 96,514
Cumulative Timesteps: 804,951,830

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 804951830...
Checkpoint 804951830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.50403
Policy Entropy: 3.18691
Value Function Loss: 0.00476

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10622
Policy Update Magnitude: 0.56873
Value Function Update Magnitude: 0.64617

Collected Steps per Second: 22,533.25428
Overall Steps per Second: 10,660.45248

Timestep Collection Time: 2.21956
Timestep Consumption Time: 2.47198
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.69155

Cumulative Model Updates: 96,520
Cumulative Timesteps: 805,001,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.34477
Policy Entropy: 3.19553
Value Function Loss: 0.00469

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.56051
Value Function Update Magnitude: 0.62171

Collected Steps per Second: 22,525.50599
Overall Steps per Second: 10,533.69012

Timestep Collection Time: 2.22095
Timestep Consumption Time: 2.52838
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.74933

Cumulative Model Updates: 96,526
Cumulative Timesteps: 805,051,872

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 805051872...
Checkpoint 805051872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.23883
Policy Entropy: 3.18946
Value Function Loss: 0.00522

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.57145
Value Function Update Magnitude: 0.62889

Collected Steps per Second: 22,378.90609
Overall Steps per Second: 10,519.90201

Timestep Collection Time: 2.23434
Timestep Consumption Time: 2.51875
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.75309

Cumulative Model Updates: 96,532
Cumulative Timesteps: 805,101,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.44006
Policy Entropy: 3.19657
Value Function Loss: 0.00485

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.57908
Value Function Update Magnitude: 0.64137

Collected Steps per Second: 22,627.90464
Overall Steps per Second: 10,519.14039

Timestep Collection Time: 2.21143
Timestep Consumption Time: 2.54561
PPO Batch Consumption Time: 0.30044
Total Iteration Time: 4.75704

Cumulative Model Updates: 96,538
Cumulative Timesteps: 805,151,914

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 805151914...
Checkpoint 805151914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.42839
Policy Entropy: 3.20043
Value Function Loss: 0.00467

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.56728
Value Function Update Magnitude: 0.64996

Collected Steps per Second: 22,555.56541
Overall Steps per Second: 10,608.12993

Timestep Collection Time: 2.21675
Timestep Consumption Time: 2.49662
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.71337

Cumulative Model Updates: 96,544
Cumulative Timesteps: 805,201,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.97992
Policy Entropy: 3.19373
Value Function Loss: 0.00440

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.55780
Value Function Update Magnitude: 0.64080

Collected Steps per Second: 22,871.07071
Overall Steps per Second: 10,563.49221

Timestep Collection Time: 2.18678
Timestep Consumption Time: 2.54783
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.73461

Cumulative Model Updates: 96,550
Cumulative Timesteps: 805,251,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 805251928...
Checkpoint 805251928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.03379
Policy Entropy: 3.16920
Value Function Loss: 0.00451

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.55623
Value Function Update Magnitude: 0.64232

Collected Steps per Second: 22,567.57913
Overall Steps per Second: 10,573.38639

Timestep Collection Time: 2.21663
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.73112

Cumulative Model Updates: 96,556
Cumulative Timesteps: 805,301,952

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.52619
Policy Entropy: 3.17157
Value Function Loss: 0.00434

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.55485
Value Function Update Magnitude: 0.65533

Collected Steps per Second: 22,341.19599
Overall Steps per Second: 10,358.26242

Timestep Collection Time: 2.23864
Timestep Consumption Time: 2.58977
PPO Batch Consumption Time: 0.30286
Total Iteration Time: 4.82842

Cumulative Model Updates: 96,562
Cumulative Timesteps: 805,351,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 805351966...
Checkpoint 805351966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.21622
Policy Entropy: 3.16797
Value Function Loss: 0.00432

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.54761
Value Function Update Magnitude: 0.64688

Collected Steps per Second: 22,188.81401
Overall Steps per Second: 10,607.14520

Timestep Collection Time: 2.25447
Timestep Consumption Time: 2.46160
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.71607

Cumulative Model Updates: 96,568
Cumulative Timesteps: 805,401,990

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.17341
Policy Entropy: 3.17134
Value Function Loss: 0.00446

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.55507
Value Function Update Magnitude: 0.62835

Collected Steps per Second: 22,432.16141
Overall Steps per Second: 10,545.15554

Timestep Collection Time: 2.23019
Timestep Consumption Time: 2.51398
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.74417

Cumulative Model Updates: 96,574
Cumulative Timesteps: 805,452,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 805452018...
Checkpoint 805452018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.40947
Policy Entropy: 3.15949
Value Function Loss: 0.00464

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.57026
Value Function Update Magnitude: 0.62937

Collected Steps per Second: 22,848.66026
Overall Steps per Second: 10,636.97402

Timestep Collection Time: 2.18963
Timestep Consumption Time: 2.51378
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.70341

Cumulative Model Updates: 96,580
Cumulative Timesteps: 805,502,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.86981
Policy Entropy: 3.15176
Value Function Loss: 0.00470

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11123
Policy Update Magnitude: 0.57710
Value Function Update Magnitude: 0.64491

Collected Steps per Second: 22,543.19257
Overall Steps per Second: 10,560.98083

Timestep Collection Time: 2.21814
Timestep Consumption Time: 2.51665
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.73479

Cumulative Model Updates: 96,586
Cumulative Timesteps: 805,552,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 805552052...
Checkpoint 805552052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.11596
Policy Entropy: 3.15138
Value Function Loss: 0.00439

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.57433
Value Function Update Magnitude: 0.65210

Collected Steps per Second: 22,624.47427
Overall Steps per Second: 10,527.92019

Timestep Collection Time: 2.21221
Timestep Consumption Time: 2.54182
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.75403

Cumulative Model Updates: 96,592
Cumulative Timesteps: 805,602,102

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.03998
Policy Entropy: 3.14369
Value Function Loss: 0.00430

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.57029
Value Function Update Magnitude: 0.64989

Collected Steps per Second: 22,704.39941
Overall Steps per Second: 10,556.80207

Timestep Collection Time: 2.20274
Timestep Consumption Time: 2.53467
PPO Batch Consumption Time: 0.29731
Total Iteration Time: 4.73742

Cumulative Model Updates: 96,598
Cumulative Timesteps: 805,652,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 805652114...
Checkpoint 805652114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.61035
Policy Entropy: 3.14777
Value Function Loss: 0.00440

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10927
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.63371

Collected Steps per Second: 22,515.35337
Overall Steps per Second: 10,538.53614

Timestep Collection Time: 2.22142
Timestep Consumption Time: 2.52459
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.74601

Cumulative Model Updates: 96,604
Cumulative Timesteps: 805,702,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.54437
Policy Entropy: 3.14234
Value Function Loss: 0.00438

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10011
Policy Update Magnitude: 0.57270
Value Function Update Magnitude: 0.62384

Collected Steps per Second: 23,036.10760
Overall Steps per Second: 10,636.96186

Timestep Collection Time: 2.17189
Timestep Consumption Time: 2.53170
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.70360

Cumulative Model Updates: 96,610
Cumulative Timesteps: 805,752,162

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 805752162...
Checkpoint 805752162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942.49754
Policy Entropy: 3.13880
Value Function Loss: 0.00455

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.62834

Collected Steps per Second: 22,726.68925
Overall Steps per Second: 10,588.84554

Timestep Collection Time: 2.20076
Timestep Consumption Time: 2.52270
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.72346

Cumulative Model Updates: 96,616
Cumulative Timesteps: 805,802,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578.79841
Policy Entropy: 3.12878
Value Function Loss: 0.00478

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08346
Policy Update Magnitude: 0.58112
Value Function Update Magnitude: 0.65597

Collected Steps per Second: 22,609.39706
Overall Steps per Second: 10,647.00692

Timestep Collection Time: 2.21244
Timestep Consumption Time: 2.48578
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.69822

Cumulative Model Updates: 96,622
Cumulative Timesteps: 805,852,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 805852200...
Checkpoint 805852200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 818.15552
Policy Entropy: 3.13514
Value Function Loss: 0.00477

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08248
Policy Update Magnitude: 0.58745
Value Function Update Magnitude: 0.64668

Collected Steps per Second: 22,546.94459
Overall Steps per Second: 10,720.75893

Timestep Collection Time: 2.21822
Timestep Consumption Time: 2.44694
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.66515

Cumulative Model Updates: 96,628
Cumulative Timesteps: 805,902,214

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.42033
Policy Entropy: 3.15163
Value Function Loss: 0.00467

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.58260
Value Function Update Magnitude: 0.63839

Collected Steps per Second: 22,699.53364
Overall Steps per Second: 10,510.38223

Timestep Collection Time: 2.20357
Timestep Consumption Time: 2.55553
PPO Batch Consumption Time: 0.29973
Total Iteration Time: 4.75910

Cumulative Model Updates: 96,634
Cumulative Timesteps: 805,952,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 805952234...
Checkpoint 805952234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.93460
Policy Entropy: 3.14079
Value Function Loss: 0.00467

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.57408
Value Function Update Magnitude: 0.64670

Collected Steps per Second: 22,276.76763
Overall Steps per Second: 10,419.11060

Timestep Collection Time: 2.24449
Timestep Consumption Time: 2.55438
PPO Batch Consumption Time: 0.29901
Total Iteration Time: 4.79887

Cumulative Model Updates: 96,640
Cumulative Timesteps: 806,002,234

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.26212
Policy Entropy: 3.14921
Value Function Loss: 0.00467

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.57502
Value Function Update Magnitude: 0.63284

Collected Steps per Second: 22,561.93421
Overall Steps per Second: 10,631.98861

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.48677
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.70298

Cumulative Model Updates: 96,646
Cumulative Timesteps: 806,052,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 806052236...
Checkpoint 806052236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 943.16738
Policy Entropy: 3.15190
Value Function Loss: 0.00458

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.57081
Value Function Update Magnitude: 0.63456

Collected Steps per Second: 22,404.00963
Overall Steps per Second: 10,596.71061

Timestep Collection Time: 2.23255
Timestep Consumption Time: 2.48760
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.72014

Cumulative Model Updates: 96,652
Cumulative Timesteps: 806,102,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.37269
Policy Entropy: 3.17345
Value Function Loss: 0.00465

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.56661
Value Function Update Magnitude: 0.61534

Collected Steps per Second: 22,607.75429
Overall Steps per Second: 10,589.11825

Timestep Collection Time: 2.21252
Timestep Consumption Time: 2.51120
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.72372

Cumulative Model Updates: 96,658
Cumulative Timesteps: 806,152,274

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 806152274...
Checkpoint 806152274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 872.05298
Policy Entropy: 3.17253
Value Function Loss: 0.00476

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.11048
Policy Update Magnitude: 0.56915
Value Function Update Magnitude: 0.60419

Collected Steps per Second: 22,111.07707
Overall Steps per Second: 10,525.43462

Timestep Collection Time: 2.26267
Timestep Consumption Time: 2.49058
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.75325

Cumulative Model Updates: 96,664
Cumulative Timesteps: 806,202,304

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.47253
Policy Entropy: 3.15765
Value Function Loss: 0.00487

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.57696
Value Function Update Magnitude: 0.59946

Collected Steps per Second: 22,521.44215
Overall Steps per Second: 10,517.53168

Timestep Collection Time: 2.22020
Timestep Consumption Time: 2.53396
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.75416

Cumulative Model Updates: 96,670
Cumulative Timesteps: 806,252,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 806252306...
Checkpoint 806252306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.23901
Policy Entropy: 3.14290
Value Function Loss: 0.00494

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.58642
Value Function Update Magnitude: 0.60647

Collected Steps per Second: 22,522.95960
Overall Steps per Second: 10,631.60449

Timestep Collection Time: 2.22093
Timestep Consumption Time: 2.48409
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.70503

Cumulative Model Updates: 96,676
Cumulative Timesteps: 806,302,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.01158
Policy Entropy: 3.14401
Value Function Loss: 0.00489

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.58588
Value Function Update Magnitude: 0.62859

Collected Steps per Second: 22,554.23255
Overall Steps per Second: 10,496.03770

Timestep Collection Time: 2.21688
Timestep Consumption Time: 2.54682
PPO Batch Consumption Time: 0.29968
Total Iteration Time: 4.76370

Cumulative Model Updates: 96,682
Cumulative Timesteps: 806,352,328

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 806352328...
Checkpoint 806352328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.26153
Policy Entropy: 3.15169
Value Function Loss: 0.00474

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.58459
Value Function Update Magnitude: 0.64065

Collected Steps per Second: 22,490.88635
Overall Steps per Second: 10,669.71262

Timestep Collection Time: 2.22383
Timestep Consumption Time: 2.46383
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.68766

Cumulative Model Updates: 96,688
Cumulative Timesteps: 806,402,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.94296
Policy Entropy: 3.14776
Value Function Loss: 0.00469

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.57682
Value Function Update Magnitude: 0.61710

Collected Steps per Second: 22,272.98641
Overall Steps per Second: 10,486.15541

Timestep Collection Time: 2.24559
Timestep Consumption Time: 2.52413
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 4.76972

Cumulative Model Updates: 96,694
Cumulative Timesteps: 806,452,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 806452360...
Checkpoint 806452360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 770.31403
Policy Entropy: 3.14202
Value Function Loss: 0.00480

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.58159
Value Function Update Magnitude: 0.62426

Collected Steps per Second: 22,354.57592
Overall Steps per Second: 10,524.99887

Timestep Collection Time: 2.23730
Timestep Consumption Time: 2.51462
PPO Batch Consumption Time: 0.29711
Total Iteration Time: 4.75192

Cumulative Model Updates: 96,700
Cumulative Timesteps: 806,502,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.80704
Policy Entropy: 3.15560
Value Function Loss: 0.00487

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10863
Policy Update Magnitude: 0.59123
Value Function Update Magnitude: 0.63131

Collected Steps per Second: 21,911.88708
Overall Steps per Second: 10,453.60086

Timestep Collection Time: 2.28205
Timestep Consumption Time: 2.50137
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.78342

Cumulative Model Updates: 96,706
Cumulative Timesteps: 806,552,378

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 806552378...
Checkpoint 806552378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.45900
Policy Entropy: 3.15718
Value Function Loss: 0.00483

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10744
Policy Update Magnitude: 0.59026
Value Function Update Magnitude: 0.62284

Collected Steps per Second: 22,569.88379
Overall Steps per Second: 10,646.79175

Timestep Collection Time: 2.21605
Timestep Consumption Time: 2.48170
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.69775

Cumulative Model Updates: 96,712
Cumulative Timesteps: 806,602,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.44908
Policy Entropy: 3.17408
Value Function Loss: 0.00483

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.58741
Value Function Update Magnitude: 0.60967

Collected Steps per Second: 22,345.17146
Overall Steps per Second: 10,379.48188

Timestep Collection Time: 2.23789
Timestep Consumption Time: 2.57989
PPO Batch Consumption Time: 0.30763
Total Iteration Time: 4.81777

Cumulative Model Updates: 96,718
Cumulative Timesteps: 806,652,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 806652400...
Checkpoint 806652400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.47254
Policy Entropy: 3.15356
Value Function Loss: 0.00494

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.58242
Value Function Update Magnitude: 0.60574

Collected Steps per Second: 22,450.37041
Overall Steps per Second: 10,546.42722

Timestep Collection Time: 2.22803
Timestep Consumption Time: 2.51481
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.74284

Cumulative Model Updates: 96,724
Cumulative Timesteps: 806,702,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.33638
Policy Entropy: 3.14446
Value Function Loss: 0.00482

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.11004
Policy Update Magnitude: 0.58119
Value Function Update Magnitude: 0.60536

Collected Steps per Second: 22,727.07446
Overall Steps per Second: 10,668.29283

Timestep Collection Time: 2.20090
Timestep Consumption Time: 2.48776
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.68866

Cumulative Model Updates: 96,730
Cumulative Timesteps: 806,752,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 806752440...
Checkpoint 806752440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,189.68622
Policy Entropy: 3.13513
Value Function Loss: 0.00474

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.58059
Value Function Update Magnitude: 0.60140

Collected Steps per Second: 22,556.35232
Overall Steps per Second: 10,579.06068

Timestep Collection Time: 2.21711
Timestep Consumption Time: 2.51015
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.72726

Cumulative Model Updates: 96,736
Cumulative Timesteps: 806,802,450

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 891.62445
Policy Entropy: 3.12981
Value Function Loss: 0.00479

Mean KL Divergence: 0.01424
SB3 Clip Fraction: 0.13157
Policy Update Magnitude: 0.57744
Value Function Update Magnitude: 0.60910

Collected Steps per Second: 22,574.27827
Overall Steps per Second: 10,524.23150

Timestep Collection Time: 2.21580
Timestep Consumption Time: 2.53704
PPO Batch Consumption Time: 0.30014
Total Iteration Time: 4.75284

Cumulative Model Updates: 96,742
Cumulative Timesteps: 806,852,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 806852470...
Checkpoint 806852470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.56617
Policy Entropy: 3.15533
Value Function Loss: 0.00474

Mean KL Divergence: 0.01586
SB3 Clip Fraction: 0.14344
Policy Update Magnitude: 0.56920
Value Function Update Magnitude: 0.60877

Collected Steps per Second: 22,456.44887
Overall Steps per Second: 10,636.16725

Timestep Collection Time: 2.22724
Timestep Consumption Time: 2.47520
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.70245

Cumulative Model Updates: 96,748
Cumulative Timesteps: 806,902,486

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.98288
Policy Entropy: 3.14960
Value Function Loss: 0.00473

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.14678
Policy Update Magnitude: 0.57056
Value Function Update Magnitude: 0.60535

Collected Steps per Second: 22,364.41412
Overall Steps per Second: 10,481.03188

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.53554
PPO Batch Consumption Time: 0.29943
Total Iteration Time: 4.77186

Cumulative Model Updates: 96,754
Cumulative Timesteps: 806,952,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 806952500...
Checkpoint 806952500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.77605
Policy Entropy: 3.17672
Value Function Loss: 0.00455

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.56874
Value Function Update Magnitude: 0.59705

Collected Steps per Second: 22,097.01064
Overall Steps per Second: 10,658.34740

Timestep Collection Time: 2.26356
Timestep Consumption Time: 2.42928
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.69285

Cumulative Model Updates: 96,760
Cumulative Timesteps: 807,002,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.76646
Policy Entropy: 3.16388
Value Function Loss: 0.00452

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.56950
Value Function Update Magnitude: 0.59595

Collected Steps per Second: 22,476.83646
Overall Steps per Second: 10,590.28079

Timestep Collection Time: 2.22514
Timestep Consumption Time: 2.49750
PPO Batch Consumption Time: 0.29469
Total Iteration Time: 4.72263

Cumulative Model Updates: 96,766
Cumulative Timesteps: 807,052,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 807052532...
Checkpoint 807052532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.47962
Policy Entropy: 3.18795
Value Function Loss: 0.00451

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10098
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.60239

Collected Steps per Second: 22,493.52542
Overall Steps per Second: 10,559.79165

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.51228
PPO Batch Consumption Time: 0.29788
Total Iteration Time: 4.73532

Cumulative Model Updates: 96,772
Cumulative Timesteps: 807,102,536

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.87776
Policy Entropy: 3.16549
Value Function Loss: 0.00446

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.55267
Value Function Update Magnitude: 0.60746

Collected Steps per Second: 22,439.28905
Overall Steps per Second: 10,602.67119

Timestep Collection Time: 2.22948
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.71843

Cumulative Model Updates: 96,778
Cumulative Timesteps: 807,152,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 807152564...
Checkpoint 807152564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.43849
Policy Entropy: 3.17579
Value Function Loss: 0.00436

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09582
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.62413

Collected Steps per Second: 22,626.88307
Overall Steps per Second: 10,708.07316

Timestep Collection Time: 2.21100
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.67199

Cumulative Model Updates: 96,784
Cumulative Timesteps: 807,202,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.58021
Policy Entropy: 3.16252
Value Function Loss: 0.00436

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.56041
Value Function Update Magnitude: 0.62656

Collected Steps per Second: 22,331.41449
Overall Steps per Second: 10,640.30217

Timestep Collection Time: 2.24043
Timestep Consumption Time: 2.46169
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.70212

Cumulative Model Updates: 96,790
Cumulative Timesteps: 807,252,624

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 807252624...
Checkpoint 807252624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.59702
Policy Entropy: 3.18273
Value Function Loss: 0.00430

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.55581
Value Function Update Magnitude: 0.60660

Collected Steps per Second: 22,295.81271
Overall Steps per Second: 10,550.27163

Timestep Collection Time: 2.24392
Timestep Consumption Time: 2.49814
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.74206

Cumulative Model Updates: 96,796
Cumulative Timesteps: 807,302,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.01296
Policy Entropy: 3.17303
Value Function Loss: 0.00459

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.56503
Value Function Update Magnitude: 0.59932

Collected Steps per Second: 22,555.40470
Overall Steps per Second: 10,429.96912

Timestep Collection Time: 2.21765
Timestep Consumption Time: 2.57815
PPO Batch Consumption Time: 0.30972
Total Iteration Time: 4.79580

Cumulative Model Updates: 96,802
Cumulative Timesteps: 807,352,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 807352674...
Checkpoint 807352674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.99567
Policy Entropy: 3.17534
Value Function Loss: 0.00465

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09643
Policy Update Magnitude: 0.57300
Value Function Update Magnitude: 0.62827

Collected Steps per Second: 22,244.66463
Overall Steps per Second: 10,630.16598

Timestep Collection Time: 2.24872
Timestep Consumption Time: 2.45695
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.70567

Cumulative Model Updates: 96,808
Cumulative Timesteps: 807,402,696

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.02605
Policy Entropy: 3.16888
Value Function Loss: 0.00459

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.56990
Value Function Update Magnitude: 0.63027

Collected Steps per Second: 22,628.89419
Overall Steps per Second: 10,535.21561

Timestep Collection Time: 2.21080
Timestep Consumption Time: 2.53784
PPO Batch Consumption Time: 0.29976
Total Iteration Time: 4.74865

Cumulative Model Updates: 96,814
Cumulative Timesteps: 807,452,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 807452724...
Checkpoint 807452724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.76499
Policy Entropy: 3.17260
Value Function Loss: 0.00450

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.62136

Collected Steps per Second: 22,228.77799
Overall Steps per Second: 10,640.34879

Timestep Collection Time: 2.25078
Timestep Consumption Time: 2.45133
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.70210

Cumulative Model Updates: 96,820
Cumulative Timesteps: 807,502,756

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.97982
Policy Entropy: 3.18682
Value Function Loss: 0.00425

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09518
Policy Update Magnitude: 0.55976
Value Function Update Magnitude: 0.59306

Collected Steps per Second: 22,757.94671
Overall Steps per Second: 10,629.78908

Timestep Collection Time: 2.19827
Timestep Consumption Time: 2.50813
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.70640

Cumulative Model Updates: 96,826
Cumulative Timesteps: 807,552,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 807552784...
Checkpoint 807552784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.19503
Policy Entropy: 3.19098
Value Function Loss: 0.00452

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08618
Policy Update Magnitude: 0.55481
Value Function Update Magnitude: 0.57831

Collected Steps per Second: 22,479.60141
Overall Steps per Second: 10,581.21872

Timestep Collection Time: 2.22548
Timestep Consumption Time: 2.50252
PPO Batch Consumption Time: 0.29812
Total Iteration Time: 4.72800

Cumulative Model Updates: 96,832
Cumulative Timesteps: 807,602,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.02450
Policy Entropy: 3.19452
Value Function Loss: 0.00465

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08465
Policy Update Magnitude: 0.56246
Value Function Update Magnitude: 0.57422

Collected Steps per Second: 22,756.13525
Overall Steps per Second: 10,712.80475

Timestep Collection Time: 2.19835
Timestep Consumption Time: 2.47139
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.66974

Cumulative Model Updates: 96,838
Cumulative Timesteps: 807,652,838

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 807652838...
Checkpoint 807652838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.12393
Policy Entropy: 3.20113
Value Function Loss: 0.00453

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.55676
Value Function Update Magnitude: 0.58345

Collected Steps per Second: 22,572.14619
Overall Steps per Second: 10,757.82329

Timestep Collection Time: 2.21609
Timestep Consumption Time: 2.43373
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.64983

Cumulative Model Updates: 96,844
Cumulative Timesteps: 807,702,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 774.29533
Policy Entropy: 3.20065
Value Function Loss: 0.00430

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.54403
Value Function Update Magnitude: 0.57992

Collected Steps per Second: 22,551.18586
Overall Steps per Second: 10,590.64508

Timestep Collection Time: 2.21789
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.72266

Cumulative Model Updates: 96,850
Cumulative Timesteps: 807,752,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 807752876...
Checkpoint 807752876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.93367
Policy Entropy: 3.17764
Value Function Loss: 0.00452

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.54779
Value Function Update Magnitude: 0.58188

Collected Steps per Second: 22,594.86911
Overall Steps per Second: 10,559.36470

Timestep Collection Time: 2.21360
Timestep Consumption Time: 2.52305
PPO Batch Consumption Time: 0.29869
Total Iteration Time: 4.73665

Cumulative Model Updates: 96,856
Cumulative Timesteps: 807,802,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.31124
Policy Entropy: 3.16978
Value Function Loss: 0.00437

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.55103
Value Function Update Magnitude: 0.59789

Collected Steps per Second: 22,528.19718
Overall Steps per Second: 10,698.00310

Timestep Collection Time: 2.22024
Timestep Consumption Time: 2.45521
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.67545

Cumulative Model Updates: 96,862
Cumulative Timesteps: 807,852,910

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 807852910...
Checkpoint 807852910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.04335
Policy Entropy: 3.18355
Value Function Loss: 0.00442

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.55110
Value Function Update Magnitude: 0.59851

Collected Steps per Second: 21,988.51041
Overall Steps per Second: 10,465.09896

Timestep Collection Time: 2.27482
Timestep Consumption Time: 2.50487
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.77970

Cumulative Model Updates: 96,868
Cumulative Timesteps: 807,902,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.85193
Policy Entropy: 3.20101
Value Function Loss: 0.00431

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.54360
Value Function Update Magnitude: 0.60409

Collected Steps per Second: 23,090.51567
Overall Steps per Second: 10,756.02812

Timestep Collection Time: 2.16747
Timestep Consumption Time: 2.48555
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.65302

Cumulative Model Updates: 96,874
Cumulative Timesteps: 807,952,978

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 807952978...
Checkpoint 807952978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,999.59896
Policy Entropy: 3.20294
Value Function Loss: 0.00434

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.54681
Value Function Update Magnitude: 0.60815

Collected Steps per Second: 21,807.43378
Overall Steps per Second: 10,495.48578

Timestep Collection Time: 2.29325
Timestep Consumption Time: 2.47165
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.76491

Cumulative Model Updates: 96,880
Cumulative Timesteps: 808,002,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.22623
Policy Entropy: 3.21515
Value Function Loss: 0.00412

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.54502
Value Function Update Magnitude: 0.60021

Collected Steps per Second: 22,513.42357
Overall Steps per Second: 10,610.86421

Timestep Collection Time: 2.22107
Timestep Consumption Time: 2.49145
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.71253

Cumulative Model Updates: 96,886
Cumulative Timesteps: 808,052,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 808052992...
Checkpoint 808052992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,622.05668
Policy Entropy: 3.22000
Value Function Loss: 0.00404

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.54167
Value Function Update Magnitude: 0.58492

Collected Steps per Second: 22,187.49319
Overall Steps per Second: 10,679.11473

Timestep Collection Time: 2.25370
Timestep Consumption Time: 2.42871
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.68241

Cumulative Model Updates: 96,892
Cumulative Timesteps: 808,102,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.76783
Policy Entropy: 3.21255
Value Function Loss: 0.00405

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.53632
Value Function Update Magnitude: 0.60043

Collected Steps per Second: 21,009.22754
Overall Steps per Second: 10,331.83368

Timestep Collection Time: 2.38076
Timestep Consumption Time: 2.46039
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.84115

Cumulative Model Updates: 96,898
Cumulative Timesteps: 808,153,014

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 808153014...
Checkpoint 808153014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.01271
Policy Entropy: 3.20477
Value Function Loss: 0.00419

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.54089
Value Function Update Magnitude: 0.61796

Collected Steps per Second: 22,442.66219
Overall Steps per Second: 10,727.46418

Timestep Collection Time: 2.22799
Timestep Consumption Time: 2.43313
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.66112

Cumulative Model Updates: 96,904
Cumulative Timesteps: 808,203,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.90455
Policy Entropy: 3.20010
Value Function Loss: 0.00450

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11364
Policy Update Magnitude: 0.55129
Value Function Update Magnitude: 0.64258

Collected Steps per Second: 22,973.00252
Overall Steps per Second: 10,862.77717

Timestep Collection Time: 2.17708
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.60416

Cumulative Model Updates: 96,910
Cumulative Timesteps: 808,253,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 808253030...
Checkpoint 808253030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.69867
Policy Entropy: 3.18802
Value Function Loss: 0.00455

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.55485
Value Function Update Magnitude: 0.64061

Collected Steps per Second: 22,851.97679
Overall Steps per Second: 10,722.16141

Timestep Collection Time: 2.18834
Timestep Consumption Time: 2.47564
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.66399

Cumulative Model Updates: 96,916
Cumulative Timesteps: 808,303,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.24537
Policy Entropy: 3.17518
Value Function Loss: 0.00455

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.55286
Value Function Update Magnitude: 0.64266

Collected Steps per Second: 22,712.59375
Overall Steps per Second: 10,692.43034

Timestep Collection Time: 2.20151
Timestep Consumption Time: 2.47488
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.67639

Cumulative Model Updates: 96,922
Cumulative Timesteps: 808,353,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 808353040...
Checkpoint 808353040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.58488
Policy Entropy: 3.18069
Value Function Loss: 0.00444

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.55127
Value Function Update Magnitude: 0.62499

Collected Steps per Second: 22,338.18550
Overall Steps per Second: 10,622.34374

Timestep Collection Time: 2.23895
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.70838

Cumulative Model Updates: 96,928
Cumulative Timesteps: 808,403,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.91875
Policy Entropy: 3.19104
Value Function Loss: 0.00443

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.55587
Value Function Update Magnitude: 0.62378

Collected Steps per Second: 23,202.90046
Overall Steps per Second: 10,773.52528

Timestep Collection Time: 2.15508
Timestep Consumption Time: 2.48630
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.64138

Cumulative Model Updates: 96,934
Cumulative Timesteps: 808,453,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 808453058...
Checkpoint 808453058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.99951
Policy Entropy: 3.19158
Value Function Loss: 0.00426

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.62683

Collected Steps per Second: 22,682.56148
Overall Steps per Second: 10,691.36252

Timestep Collection Time: 2.20460
Timestep Consumption Time: 2.47263
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.67723

Cumulative Model Updates: 96,940
Cumulative Timesteps: 808,503,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792.45793
Policy Entropy: 3.19622
Value Function Loss: 0.00446

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10371
Policy Update Magnitude: 0.55689
Value Function Update Magnitude: 0.63626

Collected Steps per Second: 23,311.01983
Overall Steps per Second: 10,744.30633

Timestep Collection Time: 2.14499
Timestep Consumption Time: 2.50882
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.65381

Cumulative Model Updates: 96,946
Cumulative Timesteps: 808,553,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 808553066...
Checkpoint 808553066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.12965
Policy Entropy: 3.20305
Value Function Loss: 0.00442

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.55729
Value Function Update Magnitude: 0.64507

Collected Steps per Second: 22,480.55001
Overall Steps per Second: 10,649.71730

Timestep Collection Time: 2.22459
Timestep Consumption Time: 2.47131
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.69590

Cumulative Model Updates: 96,952
Cumulative Timesteps: 808,603,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.98243
Policy Entropy: 3.19686
Value Function Loss: 0.00436

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11113
Policy Update Magnitude: 0.55007
Value Function Update Magnitude: 0.65046

Collected Steps per Second: 23,057.51539
Overall Steps per Second: 10,872.35857

Timestep Collection Time: 2.16988
Timestep Consumption Time: 2.43188
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.60176

Cumulative Model Updates: 96,958
Cumulative Timesteps: 808,653,108

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 808653108...
Checkpoint 808653108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.32287
Policy Entropy: 3.19323
Value Function Loss: 0.00405

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.53720
Value Function Update Magnitude: 0.62212

Collected Steps per Second: 22,653.45686
Overall Steps per Second: 10,710.92410

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.46214
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.67037

Cumulative Model Updates: 96,964
Cumulative Timesteps: 808,703,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.23590
Policy Entropy: 3.20357
Value Function Loss: 0.00413

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.53861
Value Function Update Magnitude: 0.59867

Collected Steps per Second: 22,990.41263
Overall Steps per Second: 10,758.92349

Timestep Collection Time: 2.17482
Timestep Consumption Time: 2.47249
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.64731

Cumulative Model Updates: 96,970
Cumulative Timesteps: 808,753,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 808753132...
Checkpoint 808753132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.73991
Policy Entropy: 3.20774
Value Function Loss: 0.00465

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.55664
Value Function Update Magnitude: 0.61368

Collected Steps per Second: 22,593.27666
Overall Steps per Second: 10,745.53180

Timestep Collection Time: 2.21367
Timestep Consumption Time: 2.44073
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.65440

Cumulative Model Updates: 96,976
Cumulative Timesteps: 808,803,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.72568
Policy Entropy: 3.21658
Value Function Loss: 0.00455

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11684
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.65110

Collected Steps per Second: 22,876.16746
Overall Steps per Second: 10,832.19200

Timestep Collection Time: 2.18664
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.61790

Cumulative Model Updates: 96,982
Cumulative Timesteps: 808,853,168

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 808853168...
Checkpoint 808853168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.36984
Policy Entropy: 3.21211
Value Function Loss: 0.00427

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.55462
Value Function Update Magnitude: 0.64576

Collected Steps per Second: 22,902.72771
Overall Steps per Second: 10,727.83249

Timestep Collection Time: 2.18358
Timestep Consumption Time: 2.47812
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.66171

Cumulative Model Updates: 96,988
Cumulative Timesteps: 808,903,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.21481
Policy Entropy: 3.21364
Value Function Loss: 0.00431

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.55045
Value Function Update Magnitude: 0.62073

Collected Steps per Second: 23,080.47782
Overall Steps per Second: 10,879.30421

Timestep Collection Time: 2.16720
Timestep Consumption Time: 2.43052
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.59772

Cumulative Model Updates: 96,994
Cumulative Timesteps: 808,953,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 808953198...
Checkpoint 808953198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.21526
Policy Entropy: 3.21197
Value Function Loss: 0.00444

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.55720
Value Function Update Magnitude: 0.63045

Collected Steps per Second: 22,626.85772
Overall Steps per Second: 10,673.89275

Timestep Collection Time: 2.20985
Timestep Consumption Time: 2.47466
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.68451

Cumulative Model Updates: 97,000
Cumulative Timesteps: 809,003,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.28783
Policy Entropy: 3.20997
Value Function Loss: 0.00455

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.55956
Value Function Update Magnitude: 0.63759

Collected Steps per Second: 22,747.37279
Overall Steps per Second: 10,825.11158

Timestep Collection Time: 2.19832
Timestep Consumption Time: 2.42112
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.61944

Cumulative Model Updates: 97,006
Cumulative Timesteps: 809,053,206

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 809053206...
Checkpoint 809053206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,300.87825
Policy Entropy: 3.22865
Value Function Loss: 0.00407

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.55248
Value Function Update Magnitude: 0.60293

Collected Steps per Second: 22,711.30741
Overall Steps per Second: 10,744.88048

Timestep Collection Time: 2.20207
Timestep Consumption Time: 2.45242
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.65450

Cumulative Model Updates: 97,012
Cumulative Timesteps: 809,103,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.57142
Policy Entropy: 3.22213
Value Function Loss: 0.00395

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.53663
Value Function Update Magnitude: 0.57975

Collected Steps per Second: 22,524.22902
Overall Steps per Second: 10,637.96675

Timestep Collection Time: 2.21992
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.70033

Cumulative Model Updates: 97,018
Cumulative Timesteps: 809,153,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 809153220...
Checkpoint 809153220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.93811
Policy Entropy: 3.22416
Value Function Loss: 0.00392

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.53524
Value Function Update Magnitude: 0.58177

Collected Steps per Second: 22,569.52637
Overall Steps per Second: 10,779.34097

Timestep Collection Time: 2.21671
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.64129

Cumulative Model Updates: 97,024
Cumulative Timesteps: 809,203,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.32686
Policy Entropy: 3.22541
Value Function Loss: 0.00411

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.53544
Value Function Update Magnitude: 0.56677

Collected Steps per Second: 22,846.39045
Overall Steps per Second: 10,715.04621

Timestep Collection Time: 2.18976
Timestep Consumption Time: 2.47919
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.66895

Cumulative Model Updates: 97,030
Cumulative Timesteps: 809,253,278

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 809253278...
Checkpoint 809253278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.83909
Policy Entropy: 3.22365
Value Function Loss: 0.00442

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.57763

Collected Steps per Second: 22,688.47287
Overall Steps per Second: 10,744.66673

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.44981
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.65366

Cumulative Model Updates: 97,036
Cumulative Timesteps: 809,303,280

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757.10524
Policy Entropy: 3.22575
Value Function Loss: 0.00444

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.55471
Value Function Update Magnitude: 0.57374

Collected Steps per Second: 23,209.76362
Overall Steps per Second: 10,720.98380

Timestep Collection Time: 2.15427
Timestep Consumption Time: 2.50949
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.66375

Cumulative Model Updates: 97,042
Cumulative Timesteps: 809,353,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 809353280...
Checkpoint 809353280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.11228
Policy Entropy: 3.20310
Value Function Loss: 0.00442

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09957
Policy Update Magnitude: 0.55208
Value Function Update Magnitude: 0.57641

Collected Steps per Second: 22,771.30289
Overall Steps per Second: 10,639.95165

Timestep Collection Time: 2.19627
Timestep Consumption Time: 2.50412
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.70040

Cumulative Model Updates: 97,048
Cumulative Timesteps: 809,403,292

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,680.29242
Policy Entropy: 3.19464
Value Function Loss: 0.00432

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.57317

Collected Steps per Second: 23,046.85697
Overall Steps per Second: 10,876.30225

Timestep Collection Time: 2.17045
Timestep Consumption Time: 2.42873
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.59917

Cumulative Model Updates: 97,054
Cumulative Timesteps: 809,453,314

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 809453314...
Checkpoint 809453314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.48183
Policy Entropy: 3.18960
Value Function Loss: 0.00417

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08766
Policy Update Magnitude: 0.55183
Value Function Update Magnitude: 0.59057

Collected Steps per Second: 22,857.00493
Overall Steps per Second: 10,579.41129

Timestep Collection Time: 2.18751
Timestep Consumption Time: 2.53865
PPO Batch Consumption Time: 0.29805
Total Iteration Time: 4.72616

Cumulative Model Updates: 97,060
Cumulative Timesteps: 809,503,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.10822
Policy Entropy: 3.18913
Value Function Loss: 0.00427

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.55151
Value Function Update Magnitude: 0.59596

Collected Steps per Second: 22,994.82522
Overall Steps per Second: 10,694.01900

Timestep Collection Time: 2.17536
Timestep Consumption Time: 2.50221
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.67757

Cumulative Model Updates: 97,066
Cumulative Timesteps: 809,553,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 809553336...
Checkpoint 809553336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.79092
Policy Entropy: 3.19908
Value Function Loss: 0.00452

Mean KL Divergence: 0.00783
SB3 Clip Fraction: 0.08567
Policy Update Magnitude: 0.55124
Value Function Update Magnitude: 0.59810

Collected Steps per Second: 22,588.03928
Overall Steps per Second: 10,772.49956

Timestep Collection Time: 2.21445
Timestep Consumption Time: 2.42886
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.64330

Cumulative Model Updates: 97,072
Cumulative Timesteps: 809,603,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,682.67477
Policy Entropy: 3.19451
Value Function Loss: 0.00457

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.55104
Value Function Update Magnitude: 0.58997

Collected Steps per Second: 22,718.86089
Overall Steps per Second: 10,707.57241

Timestep Collection Time: 2.20090
Timestep Consumption Time: 2.46888
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.66978

Cumulative Model Updates: 97,078
Cumulative Timesteps: 809,653,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 809653358...
Checkpoint 809653358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.07050
Policy Entropy: 3.19265
Value Function Loss: 0.00451

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.55822
Value Function Update Magnitude: 0.59865

Collected Steps per Second: 22,489.66347
Overall Steps per Second: 10,606.57242

Timestep Collection Time: 2.22449
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.71670

Cumulative Model Updates: 97,084
Cumulative Timesteps: 809,703,386

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,104.36421
Policy Entropy: 3.18468
Value Function Loss: 0.00447

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09700
Policy Update Magnitude: 0.55846
Value Function Update Magnitude: 0.58050

Collected Steps per Second: 23,080.55513
Overall Steps per Second: 10,778.65842

Timestep Collection Time: 2.16745
Timestep Consumption Time: 2.47376
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.64121

Cumulative Model Updates: 97,090
Cumulative Timesteps: 809,753,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 809753412...
Checkpoint 809753412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.17001
Policy Entropy: 3.17010
Value Function Loss: 0.00456

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.58429

Collected Steps per Second: 22,430.68228
Overall Steps per Second: 10,674.70467

Timestep Collection Time: 2.23025
Timestep Consumption Time: 2.45616
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.68641

Cumulative Model Updates: 97,096
Cumulative Timesteps: 809,803,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.51981
Policy Entropy: 3.15939
Value Function Loss: 0.00448

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10408
Policy Update Magnitude: 0.55358
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 23,005.22260
Overall Steps per Second: 10,865.02565

Timestep Collection Time: 2.17359
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.60229

Cumulative Model Updates: 97,102
Cumulative Timesteps: 809,853,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 809853442...
Checkpoint 809853442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.10509
Policy Entropy: 3.14640
Value Function Loss: 0.00447

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12286
Policy Update Magnitude: 0.56003
Value Function Update Magnitude: 0.61920

Collected Steps per Second: 22,568.96724
Overall Steps per Second: 10,688.45664

Timestep Collection Time: 2.21667
Timestep Consumption Time: 2.46389
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.68056

Cumulative Model Updates: 97,108
Cumulative Timesteps: 809,903,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,729.72702
Policy Entropy: 3.14682
Value Function Loss: 0.00448

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12577
Policy Update Magnitude: 0.55914
Value Function Update Magnitude: 0.61430

Collected Steps per Second: 23,076.91811
Overall Steps per Second: 10,855.63446

Timestep Collection Time: 2.16675
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.60609

Cumulative Model Updates: 97,114
Cumulative Timesteps: 809,953,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 809953472...
Checkpoint 809953472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.08228
Policy Entropy: 3.15192
Value Function Loss: 0.00480

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.56382
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 22,618.97951
Overall Steps per Second: 10,644.34286

Timestep Collection Time: 2.21106
Timestep Consumption Time: 2.48739
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.69846

Cumulative Model Updates: 97,120
Cumulative Timesteps: 810,003,484

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.28127
Policy Entropy: 3.16170
Value Function Loss: 0.00462

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11644
Policy Update Magnitude: 0.56710
Value Function Update Magnitude: 0.59168

Collected Steps per Second: 22,921.13495
Overall Steps per Second: 10,864.78246

Timestep Collection Time: 2.18209
Timestep Consumption Time: 2.42141
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.60350

Cumulative Model Updates: 97,126
Cumulative Timesteps: 810,053,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 810053500...
Checkpoint 810053500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.05013
Policy Entropy: 3.18586
Value Function Loss: 0.00486

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11978
Policy Update Magnitude: 0.56297
Value Function Update Magnitude: 0.59325

Collected Steps per Second: 22,929.98806
Overall Steps per Second: 10,719.71437

Timestep Collection Time: 2.18081
Timestep Consumption Time: 2.48405
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.66486

Cumulative Model Updates: 97,132
Cumulative Timesteps: 810,103,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.42757
Policy Entropy: 3.17884
Value Function Loss: 0.00477

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11676
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.60546

Collected Steps per Second: 22,846.61224
Overall Steps per Second: 10,806.52159

Timestep Collection Time: 2.18921
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.62832

Cumulative Model Updates: 97,138
Cumulative Timesteps: 810,153,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 810153522...
Checkpoint 810153522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.34567
Policy Entropy: 3.17519
Value Function Loss: 0.00493

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.56060
Value Function Update Magnitude: 0.60416

Collected Steps per Second: 22,753.94138
Overall Steps per Second: 10,726.87953

Timestep Collection Time: 2.19742
Timestep Consumption Time: 2.46377
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.66119

Cumulative Model Updates: 97,144
Cumulative Timesteps: 810,203,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.68087
Policy Entropy: 3.18131
Value Function Loss: 0.00462

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.56204
Value Function Update Magnitude: 0.60777

Collected Steps per Second: 22,903.56882
Overall Steps per Second: 10,849.23447

Timestep Collection Time: 2.18385
Timestep Consumption Time: 2.42643
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.61028

Cumulative Model Updates: 97,150
Cumulative Timesteps: 810,253,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 810253540...
Checkpoint 810253540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,568.33716
Policy Entropy: 3.19637
Value Function Loss: 0.00454

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09492
Policy Update Magnitude: 0.55839
Value Function Update Magnitude: 0.59682

Collected Steps per Second: 22,450.27641
Overall Steps per Second: 10,696.95804

Timestep Collection Time: 2.22759
Timestep Consumption Time: 2.44757
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.67516

Cumulative Model Updates: 97,156
Cumulative Timesteps: 810,303,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.90572
Policy Entropy: 3.19137
Value Function Loss: 0.00435

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.08370
Policy Update Magnitude: 0.55386
Value Function Update Magnitude: 0.57968

Collected Steps per Second: 22,817.90499
Overall Steps per Second: 10,834.27115

Timestep Collection Time: 2.19240
Timestep Consumption Time: 2.42498
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.61738

Cumulative Model Updates: 97,162
Cumulative Timesteps: 810,353,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 810353576...
Checkpoint 810353576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.45316
Policy Entropy: 3.19577
Value Function Loss: 0.00444

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.08292
Policy Update Magnitude: 0.55021
Value Function Update Magnitude: 0.58011

Collected Steps per Second: 22,537.58705
Overall Steps per Second: 10,689.91334

Timestep Collection Time: 2.21958
Timestep Consumption Time: 2.45997
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.67955

Cumulative Model Updates: 97,168
Cumulative Timesteps: 810,403,600

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.89127
Policy Entropy: 3.19183
Value Function Loss: 0.00435

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08763
Policy Update Magnitude: 0.55344
Value Function Update Magnitude: 0.60100

Collected Steps per Second: 22,804.05552
Overall Steps per Second: 10,718.73987

Timestep Collection Time: 2.19373
Timestep Consumption Time: 2.47342
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.66715

Cumulative Model Updates: 97,174
Cumulative Timesteps: 810,453,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 810453626...
Checkpoint 810453626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.03297
Policy Entropy: 3.20701
Value Function Loss: 0.00439

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08357
Policy Update Magnitude: 0.55102
Value Function Update Magnitude: 0.61591

Collected Steps per Second: 22,935.79559
Overall Steps per Second: 10,817.67872

Timestep Collection Time: 2.18043
Timestep Consumption Time: 2.44255
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.62299

Cumulative Model Updates: 97,180
Cumulative Timesteps: 810,503,636

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.45700
Policy Entropy: 3.19518
Value Function Loss: 0.00456

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08830
Policy Update Magnitude: 0.55885
Value Function Update Magnitude: 0.62036

Collected Steps per Second: 23,094.17953
Overall Steps per Second: 10,855.44025

Timestep Collection Time: 2.16557
Timestep Consumption Time: 2.44152
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.60709

Cumulative Model Updates: 97,186
Cumulative Timesteps: 810,553,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 810553648...
Checkpoint 810553648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 997.08444
Policy Entropy: 3.19474
Value Function Loss: 0.00478

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.56380
Value Function Update Magnitude: 0.62093

Collected Steps per Second: 22,582.15256
Overall Steps per Second: 10,724.78920

Timestep Collection Time: 2.21467
Timestep Consumption Time: 2.44855
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.66322

Cumulative Model Updates: 97,192
Cumulative Timesteps: 810,603,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.86640
Policy Entropy: 3.18573
Value Function Loss: 0.00505

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.56706
Value Function Update Magnitude: 0.63633

Collected Steps per Second: 23,013.60804
Overall Steps per Second: 10,818.60980

Timestep Collection Time: 2.17263
Timestep Consumption Time: 2.44904
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.62167

Cumulative Model Updates: 97,198
Cumulative Timesteps: 810,653,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 810653660...
Checkpoint 810653660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.55291
Policy Entropy: 3.18866
Value Function Loss: 0.00503

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11328
Policy Update Magnitude: 0.57639
Value Function Update Magnitude: 0.63086

Collected Steps per Second: 22,546.16938
Overall Steps per Second: 10,793.59863

Timestep Collection Time: 2.21998
Timestep Consumption Time: 2.41721
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.63719

Cumulative Model Updates: 97,204
Cumulative Timesteps: 810,703,712

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,462.11281
Policy Entropy: 3.18872
Value Function Loss: 0.00499

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.58351
Value Function Update Magnitude: 0.63033

Collected Steps per Second: 23,089.13599
Overall Steps per Second: 10,886.90173

Timestep Collection Time: 2.16587
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.59341

Cumulative Model Updates: 97,210
Cumulative Timesteps: 810,753,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 810753720...
Checkpoint 810753720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.83219
Policy Entropy: 3.17101
Value Function Loss: 0.00478

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.57561
Value Function Update Magnitude: 0.62479

Collected Steps per Second: 22,722.22404
Overall Steps per Second: 10,624.10250

Timestep Collection Time: 2.20084
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.70703

Cumulative Model Updates: 97,216
Cumulative Timesteps: 810,803,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.30898
Policy Entropy: 3.18103
Value Function Loss: 0.00477

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.57381
Value Function Update Magnitude: 0.60115

Collected Steps per Second: 22,770.30932
Overall Steps per Second: 10,821.79982

Timestep Collection Time: 2.19628
Timestep Consumption Time: 2.42495
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.62123

Cumulative Model Updates: 97,222
Cumulative Timesteps: 810,853,738

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 810853738...
Checkpoint 810853738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.27088
Policy Entropy: 3.17385
Value Function Loss: 0.00479

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.56608
Value Function Update Magnitude: 0.58281

Collected Steps per Second: 22,623.35096
Overall Steps per Second: 10,724.89439

Timestep Collection Time: 2.21143
Timestep Consumption Time: 2.45342
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.66485

Cumulative Model Updates: 97,228
Cumulative Timesteps: 810,903,768

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.39644
Policy Entropy: 3.18789
Value Function Loss: 0.00470

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.56437
Value Function Update Magnitude: 0.58478

Collected Steps per Second: 23,128.60567
Overall Steps per Second: 10,890.78067

Timestep Collection Time: 2.16243
Timestep Consumption Time: 2.42989
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.59232

Cumulative Model Updates: 97,234
Cumulative Timesteps: 810,953,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 810953782...
Checkpoint 810953782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.77639
Policy Entropy: 3.18212
Value Function Loss: 0.00488

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.57432
Value Function Update Magnitude: 0.59623

Collected Steps per Second: 22,477.30929
Overall Steps per Second: 10,635.21775

Timestep Collection Time: 2.22464
Timestep Consumption Time: 2.47709
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.70174

Cumulative Model Updates: 97,240
Cumulative Timesteps: 811,003,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.40445
Policy Entropy: 3.19260
Value Function Loss: 0.00485

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.60394

Collected Steps per Second: 23,294.25153
Overall Steps per Second: 10,892.31448

Timestep Collection Time: 2.14688
Timestep Consumption Time: 2.44443
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.59131

Cumulative Model Updates: 97,246
Cumulative Timesteps: 811,053,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 811053796...
Checkpoint 811053796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.78836
Policy Entropy: 3.17963
Value Function Loss: 0.00501

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.57467
Value Function Update Magnitude: 0.61349

Collected Steps per Second: 22,572.83877
Overall Steps per Second: 10,679.65239

Timestep Collection Time: 2.21576
Timestep Consumption Time: 2.46754
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.68330

Cumulative Model Updates: 97,252
Cumulative Timesteps: 811,103,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.69940
Policy Entropy: 3.17837
Value Function Loss: 0.00477

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11026
Policy Update Magnitude: 0.57725
Value Function Update Magnitude: 0.62985

Collected Steps per Second: 22,888.67069
Overall Steps per Second: 10,815.10057

Timestep Collection Time: 2.18510
Timestep Consumption Time: 2.43936
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.62446

Cumulative Model Updates: 97,258
Cumulative Timesteps: 811,153,826

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 811153826...
Checkpoint 811153826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.85668
Policy Entropy: 3.15886
Value Function Loss: 0.00517

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.59052
Value Function Update Magnitude: 0.62174

Collected Steps per Second: 22,181.95705
Overall Steps per Second: 10,690.88458

Timestep Collection Time: 2.25544
Timestep Consumption Time: 2.42425
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.67969

Cumulative Model Updates: 97,264
Cumulative Timesteps: 811,203,856

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.73913
Policy Entropy: 3.16813
Value Function Loss: 0.00520

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.59199
Value Function Update Magnitude: 0.63355

Collected Steps per Second: 22,692.02710
Overall Steps per Second: 10,926.33286

Timestep Collection Time: 2.20492
Timestep Consumption Time: 2.37430
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.57921

Cumulative Model Updates: 97,270
Cumulative Timesteps: 811,253,890

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 811253890...
Checkpoint 811253890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.79580
Policy Entropy: 3.17287
Value Function Loss: 0.00501

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.59070
Value Function Update Magnitude: 0.63702

Collected Steps per Second: 22,096.52020
Overall Steps per Second: 10,678.95374

Timestep Collection Time: 2.26407
Timestep Consumption Time: 2.42066
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.68473

Cumulative Model Updates: 97,276
Cumulative Timesteps: 811,303,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.85317
Policy Entropy: 3.18894
Value Function Loss: 0.00478

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.57479
Value Function Update Magnitude: 0.61157

Collected Steps per Second: 22,498.14840
Overall Steps per Second: 10,836.85856

Timestep Collection Time: 2.22267
Timestep Consumption Time: 2.39177
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.61444

Cumulative Model Updates: 97,282
Cumulative Timesteps: 811,353,924

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 811353924...
Checkpoint 811353924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.24558
Policy Entropy: 3.21009
Value Function Loss: 0.00438

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.56093
Value Function Update Magnitude: 0.58291

Collected Steps per Second: 22,157.45833
Overall Steps per Second: 10,665.22229

Timestep Collection Time: 2.25685
Timestep Consumption Time: 2.43185
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.68870

Cumulative Model Updates: 97,288
Cumulative Timesteps: 811,403,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.46697
Policy Entropy: 3.20383
Value Function Loss: 0.00439

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.55368
Value Function Update Magnitude: 0.57284

Collected Steps per Second: 22,174.96354
Overall Steps per Second: 10,731.67875

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.40594
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.66227

Cumulative Model Updates: 97,294
Cumulative Timesteps: 811,453,964

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 811453964...
Checkpoint 811453964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.51175
Policy Entropy: 3.20757
Value Function Loss: 0.00429

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.55242
Value Function Update Magnitude: 0.59116

Collected Steps per Second: 21,959.34811
Overall Steps per Second: 10,732.01291

Timestep Collection Time: 2.27703
Timestep Consumption Time: 2.38212
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.65914

Cumulative Model Updates: 97,300
Cumulative Timesteps: 811,503,966

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.66915
Policy Entropy: 3.20926
Value Function Loss: 0.00434

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.58953

Collected Steps per Second: 22,781.27651
Overall Steps per Second: 10,608.12364

Timestep Collection Time: 2.19505
Timestep Consumption Time: 2.51889
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.71393

Cumulative Model Updates: 97,306
Cumulative Timesteps: 811,553,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 811553972...
Checkpoint 811553972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.49243
Policy Entropy: 3.21130
Value Function Loss: 0.00458

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09341
Policy Update Magnitude: 0.56174
Value Function Update Magnitude: 0.57377

Collected Steps per Second: 21,872.71335
Overall Steps per Second: 10,575.31073

Timestep Collection Time: 2.28705
Timestep Consumption Time: 2.44321
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.73026

Cumulative Model Updates: 97,312
Cumulative Timesteps: 811,603,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.48773
Policy Entropy: 3.20843
Value Function Loss: 0.00465

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.07977
Policy Update Magnitude: 0.56607
Value Function Update Magnitude: 0.58042

Collected Steps per Second: 22,472.64231
Overall Steps per Second: 10,800.92379

Timestep Collection Time: 2.22511
Timestep Consumption Time: 2.40450
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.62960

Cumulative Model Updates: 97,318
Cumulative Timesteps: 811,654,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 811654000...
Checkpoint 811654000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.79575
Policy Entropy: 3.20641
Value Function Loss: 0.00460

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09205
Policy Update Magnitude: 0.56817
Value Function Update Magnitude: 0.59761

Collected Steps per Second: 21,989.85022
Overall Steps per Second: 10,747.32171

Timestep Collection Time: 2.27487
Timestep Consumption Time: 2.37969
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.65455

Cumulative Model Updates: 97,324
Cumulative Timesteps: 811,704,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.28595
Policy Entropy: 3.20802
Value Function Loss: 0.00424

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08845
Policy Update Magnitude: 0.56203
Value Function Update Magnitude: 0.59221

Collected Steps per Second: 22,326.25730
Overall Steps per Second: 10,815.50728

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.38462
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.62521

Cumulative Model Updates: 97,330
Cumulative Timesteps: 811,754,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 811754048...
Checkpoint 811754048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 850.31730
Policy Entropy: 3.21416
Value Function Loss: 0.00423

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08234
Policy Update Magnitude: 0.55136
Value Function Update Magnitude: 0.57366

Collected Steps per Second: 22,680.22189
Overall Steps per Second: 10,766.22621

Timestep Collection Time: 2.20492
Timestep Consumption Time: 2.43998
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.64490

Cumulative Model Updates: 97,336
Cumulative Timesteps: 811,804,056

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.60615
Policy Entropy: 3.19232
Value Function Loss: 0.00459

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.55645
Value Function Update Magnitude: 0.57697

Collected Steps per Second: 22,879.74609
Overall Steps per Second: 10,786.47468

Timestep Collection Time: 2.18639
Timestep Consumption Time: 2.45127
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.63766

Cumulative Model Updates: 97,342
Cumulative Timesteps: 811,854,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 811854080...
Checkpoint 811854080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.61073
Policy Entropy: 3.19023
Value Function Loss: 0.00461

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.56446
Value Function Update Magnitude: 0.61580

Collected Steps per Second: 22,938.48996
Overall Steps per Second: 10,770.46486

Timestep Collection Time: 2.18175
Timestep Consumption Time: 2.46485
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.64660

Cumulative Model Updates: 97,348
Cumulative Timesteps: 811,904,126

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.35359
Policy Entropy: 3.17180
Value Function Loss: 0.00471

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.57122
Value Function Update Magnitude: 0.62592

Collected Steps per Second: 22,428.28638
Overall Steps per Second: 10,501.31751

Timestep Collection Time: 2.23031
Timestep Consumption Time: 2.53309
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.76340

Cumulative Model Updates: 97,354
Cumulative Timesteps: 811,954,148

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 811954148...
Checkpoint 811954148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.88391
Policy Entropy: 3.18007
Value Function Loss: 0.00438

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08340
Policy Update Magnitude: 0.57033
Value Function Update Magnitude: 0.61714

Collected Steps per Second: 22,835.44839
Overall Steps per Second: 10,602.79065

Timestep Collection Time: 2.19010
Timestep Consumption Time: 2.52677
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.71687

Cumulative Model Updates: 97,360
Cumulative Timesteps: 812,004,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639.12176
Policy Entropy: 3.16867
Value Function Loss: 0.00463

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.56912
Value Function Update Magnitude: 0.60651

Collected Steps per Second: 22,907.04802
Overall Steps per Second: 10,803.98161

Timestep Collection Time: 2.18343
Timestep Consumption Time: 2.44597
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.62940

Cumulative Model Updates: 97,366
Cumulative Timesteps: 812,054,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 812054176...
Checkpoint 812054176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.80877
Policy Entropy: 3.17341
Value Function Loss: 0.00472

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.57123
Value Function Update Magnitude: 0.61653

Collected Steps per Second: 22,940.23948
Overall Steps per Second: 10,723.55102

Timestep Collection Time: 2.17958
Timestep Consumption Time: 2.48306
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.66263

Cumulative Model Updates: 97,372
Cumulative Timesteps: 812,104,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.90061
Policy Entropy: 3.17726
Value Function Loss: 0.00482

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.57353
Value Function Update Magnitude: 0.63026

Collected Steps per Second: 23,037.58892
Overall Steps per Second: 10,832.49613

Timestep Collection Time: 2.17089
Timestep Consumption Time: 2.44596
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.61685

Cumulative Model Updates: 97,378
Cumulative Timesteps: 812,154,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 812154188...
Checkpoint 812154188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.75144
Policy Entropy: 3.17457
Value Function Loss: 0.00481

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.57547
Value Function Update Magnitude: 0.63343

Collected Steps per Second: 22,758.87688
Overall Steps per Second: 10,695.16292

Timestep Collection Time: 2.19721
Timestep Consumption Time: 2.47836
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.67557

Cumulative Model Updates: 97,384
Cumulative Timesteps: 812,204,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.68694
Policy Entropy: 3.16476
Value Function Loss: 0.00487

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11566
Policy Update Magnitude: 0.58174
Value Function Update Magnitude: 0.63490

Collected Steps per Second: 22,978.29155
Overall Steps per Second: 10,817.02646

Timestep Collection Time: 2.17727
Timestep Consumption Time: 2.44784
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.62512

Cumulative Model Updates: 97,390
Cumulative Timesteps: 812,254,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 812254224...
Checkpoint 812254224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.87096
Policy Entropy: 3.15346
Value Function Loss: 0.00511

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.58573
Value Function Update Magnitude: 0.64630

Collected Steps per Second: 22,673.86020
Overall Steps per Second: 10,726.81437

Timestep Collection Time: 2.20624
Timestep Consumption Time: 2.45721
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.66345

Cumulative Model Updates: 97,396
Cumulative Timesteps: 812,304,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.10242
Policy Entropy: 3.15508
Value Function Loss: 0.00485

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.58645
Value Function Update Magnitude: 0.62144

Collected Steps per Second: 23,202.84835
Overall Steps per Second: 10,853.59703

Timestep Collection Time: 2.15603
Timestep Consumption Time: 2.45313
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.60916

Cumulative Model Updates: 97,402
Cumulative Timesteps: 812,354,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 812354274...
Checkpoint 812354274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,757.84093
Policy Entropy: 3.16634
Value Function Loss: 0.00444

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.56580
Value Function Update Magnitude: 0.58772

Collected Steps per Second: 22,682.15380
Overall Steps per Second: 10,773.61563

Timestep Collection Time: 2.20438
Timestep Consumption Time: 2.43659
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.64097

Cumulative Model Updates: 97,408
Cumulative Timesteps: 812,404,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.11172
Policy Entropy: 3.16821
Value Function Loss: 0.00429

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.55172
Value Function Update Magnitude: 0.57761

Collected Steps per Second: 23,106.91728
Overall Steps per Second: 10,819.43688

Timestep Collection Time: 2.16385
Timestep Consumption Time: 2.45746
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.62131

Cumulative Model Updates: 97,414
Cumulative Timesteps: 812,454,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 812454274...
Checkpoint 812454274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,189.19048
Policy Entropy: 3.17684
Value Function Loss: 0.00429

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09114
Policy Update Magnitude: 0.56116
Value Function Update Magnitude: 0.59202

Collected Steps per Second: 22,672.21303
Overall Steps per Second: 10,682.69297

Timestep Collection Time: 2.20649
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.68290

Cumulative Model Updates: 97,420
Cumulative Timesteps: 812,504,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.37205
Policy Entropy: 3.18461
Value Function Loss: 0.00461

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.56775
Value Function Update Magnitude: 0.60831

Collected Steps per Second: 22,998.39639
Overall Steps per Second: 10,798.70669

Timestep Collection Time: 2.17528
Timestep Consumption Time: 2.45749
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.63278

Cumulative Model Updates: 97,426
Cumulative Timesteps: 812,554,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 812554328...
Checkpoint 812554328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.58121
Policy Entropy: 3.17188
Value Function Loss: 0.00456

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.56428
Value Function Update Magnitude: 0.60840

Collected Steps per Second: 22,495.77760
Overall Steps per Second: 10,675.11902

Timestep Collection Time: 2.22380
Timestep Consumption Time: 2.46243
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.68622

Cumulative Model Updates: 97,432
Cumulative Timesteps: 812,604,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.31370
Policy Entropy: 3.17219
Value Function Loss: 0.00470

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.56601
Value Function Update Magnitude: 0.60420

Collected Steps per Second: 22,741.14351
Overall Steps per Second: 10,629.19765

Timestep Collection Time: 2.20051
Timestep Consumption Time: 2.50747
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.70798

Cumulative Model Updates: 97,438
Cumulative Timesteps: 812,654,396

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 812654396...
Checkpoint 812654396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.55522
Policy Entropy: 3.15950
Value Function Loss: 0.00473

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10090
Policy Update Magnitude: 0.57395
Value Function Update Magnitude: 0.63263

Collected Steps per Second: 22,588.53726
Overall Steps per Second: 10,567.30917

Timestep Collection Time: 2.21422
Timestep Consumption Time: 2.51887
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.73309

Cumulative Model Updates: 97,444
Cumulative Timesteps: 812,704,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.01738
Policy Entropy: 3.15877
Value Function Loss: 0.00466

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.58156
Value Function Update Magnitude: 0.67607

Collected Steps per Second: 22,830.78233
Overall Steps per Second: 10,774.80046

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.45063
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.64083

Cumulative Model Updates: 97,450
Cumulative Timesteps: 812,754,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 812754416...
Checkpoint 812754416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.96591
Policy Entropy: 3.16203
Value Function Loss: 0.00468

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11890
Policy Update Magnitude: 0.58024
Value Function Update Magnitude: 0.66643

Collected Steps per Second: 22,706.58951
Overall Steps per Second: 10,763.89594

Timestep Collection Time: 2.20271
Timestep Consumption Time: 2.44394
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.64664

Cumulative Model Updates: 97,456
Cumulative Timesteps: 812,804,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.42733
Policy Entropy: 3.18579
Value Function Loss: 0.00461

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.57608
Value Function Update Magnitude: 0.65672

Collected Steps per Second: 23,023.23233
Overall Steps per Second: 10,806.13574

Timestep Collection Time: 2.17224
Timestep Consumption Time: 2.45587
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.62811

Cumulative Model Updates: 97,462
Cumulative Timesteps: 812,854,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 812854444...
Checkpoint 812854444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.94377
Policy Entropy: 3.18763
Value Function Loss: 0.00452

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.57536
Value Function Update Magnitude: 0.66106

Collected Steps per Second: 22,650.80751
Overall Steps per Second: 10,710.59029

Timestep Collection Time: 2.20804
Timestep Consumption Time: 2.46154
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.66958

Cumulative Model Updates: 97,468
Cumulative Timesteps: 812,904,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.03128
Policy Entropy: 3.15534
Value Function Loss: 0.00461

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.57573
Value Function Update Magnitude: 0.63400

Collected Steps per Second: 22,828.53700
Overall Steps per Second: 10,665.13862

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.49793
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.68817

Cumulative Model Updates: 97,474
Cumulative Timesteps: 812,954,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 812954458...
Checkpoint 812954458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.77434
Policy Entropy: 3.15423
Value Function Loss: 0.00448

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.57851
Value Function Update Magnitude: 0.62624

Collected Steps per Second: 22,982.57574
Overall Steps per Second: 10,842.12707

Timestep Collection Time: 2.17634
Timestep Consumption Time: 2.43696
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.61330

Cumulative Model Updates: 97,480
Cumulative Timesteps: 813,004,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.01037
Policy Entropy: 3.14184
Value Function Loss: 0.00467

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.58685
Value Function Update Magnitude: 0.61884

Collected Steps per Second: 22,795.47028
Overall Steps per Second: 10,640.25733

Timestep Collection Time: 2.19359
Timestep Consumption Time: 2.50592
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.69951

Cumulative Model Updates: 97,486
Cumulative Timesteps: 813,054,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 813054480...
Checkpoint 813054480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.94917
Policy Entropy: 3.15538
Value Function Loss: 0.00472

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.14171
Policy Update Magnitude: 0.57840
Value Function Update Magnitude: 0.63114

Collected Steps per Second: 22,805.85847
Overall Steps per Second: 10,652.71163

Timestep Collection Time: 2.19277
Timestep Consumption Time: 2.50162
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.69439

Cumulative Model Updates: 97,492
Cumulative Timesteps: 813,104,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.55530
Policy Entropy: 3.14055
Value Function Loss: 0.00479

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.57870
Value Function Update Magnitude: 0.64741

Collected Steps per Second: 22,933.02281
Overall Steps per Second: 10,748.91872

Timestep Collection Time: 2.18044
Timestep Consumption Time: 2.47157
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.65200

Cumulative Model Updates: 97,498
Cumulative Timesteps: 813,154,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 813154492...
Checkpoint 813154492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.62130
Policy Entropy: 3.14740
Value Function Loss: 0.00489

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11856
Policy Update Magnitude: 0.59063
Value Function Update Magnitude: 0.64732

Collected Steps per Second: 23,067.38478
Overall Steps per Second: 10,620.16629

Timestep Collection Time: 2.16834
Timestep Consumption Time: 2.54138
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.70972

Cumulative Model Updates: 97,504
Cumulative Timesteps: 813,204,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,018.39611
Policy Entropy: 3.15697
Value Function Loss: 0.00471

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.58396
Value Function Update Magnitude: 0.63770

Collected Steps per Second: 22,594.17353
Overall Steps per Second: 10,681.87310

Timestep Collection Time: 2.21296
Timestep Consumption Time: 2.46787
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.68083

Cumulative Model Updates: 97,510
Cumulative Timesteps: 813,254,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 813254510...
Checkpoint 813254510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.22702
Policy Entropy: 3.16601
Value Function Loss: 0.00457

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.57901
Value Function Update Magnitude: 0.60189

Collected Steps per Second: 23,253.75996
Overall Steps per Second: 10,891.51790

Timestep Collection Time: 2.15122
Timestep Consumption Time: 2.44171
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.59293

Cumulative Model Updates: 97,516
Cumulative Timesteps: 813,304,534

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.49027
Policy Entropy: 3.16014
Value Function Loss: 0.00488

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.58144
Value Function Update Magnitude: 0.61480

Collected Steps per Second: 22,560.03116
Overall Steps per Second: 10,793.04606

Timestep Collection Time: 2.21649
Timestep Consumption Time: 2.41650
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.63298

Cumulative Model Updates: 97,522
Cumulative Timesteps: 813,354,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 813354538...
Checkpoint 813354538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.21019
Policy Entropy: 3.16586
Value Function Loss: 0.00491

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.58185
Value Function Update Magnitude: 0.65272

Collected Steps per Second: 22,915.61212
Overall Steps per Second: 10,724.16663

Timestep Collection Time: 2.18262
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.66386

Cumulative Model Updates: 97,528
Cumulative Timesteps: 813,404,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.90826
Policy Entropy: 3.16025
Value Function Loss: 0.00475

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.58406
Value Function Update Magnitude: 0.66268

Collected Steps per Second: 22,686.59495
Overall Steps per Second: 10,783.17045

Timestep Collection Time: 2.20430
Timestep Consumption Time: 2.43330
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.63760

Cumulative Model Updates: 97,534
Cumulative Timesteps: 813,454,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 813454562...
Checkpoint 813454562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.24988
Policy Entropy: 3.16759
Value Function Loss: 0.00429

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.57107
Value Function Update Magnitude: 0.64170

Collected Steps per Second: 22,745.67976
Overall Steps per Second: 10,736.37775

Timestep Collection Time: 2.19901
Timestep Consumption Time: 2.45973
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.65874

Cumulative Model Updates: 97,540
Cumulative Timesteps: 813,504,580

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.29041
Policy Entropy: 3.17540
Value Function Loss: 0.00439

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09387
Policy Update Magnitude: 0.56275
Value Function Update Magnitude: 0.61732

Collected Steps per Second: 22,883.89307
Overall Steps per Second: 10,834.66571

Timestep Collection Time: 2.18547
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.61592

Cumulative Model Updates: 97,546
Cumulative Timesteps: 813,554,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 813554592...
Checkpoint 813554592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.00777
Policy Entropy: 3.17092
Value Function Loss: 0.00458

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.56556
Value Function Update Magnitude: 0.61549

Collected Steps per Second: 22,661.36832
Overall Steps per Second: 10,741.40992

Timestep Collection Time: 2.20640
Timestep Consumption Time: 2.44848
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.65488

Cumulative Model Updates: 97,552
Cumulative Timesteps: 813,604,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.55068
Policy Entropy: 3.16946
Value Function Loss: 0.00490

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.57577
Value Function Update Magnitude: 0.64658

Collected Steps per Second: 22,890.34954
Overall Steps per Second: 10,852.52390

Timestep Collection Time: 2.18441
Timestep Consumption Time: 2.42299
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.60741

Cumulative Model Updates: 97,558
Cumulative Timesteps: 813,654,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 813654594...
Checkpoint 813654594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.24002
Policy Entropy: 3.17302
Value Function Loss: 0.00463

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10587
Policy Update Magnitude: 0.57596
Value Function Update Magnitude: 0.64439

Collected Steps per Second: 22,370.16543
Overall Steps per Second: 10,751.93931

Timestep Collection Time: 2.23673
Timestep Consumption Time: 2.41694
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.65367

Cumulative Model Updates: 97,564
Cumulative Timesteps: 813,704,630

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.17310
Policy Entropy: 3.16439
Value Function Loss: 0.00472

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.57506
Value Function Update Magnitude: 0.62587

Collected Steps per Second: 22,767.19690
Overall Steps per Second: 10,802.01996

Timestep Collection Time: 2.19649
Timestep Consumption Time: 2.43301
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.62950

Cumulative Model Updates: 97,570
Cumulative Timesteps: 813,754,638

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 813754638...
Checkpoint 813754638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,225.41899
Policy Entropy: 3.17974
Value Function Loss: 0.00465

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.57571
Value Function Update Magnitude: 0.61628

Collected Steps per Second: 22,782.51743
Overall Steps per Second: 10,703.48284

Timestep Collection Time: 2.19519
Timestep Consumption Time: 2.47731
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.67250

Cumulative Model Updates: 97,576
Cumulative Timesteps: 813,804,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 809.00017
Policy Entropy: 3.17833
Value Function Loss: 0.00462

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.57312
Value Function Update Magnitude: 0.62625

Collected Steps per Second: 23,080.89626
Overall Steps per Second: 10,863.36205

Timestep Collection Time: 2.16664
Timestep Consumption Time: 2.43672
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.60336

Cumulative Model Updates: 97,582
Cumulative Timesteps: 813,854,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 813854658...
Checkpoint 813854658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 564.26448
Policy Entropy: 3.18352
Value Function Loss: 0.00463

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.57129
Value Function Update Magnitude: 0.62022

Collected Steps per Second: 22,768.06701
Overall Steps per Second: 10,694.05417

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.47993
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.67643

Cumulative Model Updates: 97,588
Cumulative Timesteps: 813,904,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.00980
Policy Entropy: 3.18303
Value Function Loss: 0.00462

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.57029
Value Function Update Magnitude: 0.61584

Collected Steps per Second: 22,816.16971
Overall Steps per Second: 10,841.77305

Timestep Collection Time: 2.19266
Timestep Consumption Time: 2.42172
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.61437

Cumulative Model Updates: 97,594
Cumulative Timesteps: 813,954,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 813954696...
Checkpoint 813954696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.22766
Policy Entropy: 3.16669
Value Function Loss: 0.00472

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.57309
Value Function Update Magnitude: 0.61477

Collected Steps per Second: 22,726.74512
Overall Steps per Second: 10,699.61508

Timestep Collection Time: 2.20120
Timestep Consumption Time: 2.47430
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.67550

Cumulative Model Updates: 97,600
Cumulative Timesteps: 814,004,722

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.05952
Policy Entropy: 3.16528
Value Function Loss: 0.00460

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.57476
Value Function Update Magnitude: 0.60717

Collected Steps per Second: 22,962.57004
Overall Steps per Second: 10,843.63765

Timestep Collection Time: 2.17815
Timestep Consumption Time: 2.43432
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.61247

Cumulative Model Updates: 97,606
Cumulative Timesteps: 814,054,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 814054738...
Checkpoint 814054738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,216.15721
Policy Entropy: 3.15521
Value Function Loss: 0.00443

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.57309
Value Function Update Magnitude: 0.60259

Collected Steps per Second: 22,817.10883
Overall Steps per Second: 10,722.96481

Timestep Collection Time: 2.19248
Timestep Consumption Time: 2.47284
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.66531

Cumulative Model Updates: 97,612
Cumulative Timesteps: 814,104,764

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846.77353
Policy Entropy: 3.15022
Value Function Loss: 0.00444

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.56952
Value Function Update Magnitude: 0.60779

Collected Steps per Second: 22,692.17590
Overall Steps per Second: 10,775.49262

Timestep Collection Time: 2.20358
Timestep Consumption Time: 2.43695
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.64053

Cumulative Model Updates: 97,618
Cumulative Timesteps: 814,154,768

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 814154768...
Checkpoint 814154768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.91662
Policy Entropy: 3.15395
Value Function Loss: 0.00446

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10611
Policy Update Magnitude: 0.56968
Value Function Update Magnitude: 0.62964

Collected Steps per Second: 22,620.93996
Overall Steps per Second: 10,789.91192

Timestep Collection Time: 2.21167
Timestep Consumption Time: 2.42507
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.63674

Cumulative Model Updates: 97,624
Cumulative Timesteps: 814,204,798

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 988.81350
Policy Entropy: 3.16733
Value Function Loss: 0.00451

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.57024
Value Function Update Magnitude: 0.62494

Collected Steps per Second: 22,929.05263
Overall Steps per Second: 10,820.46388

Timestep Collection Time: 2.18169
Timestep Consumption Time: 2.44141
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.62309

Cumulative Model Updates: 97,630
Cumulative Timesteps: 814,254,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 814254822...
Checkpoint 814254822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.66447
Policy Entropy: 3.16672
Value Function Loss: 0.00451

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.62152

Collected Steps per Second: 22,669.33017
Overall Steps per Second: 10,720.61511

Timestep Collection Time: 2.20642
Timestep Consumption Time: 2.45917
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.66559

Cumulative Model Updates: 97,636
Cumulative Timesteps: 814,304,840

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.23381
Policy Entropy: 3.15448
Value Function Loss: 0.00470

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.57179
Value Function Update Magnitude: 0.62962

Collected Steps per Second: 22,867.43711
Overall Steps per Second: 10,828.13010

Timestep Collection Time: 2.18774
Timestep Consumption Time: 2.43245
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.62019

Cumulative Model Updates: 97,642
Cumulative Timesteps: 814,354,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 814354868...
Checkpoint 814354868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.74809
Policy Entropy: 3.15199
Value Function Loss: 0.00468

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.57841
Value Function Update Magnitude: 0.62260

Collected Steps per Second: 22,913.22442
Overall Steps per Second: 10,725.84362

Timestep Collection Time: 2.18311
Timestep Consumption Time: 2.48058
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.66369

Cumulative Model Updates: 97,648
Cumulative Timesteps: 814,404,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.70884
Policy Entropy: 3.15565
Value Function Loss: 0.00484

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.58031
Value Function Update Magnitude: 0.63066

Collected Steps per Second: 22,589.81816
Overall Steps per Second: 10,626.23283

Timestep Collection Time: 2.21348
Timestep Consumption Time: 2.49205
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.70552

Cumulative Model Updates: 97,654
Cumulative Timesteps: 814,454,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 814454892...
Checkpoint 814454892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.69961
Policy Entropy: 3.14827
Value Function Loss: 0.00496

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09703
Policy Update Magnitude: 0.58401
Value Function Update Magnitude: 0.63311

Collected Steps per Second: 23,110.62997
Overall Steps per Second: 10,860.68861

Timestep Collection Time: 2.16377
Timestep Consumption Time: 2.44055
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.60431

Cumulative Model Updates: 97,660
Cumulative Timesteps: 814,504,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.12033
Policy Entropy: 3.14481
Value Function Loss: 0.00488

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.58040
Value Function Update Magnitude: 0.61472

Collected Steps per Second: 22,756.73496
Overall Steps per Second: 10,697.83186

Timestep Collection Time: 2.19935
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.67852

Cumulative Model Updates: 97,666
Cumulative Timesteps: 814,554,948

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 814554948...
Checkpoint 814554948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.79970
Policy Entropy: 3.14426
Value Function Loss: 0.00478

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09483
Policy Update Magnitude: 0.56933
Value Function Update Magnitude: 0.61413

Collected Steps per Second: 22,706.29740
Overall Steps per Second: 10,937.04667

Timestep Collection Time: 2.20291
Timestep Consumption Time: 2.37053
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.57345

Cumulative Model Updates: 97,672
Cumulative Timesteps: 814,604,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.53897
Policy Entropy: 3.14480
Value Function Loss: 0.00496

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10653
Policy Update Magnitude: 0.57624
Value Function Update Magnitude: 0.63631

Collected Steps per Second: 22,461.97291
Overall Steps per Second: 10,846.80919

Timestep Collection Time: 2.22634
Timestep Consumption Time: 2.38405
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.61039

Cumulative Model Updates: 97,678
Cumulative Timesteps: 814,654,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 814654976...
Checkpoint 814654976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.41536
Policy Entropy: 3.15201
Value Function Loss: 0.00479

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.59224
Value Function Update Magnitude: 0.64274

Collected Steps per Second: 22,137.61297
Overall Steps per Second: 10,654.25940

Timestep Collection Time: 2.25977
Timestep Consumption Time: 2.43563
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.69540

Cumulative Model Updates: 97,684
Cumulative Timesteps: 814,705,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.55911
Policy Entropy: 3.15642
Value Function Loss: 0.00493

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.59090
Value Function Update Magnitude: 0.64968

Collected Steps per Second: 21,948.10033
Overall Steps per Second: 10,582.87983

Timestep Collection Time: 2.27929
Timestep Consumption Time: 2.44778
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.72707

Cumulative Model Updates: 97,690
Cumulative Timesteps: 814,755,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 814755028...
Checkpoint 814755028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,885.85157
Policy Entropy: 3.18232
Value Function Loss: 0.00461

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10964
Policy Update Magnitude: 0.58095
Value Function Update Magnitude: 0.63510

Collected Steps per Second: 22,229.63358
Overall Steps per Second: 10,718.54181

Timestep Collection Time: 2.24970
Timestep Consumption Time: 2.41605
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.66575

Cumulative Model Updates: 97,696
Cumulative Timesteps: 814,805,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735.80149
Policy Entropy: 3.15547
Value Function Loss: 0.00494

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11365
Policy Update Magnitude: 0.58356
Value Function Update Magnitude: 0.63913

Collected Steps per Second: 22,192.27414
Overall Steps per Second: 10,725.89809

Timestep Collection Time: 2.25331
Timestep Consumption Time: 2.40887
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.66217

Cumulative Model Updates: 97,702
Cumulative Timesteps: 814,855,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 814855044...
Checkpoint 814855044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.18902
Policy Entropy: 3.15634
Value Function Loss: 0.00481

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11270
Policy Update Magnitude: 0.58596
Value Function Update Magnitude: 0.63465

Collected Steps per Second: 21,662.99005
Overall Steps per Second: 10,597.11053

Timestep Collection Time: 2.30901
Timestep Consumption Time: 2.41115
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.72015

Cumulative Model Updates: 97,708
Cumulative Timesteps: 814,905,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.98029
Policy Entropy: 3.14254
Value Function Loss: 0.00481

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.57991
Value Function Update Magnitude: 0.64407

Collected Steps per Second: 21,946.03441
Overall Steps per Second: 10,587.75773

Timestep Collection Time: 2.27904
Timestep Consumption Time: 2.44490
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.72395

Cumulative Model Updates: 97,714
Cumulative Timesteps: 814,955,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 814955080...
Checkpoint 814955080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.69524
Policy Entropy: 3.15570
Value Function Loss: 0.00463

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.58264
Value Function Update Magnitude: 0.62816

Collected Steps per Second: 22,375.14063
Overall Steps per Second: 10,777.14411

Timestep Collection Time: 2.23596
Timestep Consumption Time: 2.40627
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.64223

Cumulative Model Updates: 97,720
Cumulative Timesteps: 815,005,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.00484
Policy Entropy: 3.14765
Value Function Loss: 0.00466

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.58189
Value Function Update Magnitude: 0.62609

Collected Steps per Second: 22,143.43804
Overall Steps per Second: 10,689.08491

Timestep Collection Time: 2.25810
Timestep Consumption Time: 2.41976
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.67786

Cumulative Model Updates: 97,726
Cumulative Timesteps: 815,055,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 815055112...
Checkpoint 815055112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.67591
Policy Entropy: 3.14939
Value Function Loss: 0.00454

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09665
Policy Update Magnitude: 0.57993
Value Function Update Magnitude: 0.62433

Collected Steps per Second: 23,241.30255
Overall Steps per Second: 10,736.96499

Timestep Collection Time: 2.15212
Timestep Consumption Time: 2.50637
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.65849

Cumulative Model Updates: 97,732
Cumulative Timesteps: 815,105,130

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.50638
Policy Entropy: 3.16141
Value Function Loss: 0.00430

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09008
Policy Update Magnitude: 0.57934
Value Function Update Magnitude: 0.61924

Collected Steps per Second: 22,845.75821
Overall Steps per Second: 10,771.77944

Timestep Collection Time: 2.18982
Timestep Consumption Time: 2.45454
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.64436

Cumulative Model Updates: 97,738
Cumulative Timesteps: 815,155,158

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 815155158...
Checkpoint 815155158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.72594
Policy Entropy: 3.15557
Value Function Loss: 0.00408

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.57022
Value Function Update Magnitude: 0.59525

Collected Steps per Second: 22,759.03060
Overall Steps per Second: 10,659.15562

Timestep Collection Time: 2.19781
Timestep Consumption Time: 2.49487
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.69268

Cumulative Model Updates: 97,744
Cumulative Timesteps: 815,205,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.38234
Policy Entropy: 3.15822
Value Function Loss: 0.00409

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.09017
Policy Update Magnitude: 0.56233
Value Function Update Magnitude: 0.56775

Collected Steps per Second: 22,987.61270
Overall Steps per Second: 10,823.64234

Timestep Collection Time: 2.17517
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.61970

Cumulative Model Updates: 97,750
Cumulative Timesteps: 815,255,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 815255180...
Checkpoint 815255180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.48397
Policy Entropy: 3.15429
Value Function Loss: 0.00427

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.55670
Value Function Update Magnitude: 0.55339

Collected Steps per Second: 22,888.98882
Overall Steps per Second: 10,709.56968

Timestep Collection Time: 2.18559
Timestep Consumption Time: 2.48556
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.67115

Cumulative Model Updates: 97,756
Cumulative Timesteps: 815,305,206

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,813.05566
Policy Entropy: 3.15622
Value Function Loss: 0.00439

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.55286
Value Function Update Magnitude: 0.54635

Collected Steps per Second: 22,936.12797
Overall Steps per Second: 10,674.39106

Timestep Collection Time: 2.18058
Timestep Consumption Time: 2.50484
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.68542

Cumulative Model Updates: 97,762
Cumulative Timesteps: 815,355,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 815355220...
Checkpoint 815355220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.75656
Policy Entropy: 3.16009
Value Function Loss: 0.00469

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09235
Policy Update Magnitude: 0.57027
Value Function Update Magnitude: 0.55847

Collected Steps per Second: 22,859.78674
Overall Steps per Second: 10,784.25811

Timestep Collection Time: 2.18812
Timestep Consumption Time: 2.45012
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.63824

Cumulative Model Updates: 97,768
Cumulative Timesteps: 815,405,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,934.60898
Policy Entropy: 3.15291
Value Function Loss: 0.00472

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08994
Policy Update Magnitude: 0.58030
Value Function Update Magnitude: 0.58062

Collected Steps per Second: 23,067.48788
Overall Steps per Second: 10,684.47923

Timestep Collection Time: 2.16799
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.68062

Cumulative Model Updates: 97,774
Cumulative Timesteps: 815,455,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 815455250...
Checkpoint 815455250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.91928
Policy Entropy: 3.15386
Value Function Loss: 0.00470

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.58079
Value Function Update Magnitude: 0.59267

Collected Steps per Second: 22,274.44310
Overall Steps per Second: 10,507.09901

Timestep Collection Time: 2.24580
Timestep Consumption Time: 2.51517
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.76097

Cumulative Model Updates: 97,780
Cumulative Timesteps: 815,505,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,848.58690
Policy Entropy: 3.14189
Value Function Loss: 0.00470

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10296
Policy Update Magnitude: 0.57984
Value Function Update Magnitude: 0.58397

Collected Steps per Second: 21,888.88433
Overall Steps per Second: 10,613.50160

Timestep Collection Time: 2.28500
Timestep Consumption Time: 2.42749
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.71249

Cumulative Model Updates: 97,786
Cumulative Timesteps: 815,555,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 815555290...
Checkpoint 815555290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,715.95417
Policy Entropy: 3.14067
Value Function Loss: 0.00465

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11755
Policy Update Magnitude: 0.57620
Value Function Update Magnitude: 0.57816

Collected Steps per Second: 22,096.32111
Overall Steps per Second: 10,662.27684

Timestep Collection Time: 2.26409
Timestep Consumption Time: 2.42797
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.69206

Cumulative Model Updates: 97,792
Cumulative Timesteps: 815,605,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.43722
Policy Entropy: 3.13665
Value Function Loss: 0.00446

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11136
Policy Update Magnitude: 0.57339
Value Function Update Magnitude: 0.57516

Collected Steps per Second: 22,200.43678
Overall Steps per Second: 10,708.53447

Timestep Collection Time: 2.25329
Timestep Consumption Time: 2.41813
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.67141

Cumulative Model Updates: 97,798
Cumulative Timesteps: 815,655,342

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 815655342...
Checkpoint 815655342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.11309
Policy Entropy: 3.13083
Value Function Loss: 0.00434

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.57187
Value Function Update Magnitude: 0.58007

Collected Steps per Second: 22,244.05952
Overall Steps per Second: 10,645.17178

Timestep Collection Time: 2.24977
Timestep Consumption Time: 2.45133
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.70110

Cumulative Model Updates: 97,804
Cumulative Timesteps: 815,705,386

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.91033
Policy Entropy: 3.13261
Value Function Loss: 0.00447

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.56605
Value Function Update Magnitude: 0.58325

Collected Steps per Second: 22,032.38901
Overall Steps per Second: 10,641.49794

Timestep Collection Time: 2.27057
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.70103

Cumulative Model Updates: 97,810
Cumulative Timesteps: 815,755,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 815755412...
Checkpoint 815755412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.97958
Policy Entropy: 3.11277
Value Function Loss: 0.00460

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10401
Policy Update Magnitude: 0.56906
Value Function Update Magnitude: 0.59223

Collected Steps per Second: 22,849.43990
Overall Steps per Second: 10,677.79311

Timestep Collection Time: 2.18929
Timestep Consumption Time: 2.49558
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.68486

Cumulative Model Updates: 97,816
Cumulative Timesteps: 815,805,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.23240
Policy Entropy: 3.14363
Value Function Loss: 0.00471

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09094
Policy Update Magnitude: 0.57539
Value Function Update Magnitude: 0.61137

Collected Steps per Second: 23,131.41883
Overall Steps per Second: 10,722.34730

Timestep Collection Time: 2.16243
Timestep Consumption Time: 2.50260
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.66502

Cumulative Model Updates: 97,822
Cumulative Timesteps: 815,855,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 815855456...
Checkpoint 815855456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.62055
Policy Entropy: 3.15596
Value Function Loss: 0.00475

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.57541
Value Function Update Magnitude: 0.63158

Collected Steps per Second: 22,830.57072
Overall Steps per Second: 10,622.27556

Timestep Collection Time: 2.19022
Timestep Consumption Time: 2.51724
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.70747

Cumulative Model Updates: 97,828
Cumulative Timesteps: 815,905,460

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.47731
Policy Entropy: 3.16743
Value Function Loss: 0.00442

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.56741
Value Function Update Magnitude: 0.61803

Collected Steps per Second: 22,996.14047
Overall Steps per Second: 10,801.52617

Timestep Collection Time: 2.17428
Timestep Consumption Time: 2.45470
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.62898

Cumulative Model Updates: 97,834
Cumulative Timesteps: 815,955,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 815955460...
Checkpoint 815955460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.27384
Policy Entropy: 3.15734
Value Function Loss: 0.00445

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.56166
Value Function Update Magnitude: 0.59497

Collected Steps per Second: 22,725.35680
Overall Steps per Second: 10,799.06984

Timestep Collection Time: 2.20045
Timestep Consumption Time: 2.43013
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.63058

Cumulative Model Updates: 97,840
Cumulative Timesteps: 816,005,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.67156
Policy Entropy: 3.15999
Value Function Loss: 0.00425

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.55682
Value Function Update Magnitude: 0.58176

Collected Steps per Second: 22,158.23417
Overall Steps per Second: 10,775.44289

Timestep Collection Time: 2.25650
Timestep Consumption Time: 2.38368
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.64018

Cumulative Model Updates: 97,846
Cumulative Timesteps: 816,055,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 816055466...
Checkpoint 816055466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,832.56497
Policy Entropy: 3.16397
Value Function Loss: 0.00431

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.55275
Value Function Update Magnitude: 0.57800

Collected Steps per Second: 22,922.42021
Overall Steps per Second: 10,731.98608

Timestep Collection Time: 2.18188
Timestep Consumption Time: 2.47839
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.66027

Cumulative Model Updates: 97,852
Cumulative Timesteps: 816,105,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.47004
Policy Entropy: 3.15560
Value Function Loss: 0.00455

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.58506

Collected Steps per Second: 21,605.84678
Overall Steps per Second: 10,490.90600

Timestep Collection Time: 2.31419
Timestep Consumption Time: 2.45184
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.76603

Cumulative Model Updates: 97,858
Cumulative Timesteps: 816,155,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 816155480...
Checkpoint 816155480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.26495
Policy Entropy: 3.17136
Value Function Loss: 0.00431

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11640
Policy Update Magnitude: 0.55621
Value Function Update Magnitude: 0.60552

Collected Steps per Second: 22,096.72396
Overall Steps per Second: 10,638.20825

Timestep Collection Time: 2.26305
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.29635
Total Iteration Time: 4.70060

Cumulative Model Updates: 97,864
Cumulative Timesteps: 816,205,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.31041
Policy Entropy: 3.16631
Value Function Loss: 0.00433

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.54483
Value Function Update Magnitude: 0.60867

Collected Steps per Second: 22,101.10644
Overall Steps per Second: 10,750.20862

Timestep Collection Time: 2.26333
Timestep Consumption Time: 2.38979
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.65312

Cumulative Model Updates: 97,870
Cumulative Timesteps: 816,255,508

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 816255508...
Checkpoint 816255508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.65309
Policy Entropy: 3.18587
Value Function Loss: 0.00415

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.54070
Value Function Update Magnitude: 0.59351

Collected Steps per Second: 22,288.85531
Overall Steps per Second: 10,727.59146

Timestep Collection Time: 2.24336
Timestep Consumption Time: 2.41770
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.66106

Cumulative Model Updates: 97,876
Cumulative Timesteps: 816,305,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.48041
Policy Entropy: 3.18834
Value Function Loss: 0.00437

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09846
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.58574

Collected Steps per Second: 22,826.72670
Overall Steps per Second: 10,715.49986

Timestep Collection Time: 2.19041
Timestep Consumption Time: 2.47572
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.66614

Cumulative Model Updates: 97,882
Cumulative Timesteps: 816,355,510

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 816355510...
Checkpoint 816355510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.30593
Policy Entropy: 3.19041
Value Function Loss: 0.00454

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.54422
Value Function Update Magnitude: 0.58474

Collected Steps per Second: 22,099.98961
Overall Steps per Second: 10,774.10136

Timestep Collection Time: 2.26253
Timestep Consumption Time: 2.37841
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.64094

Cumulative Model Updates: 97,888
Cumulative Timesteps: 816,405,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.92502
Policy Entropy: 3.17835
Value Function Loss: 0.00450

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.54479
Value Function Update Magnitude: 0.59069

Collected Steps per Second: 22,294.14992
Overall Steps per Second: 10,712.90923

Timestep Collection Time: 2.24445
Timestep Consumption Time: 2.42637
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.67081

Cumulative Model Updates: 97,894
Cumulative Timesteps: 816,455,550

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 816455550...
Checkpoint 816455550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.90980
Policy Entropy: 3.16808
Value Function Loss: 0.00446

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.55111
Value Function Update Magnitude: 0.58522

Collected Steps per Second: 22,170.36778
Overall Steps per Second: 10,800.07392

Timestep Collection Time: 2.25662
Timestep Consumption Time: 2.37576
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.63238

Cumulative Model Updates: 97,900
Cumulative Timesteps: 816,505,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.39427
Policy Entropy: 3.17254
Value Function Loss: 0.00444

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.57341

Collected Steps per Second: 22,066.40245
Overall Steps per Second: 10,580.24570

Timestep Collection Time: 2.26625
Timestep Consumption Time: 2.46029
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.72654

Cumulative Model Updates: 97,906
Cumulative Timesteps: 816,555,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 816555588...
Checkpoint 816555588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.27450
Policy Entropy: 3.17458
Value Function Loss: 0.00429

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.56807

Collected Steps per Second: 22,153.32381
Overall Steps per Second: 10,641.63555

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.29631
Total Iteration Time: 4.69909

Cumulative Model Updates: 97,912
Cumulative Timesteps: 816,605,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.78291
Policy Entropy: 3.16413
Value Function Loss: 0.00423

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.54464
Value Function Update Magnitude: 0.56323

Collected Steps per Second: 22,493.20035
Overall Steps per Second: 10,841.01000

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.39046
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.61451

Cumulative Model Updates: 97,918
Cumulative Timesteps: 816,655,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 816655620...
Checkpoint 816655620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513.83704
Policy Entropy: 3.16073
Value Function Loss: 0.00434

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.54884
Value Function Update Magnitude: 0.57470

Collected Steps per Second: 22,988.77511
Overall Steps per Second: 10,659.40694

Timestep Collection Time: 2.17628
Timestep Consumption Time: 2.51723
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.69351

Cumulative Model Updates: 97,924
Cumulative Timesteps: 816,705,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 839.15497
Policy Entropy: 3.15027
Value Function Loss: 0.00434

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09810
Policy Update Magnitude: 0.55443
Value Function Update Magnitude: 0.58978

Collected Steps per Second: 22,088.83367
Overall Steps per Second: 10,605.95220

Timestep Collection Time: 2.26495
Timestep Consumption Time: 2.45222
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.71716

Cumulative Model Updates: 97,930
Cumulative Timesteps: 816,755,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 816755680...
Checkpoint 816755680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.54038
Policy Entropy: 3.15657
Value Function Loss: 0.00430

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.55491
Value Function Update Magnitude: 0.59717

Collected Steps per Second: 23,199.51378
Overall Steps per Second: 10,840.19183

Timestep Collection Time: 2.15539
Timestep Consumption Time: 2.45744
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.61283

Cumulative Model Updates: 97,936
Cumulative Timesteps: 816,805,684

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 981.67521
Policy Entropy: 3.17236
Value Function Loss: 0.00443

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09105
Policy Update Magnitude: 0.55425
Value Function Update Magnitude: 0.59462

Collected Steps per Second: 22,862.52031
Overall Steps per Second: 10,613.50373

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.52440
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.71173

Cumulative Model Updates: 97,942
Cumulative Timesteps: 816,855,692

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 816855692...
Checkpoint 816855692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.19001
Policy Entropy: 3.18369
Value Function Loss: 0.00454

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09258
Policy Update Magnitude: 0.54540
Value Function Update Magnitude: 0.61216

Collected Steps per Second: 22,368.20020
Overall Steps per Second: 10,713.90332

Timestep Collection Time: 2.23541
Timestep Consumption Time: 2.43161
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.66702

Cumulative Model Updates: 97,948
Cumulative Timesteps: 816,905,694

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.31272
Policy Entropy: 3.19496
Value Function Loss: 0.00452

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08854
Policy Update Magnitude: 0.54731
Value Function Update Magnitude: 0.64707

Collected Steps per Second: 22,230.99726
Overall Steps per Second: 10,834.51832

Timestep Collection Time: 2.24956
Timestep Consumption Time: 2.36624
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.61580

Cumulative Model Updates: 97,954
Cumulative Timesteps: 816,955,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 816955704...
Checkpoint 816955704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,806.71011
Policy Entropy: 3.19381
Value Function Loss: 0.00453

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09159
Policy Update Magnitude: 0.54325
Value Function Update Magnitude: 0.63838

Collected Steps per Second: 22,073.56198
Overall Steps per Second: 10,607.91027

Timestep Collection Time: 2.26633
Timestep Consumption Time: 2.44958
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.71591

Cumulative Model Updates: 97,960
Cumulative Timesteps: 817,005,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,409.15756
Policy Entropy: 3.17886
Value Function Loss: 0.00467

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.54756
Value Function Update Magnitude: 0.62218

Collected Steps per Second: 22,277.59693
Overall Steps per Second: 10,813.42897

Timestep Collection Time: 2.24459
Timestep Consumption Time: 2.37966
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.62425

Cumulative Model Updates: 97,966
Cumulative Timesteps: 817,055,734

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 817055734...
Checkpoint 817055734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830.14487
Policy Entropy: 3.16129
Value Function Loss: 0.00453

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.55749
Value Function Update Magnitude: 0.61714

Collected Steps per Second: 22,707.17793
Overall Steps per Second: 10,760.30376

Timestep Collection Time: 2.20353
Timestep Consumption Time: 2.44652
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.65005

Cumulative Model Updates: 97,972
Cumulative Timesteps: 817,105,770

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,354.06274
Policy Entropy: 3.16553
Value Function Loss: 0.00455

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09702
Policy Update Magnitude: 0.55272
Value Function Update Magnitude: 0.61199

Collected Steps per Second: 23,144.10426
Overall Steps per Second: 10,819.24078

Timestep Collection Time: 2.16090
Timestep Consumption Time: 2.46161
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.62251

Cumulative Model Updates: 97,978
Cumulative Timesteps: 817,155,782

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 817155782...
Checkpoint 817155782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,009.96878
Policy Entropy: 3.18130
Value Function Loss: 0.00449

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.55035
Value Function Update Magnitude: 0.61406

Collected Steps per Second: 22,856.38229
Overall Steps per Second: 10,701.61515

Timestep Collection Time: 2.18784
Timestep Consumption Time: 2.48492
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.67275

Cumulative Model Updates: 97,984
Cumulative Timesteps: 817,205,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.56224
Policy Entropy: 3.17259
Value Function Loss: 0.00450

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.54986
Value Function Update Magnitude: 0.61094

Collected Steps per Second: 22,954.08330
Overall Steps per Second: 10,783.60899

Timestep Collection Time: 2.17861
Timestep Consumption Time: 2.45880
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.63741

Cumulative Model Updates: 97,990
Cumulative Timesteps: 817,255,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 817255796...
Checkpoint 817255796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.60257
Policy Entropy: 3.15286
Value Function Loss: 0.00443

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.60625

Collected Steps per Second: 22,812.03078
Overall Steps per Second: 10,809.34115

Timestep Collection Time: 2.19314
Timestep Consumption Time: 2.43526
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.62840

Cumulative Model Updates: 97,996
Cumulative Timesteps: 817,305,826

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.97918
Policy Entropy: 3.12610
Value Function Loss: 0.00440

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.56318
Value Function Update Magnitude: 0.60256

Collected Steps per Second: 22,032.76362
Overall Steps per Second: 10,758.12867

Timestep Collection Time: 2.27016
Timestep Consumption Time: 2.37916
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.64932

Cumulative Model Updates: 98,002
Cumulative Timesteps: 817,355,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 817355844...
Checkpoint 817355844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.90943
Policy Entropy: 3.12186
Value Function Loss: 0.00424

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09788
Policy Update Magnitude: 0.55738
Value Function Update Magnitude: 0.60208

Collected Steps per Second: 22,175.22711
Overall Steps per Second: 10,735.73611

Timestep Collection Time: 2.25612
Timestep Consumption Time: 2.40402
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.66014

Cumulative Model Updates: 98,008
Cumulative Timesteps: 817,405,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 572.82625
Policy Entropy: 3.11370
Value Function Loss: 0.00468

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.55782
Value Function Update Magnitude: 0.60483

Collected Steps per Second: 23,151.27534
Overall Steps per Second: 10,825.51372

Timestep Collection Time: 2.15997
Timestep Consumption Time: 2.45931
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.61927

Cumulative Model Updates: 98,014
Cumulative Timesteps: 817,455,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 817455880...
Checkpoint 817455880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.19440
Policy Entropy: 3.12959
Value Function Loss: 0.00467

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.56514
Value Function Update Magnitude: 0.62649

Collected Steps per Second: 22,007.44070
Overall Steps per Second: 10,687.74847

Timestep Collection Time: 2.27223
Timestep Consumption Time: 2.40658
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.67882

Cumulative Model Updates: 98,020
Cumulative Timesteps: 817,505,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,716.91276
Policy Entropy: 3.12341
Value Function Loss: 0.00481

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10901
Policy Update Magnitude: 0.57386
Value Function Update Magnitude: 0.62893

Collected Steps per Second: 22,618.58888
Overall Steps per Second: 10,621.96712

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.49775
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.70930

Cumulative Model Updates: 98,026
Cumulative Timesteps: 817,555,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 817555908...
Checkpoint 817555908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,737.82601
Policy Entropy: 3.13852
Value Function Loss: 0.00457

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.57530
Value Function Update Magnitude: 0.63006

Collected Steps per Second: 23,035.51058
Overall Steps per Second: 10,737.90744

Timestep Collection Time: 2.17160
Timestep Consumption Time: 2.48703
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.65864

Cumulative Model Updates: 98,032
Cumulative Timesteps: 817,605,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.05394
Policy Entropy: 3.12691
Value Function Loss: 0.00465

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.57501
Value Function Update Magnitude: 0.63747

Collected Steps per Second: 23,059.52685
Overall Steps per Second: 10,681.25925

Timestep Collection Time: 2.16908
Timestep Consumption Time: 2.51370
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.68278

Cumulative Model Updates: 98,038
Cumulative Timesteps: 817,655,950

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 817655950...
Checkpoint 817655950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.01228
Policy Entropy: 3.13730
Value Function Loss: 0.00463

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11462
Policy Update Magnitude: 0.57211
Value Function Update Magnitude: 0.63847

Collected Steps per Second: 22,784.98392
Overall Steps per Second: 10,614.43978

Timestep Collection Time: 2.19522
Timestep Consumption Time: 2.51704
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.71226

Cumulative Model Updates: 98,044
Cumulative Timesteps: 817,705,968

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.55631
Policy Entropy: 3.13382
Value Function Loss: 0.00444

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.56487
Value Function Update Magnitude: 0.64247

Collected Steps per Second: 22,102.08218
Overall Steps per Second: 10,656.52824

Timestep Collection Time: 2.26223
Timestep Consumption Time: 2.42973
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69196

Cumulative Model Updates: 98,050
Cumulative Timesteps: 817,755,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 817755968...
Checkpoint 817755968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.27683
Policy Entropy: 3.12992
Value Function Loss: 0.00440

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.55295
Value Function Update Magnitude: 0.63843

Collected Steps per Second: 22,792.89700
Overall Steps per Second: 10,667.52065

Timestep Collection Time: 2.19393
Timestep Consumption Time: 2.49376
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.68769

Cumulative Model Updates: 98,056
Cumulative Timesteps: 817,805,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.93867
Policy Entropy: 3.12112
Value Function Loss: 0.00460

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.55362
Value Function Update Magnitude: 0.63737

Collected Steps per Second: 22,595.13249
Overall Steps per Second: 10,666.36603

Timestep Collection Time: 2.21419
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.29643
Total Iteration Time: 4.69044

Cumulative Model Updates: 98,062
Cumulative Timesteps: 817,856,004

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 817856004...
Checkpoint 817856004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.89637
Policy Entropy: 3.12752
Value Function Loss: 0.00455

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.63515

Collected Steps per Second: 21,701.65889
Overall Steps per Second: 10,700.09292

Timestep Collection Time: 2.30517
Timestep Consumption Time: 2.37012
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.67529

Cumulative Model Updates: 98,068
Cumulative Timesteps: 817,906,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.62146
Policy Entropy: 3.13870
Value Function Loss: 0.00434

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09868
Policy Update Magnitude: 0.55658
Value Function Update Magnitude: 0.62376

Collected Steps per Second: 22,594.09887
Overall Steps per Second: 10,616.02938

Timestep Collection Time: 2.21385
Timestep Consumption Time: 2.49789
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.71174

Cumulative Model Updates: 98,074
Cumulative Timesteps: 817,956,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 817956050...
Checkpoint 817956050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.78006
Policy Entropy: 3.16375
Value Function Loss: 0.00396

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08919
Policy Update Magnitude: 0.54334
Value Function Update Magnitude: 0.60505

Collected Steps per Second: 23,275.20287
Overall Steps per Second: 10,932.47891

Timestep Collection Time: 2.14915
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.57554

Cumulative Model Updates: 98,080
Cumulative Timesteps: 818,006,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.39938
Policy Entropy: 3.17202
Value Function Loss: 0.00407

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.08662
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.59512

Collected Steps per Second: 22,973.37820
Overall Steps per Second: 10,776.00691

Timestep Collection Time: 2.17765
Timestep Consumption Time: 2.46489
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.64254

Cumulative Model Updates: 98,086
Cumulative Timesteps: 818,056,100

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 818056100...
Checkpoint 818056100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.97327
Policy Entropy: 3.16071
Value Function Loss: 0.00438

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.55370
Value Function Update Magnitude: 0.62040

Collected Steps per Second: 23,102.93877
Overall Steps per Second: 10,759.74539

Timestep Collection Time: 2.16544
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.64955

Cumulative Model Updates: 98,092
Cumulative Timesteps: 818,106,128

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.75388
Policy Entropy: 3.15898
Value Function Loss: 0.00449

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.55854
Value Function Update Magnitude: 0.64292

Collected Steps per Second: 22,564.93340
Overall Steps per Second: 10,569.05435

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.51557
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.73193

Cumulative Model Updates: 98,098
Cumulative Timesteps: 818,156,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 818156140...
Checkpoint 818156140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.98980
Policy Entropy: 3.16974
Value Function Loss: 0.00475

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.56214
Value Function Update Magnitude: 0.63497

Collected Steps per Second: 22,932.02173
Overall Steps per Second: 10,705.62802

Timestep Collection Time: 2.18123
Timestep Consumption Time: 2.49108
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.67231

Cumulative Model Updates: 98,104
Cumulative Timesteps: 818,206,160

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.92384
Policy Entropy: 3.16727
Value Function Loss: 0.00468

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.56065
Value Function Update Magnitude: 0.63971

Collected Steps per Second: 22,806.10977
Overall Steps per Second: 10,761.25639

Timestep Collection Time: 2.19354
Timestep Consumption Time: 2.45518
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.64871

Cumulative Model Updates: 98,110
Cumulative Timesteps: 818,256,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 818256186...
Checkpoint 818256186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.34660
Policy Entropy: 3.17804
Value Function Loss: 0.00474

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.56162
Value Function Update Magnitude: 0.61932

Collected Steps per Second: 22,859.63491
Overall Steps per Second: 10,579.27060

Timestep Collection Time: 2.18752
Timestep Consumption Time: 2.53927
PPO Batch Consumption Time: 0.29596
Total Iteration Time: 4.72679

Cumulative Model Updates: 98,116
Cumulative Timesteps: 818,306,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.05046
Policy Entropy: 3.18034
Value Function Loss: 0.00457

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09474
Policy Update Magnitude: 0.55711
Value Function Update Magnitude: 0.61307

Collected Steps per Second: 22,694.64017
Overall Steps per Second: 10,602.79190

Timestep Collection Time: 2.20325
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.71593

Cumulative Model Updates: 98,122
Cumulative Timesteps: 818,356,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 818356194...
Checkpoint 818356194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.29802
Policy Entropy: 3.19006
Value Function Loss: 0.00458

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08887
Policy Update Magnitude: 0.55372
Value Function Update Magnitude: 0.61153

Collected Steps per Second: 22,558.46443
Overall Steps per Second: 10,544.76272

Timestep Collection Time: 2.21779
Timestep Consumption Time: 2.52674
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.74454

Cumulative Model Updates: 98,128
Cumulative Timesteps: 818,406,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.09795
Policy Entropy: 3.17770
Value Function Loss: 0.00474

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.55387
Value Function Update Magnitude: 0.60629

Collected Steps per Second: 23,091.00856
Overall Steps per Second: 10,830.18850

Timestep Collection Time: 2.16595
Timestep Consumption Time: 2.45207
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.61802

Cumulative Model Updates: 98,134
Cumulative Timesteps: 818,456,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 818456238...
Checkpoint 818456238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.85459
Policy Entropy: 3.18014
Value Function Loss: 0.00472

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.55829
Value Function Update Magnitude: 0.60412

Collected Steps per Second: 22,574.39755
Overall Steps per Second: 10,720.42586

Timestep Collection Time: 2.21561
Timestep Consumption Time: 2.44988
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.66549

Cumulative Model Updates: 98,140
Cumulative Timesteps: 818,506,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.30211
Policy Entropy: 3.16162
Value Function Loss: 0.00474

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08852
Policy Update Magnitude: 0.55984
Value Function Update Magnitude: 0.61113

Collected Steps per Second: 23,073.38078
Overall Steps per Second: 10,791.46098

Timestep Collection Time: 2.16743
Timestep Consumption Time: 2.46679
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.63422

Cumulative Model Updates: 98,146
Cumulative Timesteps: 818,556,264

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 818556264...
Checkpoint 818556264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.54313
Policy Entropy: 3.15909
Value Function Loss: 0.00488

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.60944

Collected Steps per Second: 22,638.86154
Overall Steps per Second: 10,769.43022

Timestep Collection Time: 2.20895
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.64351

Cumulative Model Updates: 98,152
Cumulative Timesteps: 818,606,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 923.32812
Policy Entropy: 3.15281
Value Function Loss: 0.00497

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.56536
Value Function Update Magnitude: 0.62481

Collected Steps per Second: 23,047.40750
Overall Steps per Second: 10,794.00833

Timestep Collection Time: 2.16944
Timestep Consumption Time: 2.46276
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.63220

Cumulative Model Updates: 98,158
Cumulative Timesteps: 818,656,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 818656272...
Checkpoint 818656272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.94709
Policy Entropy: 3.15797
Value Function Loss: 0.00484

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10069
Policy Update Magnitude: 0.56396
Value Function Update Magnitude: 0.62918

Collected Steps per Second: 22,669.85640
Overall Steps per Second: 10,693.86644

Timestep Collection Time: 2.20566
Timestep Consumption Time: 2.47010
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.67576

Cumulative Model Updates: 98,164
Cumulative Timesteps: 818,706,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.59841
Policy Entropy: 3.16614
Value Function Loss: 0.00457

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.55718
Value Function Update Magnitude: 0.61358

Collected Steps per Second: 22,948.48159
Overall Steps per Second: 10,692.84902

Timestep Collection Time: 2.17932
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.67714

Cumulative Model Updates: 98,170
Cumulative Timesteps: 818,756,286

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 818756286...
Checkpoint 818756286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.56006
Policy Entropy: 3.15464
Value Function Loss: 0.00465

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.55410
Value Function Update Magnitude: 0.59667

Collected Steps per Second: 22,868.10211
Overall Steps per Second: 10,769.76374

Timestep Collection Time: 2.18680
Timestep Consumption Time: 2.45657
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.64337

Cumulative Model Updates: 98,176
Cumulative Timesteps: 818,806,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.47381
Policy Entropy: 3.13900
Value Function Loss: 0.00474

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.55474
Value Function Update Magnitude: 0.59578

Collected Steps per Second: 23,059.62157
Overall Steps per Second: 10,832.49123

Timestep Collection Time: 2.16855
Timestep Consumption Time: 2.44774
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.61630

Cumulative Model Updates: 98,182
Cumulative Timesteps: 818,856,300

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 818856300...
Checkpoint 818856300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.08166
Policy Entropy: 3.11326
Value Function Loss: 0.00468

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10188
Policy Update Magnitude: 0.55840
Value Function Update Magnitude: 0.61104

Collected Steps per Second: 22,434.74698
Overall Steps per Second: 10,734.09024

Timestep Collection Time: 2.22904
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.65880

Cumulative Model Updates: 98,188
Cumulative Timesteps: 818,906,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,017.21084
Policy Entropy: 3.12205
Value Function Loss: 0.00460

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09785
Policy Update Magnitude: 0.55900
Value Function Update Magnitude: 0.61583

Collected Steps per Second: 22,895.39819
Overall Steps per Second: 10,767.31870

Timestep Collection Time: 2.18472
Timestep Consumption Time: 2.46082
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.64554

Cumulative Model Updates: 98,194
Cumulative Timesteps: 818,956,328

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 818956328...
Checkpoint 818956328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.32451
Policy Entropy: 3.13129
Value Function Loss: 0.00441

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.55583
Value Function Update Magnitude: 0.60734

Collected Steps per Second: 22,710.33653
Overall Steps per Second: 10,805.99979

Timestep Collection Time: 2.20279
Timestep Consumption Time: 2.42668
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.62947

Cumulative Model Updates: 98,200
Cumulative Timesteps: 819,006,354

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.84066
Policy Entropy: 3.14115
Value Function Loss: 0.00466

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.56274
Value Function Update Magnitude: 0.60701

Collected Steps per Second: 22,694.40488
Overall Steps per Second: 10,691.81501

Timestep Collection Time: 2.20442
Timestep Consumption Time: 2.47467
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.67909

Cumulative Model Updates: 98,206
Cumulative Timesteps: 819,056,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 819056382...
Checkpoint 819056382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.71436
Policy Entropy: 3.12670
Value Function Loss: 0.00482

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10597
Policy Update Magnitude: 0.56974
Value Function Update Magnitude: 0.62453

Collected Steps per Second: 22,347.48035
Overall Steps per Second: 10,505.48971

Timestep Collection Time: 2.23739
Timestep Consumption Time: 2.52203
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.75942

Cumulative Model Updates: 98,212
Cumulative Timesteps: 819,106,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.00733
Policy Entropy: 3.12386
Value Function Loss: 0.00479

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.56676
Value Function Update Magnitude: 0.62478

Collected Steps per Second: 23,144.88858
Overall Steps per Second: 10,831.58356

Timestep Collection Time: 2.16030
Timestep Consumption Time: 2.45583
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.61613

Cumulative Model Updates: 98,218
Cumulative Timesteps: 819,156,382

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 819156382...
Checkpoint 819156382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.86886
Policy Entropy: 3.11944
Value Function Loss: 0.00489

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11851
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.62651

Collected Steps per Second: 22,615.09096
Overall Steps per Second: 10,674.82390

Timestep Collection Time: 2.21197
Timestep Consumption Time: 2.47419
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.68617

Cumulative Model Updates: 98,224
Cumulative Timesteps: 819,206,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.92074
Policy Entropy: 3.11317
Value Function Loss: 0.00473

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11348
Policy Update Magnitude: 0.56851
Value Function Update Magnitude: 0.62207

Collected Steps per Second: 23,143.57395
Overall Steps per Second: 10,878.48756

Timestep Collection Time: 2.16138
Timestep Consumption Time: 2.43687
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.59825

Cumulative Model Updates: 98,230
Cumulative Timesteps: 819,256,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 819256428...
Checkpoint 819256428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.49860
Policy Entropy: 3.11829
Value Function Loss: 0.00494

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11625
Policy Update Magnitude: 0.57222
Value Function Update Magnitude: 0.63365

Collected Steps per Second: 22,753.48243
Overall Steps per Second: 10,611.79116

Timestep Collection Time: 2.19896
Timestep Consumption Time: 2.51598
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.71494

Cumulative Model Updates: 98,236
Cumulative Timesteps: 819,306,462

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.44945
Policy Entropy: 3.10672
Value Function Loss: 0.00483

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.57088
Value Function Update Magnitude: 0.64704

Collected Steps per Second: 22,750.02436
Overall Steps per Second: 10,715.89257

Timestep Collection Time: 2.19894
Timestep Consumption Time: 2.46945
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.66839

Cumulative Model Updates: 98,242
Cumulative Timesteps: 819,356,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 819356488...
Checkpoint 819356488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 823.45731
Policy Entropy: 3.11256
Value Function Loss: 0.00484

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12519
Policy Update Magnitude: 0.57507
Value Function Update Magnitude: 0.64013

Collected Steps per Second: 22,982.09638
Overall Steps per Second: 10,847.50416

Timestep Collection Time: 2.17569
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.60954

Cumulative Model Updates: 98,248
Cumulative Timesteps: 819,406,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.19864
Policy Entropy: 3.11102
Value Function Loss: 0.00475

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.57861
Value Function Update Magnitude: 0.62689

Collected Steps per Second: 22,896.92068
Overall Steps per Second: 10,865.26393

Timestep Collection Time: 2.18379
Timestep Consumption Time: 2.41822
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.60201

Cumulative Model Updates: 98,254
Cumulative Timesteps: 819,456,492

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 819456492...
Checkpoint 819456492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.04002
Policy Entropy: 3.12304
Value Function Loss: 0.00478

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.57195
Value Function Update Magnitude: 0.63133

Collected Steps per Second: 22,367.70007
Overall Steps per Second: 10,729.88073

Timestep Collection Time: 2.23617
Timestep Consumption Time: 2.42539
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.66156

Cumulative Model Updates: 98,260
Cumulative Timesteps: 819,506,510

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.43416
Policy Entropy: 3.12665
Value Function Loss: 0.00465

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.56497
Value Function Update Magnitude: 0.61785

Collected Steps per Second: 23,180.91720
Overall Steps per Second: 10,925.11018

Timestep Collection Time: 2.15764
Timestep Consumption Time: 2.42044
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.57808

Cumulative Model Updates: 98,266
Cumulative Timesteps: 819,556,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 819556526...
Checkpoint 819556526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 812.48808
Policy Entropy: 3.14055
Value Function Loss: 0.00457

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.55700
Value Function Update Magnitude: 0.60249

Collected Steps per Second: 22,654.15927
Overall Steps per Second: 10,615.36616

Timestep Collection Time: 2.20834
Timestep Consumption Time: 2.50445
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.71279

Cumulative Model Updates: 98,272
Cumulative Timesteps: 819,606,554

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.44948
Policy Entropy: 3.14227
Value Function Loss: 0.00463

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.56047
Value Function Update Magnitude: 0.60187

Collected Steps per Second: 22,826.83032
Overall Steps per Second: 10,809.25942

Timestep Collection Time: 2.19172
Timestep Consumption Time: 2.43672
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.62844

Cumulative Model Updates: 98,278
Cumulative Timesteps: 819,656,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 819656584...
Checkpoint 819656584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.94628
Policy Entropy: 3.15266
Value Function Loss: 0.00456

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.55521
Value Function Update Magnitude: 0.62480

Collected Steps per Second: 22,457.94568
Overall Steps per Second: 10,773.99456

Timestep Collection Time: 2.22701
Timestep Consumption Time: 2.41510
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.64210

Cumulative Model Updates: 98,284
Cumulative Timesteps: 819,706,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.55815
Policy Entropy: 3.14973
Value Function Loss: 0.00474

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.55454
Value Function Update Magnitude: 0.64211

Collected Steps per Second: 22,903.20499
Overall Steps per Second: 10,819.71959

Timestep Collection Time: 2.18319
Timestep Consumption Time: 2.43819
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.62138

Cumulative Model Updates: 98,290
Cumulative Timesteps: 819,756,600

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 819756600...
Checkpoint 819756600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.44531
Policy Entropy: 3.14666
Value Function Loss: 0.00463

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10535
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.63450

Collected Steps per Second: 22,735.91133
Overall Steps per Second: 10,737.19801

Timestep Collection Time: 2.19996
Timestep Consumption Time: 2.45843
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.65838

Cumulative Model Updates: 98,296
Cumulative Timesteps: 819,806,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.29106
Policy Entropy: 3.14899
Value Function Loss: 0.00452

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10747
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.61839

Collected Steps per Second: 22,934.23692
Overall Steps per Second: 10,830.54005

Timestep Collection Time: 2.18076
Timestep Consumption Time: 2.43711
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.61787

Cumulative Model Updates: 98,302
Cumulative Timesteps: 819,856,632

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 819856632...
Checkpoint 819856632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.74537
Policy Entropy: 3.16144
Value Function Loss: 0.00440

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.55124
Value Function Update Magnitude: 0.63026

Collected Steps per Second: 22,756.68353
Overall Steps per Second: 10,692.09493

Timestep Collection Time: 2.19724
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.67654

Cumulative Model Updates: 98,308
Cumulative Timesteps: 819,906,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,719.39923
Policy Entropy: 3.15831
Value Function Loss: 0.00444

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.54517
Value Function Update Magnitude: 0.65104

Collected Steps per Second: 23,003.32162
Overall Steps per Second: 10,814.29253

Timestep Collection Time: 2.17412
Timestep Consumption Time: 2.45050
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.62462

Cumulative Model Updates: 98,314
Cumulative Timesteps: 819,956,646

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 819956646...
Checkpoint 819956646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.06420
Policy Entropy: 3.16074
Value Function Loss: 0.00430

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.64767

Collected Steps per Second: 22,555.91224
Overall Steps per Second: 10,765.81189

Timestep Collection Time: 2.21760
Timestep Consumption Time: 2.42859
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.64619

Cumulative Model Updates: 98,320
Cumulative Timesteps: 820,006,666

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.03016
Policy Entropy: 3.16819
Value Function Loss: 0.00447

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.55035
Value Function Update Magnitude: 0.63292

Collected Steps per Second: 23,167.30208
Overall Steps per Second: 10,939.09897

Timestep Collection Time: 2.15916
Timestep Consumption Time: 2.41361
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.57277

Cumulative Model Updates: 98,326
Cumulative Timesteps: 820,056,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 820056688...
Checkpoint 820056688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.34915
Policy Entropy: 3.17283
Value Function Loss: 0.00434

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.54484
Value Function Update Magnitude: 0.61057

Collected Steps per Second: 22,378.99588
Overall Steps per Second: 10,585.00341

Timestep Collection Time: 2.23531
Timestep Consumption Time: 2.49062
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.72593

Cumulative Model Updates: 98,332
Cumulative Timesteps: 820,106,712

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.09600
Policy Entropy: 3.16733
Value Function Loss: 0.00463

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.61904

Collected Steps per Second: 22,968.71700
Overall Steps per Second: 10,868.83083

Timestep Collection Time: 2.17818
Timestep Consumption Time: 2.42489
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.60307

Cumulative Model Updates: 98,338
Cumulative Timesteps: 820,156,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 820156742...
Checkpoint 820156742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.77620
Policy Entropy: 3.15283
Value Function Loss: 0.00447

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09583
Policy Update Magnitude: 0.54877
Value Function Update Magnitude: 0.63875

Collected Steps per Second: 22,528.79178
Overall Steps per Second: 10,664.44709

Timestep Collection Time: 2.21983
Timestep Consumption Time: 2.46959
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.68941

Cumulative Model Updates: 98,344
Cumulative Timesteps: 820,206,752

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.84868
Policy Entropy: 3.15788
Value Function Loss: 0.00457

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10009
Policy Update Magnitude: 0.55157
Value Function Update Magnitude: 0.63362

Collected Steps per Second: 23,172.17357
Overall Steps per Second: 10,889.18988

Timestep Collection Time: 2.15888
Timestep Consumption Time: 2.43521
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.59410

Cumulative Model Updates: 98,350
Cumulative Timesteps: 820,256,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 820256778...
Checkpoint 820256778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.32328
Policy Entropy: 3.16886
Value Function Loss: 0.00424

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.54914
Value Function Update Magnitude: 0.61755

Collected Steps per Second: 22,492.76841
Overall Steps per Second: 10,693.05733

Timestep Collection Time: 2.22303
Timestep Consumption Time: 2.45309
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.67612

Cumulative Model Updates: 98,356
Cumulative Timesteps: 820,306,780

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.87148
Policy Entropy: 3.17011
Value Function Loss: 0.00441

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.54903
Value Function Update Magnitude: 0.60495

Collected Steps per Second: 23,305.17032
Overall Steps per Second: 10,875.05639

Timestep Collection Time: 2.14656
Timestep Consumption Time: 2.45351
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.60007

Cumulative Model Updates: 98,362
Cumulative Timesteps: 820,356,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 820356806...
Checkpoint 820356806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.18578
Policy Entropy: 3.17773
Value Function Loss: 0.00431

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09323
Policy Update Magnitude: 0.54798
Value Function Update Magnitude: 0.60898

Collected Steps per Second: 22,467.81083
Overall Steps per Second: 10,657.40198

Timestep Collection Time: 2.22621
Timestep Consumption Time: 2.46706
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.69326

Cumulative Model Updates: 98,368
Cumulative Timesteps: 820,406,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.43337
Policy Entropy: 3.16363
Value Function Loss: 0.00481

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.61178

Collected Steps per Second: 23,085.29184
Overall Steps per Second: 10,909.67508

Timestep Collection Time: 2.16657
Timestep Consumption Time: 2.41798
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.58455

Cumulative Model Updates: 98,374
Cumulative Timesteps: 820,456,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 820456840...
Checkpoint 820456840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 927.39780
Policy Entropy: 3.17428
Value Function Loss: 0.00474

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.61695

Collected Steps per Second: 22,519.46877
Overall Steps per Second: 10,641.27928

Timestep Collection Time: 2.22146
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.70113

Cumulative Model Updates: 98,380
Cumulative Timesteps: 820,506,866

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.97561
Policy Entropy: 3.17275
Value Function Loss: 0.00460

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.63044

Collected Steps per Second: 22,908.98687
Overall Steps per Second: 10,830.00208

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.43455
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.61736

Cumulative Model Updates: 98,386
Cumulative Timesteps: 820,556,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 820556872...
Checkpoint 820556872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.91399
Policy Entropy: 3.18485
Value Function Loss: 0.00452

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.55193
Value Function Update Magnitude: 0.61064

Collected Steps per Second: 22,463.67741
Overall Steps per Second: 10,749.31720

Timestep Collection Time: 2.22653
Timestep Consumption Time: 2.42642
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.65295

Cumulative Model Updates: 98,392
Cumulative Timesteps: 820,606,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,448.12655
Policy Entropy: 3.16702
Value Function Loss: 0.00448

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.54706
Value Function Update Magnitude: 0.60142

Collected Steps per Second: 22,750.49376
Overall Steps per Second: 10,822.41177

Timestep Collection Time: 2.19863
Timestep Consumption Time: 2.42326
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.62189

Cumulative Model Updates: 98,398
Cumulative Timesteps: 820,656,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 820656908...
Checkpoint 820656908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.35027
Policy Entropy: 3.13733
Value Function Loss: 0.00468

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09650
Policy Update Magnitude: 0.54768
Value Function Update Magnitude: 0.61373

Collected Steps per Second: 22,545.77786
Overall Steps per Second: 10,684.01583

Timestep Collection Time: 2.21842
Timestep Consumption Time: 2.46297
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.68139

Cumulative Model Updates: 98,404
Cumulative Timesteps: 820,706,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.20522
Policy Entropy: 3.13254
Value Function Loss: 0.00462

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.55269
Value Function Update Magnitude: 0.60837

Collected Steps per Second: 22,998.84670
Overall Steps per Second: 10,862.16171

Timestep Collection Time: 2.17437
Timestep Consumption Time: 2.42950
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.60387

Cumulative Model Updates: 98,410
Cumulative Timesteps: 820,756,932

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 820756932...
Checkpoint 820756932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.28248
Policy Entropy: 3.11608
Value Function Loss: 0.00473

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.60708

Collected Steps per Second: 22,707.29487
Overall Steps per Second: 10,666.39983

Timestep Collection Time: 2.20255
Timestep Consumption Time: 2.48638
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.68893

Cumulative Model Updates: 98,416
Cumulative Timesteps: 820,806,946

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.77954
Policy Entropy: 3.13259
Value Function Loss: 0.00443

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.55185
Value Function Update Magnitude: 0.61167

Collected Steps per Second: 23,086.15878
Overall Steps per Second: 10,842.07388

Timestep Collection Time: 2.16693
Timestep Consumption Time: 2.44714
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.61406

Cumulative Model Updates: 98,422
Cumulative Timesteps: 820,856,972

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 820856972...
Checkpoint 820856972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.78635
Policy Entropy: 3.13457
Value Function Loss: 0.00479

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.55002
Value Function Update Magnitude: 0.60826

Collected Steps per Second: 22,414.91113
Overall Steps per Second: 10,767.37584

Timestep Collection Time: 2.23146
Timestep Consumption Time: 2.41387
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.64533

Cumulative Model Updates: 98,428
Cumulative Timesteps: 820,906,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.29624
Policy Entropy: 3.14552
Value Function Loss: 0.00470

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 0.54392
Value Function Update Magnitude: 0.58528

Collected Steps per Second: 23,188.37463
Overall Steps per Second: 10,874.33818

Timestep Collection Time: 2.15729
Timestep Consumption Time: 2.44290
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.60019

Cumulative Model Updates: 98,434
Cumulative Timesteps: 820,957,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 820957014...
Checkpoint 820957014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.44135
Policy Entropy: 3.15287
Value Function Loss: 0.00463

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.54120
Value Function Update Magnitude: 0.58031

Collected Steps per Second: 22,381.86631
Overall Steps per Second: 10,646.94842

Timestep Collection Time: 2.23529
Timestep Consumption Time: 2.46371
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.69900

Cumulative Model Updates: 98,440
Cumulative Timesteps: 821,007,044

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.29878
Policy Entropy: 3.15351
Value Function Loss: 0.00420

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09037
Policy Update Magnitude: 0.53323
Value Function Update Magnitude: 0.56948

Collected Steps per Second: 23,151.27616
Overall Steps per Second: 10,877.42684

Timestep Collection Time: 2.16014
Timestep Consumption Time: 2.43745
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.59759

Cumulative Model Updates: 98,446
Cumulative Timesteps: 821,057,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 821057054...
Checkpoint 821057054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.32572
Policy Entropy: 3.15093
Value Function Loss: 0.00423

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.53153
Value Function Update Magnitude: 0.55767

Collected Steps per Second: 22,403.31431
Overall Steps per Second: 10,641.53633

Timestep Collection Time: 2.23226
Timestep Consumption Time: 2.46725
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.69951

Cumulative Model Updates: 98,452
Cumulative Timesteps: 821,107,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.57902
Policy Entropy: 3.16308
Value Function Loss: 0.00422

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08620
Policy Update Magnitude: 0.53766
Value Function Update Magnitude: 0.57209

Collected Steps per Second: 22,834.20913
Overall Steps per Second: 10,811.45711

Timestep Collection Time: 2.19066
Timestep Consumption Time: 2.43610
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.62676

Cumulative Model Updates: 98,458
Cumulative Timesteps: 821,157,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 821157086...
Checkpoint 821157086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.03779
Policy Entropy: 3.17252
Value Function Loss: 0.00429

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08734
Policy Update Magnitude: 0.53258
Value Function Update Magnitude: 0.55946

Collected Steps per Second: 22,809.31403
Overall Steps per Second: 10,756.34706

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.64916

Cumulative Model Updates: 98,464
Cumulative Timesteps: 821,207,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.41061
Policy Entropy: 3.16147
Value Function Loss: 0.00436

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08991
Policy Update Magnitude: 0.53169
Value Function Update Magnitude: 0.55403

Collected Steps per Second: 22,676.33929
Overall Steps per Second: 10,694.39493

Timestep Collection Time: 2.20609
Timestep Consumption Time: 2.47169
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.67778

Cumulative Model Updates: 98,470
Cumulative Timesteps: 821,257,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 821257120...
Checkpoint 821257120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.35994
Policy Entropy: 3.16749
Value Function Loss: 0.00420

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08873
Policy Update Magnitude: 0.53334
Value Function Update Magnitude: 0.56458

Collected Steps per Second: 22,622.48545
Overall Steps per Second: 10,786.05634

Timestep Collection Time: 2.21028
Timestep Consumption Time: 2.42552
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.63580

Cumulative Model Updates: 98,476
Cumulative Timesteps: 821,307,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.44239
Policy Entropy: 3.14843
Value Function Loss: 0.00433

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09585
Policy Update Magnitude: 0.53957
Value Function Update Magnitude: 0.56559

Collected Steps per Second: 22,856.11935
Overall Steps per Second: 10,748.24082

Timestep Collection Time: 2.18856
Timestep Consumption Time: 2.46541
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.65397

Cumulative Model Updates: 98,482
Cumulative Timesteps: 821,357,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 821357144...
Checkpoint 821357144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.84448
Policy Entropy: 3.15380
Value Function Loss: 0.00448

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.54312
Value Function Update Magnitude: 0.56929

Collected Steps per Second: 22,755.93131
Overall Steps per Second: 10,808.97557

Timestep Collection Time: 2.19758
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.62653

Cumulative Model Updates: 98,488
Cumulative Timesteps: 821,407,152

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.62273
Policy Entropy: 3.14890
Value Function Loss: 0.00462

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.54370
Value Function Update Magnitude: 0.57914

Collected Steps per Second: 23,279.14055
Overall Steps per Second: 10,919.27849

Timestep Collection Time: 2.14836
Timestep Consumption Time: 2.43180
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.58016

Cumulative Model Updates: 98,494
Cumulative Timesteps: 821,457,164

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 821457164...
Checkpoint 821457164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.90988
Policy Entropy: 3.14680
Value Function Loss: 0.00461

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11253
Policy Update Magnitude: 0.54566
Value Function Update Magnitude: 0.56937

Collected Steps per Second: 22,713.95216
Overall Steps per Second: 10,716.56945

Timestep Collection Time: 2.20199
Timestep Consumption Time: 2.46517
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.66717

Cumulative Model Updates: 98,500
Cumulative Timesteps: 821,507,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.42980
Policy Entropy: 3.14570
Value Function Loss: 0.00438

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.55003
Value Function Update Magnitude: 0.56834

Collected Steps per Second: 23,008.99960
Overall Steps per Second: 10,824.01592

Timestep Collection Time: 2.17402
Timestep Consumption Time: 2.44737
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.62139

Cumulative Model Updates: 98,506
Cumulative Timesteps: 821,557,202

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 821557202...
Checkpoint 821557202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.40617
Policy Entropy: 3.13358
Value Function Loss: 0.00438

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.55173
Value Function Update Magnitude: 0.56693

Collected Steps per Second: 22,569.01318
Overall Steps per Second: 10,694.30771

Timestep Collection Time: 2.21569
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.67595

Cumulative Model Updates: 98,512
Cumulative Timesteps: 821,607,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 827.07074
Policy Entropy: 3.13649
Value Function Loss: 0.00433

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11223
Policy Update Magnitude: 0.54745
Value Function Update Magnitude: 0.56091

Collected Steps per Second: 22,901.84002
Overall Steps per Second: 10,826.93708

Timestep Collection Time: 2.18445
Timestep Consumption Time: 2.43624
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.62070

Cumulative Model Updates: 98,518
Cumulative Timesteps: 821,657,236

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 821657236...
Checkpoint 821657236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.31678
Policy Entropy: 3.13561
Value Function Loss: 0.00422

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.53632
Value Function Update Magnitude: 0.56397

Collected Steps per Second: 22,537.98081
Overall Steps per Second: 10,798.53397

Timestep Collection Time: 2.21972
Timestep Consumption Time: 2.41313
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.63285

Cumulative Model Updates: 98,524
Cumulative Timesteps: 821,707,264

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.91850
Policy Entropy: 3.12850
Value Function Loss: 0.00435

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.53616
Value Function Update Magnitude: 0.56065

Collected Steps per Second: 23,064.66344
Overall Steps per Second: 10,861.38504

Timestep Collection Time: 2.16903
Timestep Consumption Time: 2.43701
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.60604

Cumulative Model Updates: 98,530
Cumulative Timesteps: 821,757,292

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 821757292...
Checkpoint 821757292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.58211
Policy Entropy: 3.12351
Value Function Loss: 0.00456

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.58880

Collected Steps per Second: 22,783.73195
Overall Steps per Second: 10,615.92173

Timestep Collection Time: 2.19499
Timestep Consumption Time: 2.51586
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.71085

Cumulative Model Updates: 98,536
Cumulative Timesteps: 821,807,302

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 909.54342
Policy Entropy: 3.14145
Value Function Loss: 0.00460

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11194
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.61287

Collected Steps per Second: 22,880.01882
Overall Steps per Second: 10,726.81403

Timestep Collection Time: 2.18610
Timestep Consumption Time: 2.47679
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.66289

Cumulative Model Updates: 98,542
Cumulative Timesteps: 821,857,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 821857320...
Checkpoint 821857320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.76933
Policy Entropy: 3.14010
Value Function Loss: 0.00466

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.55496
Value Function Update Magnitude: 0.63717

Collected Steps per Second: 22,783.01066
Overall Steps per Second: 10,805.16074

Timestep Collection Time: 2.19558
Timestep Consumption Time: 2.43387
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.62945

Cumulative Model Updates: 98,548
Cumulative Timesteps: 821,907,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.93935
Policy Entropy: 3.13036
Value Function Loss: 0.00483

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.56181
Value Function Update Magnitude: 0.64364

Collected Steps per Second: 22,730.93508
Overall Steps per Second: 10,683.63951

Timestep Collection Time: 2.20053
Timestep Consumption Time: 2.48140
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.68193

Cumulative Model Updates: 98,554
Cumulative Timesteps: 821,957,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 821957362...
Checkpoint 821957362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.36001
Policy Entropy: 3.11209
Value Function Loss: 0.00482

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11711
Policy Update Magnitude: 0.56542
Value Function Update Magnitude: 0.64142

Collected Steps per Second: 22,568.75824
Overall Steps per Second: 10,660.41864

Timestep Collection Time: 2.21705
Timestep Consumption Time: 2.47658
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.69362

Cumulative Model Updates: 98,560
Cumulative Timesteps: 822,007,398

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.24508
Policy Entropy: 3.11883
Value Function Loss: 0.00471

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.12331
Policy Update Magnitude: 0.56189
Value Function Update Magnitude: 0.63723

Collected Steps per Second: 23,403.50547
Overall Steps per Second: 10,799.60790

Timestep Collection Time: 2.13660
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.63017

Cumulative Model Updates: 98,566
Cumulative Timesteps: 822,057,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 822057402...
Checkpoint 822057402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.07034
Policy Entropy: 3.11513
Value Function Loss: 0.00474

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.55585
Value Function Update Magnitude: 0.64540

Collected Steps per Second: 22,458.64657
Overall Steps per Second: 10,581.61296

Timestep Collection Time: 2.22694
Timestep Consumption Time: 2.49956
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.72650

Cumulative Model Updates: 98,572
Cumulative Timesteps: 822,107,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.35791
Policy Entropy: 3.12620
Value Function Loss: 0.00458

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08798
Policy Update Magnitude: 0.55897
Value Function Update Magnitude: 0.65212

Collected Steps per Second: 23,035.26837
Overall Steps per Second: 10,862.48628

Timestep Collection Time: 2.17076
Timestep Consumption Time: 2.43261
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.60337

Cumulative Model Updates: 98,578
Cumulative Timesteps: 822,157,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 822157420...
Checkpoint 822157420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.02770
Policy Entropy: 3.13641
Value Function Loss: 0.00458

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09496
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.63519

Collected Steps per Second: 22,494.71824
Overall Steps per Second: 10,678.96542

Timestep Collection Time: 2.22274
Timestep Consumption Time: 2.45936
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.68210

Cumulative Model Updates: 98,584
Cumulative Timesteps: 822,207,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.56153
Policy Entropy: 3.14477
Value Function Loss: 0.00446

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10681
Policy Update Magnitude: 0.54697
Value Function Update Magnitude: 0.61596

Collected Steps per Second: 22,482.99662
Overall Steps per Second: 10,622.52837

Timestep Collection Time: 2.22479
Timestep Consumption Time: 2.48407
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.70886

Cumulative Model Updates: 98,590
Cumulative Timesteps: 822,257,440

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 822257440...
Checkpoint 822257440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 823.54166
Policy Entropy: 3.14027
Value Function Loss: 0.00445

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.63183

Collected Steps per Second: 22,827.53530
Overall Steps per Second: 10,847.13223

Timestep Collection Time: 2.19156
Timestep Consumption Time: 2.42053
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.61209

Cumulative Model Updates: 98,596
Cumulative Timesteps: 822,307,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.17895
Policy Entropy: 3.12495
Value Function Loss: 0.00459

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.55468
Value Function Update Magnitude: 0.67190

Collected Steps per Second: 22,936.17331
Overall Steps per Second: 10,743.71036

Timestep Collection Time: 2.17996
Timestep Consumption Time: 2.47392
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.65389

Cumulative Model Updates: 98,602
Cumulative Timesteps: 822,357,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 822357468...
Checkpoint 822357468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.82863
Policy Entropy: 3.12894
Value Function Loss: 0.00469

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09930
Policy Update Magnitude: 0.56061
Value Function Update Magnitude: 0.68689

Collected Steps per Second: 23,165.22197
Overall Steps per Second: 10,851.54254

Timestep Collection Time: 2.15893
Timestep Consumption Time: 2.44982
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.60875

Cumulative Model Updates: 98,608
Cumulative Timesteps: 822,407,480

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.95718
Policy Entropy: 3.13156
Value Function Loss: 0.00454

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.55959
Value Function Update Magnitude: 0.67044

Collected Steps per Second: 22,931.85368
Overall Steps per Second: 10,866.14294

Timestep Collection Time: 2.18133
Timestep Consumption Time: 2.42214
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.60347

Cumulative Model Updates: 98,614
Cumulative Timesteps: 822,457,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 822457502...
Checkpoint 822457502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,379.22912
Policy Entropy: 3.14932
Value Function Loss: 0.00452

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.55167
Value Function Update Magnitude: 0.64025

Collected Steps per Second: 22,323.74084
Overall Steps per Second: 10,717.44921

Timestep Collection Time: 2.24057
Timestep Consumption Time: 2.42639
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.66697

Cumulative Model Updates: 98,620
Cumulative Timesteps: 822,507,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,156.68164
Policy Entropy: 3.16352
Value Function Loss: 0.00446

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.63740

Collected Steps per Second: 22,876.85039
Overall Steps per Second: 10,828.03390

Timestep Collection Time: 2.18614
Timestep Consumption Time: 2.43261
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.61875

Cumulative Model Updates: 98,626
Cumulative Timesteps: 822,557,532

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 822557532...
Checkpoint 822557532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,432.52709
Policy Entropy: 3.15851
Value Function Loss: 0.00439

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08646
Policy Update Magnitude: 0.53945
Value Function Update Magnitude: 0.63281

Collected Steps per Second: 22,557.26649
Overall Steps per Second: 10,655.61631

Timestep Collection Time: 2.21738
Timestep Consumption Time: 2.47667
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.69405

Cumulative Model Updates: 98,632
Cumulative Timesteps: 822,607,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.10744
Policy Entropy: 3.15327
Value Function Loss: 0.00449

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.54214
Value Function Update Magnitude: 0.62138

Collected Steps per Second: 23,056.00339
Overall Steps per Second: 10,906.13474

Timestep Collection Time: 2.17002
Timestep Consumption Time: 2.41749
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.58751

Cumulative Model Updates: 98,638
Cumulative Timesteps: 822,657,582

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 822657582...
Checkpoint 822657582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.37483
Policy Entropy: 3.13166
Value Function Loss: 0.00473

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.54552
Value Function Update Magnitude: 0.61954

Collected Steps per Second: 22,592.21473
Overall Steps per Second: 10,745.07802

Timestep Collection Time: 2.21359
Timestep Consumption Time: 2.44063
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.65422

Cumulative Model Updates: 98,644
Cumulative Timesteps: 822,707,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.49934
Policy Entropy: 3.12530
Value Function Loss: 0.00454

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.60259

Collected Steps per Second: 22,996.65490
Overall Steps per Second: 10,773.25301

Timestep Collection Time: 2.17440
Timestep Consumption Time: 2.46709
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.64149

Cumulative Model Updates: 98,650
Cumulative Timesteps: 822,757,596

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 822757596...
Checkpoint 822757596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.39817
Policy Entropy: 3.12645
Value Function Loss: 0.00448

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.60098

Collected Steps per Second: 22,634.09559
Overall Steps per Second: 10,744.45105

Timestep Collection Time: 2.20994
Timestep Consumption Time: 2.44549
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.65543

Cumulative Model Updates: 98,656
Cumulative Timesteps: 822,807,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 950.59066
Policy Entropy: 3.12247
Value Function Loss: 0.00448

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09933
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.61578

Collected Steps per Second: 23,193.28515
Overall Steps per Second: 10,918.85382

Timestep Collection Time: 2.15614
Timestep Consumption Time: 2.42383
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.57997

Cumulative Model Updates: 98,662
Cumulative Timesteps: 822,857,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 822857624...
Checkpoint 822857624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.95469
Policy Entropy: 3.12991
Value Function Loss: 0.00448

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.55510
Value Function Update Magnitude: 0.62691

Collected Steps per Second: 22,522.14411
Overall Steps per Second: 10,619.36986

Timestep Collection Time: 2.22004
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.70838

Cumulative Model Updates: 98,668
Cumulative Timesteps: 822,907,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.73008
Policy Entropy: 3.13107
Value Function Loss: 0.00483

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.55632
Value Function Update Magnitude: 0.62324

Collected Steps per Second: 22,750.12662
Overall Steps per Second: 10,797.11261

Timestep Collection Time: 2.19805
Timestep Consumption Time: 2.43337
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.63142

Cumulative Model Updates: 98,674
Cumulative Timesteps: 822,957,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 822957630...
Checkpoint 822957630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.28743
Policy Entropy: 3.13869
Value Function Loss: 0.00499

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.56065
Value Function Update Magnitude: 0.63768

Collected Steps per Second: 22,803.69205
Overall Steps per Second: 10,750.43544

Timestep Collection Time: 2.19263
Timestep Consumption Time: 2.45835
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.65097

Cumulative Model Updates: 98,680
Cumulative Timesteps: 823,007,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.33987
Policy Entropy: 3.13361
Value Function Loss: 0.00485

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.56400
Value Function Update Magnitude: 0.64032

Collected Steps per Second: 22,939.68482
Overall Steps per Second: 10,889.67063

Timestep Collection Time: 2.17963
Timestep Consumption Time: 2.41188
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.59151

Cumulative Model Updates: 98,686
Cumulative Timesteps: 823,057,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 823057630...
Checkpoint 823057630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.44027
Policy Entropy: 3.13020
Value Function Loss: 0.00476

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.56433
Value Function Update Magnitude: 0.64494

Collected Steps per Second: 22,552.97108
Overall Steps per Second: 10,672.64864

Timestep Collection Time: 2.21833
Timestep Consumption Time: 2.46935
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.68768

Cumulative Model Updates: 98,692
Cumulative Timesteps: 823,107,660

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.24735
Policy Entropy: 3.12895
Value Function Loss: 0.00467

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09398
Policy Update Magnitude: 0.56883
Value Function Update Magnitude: 0.64053

Collected Steps per Second: 22,951.90358
Overall Steps per Second: 10,862.98425

Timestep Collection Time: 2.17882
Timestep Consumption Time: 2.42471
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.60352

Cumulative Model Updates: 98,698
Cumulative Timesteps: 823,157,668

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 823157668...
Checkpoint 823157668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.17869
Policy Entropy: 3.11867
Value Function Loss: 0.00475

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11557
Policy Update Magnitude: 0.57148
Value Function Update Magnitude: 0.63349

Collected Steps per Second: 22,540.57328
Overall Steps per Second: 10,640.48309

Timestep Collection Time: 2.21884
Timestep Consumption Time: 2.48151
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.70035

Cumulative Model Updates: 98,704
Cumulative Timesteps: 823,207,682

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.40952
Policy Entropy: 3.09507
Value Function Loss: 0.00505

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.56686
Value Function Update Magnitude: 0.62858

Collected Steps per Second: 22,785.78816
Overall Steps per Second: 10,709.58542

Timestep Collection Time: 2.19453
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.66909

Cumulative Model Updates: 98,710
Cumulative Timesteps: 823,257,686

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 823257686...
Checkpoint 823257686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.79675
Policy Entropy: 3.08922
Value Function Loss: 0.00492

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11557
Policy Update Magnitude: 0.56806
Value Function Update Magnitude: 0.63906

Collected Steps per Second: 22,666.62962
Overall Steps per Second: 10,799.98197

Timestep Collection Time: 2.20624
Timestep Consumption Time: 2.42414
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.63038

Cumulative Model Updates: 98,716
Cumulative Timesteps: 823,307,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.03943
Policy Entropy: 3.09338
Value Function Loss: 0.00471

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.12374
Policy Update Magnitude: 0.56392
Value Function Update Magnitude: 0.64067

Collected Steps per Second: 23,021.36840
Overall Steps per Second: 10,856.77684

Timestep Collection Time: 2.17233
Timestep Consumption Time: 2.43401
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.60634

Cumulative Model Updates: 98,722
Cumulative Timesteps: 823,357,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 823357704...
Checkpoint 823357704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.00155
Policy Entropy: 3.12715
Value Function Loss: 0.00450

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11823
Policy Update Magnitude: 0.55583
Value Function Update Magnitude: 0.60801

Collected Steps per Second: 22,570.00228
Overall Steps per Second: 10,781.75252

Timestep Collection Time: 2.21560
Timestep Consumption Time: 2.42243
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.63802

Cumulative Model Updates: 98,728
Cumulative Timesteps: 823,407,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.60835
Policy Entropy: 3.13409
Value Function Loss: 0.00454

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.55285
Value Function Update Magnitude: 0.60084

Collected Steps per Second: 23,253.32669
Overall Steps per Second: 10,929.42825

Timestep Collection Time: 2.15049
Timestep Consumption Time: 2.42487
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.57535

Cumulative Model Updates: 98,734
Cumulative Timesteps: 823,457,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 823457716...
Checkpoint 823457716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 898.88510
Policy Entropy: 3.14402
Value Function Loss: 0.00472

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.54763
Value Function Update Magnitude: 0.60163

Collected Steps per Second: 22,560.17995
Overall Steps per Second: 10,634.93319

Timestep Collection Time: 2.21736
Timestep Consumption Time: 2.48639
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.70374

Cumulative Model Updates: 98,740
Cumulative Timesteps: 823,507,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.36898
Policy Entropy: 3.14199
Value Function Loss: 0.00463

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.54357
Value Function Update Magnitude: 0.59461

Collected Steps per Second: 23,153.88762
Overall Steps per Second: 10,840.80199

Timestep Collection Time: 2.16016
Timestep Consumption Time: 2.45353
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.61368

Cumulative Model Updates: 98,746
Cumulative Timesteps: 823,557,756

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 823557756...
Checkpoint 823557756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.93372
Policy Entropy: 3.15392
Value Function Loss: 0.00452

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.54060
Value Function Update Magnitude: 0.58586

Collected Steps per Second: 22,759.40007
Overall Steps per Second: 10,686.64572

Timestep Collection Time: 2.19821
Timestep Consumption Time: 2.48333
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.68154

Cumulative Model Updates: 98,752
Cumulative Timesteps: 823,607,786

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.54284
Policy Entropy: 3.13776
Value Function Loss: 0.00460

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.54439
Value Function Update Magnitude: 0.57804

Collected Steps per Second: 22,879.72668
Overall Steps per Second: 10,830.73979

Timestep Collection Time: 2.18604
Timestep Consumption Time: 2.43193
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.61797

Cumulative Model Updates: 98,758
Cumulative Timesteps: 823,657,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 823657802...
Checkpoint 823657802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.80227
Policy Entropy: 3.14104
Value Function Loss: 0.00469

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10338
Policy Update Magnitude: 0.55589
Value Function Update Magnitude: 0.59706

Collected Steps per Second: 22,599.21319
Overall Steps per Second: 10,728.98808

Timestep Collection Time: 2.21291
Timestep Consumption Time: 2.44829
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.66120

Cumulative Model Updates: 98,764
Cumulative Timesteps: 823,707,812

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.96438
Policy Entropy: 3.13398
Value Function Loss: 0.00477

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.56439
Value Function Update Magnitude: 0.62385

Collected Steps per Second: 22,928.11467
Overall Steps per Second: 10,824.66779

Timestep Collection Time: 2.18073
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.61908

Cumulative Model Updates: 98,770
Cumulative Timesteps: 823,757,812

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 823757812...
Checkpoint 823757812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.11218
Policy Entropy: 3.13473
Value Function Loss: 0.00492

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.57074
Value Function Update Magnitude: 0.65333

Collected Steps per Second: 22,805.80849
Overall Steps per Second: 10,746.24936

Timestep Collection Time: 2.19295
Timestep Consumption Time: 2.46095
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.65390

Cumulative Model Updates: 98,776
Cumulative Timesteps: 823,807,824

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.26769
Policy Entropy: 3.13436
Value Function Loss: 0.00502

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.56935
Value Function Update Magnitude: 0.66877

Collected Steps per Second: 22,936.76228
Overall Steps per Second: 10,871.09129

Timestep Collection Time: 2.18043
Timestep Consumption Time: 2.42003
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.60046

Cumulative Model Updates: 98,782
Cumulative Timesteps: 823,857,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 823857836...
Checkpoint 823857836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.70717
Policy Entropy: 3.12894
Value Function Loss: 0.00520

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.57012
Value Function Update Magnitude: 0.65272

Collected Steps per Second: 22,391.83135
Overall Steps per Second: 10,669.37144

Timestep Collection Time: 2.23367
Timestep Consumption Time: 2.45414
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.68781

Cumulative Model Updates: 98,788
Cumulative Timesteps: 823,907,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.07707
Policy Entropy: 3.13263
Value Function Loss: 0.00493

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.57306
Value Function Update Magnitude: 0.64115

Collected Steps per Second: 23,138.72321
Overall Steps per Second: 10,869.80617

Timestep Collection Time: 2.16157
Timestep Consumption Time: 2.43980
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.60137

Cumulative Model Updates: 98,794
Cumulative Timesteps: 823,957,868

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 823957868...
Checkpoint 823957868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.77776
Policy Entropy: 3.13373
Value Function Loss: 0.00477

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.64108

Collected Steps per Second: 22,710.24005
Overall Steps per Second: 10,660.55052

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.48854
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.69019

Cumulative Model Updates: 98,800
Cumulative Timesteps: 824,007,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.77207
Policy Entropy: 3.13945
Value Function Loss: 0.00458

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.55267
Value Function Update Magnitude: 0.63215

Collected Steps per Second: 23,229.72211
Overall Steps per Second: 10,923.89426

Timestep Collection Time: 2.15241
Timestep Consumption Time: 2.42471
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.57712

Cumulative Model Updates: 98,806
Cumulative Timesteps: 824,057,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 824057868...
Checkpoint 824057868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.80930
Policy Entropy: 3.15395
Value Function Loss: 0.00456

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08850
Policy Update Magnitude: 0.54848
Value Function Update Magnitude: 0.61435

Collected Steps per Second: 22,514.24257
Overall Steps per Second: 10,658.02319

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.47128
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.69280

Cumulative Model Updates: 98,812
Cumulative Timesteps: 824,107,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.00416
Policy Entropy: 3.15391
Value Function Loss: 0.00456

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.59785

Collected Steps per Second: 22,712.09576
Overall Steps per Second: 10,614.38239

Timestep Collection Time: 2.20235
Timestep Consumption Time: 2.51012
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.71247

Cumulative Model Updates: 98,818
Cumulative Timesteps: 824,157,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 824157904...
Checkpoint 824157904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.11380
Policy Entropy: 3.15638
Value Function Loss: 0.00443

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.54515
Value Function Update Magnitude: 0.59263

Collected Steps per Second: 22,675.92717
Overall Steps per Second: 10,630.69807

Timestep Collection Time: 2.20551
Timestep Consumption Time: 2.49898
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.70449

Cumulative Model Updates: 98,824
Cumulative Timesteps: 824,207,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.89223
Policy Entropy: 3.15687
Value Function Loss: 0.00433

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08814
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.58878

Collected Steps per Second: 22,949.74317
Overall Steps per Second: 10,717.69580

Timestep Collection Time: 2.17920
Timestep Consumption Time: 2.48711
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.66630

Cumulative Model Updates: 98,830
Cumulative Timesteps: 824,257,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 824257928...
Checkpoint 824257928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.99942
Policy Entropy: 3.15572
Value Function Loss: 0.00412

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.53451
Value Function Update Magnitude: 0.56711

Collected Steps per Second: 22,800.30568
Overall Steps per Second: 10,634.37143

Timestep Collection Time: 2.19365
Timestep Consumption Time: 2.50959
PPO Batch Consumption Time: 0.29698
Total Iteration Time: 4.70324

Cumulative Model Updates: 98,836
Cumulative Timesteps: 824,307,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.71524
Policy Entropy: 3.15128
Value Function Loss: 0.00430

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.52793
Value Function Update Magnitude: 0.56654

Collected Steps per Second: 22,739.69397
Overall Steps per Second: 10,832.08331

Timestep Collection Time: 2.19968
Timestep Consumption Time: 2.41809
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.61776

Cumulative Model Updates: 98,842
Cumulative Timesteps: 824,357,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 824357964...
Checkpoint 824357964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 913.35677
Policy Entropy: 3.14890
Value Function Loss: 0.00439

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.54233
Value Function Update Magnitude: 0.58681

Collected Steps per Second: 22,406.65202
Overall Steps per Second: 10,693.99183

Timestep Collection Time: 2.23210
Timestep Consumption Time: 2.44473
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.67683

Cumulative Model Updates: 98,848
Cumulative Timesteps: 824,407,978

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.38403
Policy Entropy: 3.14413
Value Function Loss: 0.00438

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11579
Policy Update Magnitude: 0.54620
Value Function Update Magnitude: 0.59595

Collected Steps per Second: 23,136.98179
Overall Steps per Second: 10,891.15233

Timestep Collection Time: 2.16217
Timestep Consumption Time: 2.43110
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.59327

Cumulative Model Updates: 98,854
Cumulative Timesteps: 824,458,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 824458004...
Checkpoint 824458004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,186.00322
Policy Entropy: 3.13299
Value Function Loss: 0.00427

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.54505
Value Function Update Magnitude: 0.59060

Collected Steps per Second: 22,438.19572
Overall Steps per Second: 10,690.64892

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.44991
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.67942

Cumulative Model Updates: 98,860
Cumulative Timesteps: 824,508,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.12947
Policy Entropy: 3.12946
Value Function Loss: 0.00444

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10543
Policy Update Magnitude: 0.54407
Value Function Update Magnitude: 0.57039

Collected Steps per Second: 22,894.77479
Overall Steps per Second: 10,850.92426

Timestep Collection Time: 2.18495
Timestep Consumption Time: 2.42516
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.61011

Cumulative Model Updates: 98,866
Cumulative Timesteps: 824,558,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 824558054...
Checkpoint 824558054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.42799
Policy Entropy: 3.12447
Value Function Loss: 0.00450

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10226
Policy Update Magnitude: 0.54935
Value Function Update Magnitude: 0.57435

Collected Steps per Second: 22,367.83584
Overall Steps per Second: 10,724.25046

Timestep Collection Time: 2.23535
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.66233

Cumulative Model Updates: 98,872
Cumulative Timesteps: 824,608,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.24061
Policy Entropy: 3.13130
Value Function Loss: 0.00437

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10211
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.57409

Collected Steps per Second: 23,261.37330
Overall Steps per Second: 10,926.61573

Timestep Collection Time: 2.14974
Timestep Consumption Time: 2.42679
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.57653

Cumulative Model Updates: 98,878
Cumulative Timesteps: 824,658,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 824658060...
Checkpoint 824658060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.94561
Policy Entropy: 3.14698
Value Function Loss: 0.00423

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.54217
Value Function Update Magnitude: 0.58955

Collected Steps per Second: 22,362.90251
Overall Steps per Second: 10,639.93686

Timestep Collection Time: 2.23710
Timestep Consumption Time: 2.46481
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.70191

Cumulative Model Updates: 98,884
Cumulative Timesteps: 824,708,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 918.43953
Policy Entropy: 3.15574
Value Function Loss: 0.00439

Mean KL Divergence: 0.00697
SB3 Clip Fraction: 0.07585
Policy Update Magnitude: 0.54447
Value Function Update Magnitude: 0.59535

Collected Steps per Second: 22,975.88143
Overall Steps per Second: 10,772.02483

Timestep Collection Time: 2.17715
Timestep Consumption Time: 2.46654
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.64370

Cumulative Model Updates: 98,890
Cumulative Timesteps: 824,758,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 824758110...
Checkpoint 824758110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,089.06635
Policy Entropy: 3.15336
Value Function Loss: 0.00454

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08843
Policy Update Magnitude: 0.54510
Value Function Update Magnitude: 0.59457

Collected Steps per Second: 22,750.41387
Overall Steps per Second: 10,800.04993

Timestep Collection Time: 2.19847
Timestep Consumption Time: 2.43262
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.63109

Cumulative Model Updates: 98,896
Cumulative Timesteps: 824,808,126

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.87087
Policy Entropy: 3.14618
Value Function Loss: 0.00469

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.55255
Value Function Update Magnitude: 0.59947

Collected Steps per Second: 22,572.38838
Overall Steps per Second: 10,481.57218

Timestep Collection Time: 2.21554
Timestep Consumption Time: 2.55569
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.77123

Cumulative Model Updates: 98,902
Cumulative Timesteps: 824,858,136

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 824858136...
Checkpoint 824858136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.21930
Policy Entropy: 3.15930
Value Function Loss: 0.00445

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.55235
Value Function Update Magnitude: 0.60174

Collected Steps per Second: 22,741.65095
Overall Steps per Second: 10,678.32488

Timestep Collection Time: 2.19966
Timestep Consumption Time: 2.48497
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.68463

Cumulative Model Updates: 98,908
Cumulative Timesteps: 824,908,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,092.17636
Policy Entropy: 3.15941
Value Function Loss: 0.00434

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10002
Policy Update Magnitude: 0.54347
Value Function Update Magnitude: 0.59971

Collected Steps per Second: 23,101.25796
Overall Steps per Second: 10,825.08149

Timestep Collection Time: 2.16473
Timestep Consumption Time: 2.45491
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.61964

Cumulative Model Updates: 98,914
Cumulative Timesteps: 824,958,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 824958168...
Checkpoint 824958168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,952.40291
Policy Entropy: 3.18298
Value Function Loss: 0.00423

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 0.53420
Value Function Update Magnitude: 0.56939

Collected Steps per Second: 22,927.22478
Overall Steps per Second: 10,628.38866

Timestep Collection Time: 2.18177
Timestep Consumption Time: 2.52468
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.70645

Cumulative Model Updates: 98,920
Cumulative Timesteps: 825,008,190

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.28125
Policy Entropy: 3.18232
Value Function Loss: 0.00427

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08468
Policy Update Magnitude: 0.53163
Value Function Update Magnitude: 0.56851

Collected Steps per Second: 22,468.69763
Overall Steps per Second: 10,526.25732

Timestep Collection Time: 2.22656
Timestep Consumption Time: 2.52612
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.75269

Cumulative Model Updates: 98,926
Cumulative Timesteps: 825,058,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 825058218...
Checkpoint 825058218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.79309
Policy Entropy: 3.18505
Value Function Loss: 0.00433

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09277
Policy Update Magnitude: 0.53345
Value Function Update Magnitude: 0.59010

Collected Steps per Second: 22,206.02192
Overall Steps per Second: 10,560.54290

Timestep Collection Time: 2.25263
Timestep Consumption Time: 2.48406
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.73669

Cumulative Model Updates: 98,932
Cumulative Timesteps: 825,108,240

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.36765
Policy Entropy: 3.17304
Value Function Loss: 0.00459

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.54539
Value Function Update Magnitude: 0.62310

Collected Steps per Second: 23,013.03500
Overall Steps per Second: 10,805.36724

Timestep Collection Time: 2.17268
Timestep Consumption Time: 2.45465
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.62733

Cumulative Model Updates: 98,938
Cumulative Timesteps: 825,158,240

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 825158240...
Checkpoint 825158240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715.68255
Policy Entropy: 3.16932
Value Function Loss: 0.00470

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08635
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.63654

Collected Steps per Second: 22,536.91779
Overall Steps per Second: 10,677.11607

Timestep Collection Time: 2.21982
Timestep Consumption Time: 2.46571
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.68553

Cumulative Model Updates: 98,944
Cumulative Timesteps: 825,208,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.60491
Policy Entropy: 3.17273
Value Function Loss: 0.00468

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.55724
Value Function Update Magnitude: 0.64930

Collected Steps per Second: 23,024.62422
Overall Steps per Second: 10,683.17496

Timestep Collection Time: 2.17254
Timestep Consumption Time: 2.50977
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.68232

Cumulative Model Updates: 98,950
Cumulative Timesteps: 825,258,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 825258290...
Checkpoint 825258290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.71085
Policy Entropy: 3.17193
Value Function Loss: 0.00440

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.55064
Value Function Update Magnitude: 0.64112

Collected Steps per Second: 22,597.71410
Overall Steps per Second: 10,601.83126

Timestep Collection Time: 2.21306
Timestep Consumption Time: 2.50405
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.71711

Cumulative Model Updates: 98,956
Cumulative Timesteps: 825,308,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.02487
Policy Entropy: 3.16616
Value Function Loss: 0.00438

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.54090
Value Function Update Magnitude: 0.62786

Collected Steps per Second: 23,307.86538
Overall Steps per Second: 10,748.71593

Timestep Collection Time: 2.14528
Timestep Consumption Time: 2.50662
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.65190

Cumulative Model Updates: 98,962
Cumulative Timesteps: 825,358,302

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 825358302...
Checkpoint 825358302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.74503
Policy Entropy: 3.17266
Value Function Loss: 0.00416

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.53955
Value Function Update Magnitude: 0.60823

Collected Steps per Second: 22,881.16232
Overall Steps per Second: 10,643.24548

Timestep Collection Time: 2.18547
Timestep Consumption Time: 2.51291
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.69838

Cumulative Model Updates: 98,968
Cumulative Timesteps: 825,408,308

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800.73433
Policy Entropy: 3.16088
Value Function Loss: 0.00429

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.54171
Value Function Update Magnitude: 0.60369

Collected Steps per Second: 22,924.68438
Overall Steps per Second: 10,848.23679

Timestep Collection Time: 2.18228
Timestep Consumption Time: 2.42935
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.61162

Cumulative Model Updates: 98,974
Cumulative Timesteps: 825,458,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 825458336...
Checkpoint 825458336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.98462
Policy Entropy: 3.16863
Value Function Loss: 0.00436

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.54227
Value Function Update Magnitude: 0.59579

Collected Steps per Second: 22,514.29499
Overall Steps per Second: 10,679.22128

Timestep Collection Time: 2.22090
Timestep Consumption Time: 2.46128
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.68218

Cumulative Model Updates: 98,980
Cumulative Timesteps: 825,508,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.05619
Policy Entropy: 3.16217
Value Function Loss: 0.00440

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.53860
Value Function Update Magnitude: 0.58980

Collected Steps per Second: 22,817.54419
Overall Steps per Second: 10,626.40318

Timestep Collection Time: 2.19165
Timestep Consumption Time: 2.51437
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.70601

Cumulative Model Updates: 98,986
Cumulative Timesteps: 825,558,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 825558346...
Checkpoint 825558346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.62532
Policy Entropy: 3.18275
Value Function Loss: 0.00464

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.08450
Policy Update Magnitude: 0.53728
Value Function Update Magnitude: 0.59370

Collected Steps per Second: 22,874.58226
Overall Steps per Second: 10,669.38488

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.50147
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.68818

Cumulative Model Updates: 98,992
Cumulative Timesteps: 825,608,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.94775
Policy Entropy: 3.18028
Value Function Loss: 0.00453

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08983
Policy Update Magnitude: 0.53441
Value Function Update Magnitude: 0.60304

Collected Steps per Second: 22,822.62875
Overall Steps per Second: 10,802.42913

Timestep Collection Time: 2.19107
Timestep Consumption Time: 2.43807
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.62914

Cumulative Model Updates: 98,998
Cumulative Timesteps: 825,658,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 825658372...
Checkpoint 825658372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.99343
Policy Entropy: 3.16640
Value Function Loss: 0.00461

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.54328
Value Function Update Magnitude: 0.61153

Collected Steps per Second: 22,402.07589
Overall Steps per Second: 10,583.76326

Timestep Collection Time: 2.23319
Timestep Consumption Time: 2.49368
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.72686

Cumulative Model Updates: 99,004
Cumulative Timesteps: 825,708,400

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.47068
Policy Entropy: 3.15870
Value Function Loss: 0.00430

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09990
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.62788

Collected Steps per Second: 22,906.92161
Overall Steps per Second: 10,831.16909

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.61686

Cumulative Model Updates: 99,010
Cumulative Timesteps: 825,758,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 825758406...
Checkpoint 825758406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.64030
Policy Entropy: 3.13616
Value Function Loss: 0.00468

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.62189

Collected Steps per Second: 22,543.82247
Overall Steps per Second: 10,691.97735

Timestep Collection Time: 2.21906
Timestep Consumption Time: 2.45978
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.67884

Cumulative Model Updates: 99,016
Cumulative Timesteps: 825,808,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 710.18759
Policy Entropy: 3.12862
Value Function Loss: 0.00490

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11489
Policy Update Magnitude: 0.56183
Value Function Update Magnitude: 0.63703

Collected Steps per Second: 22,985.54059
Overall Steps per Second: 10,852.29234

Timestep Collection Time: 2.17545
Timestep Consumption Time: 2.43224
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.60769

Cumulative Model Updates: 99,022
Cumulative Timesteps: 825,858,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 825858436...
Checkpoint 825858436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.01532
Policy Entropy: 3.12100
Value Function Loss: 0.00504

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.57692
Value Function Update Magnitude: 0.67000

Collected Steps per Second: 22,498.15249
Overall Steps per Second: 10,791.85134

Timestep Collection Time: 2.22258
Timestep Consumption Time: 2.41091
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.63350

Cumulative Model Updates: 99,028
Cumulative Timesteps: 825,908,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.63748
Policy Entropy: 3.13099
Value Function Loss: 0.00469

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.57324
Value Function Update Magnitude: 0.68332

Collected Steps per Second: 23,025.40484
Overall Steps per Second: 10,861.20771

Timestep Collection Time: 2.17169
Timestep Consumption Time: 2.43222
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.60391

Cumulative Model Updates: 99,034
Cumulative Timesteps: 825,958,444

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 825958444...
Checkpoint 825958444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.22225
Policy Entropy: 3.14577
Value Function Loss: 0.00443

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.56072
Value Function Update Magnitude: 0.66125

Collected Steps per Second: 22,678.55383
Overall Steps per Second: 10,630.06229

Timestep Collection Time: 2.20570
Timestep Consumption Time: 2.50001
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.70571

Cumulative Model Updates: 99,040
Cumulative Timesteps: 826,008,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.68732
Policy Entropy: 3.13918
Value Function Loss: 0.00470

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.55683
Value Function Update Magnitude: 0.62983

Collected Steps per Second: 22,462.13561
Overall Steps per Second: 10,564.98758

Timestep Collection Time: 2.22730
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.73545

Cumulative Model Updates: 99,046
Cumulative Timesteps: 826,058,496

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 826058496...
Checkpoint 826058496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.90946
Policy Entropy: 3.15637
Value Function Loss: 0.00469

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09204
Policy Update Magnitude: 0.56193
Value Function Update Magnitude: 0.63971

Collected Steps per Second: 22,914.82599
Overall Steps per Second: 10,736.97350

Timestep Collection Time: 2.18217
Timestep Consumption Time: 2.47501
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.65718

Cumulative Model Updates: 99,052
Cumulative Timesteps: 826,108,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.04174
Policy Entropy: 3.15821
Value Function Loss: 0.00485

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.56563
Value Function Update Magnitude: 0.63320

Collected Steps per Second: 22,889.51001
Overall Steps per Second: 10,695.82487

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.49091
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.67584

Cumulative Model Updates: 99,058
Cumulative Timesteps: 826,158,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 826158512...
Checkpoint 826158512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,539.05136
Policy Entropy: 3.15502
Value Function Loss: 0.00470

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.56599
Value Function Update Magnitude: 0.62997

Collected Steps per Second: 22,867.44272
Overall Steps per Second: 10,650.28785

Timestep Collection Time: 2.18721
Timestep Consumption Time: 2.50900
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.69621

Cumulative Model Updates: 99,064
Cumulative Timesteps: 826,208,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.69800
Policy Entropy: 3.13575
Value Function Loss: 0.00503

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.57495
Value Function Update Magnitude: 0.63589

Collected Steps per Second: 22,962.65435
Overall Steps per Second: 10,832.69974

Timestep Collection Time: 2.17823
Timestep Consumption Time: 2.43908
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.61732

Cumulative Model Updates: 99,070
Cumulative Timesteps: 826,258,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 826258546...
Checkpoint 826258546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.68671
Policy Entropy: 3.15391
Value Function Loss: 0.00485

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.57594
Value Function Update Magnitude: 0.66766

Collected Steps per Second: 22,432.72268
Overall Steps per Second: 10,746.52441

Timestep Collection Time: 2.23094
Timestep Consumption Time: 2.42601
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.65695

Cumulative Model Updates: 99,076
Cumulative Timesteps: 826,308,592

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.42029
Policy Entropy: 3.14948
Value Function Loss: 0.00471

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.56467
Value Function Update Magnitude: 0.65100

Collected Steps per Second: 22,944.28827
Overall Steps per Second: 10,847.14456

Timestep Collection Time: 2.18024
Timestep Consumption Time: 2.43148
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.61172

Cumulative Model Updates: 99,082
Cumulative Timesteps: 826,358,616

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 826358616...
Checkpoint 826358616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.36670
Policy Entropy: 3.15963
Value Function Loss: 0.00459

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.55910
Value Function Update Magnitude: 0.62567

Collected Steps per Second: 22,776.81725
Overall Steps per Second: 10,661.53460

Timestep Collection Time: 2.19600
Timestep Consumption Time: 2.49544
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.69144

Cumulative Model Updates: 99,088
Cumulative Timesteps: 826,408,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.65349
Policy Entropy: 3.14731
Value Function Loss: 0.00462

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.62865

Collected Steps per Second: 22,874.40234
Overall Steps per Second: 10,829.08628

Timestep Collection Time: 2.18672
Timestep Consumption Time: 2.43232
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.61904

Cumulative Model Updates: 99,094
Cumulative Timesteps: 826,458,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 826458654...
Checkpoint 826458654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.12011
Policy Entropy: 3.16050
Value Function Loss: 0.00472

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.56418
Value Function Update Magnitude: 0.64278

Collected Steps per Second: 22,644.31802
Overall Steps per Second: 10,764.24365

Timestep Collection Time: 2.20832
Timestep Consumption Time: 2.43724
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.64557

Cumulative Model Updates: 99,100
Cumulative Timesteps: 826,508,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.95394
Policy Entropy: 3.16484
Value Function Loss: 0.00482

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.57290
Value Function Update Magnitude: 0.64349

Collected Steps per Second: 23,114.96999
Overall Steps per Second: 10,845.36743

Timestep Collection Time: 2.16431
Timestep Consumption Time: 2.44853
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.61285

Cumulative Model Updates: 99,106
Cumulative Timesteps: 826,558,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 826558688...
Checkpoint 826558688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.17623
Policy Entropy: 3.16247
Value Function Loss: 0.00498

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.57666
Value Function Update Magnitude: 0.65165

Collected Steps per Second: 22,633.07284
Overall Steps per Second: 10,743.98797

Timestep Collection Time: 2.20942
Timestep Consumption Time: 2.44490
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.65432

Cumulative Model Updates: 99,112
Cumulative Timesteps: 826,608,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.85261
Policy Entropy: 3.14752
Value Function Loss: 0.00495

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.58252
Value Function Update Magnitude: 0.68024

Collected Steps per Second: 22,263.13311
Overall Steps per Second: 10,563.10890

Timestep Collection Time: 2.24694
Timestep Consumption Time: 2.48878
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.73573

Cumulative Model Updates: 99,118
Cumulative Timesteps: 826,658,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 826658718...
Checkpoint 826658718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.88299
Policy Entropy: 3.14079
Value Function Loss: 0.00493

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.58068
Value Function Update Magnitude: 0.67286

Collected Steps per Second: 22,762.75768
Overall Steps per Second: 10,975.67293

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.35924
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.55608

Cumulative Model Updates: 99,124
Cumulative Timesteps: 826,708,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.17446
Policy Entropy: 3.15106
Value Function Loss: 0.00489

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.57500
Value Function Update Magnitude: 0.66574

Collected Steps per Second: 22,280.77437
Overall Steps per Second: 10,801.35957

Timestep Collection Time: 2.24525
Timestep Consumption Time: 2.38620
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.63145

Cumulative Model Updates: 99,130
Cumulative Timesteps: 826,758,750

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 826758750...
Checkpoint 826758750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.12812
Policy Entropy: 3.14474
Value Function Loss: 0.00476

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.56127
Value Function Update Magnitude: 0.65604

Collected Steps per Second: 22,330.50423
Overall Steps per Second: 10,703.49415

Timestep Collection Time: 2.24034
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.67399

Cumulative Model Updates: 99,136
Cumulative Timesteps: 826,808,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.76642
Policy Entropy: 3.14537
Value Function Loss: 0.00498

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.64445

Collected Steps per Second: 22,194.96872
Overall Steps per Second: 10,664.08251

Timestep Collection Time: 2.25357
Timestep Consumption Time: 2.43675
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.69032

Cumulative Model Updates: 99,142
Cumulative Timesteps: 826,858,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 826858796...
Checkpoint 826858796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.18844
Policy Entropy: 3.13788
Value Function Loss: 0.00503

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.57128
Value Function Update Magnitude: 0.66029

Collected Steps per Second: 22,076.17592
Overall Steps per Second: 10,762.92260

Timestep Collection Time: 2.26516
Timestep Consumption Time: 2.38098
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.64614

Cumulative Model Updates: 99,148
Cumulative Timesteps: 826,908,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.60927
Policy Entropy: 3.14720
Value Function Loss: 0.00517

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.56996
Value Function Update Magnitude: 0.66335

Collected Steps per Second: 22,240.44169
Overall Steps per Second: 10,665.00425

Timestep Collection Time: 2.24888
Timestep Consumption Time: 2.44085
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.68973

Cumulative Model Updates: 99,154
Cumulative Timesteps: 826,958,818

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 826958818...
Checkpoint 826958818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.52012
Policy Entropy: 3.15282
Value Function Loss: 0.00504

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10184
Policy Update Magnitude: 0.57427
Value Function Update Magnitude: 0.66428

Collected Steps per Second: 22,315.99135
Overall Steps per Second: 10,721.05068

Timestep Collection Time: 2.24108
Timestep Consumption Time: 2.42376
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.66484

Cumulative Model Updates: 99,160
Cumulative Timesteps: 827,008,830

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 827.22377
Policy Entropy: 3.15600
Value Function Loss: 0.00492

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10561
Policy Update Magnitude: 0.57156
Value Function Update Magnitude: 0.66225

Collected Steps per Second: 22,582.66046
Overall Steps per Second: 10,726.49698

Timestep Collection Time: 2.21435
Timestep Consumption Time: 2.44756
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.66191

Cumulative Model Updates: 99,166
Cumulative Timesteps: 827,058,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 827058836...
Checkpoint 827058836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,390.10383
Policy Entropy: 3.14588
Value Function Loss: 0.00501

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.57394
Value Function Update Magnitude: 0.64788

Collected Steps per Second: 21,980.58733
Overall Steps per Second: 10,633.23400

Timestep Collection Time: 2.27546
Timestep Consumption Time: 2.42828
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.70374

Cumulative Model Updates: 99,172
Cumulative Timesteps: 827,108,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 821.53357
Policy Entropy: 3.13909
Value Function Loss: 0.00509

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11517
Policy Update Magnitude: 0.58415
Value Function Update Magnitude: 0.64475

Collected Steps per Second: 22,553.53026
Overall Steps per Second: 10,840.61341

Timestep Collection Time: 2.21828
Timestep Consumption Time: 2.39677
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.61505

Cumulative Model Updates: 99,178
Cumulative Timesteps: 827,158,882

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 827158882...
Checkpoint 827158882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,582.58828
Policy Entropy: 3.14873
Value Function Loss: 0.00505

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 0.57879
Value Function Update Magnitude: 0.64618

Collected Steps per Second: 21,908.63135
Overall Steps per Second: 10,784.77458

Timestep Collection Time: 2.28257
Timestep Consumption Time: 2.35434
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.63691

Cumulative Model Updates: 99,184
Cumulative Timesteps: 827,208,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.83330
Policy Entropy: 3.15235
Value Function Loss: 0.00491

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11898
Policy Update Magnitude: 0.56571
Value Function Update Magnitude: 0.66350

Collected Steps per Second: 21,945.56906
Overall Steps per Second: 10,756.24930

Timestep Collection Time: 2.27955
Timestep Consumption Time: 2.37133
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.65088

Cumulative Model Updates: 99,190
Cumulative Timesteps: 827,258,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 827258916...
Checkpoint 827258916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.19850
Policy Entropy: 3.15494
Value Function Loss: 0.00485

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.56655
Value Function Update Magnitude: 0.65863

Collected Steps per Second: 22,891.56483
Overall Steps per Second: 10,720.01985

Timestep Collection Time: 2.18439
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.66454

Cumulative Model Updates: 99,196
Cumulative Timesteps: 827,308,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.54033
Policy Entropy: 3.13490
Value Function Loss: 0.00506

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.57287
Value Function Update Magnitude: 0.65956

Collected Steps per Second: 22,779.80491
Overall Steps per Second: 10,640.18858

Timestep Collection Time: 2.19528
Timestep Consumption Time: 2.50464
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.69992

Cumulative Model Updates: 99,202
Cumulative Timesteps: 827,358,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 827358928...
Checkpoint 827358928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.27880
Policy Entropy: 3.15155
Value Function Loss: 0.00492

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.11191
Policy Update Magnitude: 0.57282
Value Function Update Magnitude: 0.64530

Collected Steps per Second: 23,236.80497
Overall Steps per Second: 10,847.99907

Timestep Collection Time: 2.15210
Timestep Consumption Time: 2.45778
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.60988

Cumulative Model Updates: 99,208
Cumulative Timesteps: 827,408,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.28428
Policy Entropy: 3.15485
Value Function Loss: 0.00507

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.56878
Value Function Update Magnitude: 0.63327

Collected Steps per Second: 22,722.06505
Overall Steps per Second: 10,611.65460

Timestep Collection Time: 2.20130
Timestep Consumption Time: 2.51220
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.71350

Cumulative Model Updates: 99,214
Cumulative Timesteps: 827,458,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 827458954...
Checkpoint 827458954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.02699
Policy Entropy: 3.14366
Value Function Loss: 0.00491

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.57021
Value Function Update Magnitude: 0.64270

Collected Steps per Second: 22,830.93140
Overall Steps per Second: 10,626.91420

Timestep Collection Time: 2.19027
Timestep Consumption Time: 2.51533
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.70560

Cumulative Model Updates: 99,220
Cumulative Timesteps: 827,508,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.88262
Policy Entropy: 3.13214
Value Function Loss: 0.00502

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.57534
Value Function Update Magnitude: 0.67284

Collected Steps per Second: 22,754.26112
Overall Steps per Second: 10,760.64136

Timestep Collection Time: 2.19783
Timestep Consumption Time: 2.44966
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.64749

Cumulative Model Updates: 99,226
Cumulative Timesteps: 827,558,970

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 827558970...
Checkpoint 827558970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 846.18991
Policy Entropy: 3.12636
Value Function Loss: 0.00487

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.57774
Value Function Update Magnitude: 0.69307

Collected Steps per Second: 22,746.88618
Overall Steps per Second: 10,694.33571

Timestep Collection Time: 2.19863
Timestep Consumption Time: 2.47786
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.67649

Cumulative Model Updates: 99,232
Cumulative Timesteps: 827,608,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.00918
Policy Entropy: 3.12690
Value Function Loss: 0.00481

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.57075
Value Function Update Magnitude: 0.68849

Collected Steps per Second: 23,217.32654
Overall Steps per Second: 10,837.17502

Timestep Collection Time: 2.15425
Timestep Consumption Time: 2.46097
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.61522

Cumulative Model Updates: 99,238
Cumulative Timesteps: 827,658,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 827658998...
Checkpoint 827658998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.01405
Policy Entropy: 3.11728
Value Function Loss: 0.00492

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.56523
Value Function Update Magnitude: 0.66722

Collected Steps per Second: 22,502.84491
Overall Steps per Second: 10,746.02546

Timestep Collection Time: 2.22265
Timestep Consumption Time: 2.43172
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.65437

Cumulative Model Updates: 99,244
Cumulative Timesteps: 827,709,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,444.49160
Policy Entropy: 3.12794
Value Function Loss: 0.00489

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.56883
Value Function Update Magnitude: 0.64627

Collected Steps per Second: 22,769.64892
Overall Steps per Second: 10,748.59320

Timestep Collection Time: 2.19634
Timestep Consumption Time: 2.45636
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.65270

Cumulative Model Updates: 99,250
Cumulative Timesteps: 827,759,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 827759024...
Checkpoint 827759024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.37645
Policy Entropy: 3.12951
Value Function Loss: 0.00488

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.57729
Value Function Update Magnitude: 0.64128

Collected Steps per Second: 22,950.60664
Overall Steps per Second: 10,777.26568

Timestep Collection Time: 2.17929
Timestep Consumption Time: 2.46159
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.64088

Cumulative Model Updates: 99,256
Cumulative Timesteps: 827,809,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.35208
Policy Entropy: 3.12686
Value Function Loss: 0.00462

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.56871
Value Function Update Magnitude: 0.64289

Collected Steps per Second: 22,520.44732
Overall Steps per Second: 10,562.86100

Timestep Collection Time: 2.22056
Timestep Consumption Time: 2.51376
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.73432

Cumulative Model Updates: 99,262
Cumulative Timesteps: 827,859,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 827859048...
Checkpoint 827859048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.25171
Policy Entropy: 3.12320
Value Function Loss: 0.00476

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.56688
Value Function Update Magnitude: 0.64772

Collected Steps per Second: 23,263.71631
Overall Steps per Second: 10,904.70787

Timestep Collection Time: 2.14979
Timestep Consumption Time: 2.43649
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.58628

Cumulative Model Updates: 99,268
Cumulative Timesteps: 827,909,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.70812
Policy Entropy: 3.14208
Value Function Loss: 0.00469

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.57074
Value Function Update Magnitude: 0.64052

Collected Steps per Second: 22,822.80999
Overall Steps per Second: 10,622.00838

Timestep Collection Time: 2.19105
Timestep Consumption Time: 2.51672
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.70777

Cumulative Model Updates: 99,274
Cumulative Timesteps: 827,959,066

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 827959066...
Checkpoint 827959066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.62748
Policy Entropy: 3.14439
Value Function Loss: 0.00481

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.57059
Value Function Update Magnitude: 0.62743

Collected Steps per Second: 23,163.54773
Overall Steps per Second: 10,769.88255

Timestep Collection Time: 2.15960
Timestep Consumption Time: 2.48520
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.64480

Cumulative Model Updates: 99,280
Cumulative Timesteps: 828,009,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,968.73190
Policy Entropy: 3.15764
Value Function Loss: 0.00471

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.56728
Value Function Update Magnitude: 0.61074

Collected Steps per Second: 23,029.47934
Overall Steps per Second: 10,698.99059

Timestep Collection Time: 2.17174
Timestep Consumption Time: 2.50291
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.67465

Cumulative Model Updates: 99,286
Cumulative Timesteps: 828,059,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 828059104...
Checkpoint 828059104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.96287
Policy Entropy: 3.15692
Value Function Loss: 0.00451

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.56084
Value Function Update Magnitude: 0.59684

Collected Steps per Second: 22,014.34661
Overall Steps per Second: 10,618.25825

Timestep Collection Time: 2.27188
Timestep Consumption Time: 2.43831
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.71019

Cumulative Model Updates: 99,292
Cumulative Timesteps: 828,109,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.48326
Policy Entropy: 3.15376
Value Function Loss: 0.00447

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.59957

Collected Steps per Second: 22,144.52323
Overall Steps per Second: 10,797.16243

Timestep Collection Time: 2.25889
Timestep Consumption Time: 2.37400
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.63288

Cumulative Model Updates: 99,298
Cumulative Timesteps: 828,159,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 828159140...
Checkpoint 828159140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578.23631
Policy Entropy: 3.14200
Value Function Loss: 0.00470

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.55550
Value Function Update Magnitude: 0.61059

Collected Steps per Second: 21,926.69620
Overall Steps per Second: 10,752.29266

Timestep Collection Time: 2.28105
Timestep Consumption Time: 2.37060
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.65166

Cumulative Model Updates: 99,304
Cumulative Timesteps: 828,209,156

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.06830
Policy Entropy: 3.13045
Value Function Loss: 0.00474

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.56775
Value Function Update Magnitude: 0.62605

Collected Steps per Second: 22,087.71729
Overall Steps per Second: 10,674.75141

Timestep Collection Time: 2.26397
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.68451

Cumulative Model Updates: 99,310
Cumulative Timesteps: 828,259,162

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 828259162...
Checkpoint 828259162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898.13971
Policy Entropy: 3.12297
Value Function Loss: 0.00488

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.57549
Value Function Update Magnitude: 0.62458

Collected Steps per Second: 22,994.36176
Overall Steps per Second: 10,849.46932

Timestep Collection Time: 2.17479
Timestep Consumption Time: 2.43446
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.60926

Cumulative Model Updates: 99,316
Cumulative Timesteps: 828,309,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 723.06861
Policy Entropy: 3.12431
Value Function Loss: 0.00493

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.58342
Value Function Update Magnitude: 0.64685

Collected Steps per Second: 23,006.91965
Overall Steps per Second: 10,821.90140

Timestep Collection Time: 2.17352
Timestep Consumption Time: 2.44729
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.62081

Cumulative Model Updates: 99,322
Cumulative Timesteps: 828,359,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 828359176...
Checkpoint 828359176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.62064
Policy Entropy: 3.13356
Value Function Loss: 0.00496

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.58839
Value Function Update Magnitude: 0.66710

Collected Steps per Second: 22,359.05414
Overall Steps per Second: 10,689.93932

Timestep Collection Time: 2.23650
Timestep Consumption Time: 2.44136
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.67786

Cumulative Model Updates: 99,328
Cumulative Timesteps: 828,409,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.57514
Policy Entropy: 3.14688
Value Function Loss: 0.00506

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.58017
Value Function Update Magnitude: 0.65275

Collected Steps per Second: 22,589.36207
Overall Steps per Second: 10,541.11263

Timestep Collection Time: 2.21449
Timestep Consumption Time: 2.53112
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.74561

Cumulative Model Updates: 99,334
Cumulative Timesteps: 828,459,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 828459206...
Checkpoint 828459206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.08902
Policy Entropy: 3.14226
Value Function Loss: 0.00507

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.58531
Value Function Update Magnitude: 0.64916

Collected Steps per Second: 22,921.81725
Overall Steps per Second: 10,665.68748

Timestep Collection Time: 2.18211
Timestep Consumption Time: 2.50750
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.68962

Cumulative Model Updates: 99,340
Cumulative Timesteps: 828,509,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.01510
Policy Entropy: 3.12366
Value Function Loss: 0.00511

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.58992
Value Function Update Magnitude: 0.64005

Collected Steps per Second: 23,081.17112
Overall Steps per Second: 10,800.61607

Timestep Collection Time: 2.16679
Timestep Consumption Time: 2.46369
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.63048

Cumulative Model Updates: 99,346
Cumulative Timesteps: 828,559,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 828559236...
Checkpoint 828559236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 490.87511
Policy Entropy: 3.12380
Value Function Loss: 0.00498

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.58590
Value Function Update Magnitude: 0.67101

Collected Steps per Second: 23,142.41275
Overall Steps per Second: 10,674.00124

Timestep Collection Time: 2.16088
Timestep Consumption Time: 2.52415
PPO Batch Consumption Time: 0.29490
Total Iteration Time: 4.68503

Cumulative Model Updates: 99,352
Cumulative Timesteps: 828,609,244

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.65933
Policy Entropy: 3.13766
Value Function Loss: 0.00520

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.12826
Policy Update Magnitude: 0.58668
Value Function Update Magnitude: 0.67789

Collected Steps per Second: 22,541.63489
Overall Steps per Second: 10,574.38727

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.51179
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.73124

Cumulative Model Updates: 99,358
Cumulative Timesteps: 828,659,274

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 828659274...
Checkpoint 828659274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.69276
Policy Entropy: 3.14637
Value Function Loss: 0.00506

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.58523
Value Function Update Magnitude: 0.66600

Collected Steps per Second: 22,785.85058
Overall Steps per Second: 10,588.62767

Timestep Collection Time: 2.19549
Timestep Consumption Time: 2.52902
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.72450

Cumulative Model Updates: 99,364
Cumulative Timesteps: 828,709,300

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.12401
Policy Entropy: 3.14303
Value Function Loss: 0.00507

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.57395
Value Function Update Magnitude: 0.64825

Collected Steps per Second: 22,967.30110
Overall Steps per Second: 10,819.94985

Timestep Collection Time: 2.17779
Timestep Consumption Time: 2.44497
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.62276

Cumulative Model Updates: 99,370
Cumulative Timesteps: 828,759,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 828759318...
Checkpoint 828759318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 715.13238
Policy Entropy: 3.14401
Value Function Loss: 0.00480

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.56255
Value Function Update Magnitude: 0.64139

Collected Steps per Second: 23,007.44270
Overall Steps per Second: 10,683.15793

Timestep Collection Time: 2.17443
Timestep Consumption Time: 2.50846
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.68289

Cumulative Model Updates: 99,376
Cumulative Timesteps: 828,809,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 891.44010
Policy Entropy: 3.15024
Value Function Loss: 0.00514

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.57264
Value Function Update Magnitude: 0.64835

Collected Steps per Second: 23,000.58555
Overall Steps per Second: 10,812.20716

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.45054
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.62440

Cumulative Model Updates: 99,382
Cumulative Timesteps: 828,859,346

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 828859346...
Checkpoint 828859346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.96593
Policy Entropy: 3.15823
Value Function Loss: 0.00491

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.13854
Policy Update Magnitude: 0.57874
Value Function Update Magnitude: 0.66744

Collected Steps per Second: 22,742.13983
Overall Steps per Second: 10,759.49084

Timestep Collection Time: 2.19979
Timestep Consumption Time: 2.44987
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.64966

Cumulative Model Updates: 99,388
Cumulative Timesteps: 828,909,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.49321
Policy Entropy: 3.16885
Value Function Loss: 0.00490

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.66907

Collected Steps per Second: 23,149.75022
Overall Steps per Second: 10,840.93257

Timestep Collection Time: 2.16011
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.61270

Cumulative Model Updates: 99,394
Cumulative Timesteps: 828,959,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 828959380...
Checkpoint 828959380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.07561
Policy Entropy: 3.16369
Value Function Loss: 0.00490

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.56438
Value Function Update Magnitude: 0.64217

Collected Steps per Second: 22,754.42584
Overall Steps per Second: 10,702.09451

Timestep Collection Time: 2.19764
Timestep Consumption Time: 2.47490
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.67254

Cumulative Model Updates: 99,400
Cumulative Timesteps: 829,009,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.27601
Policy Entropy: 3.14765
Value Function Loss: 0.00491

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.56788
Value Function Update Magnitude: 0.64641

Collected Steps per Second: 22,812.12808
Overall Steps per Second: 10,642.93759

Timestep Collection Time: 2.19296
Timestep Consumption Time: 2.50744
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.70039

Cumulative Model Updates: 99,406
Cumulative Timesteps: 829,059,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 829059412...
Checkpoint 829059412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.07956
Policy Entropy: 3.15578
Value Function Loss: 0.00488

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.56932
Value Function Update Magnitude: 0.66003

Collected Steps per Second: 22,913.92522
Overall Steps per Second: 10,864.76436

Timestep Collection Time: 2.18217
Timestep Consumption Time: 2.42005
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.60222

Cumulative Model Updates: 99,412
Cumulative Timesteps: 829,109,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.62069
Policy Entropy: 3.17540
Value Function Loss: 0.00478

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13024
Policy Update Magnitude: 0.55986
Value Function Update Magnitude: 0.66685

Collected Steps per Second: 22,799.20262
Overall Steps per Second: 10,609.52261

Timestep Collection Time: 2.19402
Timestep Consumption Time: 2.52080
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.71482

Cumulative Model Updates: 99,418
Cumulative Timesteps: 829,159,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 829159436...
Checkpoint 829159436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.74953
Policy Entropy: 3.19196
Value Function Loss: 0.00472

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10037
Policy Update Magnitude: 0.55867
Value Function Update Magnitude: 0.67065

Collected Steps per Second: 23,022.37555
Overall Steps per Second: 10,710.47362

Timestep Collection Time: 2.17276
Timestep Consumption Time: 2.49763
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.67038

Cumulative Model Updates: 99,424
Cumulative Timesteps: 829,209,458

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,457.79631
Policy Entropy: 3.19963
Value Function Loss: 0.00479

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.56104
Value Function Update Magnitude: 0.66833

Collected Steps per Second: 22,820.96981
Overall Steps per Second: 10,739.60578

Timestep Collection Time: 2.19105
Timestep Consumption Time: 2.46480
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.65585

Cumulative Model Updates: 99,430
Cumulative Timesteps: 829,259,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 829259460...
Checkpoint 829259460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.07887
Policy Entropy: 3.19202
Value Function Loss: 0.00458

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.55957
Value Function Update Magnitude: 0.64914

Collected Steps per Second: 22,731.54404
Overall Steps per Second: 10,613.99745

Timestep Collection Time: 2.20073
Timestep Consumption Time: 2.51248
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.71321

Cumulative Model Updates: 99,436
Cumulative Timesteps: 829,309,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.51447
Policy Entropy: 3.18653
Value Function Loss: 0.00449

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.54513
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 22,757.82087
Overall Steps per Second: 10,652.43638

Timestep Collection Time: 2.19757
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.69489

Cumulative Model Updates: 99,442
Cumulative Timesteps: 829,359,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 829359498...
Checkpoint 829359498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.08925
Policy Entropy: 3.18181
Value Function Loss: 0.00465

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10642
Policy Update Magnitude: 0.54795
Value Function Update Magnitude: 0.64516

Collected Steps per Second: 23,008.43311
Overall Steps per Second: 10,803.94452

Timestep Collection Time: 2.17433
Timestep Consumption Time: 2.45620
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.63053

Cumulative Model Updates: 99,448
Cumulative Timesteps: 829,409,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.81726
Policy Entropy: 3.17351
Value Function Loss: 0.00471

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.56590
Value Function Update Magnitude: 0.68056

Collected Steps per Second: 22,859.37008
Overall Steps per Second: 10,624.37468

Timestep Collection Time: 2.18799
Timestep Consumption Time: 2.51968
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.70767

Cumulative Model Updates: 99,454
Cumulative Timesteps: 829,459,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 829459542...
Checkpoint 829459542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.09738
Policy Entropy: 3.16913
Value Function Loss: 0.00466

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.68303

Collected Steps per Second: 22,889.23845
Overall Steps per Second: 10,637.14576

Timestep Collection Time: 2.18504
Timestep Consumption Time: 2.51678
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.70183

Cumulative Model Updates: 99,460
Cumulative Timesteps: 829,509,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691.77013
Policy Entropy: 3.16722
Value Function Loss: 0.00468

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.54471
Value Function Update Magnitude: 0.65505

Collected Steps per Second: 23,128.84948
Overall Steps per Second: 10,843.98590

Timestep Collection Time: 2.16180
Timestep Consumption Time: 2.44905
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.61085

Cumulative Model Updates: 99,466
Cumulative Timesteps: 829,559,556

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 829559556...
Checkpoint 829559556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.70128
Policy Entropy: 3.16572
Value Function Loss: 0.00449

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.54419
Value Function Update Magnitude: 0.61496

Collected Steps per Second: 22,301.68749
Overall Steps per Second: 10,682.26834

Timestep Collection Time: 2.24333
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.68346

Cumulative Model Updates: 99,472
Cumulative Timesteps: 829,609,586

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749.59893
Policy Entropy: 3.16748
Value Function Loss: 0.00439

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.54639
Value Function Update Magnitude: 0.60988

Collected Steps per Second: 22,200.91115
Overall Steps per Second: 10,791.49485

Timestep Collection Time: 2.25360
Timestep Consumption Time: 2.38264
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.63624

Cumulative Model Updates: 99,478
Cumulative Timesteps: 829,659,618

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 829659618...
Checkpoint 829659618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.62381
Policy Entropy: 3.17591
Value Function Loss: 0.00418

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.53782
Value Function Update Magnitude: 0.59146

Collected Steps per Second: 22,101.81747
Overall Steps per Second: 10,706.26106

Timestep Collection Time: 2.26407
Timestep Consumption Time: 2.40983
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.67390

Cumulative Model Updates: 99,484
Cumulative Timesteps: 829,709,658

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,945.69728
Policy Entropy: 3.17792
Value Function Loss: 0.00436

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10996
Policy Update Magnitude: 0.53331
Value Function Update Magnitude: 0.57629

Collected Steps per Second: 22,071.55882
Overall Steps per Second: 10,775.99166

Timestep Collection Time: 2.26536
Timestep Consumption Time: 2.37459
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.63994

Cumulative Model Updates: 99,490
Cumulative Timesteps: 829,759,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 829759658...
Checkpoint 829759658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.72338
Policy Entropy: 3.17831
Value Function Loss: 0.00466

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.53518
Value Function Update Magnitude: 0.58069

Collected Steps per Second: 21,950.90525
Overall Steps per Second: 10,739.27284

Timestep Collection Time: 2.27863
Timestep Consumption Time: 2.37885
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.65748

Cumulative Model Updates: 99,496
Cumulative Timesteps: 829,809,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.01228
Policy Entropy: 3.18209
Value Function Loss: 0.00469

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.54900
Value Function Update Magnitude: 0.59154

Collected Steps per Second: 22,017.45220
Overall Steps per Second: 10,651.79275

Timestep Collection Time: 2.27120
Timestep Consumption Time: 2.42341
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.69461

Cumulative Model Updates: 99,502
Cumulative Timesteps: 829,859,682

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 829859682...
Checkpoint 829859682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.66286
Policy Entropy: 3.20071
Value Function Loss: 0.00443

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11251
Policy Update Magnitude: 0.54560
Value Function Update Magnitude: 0.60892

Collected Steps per Second: 22,350.37066
Overall Steps per Second: 10,847.72375

Timestep Collection Time: 2.23746
Timestep Consumption Time: 2.37254
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.61000

Cumulative Model Updates: 99,508
Cumulative Timesteps: 829,909,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.56071
Policy Entropy: 3.20316
Value Function Loss: 0.00456

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.54448
Value Function Update Magnitude: 0.62062

Collected Steps per Second: 22,053.89902
Overall Steps per Second: 10,669.97202

Timestep Collection Time: 2.26717
Timestep Consumption Time: 2.41888
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.68605

Cumulative Model Updates: 99,514
Cumulative Timesteps: 829,959,690

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 829959690...
Checkpoint 829959690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.87346
Policy Entropy: 3.19042
Value Function Loss: 0.00464

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.55500
Value Function Update Magnitude: 0.62587

Collected Steps per Second: 22,066.24045
Overall Steps per Second: 10,667.73955

Timestep Collection Time: 2.26717
Timestep Consumption Time: 2.42248
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.68965

Cumulative Model Updates: 99,520
Cumulative Timesteps: 830,009,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.27599
Policy Entropy: 3.17688
Value Function Loss: 0.00462

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.11133
Policy Update Magnitude: 0.55154
Value Function Update Magnitude: 0.61702

Collected Steps per Second: 22,338.05946
Overall Steps per Second: 10,737.33886

Timestep Collection Time: 2.23833
Timestep Consumption Time: 2.41832
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.65665

Cumulative Model Updates: 99,526
Cumulative Timesteps: 830,059,718

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 830059718...
Checkpoint 830059718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.85081
Policy Entropy: 3.18009
Value Function Loss: 0.00447

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.54175
Value Function Update Magnitude: 0.59155

Collected Steps per Second: 21,971.70383
Overall Steps per Second: 10,637.50290

Timestep Collection Time: 2.27602
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.70110

Cumulative Model Updates: 99,532
Cumulative Timesteps: 830,109,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.35224
Policy Entropy: 3.18231
Value Function Loss: 0.00448

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.53839
Value Function Update Magnitude: 0.58169

Collected Steps per Second: 22,964.15319
Overall Steps per Second: 10,783.61744

Timestep Collection Time: 2.17731
Timestep Consumption Time: 2.45936
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.63666

Cumulative Model Updates: 99,538
Cumulative Timesteps: 830,159,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 830159726...
Checkpoint 830159726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.45948
Policy Entropy: 3.17627
Value Function Loss: 0.00465

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08732
Policy Update Magnitude: 0.54870
Value Function Update Magnitude: 0.59601

Collected Steps per Second: 22,755.87920
Overall Steps per Second: 10,802.20649

Timestep Collection Time: 2.19785
Timestep Consumption Time: 2.43213
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.62998

Cumulative Model Updates: 99,544
Cumulative Timesteps: 830,209,740

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 988.12122
Policy Entropy: 3.17258
Value Function Loss: 0.00453

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08892
Policy Update Magnitude: 0.55790
Value Function Update Magnitude: 0.63280

Collected Steps per Second: 22,923.88546
Overall Steps per Second: 10,777.77026

Timestep Collection Time: 2.18244
Timestep Consumption Time: 2.45952
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.64196

Cumulative Model Updates: 99,550
Cumulative Timesteps: 830,259,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 830259770...
Checkpoint 830259770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.72855
Policy Entropy: 3.17517
Value Function Loss: 0.00465

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.56443
Value Function Update Magnitude: 0.64402

Collected Steps per Second: 23,063.63451
Overall Steps per Second: 10,721.00609

Timestep Collection Time: 2.16878
Timestep Consumption Time: 2.49682
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.66561

Cumulative Model Updates: 99,556
Cumulative Timesteps: 830,309,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.17404
Policy Entropy: 3.17333
Value Function Loss: 0.00466

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 23,081.29789
Overall Steps per Second: 10,828.39846

Timestep Collection Time: 2.16695
Timestep Consumption Time: 2.45202
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.61897

Cumulative Model Updates: 99,562
Cumulative Timesteps: 830,359,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 830359806...
Checkpoint 830359806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.93018
Policy Entropy: 3.17967
Value Function Loss: 0.00471

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.56369
Value Function Update Magnitude: 0.64979

Collected Steps per Second: 22,739.35186
Overall Steps per Second: 10,688.04686

Timestep Collection Time: 2.19989
Timestep Consumption Time: 2.48048
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.68037

Cumulative Model Updates: 99,568
Cumulative Timesteps: 830,409,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.91480
Policy Entropy: 3.17576
Value Function Loss: 0.00477

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.56478
Value Function Update Magnitude: 0.66644

Collected Steps per Second: 22,797.79708
Overall Steps per Second: 10,667.71013

Timestep Collection Time: 2.19363
Timestep Consumption Time: 2.49435
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.68798

Cumulative Model Updates: 99,574
Cumulative Timesteps: 830,459,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 830459840...
Checkpoint 830459840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.13899
Policy Entropy: 3.17539
Value Function Loss: 0.00459

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.67798

Collected Steps per Second: 23,065.10310
Overall Steps per Second: 10,854.87701

Timestep Collection Time: 2.16856
Timestep Consumption Time: 2.43933
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.60788

Cumulative Model Updates: 99,580
Cumulative Timesteps: 830,509,858

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.22613
Policy Entropy: 3.17653
Value Function Loss: 0.00462

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.55825
Value Function Update Magnitude: 0.67435

Collected Steps per Second: 22,791.49012
Overall Steps per Second: 10,675.97159

Timestep Collection Time: 2.19503
Timestep Consumption Time: 2.49101
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.68604

Cumulative Model Updates: 99,586
Cumulative Timesteps: 830,559,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 830559886...
Checkpoint 830559886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.29290
Policy Entropy: 3.15946
Value Function Loss: 0.00477

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.55933
Value Function Update Magnitude: 0.67789

Collected Steps per Second: 22,880.36444
Overall Steps per Second: 10,805.57409

Timestep Collection Time: 2.18545
Timestep Consumption Time: 2.44216
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.62761

Cumulative Model Updates: 99,592
Cumulative Timesteps: 830,609,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894.77614
Policy Entropy: 3.15567
Value Function Loss: 0.00498

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10032
Policy Update Magnitude: 0.56941
Value Function Update Magnitude: 0.68332

Collected Steps per Second: 22,279.84552
Overall Steps per Second: 10,564.44489

Timestep Collection Time: 2.24454
Timestep Consumption Time: 2.48907
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.73361

Cumulative Model Updates: 99,598
Cumulative Timesteps: 830,659,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 830659898...
Checkpoint 830659898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.00063
Policy Entropy: 3.14023
Value Function Loss: 0.00473

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.57437
Value Function Update Magnitude: 0.67648

Collected Steps per Second: 22,834.05302
Overall Steps per Second: 10,642.86473

Timestep Collection Time: 2.19050
Timestep Consumption Time: 2.50917
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.69967

Cumulative Model Updates: 99,604
Cumulative Timesteps: 830,709,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.54152
Policy Entropy: 3.15026
Value Function Loss: 0.00462

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09744
Policy Update Magnitude: 0.56460
Value Function Update Magnitude: 0.64673

Collected Steps per Second: 22,837.76253
Overall Steps per Second: 10,666.93646

Timestep Collection Time: 2.19014
Timestep Consumption Time: 2.49892
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.68907

Cumulative Model Updates: 99,610
Cumulative Timesteps: 830,759,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 830759934...
Checkpoint 830759934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 943.56420
Policy Entropy: 3.14327
Value Function Loss: 0.00465

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.56540
Value Function Update Magnitude: 0.65199

Collected Steps per Second: 23,135.69527
Overall Steps per Second: 10,871.70531

Timestep Collection Time: 2.16185
Timestep Consumption Time: 2.43871
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.60057

Cumulative Model Updates: 99,616
Cumulative Timesteps: 830,809,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,781.05978
Policy Entropy: 3.15386
Value Function Loss: 0.00466

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.57410
Value Function Update Magnitude: 0.64613

Collected Steps per Second: 22,666.60106
Overall Steps per Second: 10,589.44465

Timestep Collection Time: 2.20704
Timestep Consumption Time: 2.51710
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.72414

Cumulative Model Updates: 99,622
Cumulative Timesteps: 830,859,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 830859976...
Checkpoint 830859976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.01167
Policy Entropy: 3.15908
Value Function Loss: 0.00459

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.57107
Value Function Update Magnitude: 0.62861

Collected Steps per Second: 22,999.87530
Overall Steps per Second: 10,738.65525

Timestep Collection Time: 2.17479
Timestep Consumption Time: 2.48314
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.65794

Cumulative Model Updates: 99,628
Cumulative Timesteps: 830,909,996

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.95787
Policy Entropy: 3.17584
Value Function Loss: 0.00436

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.55996
Value Function Update Magnitude: 0.61129

Collected Steps per Second: 22,852.43665
Overall Steps per Second: 10,682.19799

Timestep Collection Time: 2.18848
Timestep Consumption Time: 2.49333
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.68181

Cumulative Model Updates: 99,634
Cumulative Timesteps: 830,960,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 830960008...
Checkpoint 830960008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,925.79344
Policy Entropy: 3.17475
Value Function Loss: 0.00444

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12801
Policy Update Magnitude: 0.55079
Value Function Update Magnitude: 0.58785

Collected Steps per Second: 22,290.11405
Overall Steps per Second: 10,653.44864

Timestep Collection Time: 2.24422
Timestep Consumption Time: 2.45135
PPO Batch Consumption Time: 0.29619
Total Iteration Time: 4.69557

Cumulative Model Updates: 99,640
Cumulative Timesteps: 831,010,032

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.53737
Policy Entropy: 3.17801
Value Function Loss: 0.00474

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10916
Policy Update Magnitude: 0.55505
Value Function Update Magnitude: 0.60778

Collected Steps per Second: 22,077.77989
Overall Steps per Second: 10,689.00269

Timestep Collection Time: 2.26608
Timestep Consumption Time: 2.41443
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.68051

Cumulative Model Updates: 99,646
Cumulative Timesteps: 831,060,062

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 831060062...
Checkpoint 831060062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.32128
Policy Entropy: 3.17877
Value Function Loss: 0.00475

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.56204
Value Function Update Magnitude: 0.63730

Collected Steps per Second: 23,081.26804
Overall Steps per Second: 10,882.02206

Timestep Collection Time: 2.16626
Timestep Consumption Time: 2.42848
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.59473

Cumulative Model Updates: 99,652
Cumulative Timesteps: 831,110,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.72791
Policy Entropy: 3.17205
Value Function Loss: 0.00482

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.56336
Value Function Update Magnitude: 0.64287

Collected Steps per Second: 22,662.96807
Overall Steps per Second: 10,770.57196

Timestep Collection Time: 2.20721
Timestep Consumption Time: 2.43711
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.64432

Cumulative Model Updates: 99,658
Cumulative Timesteps: 831,160,084

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 831160084...
Checkpoint 831160084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.16270
Policy Entropy: 3.16858
Value Function Loss: 0.00445

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.56139
Value Function Update Magnitude: 0.63548

Collected Steps per Second: 22,417.11195
Overall Steps per Second: 10,653.83227

Timestep Collection Time: 2.23213
Timestep Consumption Time: 2.46458
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.69671

Cumulative Model Updates: 99,664
Cumulative Timesteps: 831,210,122

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.24850
Policy Entropy: 3.18677
Value Function Loss: 0.00446

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08386
Policy Update Magnitude: 0.55295
Value Function Update Magnitude: 0.62223

Collected Steps per Second: 22,304.75710
Overall Steps per Second: 10,526.80641

Timestep Collection Time: 2.24185
Timestep Consumption Time: 2.50830
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.75016

Cumulative Model Updates: 99,670
Cumulative Timesteps: 831,260,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 831260126...
Checkpoint 831260126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.77283
Policy Entropy: 3.18512
Value Function Loss: 0.00441

Mean KL Divergence: 0.00767
SB3 Clip Fraction: 0.08310
Policy Update Magnitude: 0.55418
Value Function Update Magnitude: 0.60926

Collected Steps per Second: 22,024.64703
Overall Steps per Second: 10,660.61224

Timestep Collection Time: 2.27091
Timestep Consumption Time: 2.42075
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.69166

Cumulative Model Updates: 99,676
Cumulative Timesteps: 831,310,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.91766
Policy Entropy: 3.18049
Value Function Loss: 0.00447

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08445
Policy Update Magnitude: 0.55587
Value Function Update Magnitude: 0.59039

Collected Steps per Second: 22,689.05504
Overall Steps per Second: 10,907.43018

Timestep Collection Time: 2.20388
Timestep Consumption Time: 2.38052
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.58440

Cumulative Model Updates: 99,682
Cumulative Timesteps: 831,360,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 831360146...
Checkpoint 831360146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,805.34905
Policy Entropy: 3.17629
Value Function Loss: 0.00418

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.55224
Value Function Update Magnitude: 0.58880

Collected Steps per Second: 21,759.67174
Overall Steps per Second: 10,639.42683

Timestep Collection Time: 2.29866
Timestep Consumption Time: 2.40254
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.70119

Cumulative Model Updates: 99,688
Cumulative Timesteps: 831,410,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.36593
Policy Entropy: 3.18067
Value Function Loss: 0.00413

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08400
Policy Update Magnitude: 0.54330
Value Function Update Magnitude: 0.58047

Collected Steps per Second: 22,253.51068
Overall Steps per Second: 10,808.73024

Timestep Collection Time: 2.24818
Timestep Consumption Time: 2.38048
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.62867

Cumulative Model Updates: 99,694
Cumulative Timesteps: 831,460,194

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 831460194...
Checkpoint 831460194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.88876
Policy Entropy: 3.17947
Value Function Loss: 0.00419

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.53819
Value Function Update Magnitude: 0.57180

Collected Steps per Second: 22,213.70517
Overall Steps per Second: 10,761.52838

Timestep Collection Time: 2.25221
Timestep Consumption Time: 2.39675
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.64897

Cumulative Model Updates: 99,700
Cumulative Timesteps: 831,510,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.67358
Policy Entropy: 3.17068
Value Function Loss: 0.00461

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08987
Policy Update Magnitude: 0.54654
Value Function Update Magnitude: 0.57648

Collected Steps per Second: 22,300.99294
Overall Steps per Second: 10,824.18773

Timestep Collection Time: 2.24223
Timestep Consumption Time: 2.37742
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.61965

Cumulative Model Updates: 99,706
Cumulative Timesteps: 831,560,228

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 831560228...
Checkpoint 831560228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 850.28838
Policy Entropy: 3.18015
Value Function Loss: 0.00464

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.55285
Value Function Update Magnitude: 0.59080

Collected Steps per Second: 22,140.44613
Overall Steps per Second: 10,671.10235

Timestep Collection Time: 2.25939
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.68780

Cumulative Model Updates: 99,712
Cumulative Timesteps: 831,610,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.93245
Policy Entropy: 3.17247
Value Function Loss: 0.00476

Mean KL Divergence: 0.00761
SB3 Clip Fraction: 0.08100
Policy Update Magnitude: 0.55744
Value Function Update Magnitude: 0.61412

Collected Steps per Second: 21,956.09150
Overall Steps per Second: 10,631.21935

Timestep Collection Time: 2.27773
Timestep Consumption Time: 2.42634
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.70407

Cumulative Model Updates: 99,718
Cumulative Timesteps: 831,660,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 831660262...
Checkpoint 831660262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925.48814
Policy Entropy: 3.17411
Value Function Loss: 0.00470

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08583
Policy Update Magnitude: 0.55967
Value Function Update Magnitude: 0.61290

Collected Steps per Second: 23,070.94856
Overall Steps per Second: 10,866.09119

Timestep Collection Time: 2.16844
Timestep Consumption Time: 2.43561
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.60405

Cumulative Model Updates: 99,724
Cumulative Timesteps: 831,710,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,803.47234
Policy Entropy: 3.15972
Value Function Loss: 0.00454

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.60969

Collected Steps per Second: 22,146.44966
Overall Steps per Second: 10,602.55966

Timestep Collection Time: 2.25860
Timestep Consumption Time: 2.45913
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.71773

Cumulative Model Updates: 99,730
Cumulative Timesteps: 831,760,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 831760310...
Checkpoint 831760310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.22788
Policy Entropy: 3.16246
Value Function Loss: 0.00467

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08961
Policy Update Magnitude: 0.55994
Value Function Update Magnitude: 0.62096

Collected Steps per Second: 22,126.51902
Overall Steps per Second: 10,609.90992

Timestep Collection Time: 2.26109
Timestep Consumption Time: 2.45432
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.71540

Cumulative Model Updates: 99,736
Cumulative Timesteps: 831,810,340

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.35289
Policy Entropy: 3.15735
Value Function Loss: 0.00451

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.55755
Value Function Update Magnitude: 0.62911

Collected Steps per Second: 22,354.10717
Overall Steps per Second: 10,832.53708

Timestep Collection Time: 2.23681
Timestep Consumption Time: 2.37909
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.61591

Cumulative Model Updates: 99,742
Cumulative Timesteps: 831,860,342

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 831860342...
Checkpoint 831860342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.15038
Policy Entropy: 3.15173
Value Function Loss: 0.00476

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09123
Policy Update Magnitude: 0.56655
Value Function Update Magnitude: 0.64741

Collected Steps per Second: 22,017.28414
Overall Steps per Second: 10,686.77689

Timestep Collection Time: 2.27185
Timestep Consumption Time: 2.40870
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.68055

Cumulative Model Updates: 99,748
Cumulative Timesteps: 831,910,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.69190
Policy Entropy: 3.15546
Value Function Loss: 0.00481

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.57369
Value Function Update Magnitude: 0.63605

Collected Steps per Second: 22,994.77065
Overall Steps per Second: 10,810.25945

Timestep Collection Time: 2.17449
Timestep Consumption Time: 2.45093
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.62542

Cumulative Model Updates: 99,754
Cumulative Timesteps: 831,960,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 831960364...
Checkpoint 831960364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.24985
Policy Entropy: 3.15682
Value Function Loss: 0.00485

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.58021
Value Function Update Magnitude: 0.64288

Collected Steps per Second: 22,553.97888
Overall Steps per Second: 10,770.55080

Timestep Collection Time: 2.21815
Timestep Consumption Time: 2.42674
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.64489

Cumulative Model Updates: 99,760
Cumulative Timesteps: 832,010,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677.84172
Policy Entropy: 3.15161
Value Function Loss: 0.00487

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.64523

Collected Steps per Second: 22,710.03582
Overall Steps per Second: 10,626.81666

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.70621

Cumulative Model Updates: 99,766
Cumulative Timesteps: 832,060,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 832060404...
Checkpoint 832060404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.27999
Policy Entropy: 3.14636
Value Function Loss: 0.00471

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09579
Policy Update Magnitude: 0.57765
Value Function Update Magnitude: 0.64253

Collected Steps per Second: 23,025.44831
Overall Steps per Second: 10,848.99458

Timestep Collection Time: 2.17168
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.60909

Cumulative Model Updates: 99,772
Cumulative Timesteps: 832,110,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,441.70336
Policy Entropy: 3.14108
Value Function Loss: 0.00475

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.58156
Value Function Update Magnitude: 0.63702

Collected Steps per Second: 23,000.33346
Overall Steps per Second: 10,697.31491

Timestep Collection Time: 2.17510
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.67669

Cumulative Model Updates: 99,778
Cumulative Timesteps: 832,160,436

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 832160436...
Checkpoint 832160436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.28352
Policy Entropy: 3.15532
Value Function Loss: 0.00481

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09717
Policy Update Magnitude: 0.58870
Value Function Update Magnitude: 0.64480

Collected Steps per Second: 23,109.22953
Overall Steps per Second: 10,849.35637

Timestep Collection Time: 2.16442
Timestep Consumption Time: 2.44581
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.61023

Cumulative Model Updates: 99,784
Cumulative Timesteps: 832,210,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.13109
Policy Entropy: 3.17735
Value Function Loss: 0.00452

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.58130
Value Function Update Magnitude: 0.65756

Collected Steps per Second: 22,607.53628
Overall Steps per Second: 10,572.29555

Timestep Collection Time: 2.21289
Timestep Consumption Time: 2.51910
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.73199

Cumulative Model Updates: 99,790
Cumulative Timesteps: 832,260,482

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 832260482...
Checkpoint 832260482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.78053
Policy Entropy: 3.19976
Value Function Loss: 0.00453

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08409
Policy Update Magnitude: 0.56856
Value Function Update Magnitude: 0.64708

Collected Steps per Second: 22,979.27009
Overall Steps per Second: 10,681.30871

Timestep Collection Time: 2.17622
Timestep Consumption Time: 2.50560
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.68182

Cumulative Model Updates: 99,796
Cumulative Timesteps: 832,310,490

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.74918
Policy Entropy: 3.18004
Value Function Loss: 0.00454

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.55866
Value Function Update Magnitude: 0.63718

Collected Steps per Second: 23,034.76990
Overall Steps per Second: 10,853.14991

Timestep Collection Time: 2.17089
Timestep Consumption Time: 2.43662
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.60751

Cumulative Model Updates: 99,802
Cumulative Timesteps: 832,360,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 832360496...
Checkpoint 832360496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.75830
Policy Entropy: 3.17468
Value Function Loss: 0.00462

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.63404

Collected Steps per Second: 22,716.79370
Overall Steps per Second: 10,571.85741

Timestep Collection Time: 2.20137
Timestep Consumption Time: 2.52893
PPO Batch Consumption Time: 0.29756
Total Iteration Time: 4.73029

Cumulative Model Updates: 99,808
Cumulative Timesteps: 832,410,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.86148
Policy Entropy: 3.16438
Value Function Loss: 0.00465

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.56340
Value Function Update Magnitude: 0.63534

Collected Steps per Second: 22,989.61189
Overall Steps per Second: 10,810.62110

Timestep Collection Time: 2.17594
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.62730

Cumulative Model Updates: 99,814
Cumulative Timesteps: 832,460,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 832460528...
Checkpoint 832460528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.20654
Policy Entropy: 3.18270
Value Function Loss: 0.00460

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.56636
Value Function Update Magnitude: 0.64097

Collected Steps per Second: 22,656.03224
Overall Steps per Second: 10,716.68145

Timestep Collection Time: 2.20754
Timestep Consumption Time: 2.45939
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.66693

Cumulative Model Updates: 99,820
Cumulative Timesteps: 832,510,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.18248
Policy Entropy: 3.18317
Value Function Loss: 0.00473

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.57364
Value Function Update Magnitude: 0.65056

Collected Steps per Second: 23,093.80234
Overall Steps per Second: 10,809.60763

Timestep Collection Time: 2.16638
Timestep Consumption Time: 2.46191
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.62829

Cumulative Model Updates: 99,826
Cumulative Timesteps: 832,560,572

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 832560572...
Checkpoint 832560572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.74292
Policy Entropy: 3.16708
Value Function Loss: 0.00467

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.57683
Value Function Update Magnitude: 0.63530

Collected Steps per Second: 22,585.12299
Overall Steps per Second: 10,730.23775

Timestep Collection Time: 2.21385
Timestep Consumption Time: 2.44588
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.65973

Cumulative Model Updates: 99,832
Cumulative Timesteps: 832,610,572

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.67418
Policy Entropy: 3.17534
Value Function Loss: 0.00463

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.56697
Value Function Update Magnitude: 0.62462

Collected Steps per Second: 23,260.88043
Overall Steps per Second: 10,874.89252

Timestep Collection Time: 2.15048
Timestep Consumption Time: 2.44929
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.59977

Cumulative Model Updates: 99,838
Cumulative Timesteps: 832,660,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 832660594...
Checkpoint 832660594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.77531
Policy Entropy: 3.17367
Value Function Loss: 0.00473

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.55724
Value Function Update Magnitude: 0.61514

Collected Steps per Second: 22,740.33860
Overall Steps per Second: 10,720.76279

Timestep Collection Time: 2.19882
Timestep Consumption Time: 2.46521
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.66403

Cumulative Model Updates: 99,844
Cumulative Timesteps: 832,710,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.47573
Policy Entropy: 3.15891
Value Function Loss: 0.00493

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10044
Policy Update Magnitude: 0.56172
Value Function Update Magnitude: 0.60681

Collected Steps per Second: 23,094.15515
Overall Steps per Second: 10,827.03426

Timestep Collection Time: 2.16618
Timestep Consumption Time: 2.45430
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.62047

Cumulative Model Updates: 99,850
Cumulative Timesteps: 832,760,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 832760622...
Checkpoint 832760622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.59511
Policy Entropy: 3.15309
Value Function Loss: 0.00504

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.57589
Value Function Update Magnitude: 0.60823

Collected Steps per Second: 22,508.38428
Overall Steps per Second: 10,712.86151

Timestep Collection Time: 2.22211
Timestep Consumption Time: 2.44668
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.66878

Cumulative Model Updates: 99,856
Cumulative Timesteps: 832,810,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.38655
Policy Entropy: 3.14653
Value Function Loss: 0.00496

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10152
Policy Update Magnitude: 0.58162
Value Function Update Magnitude: 0.62649

Collected Steps per Second: 22,988.47934
Overall Steps per Second: 10,828.31806

Timestep Collection Time: 2.17613
Timestep Consumption Time: 2.44379
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.61992

Cumulative Model Updates: 99,862
Cumulative Timesteps: 832,860,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 832860664...
Checkpoint 832860664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.65262
Policy Entropy: 3.16207
Value Function Loss: 0.00486

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.58016
Value Function Update Magnitude: 0.63846

Collected Steps per Second: 22,807.13027
Overall Steps per Second: 10,717.09480

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.47384
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.66675

Cumulative Model Updates: 99,868
Cumulative Timesteps: 832,910,678

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.87447
Policy Entropy: 3.15878
Value Function Loss: 0.00475

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.58020
Value Function Update Magnitude: 0.63334

Collected Steps per Second: 22,984.04020
Overall Steps per Second: 10,820.87324

Timestep Collection Time: 2.17708
Timestep Consumption Time: 2.44714
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.62421

Cumulative Model Updates: 99,874
Cumulative Timesteps: 832,960,716

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 832960716...
Checkpoint 832960716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 670.04191
Policy Entropy: 3.14816
Value Function Loss: 0.00482

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.58076
Value Function Update Magnitude: 0.61688

Collected Steps per Second: 22,358.16483
Overall Steps per Second: 10,645.58376

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.46046
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.69678

Cumulative Model Updates: 99,880
Cumulative Timesteps: 833,010,716

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.48741
Policy Entropy: 3.13883
Value Function Loss: 0.00489

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.58135
Value Function Update Magnitude: 0.61268

Collected Steps per Second: 22,947.34259
Overall Steps per Second: 10,689.74628

Timestep Collection Time: 2.18056
Timestep Consumption Time: 2.50038
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.68093

Cumulative Model Updates: 99,886
Cumulative Timesteps: 833,060,754

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 833060754...
Checkpoint 833060754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.84714
Policy Entropy: 3.14653
Value Function Loss: 0.00480

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.57654
Value Function Update Magnitude: 0.61925

Collected Steps per Second: 22,694.33533
Overall Steps per Second: 10,611.67580

Timestep Collection Time: 2.20425
Timestep Consumption Time: 2.50980
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.71405

Cumulative Model Updates: 99,892
Cumulative Timesteps: 833,110,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.61280
Policy Entropy: 3.15404
Value Function Loss: 0.00486

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08311
Policy Update Magnitude: 0.57469
Value Function Update Magnitude: 0.62229

Collected Steps per Second: 23,232.53008
Overall Steps per Second: 10,772.95813

Timestep Collection Time: 2.15310
Timestep Consumption Time: 2.49019
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.64329

Cumulative Model Updates: 99,898
Cumulative Timesteps: 833,160,800

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 833160800...
Checkpoint 833160800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.45658
Policy Entropy: 3.16533
Value Function Loss: 0.00482

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08768
Policy Update Magnitude: 0.57913
Value Function Update Magnitude: 0.63363

Collected Steps per Second: 22,452.75010
Overall Steps per Second: 10,690.63970

Timestep Collection Time: 2.22690
Timestep Consumption Time: 2.45009
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.67699

Cumulative Model Updates: 99,904
Cumulative Timesteps: 833,210,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 833.28819
Policy Entropy: 3.15799
Value Function Loss: 0.00511

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08966
Policy Update Magnitude: 0.57454
Value Function Update Magnitude: 0.63242

Collected Steps per Second: 23,233.10602
Overall Steps per Second: 10,844.16206

Timestep Collection Time: 2.15210
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.61078

Cumulative Model Updates: 99,910
Cumulative Timesteps: 833,260,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 833260800...
Checkpoint 833260800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938.96065
Policy Entropy: 3.13788
Value Function Loss: 0.00493

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.58120
Value Function Update Magnitude: 0.63105

Collected Steps per Second: 22,695.44393
Overall Steps per Second: 10,704.72937

Timestep Collection Time: 2.20441
Timestep Consumption Time: 2.46923
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.67364

Cumulative Model Updates: 99,916
Cumulative Timesteps: 833,310,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 698.84227
Policy Entropy: 3.14411
Value Function Loss: 0.00496

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.58108
Value Function Update Magnitude: 0.60750

Collected Steps per Second: 23,174.38472
Overall Steps per Second: 10,867.63227

Timestep Collection Time: 2.15816
Timestep Consumption Time: 2.44395
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.60211

Cumulative Model Updates: 99,922
Cumulative Timesteps: 833,360,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 833360844...
Checkpoint 833360844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,722.23322
Policy Entropy: 3.15119
Value Function Loss: 0.00473

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.60083

Collected Steps per Second: 22,740.87416
Overall Steps per Second: 10,645.42129

Timestep Collection Time: 2.19930
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.69817

Cumulative Model Updates: 99,928
Cumulative Timesteps: 833,410,858

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.32394
Policy Entropy: 3.14258
Value Function Loss: 0.00484

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.57079
Value Function Update Magnitude: 0.61226

Collected Steps per Second: 23,005.04942
Overall Steps per Second: 10,814.38229

Timestep Collection Time: 2.17370
Timestep Consumption Time: 2.45033
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.62403

Cumulative Model Updates: 99,934
Cumulative Timesteps: 833,460,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 833460864...
Checkpoint 833460864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.31201
Policy Entropy: 3.13603
Value Function Loss: 0.00457

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.56692
Value Function Update Magnitude: 0.62047

Collected Steps per Second: 22,695.88109
Overall Steps per Second: 10,800.01183

Timestep Collection Time: 2.20340
Timestep Consumption Time: 2.42697
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.63037

Cumulative Model Updates: 99,940
Cumulative Timesteps: 833,510,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.38886
Policy Entropy: 3.13056
Value Function Loss: 0.00482

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.56897
Value Function Update Magnitude: 0.61630

Collected Steps per Second: 22,833.01963
Overall Steps per Second: 10,773.11271

Timestep Collection Time: 2.18990
Timestep Consumption Time: 2.45147
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.64137

Cumulative Model Updates: 99,946
Cumulative Timesteps: 833,560,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 833560874...
Checkpoint 833560874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.75949
Policy Entropy: 3.14641
Value Function Loss: 0.00484

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.60900

Collected Steps per Second: 22,506.99175
Overall Steps per Second: 10,671.81087

Timestep Collection Time: 2.22198
Timestep Consumption Time: 2.46420
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.68618

Cumulative Model Updates: 99,952
Cumulative Timesteps: 833,610,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 865.61121
Policy Entropy: 3.15353
Value Function Loss: 0.00477

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.56221
Value Function Update Magnitude: 0.61004

Collected Steps per Second: 22,840.53725
Overall Steps per Second: 10,687.43953

Timestep Collection Time: 2.18997
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.68026

Cumulative Model Updates: 99,958
Cumulative Timesteps: 833,660,904

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 833660904...
Checkpoint 833660904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.23117
Policy Entropy: 3.15648
Value Function Loss: 0.00452

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09898
Policy Update Magnitude: 0.55947
Value Function Update Magnitude: 0.60925

Collected Steps per Second: 22,867.77182
Overall Steps per Second: 10,791.78551

Timestep Collection Time: 2.18745
Timestep Consumption Time: 2.44775
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.63519

Cumulative Model Updates: 99,964
Cumulative Timesteps: 833,710,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.66184
Policy Entropy: 3.14659
Value Function Loss: 0.00453

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.55906
Value Function Update Magnitude: 0.61878

Collected Steps per Second: 23,297.07336
Overall Steps per Second: 10,757.83507

Timestep Collection Time: 2.14705
Timestep Consumption Time: 2.50258
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.64963

Cumulative Model Updates: 99,970
Cumulative Timesteps: 833,760,946

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 833760946...
Checkpoint 833760946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.84999
Policy Entropy: 3.15973
Value Function Loss: 0.00468

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09315
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.63435

Collected Steps per Second: 22,658.13296
Overall Steps per Second: 10,636.75061

Timestep Collection Time: 2.20742
Timestep Consumption Time: 2.49477
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.70219

Cumulative Model Updates: 99,976
Cumulative Timesteps: 833,810,962

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.73287
Policy Entropy: 3.15198
Value Function Loss: 0.00493

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08818
Policy Update Magnitude: 0.58064
Value Function Update Magnitude: 0.64017

Collected Steps per Second: 23,186.89484
Overall Steps per Second: 10,710.66668

Timestep Collection Time: 2.15699
Timestep Consumption Time: 2.51256
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.66955

Cumulative Model Updates: 99,982
Cumulative Timesteps: 833,860,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 833860976...
Checkpoint 833860976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.69184
Policy Entropy: 3.16332
Value Function Loss: 0.00498

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.58084
Value Function Update Magnitude: 0.63693

Collected Steps per Second: 22,588.49744
Overall Steps per Second: 10,673.79420

Timestep Collection Time: 2.21378
Timestep Consumption Time: 2.47115
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.68493

Cumulative Model Updates: 99,988
Cumulative Timesteps: 833,910,982

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.72751
Policy Entropy: 3.15811
Value Function Loss: 0.00498

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10639
Policy Update Magnitude: 0.58160
Value Function Update Magnitude: 0.64042

Collected Steps per Second: 23,171.41030
Overall Steps per Second: 10,810.75614

Timestep Collection Time: 2.15887
Timestep Consumption Time: 2.46838
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.62724

Cumulative Model Updates: 99,994
Cumulative Timesteps: 833,961,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 833961006...
Checkpoint 833961006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.30562
Policy Entropy: 3.17343
Value Function Loss: 0.00464

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.58147
Value Function Update Magnitude: 0.66517

Collected Steps per Second: 22,509.66216
Overall Steps per Second: 10,745.06962

Timestep Collection Time: 2.22189
Timestep Consumption Time: 2.43271
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.65460

Cumulative Model Updates: 100,000
Cumulative Timesteps: 834,011,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.03627
Policy Entropy: 3.18399
Value Function Loss: 0.00436

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.56903
Value Function Update Magnitude: 0.64764

Collected Steps per Second: 23,248.21834
Overall Steps per Second: 10,824.72479

Timestep Collection Time: 2.15087
Timestep Consumption Time: 2.46855
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.61942

Cumulative Model Updates: 100,006
Cumulative Timesteps: 834,061,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 834061024...
Checkpoint 834061024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,738.07006
Policy Entropy: 3.18592
Value Function Loss: 0.00431

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08690
Policy Update Magnitude: 0.55662
Value Function Update Magnitude: 0.63062

Collected Steps per Second: 22,886.79165
Overall Steps per Second: 10,698.10035

Timestep Collection Time: 2.18528
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.67504

Cumulative Model Updates: 100,012
Cumulative Timesteps: 834,111,038

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620.23726
Policy Entropy: 3.18513
Value Function Loss: 0.00461

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.56195
Value Function Update Magnitude: 0.60029

Collected Steps per Second: 23,159.60282
Overall Steps per Second: 10,865.10705

Timestep Collection Time: 2.15988
Timestep Consumption Time: 2.44403
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.60391

Cumulative Model Updates: 100,018
Cumulative Timesteps: 834,161,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 834161060...
Checkpoint 834161060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.64439
Policy Entropy: 3.16931
Value Function Loss: 0.00468

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.56433
Value Function Update Magnitude: 0.59913

Collected Steps per Second: 22,360.18480
Overall Steps per Second: 10,667.99799

Timestep Collection Time: 2.23656
Timestep Consumption Time: 2.45129
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.68785

Cumulative Model Updates: 100,024
Cumulative Timesteps: 834,211,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.78062
Policy Entropy: 3.16666
Value Function Loss: 0.00490

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10029
Policy Update Magnitude: 0.56999
Value Function Update Magnitude: 0.58479

Collected Steps per Second: 22,734.94320
Overall Steps per Second: 10,674.89819

Timestep Collection Time: 2.19970
Timestep Consumption Time: 2.48512
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.68482

Cumulative Model Updates: 100,030
Cumulative Timesteps: 834,261,080

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 834261080...
Checkpoint 834261080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.33454
Policy Entropy: 3.15802
Value Function Loss: 0.00477

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.57065
Value Function Update Magnitude: 0.59501

Collected Steps per Second: 22,827.65051
Overall Steps per Second: 10,791.60228

Timestep Collection Time: 2.19129
Timestep Consumption Time: 2.44398
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.63527

Cumulative Model Updates: 100,036
Cumulative Timesteps: 834,311,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.14472
Policy Entropy: 3.17058
Value Function Loss: 0.00455

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.56301
Value Function Update Magnitude: 0.59230

Collected Steps per Second: 23,021.61744
Overall Steps per Second: 10,671.70248

Timestep Collection Time: 2.17231
Timestep Consumption Time: 2.51392
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.68623

Cumulative Model Updates: 100,042
Cumulative Timesteps: 834,361,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 834361112...
Checkpoint 834361112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,944.17176
Policy Entropy: 3.17411
Value Function Loss: 0.00450

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11153
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.58103

Collected Steps per Second: 22,644.12714
Overall Steps per Second: 10,595.85782

Timestep Collection Time: 2.20905
Timestep Consumption Time: 2.51185
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.72090

Cumulative Model Updates: 100,048
Cumulative Timesteps: 834,411,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.03852
Policy Entropy: 3.16025
Value Function Loss: 0.00462

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11722
Policy Update Magnitude: 0.56520
Value Function Update Magnitude: 0.58420

Collected Steps per Second: 23,037.45463
Overall Steps per Second: 10,844.96049

Timestep Collection Time: 2.17116
Timestep Consumption Time: 2.44094
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.61210

Cumulative Model Updates: 100,054
Cumulative Timesteps: 834,461,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 834461152...
Checkpoint 834461152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.66656
Policy Entropy: 3.16448
Value Function Loss: 0.00437

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11804
Policy Update Magnitude: 0.56281
Value Function Update Magnitude: 0.58276

Collected Steps per Second: 22,358.37694
Overall Steps per Second: 10,636.75083

Timestep Collection Time: 2.23701
Timestep Consumption Time: 2.46517
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.70219

Cumulative Model Updates: 100,060
Cumulative Timesteps: 834,511,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 739.74414
Policy Entropy: 3.16354
Value Function Loss: 0.00436

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.57406

Collected Steps per Second: 22,894.28969
Overall Steps per Second: 10,774.54405

Timestep Collection Time: 2.18395
Timestep Consumption Time: 2.45662
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.64057

Cumulative Model Updates: 100,066
Cumulative Timesteps: 834,561,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 834561168...
Checkpoint 834561168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.57329
Policy Entropy: 3.17848
Value Function Loss: 0.00447

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.55458
Value Function Update Magnitude: 0.58682

Collected Steps per Second: 22,419.09323
Overall Steps per Second: 10,696.10696

Timestep Collection Time: 2.23069
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.67553

Cumulative Model Updates: 100,072
Cumulative Timesteps: 834,611,178

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 835.64517
Policy Entropy: 3.16224
Value Function Loss: 0.00473

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.56103
Value Function Update Magnitude: 0.61605

Collected Steps per Second: 22,922.79527
Overall Steps per Second: 10,659.68428

Timestep Collection Time: 2.18185
Timestep Consumption Time: 2.51004
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.69188

Cumulative Model Updates: 100,078
Cumulative Timesteps: 834,661,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 834661192...
Checkpoint 834661192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.32665
Policy Entropy: 3.15917
Value Function Loss: 0.00480

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.57070
Value Function Update Magnitude: 0.63407

Collected Steps per Second: 23,050.47210
Overall Steps per Second: 10,839.08356

Timestep Collection Time: 2.16959
Timestep Consumption Time: 2.44427
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.61386

Cumulative Model Updates: 100,084
Cumulative Timesteps: 834,711,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.58691
Policy Entropy: 3.14618
Value Function Loss: 0.00499

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11266
Policy Update Magnitude: 0.58372
Value Function Update Magnitude: 0.64654

Collected Steps per Second: 22,909.94180
Overall Steps per Second: 10,663.82900

Timestep Collection Time: 2.18359
Timestep Consumption Time: 2.50759
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.69119

Cumulative Model Updates: 100,090
Cumulative Timesteps: 834,761,228

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 834761228...
Checkpoint 834761228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.47656
Policy Entropy: 3.14584
Value Function Loss: 0.00486

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10553
Policy Update Magnitude: 0.58466
Value Function Update Magnitude: 0.64507

Collected Steps per Second: 22,726.94023
Overall Steps per Second: 10,599.13259

Timestep Collection Time: 2.20100
Timestep Consumption Time: 2.51844
PPO Batch Consumption Time: 0.29585
Total Iteration Time: 4.71944

Cumulative Model Updates: 100,096
Cumulative Timesteps: 834,811,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.09879
Policy Entropy: 3.14691
Value Function Loss: 0.00479

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10781
Policy Update Magnitude: 0.57622
Value Function Update Magnitude: 0.62886

Collected Steps per Second: 22,926.18040
Overall Steps per Second: 10,604.30446

Timestep Collection Time: 2.18309
Timestep Consumption Time: 2.53669
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.71978

Cumulative Model Updates: 100,102
Cumulative Timesteps: 834,861,300

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 834861300...
Checkpoint 834861300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758.38699
Policy Entropy: 3.16292
Value Function Loss: 0.00476

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.56473
Value Function Update Magnitude: 0.61134

Collected Steps per Second: 22,853.10055
Overall Steps per Second: 10,693.00949

Timestep Collection Time: 2.18885
Timestep Consumption Time: 2.48916
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.67801

Cumulative Model Updates: 100,108
Cumulative Timesteps: 834,911,322

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.60911
Policy Entropy: 3.16451
Value Function Loss: 0.00464

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.55905
Value Function Update Magnitude: 0.61472

Collected Steps per Second: 22,751.60393
Overall Steps per Second: 10,810.37197

Timestep Collection Time: 2.19826
Timestep Consumption Time: 2.42822
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.62648

Cumulative Model Updates: 100,114
Cumulative Timesteps: 834,961,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 834961336...
Checkpoint 834961336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.09499
Policy Entropy: 3.17635
Value Function Loss: 0.00465

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.56031
Value Function Update Magnitude: 0.60721

Collected Steps per Second: 22,697.41715
Overall Steps per Second: 10,597.53168

Timestep Collection Time: 2.20333
Timestep Consumption Time: 2.51569
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.71902

Cumulative Model Updates: 100,120
Cumulative Timesteps: 835,011,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.83720
Policy Entropy: 3.15841
Value Function Loss: 0.00491

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.56540
Value Function Update Magnitude: 0.62302

Collected Steps per Second: 23,171.08662
Overall Steps per Second: 10,816.31707

Timestep Collection Time: 2.15855
Timestep Consumption Time: 2.46557
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.62412

Cumulative Model Updates: 100,126
Cumulative Timesteps: 835,061,362

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 835061362...
Checkpoint 835061362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 812.54987
Policy Entropy: 3.14393
Value Function Loss: 0.00487

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.57601
Value Function Update Magnitude: 0.65489

Collected Steps per Second: 22,466.62987
Overall Steps per Second: 10,649.75266

Timestep Collection Time: 2.22624
Timestep Consumption Time: 2.47021
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.69645

Cumulative Model Updates: 100,132
Cumulative Timesteps: 835,111,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.01757
Policy Entropy: 3.12585
Value Function Loss: 0.00498

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.58900
Value Function Update Magnitude: 0.67132

Collected Steps per Second: 22,739.08152
Overall Steps per Second: 10,736.23388

Timestep Collection Time: 2.19982
Timestep Consumption Time: 2.45935
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.65918

Cumulative Model Updates: 100,138
Cumulative Timesteps: 835,161,400

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 835161400...
Checkpoint 835161400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.49188
Policy Entropy: 3.13415
Value Function Loss: 0.00476

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.08940
Policy Update Magnitude: 0.59044
Value Function Update Magnitude: 0.67101

Collected Steps per Second: 22,733.79472
Overall Steps per Second: 10,801.44311

Timestep Collection Time: 2.20025
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.63086

Cumulative Model Updates: 100,144
Cumulative Timesteps: 835,211,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.86924
Policy Entropy: 3.13404
Value Function Loss: 0.00472

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.57987
Value Function Update Magnitude: 0.65698

Collected Steps per Second: 23,162.62949
Overall Steps per Second: 10,840.76100

Timestep Collection Time: 2.15891
Timestep Consumption Time: 2.45387
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.61278

Cumulative Model Updates: 100,150
Cumulative Timesteps: 835,261,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 835261426...
Checkpoint 835261426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.97749
Policy Entropy: 3.14496
Value Function Loss: 0.00498

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.66000

Collected Steps per Second: 22,843.40713
Overall Steps per Second: 10,680.33540

Timestep Collection Time: 2.18908
Timestep Consumption Time: 2.49298
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.68206

Cumulative Model Updates: 100,156
Cumulative Timesteps: 835,311,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,465.82587
Policy Entropy: 3.13630
Value Function Loss: 0.00484

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.58427
Value Function Update Magnitude: 0.69677

Collected Steps per Second: 22,851.72420
Overall Steps per Second: 10,672.05836

Timestep Collection Time: 2.18968
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.68869

Cumulative Model Updates: 100,162
Cumulative Timesteps: 835,361,470

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 835361470...
Checkpoint 835361470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.78456
Policy Entropy: 3.12941
Value Function Loss: 0.00474

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.69667

Collected Steps per Second: 22,518.04189
Overall Steps per Second: 10,589.20110

Timestep Collection Time: 2.22177
Timestep Consumption Time: 2.50285
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.72462

Cumulative Model Updates: 100,168
Cumulative Timesteps: 835,411,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.63998
Policy Entropy: 3.12526
Value Function Loss: 0.00454

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.56458
Value Function Update Magnitude: 0.66895

Collected Steps per Second: 23,180.43891
Overall Steps per Second: 10,787.56982

Timestep Collection Time: 2.15734
Timestep Consumption Time: 2.47837
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.63571

Cumulative Model Updates: 100,174
Cumulative Timesteps: 835,461,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 835461508...
Checkpoint 835461508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,419.51564
Policy Entropy: 3.12061
Value Function Loss: 0.00449

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08898
Policy Update Magnitude: 0.56228
Value Function Update Magnitude: 0.64869

Collected Steps per Second: 22,574.54796
Overall Steps per Second: 10,624.74530

Timestep Collection Time: 2.21630
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.70901

Cumulative Model Updates: 100,180
Cumulative Timesteps: 835,511,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.84333
Policy Entropy: 3.13256
Value Function Loss: 0.00443

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08802
Policy Update Magnitude: 0.55990
Value Function Update Magnitude: 0.63306

Collected Steps per Second: 23,189.08644
Overall Steps per Second: 10,831.57296

Timestep Collection Time: 2.15653
Timestep Consumption Time: 2.46034
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.61687

Cumulative Model Updates: 100,186
Cumulative Timesteps: 835,561,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 835561548...
Checkpoint 835561548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.02885
Policy Entropy: 3.13170
Value Function Loss: 0.00463

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.56623
Value Function Update Magnitude: 0.61603

Collected Steps per Second: 22,344.82592
Overall Steps per Second: 10,660.06375

Timestep Collection Time: 2.23783
Timestep Consumption Time: 2.45295
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.69078

Cumulative Model Updates: 100,192
Cumulative Timesteps: 835,611,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.92167
Policy Entropy: 3.14968
Value Function Loss: 0.00468

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.56902
Value Function Update Magnitude: 0.60503

Collected Steps per Second: 22,919.75309
Overall Steps per Second: 10,661.56237

Timestep Collection Time: 2.18214
Timestep Consumption Time: 2.50892
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.69106

Cumulative Model Updates: 100,198
Cumulative Timesteps: 835,661,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 835661566...
Checkpoint 835661566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.46822
Policy Entropy: 3.13682
Value Function Loss: 0.00481

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09728
Policy Update Magnitude: 0.56163
Value Function Update Magnitude: 0.61912

Collected Steps per Second: 23,074.10145
Overall Steps per Second: 10,871.34145

Timestep Collection Time: 2.16815
Timestep Consumption Time: 2.43368
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.60182

Cumulative Model Updates: 100,204
Cumulative Timesteps: 835,711,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.54590
Policy Entropy: 3.12126
Value Function Loss: 0.00469

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.08194
Policy Update Magnitude: 0.56182
Value Function Update Magnitude: 0.62723

Collected Steps per Second: 22,273.85194
Overall Steps per Second: 10,705.02349

Timestep Collection Time: 2.24487
Timestep Consumption Time: 2.42602
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.67089

Cumulative Model Updates: 100,210
Cumulative Timesteps: 835,761,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 835761596...
Checkpoint 835761596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.38065
Policy Entropy: 3.11482
Value Function Loss: 0.00453

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08630
Policy Update Magnitude: 0.56113
Value Function Update Magnitude: 0.61962

Collected Steps per Second: 21,807.29553
Overall Steps per Second: 10,576.37993

Timestep Collection Time: 2.29373
Timestep Consumption Time: 2.43568
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.72941

Cumulative Model Updates: 100,216
Cumulative Timesteps: 835,811,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.59796
Policy Entropy: 3.12419
Value Function Loss: 0.00464

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.55850
Value Function Update Magnitude: 0.61974

Collected Steps per Second: 22,318.74598
Overall Steps per Second: 10,774.22822

Timestep Collection Time: 2.24081
Timestep Consumption Time: 2.40101
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.64182

Cumulative Model Updates: 100,222
Cumulative Timesteps: 835,861,628

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 835861628...
Checkpoint 835861628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.06259
Policy Entropy: 3.11824
Value Function Loss: 0.00469

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.56597
Value Function Update Magnitude: 0.63060

Collected Steps per Second: 22,942.32417
Overall Steps per Second: 10,643.06966

Timestep Collection Time: 2.17955
Timestep Consumption Time: 2.51872
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.69827

Cumulative Model Updates: 100,228
Cumulative Timesteps: 835,911,632

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.88188
Policy Entropy: 3.11320
Value Function Loss: 0.00475

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.57232
Value Function Update Magnitude: 0.63345

Collected Steps per Second: 23,199.53521
Overall Steps per Second: 10,865.63272

Timestep Collection Time: 2.15530
Timestep Consumption Time: 2.44655
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.60185

Cumulative Model Updates: 100,234
Cumulative Timesteps: 835,961,634

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 835961634...
Checkpoint 835961634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.23796
Policy Entropy: 3.11188
Value Function Loss: 0.00476

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.57613
Value Function Update Magnitude: 0.63625

Collected Steps per Second: 22,575.69743
Overall Steps per Second: 10,723.62403

Timestep Collection Time: 2.21575
Timestep Consumption Time: 2.44891
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.66465

Cumulative Model Updates: 100,240
Cumulative Timesteps: 836,011,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.78130
Policy Entropy: 3.12186
Value Function Loss: 0.00500

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11171
Policy Update Magnitude: 0.57978
Value Function Update Magnitude: 0.62989

Collected Steps per Second: 23,109.47960
Overall Steps per Second: 10,851.58844

Timestep Collection Time: 2.16405
Timestep Consumption Time: 2.44449
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.60854

Cumulative Model Updates: 100,246
Cumulative Timesteps: 836,061,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 836061666...
Checkpoint 836061666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.81050
Policy Entropy: 3.12498
Value Function Loss: 0.00501

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.58628
Value Function Update Magnitude: 0.63401

Collected Steps per Second: 22,668.64731
Overall Steps per Second: 10,646.91291

Timestep Collection Time: 2.20595
Timestep Consumption Time: 2.49081
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.69676

Cumulative Model Updates: 100,252
Cumulative Timesteps: 836,111,672

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 893.72300
Policy Entropy: 3.12484
Value Function Loss: 0.00498

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.58150
Value Function Update Magnitude: 0.62608

Collected Steps per Second: 23,142.13373
Overall Steps per Second: 10,828.34268

Timestep Collection Time: 2.16186
Timestep Consumption Time: 2.45842
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.62028

Cumulative Model Updates: 100,258
Cumulative Timesteps: 836,161,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 836161702...
Checkpoint 836161702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.62760
Policy Entropy: 3.12481
Value Function Loss: 0.00507

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.57642
Value Function Update Magnitude: 0.61777

Collected Steps per Second: 22,314.89962
Overall Steps per Second: 10,651.68605

Timestep Collection Time: 2.24173
Timestep Consumption Time: 2.45461
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.69635

Cumulative Model Updates: 100,264
Cumulative Timesteps: 836,211,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.76883
Policy Entropy: 3.12385
Value Function Loss: 0.00494

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.58200
Value Function Update Magnitude: 0.64757

Collected Steps per Second: 23,203.51358
Overall Steps per Second: 10,770.77210

Timestep Collection Time: 2.15579
Timestep Consumption Time: 2.48844
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.64424

Cumulative Model Updates: 100,270
Cumulative Timesteps: 836,261,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 836261748...
Checkpoint 836261748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.90872
Policy Entropy: 3.12089
Value Function Loss: 0.00471

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.57763
Value Function Update Magnitude: 0.63862

Collected Steps per Second: 22,853.41258
Overall Steps per Second: 10,801.54035

Timestep Collection Time: 2.18812
Timestep Consumption Time: 2.44141
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.62952

Cumulative Model Updates: 100,276
Cumulative Timesteps: 836,311,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.73206
Policy Entropy: 3.12583
Value Function Loss: 0.00473

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08722
Policy Update Magnitude: 0.57281
Value Function Update Magnitude: 0.60247

Collected Steps per Second: 22,446.03126
Overall Steps per Second: 10,843.05418

Timestep Collection Time: 2.22810
Timestep Consumption Time: 2.38425
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.61235

Cumulative Model Updates: 100,282
Cumulative Timesteps: 836,361,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 836361766...
Checkpoint 836361766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.52914
Policy Entropy: 3.12361
Value Function Loss: 0.00489

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.57281
Value Function Update Magnitude: 0.60599

Collected Steps per Second: 21,829.72093
Overall Steps per Second: 10,737.73651

Timestep Collection Time: 2.29146
Timestep Consumption Time: 2.36706
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.65852

Cumulative Model Updates: 100,288
Cumulative Timesteps: 836,411,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.13153
Policy Entropy: 3.10974
Value Function Loss: 0.00495

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.57721
Value Function Update Magnitude: 0.61583

Collected Steps per Second: 22,749.19468
Overall Steps per Second: 10,654.97994

Timestep Collection Time: 2.19788
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.69264

Cumulative Model Updates: 100,294
Cumulative Timesteps: 836,461,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 836461788...
Checkpoint 836461788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.10655
Policy Entropy: 3.12310
Value Function Loss: 0.00480

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11252
Policy Update Magnitude: 0.58022
Value Function Update Magnitude: 0.63010

Collected Steps per Second: 22,877.23992
Overall Steps per Second: 10,817.69291

Timestep Collection Time: 2.18619
Timestep Consumption Time: 2.43716
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.62335

Cumulative Model Updates: 100,300
Cumulative Timesteps: 836,511,802

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.23047
Policy Entropy: 3.13205
Value Function Loss: 0.00452

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.56915
Value Function Update Magnitude: 0.62929

Collected Steps per Second: 22,194.91104
Overall Steps per Second: 10,667.12406

Timestep Collection Time: 2.25394
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.68974

Cumulative Model Updates: 100,306
Cumulative Timesteps: 836,561,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 836561828...
Checkpoint 836561828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.00525
Policy Entropy: 3.14844
Value Function Loss: 0.00448

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.55052
Value Function Update Magnitude: 0.60602

Collected Steps per Second: 22,100.36224
Overall Steps per Second: 10,627.47136

Timestep Collection Time: 2.26376
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.70761

Cumulative Model Updates: 100,312
Cumulative Timesteps: 836,611,858

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.78334
Policy Entropy: 3.15384
Value Function Loss: 0.00446

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.54888
Value Function Update Magnitude: 0.60611

Collected Steps per Second: 23,042.91328
Overall Steps per Second: 10,795.18352

Timestep Collection Time: 2.17021
Timestep Consumption Time: 2.46222
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.63244

Cumulative Model Updates: 100,318
Cumulative Timesteps: 836,661,866

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 836661866...
Checkpoint 836661866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.30368
Policy Entropy: 3.14734
Value Function Loss: 0.00489

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.56194
Value Function Update Magnitude: 0.62658

Collected Steps per Second: 22,664.91834
Overall Steps per Second: 10,641.46816

Timestep Collection Time: 2.20729
Timestep Consumption Time: 2.49394
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.70123

Cumulative Model Updates: 100,324
Cumulative Timesteps: 836,711,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,607.41511
Policy Entropy: 3.13205
Value Function Loss: 0.00496

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.11100
Policy Update Magnitude: 0.56897
Value Function Update Magnitude: 0.64765

Collected Steps per Second: 22,408.88878
Overall Steps per Second: 10,834.07987

Timestep Collection Time: 2.23170
Timestep Consumption Time: 2.38429
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.61599

Cumulative Model Updates: 100,330
Cumulative Timesteps: 836,761,904

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 836761904...
Checkpoint 836761904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.80325
Policy Entropy: 3.11699
Value Function Loss: 0.00493

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.56112
Value Function Update Magnitude: 0.63799

Collected Steps per Second: 21,819.01083
Overall Steps per Second: 10,721.79301

Timestep Collection Time: 2.29231
Timestep Consumption Time: 2.37258
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.66489

Cumulative Model Updates: 100,336
Cumulative Timesteps: 836,811,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.08820
Policy Entropy: 3.13301
Value Function Loss: 0.00465

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09128
Policy Update Magnitude: 0.55333
Value Function Update Magnitude: 0.61595

Collected Steps per Second: 22,441.11395
Overall Steps per Second: 10,857.47100

Timestep Collection Time: 2.22850
Timestep Consumption Time: 2.37755
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.60605

Cumulative Model Updates: 100,342
Cumulative Timesteps: 836,861,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 836861930...
Checkpoint 836861930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.71054
Policy Entropy: 3.13390
Value Function Loss: 0.00473

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.55615
Value Function Update Magnitude: 0.59705

Collected Steps per Second: 21,925.86938
Overall Steps per Second: 10,695.24753

Timestep Collection Time: 2.28160
Timestep Consumption Time: 2.39581
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.67740

Cumulative Model Updates: 100,348
Cumulative Timesteps: 836,911,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.94614
Policy Entropy: 3.14163
Value Function Loss: 0.00471

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.56226
Value Function Update Magnitude: 0.60309

Collected Steps per Second: 22,296.97936
Overall Steps per Second: 10,825.16544

Timestep Collection Time: 2.24335
Timestep Consumption Time: 2.37736
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.62071

Cumulative Model Updates: 100,354
Cumulative Timesteps: 836,961,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 836961976...
Checkpoint 836961976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.97830
Policy Entropy: 3.12046
Value Function Loss: 0.00466

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08765
Policy Update Magnitude: 0.56029
Value Function Update Magnitude: 0.60934

Collected Steps per Second: 22,749.26997
Overall Steps per Second: 10,684.27014

Timestep Collection Time: 2.19831
Timestep Consumption Time: 2.48240
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.68071

Cumulative Model Updates: 100,360
Cumulative Timesteps: 837,011,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.14076
Policy Entropy: 3.13096
Value Function Loss: 0.00433

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.55330
Value Function Update Magnitude: 0.60933

Collected Steps per Second: 23,097.38843
Overall Steps per Second: 10,829.95489

Timestep Collection Time: 2.16475
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.61682

Cumulative Model Updates: 100,366
Cumulative Timesteps: 837,061,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 837061986...
Checkpoint 837061986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.69651
Policy Entropy: 3.14588
Value Function Loss: 0.00438

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 0.59167

Collected Steps per Second: 21,446.05610
Overall Steps per Second: 10,636.42525

Timestep Collection Time: 2.33208
Timestep Consumption Time: 2.37006
PPO Batch Consumption Time: 0.28192
Total Iteration Time: 4.70214

Cumulative Model Updates: 100,372
Cumulative Timesteps: 837,112,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.47056
Policy Entropy: 3.14079
Value Function Loss: 0.00436

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09462
Policy Update Magnitude: 0.54804
Value Function Update Magnitude: 0.57963

Collected Steps per Second: 22,324.67635
Overall Steps per Second: 10,691.82963

Timestep Collection Time: 2.23985
Timestep Consumption Time: 2.43699
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.67684

Cumulative Model Updates: 100,378
Cumulative Timesteps: 837,162,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 837162004...
Checkpoint 837162004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938.22266
Policy Entropy: 3.13804
Value Function Loss: 0.00459

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09093
Policy Update Magnitude: 0.55002
Value Function Update Magnitude: 0.59173

Collected Steps per Second: 22,957.55922
Overall Steps per Second: 10,685.57789

Timestep Collection Time: 2.17906
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.68164

Cumulative Model Updates: 100,384
Cumulative Timesteps: 837,212,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.51521
Policy Entropy: 3.13070
Value Function Loss: 0.00456

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.55056
Value Function Update Magnitude: 0.59673

Collected Steps per Second: 22,261.45933
Overall Steps per Second: 10,474.34072

Timestep Collection Time: 2.24702
Timestep Consumption Time: 2.52865
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.77567

Cumulative Model Updates: 100,390
Cumulative Timesteps: 837,262,052

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 837262052...
Checkpoint 837262052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,642.50947
Policy Entropy: 3.12903
Value Function Loss: 0.00444

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.08023
Policy Update Magnitude: 0.55300
Value Function Update Magnitude: 0.59253

Collected Steps per Second: 22,835.54241
Overall Steps per Second: 10,799.05702

Timestep Collection Time: 2.19001
Timestep Consumption Time: 2.44095
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.63096

Cumulative Model Updates: 100,396
Cumulative Timesteps: 837,312,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,373.89948
Policy Entropy: 3.11987
Value Function Loss: 0.00452

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.57794

Collected Steps per Second: 22,096.94759
Overall Steps per Second: 10,639.27980

Timestep Collection Time: 2.26393
Timestep Consumption Time: 2.43808
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.70201

Cumulative Model Updates: 100,402
Cumulative Timesteps: 837,362,088

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 837362088...
Checkpoint 837362088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.72067
Policy Entropy: 3.12429
Value Function Loss: 0.00463

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.56538
Value Function Update Magnitude: 0.59043

Collected Steps per Second: 22,531.07650
Overall Steps per Second: 10,540.93820

Timestep Collection Time: 2.22040
Timestep Consumption Time: 2.52567
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.74607

Cumulative Model Updates: 100,408
Cumulative Timesteps: 837,412,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.04350
Policy Entropy: 3.12839
Value Function Loss: 0.00464

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.57040
Value Function Update Magnitude: 0.60843

Collected Steps per Second: 23,336.87983
Overall Steps per Second: 10,886.10879

Timestep Collection Time: 2.14296
Timestep Consumption Time: 2.45097
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.59393

Cumulative Model Updates: 100,414
Cumulative Timesteps: 837,462,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 837462126...
Checkpoint 837462126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.30048
Policy Entropy: 3.12205
Value Function Loss: 0.00456

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10047
Policy Update Magnitude: 0.57109
Value Function Update Magnitude: 0.61169

Collected Steps per Second: 22,773.10079
Overall Steps per Second: 10,722.94241

Timestep Collection Time: 2.19645
Timestep Consumption Time: 2.46831
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.66476

Cumulative Model Updates: 100,420
Cumulative Timesteps: 837,512,146

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.32990
Policy Entropy: 3.12142
Value Function Loss: 0.00465

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.56773
Value Function Update Magnitude: 0.60862

Collected Steps per Second: 23,040.83129
Overall Steps per Second: 10,802.49774

Timestep Collection Time: 2.17032
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.62911

Cumulative Model Updates: 100,426
Cumulative Timesteps: 837,562,152

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 837562152...
Checkpoint 837562152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.52840
Policy Entropy: 3.12058
Value Function Loss: 0.00454

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.56106
Value Function Update Magnitude: 0.60804

Collected Steps per Second: 21,863.95650
Overall Steps per Second: 10,757.84659

Timestep Collection Time: 2.28760
Timestep Consumption Time: 2.36166
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.64926

Cumulative Model Updates: 100,432
Cumulative Timesteps: 837,612,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.46837
Policy Entropy: 3.12828
Value Function Loss: 0.00451

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.55582
Value Function Update Magnitude: 0.61224

Collected Steps per Second: 22,321.25028
Overall Steps per Second: 10,810.65988

Timestep Collection Time: 2.24100
Timestep Consumption Time: 2.38610
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.62710

Cumulative Model Updates: 100,438
Cumulative Timesteps: 837,662,190

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 837662190...
Checkpoint 837662190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.64048
Policy Entropy: 3.13356
Value Function Loss: 0.00419

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.59044

Collected Steps per Second: 21,912.15083
Overall Steps per Second: 10,688.13794

Timestep Collection Time: 2.28248
Timestep Consumption Time: 2.39692
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.67939

Cumulative Model Updates: 100,444
Cumulative Timesteps: 837,712,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.61427
Policy Entropy: 3.13443
Value Function Loss: 0.00436

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08408
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.57508

Collected Steps per Second: 22,362.63231
Overall Steps per Second: 10,810.52092

Timestep Collection Time: 2.23730
Timestep Consumption Time: 2.39078
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.62808

Cumulative Model Updates: 100,450
Cumulative Timesteps: 837,762,236

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 837762236...
Checkpoint 837762236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.57250
Policy Entropy: 3.13574
Value Function Loss: 0.00443

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08951
Policy Update Magnitude: 0.55460
Value Function Update Magnitude: 0.58114

Collected Steps per Second: 21,911.29609
Overall Steps per Second: 10,733.32839

Timestep Collection Time: 2.28311
Timestep Consumption Time: 2.37770
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.66081

Cumulative Model Updates: 100,456
Cumulative Timesteps: 837,812,262

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,106.49681
Policy Entropy: 3.13958
Value Function Loss: 0.00471

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.55042
Value Function Update Magnitude: 0.59012

Collected Steps per Second: 22,048.93630
Overall Steps per Second: 10,689.22056

Timestep Collection Time: 2.26904
Timestep Consumption Time: 2.41137
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.68042

Cumulative Model Updates: 100,462
Cumulative Timesteps: 837,862,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 837862292...
Checkpoint 837862292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,497.95054
Policy Entropy: 3.13623
Value Function Loss: 0.00469

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.54651
Value Function Update Magnitude: 0.59961

Collected Steps per Second: 22,156.94085
Overall Steps per Second: 10,799.43475

Timestep Collection Time: 2.25744
Timestep Consumption Time: 2.37410
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.63154

Cumulative Model Updates: 100,468
Cumulative Timesteps: 837,912,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.47034
Policy Entropy: 3.13141
Value Function Loss: 0.00472

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10606
Policy Update Magnitude: 0.55999
Value Function Update Magnitude: 0.61624

Collected Steps per Second: 23,087.71620
Overall Steps per Second: 10,758.86056

Timestep Collection Time: 2.16669
Timestep Consumption Time: 2.48287
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.64956

Cumulative Model Updates: 100,474
Cumulative Timesteps: 837,962,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 837962334...
Checkpoint 837962334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638.19892
Policy Entropy: 3.13419
Value Function Loss: 0.00460

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11124
Policy Update Magnitude: 0.56219
Value Function Update Magnitude: 0.63710

Collected Steps per Second: 22,091.86061
Overall Steps per Second: 10,750.56788

Timestep Collection Time: 2.26328
Timestep Consumption Time: 2.38764
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.65092

Cumulative Model Updates: 100,480
Cumulative Timesteps: 838,012,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.51936
Policy Entropy: 3.14950
Value Function Loss: 0.00442

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.55662
Value Function Update Magnitude: 0.62944

Collected Steps per Second: 22,035.77904
Overall Steps per Second: 10,594.60611

Timestep Collection Time: 2.26949
Timestep Consumption Time: 2.45084
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.72033

Cumulative Model Updates: 100,486
Cumulative Timesteps: 838,062,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 838062344...
Checkpoint 838062344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.46155
Policy Entropy: 3.13992
Value Function Loss: 0.00433

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.54981
Value Function Update Magnitude: 0.60086

Collected Steps per Second: 21,979.07004
Overall Steps per Second: 10,609.92515

Timestep Collection Time: 2.27526
Timestep Consumption Time: 2.43807
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.71332

Cumulative Model Updates: 100,492
Cumulative Timesteps: 838,112,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.12349
Policy Entropy: 3.14780
Value Function Loss: 0.00469

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.55119
Value Function Update Magnitude: 0.59208

Collected Steps per Second: 22,389.27434
Overall Steps per Second: 10,809.03686

Timestep Collection Time: 2.23455
Timestep Consumption Time: 2.39398
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.62853

Cumulative Model Updates: 100,498
Cumulative Timesteps: 838,162,382

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 838162382...
Checkpoint 838162382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 588.19949
Policy Entropy: 3.12689
Value Function Loss: 0.00478

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11632
Policy Update Magnitude: 0.55434
Value Function Update Magnitude: 0.60713

Collected Steps per Second: 21,899.92511
Overall Steps per Second: 10,775.75320

Timestep Collection Time: 2.28412
Timestep Consumption Time: 2.35797
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.64209

Cumulative Model Updates: 100,504
Cumulative Timesteps: 838,212,404

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.57999
Policy Entropy: 3.12157
Value Function Loss: 0.00483

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.62353

Collected Steps per Second: 22,203.89954
Overall Steps per Second: 10,804.86336

Timestep Collection Time: 2.25222
Timestep Consumption Time: 2.37607
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.62829

Cumulative Model Updates: 100,510
Cumulative Timesteps: 838,262,412

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 838262412...
Checkpoint 838262412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.50284
Policy Entropy: 3.11884
Value Function Loss: 0.00469

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09165
Policy Update Magnitude: 0.55851
Value Function Update Magnitude: 0.61567

Collected Steps per Second: 22,150.33601
Overall Steps per Second: 10,716.85355

Timestep Collection Time: 2.25730
Timestep Consumption Time: 2.40825
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.66555

Cumulative Model Updates: 100,516
Cumulative Timesteps: 838,312,412

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.83029
Policy Entropy: 3.13144
Value Function Loss: 0.00456

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11870
Policy Update Magnitude: 0.55671
Value Function Update Magnitude: 0.61557

Collected Steps per Second: 22,222.44737
Overall Steps per Second: 10,797.63583

Timestep Collection Time: 2.25034
Timestep Consumption Time: 2.38105
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.63138

Cumulative Model Updates: 100,522
Cumulative Timesteps: 838,362,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 838362420...
Checkpoint 838362420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.06167
Policy Entropy: 3.14228
Value Function Loss: 0.00440

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.54850
Value Function Update Magnitude: 0.61538

Collected Steps per Second: 21,813.79832
Overall Steps per Second: 10,661.85607

Timestep Collection Time: 2.29323
Timestep Consumption Time: 2.39864
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.69187

Cumulative Model Updates: 100,528
Cumulative Timesteps: 838,412,444

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,100.03878
Policy Entropy: 3.14917
Value Function Loss: 0.00434

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.53113
Value Function Update Magnitude: 0.58262

Collected Steps per Second: 22,206.18654
Overall Steps per Second: 10,702.74238

Timestep Collection Time: 2.25262
Timestep Consumption Time: 2.42114
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.67376

Cumulative Model Updates: 100,534
Cumulative Timesteps: 838,462,466

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 838462466...
Checkpoint 838462466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.01004
Policy Entropy: 3.14381
Value Function Loss: 0.00442

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13376
Policy Update Magnitude: 0.53141
Value Function Update Magnitude: 0.56489

Collected Steps per Second: 23,077.91783
Overall Steps per Second: 10,837.52875

Timestep Collection Time: 2.16675
Timestep Consumption Time: 2.44722
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.61397

Cumulative Model Updates: 100,540
Cumulative Timesteps: 838,512,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.70431
Policy Entropy: 3.13127
Value Function Loss: 0.00461

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.54055
Value Function Update Magnitude: 0.58105

Collected Steps per Second: 22,178.09156
Overall Steps per Second: 10,674.50936

Timestep Collection Time: 2.25457
Timestep Consumption Time: 2.42968
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.68424

Cumulative Model Updates: 100,546
Cumulative Timesteps: 838,562,472

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 838562472...
Checkpoint 838562472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.89894
Policy Entropy: 3.14398
Value Function Loss: 0.00441

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.12030
Policy Update Magnitude: 0.54220
Value Function Update Magnitude: 0.60302

Collected Steps per Second: 22,144.99197
Overall Steps per Second: 10,669.84254

Timestep Collection Time: 2.25893
Timestep Consumption Time: 2.42942
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.68835

Cumulative Model Updates: 100,552
Cumulative Timesteps: 838,612,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.43022
Policy Entropy: 3.15615
Value Function Loss: 0.00462

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.54259
Value Function Update Magnitude: 0.59496

Collected Steps per Second: 22,215.04586
Overall Steps per Second: 10,745.29207

Timestep Collection Time: 2.25091
Timestep Consumption Time: 2.40267
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.65357

Cumulative Model Updates: 100,558
Cumulative Timesteps: 838,662,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 838662500...
Checkpoint 838662500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.38281
Policy Entropy: 3.16767
Value Function Loss: 0.00462

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.54974
Value Function Update Magnitude: 0.59819

Collected Steps per Second: 22,093.20780
Overall Steps per Second: 10,640.73689

Timestep Collection Time: 2.26459
Timestep Consumption Time: 2.43734
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.70193

Cumulative Model Updates: 100,564
Cumulative Timesteps: 838,712,532

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.09303
Policy Entropy: 3.14717
Value Function Loss: 0.00512

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.61900

Collected Steps per Second: 22,944.55944
Overall Steps per Second: 10,794.94633

Timestep Collection Time: 2.17978
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.63309

Cumulative Model Updates: 100,570
Cumulative Timesteps: 838,762,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 838762546...
Checkpoint 838762546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.47379
Policy Entropy: 3.14504
Value Function Loss: 0.00509

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.62335

Collected Steps per Second: 22,687.91647
Overall Steps per Second: 10,719.70938

Timestep Collection Time: 2.20399
Timestep Consumption Time: 2.46069
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.66468

Cumulative Model Updates: 100,576
Cumulative Timesteps: 838,812,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.39461
Policy Entropy: 3.14036
Value Function Loss: 0.00525

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10452
Policy Update Magnitude: 0.56578
Value Function Update Magnitude: 0.62491

Collected Steps per Second: 22,884.03230
Overall Steps per Second: 10,695.10529

Timestep Collection Time: 2.18554
Timestep Consumption Time: 2.49080
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.67634

Cumulative Model Updates: 100,582
Cumulative Timesteps: 838,862,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 838862564...
Checkpoint 838862564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.27725
Policy Entropy: 3.14326
Value Function Loss: 0.00528

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11939
Policy Update Magnitude: 0.58112
Value Function Update Magnitude: 0.64038

Collected Steps per Second: 23,048.23374
Overall Steps per Second: 10,847.28137

Timestep Collection Time: 2.17014
Timestep Consumption Time: 2.44096
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.61111

Cumulative Model Updates: 100,588
Cumulative Timesteps: 838,912,582

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.32807
Policy Entropy: 3.14552
Value Function Loss: 0.00496

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11589
Policy Update Magnitude: 0.58475
Value Function Update Magnitude: 0.65303

Collected Steps per Second: 22,687.51818
Overall Steps per Second: 10,619.46219

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.50488
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.70909

Cumulative Model Updates: 100,594
Cumulative Timesteps: 838,962,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 838962590...
Checkpoint 838962590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.66331
Policy Entropy: 3.15469
Value Function Loss: 0.00502

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.57934
Value Function Update Magnitude: 0.65833

Collected Steps per Second: 23,291.47060
Overall Steps per Second: 10,873.28228

Timestep Collection Time: 2.14722
Timestep Consumption Time: 2.45231
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.59953

Cumulative Model Updates: 100,600
Cumulative Timesteps: 839,012,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.26867
Policy Entropy: 3.13987
Value Function Loss: 0.00486

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.58378
Value Function Update Magnitude: 0.65940

Collected Steps per Second: 22,924.01648
Overall Steps per Second: 10,680.99674

Timestep Collection Time: 2.18121
Timestep Consumption Time: 2.50019
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.68140

Cumulative Model Updates: 100,606
Cumulative Timesteps: 839,062,604

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 839062604...
Checkpoint 839062604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.87153
Policy Entropy: 3.14116
Value Function Loss: 0.00498

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.57909
Value Function Update Magnitude: 0.67885

Collected Steps per Second: 22,963.82518
Overall Steps per Second: 10,845.11232

Timestep Collection Time: 2.17734
Timestep Consumption Time: 2.43303
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.61037

Cumulative Model Updates: 100,612
Cumulative Timesteps: 839,112,604

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.52413
Policy Entropy: 3.13115
Value Function Loss: 0.00467

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.56576
Value Function Update Magnitude: 0.66416

Collected Steps per Second: 22,757.15246
Overall Steps per Second: 10,617.74345

Timestep Collection Time: 2.19790
Timestep Consumption Time: 2.51289
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 4.71079

Cumulative Model Updates: 100,618
Cumulative Timesteps: 839,162,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 839162622...
Checkpoint 839162622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615.33685
Policy Entropy: 3.13306
Value Function Loss: 0.00501

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.56702
Value Function Update Magnitude: 0.62607

Collected Steps per Second: 22,795.40181
Overall Steps per Second: 10,604.84672

Timestep Collection Time: 2.19386
Timestep Consumption Time: 2.52190
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.71577

Cumulative Model Updates: 100,624
Cumulative Timesteps: 839,212,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.02457
Policy Entropy: 3.12311
Value Function Loss: 0.00520

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.57414
Value Function Update Magnitude: 0.61823

Collected Steps per Second: 23,005.63058
Overall Steps per Second: 10,778.55202

Timestep Collection Time: 2.17416
Timestep Consumption Time: 2.46635
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.64051

Cumulative Model Updates: 100,630
Cumulative Timesteps: 839,262,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 839262650...
Checkpoint 839262650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.12208
Policy Entropy: 3.12744
Value Function Loss: 0.00511

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10616
Policy Update Magnitude: 0.57874
Value Function Update Magnitude: 0.62230

Collected Steps per Second: 22,609.43403
Overall Steps per Second: 10,768.90025

Timestep Collection Time: 2.21262
Timestep Consumption Time: 2.43280
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.64541

Cumulative Model Updates: 100,636
Cumulative Timesteps: 839,312,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,273.21095
Policy Entropy: 3.12346
Value Function Loss: 0.00487

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.57356
Value Function Update Magnitude: 0.61819

Collected Steps per Second: 22,647.49640
Overall Steps per Second: 10,631.69842

Timestep Collection Time: 2.20907
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.70574

Cumulative Model Updates: 100,642
Cumulative Timesteps: 839,362,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 839362706...
Checkpoint 839362706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,824.84990
Policy Entropy: 3.12823
Value Function Loss: 0.00482

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.56535
Value Function Update Magnitude: 0.61784

Collected Steps per Second: 22,729.73325
Overall Steps per Second: 10,780.93018

Timestep Collection Time: 2.20020
Timestep Consumption Time: 2.43854
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.63875

Cumulative Model Updates: 100,648
Cumulative Timesteps: 839,412,716

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.73214
Policy Entropy: 3.12125
Value Function Loss: 0.00470

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.56161
Value Function Update Magnitude: 0.61020

Collected Steps per Second: 22,776.56284
Overall Steps per Second: 10,564.32980

Timestep Collection Time: 2.19577
Timestep Consumption Time: 2.53828
PPO Batch Consumption Time: 0.29721
Total Iteration Time: 4.73404

Cumulative Model Updates: 100,654
Cumulative Timesteps: 839,462,728

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 839462728...
Checkpoint 839462728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.21797
Policy Entropy: 3.11685
Value Function Loss: 0.00476

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.56011
Value Function Update Magnitude: 0.61218

Collected Steps per Second: 22,905.33840
Overall Steps per Second: 10,639.32246

Timestep Collection Time: 2.18377
Timestep Consumption Time: 2.51766
PPO Batch Consumption Time: 0.29634
Total Iteration Time: 4.70143

Cumulative Model Updates: 100,660
Cumulative Timesteps: 839,512,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.53142
Policy Entropy: 3.11303
Value Function Loss: 0.00477

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.60791

Collected Steps per Second: 22,627.57628
Overall Steps per Second: 10,560.81550

Timestep Collection Time: 2.20996
Timestep Consumption Time: 2.52509
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.73505

Cumulative Model Updates: 100,666
Cumulative Timesteps: 839,562,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 839562754...
Checkpoint 839562754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.11872
Policy Entropy: 3.11510
Value Function Loss: 0.00488

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.56727
Value Function Update Magnitude: 0.61968

Collected Steps per Second: 23,110.51383
Overall Steps per Second: 10,845.49739

Timestep Collection Time: 2.16447
Timestep Consumption Time: 2.44777
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.61224

Cumulative Model Updates: 100,672
Cumulative Timesteps: 839,612,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 778.36948
Policy Entropy: 3.12147
Value Function Loss: 0.00475

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09352
Policy Update Magnitude: 0.56050
Value Function Update Magnitude: 0.61966

Collected Steps per Second: 22,633.94861
Overall Steps per Second: 10,589.09540

Timestep Collection Time: 2.20960
Timestep Consumption Time: 2.51337
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.72297

Cumulative Model Updates: 100,678
Cumulative Timesteps: 839,662,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 839662788...
Checkpoint 839662788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.93145
Policy Entropy: 3.12403
Value Function Loss: 0.00495

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08424
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.61585

Collected Steps per Second: 22,719.95083
Overall Steps per Second: 10,615.69210

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.51040
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.71208

Cumulative Model Updates: 100,684
Cumulative Timesteps: 839,712,810

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.90433
Policy Entropy: 3.12527
Value Function Loss: 0.00490

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.56459
Value Function Update Magnitude: 0.62472

Collected Steps per Second: 22,749.08920
Overall Steps per Second: 10,615.26310

Timestep Collection Time: 2.19851
Timestep Consumption Time: 2.51301
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.71152

Cumulative Model Updates: 100,690
Cumulative Timesteps: 839,762,824

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 839762824...
Checkpoint 839762824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 813.66107
Policy Entropy: 3.10619
Value Function Loss: 0.00519

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11688
Policy Update Magnitude: 0.56415
Value Function Update Magnitude: 0.62306

Collected Steps per Second: 23,041.19753
Overall Steps per Second: 10,861.83686

Timestep Collection Time: 2.17011
Timestep Consumption Time: 2.43334
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.60346

Cumulative Model Updates: 100,696
Cumulative Timesteps: 839,812,826

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.99567
Policy Entropy: 3.09627
Value Function Loss: 0.00537

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.57438
Value Function Update Magnitude: 0.62971

Collected Steps per Second: 23,228.29457
Overall Steps per Second: 10,916.46519

Timestep Collection Time: 2.15341
Timestep Consumption Time: 2.42866
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.58207

Cumulative Model Updates: 100,702
Cumulative Timesteps: 839,862,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 839862846...
Checkpoint 839862846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 957.84602
Policy Entropy: 3.08697
Value Function Loss: 0.00531

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11466
Policy Update Magnitude: 0.58074
Value Function Update Magnitude: 0.63160

Collected Steps per Second: 22,932.92372
Overall Steps per Second: 10,695.24962

Timestep Collection Time: 2.18027
Timestep Consumption Time: 2.49470
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.67497

Cumulative Model Updates: 100,708
Cumulative Timesteps: 839,912,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.90110
Policy Entropy: 3.10653
Value Function Loss: 0.00511

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.58026
Value Function Update Magnitude: 0.64530

Collected Steps per Second: 22,904.17186
Overall Steps per Second: 10,828.44302

Timestep Collection Time: 2.18336
Timestep Consumption Time: 2.43485
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.61821

Cumulative Model Updates: 100,714
Cumulative Timesteps: 839,962,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 839962854...
Checkpoint 839962854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.09620
Policy Entropy: 3.10715
Value Function Loss: 0.00492

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.57505
Value Function Update Magnitude: 0.66050

Collected Steps per Second: 22,730.17575
Overall Steps per Second: 10,693.77735

Timestep Collection Time: 2.20069
Timestep Consumption Time: 2.47699
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.67767

Cumulative Model Updates: 100,720
Cumulative Timesteps: 840,012,876

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.25622
Policy Entropy: 3.10083
Value Function Loss: 0.00501

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11372
Policy Update Magnitude: 0.57649
Value Function Update Magnitude: 0.67495

Collected Steps per Second: 22,314.51306
Overall Steps per Second: 10,554.37487

Timestep Collection Time: 2.24069
Timestep Consumption Time: 2.49668
PPO Batch Consumption Time: 0.29516
Total Iteration Time: 4.73737

Cumulative Model Updates: 100,726
Cumulative Timesteps: 840,062,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 840062876...
Checkpoint 840062876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.00630
Policy Entropy: 3.07685
Value Function Loss: 0.00521

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11651
Policy Update Magnitude: 0.57954
Value Function Update Magnitude: 0.67361

Collected Steps per Second: 22,865.17733
Overall Steps per Second: 10,714.51363

Timestep Collection Time: 2.18743
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.66806

Cumulative Model Updates: 100,732
Cumulative Timesteps: 840,112,892

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 569.70188
Policy Entropy: 3.09715
Value Function Loss: 0.00507

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.15128
Policy Update Magnitude: 0.58044
Value Function Update Magnitude: 0.66386

Collected Steps per Second: 22,742.30669
Overall Steps per Second: 10,771.21638

Timestep Collection Time: 2.19881
Timestep Consumption Time: 2.44375
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.64256

Cumulative Model Updates: 100,738
Cumulative Timesteps: 840,162,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 840162898...
Checkpoint 840162898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.58305
Policy Entropy: 3.10804
Value Function Loss: 0.00494

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.12028
Policy Update Magnitude: 0.56767
Value Function Update Magnitude: 0.64018

Collected Steps per Second: 22,797.40688
Overall Steps per Second: 10,664.41844

Timestep Collection Time: 2.19323
Timestep Consumption Time: 2.49526
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.68849

Cumulative Model Updates: 100,744
Cumulative Timesteps: 840,212,898

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 984.87101
Policy Entropy: 3.10788
Value Function Loss: 0.00492

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.55995
Value Function Update Magnitude: 0.62541

Collected Steps per Second: 22,713.08742
Overall Steps per Second: 10,815.17916

Timestep Collection Time: 2.20234
Timestep Consumption Time: 2.42282
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.62517

Cumulative Model Updates: 100,750
Cumulative Timesteps: 840,262,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 840262920...
Checkpoint 840262920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.61419
Policy Entropy: 3.09528
Value Function Loss: 0.00486

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.55985
Value Function Update Magnitude: 0.63015

Collected Steps per Second: 22,417.63340
Overall Steps per Second: 10,743.54682

Timestep Collection Time: 2.23048
Timestep Consumption Time: 2.42367
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.65414

Cumulative Model Updates: 100,756
Cumulative Timesteps: 840,312,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.87600
Policy Entropy: 3.09867
Value Function Loss: 0.00492

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.57019
Value Function Update Magnitude: 0.65774

Collected Steps per Second: 22,880.01111
Overall Steps per Second: 10,835.95512

Timestep Collection Time: 2.18654
Timestep Consumption Time: 2.43031
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.61685

Cumulative Model Updates: 100,762
Cumulative Timesteps: 840,362,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 840362950...
Checkpoint 840362950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.29283
Policy Entropy: 3.09450
Value Function Loss: 0.00495

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.57971
Value Function Update Magnitude: 0.67139

Collected Steps per Second: 21,980.73403
Overall Steps per Second: 10,601.97032

Timestep Collection Time: 2.27718
Timestep Consumption Time: 2.44402
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.72120

Cumulative Model Updates: 100,768
Cumulative Timesteps: 840,413,004

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.06869
Policy Entropy: 3.08901
Value Function Loss: 0.00505

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.57298
Value Function Update Magnitude: 0.67618

Collected Steps per Second: 22,910.42491
Overall Steps per Second: 10,706.32885

Timestep Collection Time: 2.18241
Timestep Consumption Time: 2.48772
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.67013

Cumulative Model Updates: 100,774
Cumulative Timesteps: 840,463,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 840463004...
Checkpoint 840463004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.37165
Policy Entropy: 3.08537
Value Function Loss: 0.00481

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10448
Policy Update Magnitude: 0.56679
Value Function Update Magnitude: 0.65435

Collected Steps per Second: 22,803.83675
Overall Steps per Second: 10,753.58918

Timestep Collection Time: 2.19481
Timestep Consumption Time: 2.45945
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.65426

Cumulative Model Updates: 100,780
Cumulative Timesteps: 840,513,054

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.55167
Policy Entropy: 3.10228
Value Function Loss: 0.00458

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09807
Policy Update Magnitude: 0.55358
Value Function Update Magnitude: 0.63812

Collected Steps per Second: 22,667.27652
Overall Steps per Second: 10,595.09491

Timestep Collection Time: 2.20688
Timestep Consumption Time: 2.51455
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.72143

Cumulative Model Updates: 100,786
Cumulative Timesteps: 840,563,078

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 840563078...
Checkpoint 840563078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.88692
Policy Entropy: 3.12497
Value Function Loss: 0.00475

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.54735
Value Function Update Magnitude: 0.60966

Collected Steps per Second: 22,745.36925
Overall Steps per Second: 10,638.50992

Timestep Collection Time: 2.19869
Timestep Consumption Time: 2.50216
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.70085

Cumulative Model Updates: 100,792
Cumulative Timesteps: 840,613,088

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,047.70790
Policy Entropy: 3.14605
Value Function Loss: 0.00476

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.54967
Value Function Update Magnitude: 0.61062

Collected Steps per Second: 22,817.22122
Overall Steps per Second: 10,817.48377

Timestep Collection Time: 2.19247
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.62455

Cumulative Model Updates: 100,798
Cumulative Timesteps: 840,663,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 840663114...
Checkpoint 840663114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,433.56586
Policy Entropy: 3.14458
Value Function Loss: 0.00476

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.55457
Value Function Update Magnitude: 0.62181

Collected Steps per Second: 22,642.57398
Overall Steps per Second: 10,748.67417

Timestep Collection Time: 2.20911
Timestep Consumption Time: 2.44448
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.65360

Cumulative Model Updates: 100,804
Cumulative Timesteps: 840,713,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.57125
Policy Entropy: 3.15565
Value Function Loss: 0.00461

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.55812
Value Function Update Magnitude: 0.63002

Collected Steps per Second: 22,821.15470
Overall Steps per Second: 10,798.85857

Timestep Collection Time: 2.19139
Timestep Consumption Time: 2.43966
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.63105

Cumulative Model Updates: 100,810
Cumulative Timesteps: 840,763,144

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 840763144...
Checkpoint 840763144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.15613
Policy Entropy: 3.15614
Value Function Loss: 0.00462

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.55683
Value Function Update Magnitude: 0.62409

Collected Steps per Second: 22,725.94972
Overall Steps per Second: 10,769.53530

Timestep Collection Time: 2.20057
Timestep Consumption Time: 2.44309
PPO Batch Consumption Time: 0.29633
Total Iteration Time: 4.64365

Cumulative Model Updates: 100,816
Cumulative Timesteps: 840,813,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,905.23782
Policy Entropy: 3.15891
Value Function Loss: 0.00460

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09179
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.63798

Collected Steps per Second: 21,902.73062
Overall Steps per Second: 10,437.30561

Timestep Collection Time: 2.28291
Timestep Consumption Time: 2.50779
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.79070

Cumulative Model Updates: 100,822
Cumulative Timesteps: 840,863,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 840863156...
Checkpoint 840863156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.51475
Policy Entropy: 3.17047
Value Function Loss: 0.00447

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08305
Policy Update Magnitude: 0.54378
Value Function Update Magnitude: 0.63317

Collected Steps per Second: 22,481.01341
Overall Steps per Second: 10,634.20405

Timestep Collection Time: 2.22490
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.70350

Cumulative Model Updates: 100,828
Cumulative Timesteps: 840,913,174

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.47966
Policy Entropy: 3.16805
Value Function Loss: 0.00435

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.54274
Value Function Update Magnitude: 0.62387

Collected Steps per Second: 22,007.81106
Overall Steps per Second: 10,436.01817

Timestep Collection Time: 2.27283
Timestep Consumption Time: 2.52019
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.79302

Cumulative Model Updates: 100,834
Cumulative Timesteps: 840,963,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 840963194...
Checkpoint 840963194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.95834
Policy Entropy: 3.15205
Value Function Loss: 0.00466

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.55139
Value Function Update Magnitude: 0.63408

Collected Steps per Second: 22,531.09041
Overall Steps per Second: 10,644.47387

Timestep Collection Time: 2.21942
Timestep Consumption Time: 2.47841
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.69784

Cumulative Model Updates: 100,840
Cumulative Timesteps: 841,013,200

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 537.27778
Policy Entropy: 3.13886
Value Function Loss: 0.00481

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.55917
Value Function Update Magnitude: 0.63338

Collected Steps per Second: 22,824.13246
Overall Steps per Second: 10,756.14194

Timestep Collection Time: 2.19110
Timestep Consumption Time: 2.45833
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.64944

Cumulative Model Updates: 100,846
Cumulative Timesteps: 841,063,210

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 841063210...
Checkpoint 841063210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.82390
Policy Entropy: 3.13037
Value Function Loss: 0.00485

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09548
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.65295

Collected Steps per Second: 22,652.74995
Overall Steps per Second: 10,824.04132

Timestep Collection Time: 2.20839
Timestep Consumption Time: 2.41336
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.62175

Cumulative Model Updates: 100,852
Cumulative Timesteps: 841,113,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 827.31409
Policy Entropy: 3.12205
Value Function Loss: 0.00480

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.55643
Value Function Update Magnitude: 0.63776

Collected Steps per Second: 22,873.68152
Overall Steps per Second: 10,808.91715

Timestep Collection Time: 2.18653
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.62711

Cumulative Model Updates: 100,858
Cumulative Timesteps: 841,163,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 841163250...
Checkpoint 841163250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.71943
Policy Entropy: 3.12607
Value Function Loss: 0.00487

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.63478

Collected Steps per Second: 22,602.93248
Overall Steps per Second: 10,712.59608

Timestep Collection Time: 2.21237
Timestep Consumption Time: 2.45559
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.66796

Cumulative Model Updates: 100,864
Cumulative Timesteps: 841,213,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.89442
Policy Entropy: 3.12006
Value Function Loss: 0.00502

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11238
Policy Update Magnitude: 0.56332
Value Function Update Magnitude: 0.66196

Collected Steps per Second: 22,868.43166
Overall Steps per Second: 10,678.46904

Timestep Collection Time: 2.18694
Timestep Consumption Time: 2.49650
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.68344

Cumulative Model Updates: 100,870
Cumulative Timesteps: 841,263,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 841263268...
Checkpoint 841263268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.34533
Policy Entropy: 3.13283
Value Function Loss: 0.00471

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.56280
Value Function Update Magnitude: 0.66342

Collected Steps per Second: 23,211.55786
Overall Steps per Second: 10,869.07453

Timestep Collection Time: 2.15548
Timestep Consumption Time: 2.44767
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.60315

Cumulative Model Updates: 100,876
Cumulative Timesteps: 841,313,300

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.62116
Policy Entropy: 3.13656
Value Function Loss: 0.00491

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.56286
Value Function Update Magnitude: 0.66595

Collected Steps per Second: 22,719.19773
Overall Steps per Second: 10,796.27983

Timestep Collection Time: 2.20096
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.63160

Cumulative Model Updates: 100,882
Cumulative Timesteps: 841,363,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 841363304...
Checkpoint 841363304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.81689
Policy Entropy: 3.13488
Value Function Loss: 0.00488

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.56350
Value Function Update Magnitude: 0.65913

Collected Steps per Second: 22,393.79277
Overall Steps per Second: 10,697.41436

Timestep Collection Time: 2.23383
Timestep Consumption Time: 2.44244
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.67627

Cumulative Model Updates: 100,888
Cumulative Timesteps: 841,413,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.29978
Policy Entropy: 3.13254
Value Function Loss: 0.00490

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11866
Policy Update Magnitude: 0.57314
Value Function Update Magnitude: 0.65400

Collected Steps per Second: 22,857.67575
Overall Steps per Second: 10,874.58695

Timestep Collection Time: 2.18754
Timestep Consumption Time: 2.41052
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.59806

Cumulative Model Updates: 100,894
Cumulative Timesteps: 841,463,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 841463330...
Checkpoint 841463330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.80211
Policy Entropy: 3.13260
Value Function Loss: 0.00472

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11448
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.64617

Collected Steps per Second: 22,584.16033
Overall Steps per Second: 10,695.14715

Timestep Collection Time: 2.21492
Timestep Consumption Time: 2.46216
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.67707

Cumulative Model Updates: 100,900
Cumulative Timesteps: 841,513,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.09231
Policy Entropy: 3.14001
Value Function Loss: 0.00450

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10375
Policy Update Magnitude: 0.56225
Value Function Update Magnitude: 0.62431

Collected Steps per Second: 22,582.68521
Overall Steps per Second: 10,660.03251

Timestep Collection Time: 2.21453
Timestep Consumption Time: 2.47683
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.69136

Cumulative Model Updates: 100,906
Cumulative Timesteps: 841,563,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 841563362...
Checkpoint 841563362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.05386
Policy Entropy: 3.14605
Value Function Loss: 0.00452

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09343
Policy Update Magnitude: 0.55253
Value Function Update Magnitude: 0.62486

Collected Steps per Second: 22,574.59919
Overall Steps per Second: 10,671.56942

Timestep Collection Time: 2.21576
Timestep Consumption Time: 2.47146
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.68722

Cumulative Model Updates: 100,912
Cumulative Timesteps: 841,613,382

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,824.34034
Policy Entropy: 3.14032
Value Function Loss: 0.00466

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.63386

Collected Steps per Second: 23,090.47878
Overall Steps per Second: 10,718.71765

Timestep Collection Time: 2.16713
Timestep Consumption Time: 2.50134
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.66847

Cumulative Model Updates: 100,918
Cumulative Timesteps: 841,663,422

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 841663422...
Checkpoint 841663422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760.79335
Policy Entropy: 3.13159
Value Function Loss: 0.00478

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09399
Policy Update Magnitude: 0.55916
Value Function Update Magnitude: 0.65774

Collected Steps per Second: 22,852.48793
Overall Steps per Second: 10,645.49258

Timestep Collection Time: 2.18803
Timestep Consumption Time: 2.50898
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.69701

Cumulative Model Updates: 100,924
Cumulative Timesteps: 841,713,424

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.74938
Policy Entropy: 3.13473
Value Function Loss: 0.00469

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.56908
Value Function Update Magnitude: 0.65958

Collected Steps per Second: 22,877.56272
Overall Steps per Second: 10,817.27311

Timestep Collection Time: 2.18555
Timestep Consumption Time: 2.43669
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.62224

Cumulative Model Updates: 100,930
Cumulative Timesteps: 841,763,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 841763424...
Checkpoint 841763424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 812.41070
Policy Entropy: 3.12612
Value Function Loss: 0.00502

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09972
Policy Update Magnitude: 0.56973
Value Function Update Magnitude: 0.65961

Collected Steps per Second: 22,787.35403
Overall Steps per Second: 10,695.88515

Timestep Collection Time: 2.19438
Timestep Consumption Time: 2.48069
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.67507

Cumulative Model Updates: 100,936
Cumulative Timesteps: 841,813,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.91203
Policy Entropy: 3.10787
Value Function Loss: 0.00527

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10078
Policy Update Magnitude: 0.57829
Value Function Update Magnitude: 0.67240

Collected Steps per Second: 22,819.20451
Overall Steps per Second: 10,813.45714

Timestep Collection Time: 2.19122
Timestep Consumption Time: 2.43283
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.62405

Cumulative Model Updates: 100,942
Cumulative Timesteps: 841,863,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 841863430...
Checkpoint 841863430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.18103
Policy Entropy: 3.10155
Value Function Loss: 0.00496

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.58627
Value Function Update Magnitude: 0.67154

Collected Steps per Second: 22,876.53889
Overall Steps per Second: 10,729.84178

Timestep Collection Time: 2.18696
Timestep Consumption Time: 2.47574
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.66270

Cumulative Model Updates: 100,948
Cumulative Timesteps: 841,913,460

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.63850
Policy Entropy: 3.09153
Value Function Loss: 0.00511

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10314
Policy Update Magnitude: 0.58343
Value Function Update Magnitude: 0.65885

Collected Steps per Second: 22,666.93130
Overall Steps per Second: 10,657.88048

Timestep Collection Time: 2.20586
Timestep Consumption Time: 2.48551
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.69136

Cumulative Model Updates: 100,954
Cumulative Timesteps: 841,963,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 841963460...
Checkpoint 841963460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.93776
Policy Entropy: 3.09773
Value Function Loss: 0.00502

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.58301
Value Function Update Magnitude: 0.68118

Collected Steps per Second: 23,113.41699
Overall Steps per Second: 10,943.83682

Timestep Collection Time: 2.16498
Timestep Consumption Time: 2.40746
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.57244

Cumulative Model Updates: 100,960
Cumulative Timesteps: 842,013,500

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.17267
Policy Entropy: 3.09197
Value Function Loss: 0.00512

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.57885
Value Function Update Magnitude: 0.68159

Collected Steps per Second: 22,718.22448
Overall Steps per Second: 10,815.57632

Timestep Collection Time: 2.20158
Timestep Consumption Time: 2.42286
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.62444

Cumulative Model Updates: 100,966
Cumulative Timesteps: 842,063,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 842063516...
Checkpoint 842063516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.99214
Policy Entropy: 3.09748
Value Function Loss: 0.00498

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10791
Policy Update Magnitude: 0.57301
Value Function Update Magnitude: 0.65946

Collected Steps per Second: 22,762.11487
Overall Steps per Second: 10,696.50538

Timestep Collection Time: 2.19725
Timestep Consumption Time: 2.47849
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.67573

Cumulative Model Updates: 100,972
Cumulative Timesteps: 842,113,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.58425
Policy Entropy: 3.09904
Value Function Loss: 0.00499

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.56927
Value Function Update Magnitude: 0.65221

Collected Steps per Second: 22,793.25298
Overall Steps per Second: 10,840.12932

Timestep Collection Time: 2.19363
Timestep Consumption Time: 2.41886
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.61249

Cumulative Model Updates: 100,978
Cumulative Timesteps: 842,163,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 842163530...
Checkpoint 842163530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.62915
Policy Entropy: 3.10018
Value Function Loss: 0.00488

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.57577
Value Function Update Magnitude: 0.65819

Collected Steps per Second: 22,661.22966
Overall Steps per Second: 10,727.20196

Timestep Collection Time: 2.20641
Timestep Consumption Time: 2.45464
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.66105

Cumulative Model Updates: 100,984
Cumulative Timesteps: 842,213,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.50502
Policy Entropy: 3.09548
Value Function Loss: 0.00506

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11798
Policy Update Magnitude: 0.57760
Value Function Update Magnitude: 0.67605

Collected Steps per Second: 22,836.51777
Overall Steps per Second: 10,820.01412

Timestep Collection Time: 2.19018
Timestep Consumption Time: 2.43237
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.62254

Cumulative Model Updates: 100,990
Cumulative Timesteps: 842,263,546

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 842263546...
Checkpoint 842263546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.63455
Policy Entropy: 3.09903
Value Function Loss: 0.00502

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11788
Policy Update Magnitude: 0.59335
Value Function Update Magnitude: 0.67946

Collected Steps per Second: 22,846.06734
Overall Steps per Second: 10,698.41828

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.48602
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.67546

Cumulative Model Updates: 100,996
Cumulative Timesteps: 842,313,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.69177
Policy Entropy: 3.10464
Value Function Loss: 0.00475

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.65606

Collected Steps per Second: 22,880.13642
Overall Steps per Second: 10,826.65226

Timestep Collection Time: 2.18635
Timestep Consumption Time: 2.43410
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.62045

Cumulative Model Updates: 101,002
Cumulative Timesteps: 842,363,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 842363590...
Checkpoint 842363590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.02162
Policy Entropy: 3.09462
Value Function Loss: 0.00481

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11111
Policy Update Magnitude: 0.57261
Value Function Update Magnitude: 0.62588

Collected Steps per Second: 22,568.42079
Overall Steps per Second: 10,721.88247

Timestep Collection Time: 2.21549
Timestep Consumption Time: 2.44788
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.66336

Cumulative Model Updates: 101,008
Cumulative Timesteps: 842,413,590

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.67098
Policy Entropy: 3.08079
Value Function Loss: 0.00484

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11648
Policy Update Magnitude: 0.57460
Value Function Update Magnitude: 0.62386

Collected Steps per Second: 22,825.53871
Overall Steps per Second: 10,815.78562

Timestep Collection Time: 2.19176
Timestep Consumption Time: 2.43371
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.62546

Cumulative Model Updates: 101,014
Cumulative Timesteps: 842,463,618

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 842463618...
Checkpoint 842463618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.94443
Policy Entropy: 3.06939
Value Function Loss: 0.00489

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.58067
Value Function Update Magnitude: 0.62114

Collected Steps per Second: 22,578.21341
Overall Steps per Second: 10,743.71544

Timestep Collection Time: 2.21452
Timestep Consumption Time: 2.43936
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.65388

Cumulative Model Updates: 101,020
Cumulative Timesteps: 842,513,618

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.86420
Policy Entropy: 3.08015
Value Function Loss: 0.00485

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11254
Policy Update Magnitude: 0.57778
Value Function Update Magnitude: 0.61222

Collected Steps per Second: 22,516.80779
Overall Steps per Second: 10,645.28510

Timestep Collection Time: 2.22083
Timestep Consumption Time: 2.47665
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.69748

Cumulative Model Updates: 101,026
Cumulative Timesteps: 842,563,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 842563624...
Checkpoint 842563624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.53332
Policy Entropy: 3.07711
Value Function Loss: 0.00484

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11506
Policy Update Magnitude: 0.57472
Value Function Update Magnitude: 0.62267

Collected Steps per Second: 23,063.16359
Overall Steps per Second: 10,874.91804

Timestep Collection Time: 2.16796
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.59774

Cumulative Model Updates: 101,032
Cumulative Timesteps: 842,613,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.64976
Policy Entropy: 3.06428
Value Function Loss: 0.00508

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.57992
Value Function Update Magnitude: 0.61562

Collected Steps per Second: 22,935.89027
Overall Steps per Second: 10,850.76781

Timestep Collection Time: 2.18025
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.60852

Cumulative Model Updates: 101,038
Cumulative Timesteps: 842,663,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 842663630...
Checkpoint 842663630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.68413
Policy Entropy: 3.05593
Value Function Loss: 0.00514

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.58409
Value Function Update Magnitude: 0.60903

Collected Steps per Second: 22,832.84062
Overall Steps per Second: 10,683.85629

Timestep Collection Time: 2.19079
Timestep Consumption Time: 2.49123
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.68202

Cumulative Model Updates: 101,044
Cumulative Timesteps: 842,713,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.53688
Policy Entropy: 3.05818
Value Function Loss: 0.00503

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.58767
Value Function Update Magnitude: 0.62294

Collected Steps per Second: 22,867.73193
Overall Steps per Second: 10,851.36049

Timestep Collection Time: 2.18684
Timestep Consumption Time: 2.42162
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.60845

Cumulative Model Updates: 101,050
Cumulative Timesteps: 842,763,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 842763660...
Checkpoint 842763660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.80900
Policy Entropy: 3.06749
Value Function Loss: 0.00497

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.58816
Value Function Update Magnitude: 0.62768

Collected Steps per Second: 22,664.11903
Overall Steps per Second: 10,699.65146

Timestep Collection Time: 2.20728
Timestep Consumption Time: 2.46820
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.67548

Cumulative Model Updates: 101,056
Cumulative Timesteps: 842,813,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409.61147
Policy Entropy: 3.06750
Value Function Loss: 0.00494

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.58927
Value Function Update Magnitude: 0.62234

Collected Steps per Second: 22,842.60656
Overall Steps per Second: 10,833.43737

Timestep Collection Time: 2.18959
Timestep Consumption Time: 2.42722
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.61682

Cumulative Model Updates: 101,062
Cumulative Timesteps: 842,863,702

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 842863702...
Checkpoint 842863702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.96383
Policy Entropy: 3.06450
Value Function Loss: 0.00483

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.59311
Value Function Update Magnitude: 0.61817

Collected Steps per Second: 22,814.20161
Overall Steps per Second: 10,733.06670

Timestep Collection Time: 2.19223
Timestep Consumption Time: 2.46757
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.65981

Cumulative Model Updates: 101,068
Cumulative Timesteps: 842,913,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.62084
Policy Entropy: 3.06017
Value Function Loss: 0.00479

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.58722
Value Function Update Magnitude: 0.60553

Collected Steps per Second: 22,391.74770
Overall Steps per Second: 10,578.61036

Timestep Collection Time: 2.23395
Timestep Consumption Time: 2.49465
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.72860

Cumulative Model Updates: 101,074
Cumulative Timesteps: 842,963,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 842963738...
Checkpoint 842963738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.48712
Policy Entropy: 3.08585
Value Function Loss: 0.00471

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10304
Policy Update Magnitude: 0.57384
Value Function Update Magnitude: 0.59363

Collected Steps per Second: 21,175.61457
Overall Steps per Second: 10,412.62738

Timestep Collection Time: 2.36168
Timestep Consumption Time: 2.44114
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.80282

Cumulative Model Updates: 101,080
Cumulative Timesteps: 843,013,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 592.37450
Policy Entropy: 3.08982
Value Function Loss: 0.00496

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.57573
Value Function Update Magnitude: 0.59923

Collected Steps per Second: 22,848.22676
Overall Steps per Second: 10,676.41394

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.49507
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.68360

Cumulative Model Updates: 101,086
Cumulative Timesteps: 843,063,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 843063752...
Checkpoint 843063752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.72026
Policy Entropy: 3.10121
Value Function Loss: 0.00482

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09386
Policy Update Magnitude: 0.57565
Value Function Update Magnitude: 0.61643

Collected Steps per Second: 22,884.88373
Overall Steps per Second: 10,867.72799

Timestep Collection Time: 2.18529
Timestep Consumption Time: 2.41641
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.60170

Cumulative Model Updates: 101,092
Cumulative Timesteps: 843,113,762

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.40995
Policy Entropy: 3.08638
Value Function Loss: 0.00512

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.58321
Value Function Update Magnitude: 0.62778

Collected Steps per Second: 22,639.11761
Overall Steps per Second: 10,621.11568

Timestep Collection Time: 2.20910
Timestep Consumption Time: 2.49964
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.70873

Cumulative Model Updates: 101,098
Cumulative Timesteps: 843,163,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 843163774...
Checkpoint 843163774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.58543
Policy Entropy: 3.10374
Value Function Loss: 0.00545

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12362
Policy Update Magnitude: 0.58516
Value Function Update Magnitude: 0.63568

Collected Steps per Second: 22,833.96279
Overall Steps per Second: 10,957.65018

Timestep Collection Time: 2.19095
Timestep Consumption Time: 2.37463
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.56558

Cumulative Model Updates: 101,104
Cumulative Timesteps: 843,213,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.05734
Policy Entropy: 3.10048
Value Function Loss: 0.00544

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.59391
Value Function Update Magnitude: 0.65824

Collected Steps per Second: 22,232.49068
Overall Steps per Second: 10,702.82062

Timestep Collection Time: 2.25004
Timestep Consumption Time: 2.42387
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.67391

Cumulative Model Updates: 101,110
Cumulative Timesteps: 843,263,826

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 843263826...
Checkpoint 843263826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.76070
Policy Entropy: 3.10876
Value Function Loss: 0.00533

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.58852
Value Function Update Magnitude: 0.66534

Collected Steps per Second: 22,382.11880
Overall Steps per Second: 10,847.60405

Timestep Collection Time: 2.23419
Timestep Consumption Time: 2.37567
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.60987

Cumulative Model Updates: 101,116
Cumulative Timesteps: 843,313,832

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.96354
Policy Entropy: 3.11820
Value Function Loss: 0.00489

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.57329
Value Function Update Magnitude: 0.66743

Collected Steps per Second: 21,776.02236
Overall Steps per Second: 10,533.78662

Timestep Collection Time: 2.29684
Timestep Consumption Time: 2.45131
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.74815

Cumulative Model Updates: 101,122
Cumulative Timesteps: 843,363,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 843363848...
Checkpoint 843363848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.07106
Policy Entropy: 3.12156
Value Function Loss: 0.00469

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.65371

Collected Steps per Second: 22,293.93846
Overall Steps per Second: 10,658.66849

Timestep Collection Time: 2.24285
Timestep Consumption Time: 2.44835
PPO Batch Consumption Time: 0.29674
Total Iteration Time: 4.69121

Cumulative Model Updates: 101,128
Cumulative Timesteps: 843,413,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.13586
Policy Entropy: 3.12208
Value Function Loss: 0.00485

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09155
Policy Update Magnitude: 0.57005
Value Function Update Magnitude: 0.64908

Collected Steps per Second: 22,372.73783
Overall Steps per Second: 10,838.80631

Timestep Collection Time: 2.23522
Timestep Consumption Time: 2.37857
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.61379

Cumulative Model Updates: 101,134
Cumulative Timesteps: 843,463,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 843463858...
Checkpoint 843463858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.34197
Policy Entropy: 3.11289
Value Function Loss: 0.00476

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.57123
Value Function Update Magnitude: 0.66915

Collected Steps per Second: 21,713.79187
Overall Steps per Second: 10,697.69190

Timestep Collection Time: 2.30333
Timestep Consumption Time: 2.37189
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.67521

Cumulative Model Updates: 101,140
Cumulative Timesteps: 843,513,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.33769
Policy Entropy: 3.10841
Value Function Loss: 0.00490

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.56857
Value Function Update Magnitude: 0.65594

Collected Steps per Second: 22,145.29747
Overall Steps per Second: 10,776.77568

Timestep Collection Time: 2.25863
Timestep Consumption Time: 2.38265
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.64128

Cumulative Model Updates: 101,146
Cumulative Timesteps: 843,563,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 843563890...
Checkpoint 843563890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743.62394
Policy Entropy: 3.09273
Value Function Loss: 0.00493

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.57370
Value Function Update Magnitude: 0.65049

Collected Steps per Second: 21,569.09565
Overall Steps per Second: 10,663.01886

Timestep Collection Time: 2.31887
Timestep Consumption Time: 2.37173
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.69060

Cumulative Model Updates: 101,152
Cumulative Timesteps: 843,613,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.11621
Policy Entropy: 3.09332
Value Function Loss: 0.00536

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.58234
Value Function Update Magnitude: 0.63561

Collected Steps per Second: 22,931.67000
Overall Steps per Second: 10,621.06508

Timestep Collection Time: 2.18039
Timestep Consumption Time: 2.52724
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.70763

Cumulative Model Updates: 101,158
Cumulative Timesteps: 843,663,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 843663906...
Checkpoint 843663906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.56841
Policy Entropy: 3.08067
Value Function Loss: 0.00534

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.58724
Value Function Update Magnitude: 0.63753

Collected Steps per Second: 22,956.31588
Overall Steps per Second: 10,747.25995

Timestep Collection Time: 2.17831
Timestep Consumption Time: 2.47460
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.65291

Cumulative Model Updates: 101,164
Cumulative Timesteps: 843,713,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.65995
Policy Entropy: 3.08466
Value Function Loss: 0.00512

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.58755
Value Function Update Magnitude: 0.63501

Collected Steps per Second: 22,996.65742
Overall Steps per Second: 10,716.12278

Timestep Collection Time: 2.17458
Timestep Consumption Time: 2.49204
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.66661

Cumulative Model Updates: 101,170
Cumulative Timesteps: 843,763,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 843763920...
Checkpoint 843763920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.12782
Policy Entropy: 3.07692
Value Function Loss: 0.00491

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09236
Policy Update Magnitude: 0.58807
Value Function Update Magnitude: 0.61934

Collected Steps per Second: 22,849.30515
Overall Steps per Second: 10,609.54003

Timestep Collection Time: 2.18869
Timestep Consumption Time: 2.52499
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.71368

Cumulative Model Updates: 101,176
Cumulative Timesteps: 843,813,930

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.69226
Policy Entropy: 3.08414
Value Function Loss: 0.00478

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09661
Policy Update Magnitude: 0.58447
Value Function Update Magnitude: 0.62381

Collected Steps per Second: 22,648.35023
Overall Steps per Second: 10,618.94205

Timestep Collection Time: 2.20873
Timestep Consumption Time: 2.50210
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.71083

Cumulative Model Updates: 101,182
Cumulative Timesteps: 843,863,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 843863954...
Checkpoint 843863954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 863.08723
Policy Entropy: 3.08397
Value Function Loss: 0.00489

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.58183
Value Function Update Magnitude: 0.63978

Collected Steps per Second: 22,975.86578
Overall Steps per Second: 10,712.20550

Timestep Collection Time: 2.17646
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.66813

Cumulative Model Updates: 101,188
Cumulative Timesteps: 843,913,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,327.80612
Policy Entropy: 3.10020
Value Function Loss: 0.00470

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10292
Policy Update Magnitude: 0.57948
Value Function Update Magnitude: 0.63494

Collected Steps per Second: 22,784.67128
Overall Steps per Second: 10,726.66922

Timestep Collection Time: 2.19534
Timestep Consumption Time: 2.46781
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.66314

Cumulative Model Updates: 101,194
Cumulative Timesteps: 843,963,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 843963980...
Checkpoint 843963980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.21186
Policy Entropy: 3.08887
Value Function Loss: 0.00482

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10989
Policy Update Magnitude: 0.57308
Value Function Update Magnitude: 0.62352

Collected Steps per Second: 22,663.99300
Overall Steps per Second: 10,600.99867

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.51110
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.71786

Cumulative Model Updates: 101,200
Cumulative Timesteps: 844,013,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.37859
Policy Entropy: 3.10318
Value Function Loss: 0.00511

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.63156

Collected Steps per Second: 23,209.67552
Overall Steps per Second: 10,887.50039

Timestep Collection Time: 2.15539
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.59481

Cumulative Model Updates: 101,206
Cumulative Timesteps: 844,064,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 844064020...
Checkpoint 844064020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.79589
Policy Entropy: 3.10421
Value Function Loss: 0.00509

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09532
Policy Update Magnitude: 0.58372
Value Function Update Magnitude: 0.66245

Collected Steps per Second: 22,401.17060
Overall Steps per Second: 10,677.57716

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.45127
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.68383

Cumulative Model Updates: 101,212
Cumulative Timesteps: 844,114,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,277.09595
Policy Entropy: 3.09943
Value Function Loss: 0.00516

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09301
Policy Update Magnitude: 0.57984
Value Function Update Magnitude: 0.66472

Collected Steps per Second: 22,990.36191
Overall Steps per Second: 10,773.50993

Timestep Collection Time: 2.17604
Timestep Consumption Time: 2.46757
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.64361

Cumulative Model Updates: 101,218
Cumulative Timesteps: 844,164,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 844164060...
Checkpoint 844164060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.42357
Policy Entropy: 3.09367
Value Function Loss: 0.00518

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.58576
Value Function Update Magnitude: 0.64870

Collected Steps per Second: 22,642.15864
Overall Steps per Second: 10,748.41156

Timestep Collection Time: 2.20880
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.65297

Cumulative Model Updates: 101,224
Cumulative Timesteps: 844,214,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.66572
Policy Entropy: 3.08538
Value Function Loss: 0.00495

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.64654

Collected Steps per Second: 22,896.18108
Overall Steps per Second: 10,667.70210

Timestep Collection Time: 2.18482
Timestep Consumption Time: 2.50448
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.68929

Cumulative Model Updates: 101,230
Cumulative Timesteps: 844,264,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 844264096...
Checkpoint 844264096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 688.71837
Policy Entropy: 3.09914
Value Function Loss: 0.00469

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.56944
Value Function Update Magnitude: 0.63285

Collected Steps per Second: 22,927.05560
Overall Steps per Second: 10,823.29692

Timestep Collection Time: 2.18179
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.62170

Cumulative Model Updates: 101,236
Cumulative Timesteps: 844,314,118

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 838.31139
Policy Entropy: 3.09577
Value Function Loss: 0.00475

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09072
Policy Update Magnitude: 0.57088
Value Function Update Magnitude: 0.60195

Collected Steps per Second: 22,723.52763
Overall Steps per Second: 10,564.59412

Timestep Collection Time: 2.20045
Timestep Consumption Time: 2.53253
PPO Batch Consumption Time: 0.29580
Total Iteration Time: 4.73298

Cumulative Model Updates: 101,242
Cumulative Timesteps: 844,364,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 844364120...
Checkpoint 844364120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 857.88603
Policy Entropy: 3.09129
Value Function Loss: 0.00469

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.56867
Value Function Update Magnitude: 0.59638

Collected Steps per Second: 22,709.93890
Overall Steps per Second: 10,602.33102

Timestep Collection Time: 2.20247
Timestep Consumption Time: 2.51517
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.71764

Cumulative Model Updates: 101,248
Cumulative Timesteps: 844,414,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.48636
Policy Entropy: 3.08153
Value Function Loss: 0.00465

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09073
Policy Update Magnitude: 0.56519
Value Function Update Magnitude: 0.60524

Collected Steps per Second: 22,807.45779
Overall Steps per Second: 10,664.86667

Timestep Collection Time: 2.19297
Timestep Consumption Time: 2.49682
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.68979

Cumulative Model Updates: 101,254
Cumulative Timesteps: 844,464,154

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 844464154...
Checkpoint 844464154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.34807
Policy Entropy: 3.08680
Value Function Loss: 0.00475

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.57255
Value Function Update Magnitude: 0.60884

Collected Steps per Second: 23,011.56639
Overall Steps per Second: 10,813.66153

Timestep Collection Time: 2.17308
Timestep Consumption Time: 2.45125
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.62434

Cumulative Model Updates: 101,260
Cumulative Timesteps: 844,514,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.61297
Policy Entropy: 3.08652
Value Function Loss: 0.00482

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10760
Policy Update Magnitude: 0.57619
Value Function Update Magnitude: 0.64647

Collected Steps per Second: 22,594.54622
Overall Steps per Second: 10,522.46859

Timestep Collection Time: 2.21345
Timestep Consumption Time: 2.53942
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.75288

Cumulative Model Updates: 101,266
Cumulative Timesteps: 844,564,172

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 844564172...
Checkpoint 844564172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 898.38443
Policy Entropy: 3.08496
Value Function Loss: 0.00510

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.58566
Value Function Update Magnitude: 0.65444

Collected Steps per Second: 22,890.51926
Overall Steps per Second: 10,623.00831

Timestep Collection Time: 2.18536
Timestep Consumption Time: 2.52367
PPO Batch Consumption Time: 0.29582
Total Iteration Time: 4.70902

Cumulative Model Updates: 101,272
Cumulative Timesteps: 844,614,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.56316
Policy Entropy: 3.09834
Value Function Loss: 0.00518

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09992
Policy Update Magnitude: 0.58998
Value Function Update Magnitude: 0.65048

Collected Steps per Second: 22,913.61198
Overall Steps per Second: 10,712.96787

Timestep Collection Time: 2.18237
Timestep Consumption Time: 2.48543
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.66780

Cumulative Model Updates: 101,278
Cumulative Timesteps: 844,664,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 844664202...
Checkpoint 844664202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.44936
Policy Entropy: 3.09851
Value Function Loss: 0.00503

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09856
Policy Update Magnitude: 0.58878
Value Function Update Magnitude: 0.64723

Collected Steps per Second: 22,911.04405
Overall Steps per Second: 10,790.53601

Timestep Collection Time: 2.18270
Timestep Consumption Time: 2.45173
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.63443

Cumulative Model Updates: 101,284
Cumulative Timesteps: 844,714,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,703.78232
Policy Entropy: 3.09835
Value Function Loss: 0.00499

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.58283
Value Function Update Magnitude: 0.64005

Collected Steps per Second: 22,992.17997
Overall Steps per Second: 10,677.56203

Timestep Collection Time: 2.17483
Timestep Consumption Time: 2.50827
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.68309

Cumulative Model Updates: 101,290
Cumulative Timesteps: 844,764,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 844764214...
Checkpoint 844764214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.47134
Policy Entropy: 3.08435
Value Function Loss: 0.00487

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09081
Policy Update Magnitude: 0.57815
Value Function Update Magnitude: 0.64198

Collected Steps per Second: 22,627.05090
Overall Steps per Second: 10,618.90506

Timestep Collection Time: 2.21098
Timestep Consumption Time: 2.50024
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.71122

Cumulative Model Updates: 101,296
Cumulative Timesteps: 844,814,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.20106
Policy Entropy: 3.07961
Value Function Loss: 0.00478

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.56795
Value Function Update Magnitude: 0.62895

Collected Steps per Second: 22,695.14670
Overall Steps per Second: 10,686.29028

Timestep Collection Time: 2.20347
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.67964

Cumulative Model Updates: 101,302
Cumulative Timesteps: 844,864,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 844864250...
Checkpoint 844864250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 825.49902
Policy Entropy: 3.08473
Value Function Loss: 0.00491

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.57144
Value Function Update Magnitude: 0.61440

Collected Steps per Second: 22,545.32227
Overall Steps per Second: 10,740.88052

Timestep Collection Time: 2.21909
Timestep Consumption Time: 2.43882
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.65790

Cumulative Model Updates: 101,308
Cumulative Timesteps: 844,914,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.56509
Policy Entropy: 3.08013
Value Function Loss: 0.00506

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.58082
Value Function Update Magnitude: 0.62639

Collected Steps per Second: 22,675.38735
Overall Steps per Second: 10,767.22577

Timestep Collection Time: 2.20521
Timestep Consumption Time: 2.43888
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.64409

Cumulative Model Updates: 101,314
Cumulative Timesteps: 844,964,284

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 844964284...
Checkpoint 844964284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.43762
Policy Entropy: 3.06859
Value Function Loss: 0.00526

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.59288
Value Function Update Magnitude: 0.63542

Collected Steps per Second: 22,981.12368
Overall Steps per Second: 10,729.69753

Timestep Collection Time: 2.17613
Timestep Consumption Time: 2.48476
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.66090

Cumulative Model Updates: 101,320
Cumulative Timesteps: 845,014,294

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 808.21334
Policy Entropy: 3.07509
Value Function Loss: 0.00498

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.59252
Value Function Update Magnitude: 0.64401

Collected Steps per Second: 23,079.54982
Overall Steps per Second: 10,872.12992

Timestep Collection Time: 2.16677
Timestep Consumption Time: 2.43288
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.59965

Cumulative Model Updates: 101,326
Cumulative Timesteps: 845,064,302

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 845064302...
Checkpoint 845064302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.07658
Policy Entropy: 3.09062
Value Function Loss: 0.00493

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09797
Policy Update Magnitude: 0.58051
Value Function Update Magnitude: 0.63552

Collected Steps per Second: 22,600.28203
Overall Steps per Second: 10,688.65870

Timestep Collection Time: 2.21351
Timestep Consumption Time: 2.46678
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.68029

Cumulative Model Updates: 101,332
Cumulative Timesteps: 845,114,328

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.91077
Policy Entropy: 3.10162
Value Function Loss: 0.00463

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10305
Policy Update Magnitude: 0.56517
Value Function Update Magnitude: 0.61324

Collected Steps per Second: 22,803.92419
Overall Steps per Second: 10,809.45014

Timestep Collection Time: 2.19304
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.62651

Cumulative Model Updates: 101,338
Cumulative Timesteps: 845,164,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 845164338...
Checkpoint 845164338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.32913
Policy Entropy: 3.08367
Value Function Loss: 0.00483

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.56918
Value Function Update Magnitude: 0.60292

Collected Steps per Second: 22,780.02147
Overall Steps per Second: 10,736.85326

Timestep Collection Time: 2.19596
Timestep Consumption Time: 2.46313
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.65909

Cumulative Model Updates: 101,344
Cumulative Timesteps: 845,214,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995.83152
Policy Entropy: 3.08741
Value Function Loss: 0.00485

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10461
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.60380

Collected Steps per Second: 23,112.22441
Overall Steps per Second: 10,870.28833

Timestep Collection Time: 2.16405
Timestep Consumption Time: 2.43712
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.60117

Cumulative Model Updates: 101,350
Cumulative Timesteps: 845,264,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 845264378...
Checkpoint 845264378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.32661
Policy Entropy: 3.08319
Value Function Loss: 0.00513

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.57924
Value Function Update Magnitude: 0.61397

Collected Steps per Second: 22,278.23685
Overall Steps per Second: 10,714.83892

Timestep Collection Time: 2.24461
Timestep Consumption Time: 2.42237
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.66699

Cumulative Model Updates: 101,356
Cumulative Timesteps: 845,314,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.25089
Policy Entropy: 3.09947
Value Function Loss: 0.00481

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10965
Policy Update Magnitude: 0.56997
Value Function Update Magnitude: 0.61115

Collected Steps per Second: 23,177.09102
Overall Steps per Second: 10,874.86476

Timestep Collection Time: 2.15791
Timestep Consumption Time: 2.44114
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.59905

Cumulative Model Updates: 101,362
Cumulative Timesteps: 845,364,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 845364398...
Checkpoint 845364398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.14399
Policy Entropy: 3.08054
Value Function Loss: 0.00486

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12275
Policy Update Magnitude: 0.56417
Value Function Update Magnitude: 0.60726

Collected Steps per Second: 22,729.39879
Overall Steps per Second: 10,629.87448

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.50413
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.70410

Cumulative Model Updates: 101,368
Cumulative Timesteps: 845,414,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.79918
Policy Entropy: 3.08613
Value Function Loss: 0.00499

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.57231
Value Function Update Magnitude: 0.60746

Collected Steps per Second: 22,677.66970
Overall Steps per Second: 10,652.01014

Timestep Collection Time: 2.20569
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.69583

Cumulative Model Updates: 101,374
Cumulative Timesteps: 845,464,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 845464422...
Checkpoint 845464422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.90991
Policy Entropy: 3.08702
Value Function Loss: 0.00505

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.58236
Value Function Update Magnitude: 0.61371

Collected Steps per Second: 22,510.06177
Overall Steps per Second: 10,673.60410

Timestep Collection Time: 2.22247
Timestep Consumption Time: 2.46460
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.68708

Cumulative Model Updates: 101,380
Cumulative Timesteps: 845,514,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.13232
Policy Entropy: 3.09264
Value Function Loss: 0.00482

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.57287
Value Function Update Magnitude: 0.61432

Collected Steps per Second: 23,021.32427
Overall Steps per Second: 10,671.70299

Timestep Collection Time: 2.17329
Timestep Consumption Time: 2.51500
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.68829

Cumulative Model Updates: 101,386
Cumulative Timesteps: 845,564,482

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 845564482...
Checkpoint 845564482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.27742
Policy Entropy: 3.08731
Value Function Loss: 0.00471

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10232
Policy Update Magnitude: 0.56395
Value Function Update Magnitude: 0.60394

Collected Steps per Second: 22,572.84588
Overall Steps per Second: 10,658.06668

Timestep Collection Time: 2.21567
Timestep Consumption Time: 2.47692
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.69260

Cumulative Model Updates: 101,392
Cumulative Timesteps: 845,614,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.21552
Policy Entropy: 3.08670
Value Function Loss: 0.00456

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09380
Policy Update Magnitude: 0.56411
Value Function Update Magnitude: 0.60315

Collected Steps per Second: 22,817.81289
Overall Steps per Second: 10,831.64391

Timestep Collection Time: 2.19250
Timestep Consumption Time: 2.42619
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.61869

Cumulative Model Updates: 101,398
Cumulative Timesteps: 845,664,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 845664524...
Checkpoint 845664524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 602.50411
Policy Entropy: 3.09639
Value Function Loss: 0.00485

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09877
Policy Update Magnitude: 0.57606
Value Function Update Magnitude: 0.60994

Collected Steps per Second: 22,309.03260
Overall Steps per Second: 10,721.75655

Timestep Collection Time: 2.24205
Timestep Consumption Time: 2.42304
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.66509

Cumulative Model Updates: 101,404
Cumulative Timesteps: 845,714,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.38972
Policy Entropy: 3.10282
Value Function Loss: 0.00509

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.57872
Value Function Update Magnitude: 0.62145

Collected Steps per Second: 23,134.41015
Overall Steps per Second: 10,904.90672

Timestep Collection Time: 2.16249
Timestep Consumption Time: 2.42517
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.58766

Cumulative Model Updates: 101,410
Cumulative Timesteps: 845,764,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 845764570...
Checkpoint 845764570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.46233
Policy Entropy: 3.10815
Value Function Loss: 0.00522

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.57685
Value Function Update Magnitude: 0.62068

Collected Steps per Second: 22,686.67832
Overall Steps per Second: 10,621.20724

Timestep Collection Time: 2.20429
Timestep Consumption Time: 2.50403
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.70832

Cumulative Model Updates: 101,416
Cumulative Timesteps: 845,814,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.34755
Policy Entropy: 3.10314
Value Function Loss: 0.00522

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.58131
Value Function Update Magnitude: 0.63605

Collected Steps per Second: 23,109.18661
Overall Steps per Second: 10,891.68161

Timestep Collection Time: 2.16381
Timestep Consumption Time: 2.42721
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.59103

Cumulative Model Updates: 101,422
Cumulative Timesteps: 845,864,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 845864582...
Checkpoint 845864582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488.02485
Policy Entropy: 3.10606
Value Function Loss: 0.00530

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10261
Policy Update Magnitude: 0.58672
Value Function Update Magnitude: 0.63780

Collected Steps per Second: 22,341.38940
Overall Steps per Second: 10,744.87858

Timestep Collection Time: 2.23898
Timestep Consumption Time: 2.41644
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.65543

Cumulative Model Updates: 101,428
Cumulative Timesteps: 845,914,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.44168
Policy Entropy: 3.10344
Value Function Loss: 0.00505

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10550
Policy Update Magnitude: 0.58585
Value Function Update Magnitude: 0.61637

Collected Steps per Second: 23,183.41101
Overall Steps per Second: 10,830.31295

Timestep Collection Time: 2.15715
Timestep Consumption Time: 2.46045
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.61760

Cumulative Model Updates: 101,434
Cumulative Timesteps: 845,964,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 845964614...
Checkpoint 845964614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 818.74847
Policy Entropy: 3.09234
Value Function Loss: 0.00518

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.58712
Value Function Update Magnitude: 0.59580

Collected Steps per Second: 22,865.37958
Overall Steps per Second: 10,631.45763

Timestep Collection Time: 2.18811
Timestep Consumption Time: 2.51792
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 4.70603

Cumulative Model Updates: 101,440
Cumulative Timesteps: 846,014,646

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.54225
Policy Entropy: 3.07714
Value Function Loss: 0.00526

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.59294
Value Function Update Magnitude: 0.59190

Collected Steps per Second: 23,261.98143
Overall Steps per Second: 10,897.50757

Timestep Collection Time: 2.14969
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.58876

Cumulative Model Updates: 101,446
Cumulative Timesteps: 846,064,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 846064652...
Checkpoint 846064652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.73216
Policy Entropy: 3.06988
Value Function Loss: 0.00526

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11282
Policy Update Magnitude: 0.59069
Value Function Update Magnitude: 0.60160

Collected Steps per Second: 22,211.50563
Overall Steps per Second: 10,671.28674

Timestep Collection Time: 2.25217
Timestep Consumption Time: 2.43555
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.68772

Cumulative Model Updates: 101,452
Cumulative Timesteps: 846,114,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.20918
Policy Entropy: 3.05938
Value Function Loss: 0.00510

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.58711
Value Function Update Magnitude: 0.60988

Collected Steps per Second: 22,326.43966
Overall Steps per Second: 10,789.66848

Timestep Collection Time: 2.23968
Timestep Consumption Time: 2.39476
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.63443

Cumulative Model Updates: 101,458
Cumulative Timesteps: 846,164,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 846164680...
Checkpoint 846164680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.85612
Policy Entropy: 3.06819
Value Function Loss: 0.00509

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.58753
Value Function Update Magnitude: 0.62535

Collected Steps per Second: 22,216.28279
Overall Steps per Second: 10,759.49291

Timestep Collection Time: 2.25087
Timestep Consumption Time: 2.39675
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.64762

Cumulative Model Updates: 101,464
Cumulative Timesteps: 846,214,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.49536
Policy Entropy: 3.05776
Value Function Loss: 0.00509

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10924
Policy Update Magnitude: 0.59535
Value Function Update Magnitude: 0.62745

Collected Steps per Second: 22,244.81103
Overall Steps per Second: 10,815.87252

Timestep Collection Time: 2.24870
Timestep Consumption Time: 2.37617
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.62487

Cumulative Model Updates: 101,470
Cumulative Timesteps: 846,264,708

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 846264708...
Checkpoint 846264708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.31948
Policy Entropy: 3.07337
Value Function Loss: 0.00503

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.59309
Value Function Update Magnitude: 0.63829

Collected Steps per Second: 22,075.93819
Overall Steps per Second: 10,801.18868

Timestep Collection Time: 2.26500
Timestep Consumption Time: 2.36431
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.62931

Cumulative Model Updates: 101,476
Cumulative Timesteps: 846,314,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.60228
Policy Entropy: 3.08214
Value Function Loss: 0.00506

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11530
Policy Update Magnitude: 0.58651
Value Function Update Magnitude: 0.63698

Collected Steps per Second: 22,011.32910
Overall Steps per Second: 10,758.75747

Timestep Collection Time: 2.27183
Timestep Consumption Time: 2.37610
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.64793

Cumulative Model Updates: 101,482
Cumulative Timesteps: 846,364,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 846364716...
Checkpoint 846364716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.77040
Policy Entropy: 3.08510
Value Function Loss: 0.00538

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.59057
Value Function Update Magnitude: 0.67167

Collected Steps per Second: 22,060.00317
Overall Steps per Second: 10,700.06978

Timestep Collection Time: 2.26763
Timestep Consumption Time: 2.40748
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.67511

Cumulative Model Updates: 101,488
Cumulative Timesteps: 846,414,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,534.92036
Policy Entropy: 3.08897
Value Function Loss: 0.00550

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.59711
Value Function Update Magnitude: 0.67221

Collected Steps per Second: 23,112.40457
Overall Steps per Second: 10,856.81980

Timestep Collection Time: 2.16447
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.60779

Cumulative Model Updates: 101,494
Cumulative Timesteps: 846,464,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 846464766...
Checkpoint 846464766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.06363
Policy Entropy: 3.10070
Value Function Loss: 0.00549

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.60274
Value Function Update Magnitude: 0.67246

Collected Steps per Second: 22,500.83426
Overall Steps per Second: 10,694.96099

Timestep Collection Time: 2.22294
Timestep Consumption Time: 2.45384
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.67678

Cumulative Model Updates: 101,500
Cumulative Timesteps: 846,514,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.25657
Policy Entropy: 3.09818
Value Function Loss: 0.00532

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.60206
Value Function Update Magnitude: 0.67653

Collected Steps per Second: 22,856.01596
Overall Steps per Second: 10,662.29222

Timestep Collection Time: 2.18857
Timestep Consumption Time: 2.50292
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.69149

Cumulative Model Updates: 101,506
Cumulative Timesteps: 846,564,806

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 846564806...
Checkpoint 846564806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.65600
Policy Entropy: 3.09056
Value Function Loss: 0.00526

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.59421
Value Function Update Magnitude: 0.67219

Collected Steps per Second: 23,052.91913
Overall Steps per Second: 10,854.13827

Timestep Collection Time: 2.16996
Timestep Consumption Time: 2.43879
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.60875

Cumulative Model Updates: 101,512
Cumulative Timesteps: 846,614,830

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.48181
Policy Entropy: 3.09895
Value Function Loss: 0.00511

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.59144
Value Function Update Magnitude: 0.66017

Collected Steps per Second: 23,115.84638
Overall Steps per Second: 10,695.37037

Timestep Collection Time: 2.16362
Timestep Consumption Time: 2.51260
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.67623

Cumulative Model Updates: 101,518
Cumulative Timesteps: 846,664,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 846664844...
Checkpoint 846664844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.52725
Policy Entropy: 3.10148
Value Function Loss: 0.00510

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.58827
Value Function Update Magnitude: 0.66248

Collected Steps per Second: 22,534.64047
Overall Steps per Second: 10,570.91705

Timestep Collection Time: 2.21881
Timestep Consumption Time: 2.51115
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.72996

Cumulative Model Updates: 101,524
Cumulative Timesteps: 846,714,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.95895
Policy Entropy: 3.10247
Value Function Loss: 0.00507

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10006
Policy Update Magnitude: 0.59131
Value Function Update Magnitude: 0.66712

Collected Steps per Second: 23,048.76091
Overall Steps per Second: 10,840.20775

Timestep Collection Time: 2.17062
Timestep Consumption Time: 2.44461
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.61523

Cumulative Model Updates: 101,530
Cumulative Timesteps: 846,764,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 846764874...
Checkpoint 846764874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.02728
Policy Entropy: 3.11590
Value Function Loss: 0.00505

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.59111
Value Function Update Magnitude: 0.66685

Collected Steps per Second: 23,036.87881
Overall Steps per Second: 10,672.83872

Timestep Collection Time: 2.17087
Timestep Consumption Time: 2.51486
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.68573

Cumulative Model Updates: 101,536
Cumulative Timesteps: 846,814,884

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.11308
Policy Entropy: 3.12812
Value Function Loss: 0.00493

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11488
Policy Update Magnitude: 0.58387
Value Function Update Magnitude: 0.64288

Collected Steps per Second: 23,262.35050
Overall Steps per Second: 10,856.35130

Timestep Collection Time: 2.15034
Timestep Consumption Time: 2.45728
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.60763

Cumulative Model Updates: 101,542
Cumulative Timesteps: 846,864,906

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 846864906...
Checkpoint 846864906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.94188
Policy Entropy: 3.12157
Value Function Loss: 0.00496

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.63297

Collected Steps per Second: 23,091.54600
Overall Steps per Second: 10,671.33005

Timestep Collection Time: 2.16599
Timestep Consumption Time: 2.52096
PPO Batch Consumption Time: 0.29683
Total Iteration Time: 4.68695

Cumulative Model Updates: 101,548
Cumulative Timesteps: 846,914,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.47496
Policy Entropy: 3.12818
Value Function Loss: 0.00478

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.56793
Value Function Update Magnitude: 0.63817

Collected Steps per Second: 22,342.41128
Overall Steps per Second: 10,825.34593

Timestep Collection Time: 2.23834
Timestep Consumption Time: 2.38137
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.61971

Cumulative Model Updates: 101,554
Cumulative Timesteps: 846,964,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 846964932...
Checkpoint 846964932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.95869
Policy Entropy: 3.12111
Value Function Loss: 0.00474

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.56668
Value Function Update Magnitude: 0.63912

Collected Steps per Second: 22,001.24496
Overall Steps per Second: 10,674.62016

Timestep Collection Time: 2.27333
Timestep Consumption Time: 2.41218
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.68551

Cumulative Model Updates: 101,560
Cumulative Timesteps: 847,014,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.90262
Policy Entropy: 3.13739
Value Function Loss: 0.00516

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.57634
Value Function Update Magnitude: 0.64493

Collected Steps per Second: 22,914.95703
Overall Steps per Second: 10,814.52378

Timestep Collection Time: 2.18224
Timestep Consumption Time: 2.44172
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.62397

Cumulative Model Updates: 101,566
Cumulative Timesteps: 847,064,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 847064954...
Checkpoint 847064954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.12707
Policy Entropy: 3.12852
Value Function Loss: 0.00525

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11195
Policy Update Magnitude: 0.58023
Value Function Update Magnitude: 0.65200

Collected Steps per Second: 22,568.52833
Overall Steps per Second: 10,746.35436

Timestep Collection Time: 2.21574
Timestep Consumption Time: 2.43756
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.65330

Cumulative Model Updates: 101,572
Cumulative Timesteps: 847,114,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.71227
Policy Entropy: 3.13924
Value Function Loss: 0.00512

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.57672
Value Function Update Magnitude: 0.67004

Collected Steps per Second: 22,949.34816
Overall Steps per Second: 10,805.17450

Timestep Collection Time: 2.17976
Timestep Consumption Time: 2.44988
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.62963

Cumulative Model Updates: 101,578
Cumulative Timesteps: 847,164,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 847164984...
Checkpoint 847164984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,404.59729
Policy Entropy: 3.15067
Value Function Loss: 0.00492

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.12065
Policy Update Magnitude: 0.56670
Value Function Update Magnitude: 0.66255

Collected Steps per Second: 22,635.82969
Overall Steps per Second: 10,749.28044

Timestep Collection Time: 2.20898
Timestep Consumption Time: 2.44268
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.65166

Cumulative Model Updates: 101,584
Cumulative Timesteps: 847,214,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.63614
Policy Entropy: 3.16770
Value Function Loss: 0.00483

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.55823
Value Function Update Magnitude: 0.65180

Collected Steps per Second: 22,795.91792
Overall Steps per Second: 10,668.70629

Timestep Collection Time: 2.19399
Timestep Consumption Time: 2.49393
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.68792

Cumulative Model Updates: 101,590
Cumulative Timesteps: 847,265,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 847265000...
Checkpoint 847265000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.21473
Policy Entropy: 3.17384
Value Function Loss: 0.00475

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.55347
Value Function Update Magnitude: 0.63025

Collected Steps per Second: 22,614.97392
Overall Steps per Second: 10,625.34926

Timestep Collection Time: 2.21163
Timestep Consumption Time: 2.49560
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.70723

Cumulative Model Updates: 101,596
Cumulative Timesteps: 847,315,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.96145
Policy Entropy: 3.16485
Value Function Loss: 0.00463

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.54392
Value Function Update Magnitude: 0.62499

Collected Steps per Second: 22,974.92641
Overall Steps per Second: 10,674.29278

Timestep Collection Time: 2.17724
Timestep Consumption Time: 2.50897
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.68621

Cumulative Model Updates: 101,602
Cumulative Timesteps: 847,365,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 847365038...
Checkpoint 847365038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.25332
Policy Entropy: 3.17917
Value Function Loss: 0.00482

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.55227
Value Function Update Magnitude: 0.62414

Collected Steps per Second: 22,905.69486
Overall Steps per Second: 10,628.89657

Timestep Collection Time: 2.18304
Timestep Consumption Time: 2.52150
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 4.70453

Cumulative Model Updates: 101,608
Cumulative Timesteps: 847,415,042

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.62889
Policy Entropy: 3.16807
Value Function Loss: 0.00486

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.55224
Value Function Update Magnitude: 0.64644

Collected Steps per Second: 23,096.68195
Overall Steps per Second: 10,832.09318

Timestep Collection Time: 2.16499
Timestep Consumption Time: 2.45130
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.61628

Cumulative Model Updates: 101,614
Cumulative Timesteps: 847,465,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 847465046...
Checkpoint 847465046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.14257
Policy Entropy: 3.17384
Value Function Loss: 0.00495

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.08664
Policy Update Magnitude: 0.55120
Value Function Update Magnitude: 0.66011

Collected Steps per Second: 22,863.06427
Overall Steps per Second: 10,707.96949

Timestep Collection Time: 2.18790
Timestep Consumption Time: 2.48358
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.67147

Cumulative Model Updates: 101,620
Cumulative Timesteps: 847,515,068

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.31968
Policy Entropy: 3.17108
Value Function Loss: 0.00463

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.54427
Value Function Update Magnitude: 0.65591

Collected Steps per Second: 23,003.94024
Overall Steps per Second: 10,698.38648

Timestep Collection Time: 2.17441
Timestep Consumption Time: 2.50106
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.67547

Cumulative Model Updates: 101,626
Cumulative Timesteps: 847,565,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 847565088...
Checkpoint 847565088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.05762
Policy Entropy: 3.15851
Value Function Loss: 0.00438

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.53693
Value Function Update Magnitude: 0.63527

Collected Steps per Second: 22,268.64914
Overall Steps per Second: 10,729.09367

Timestep Collection Time: 2.24549
Timestep Consumption Time: 2.41511
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.66060

Cumulative Model Updates: 101,632
Cumulative Timesteps: 847,615,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.17261
Policy Entropy: 3.15375
Value Function Loss: 0.00430

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09271
Policy Update Magnitude: 0.53790
Value Function Update Magnitude: 0.61885

Collected Steps per Second: 22,204.12964
Overall Steps per Second: 10,643.37364

Timestep Collection Time: 2.25273
Timestep Consumption Time: 2.44690
PPO Batch Consumption Time: 0.29532
Total Iteration Time: 4.69964

Cumulative Model Updates: 101,638
Cumulative Timesteps: 847,665,112

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 847665112...
Checkpoint 847665112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.34272
Policy Entropy: 3.15127
Value Function Loss: 0.00458

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.54750
Value Function Update Magnitude: 0.62682

Collected Steps per Second: 21,597.15228
Overall Steps per Second: 10,591.24471

Timestep Collection Time: 2.31632
Timestep Consumption Time: 2.40701
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.72334

Cumulative Model Updates: 101,644
Cumulative Timesteps: 847,715,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,638.61331
Policy Entropy: 3.14382
Value Function Loss: 0.00481

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09342
Policy Update Magnitude: 0.55564
Value Function Update Magnitude: 0.62567

Collected Steps per Second: 22,376.27767
Overall Steps per Second: 10,837.80421

Timestep Collection Time: 2.23576
Timestep Consumption Time: 2.38030
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.61606

Cumulative Model Updates: 101,650
Cumulative Timesteps: 847,765,166

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 847765166...
Checkpoint 847765166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.74950
Policy Entropy: 3.13808
Value Function Loss: 0.00499

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.55635
Value Function Update Magnitude: 0.63196

Collected Steps per Second: 22,656.00619
Overall Steps per Second: 10,757.60774

Timestep Collection Time: 2.20807
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.65029

Cumulative Model Updates: 101,656
Cumulative Timesteps: 847,815,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.10361
Policy Entropy: 3.13583
Value Function Loss: 0.00490

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.56195
Value Function Update Magnitude: 0.63776

Collected Steps per Second: 22,478.76855
Overall Steps per Second: 10,855.80517

Timestep Collection Time: 2.22477
Timestep Consumption Time: 2.38199
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.60675

Cumulative Model Updates: 101,662
Cumulative Timesteps: 847,865,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 847865202...
Checkpoint 847865202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.76450
Policy Entropy: 3.13527
Value Function Loss: 0.00476

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.56043
Value Function Update Magnitude: 0.63472

Collected Steps per Second: 21,762.69944
Overall Steps per Second: 10,734.50876

Timestep Collection Time: 2.29751
Timestep Consumption Time: 2.36037
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.65787

Cumulative Model Updates: 101,668
Cumulative Timesteps: 847,915,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,571.82806
Policy Entropy: 3.13577
Value Function Loss: 0.00471

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09120
Policy Update Magnitude: 0.54883
Value Function Update Magnitude: 0.61835

Collected Steps per Second: 21,803.22679
Overall Steps per Second: 10,572.13934

Timestep Collection Time: 2.29342
Timestep Consumption Time: 2.43637
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.72979

Cumulative Model Updates: 101,674
Cumulative Timesteps: 847,965,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 847965206...
Checkpoint 847965206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.58235
Policy Entropy: 3.13373
Value Function Loss: 0.00484

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.55579
Value Function Update Magnitude: 0.60889

Collected Steps per Second: 22,110.69919
Overall Steps per Second: 10,694.41816

Timestep Collection Time: 2.26225
Timestep Consumption Time: 2.41495
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.67721

Cumulative Model Updates: 101,680
Cumulative Timesteps: 848,015,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.33095
Policy Entropy: 3.11512
Value Function Loss: 0.00481

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09460
Policy Update Magnitude: 0.55874
Value Function Update Magnitude: 0.60550

Collected Steps per Second: 23,100.53341
Overall Steps per Second: 10,684.10500

Timestep Collection Time: 2.16558
Timestep Consumption Time: 2.51671
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.68228

Cumulative Model Updates: 101,686
Cumulative Timesteps: 848,065,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 848065252...
Checkpoint 848065252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 869.70364
Policy Entropy: 3.10232
Value Function Loss: 0.00510

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.62751

Collected Steps per Second: 22,797.39428
Overall Steps per Second: 10,633.30579

Timestep Collection Time: 2.19350
Timestep Consumption Time: 2.50927
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.70277

Cumulative Model Updates: 101,692
Cumulative Timesteps: 848,115,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.60715
Policy Entropy: 3.10096
Value Function Loss: 0.00494

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.57200
Value Function Update Magnitude: 0.64535

Collected Steps per Second: 23,010.73693
Overall Steps per Second: 10,804.55937

Timestep Collection Time: 2.17299
Timestep Consumption Time: 2.45488
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.62786

Cumulative Model Updates: 101,698
Cumulative Timesteps: 848,165,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 848165260...
Checkpoint 848165260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.02946
Policy Entropy: 3.10534
Value Function Loss: 0.00527

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.57513
Value Function Update Magnitude: 0.64844

Collected Steps per Second: 22,723.62409
Overall Steps per Second: 10,779.46045

Timestep Collection Time: 2.20132
Timestep Consumption Time: 2.43917
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.64049

Cumulative Model Updates: 101,704
Cumulative Timesteps: 848,215,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.38132
Policy Entropy: 3.10747
Value Function Loss: 0.00528

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.57692
Value Function Update Magnitude: 0.65251

Collected Steps per Second: 23,324.19493
Overall Steps per Second: 10,916.44198

Timestep Collection Time: 2.14421
Timestep Consumption Time: 2.43714
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.58135

Cumulative Model Updates: 101,710
Cumulative Timesteps: 848,265,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 848265294...
Checkpoint 848265294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.92856
Policy Entropy: 3.11282
Value Function Loss: 0.00522

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11137
Policy Update Magnitude: 0.60717
Value Function Update Magnitude: 0.67380

Collected Steps per Second: 22,674.25050
Overall Steps per Second: 10,602.03675

Timestep Collection Time: 2.20585
Timestep Consumption Time: 2.51173
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.71758

Cumulative Model Updates: 101,716
Cumulative Timesteps: 848,315,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 981.42908
Policy Entropy: 3.12149
Value Function Loss: 0.00538

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.11152
Policy Update Magnitude: 0.59944
Value Function Update Magnitude: 0.68847

Collected Steps per Second: 23,074.40381
Overall Steps per Second: 10,835.65733

Timestep Collection Time: 2.16699
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.61458

Cumulative Model Updates: 101,722
Cumulative Timesteps: 848,365,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 848365312...
Checkpoint 848365312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591.92785
Policy Entropy: 3.11432
Value Function Loss: 0.00560

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.58631
Value Function Update Magnitude: 0.69220

Collected Steps per Second: 22,612.07858
Overall Steps per Second: 10,758.61027

Timestep Collection Time: 2.21121
Timestep Consumption Time: 2.43623
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.64744

Cumulative Model Updates: 101,728
Cumulative Timesteps: 848,415,312

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404.54421
Policy Entropy: 3.09993
Value Function Loss: 0.00557

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10495
Policy Update Magnitude: 0.58191
Value Function Update Magnitude: 0.69679

Collected Steps per Second: 23,265.50553
Overall Steps per Second: 10,856.99118

Timestep Collection Time: 2.14979
Timestep Consumption Time: 2.45701
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.60680

Cumulative Model Updates: 101,734
Cumulative Timesteps: 848,465,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 848465328...
Checkpoint 848465328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.29275
Policy Entropy: 3.10518
Value Function Loss: 0.00527

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11571
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.65949

Collected Steps per Second: 22,536.36698
Overall Steps per Second: 10,654.42518

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.69364

Cumulative Model Updates: 101,740
Cumulative Timesteps: 848,515,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.45763
Policy Entropy: 3.09984
Value Function Loss: 0.00496

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10542
Policy Update Magnitude: 0.56732
Value Function Update Magnitude: 0.62949

Collected Steps per Second: 22,855.66970
Overall Steps per Second: 10,649.04459

Timestep Collection Time: 2.18773
Timestep Consumption Time: 2.50772
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.69544

Cumulative Model Updates: 101,746
Cumulative Timesteps: 848,565,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 848565338...
Checkpoint 848565338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.51616
Policy Entropy: 3.09244
Value Function Loss: 0.00497

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.56160
Value Function Update Magnitude: 0.60979

Collected Steps per Second: 22,888.49263
Overall Steps per Second: 10,839.07892

Timestep Collection Time: 2.18555
Timestep Consumption Time: 2.42960
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.61515

Cumulative Model Updates: 101,752
Cumulative Timesteps: 848,615,362

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.61433
Policy Entropy: 3.10088
Value Function Loss: 0.00478

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.59190

Collected Steps per Second: 22,992.46035
Overall Steps per Second: 10,679.95500

Timestep Collection Time: 2.17584
Timestep Consumption Time: 2.50845
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.68429

Cumulative Model Updates: 101,758
Cumulative Timesteps: 848,665,390

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 848665390...
Checkpoint 848665390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,853.86374
Policy Entropy: 3.10770
Value Function Loss: 0.00493

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09146
Policy Update Magnitude: 0.55788
Value Function Update Magnitude: 0.58925

Collected Steps per Second: 22,813.24087
Overall Steps per Second: 10,682.11980

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.49040
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.68334

Cumulative Model Updates: 101,764
Cumulative Timesteps: 848,715,418

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.56667
Policy Entropy: 3.11735
Value Function Loss: 0.00467

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10539
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 0.60635

Collected Steps per Second: 23,211.42701
Overall Steps per Second: 10,673.47794

Timestep Collection Time: 2.15489
Timestep Consumption Time: 2.53131
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.68620

Cumulative Model Updates: 101,770
Cumulative Timesteps: 848,765,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 848765436...
Checkpoint 848765436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.63871
Policy Entropy: 3.11720
Value Function Loss: 0.00473

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.61653

Collected Steps per Second: 22,762.79278
Overall Steps per Second: 10,646.45880

Timestep Collection Time: 2.19709
Timestep Consumption Time: 2.50043
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.69752

Cumulative Model Updates: 101,776
Cumulative Timesteps: 848,815,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.43914
Policy Entropy: 3.13735
Value Function Loss: 0.00461

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.55183
Value Function Update Magnitude: 0.62452

Collected Steps per Second: 23,007.16865
Overall Steps per Second: 10,835.55872

Timestep Collection Time: 2.17445
Timestep Consumption Time: 2.44257
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.61702

Cumulative Model Updates: 101,782
Cumulative Timesteps: 848,865,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 848865476...
Checkpoint 848865476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.89868
Policy Entropy: 3.15095
Value Function Loss: 0.00471

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10537
Policy Update Magnitude: 0.55058
Value Function Update Magnitude: 0.61839

Collected Steps per Second: 22,446.70523
Overall Steps per Second: 10,692.90714

Timestep Collection Time: 2.22785
Timestep Consumption Time: 2.44889
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.67675

Cumulative Model Updates: 101,788
Cumulative Timesteps: 848,915,484

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.83600
Policy Entropy: 3.15426
Value Function Loss: 0.00483

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.55345
Value Function Update Magnitude: 0.61991

Collected Steps per Second: 23,014.96290
Overall Steps per Second: 10,825.87102

Timestep Collection Time: 2.17328
Timestep Consumption Time: 2.44695
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.62023

Cumulative Model Updates: 101,794
Cumulative Timesteps: 848,965,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 848965502...
Checkpoint 848965502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.82194
Policy Entropy: 3.15004
Value Function Loss: 0.00501

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.56162
Value Function Update Magnitude: 0.61613

Collected Steps per Second: 22,560.27913
Overall Steps per Second: 10,696.69319

Timestep Collection Time: 2.21726
Timestep Consumption Time: 2.45914
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.67640

Cumulative Model Updates: 101,800
Cumulative Timesteps: 849,015,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.45715
Policy Entropy: 3.14760
Value Function Loss: 0.00492

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.08928
Policy Update Magnitude: 0.56902
Value Function Update Magnitude: 0.61224

Collected Steps per Second: 23,186.40128
Overall Steps per Second: 10,858.90108

Timestep Collection Time: 2.15687
Timestep Consumption Time: 2.44857
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.60544

Cumulative Model Updates: 101,806
Cumulative Timesteps: 849,065,534

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 849065534...
Checkpoint 849065534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.21899
Policy Entropy: 3.13513
Value Function Loss: 0.00495

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08874
Policy Update Magnitude: 0.56752
Value Function Update Magnitude: 0.62346

Collected Steps per Second: 22,316.97222
Overall Steps per Second: 10,666.10500

Timestep Collection Time: 2.24099
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.68887

Cumulative Model Updates: 101,812
Cumulative Timesteps: 849,115,546

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.49108
Policy Entropy: 3.15588
Value Function Loss: 0.00483

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08486
Policy Update Magnitude: 0.56348
Value Function Update Magnitude: 0.61937

Collected Steps per Second: 22,890.46243
Overall Steps per Second: 10,630.71878

Timestep Collection Time: 2.18449
Timestep Consumption Time: 2.51924
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.70373

Cumulative Model Updates: 101,818
Cumulative Timesteps: 849,165,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 849165550...
Checkpoint 849165550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.78259
Policy Entropy: 3.15431
Value Function Loss: 0.00496

Mean KL Divergence: 0.00786
SB3 Clip Fraction: 0.08455
Policy Update Magnitude: 0.56637
Value Function Update Magnitude: 0.63426

Collected Steps per Second: 22,689.50061
Overall Steps per Second: 10,591.20484

Timestep Collection Time: 2.20437
Timestep Consumption Time: 2.51804
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.72241

Cumulative Model Updates: 101,824
Cumulative Timesteps: 849,215,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.03749
Policy Entropy: 3.17061
Value Function Loss: 0.00490

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.63564

Collected Steps per Second: 23,116.23486
Overall Steps per Second: 10,816.67356

Timestep Collection Time: 2.16341
Timestep Consumption Time: 2.46000
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.62342

Cumulative Model Updates: 101,830
Cumulative Timesteps: 849,265,576

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 849265576...
Checkpoint 849265576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.46520
Policy Entropy: 3.16010
Value Function Loss: 0.00501

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.56493
Value Function Update Magnitude: 0.65043

Collected Steps per Second: 22,748.40948
Overall Steps per Second: 10,651.23605

Timestep Collection Time: 2.19813
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.69467

Cumulative Model Updates: 101,836
Cumulative Timesteps: 849,315,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911.31389
Policy Entropy: 3.16100
Value Function Loss: 0.00484

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09187
Policy Update Magnitude: 0.56923
Value Function Update Magnitude: 0.63619

Collected Steps per Second: 22,701.69818
Overall Steps per Second: 10,711.23642

Timestep Collection Time: 2.20301
Timestep Consumption Time: 2.46611
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.66912

Cumulative Model Updates: 101,842
Cumulative Timesteps: 849,365,592

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 849365592...
Checkpoint 849365592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.16876
Policy Entropy: 3.15235
Value Function Loss: 0.00482

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08698
Policy Update Magnitude: 0.56770
Value Function Update Magnitude: 0.61845

Collected Steps per Second: 23,041.46935
Overall Steps per Second: 10,898.15710

Timestep Collection Time: 2.17069
Timestep Consumption Time: 2.41870
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.58940

Cumulative Model Updates: 101,848
Cumulative Timesteps: 849,415,608

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.65210
Policy Entropy: 3.15448
Value Function Loss: 0.00505

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08394
Policy Update Magnitude: 0.56895
Value Function Update Magnitude: 0.61610

Collected Steps per Second: 23,026.31140
Overall Steps per Second: 10,877.23445

Timestep Collection Time: 2.17221
Timestep Consumption Time: 2.42620
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.59841

Cumulative Model Updates: 101,854
Cumulative Timesteps: 849,465,626

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 849465626...
Checkpoint 849465626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.89829
Policy Entropy: 3.17768
Value Function Loss: 0.00499

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08624
Policy Update Magnitude: 0.56844
Value Function Update Magnitude: 0.62318

Collected Steps per Second: 22,654.16506
Overall Steps per Second: 10,628.10236

Timestep Collection Time: 2.20798
Timestep Consumption Time: 2.49841
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.70639

Cumulative Model Updates: 101,860
Cumulative Timesteps: 849,515,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.81363
Policy Entropy: 3.15922
Value Function Loss: 0.00520

Mean KL Divergence: 0.00768
SB3 Clip Fraction: 0.08369
Policy Update Magnitude: 0.56893
Value Function Update Magnitude: 0.62606

Collected Steps per Second: 23,015.77316
Overall Steps per Second: 10,879.39618

Timestep Collection Time: 2.17294
Timestep Consumption Time: 2.42400
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.59695

Cumulative Model Updates: 101,866
Cumulative Timesteps: 849,565,658

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 849565658...
Checkpoint 849565658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721.09427
Policy Entropy: 3.15765
Value Function Loss: 0.00519

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08269
Policy Update Magnitude: 0.57052
Value Function Update Magnitude: 0.63634

Collected Steps per Second: 22,655.18373
Overall Steps per Second: 10,646.54010

Timestep Collection Time: 2.20797
Timestep Consumption Time: 2.49046
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.69843

Cumulative Model Updates: 101,872
Cumulative Timesteps: 849,615,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.21942
Policy Entropy: 3.14337
Value Function Loss: 0.00528

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08745
Policy Update Magnitude: 0.57035
Value Function Update Magnitude: 0.63294

Collected Steps per Second: 22,801.41504
Overall Steps per Second: 10,679.91905

Timestep Collection Time: 2.19372
Timestep Consumption Time: 2.48983
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.68356

Cumulative Model Updates: 101,878
Cumulative Timesteps: 849,665,700

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 849665700...
Checkpoint 849665700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.49679
Policy Entropy: 3.15278
Value Function Loss: 0.00499

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.56499
Value Function Update Magnitude: 0.62989

Collected Steps per Second: 22,593.37646
Overall Steps per Second: 10,802.48917

Timestep Collection Time: 2.21357
Timestep Consumption Time: 2.41610
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.62967

Cumulative Model Updates: 101,884
Cumulative Timesteps: 849,715,712

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.54874
Policy Entropy: 3.15233
Value Function Loss: 0.00502

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.55789
Value Function Update Magnitude: 0.63462

Collected Steps per Second: 22,489.47169
Overall Steps per Second: 10,578.88670

Timestep Collection Time: 2.22460
Timestep Consumption Time: 2.50463
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.72923

Cumulative Model Updates: 101,890
Cumulative Timesteps: 849,765,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 849765742...
Checkpoint 849765742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.75466
Policy Entropy: 3.16471
Value Function Loss: 0.00499

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10662
Policy Update Magnitude: 0.55415
Value Function Update Magnitude: 0.62291

Collected Steps per Second: 22,626.18496
Overall Steps per Second: 10,589.86864

Timestep Collection Time: 2.21001
Timestep Consumption Time: 2.51187
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.72187

Cumulative Model Updates: 101,896
Cumulative Timesteps: 849,815,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.65319
Policy Entropy: 3.16062
Value Function Loss: 0.00485

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.61778

Collected Steps per Second: 22,650.23616
Overall Steps per Second: 10,649.24874

Timestep Collection Time: 2.20775
Timestep Consumption Time: 2.48798
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.69573

Cumulative Model Updates: 101,902
Cumulative Timesteps: 849,865,752

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 849865752...
Checkpoint 849865752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.33727
Policy Entropy: 3.15164
Value Function Loss: 0.00463

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09157
Policy Update Magnitude: 0.54660
Value Function Update Magnitude: 0.62777

Collected Steps per Second: 22,850.42441
Overall Steps per Second: 10,844.67619

Timestep Collection Time: 2.18928
Timestep Consumption Time: 2.42367
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.61295

Cumulative Model Updates: 101,908
Cumulative Timesteps: 849,915,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.89630
Policy Entropy: 3.16323
Value Function Loss: 0.00457

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.54428
Value Function Update Magnitude: 0.64440

Collected Steps per Second: 22,803.53928
Overall Steps per Second: 10,662.32520

Timestep Collection Time: 2.19282
Timestep Consumption Time: 2.49697
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.68978

Cumulative Model Updates: 101,914
Cumulative Timesteps: 849,965,782

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 849965782...
Checkpoint 849965782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,329.39266
Policy Entropy: 3.16925
Value Function Loss: 0.00470

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09366
Policy Update Magnitude: 0.55329
Value Function Update Magnitude: 0.64564

Collected Steps per Second: 22,900.81335
Overall Steps per Second: 10,854.83744

Timestep Collection Time: 2.18342
Timestep Consumption Time: 2.42301
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.60643

Cumulative Model Updates: 101,920
Cumulative Timesteps: 850,015,784

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.95815
Policy Entropy: 3.17667
Value Function Loss: 0.00497

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08612
Policy Update Magnitude: 0.55750
Value Function Update Magnitude: 0.64267

Collected Steps per Second: 22,708.62316
Overall Steps per Second: 10,673.85944

Timestep Collection Time: 2.20295
Timestep Consumption Time: 2.48383
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.68678

Cumulative Model Updates: 101,926
Cumulative Timesteps: 850,065,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 850065810...
Checkpoint 850065810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.09668
Policy Entropy: 3.17587
Value Function Loss: 0.00469

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09056
Policy Update Magnitude: 0.56158
Value Function Update Magnitude: 0.65013

Collected Steps per Second: 22,762.52154
Overall Steps per Second: 10,662.79405

Timestep Collection Time: 2.19756
Timestep Consumption Time: 2.49371
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.69127

Cumulative Model Updates: 101,932
Cumulative Timesteps: 850,115,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.94048
Policy Entropy: 3.18432
Value Function Loss: 0.00454

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08393
Policy Update Magnitude: 0.54989
Value Function Update Magnitude: 0.64201

Collected Steps per Second: 23,096.05008
Overall Steps per Second: 10,750.87058

Timestep Collection Time: 2.16557
Timestep Consumption Time: 2.48671
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.65227

Cumulative Model Updates: 101,938
Cumulative Timesteps: 850,165,848

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 850165848...
Checkpoint 850165848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 901.31529
Policy Entropy: 3.19859
Value Function Loss: 0.00448

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08628
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.61445

Collected Steps per Second: 22,625.76397
Overall Steps per Second: 10,628.61753

Timestep Collection Time: 2.21040
Timestep Consumption Time: 2.49501
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.70541

Cumulative Model Updates: 101,944
Cumulative Timesteps: 850,215,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.46278
Policy Entropy: 3.18294
Value Function Loss: 0.00476

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08832
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.60533

Collected Steps per Second: 22,964.43126
Overall Steps per Second: 10,825.43955

Timestep Collection Time: 2.17763
Timestep Consumption Time: 2.44186
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.61949

Cumulative Model Updates: 101,950
Cumulative Timesteps: 850,265,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 850265868...
Checkpoint 850265868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.93581
Policy Entropy: 3.17660
Value Function Loss: 0.00493

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.54902
Value Function Update Magnitude: 0.62484

Collected Steps per Second: 22,542.13159
Overall Steps per Second: 10,800.51507

Timestep Collection Time: 2.21825
Timestep Consumption Time: 2.41153
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.62978

Cumulative Model Updates: 101,956
Cumulative Timesteps: 850,315,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.25363
Policy Entropy: 3.17031
Value Function Loss: 0.00492

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.54866
Value Function Update Magnitude: 0.63814

Collected Steps per Second: 23,000.42525
Overall Steps per Second: 10,864.09662

Timestep Collection Time: 2.17474
Timestep Consumption Time: 2.42941
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.60416

Cumulative Model Updates: 101,962
Cumulative Timesteps: 850,365,892

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 850365892...
Checkpoint 850365892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.93889
Policy Entropy: 3.18014
Value Function Loss: 0.00471

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.54484
Value Function Update Magnitude: 0.63985

Collected Steps per Second: 22,634.57224
Overall Steps per Second: 10,641.61594

Timestep Collection Time: 2.20936
Timestep Consumption Time: 2.48992
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.69929

Cumulative Model Updates: 101,968
Cumulative Timesteps: 850,415,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.25457
Policy Entropy: 3.17297
Value Function Loss: 0.00491

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.54158
Value Function Update Magnitude: 0.61013

Collected Steps per Second: 22,886.30269
Overall Steps per Second: 10,836.18553

Timestep Collection Time: 2.18524
Timestep Consumption Time: 2.43004
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.61528

Cumulative Model Updates: 101,974
Cumulative Timesteps: 850,465,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 850465912...
Checkpoint 850465912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.60793
Policy Entropy: 3.16710
Value Function Loss: 0.00502

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.08742
Policy Update Magnitude: 0.55247
Value Function Update Magnitude: 0.61768

Collected Steps per Second: 22,294.71056
Overall Steps per Second: 10,710.49862

Timestep Collection Time: 2.24367
Timestep Consumption Time: 2.42670
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.67037

Cumulative Model Updates: 101,980
Cumulative Timesteps: 850,515,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 987.28835
Policy Entropy: 3.14770
Value Function Loss: 0.00496

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08934
Policy Update Magnitude: 0.56095
Value Function Update Magnitude: 0.61227

Collected Steps per Second: 22,890.95777
Overall Steps per Second: 10,833.46068

Timestep Collection Time: 2.18453
Timestep Consumption Time: 2.43135
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.61588

Cumulative Model Updates: 101,986
Cumulative Timesteps: 850,565,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 850565940...
Checkpoint 850565940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.00175
Policy Entropy: 3.15960
Value Function Loss: 0.00484

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.55941
Value Function Update Magnitude: 0.60436

Collected Steps per Second: 22,587.86559
Overall Steps per Second: 10,698.23131

Timestep Collection Time: 2.21482
Timestep Consumption Time: 2.46147
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.67629

Cumulative Model Updates: 101,992
Cumulative Timesteps: 850,615,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.09011
Policy Entropy: 3.15298
Value Function Loss: 0.00469

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.08644
Policy Update Magnitude: 0.55239
Value Function Update Magnitude: 0.60337

Collected Steps per Second: 22,904.59535
Overall Steps per Second: 10,857.52765

Timestep Collection Time: 2.18410
Timestep Consumption Time: 2.42339
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.60749

Cumulative Model Updates: 101,998
Cumulative Timesteps: 850,665,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 850665994...
Checkpoint 850665994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.77260
Policy Entropy: 3.15715
Value Function Loss: 0.00477

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.09152
Policy Update Magnitude: 0.55441
Value Function Update Magnitude: 0.60089

Collected Steps per Second: 22,606.95461
Overall Steps per Second: 10,700.94689

Timestep Collection Time: 2.21277
Timestep Consumption Time: 2.46196
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.67473

Cumulative Model Updates: 102,004
Cumulative Timesteps: 850,716,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.41954
Policy Entropy: 3.15538
Value Function Loss: 0.00494

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.55772
Value Function Update Magnitude: 0.59042

Collected Steps per Second: 22,978.39190
Overall Steps per Second: 10,856.83289

Timestep Collection Time: 2.17683
Timestep Consumption Time: 2.43041
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.60724

Cumulative Model Updates: 102,010
Cumulative Timesteps: 850,766,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 850766038...
Checkpoint 850766038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 815.26365
Policy Entropy: 3.17623
Value Function Loss: 0.00496

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09576
Policy Update Magnitude: 0.56020
Value Function Update Magnitude: 0.60031

Collected Steps per Second: 22,716.27169
Overall Steps per Second: 10,687.90943

Timestep Collection Time: 2.20186
Timestep Consumption Time: 2.47801
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.67987

Cumulative Model Updates: 102,016
Cumulative Timesteps: 850,816,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,901.95475
Policy Entropy: 3.17960
Value Function Loss: 0.00482

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.55429
Value Function Update Magnitude: 0.59861

Collected Steps per Second: 22,935.64418
Overall Steps per Second: 10,762.37220

Timestep Collection Time: 2.18132
Timestep Consumption Time: 2.46728
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.64860

Cumulative Model Updates: 102,022
Cumulative Timesteps: 850,866,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 850866086...
Checkpoint 850866086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.15675
Policy Entropy: 3.18229
Value Function Loss: 0.00457

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08399
Policy Update Magnitude: 0.55576
Value Function Update Magnitude: 0.60773

Collected Steps per Second: 22,749.19124
Overall Steps per Second: 10,853.21496

Timestep Collection Time: 2.19885
Timestep Consumption Time: 2.41011
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.60896

Cumulative Model Updates: 102,028
Cumulative Timesteps: 850,916,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.03484
Policy Entropy: 3.18475
Value Function Loss: 0.00460

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.55098
Value Function Update Magnitude: 0.59801

Collected Steps per Second: 23,179.62906
Overall Steps per Second: 10,856.02542

Timestep Collection Time: 2.15827
Timestep Consumption Time: 2.45004
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 4.60832

Cumulative Model Updates: 102,034
Cumulative Timesteps: 850,966,136

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 850966136...
Checkpoint 850966136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.32104
Policy Entropy: 3.17189
Value Function Loss: 0.00481

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09191
Policy Update Magnitude: 0.55781
Value Function Update Magnitude: 0.59357

Collected Steps per Second: 22,816.81923
Overall Steps per Second: 10,646.14370

Timestep Collection Time: 2.19198
Timestep Consumption Time: 2.50587
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.69785

Cumulative Model Updates: 102,040
Cumulative Timesteps: 851,016,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.58110
Policy Entropy: 3.14820
Value Function Loss: 0.00495

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09758
Policy Update Magnitude: 0.56514
Value Function Update Magnitude: 0.61575

Collected Steps per Second: 23,045.17164
Overall Steps per Second: 10,854.76136

Timestep Collection Time: 2.17078
Timestep Consumption Time: 2.43789
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.60867

Cumulative Model Updates: 102,046
Cumulative Timesteps: 851,066,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 851066176...
Checkpoint 851066176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 943.41858
Policy Entropy: 3.14358
Value Function Loss: 0.00482

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.56494
Value Function Update Magnitude: 0.61728

Collected Steps per Second: 22,736.69537
Overall Steps per Second: 10,627.27828

Timestep Collection Time: 2.20094
Timestep Consumption Time: 2.50789
PPO Batch Consumption Time: 0.29603
Total Iteration Time: 4.70883

Cumulative Model Updates: 102,052
Cumulative Timesteps: 851,116,218

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.66843
Policy Entropy: 3.14494
Value Function Loss: 0.00496

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.56491
Value Function Update Magnitude: 0.60166

Collected Steps per Second: 22,617.90261
Overall Steps per Second: 10,868.41821

Timestep Collection Time: 2.21126
Timestep Consumption Time: 2.39052
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.60177

Cumulative Model Updates: 102,058
Cumulative Timesteps: 851,166,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 851166232...
Checkpoint 851166232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 872.23644
Policy Entropy: 3.15727
Value Function Loss: 0.00506

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09394
Policy Update Magnitude: 0.56779
Value Function Update Magnitude: 0.60301

Collected Steps per Second: 22,418.01117
Overall Steps per Second: 10,742.10108

Timestep Collection Time: 2.23035
Timestep Consumption Time: 2.42423
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.65458

Cumulative Model Updates: 102,064
Cumulative Timesteps: 851,216,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.40621
Policy Entropy: 3.16381
Value Function Loss: 0.00492

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.55584
Value Function Update Magnitude: 0.61370

Collected Steps per Second: 21,926.64821
Overall Steps per Second: 10,642.23489

Timestep Collection Time: 2.28042
Timestep Consumption Time: 2.41803
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.69845

Cumulative Model Updates: 102,070
Cumulative Timesteps: 851,266,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 851266234...
Checkpoint 851266234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.05325
Policy Entropy: 3.17041
Value Function Loss: 0.00481

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.55133
Value Function Update Magnitude: 0.60432

Collected Steps per Second: 22,291.76991
Overall Steps per Second: 10,821.85139

Timestep Collection Time: 2.24361
Timestep Consumption Time: 2.37797
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.62158

Cumulative Model Updates: 102,076
Cumulative Timesteps: 851,316,248

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.47689
Policy Entropy: 3.17282
Value Function Loss: 0.00449

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09222
Policy Update Magnitude: 0.55174
Value Function Update Magnitude: 0.58568

Collected Steps per Second: 22,254.20737
Overall Steps per Second: 10,737.98109

Timestep Collection Time: 2.24695
Timestep Consumption Time: 2.40980
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.65674

Cumulative Model Updates: 102,082
Cumulative Timesteps: 851,366,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 851366252...
Checkpoint 851366252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.09348
Policy Entropy: 3.16174
Value Function Loss: 0.00461

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08490
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.58445

Collected Steps per Second: 22,355.63583
Overall Steps per Second: 10,836.71369

Timestep Collection Time: 2.23702
Timestep Consumption Time: 2.37785
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.61487

Cumulative Model Updates: 102,088
Cumulative Timesteps: 851,416,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748.31727
Policy Entropy: 3.16350
Value Function Loss: 0.00464

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.56044
Value Function Update Magnitude: 0.59282

Collected Steps per Second: 22,051.62263
Overall Steps per Second: 10,622.20463

Timestep Collection Time: 2.26840
Timestep Consumption Time: 2.44079
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.70919

Cumulative Model Updates: 102,094
Cumulative Timesteps: 851,466,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 851466284...
Checkpoint 851466284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,839.01186
Policy Entropy: 3.15738
Value Function Loss: 0.00503

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08938
Policy Update Magnitude: 0.56000
Value Function Update Magnitude: 0.61411

Collected Steps per Second: 22,127.10376
Overall Steps per Second: 10,696.25037

Timestep Collection Time: 2.26067
Timestep Consumption Time: 2.41593
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.67659

Cumulative Model Updates: 102,100
Cumulative Timesteps: 851,516,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.17615
Policy Entropy: 3.16643
Value Function Loss: 0.00468

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.55852
Value Function Update Magnitude: 0.61744

Collected Steps per Second: 22,626.71997
Overall Steps per Second: 10,740.31371

Timestep Collection Time: 2.21040
Timestep Consumption Time: 2.44627
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.65666

Cumulative Model Updates: 102,106
Cumulative Timesteps: 851,566,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 851566320...
Checkpoint 851566320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.57988
Policy Entropy: 3.17026
Value Function Loss: 0.00477

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09004
Policy Update Magnitude: 0.55755
Value Function Update Magnitude: 0.59756

Collected Steps per Second: 22,137.73858
Overall Steps per Second: 10,632.29563

Timestep Collection Time: 2.25877
Timestep Consumption Time: 2.44426
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.70303

Cumulative Model Updates: 102,112
Cumulative Timesteps: 851,616,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.92478
Policy Entropy: 3.18063
Value Function Loss: 0.00448

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.55449
Value Function Update Magnitude: 0.59005

Collected Steps per Second: 22,371.27560
Overall Steps per Second: 10,802.38681

Timestep Collection Time: 2.23581
Timestep Consumption Time: 2.39446
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.63027

Cumulative Model Updates: 102,118
Cumulative Timesteps: 851,666,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 851666342...
Checkpoint 851666342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.81390
Policy Entropy: 3.17144
Value Function Loss: 0.00486

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09414
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.57901

Collected Steps per Second: 21,496.66870
Overall Steps per Second: 10,661.24651

Timestep Collection Time: 2.32622
Timestep Consumption Time: 2.36422
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.69045

Cumulative Model Updates: 102,124
Cumulative Timesteps: 851,716,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.00884
Policy Entropy: 3.17605
Value Function Loss: 0.00465

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09617
Policy Update Magnitude: 0.55482
Value Function Update Magnitude: 0.58240

Collected Steps per Second: 22,091.20998
Overall Steps per Second: 10,573.05788

Timestep Collection Time: 2.26534
Timestep Consumption Time: 2.46783
PPO Batch Consumption Time: 0.29618
Total Iteration Time: 4.73316

Cumulative Model Updates: 102,130
Cumulative Timesteps: 851,766,392

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 851766392...
Checkpoint 851766392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.47324
Policy Entropy: 3.17850
Value Function Loss: 0.00462

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.55443
Value Function Update Magnitude: 0.57724

Collected Steps per Second: 23,152.68292
Overall Steps per Second: 10,680.14798

Timestep Collection Time: 2.15975
Timestep Consumption Time: 2.52221
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.68196

Cumulative Model Updates: 102,136
Cumulative Timesteps: 851,816,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.19779
Policy Entropy: 3.19183
Value Function Loss: 0.00438

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.54856
Value Function Update Magnitude: 0.56423

Collected Steps per Second: 22,994.56973
Overall Steps per Second: 10,827.39678

Timestep Collection Time: 2.17451
Timestep Consumption Time: 2.44359
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.61810

Cumulative Model Updates: 102,142
Cumulative Timesteps: 851,866,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 851866398...
Checkpoint 851866398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.46874
Policy Entropy: 3.19382
Value Function Loss: 0.00447

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09254
Policy Update Magnitude: 0.54215
Value Function Update Magnitude: 0.58296

Collected Steps per Second: 21,829.91221
Overall Steps per Second: 10,651.80719

Timestep Collection Time: 2.29080
Timestep Consumption Time: 2.40399
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.69479

Cumulative Model Updates: 102,148
Cumulative Timesteps: 851,916,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.98156
Policy Entropy: 3.18382
Value Function Loss: 0.00487

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.55411
Value Function Update Magnitude: 0.59086

Collected Steps per Second: 22,824.68535
Overall Steps per Second: 10,706.43938

Timestep Collection Time: 2.19096
Timestep Consumption Time: 2.47987
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.67083

Cumulative Model Updates: 102,154
Cumulative Timesteps: 851,966,414

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 851966414...
Checkpoint 851966414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 674.47870
Policy Entropy: 3.17019
Value Function Loss: 0.00501

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10370
Policy Update Magnitude: 0.56595
Value Function Update Magnitude: 0.58673

Collected Steps per Second: 23,219.06956
Overall Steps per Second: 10,855.45843

Timestep Collection Time: 2.15461
Timestep Consumption Time: 2.45395
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.60856

Cumulative Model Updates: 102,160
Cumulative Timesteps: 852,016,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.51614
Policy Entropy: 3.17292
Value Function Loss: 0.00508

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10440
Policy Update Magnitude: 0.56283
Value Function Update Magnitude: 0.59227

Collected Steps per Second: 22,678.78698
Overall Steps per Second: 10,639.36442

Timestep Collection Time: 2.20585
Timestep Consumption Time: 2.49612
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.70197

Cumulative Model Updates: 102,166
Cumulative Timesteps: 852,066,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 852066468...
Checkpoint 852066468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,324.81400
Policy Entropy: 3.18215
Value Function Loss: 0.00488

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.56124
Value Function Update Magnitude: 0.60415

Collected Steps per Second: 23,118.98523
Overall Steps per Second: 10,869.88241

Timestep Collection Time: 2.16385
Timestep Consumption Time: 2.43841
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.60226

Cumulative Model Updates: 102,172
Cumulative Timesteps: 852,116,494

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.62014
Policy Entropy: 3.18206
Value Function Loss: 0.00495

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10167
Policy Update Magnitude: 0.56020
Value Function Update Magnitude: 0.61513

Collected Steps per Second: 22,922.74430
Overall Steps per Second: 10,677.87036

Timestep Collection Time: 2.18211
Timestep Consumption Time: 2.50234
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.68445

Cumulative Model Updates: 102,178
Cumulative Timesteps: 852,166,514

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 852166514...
Checkpoint 852166514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.73312
Policy Entropy: 3.18282
Value Function Loss: 0.00477

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10126
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.61578

Collected Steps per Second: 23,030.64088
Overall Steps per Second: 10,813.01887

Timestep Collection Time: 2.17276
Timestep Consumption Time: 2.45500
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.62775

Cumulative Model Updates: 102,184
Cumulative Timesteps: 852,216,554

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,973.24161
Policy Entropy: 3.18280
Value Function Loss: 0.00459

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.54586
Value Function Update Magnitude: 0.60352

Collected Steps per Second: 22,460.10294
Overall Steps per Second: 10,557.75064

Timestep Collection Time: 2.22679
Timestep Consumption Time: 2.51039
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.73718

Cumulative Model Updates: 102,190
Cumulative Timesteps: 852,266,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 852266568...
Checkpoint 852266568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 937.25888
Policy Entropy: 3.18327
Value Function Loss: 0.00473

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.54819
Value Function Update Magnitude: 0.58591

Collected Steps per Second: 23,002.35581
Overall Steps per Second: 10,703.25112

Timestep Collection Time: 2.17369
Timestep Consumption Time: 2.49779
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.67148

Cumulative Model Updates: 102,196
Cumulative Timesteps: 852,316,568

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.38675
Policy Entropy: 3.19818
Value Function Loss: 0.00451

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.54591
Value Function Update Magnitude: 0.59073

Collected Steps per Second: 22,909.13385
Overall Steps per Second: 10,769.32731

Timestep Collection Time: 2.18306
Timestep Consumption Time: 2.46087
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.64393

Cumulative Model Updates: 102,202
Cumulative Timesteps: 852,366,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 852366580...
Checkpoint 852366580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.51899
Policy Entropy: 3.20422
Value Function Loss: 0.00463

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.53297
Value Function Update Magnitude: 0.59970

Collected Steps per Second: 23,144.89286
Overall Steps per Second: 10,659.90050

Timestep Collection Time: 2.16030
Timestep Consumption Time: 2.53017
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.69048

Cumulative Model Updates: 102,208
Cumulative Timesteps: 852,416,580

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.31045
Policy Entropy: 3.22039
Value Function Loss: 0.00441

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.52415
Value Function Update Magnitude: 0.60599

Collected Steps per Second: 23,000.66450
Overall Steps per Second: 10,688.22888

Timestep Collection Time: 2.17411
Timestep Consumption Time: 2.50449
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.67860

Cumulative Model Updates: 102,214
Cumulative Timesteps: 852,466,586

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 852466586...
Checkpoint 852466586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.29994
Policy Entropy: 3.21487
Value Function Loss: 0.00465

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09303
Policy Update Magnitude: 0.52886
Value Function Update Magnitude: 0.59012

Collected Steps per Second: 22,329.24623
Overall Steps per Second: 10,840.80325

Timestep Collection Time: 2.23966
Timestep Consumption Time: 2.37346
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.61313

Cumulative Model Updates: 102,220
Cumulative Timesteps: 852,516,596

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.74987
Policy Entropy: 3.20345
Value Function Loss: 0.00481

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.53874
Value Function Update Magnitude: 0.59570

Collected Steps per Second: 21,971.52171
Overall Steps per Second: 10,624.78417

Timestep Collection Time: 2.27649
Timestep Consumption Time: 2.43118
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.70767

Cumulative Model Updates: 102,226
Cumulative Timesteps: 852,566,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 852566614...
Checkpoint 852566614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.24287
Policy Entropy: 3.19447
Value Function Loss: 0.00465

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.53995
Value Function Update Magnitude: 0.60265

Collected Steps per Second: 22,294.89042
Overall Steps per Second: 10,702.14954

Timestep Collection Time: 2.24365
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.67401

Cumulative Model Updates: 102,232
Cumulative Timesteps: 852,616,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.50893
Policy Entropy: 3.19733
Value Function Loss: 0.00464

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.53870
Value Function Update Magnitude: 0.60001

Collected Steps per Second: 22,092.17548
Overall Steps per Second: 10,743.54299

Timestep Collection Time: 2.26433
Timestep Consumption Time: 2.39186
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.65619

Cumulative Model Updates: 102,238
Cumulative Timesteps: 852,666,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 852666660...
Checkpoint 852666660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.57429
Policy Entropy: 3.18997
Value Function Loss: 0.00438

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.53850
Value Function Update Magnitude: 0.59285

Collected Steps per Second: 22,005.04400
Overall Steps per Second: 10,626.97585

Timestep Collection Time: 2.27312
Timestep Consumption Time: 2.43377
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.70689

Cumulative Model Updates: 102,244
Cumulative Timesteps: 852,716,680

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.75854
Policy Entropy: 3.17280
Value Function Loss: 0.00451

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.53974
Value Function Update Magnitude: 0.61088

Collected Steps per Second: 22,903.34026
Overall Steps per Second: 10,775.35893

Timestep Collection Time: 2.18352
Timestep Consumption Time: 2.45762
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.64114

Cumulative Model Updates: 102,250
Cumulative Timesteps: 852,766,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 852766690...
Checkpoint 852766690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.48631
Policy Entropy: 3.17181
Value Function Loss: 0.00479

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.54755
Value Function Update Magnitude: 0.61442

Collected Steps per Second: 22,635.00126
Overall Steps per Second: 10,753.08373

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.44154
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.65113

Cumulative Model Updates: 102,256
Cumulative Timesteps: 852,816,704

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.50361
Policy Entropy: 3.16941
Value Function Loss: 0.00486

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.55453
Value Function Update Magnitude: 0.62353

Collected Steps per Second: 22,695.93833
Overall Steps per Second: 10,584.53409

Timestep Collection Time: 2.20321
Timestep Consumption Time: 2.52104
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.72425

Cumulative Model Updates: 102,262
Cumulative Timesteps: 852,866,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 852866708...
Checkpoint 852866708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 936.71219
Policy Entropy: 3.18108
Value Function Loss: 0.00486

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11510
Policy Update Magnitude: 0.54851
Value Function Update Magnitude: 0.60533

Collected Steps per Second: 22,845.67851
Overall Steps per Second: 10,681.51245

Timestep Collection Time: 2.18895
Timestep Consumption Time: 2.49279
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.68173

Cumulative Model Updates: 102,268
Cumulative Timesteps: 852,916,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.52338
Policy Entropy: 3.16381
Value Function Loss: 0.00492

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.54905
Value Function Update Magnitude: 0.59264

Collected Steps per Second: 23,035.89385
Overall Steps per Second: 10,735.13407

Timestep Collection Time: 2.17087
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.65835

Cumulative Model Updates: 102,274
Cumulative Timesteps: 852,966,724

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 852966724...
Checkpoint 852966724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.33463
Policy Entropy: 3.17437
Value Function Loss: 0.00475

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.55236
Value Function Update Magnitude: 0.59177

Collected Steps per Second: 22,491.74169
Overall Steps per Second: 10,670.22904

Timestep Collection Time: 2.22322
Timestep Consumption Time: 2.46309
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 4.68631

Cumulative Model Updates: 102,280
Cumulative Timesteps: 853,016,728

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.91189
Policy Entropy: 3.17830
Value Function Loss: 0.00460

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.55534
Value Function Update Magnitude: 0.59870

Collected Steps per Second: 21,989.80271
Overall Steps per Second: 10,767.65127

Timestep Collection Time: 2.27378
Timestep Consumption Time: 2.36976
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.64354

Cumulative Model Updates: 102,286
Cumulative Timesteps: 853,066,728

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 853066728...
Checkpoint 853066728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.82015
Policy Entropy: 3.17575
Value Function Loss: 0.00478

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10921
Policy Update Magnitude: 0.55257
Value Function Update Magnitude: 0.60220

Collected Steps per Second: 22,115.16824
Overall Steps per Second: 10,758.85348

Timestep Collection Time: 2.26143
Timestep Consumption Time: 2.38702
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.64845

Cumulative Model Updates: 102,292
Cumulative Timesteps: 853,116,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.47810
Policy Entropy: 3.17876
Value Function Loss: 0.00469

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.55581
Value Function Update Magnitude: 0.60784

Collected Steps per Second: 21,651.80958
Overall Steps per Second: 10,469.68052

Timestep Collection Time: 2.31057
Timestep Consumption Time: 2.46780
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.77837

Cumulative Model Updates: 102,298
Cumulative Timesteps: 853,166,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 853166768...
Checkpoint 853166768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 846.37856
Policy Entropy: 3.17880
Value Function Loss: 0.00475

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10948
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.59954

Collected Steps per Second: 22,201.64903
Overall Steps per Second: 10,654.38728

Timestep Collection Time: 2.25245
Timestep Consumption Time: 2.44121
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.69365

Cumulative Model Updates: 102,304
Cumulative Timesteps: 853,216,776

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,033.04330
Policy Entropy: 3.16200
Value Function Loss: 0.00470

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.54881
Value Function Update Magnitude: 0.58288

Collected Steps per Second: 22,553.99730
Overall Steps per Second: 10,905.76950

Timestep Collection Time: 2.21699
Timestep Consumption Time: 2.36792
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.58491

Cumulative Model Updates: 102,310
Cumulative Timesteps: 853,266,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 853266778...
Checkpoint 853266778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 870.60849
Policy Entropy: 3.16269
Value Function Loss: 0.00474

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09168
Policy Update Magnitude: 0.55017
Value Function Update Magnitude: 0.57605

Collected Steps per Second: 22,057.06835
Overall Steps per Second: 10,613.08664

Timestep Collection Time: 2.26766
Timestep Consumption Time: 2.44520
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.71286

Cumulative Model Updates: 102,316
Cumulative Timesteps: 853,316,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,720.00875
Policy Entropy: 3.15574
Value Function Loss: 0.00465

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.57783

Collected Steps per Second: 22,519.53925
Overall Steps per Second: 10,848.39677

Timestep Collection Time: 2.22109
Timestep Consumption Time: 2.38954
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.61064

Cumulative Model Updates: 102,322
Cumulative Timesteps: 853,366,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 853366814...
Checkpoint 853366814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.27839
Policy Entropy: 3.17042
Value Function Loss: 0.00473

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09192
Policy Update Magnitude: 0.54968
Value Function Update Magnitude: 0.58671

Collected Steps per Second: 22,809.00313
Overall Steps per Second: 10,692.03117

Timestep Collection Time: 2.19238
Timestep Consumption Time: 2.48456
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.67694

Cumulative Model Updates: 102,328
Cumulative Timesteps: 853,416,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.40066
Policy Entropy: 3.16388
Value Function Loss: 0.00463

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.55720
Value Function Update Magnitude: 0.58960

Collected Steps per Second: 22,889.36795
Overall Steps per Second: 10,623.89707

Timestep Collection Time: 2.18442
Timestep Consumption Time: 2.52195
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.70637

Cumulative Model Updates: 102,334
Cumulative Timesteps: 853,466,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 853466820...
Checkpoint 853466820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.46391
Policy Entropy: 3.15665
Value Function Loss: 0.00459

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.55589
Value Function Update Magnitude: 0.60923

Collected Steps per Second: 22,673.04450
Overall Steps per Second: 10,629.46859

Timestep Collection Time: 2.20570
Timestep Consumption Time: 2.49914
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.70484

Cumulative Model Updates: 102,340
Cumulative Timesteps: 853,516,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.73439
Policy Entropy: 3.16430
Value Function Loss: 0.00475

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.55438
Value Function Update Magnitude: 0.60633

Collected Steps per Second: 23,238.93694
Overall Steps per Second: 10,715.50706

Timestep Collection Time: 2.15182
Timestep Consumption Time: 2.51488
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.66669

Cumulative Model Updates: 102,346
Cumulative Timesteps: 853,566,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 853566836...
Checkpoint 853566836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.16873
Policy Entropy: 3.16577
Value Function Loss: 0.00471

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.55032
Value Function Update Magnitude: 0.60771

Collected Steps per Second: 23,169.31787
Overall Steps per Second: 10,695.20981

Timestep Collection Time: 2.15837
Timestep Consumption Time: 2.51737
PPO Batch Consumption Time: 0.29686
Total Iteration Time: 4.67574

Cumulative Model Updates: 102,352
Cumulative Timesteps: 853,616,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 850.87729
Policy Entropy: 3.14767
Value Function Loss: 0.00473

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09542
Policy Update Magnitude: 0.55275
Value Function Update Magnitude: 0.58740

Collected Steps per Second: 22,665.12732
Overall Steps per Second: 10,754.02911

Timestep Collection Time: 2.20674
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.65091

Cumulative Model Updates: 102,358
Cumulative Timesteps: 853,666,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 853666860...
Checkpoint 853666860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767.49948
Policy Entropy: 3.13704
Value Function Loss: 0.00459

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.55085
Value Function Update Magnitude: 0.56518

Collected Steps per Second: 22,912.42176
Overall Steps per Second: 10,783.05601

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.63857

Cumulative Model Updates: 102,364
Cumulative Timesteps: 853,716,878

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667.12716
Policy Entropy: 3.14477
Value Function Loss: 0.00461

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.54959
Value Function Update Magnitude: 0.55714

Collected Steps per Second: 22,849.28584
Overall Steps per Second: 10,791.14456

Timestep Collection Time: 2.18825
Timestep Consumption Time: 2.44518
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.63343

Cumulative Model Updates: 102,370
Cumulative Timesteps: 853,766,878

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 853766878...
Checkpoint 853766878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.64346
Policy Entropy: 3.14855
Value Function Loss: 0.00453

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.54660
Value Function Update Magnitude: 0.56348

Collected Steps per Second: 21,838.02313
Overall Steps per Second: 10,728.44917

Timestep Collection Time: 2.29032
Timestep Consumption Time: 2.37168
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.66200

Cumulative Model Updates: 102,376
Cumulative Timesteps: 853,816,894

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.01679
Policy Entropy: 3.14023
Value Function Loss: 0.00476

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.56783

Collected Steps per Second: 22,620.18568
Overall Steps per Second: 10,631.15419

Timestep Collection Time: 2.21042
Timestep Consumption Time: 2.49274
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.70316

Cumulative Model Updates: 102,382
Cumulative Timesteps: 853,866,894

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 853866894...
Checkpoint 853866894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.75312
Policy Entropy: 3.12563
Value Function Loss: 0.00477

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.55982
Value Function Update Magnitude: 0.55757

Collected Steps per Second: 23,052.47914
Overall Steps per Second: 10,826.25821

Timestep Collection Time: 2.16983
Timestep Consumption Time: 2.45042
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.62025

Cumulative Model Updates: 102,388
Cumulative Timesteps: 853,916,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.65813
Policy Entropy: 3.13983
Value Function Loss: 0.00477

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.56480
Value Function Update Magnitude: 0.57034

Collected Steps per Second: 23,155.36482
Overall Steps per Second: 10,850.55243

Timestep Collection Time: 2.15967
Timestep Consumption Time: 2.44913
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.60880

Cumulative Model Updates: 102,394
Cumulative Timesteps: 853,966,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 853966922...
Checkpoint 853966922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.97757
Policy Entropy: 3.14426
Value Function Loss: 0.00458

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.55735
Value Function Update Magnitude: 0.60300

Collected Steps per Second: 22,893.23956
Overall Steps per Second: 10,789.99363

Timestep Collection Time: 2.18492
Timestep Consumption Time: 2.45085
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.63578

Cumulative Model Updates: 102,400
Cumulative Timesteps: 854,016,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370.72433
Policy Entropy: 3.15027
Value Function Loss: 0.00442

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.55753
Value Function Update Magnitude: 0.59555

Collected Steps per Second: 22,027.82938
Overall Steps per Second: 10,675.03825

Timestep Collection Time: 2.27095
Timestep Consumption Time: 2.41513
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.68607

Cumulative Model Updates: 102,406
Cumulative Timesteps: 854,066,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 854066966...
Checkpoint 854066966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 945.05150
Policy Entropy: 3.15168
Value Function Loss: 0.00446

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09486
Policy Update Magnitude: 0.55138
Value Function Update Magnitude: 0.58773

Collected Steps per Second: 22,291.44759
Overall Steps per Second: 10,869.27842

Timestep Collection Time: 2.24346
Timestep Consumption Time: 2.35758
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.60104

Cumulative Model Updates: 102,412
Cumulative Timesteps: 854,116,976

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 990.94311
Policy Entropy: 3.14644
Value Function Loss: 0.00450

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.54636
Value Function Update Magnitude: 0.57834

Collected Steps per Second: 21,671.94615
Overall Steps per Second: 10,505.36347

Timestep Collection Time: 2.30796
Timestep Consumption Time: 2.45323
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.76119

Cumulative Model Updates: 102,418
Cumulative Timesteps: 854,166,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 854166994...
Checkpoint 854166994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.19940
Policy Entropy: 3.15577
Value Function Loss: 0.00436

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.54749
Value Function Update Magnitude: 0.57134

Collected Steps per Second: 22,344.48028
Overall Steps per Second: 10,714.04714

Timestep Collection Time: 2.23885
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.66920

Cumulative Model Updates: 102,424
Cumulative Timesteps: 854,217,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.23740
Policy Entropy: 3.13704
Value Function Loss: 0.00468

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.55254
Value Function Update Magnitude: 0.58073

Collected Steps per Second: 21,983.78907
Overall Steps per Second: 10,765.32795

Timestep Collection Time: 2.27513
Timestep Consumption Time: 2.37090
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.64603

Cumulative Model Updates: 102,430
Cumulative Timesteps: 854,267,036

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 854267036...
Checkpoint 854267036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.09477
Policy Entropy: 3.12961
Value Function Loss: 0.00461

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.55855
Value Function Update Magnitude: 0.59817

Collected Steps per Second: 22,734.47341
Overall Steps per Second: 10,644.88680

Timestep Collection Time: 2.19992
Timestep Consumption Time: 2.49849
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.69841

Cumulative Model Updates: 102,436
Cumulative Timesteps: 854,317,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.15127
Policy Entropy: 3.11671
Value Function Loss: 0.00475

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.56784
Value Function Update Magnitude: 0.59046

Collected Steps per Second: 22,864.38044
Overall Steps per Second: 10,675.01582

Timestep Collection Time: 2.18794
Timestep Consumption Time: 2.49832
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.68627

Cumulative Model Updates: 102,442
Cumulative Timesteps: 854,367,076

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 854367076...
Checkpoint 854367076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.77751
Policy Entropy: 3.13223
Value Function Loss: 0.00477

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.57031
Value Function Update Magnitude: 0.59303

Collected Steps per Second: 23,106.04780
Overall Steps per Second: 10,820.44522

Timestep Collection Time: 2.16480
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.62273

Cumulative Model Updates: 102,448
Cumulative Timesteps: 854,417,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758.76700
Policy Entropy: 3.15785
Value Function Loss: 0.00516

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.57218
Value Function Update Magnitude: 0.60975

Collected Steps per Second: 22,766.59138
Overall Steps per Second: 10,614.33779

Timestep Collection Time: 2.19743
Timestep Consumption Time: 2.51582
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.71325

Cumulative Model Updates: 102,454
Cumulative Timesteps: 854,467,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 854467124...
Checkpoint 854467124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.82945
Policy Entropy: 3.17876
Value Function Loss: 0.00496

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.56501
Value Function Update Magnitude: 0.59983

Collected Steps per Second: 23,001.52040
Overall Steps per Second: 10,717.53932

Timestep Collection Time: 2.17403
Timestep Consumption Time: 2.49178
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.66581

Cumulative Model Updates: 102,460
Cumulative Timesteps: 854,517,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.58971
Policy Entropy: 3.18177
Value Function Loss: 0.00492

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.55921
Value Function Update Magnitude: 0.59482

Collected Steps per Second: 23,205.10076
Overall Steps per Second: 10,721.53326

Timestep Collection Time: 2.15599
Timestep Consumption Time: 2.51032
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.66631

Cumulative Model Updates: 102,466
Cumulative Timesteps: 854,567,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 854567160...
Checkpoint 854567160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.53583
Policy Entropy: 3.15918
Value Function Loss: 0.00471

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.55783
Value Function Update Magnitude: 0.59211

Collected Steps per Second: 22,842.48801
Overall Steps per Second: 10,676.96841

Timestep Collection Time: 2.19013
Timestep Consumption Time: 2.49547
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.68560

Cumulative Model Updates: 102,472
Cumulative Timesteps: 854,617,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.06888
Policy Entropy: 3.14397
Value Function Loss: 0.00498

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.56649
Value Function Update Magnitude: 0.59742

Collected Steps per Second: 22,954.02122
Overall Steps per Second: 10,796.67578

Timestep Collection Time: 2.17835
Timestep Consumption Time: 2.45289
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.63124

Cumulative Model Updates: 102,478
Cumulative Timesteps: 854,667,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 854667190...
Checkpoint 854667190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.58351
Policy Entropy: 3.12937
Value Function Loss: 0.00507

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.57562
Value Function Update Magnitude: 0.60147

Collected Steps per Second: 22,338.73211
Overall Steps per Second: 10,669.86569

Timestep Collection Time: 2.23826
Timestep Consumption Time: 2.44783
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.68609

Cumulative Model Updates: 102,484
Cumulative Timesteps: 854,717,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.91493
Policy Entropy: 3.13524
Value Function Loss: 0.00504

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14276
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.61396

Collected Steps per Second: 22,810.50690
Overall Steps per Second: 10,620.27912

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.51711
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.71005

Cumulative Model Updates: 102,490
Cumulative Timesteps: 854,767,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 854767212...
Checkpoint 854767212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,593.08570
Policy Entropy: 3.15114
Value Function Loss: 0.00479

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.14520
Policy Update Magnitude: 0.55861
Value Function Update Magnitude: 0.61701

Collected Steps per Second: 22,868.16177
Overall Steps per Second: 10,672.72520

Timestep Collection Time: 2.18741
Timestep Consumption Time: 2.49949
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.68690

Cumulative Model Updates: 102,496
Cumulative Timesteps: 854,817,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.94572
Policy Entropy: 3.15405
Value Function Loss: 0.00471

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.55646
Value Function Update Magnitude: 0.58602

Collected Steps per Second: 22,821.99999
Overall Steps per Second: 10,776.44423

Timestep Collection Time: 2.19122
Timestep Consumption Time: 2.44927
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.64049

Cumulative Model Updates: 102,502
Cumulative Timesteps: 854,867,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 854867242...
Checkpoint 854867242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 817.03039
Policy Entropy: 3.14501
Value Function Loss: 0.00462

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.55968
Value Function Update Magnitude: 0.56913

Collected Steps per Second: 23,039.28458
Overall Steps per Second: 10,664.10245

Timestep Collection Time: 2.17151
Timestep Consumption Time: 2.51993
PPO Batch Consumption Time: 0.29589
Total Iteration Time: 4.69144

Cumulative Model Updates: 102,508
Cumulative Timesteps: 854,917,272

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.58293
Policy Entropy: 3.13268
Value Function Loss: 0.00462

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11737
Policy Update Magnitude: 0.55030
Value Function Update Magnitude: 0.55523

Collected Steps per Second: 23,082.76576
Overall Steps per Second: 10,811.63854

Timestep Collection Time: 2.16681
Timestep Consumption Time: 2.45931
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.62613

Cumulative Model Updates: 102,514
Cumulative Timesteps: 854,967,288

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 854967288...
Checkpoint 854967288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.17154
Policy Entropy: 3.12584
Value Function Loss: 0.00453

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.12499
Policy Update Magnitude: 0.54580
Value Function Update Magnitude: 0.56061

Collected Steps per Second: 22,812.50453
Overall Steps per Second: 10,686.43859

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.48735
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.67939

Cumulative Model Updates: 102,520
Cumulative Timesteps: 855,017,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.27265
Policy Entropy: 3.12103
Value Function Loss: 0.00457

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.54347
Value Function Update Magnitude: 0.57328

Collected Steps per Second: 22,125.93425
Overall Steps per Second: 10,813.68482

Timestep Collection Time: 2.26070
Timestep Consumption Time: 2.36492
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.62562

Cumulative Model Updates: 102,526
Cumulative Timesteps: 855,067,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 855067314...
Checkpoint 855067314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.88771
Policy Entropy: 3.13793
Value Function Loss: 0.00476

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10913
Policy Update Magnitude: 0.54657
Value Function Update Magnitude: 0.57110

Collected Steps per Second: 21,739.54993
Overall Steps per Second: 10,667.26175

Timestep Collection Time: 2.30088
Timestep Consumption Time: 2.38824
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.68911

Cumulative Model Updates: 102,532
Cumulative Timesteps: 855,117,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.81853
Policy Entropy: 3.16204
Value Function Loss: 0.00491

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.57685

Collected Steps per Second: 22,217.75614
Overall Steps per Second: 10,647.71891

Timestep Collection Time: 2.25054
Timestep Consumption Time: 2.44549
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.69603

Cumulative Model Updates: 102,538
Cumulative Timesteps: 855,167,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 855167336...
Checkpoint 855167336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.50439
Policy Entropy: 3.16600
Value Function Loss: 0.00477

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08971
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.57172

Collected Steps per Second: 21,908.15049
Overall Steps per Second: 10,594.44726

Timestep Collection Time: 2.28262
Timestep Consumption Time: 2.43759
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.72021

Cumulative Model Updates: 102,544
Cumulative Timesteps: 855,217,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.87478
Policy Entropy: 3.15203
Value Function Loss: 0.00483

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10153
Policy Update Magnitude: 0.54503
Value Function Update Magnitude: 0.56603

Collected Steps per Second: 22,345.15068
Overall Steps per Second: 10,850.75881

Timestep Collection Time: 2.23825
Timestep Consumption Time: 2.37101
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.60926

Cumulative Model Updates: 102,550
Cumulative Timesteps: 855,267,358

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 855267358...
Checkpoint 855267358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,494.14363
Policy Entropy: 3.14110
Value Function Loss: 0.00451

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.54022
Value Function Update Magnitude: 0.56836

Collected Steps per Second: 22,182.20981
Overall Steps per Second: 10,630.85170

Timestep Collection Time: 2.25541
Timestep Consumption Time: 2.45070
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.70611

Cumulative Model Updates: 102,556
Cumulative Timesteps: 855,317,388

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.93038
Policy Entropy: 3.15358
Value Function Loss: 0.00429

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.53774
Value Function Update Magnitude: 0.56887

Collected Steps per Second: 22,121.47346
Overall Steps per Second: 10,766.71123

Timestep Collection Time: 2.26052
Timestep Consumption Time: 2.38398
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.64450

Cumulative Model Updates: 102,562
Cumulative Timesteps: 855,367,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 855367394...
Checkpoint 855367394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.03271
Policy Entropy: 3.15388
Value Function Loss: 0.00432

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.53831
Value Function Update Magnitude: 0.57037

Collected Steps per Second: 22,260.05022
Overall Steps per Second: 10,765.86392

Timestep Collection Time: 2.24690
Timestep Consumption Time: 2.39890
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.64580

Cumulative Model Updates: 102,568
Cumulative Timesteps: 855,417,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 923.98047
Policy Entropy: 3.16333
Value Function Loss: 0.00438

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.54144
Value Function Update Magnitude: 0.58098

Collected Steps per Second: 22,428.83030
Overall Steps per Second: 10,493.86126

Timestep Collection Time: 2.22999
Timestep Consumption Time: 2.53623
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.76622

Cumulative Model Updates: 102,574
Cumulative Timesteps: 855,467,426

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 855467426...
Checkpoint 855467426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.08179
Policy Entropy: 3.15830
Value Function Loss: 0.00461

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.54619
Value Function Update Magnitude: 0.58179

Collected Steps per Second: 23,082.56879
Overall Steps per Second: 10,646.26832

Timestep Collection Time: 2.16761
Timestep Consumption Time: 2.53207
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.69967

Cumulative Model Updates: 102,580
Cumulative Timesteps: 855,517,460

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.35572
Policy Entropy: 3.16429
Value Function Loss: 0.00458

Mean KL Divergence: 0.00799
SB3 Clip Fraction: 0.08678
Policy Update Magnitude: 0.55213
Value Function Update Magnitude: 0.59680

Collected Steps per Second: 23,059.90319
Overall Steps per Second: 10,825.03740

Timestep Collection Time: 2.16905
Timestep Consumption Time: 2.45154
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.62058

Cumulative Model Updates: 102,586
Cumulative Timesteps: 855,567,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 855567478...
Checkpoint 855567478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 985.14546
Policy Entropy: 3.16852
Value Function Loss: 0.00451

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08063
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.62086

Collected Steps per Second: 22,848.10184
Overall Steps per Second: 10,670.31246

Timestep Collection Time: 2.18863
Timestep Consumption Time: 2.49783
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.68646

Cumulative Model Updates: 102,592
Cumulative Timesteps: 855,617,484

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.61683
Policy Entropy: 3.16174
Value Function Loss: 0.00477

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09612
Policy Update Magnitude: 0.55544
Value Function Update Magnitude: 0.62490

Collected Steps per Second: 22,276.31645
Overall Steps per Second: 10,810.63864

Timestep Collection Time: 2.24579
Timestep Consumption Time: 2.38187
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.62766

Cumulative Model Updates: 102,598
Cumulative Timesteps: 855,667,512

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 855667512...
Checkpoint 855667512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.70260
Policy Entropy: 3.15873
Value Function Loss: 0.00491

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.63479

Collected Steps per Second: 21,935.02932
Overall Steps per Second: 10,714.05766

Timestep Collection Time: 2.27946
Timestep Consumption Time: 2.38731
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.66677

Cumulative Model Updates: 102,604
Cumulative Timesteps: 855,717,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.10769
Policy Entropy: 3.14536
Value Function Loss: 0.00490

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.55209
Value Function Update Magnitude: 0.62434

Collected Steps per Second: 22,607.81815
Overall Steps per Second: 10,587.84880

Timestep Collection Time: 2.21162
Timestep Consumption Time: 2.51077
PPO Batch Consumption Time: 0.29591
Total Iteration Time: 4.72239

Cumulative Model Updates: 102,610
Cumulative Timesteps: 855,767,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 855767512...
Checkpoint 855767512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.33003
Policy Entropy: 3.15170
Value Function Loss: 0.00490

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.55767
Value Function Update Magnitude: 0.59228

Collected Steps per Second: 22,035.11894
Overall Steps per Second: 10,642.30997

Timestep Collection Time: 2.27029
Timestep Consumption Time: 2.43039
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.70067

Cumulative Model Updates: 102,616
Cumulative Timesteps: 855,817,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.50159
Policy Entropy: 3.17659
Value Function Loss: 0.00502

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08700
Policy Update Magnitude: 0.56011
Value Function Update Magnitude: 0.58175

Collected Steps per Second: 23,087.36726
Overall Steps per Second: 10,824.00000

Timestep Collection Time: 2.16595
Timestep Consumption Time: 2.45397
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.61992

Cumulative Model Updates: 102,622
Cumulative Timesteps: 855,867,544

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 855867544...
Checkpoint 855867544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,394.16114
Policy Entropy: 3.17368
Value Function Loss: 0.00517

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.08743
Policy Update Magnitude: 0.56216
Value Function Update Magnitude: 0.59257

Collected Steps per Second: 22,971.35169
Overall Steps per Second: 10,648.45313

Timestep Collection Time: 2.17837
Timestep Consumption Time: 2.52091
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.69927

Cumulative Model Updates: 102,628
Cumulative Timesteps: 855,917,584

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.75829
Policy Entropy: 3.16922
Value Function Loss: 0.00478

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08925
Policy Update Magnitude: 0.55672
Value Function Update Magnitude: 0.59516

Collected Steps per Second: 23,165.53270
Overall Steps per Second: 10,829.33909

Timestep Collection Time: 2.15855
Timestep Consumption Time: 2.45890
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.61746

Cumulative Model Updates: 102,634
Cumulative Timesteps: 855,967,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 855967588...
Checkpoint 855967588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.40749
Policy Entropy: 3.16239
Value Function Loss: 0.00443

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.57289

Collected Steps per Second: 22,928.70307
Overall Steps per Second: 10,688.42182

Timestep Collection Time: 2.18120
Timestep Consumption Time: 2.49789
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.67908

Cumulative Model Updates: 102,640
Cumulative Timesteps: 856,017,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.02581
Policy Entropy: 3.16848
Value Function Loss: 0.00443

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.53763
Value Function Update Magnitude: 0.56804

Collected Steps per Second: 23,034.83781
Overall Steps per Second: 10,808.97923

Timestep Collection Time: 2.17089
Timestep Consumption Time: 2.45545
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.62634

Cumulative Model Updates: 102,646
Cumulative Timesteps: 856,067,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 856067606...
Checkpoint 856067606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744.87162
Policy Entropy: 3.17374
Value Function Loss: 0.00456

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08793
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.59365

Collected Steps per Second: 22,079.82874
Overall Steps per Second: 10,743.63958

Timestep Collection Time: 2.26505
Timestep Consumption Time: 2.38998
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.65503

Cumulative Model Updates: 102,652
Cumulative Timesteps: 856,117,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.46841
Policy Entropy: 3.14463
Value Function Loss: 0.00458

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.54694
Value Function Update Magnitude: 0.61591

Collected Steps per Second: 22,257.98689
Overall Steps per Second: 10,846.84992

Timestep Collection Time: 2.24728
Timestep Consumption Time: 2.36419
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.61148

Cumulative Model Updates: 102,658
Cumulative Timesteps: 856,167,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 856167638...
Checkpoint 856167638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.90566
Policy Entropy: 3.14026
Value Function Loss: 0.00461

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.55142
Value Function Update Magnitude: 0.61449

Collected Steps per Second: 21,958.16322
Overall Steps per Second: 10,641.44598

Timestep Collection Time: 2.27751
Timestep Consumption Time: 2.42204
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.69955

Cumulative Model Updates: 102,664
Cumulative Timesteps: 856,217,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,264.56290
Policy Entropy: 3.12279
Value Function Loss: 0.00474

Mean KL Divergence: 0.01488
SB3 Clip Fraction: 0.13885
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.60623

Collected Steps per Second: 23,048.50741
Overall Steps per Second: 10,723.31812

Timestep Collection Time: 2.17055
Timestep Consumption Time: 2.49479
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.66535

Cumulative Model Updates: 102,670
Cumulative Timesteps: 856,267,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 856267676...
Checkpoint 856267676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.61351
Policy Entropy: 3.14444
Value Function Loss: 0.00472

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.55272
Value Function Update Magnitude: 0.60400

Collected Steps per Second: 22,909.72151
Overall Steps per Second: 10,775.93520

Timestep Collection Time: 2.18327
Timestep Consumption Time: 2.45837
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.64164

Cumulative Model Updates: 102,676
Cumulative Timesteps: 856,317,694

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.12505
Policy Entropy: 3.16605
Value Function Loss: 0.00484

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.55082
Value Function Update Magnitude: 0.61916

Collected Steps per Second: 23,284.16422
Overall Steps per Second: 10,748.25932

Timestep Collection Time: 2.14755
Timestep Consumption Time: 2.50473
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.65229

Cumulative Model Updates: 102,682
Cumulative Timesteps: 856,367,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 856367698...
Checkpoint 856367698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,545.82530
Policy Entropy: 3.17963
Value Function Loss: 0.00488

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.54522
Value Function Update Magnitude: 0.61563

Collected Steps per Second: 21,719.06400
Overall Steps per Second: 10,579.93182

Timestep Collection Time: 2.30268
Timestep Consumption Time: 2.42439
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.72706

Cumulative Model Updates: 102,688
Cumulative Timesteps: 856,417,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.27145
Policy Entropy: 3.16119
Value Function Loss: 0.00488

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.54142
Value Function Update Magnitude: 0.61070

Collected Steps per Second: 22,506.47784
Overall Steps per Second: 10,769.07848

Timestep Collection Time: 2.22212
Timestep Consumption Time: 2.42192
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.64404

Cumulative Model Updates: 102,694
Cumulative Timesteps: 856,467,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 856467722...
Checkpoint 856467722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.16181
Policy Entropy: 3.14386
Value Function Loss: 0.00481

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10256
Policy Update Magnitude: 0.54379
Value Function Update Magnitude: 0.60180

Collected Steps per Second: 22,135.53307
Overall Steps per Second: 10,635.65171

Timestep Collection Time: 2.26062
Timestep Consumption Time: 2.44431
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.70493

Cumulative Model Updates: 102,700
Cumulative Timesteps: 856,517,762

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,674.01800
Policy Entropy: 3.13889
Value Function Loss: 0.00511

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10986
Policy Update Magnitude: 0.55266
Value Function Update Magnitude: 0.61965

Collected Steps per Second: 22,304.17173
Overall Steps per Second: 10,836.16081

Timestep Collection Time: 2.24290
Timestep Consumption Time: 2.37368
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.61658

Cumulative Model Updates: 102,706
Cumulative Timesteps: 856,567,788

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 856567788...
Checkpoint 856567788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.44045
Policy Entropy: 3.13858
Value Function Loss: 0.00512

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10872
Policy Update Magnitude: 0.56414
Value Function Update Magnitude: 0.65550

Collected Steps per Second: 21,901.21078
Overall Steps per Second: 10,749.15922

Timestep Collection Time: 2.28344
Timestep Consumption Time: 2.36902
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.65246

Cumulative Model Updates: 102,712
Cumulative Timesteps: 856,617,798

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.07176
Policy Entropy: 3.14138
Value Function Loss: 0.00512

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10778
Policy Update Magnitude: 0.56424
Value Function Update Magnitude: 0.65966

Collected Steps per Second: 22,070.85919
Overall Steps per Second: 10,759.26370

Timestep Collection Time: 2.26643
Timestep Consumption Time: 2.38278
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.64920

Cumulative Model Updates: 102,718
Cumulative Timesteps: 856,667,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 856667820...
Checkpoint 856667820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691.84937
Policy Entropy: 3.14674
Value Function Loss: 0.00482

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.55766
Value Function Update Magnitude: 0.65489

Collected Steps per Second: 21,959.14324
Overall Steps per Second: 10,707.44807

Timestep Collection Time: 2.27723
Timestep Consumption Time: 2.39298
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.67021

Cumulative Model Updates: 102,724
Cumulative Timesteps: 856,717,826

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,516.44485
Policy Entropy: 3.15230
Value Function Loss: 0.00477

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.55314
Value Function Update Magnitude: 0.64098

Collected Steps per Second: 22,319.85049
Overall Steps per Second: 10,762.29702

Timestep Collection Time: 2.24052
Timestep Consumption Time: 2.40607
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.64659

Cumulative Model Updates: 102,730
Cumulative Timesteps: 856,767,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 856767834...
Checkpoint 856767834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.65102
Policy Entropy: 3.15909
Value Function Loss: 0.00499

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.55704
Value Function Update Magnitude: 0.64239

Collected Steps per Second: 22,521.11281
Overall Steps per Second: 10,596.22326

Timestep Collection Time: 2.22076
Timestep Consumption Time: 2.49922
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.71998

Cumulative Model Updates: 102,736
Cumulative Timesteps: 856,817,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.83855
Policy Entropy: 3.16330
Value Function Loss: 0.00480

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08650
Policy Update Magnitude: 0.55686
Value Function Update Magnitude: 0.62945

Collected Steps per Second: 23,399.16499
Overall Steps per Second: 10,733.88398

Timestep Collection Time: 2.13743
Timestep Consumption Time: 2.52202
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.65945

Cumulative Model Updates: 102,742
Cumulative Timesteps: 856,867,862

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 856867862...
Checkpoint 856867862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.34987
Policy Entropy: 3.16212
Value Function Loss: 0.00468

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.54623
Value Function Update Magnitude: 0.59028

Collected Steps per Second: 21,986.17377
Overall Steps per Second: 10,545.17189

Timestep Collection Time: 2.27416
Timestep Consumption Time: 2.46735
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.74151

Cumulative Model Updates: 102,748
Cumulative Timesteps: 856,917,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.44820
Policy Entropy: 3.15560
Value Function Loss: 0.00464

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.54825
Value Function Update Magnitude: 0.59751

Collected Steps per Second: 23,283.67952
Overall Steps per Second: 10,867.89537

Timestep Collection Time: 2.14777
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.60144

Cumulative Model Updates: 102,754
Cumulative Timesteps: 856,967,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 856967870...
Checkpoint 856967870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.62784
Policy Entropy: 3.13946
Value Function Loss: 0.00518

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.55648
Value Function Update Magnitude: 0.61174

Collected Steps per Second: 22,448.84412
Overall Steps per Second: 10,690.00686

Timestep Collection Time: 2.22800
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.67876

Cumulative Model Updates: 102,760
Cumulative Timesteps: 857,017,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.98958
Policy Entropy: 3.14169
Value Function Loss: 0.00544

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.56732
Value Function Update Magnitude: 0.62822

Collected Steps per Second: 22,871.13604
Overall Steps per Second: 10,655.26719

Timestep Collection Time: 2.18686
Timestep Consumption Time: 2.50716
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.69402

Cumulative Model Updates: 102,766
Cumulative Timesteps: 857,067,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 857067902...
Checkpoint 857067902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.39271
Policy Entropy: 3.15274
Value Function Loss: 0.00546

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.57093
Value Function Update Magnitude: 0.65937

Collected Steps per Second: 22,814.42394
Overall Steps per Second: 10,803.10045

Timestep Collection Time: 2.19230
Timestep Consumption Time: 2.43748
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.62978

Cumulative Model Updates: 102,772
Cumulative Timesteps: 857,117,918

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.82226
Policy Entropy: 3.16395
Value Function Loss: 0.00501

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11371
Policy Update Magnitude: 0.56480
Value Function Update Magnitude: 0.67225

Collected Steps per Second: 22,913.98958
Overall Steps per Second: 10,627.09890

Timestep Collection Time: 2.18303
Timestep Consumption Time: 2.52399
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.70702

Cumulative Model Updates: 102,778
Cumulative Timesteps: 857,167,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 857167940...
Checkpoint 857167940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.01480
Policy Entropy: 3.16492
Value Function Loss: 0.00484

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10547
Policy Update Magnitude: 0.55482
Value Function Update Magnitude: 0.66133

Collected Steps per Second: 22,774.65473
Overall Steps per Second: 10,614.52082

Timestep Collection Time: 2.19613
Timestep Consumption Time: 2.51591
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 4.71204

Cumulative Model Updates: 102,784
Cumulative Timesteps: 857,217,956

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 982.20354
Policy Entropy: 3.17431
Value Function Loss: 0.00465

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09129
Policy Update Magnitude: 0.55407
Value Function Update Magnitude: 0.64554

Collected Steps per Second: 23,084.41330
Overall Steps per Second: 10,842.61761

Timestep Collection Time: 2.16631
Timestep Consumption Time: 2.44586
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.61217

Cumulative Model Updates: 102,790
Cumulative Timesteps: 857,267,964

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 857267964...
Checkpoint 857267964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.04270
Policy Entropy: 3.17206
Value Function Loss: 0.00481

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.55274
Value Function Update Magnitude: 0.63038

Collected Steps per Second: 22,956.38778
Overall Steps per Second: 10,640.79647

Timestep Collection Time: 2.17839
Timestep Consumption Time: 2.52126
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.69965

Cumulative Model Updates: 102,796
Cumulative Timesteps: 857,317,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.45670
Policy Entropy: 3.16220
Value Function Loss: 0.00500

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08655
Policy Update Magnitude: 0.56182
Value Function Update Magnitude: 0.63868

Collected Steps per Second: 23,148.43307
Overall Steps per Second: 10,752.30984

Timestep Collection Time: 2.16110
Timestep Consumption Time: 2.49149
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.65258

Cumulative Model Updates: 102,802
Cumulative Timesteps: 857,367,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 857367998...
Checkpoint 857367998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.50993
Policy Entropy: 3.15128
Value Function Loss: 0.00504

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.56860
Value Function Update Magnitude: 0.65824

Collected Steps per Second: 22,537.39420
Overall Steps per Second: 10,734.41884

Timestep Collection Time: 2.22004
Timestep Consumption Time: 2.44104
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.66108

Cumulative Model Updates: 102,808
Cumulative Timesteps: 857,418,032

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.40074
Policy Entropy: 3.14386
Value Function Loss: 0.00514

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09561
Policy Update Magnitude: 0.56591
Value Function Update Magnitude: 0.64473

Collected Steps per Second: 22,819.44404
Overall Steps per Second: 10,621.71284

Timestep Collection Time: 2.19120
Timestep Consumption Time: 2.51633
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.70753

Cumulative Model Updates: 102,814
Cumulative Timesteps: 857,468,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 857468034...
Checkpoint 857468034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 807.44085
Policy Entropy: 3.14802
Value Function Loss: 0.00504

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.56670
Value Function Update Magnitude: 0.64762

Collected Steps per Second: 22,719.55416
Overall Steps per Second: 10,614.94584

Timestep Collection Time: 2.20189
Timestep Consumption Time: 2.51090
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.71279

Cumulative Model Updates: 102,820
Cumulative Timesteps: 857,518,060

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.18109
Policy Entropy: 3.15287
Value Function Loss: 0.00486

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08960
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.63732

Collected Steps per Second: 23,296.51620
Overall Steps per Second: 10,843.31691

Timestep Collection Time: 2.14667
Timestep Consumption Time: 2.46538
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.61206

Cumulative Model Updates: 102,826
Cumulative Timesteps: 857,568,070

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 857568070...
Checkpoint 857568070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 890.24971
Policy Entropy: 3.15239
Value Function Loss: 0.00480

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.55010
Value Function Update Magnitude: 0.62531

Collected Steps per Second: 22,339.59543
Overall Steps per Second: 10,695.66946

Timestep Collection Time: 2.23916
Timestep Consumption Time: 2.43768
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.67685

Cumulative Model Updates: 102,832
Cumulative Timesteps: 857,618,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.93994
Policy Entropy: 3.14072
Value Function Loss: 0.00483

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.54665
Value Function Update Magnitude: 0.61395

Collected Steps per Second: 23,195.38289
Overall Steps per Second: 10,863.15966

Timestep Collection Time: 2.15629
Timestep Consumption Time: 2.44789
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.60419

Cumulative Model Updates: 102,838
Cumulative Timesteps: 857,668,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 857668108...
Checkpoint 857668108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.77259
Policy Entropy: 3.13247
Value Function Loss: 0.00490

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.55651
Value Function Update Magnitude: 0.62780

Collected Steps per Second: 22,755.26541
Overall Steps per Second: 10,632.59135

Timestep Collection Time: 2.19773
Timestep Consumption Time: 2.50573
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.70346

Cumulative Model Updates: 102,844
Cumulative Timesteps: 857,718,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.89444
Policy Entropy: 3.13665
Value Function Loss: 0.00484

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.55595
Value Function Update Magnitude: 0.63989

Collected Steps per Second: 23,072.49812
Overall Steps per Second: 10,816.94588

Timestep Collection Time: 2.16760
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.62349

Cumulative Model Updates: 102,850
Cumulative Timesteps: 857,768,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 857768130...
Checkpoint 857768130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.63251
Policy Entropy: 3.13953
Value Function Loss: 0.00493

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.55269
Value Function Update Magnitude: 0.63906

Collected Steps per Second: 22,864.08483
Overall Steps per Second: 10,732.31216

Timestep Collection Time: 2.18727
Timestep Consumption Time: 2.47249
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.65976

Cumulative Model Updates: 102,856
Cumulative Timesteps: 857,818,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.38954
Policy Entropy: 3.12829
Value Function Loss: 0.00497

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.55449
Value Function Update Magnitude: 0.62897

Collected Steps per Second: 22,812.74983
Overall Steps per Second: 10,671.74731

Timestep Collection Time: 2.19211
Timestep Consumption Time: 2.49391
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.68602

Cumulative Model Updates: 102,862
Cumulative Timesteps: 857,868,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 857868148...
Checkpoint 857868148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.18613
Policy Entropy: 3.11662
Value Function Loss: 0.00491

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.55247
Value Function Update Magnitude: 0.60344

Collected Steps per Second: 22,996.44422
Overall Steps per Second: 10,779.60522

Timestep Collection Time: 2.17477
Timestep Consumption Time: 2.46473
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.63950

Cumulative Model Updates: 102,868
Cumulative Timesteps: 857,918,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.74166
Policy Entropy: 3.12507
Value Function Loss: 0.00519

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.56066
Value Function Update Magnitude: 0.59348

Collected Steps per Second: 22,840.55480
Overall Steps per Second: 10,572.63269

Timestep Collection Time: 2.18953
Timestep Consumption Time: 2.54061
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.73014

Cumulative Model Updates: 102,874
Cumulative Timesteps: 857,968,170

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 857968170...
Checkpoint 857968170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,873.38891
Policy Entropy: 3.13864
Value Function Loss: 0.00498

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09646
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.60351

Collected Steps per Second: 22,329.12935
Overall Steps per Second: 10,579.02848

Timestep Collection Time: 2.24003
Timestep Consumption Time: 2.48800
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.72803

Cumulative Model Updates: 102,880
Cumulative Timesteps: 858,018,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.67003
Policy Entropy: 3.15622
Value Function Loss: 0.00500

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.54562
Value Function Update Magnitude: 0.60512

Collected Steps per Second: 23,200.30542
Overall Steps per Second: 10,872.55728

Timestep Collection Time: 2.15601
Timestep Consumption Time: 2.44457
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.60057

Cumulative Model Updates: 102,886
Cumulative Timesteps: 858,068,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 858068208...
Checkpoint 858068208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.19322
Policy Entropy: 3.15095
Value Function Loss: 0.00491

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.08186
Policy Update Magnitude: 0.55075
Value Function Update Magnitude: 0.59957

Collected Steps per Second: 22,694.99839
Overall Steps per Second: 10,717.00987

Timestep Collection Time: 2.20383
Timestep Consumption Time: 2.46314
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.66697

Cumulative Model Updates: 102,892
Cumulative Timesteps: 858,118,224

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.71373
Policy Entropy: 3.14030
Value Function Loss: 0.00510

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.55566
Value Function Update Magnitude: 0.60705

Collected Steps per Second: 23,350.94130
Overall Steps per Second: 10,872.13430

Timestep Collection Time: 2.14227
Timestep Consumption Time: 2.45885
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.60112

Cumulative Model Updates: 102,898
Cumulative Timesteps: 858,168,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 858168248...
Checkpoint 858168248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.96187
Policy Entropy: 3.12612
Value Function Loss: 0.00527

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.56862
Value Function Update Magnitude: 0.62190

Collected Steps per Second: 22,847.49543
Overall Steps per Second: 10,690.60834

Timestep Collection Time: 2.18895
Timestep Consumption Time: 2.48918
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.67812

Cumulative Model Updates: 102,904
Cumulative Timesteps: 858,218,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.71657
Policy Entropy: 3.13277
Value Function Loss: 0.00502

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.57415
Value Function Update Magnitude: 0.63930

Collected Steps per Second: 23,204.10827
Overall Steps per Second: 10,828.57244

Timestep Collection Time: 2.15522
Timestep Consumption Time: 2.46312
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.61834

Cumulative Model Updates: 102,910
Cumulative Timesteps: 858,268,270

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 858268270...
Checkpoint 858268270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.48218
Policy Entropy: 3.13727
Value Function Loss: 0.00492

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.56011
Value Function Update Magnitude: 0.64259

Collected Steps per Second: 22,804.73122
Overall Steps per Second: 10,671.71657

Timestep Collection Time: 2.19367
Timestep Consumption Time: 2.49405
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.68772

Cumulative Model Updates: 102,916
Cumulative Timesteps: 858,318,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.88629
Policy Entropy: 3.13861
Value Function Loss: 0.00474

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.55967
Value Function Update Magnitude: 0.62917

Collected Steps per Second: 22,409.94755
Overall Steps per Second: 10,838.50352

Timestep Collection Time: 2.23187
Timestep Consumption Time: 2.38279
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.61466

Cumulative Model Updates: 102,922
Cumulative Timesteps: 858,368,312

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 858368312...
Checkpoint 858368312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,207.96381
Policy Entropy: 3.12830
Value Function Loss: 0.00498

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.63583

Collected Steps per Second: 22,459.28245
Overall Steps per Second: 10,690.88464

Timestep Collection Time: 2.22750
Timestep Consumption Time: 2.45200
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.67950

Cumulative Model Updates: 102,928
Cumulative Timesteps: 858,418,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.57268
Policy Entropy: 3.13374
Value Function Loss: 0.00480

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10842
Policy Update Magnitude: 0.55024
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 22,380.04662
Overall Steps per Second: 10,733.52125

Timestep Collection Time: 2.23431
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.65868

Cumulative Model Updates: 102,934
Cumulative Timesteps: 858,468,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 858468344...
Checkpoint 858468344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 865.69546
Policy Entropy: 3.13867
Value Function Loss: 0.00481

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10586
Policy Update Magnitude: 0.54768
Value Function Update Magnitude: 0.62336

Collected Steps per Second: 22,332.34213
Overall Steps per Second: 10,826.80538

Timestep Collection Time: 2.23980
Timestep Consumption Time: 2.38021
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.62001

Cumulative Model Updates: 102,940
Cumulative Timesteps: 858,518,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.30699
Policy Entropy: 3.14373
Value Function Loss: 0.00462

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.54389
Value Function Update Magnitude: 0.62759

Collected Steps per Second: 22,983.18106
Overall Steps per Second: 10,859.88302

Timestep Collection Time: 2.17637
Timestep Consumption Time: 2.42957
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.60594

Cumulative Model Updates: 102,946
Cumulative Timesteps: 858,568,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 858568384...
Checkpoint 858568384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.41405
Policy Entropy: 3.12090
Value Function Loss: 0.00458

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.54782
Value Function Update Magnitude: 0.63392

Collected Steps per Second: 22,510.69596
Overall Steps per Second: 10,703.93846

Timestep Collection Time: 2.22205
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.67305

Cumulative Model Updates: 102,952
Cumulative Timesteps: 858,618,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.36101
Policy Entropy: 3.11323
Value Function Loss: 0.00470

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.55144
Value Function Update Magnitude: 0.64052

Collected Steps per Second: 22,156.79396
Overall Steps per Second: 10,657.89533

Timestep Collection Time: 2.25737
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.69286

Cumulative Model Updates: 102,958
Cumulative Timesteps: 858,668,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 858668420...
Checkpoint 858668420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 954.17200
Policy Entropy: 3.13386
Value Function Loss: 0.00467

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10505
Policy Update Magnitude: 0.55423
Value Function Update Magnitude: 0.65740

Collected Steps per Second: 22,112.97083
Overall Steps per Second: 10,766.41561

Timestep Collection Time: 2.26121
Timestep Consumption Time: 2.38305
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.64426

Cumulative Model Updates: 102,964
Cumulative Timesteps: 858,718,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,742.39244
Policy Entropy: 3.14095
Value Function Loss: 0.00453

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.54176
Value Function Update Magnitude: 0.65829

Collected Steps per Second: 22,178.78870
Overall Steps per Second: 10,616.44743

Timestep Collection Time: 2.25576
Timestep Consumption Time: 2.45674
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.71250

Cumulative Model Updates: 102,970
Cumulative Timesteps: 858,768,452

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 858768452...
Checkpoint 858768452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 956.92217
Policy Entropy: 3.13478
Value Function Loss: 0.00453

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.53983
Value Function Update Magnitude: 0.64610

Collected Steps per Second: 21,891.25833
Overall Steps per Second: 10,602.86509

Timestep Collection Time: 2.28429
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.71627

Cumulative Model Updates: 102,976
Cumulative Timesteps: 858,818,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.78617
Policy Entropy: 3.15015
Value Function Loss: 0.00475

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08977
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.65256

Collected Steps per Second: 22,296.55695
Overall Steps per Second: 10,789.78342

Timestep Collection Time: 2.24366
Timestep Consumption Time: 2.39276
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.63642

Cumulative Model Updates: 102,982
Cumulative Timesteps: 858,868,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 858868484...
Checkpoint 858868484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,807.81222
Policy Entropy: 3.15319
Value Function Loss: 0.00478

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09100
Policy Update Magnitude: 0.54862
Value Function Update Magnitude: 0.65672

Collected Steps per Second: 21,869.76524
Overall Steps per Second: 10,748.52034

Timestep Collection Time: 2.28718
Timestep Consumption Time: 2.36649
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.65366

Cumulative Model Updates: 102,988
Cumulative Timesteps: 858,918,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.11741
Policy Entropy: 3.15666
Value Function Loss: 0.00460

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08111
Policy Update Magnitude: 0.54415
Value Function Update Magnitude: 0.64466

Collected Steps per Second: 21,968.41320
Overall Steps per Second: 10,619.78543

Timestep Collection Time: 2.27745
Timestep Consumption Time: 2.43375
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.71121

Cumulative Model Updates: 102,994
Cumulative Timesteps: 858,968,536

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 858968536...
Checkpoint 858968536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.88900
Policy Entropy: 3.14638
Value Function Loss: 0.00467

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.07857
Policy Update Magnitude: 0.54243
Value Function Update Magnitude: 0.62783

Collected Steps per Second: 22,878.84547
Overall Steps per Second: 10,706.69425

Timestep Collection Time: 2.18665
Timestep Consumption Time: 2.48594
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.67259

Cumulative Model Updates: 103,000
Cumulative Timesteps: 859,018,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.21995
Policy Entropy: 3.14801
Value Function Loss: 0.00441

Mean KL Divergence: 0.00779
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.53455
Value Function Update Magnitude: 0.62363

Collected Steps per Second: 23,027.72872
Overall Steps per Second: 10,688.71173

Timestep Collection Time: 2.17190
Timestep Consumption Time: 2.50724
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.67914

Cumulative Model Updates: 103,006
Cumulative Timesteps: 859,068,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 859068578...
Checkpoint 859068578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.46740
Policy Entropy: 3.13107
Value Function Loss: 0.00460

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.60157

Collected Steps per Second: 22,294.82357
Overall Steps per Second: 10,666.02313

Timestep Collection Time: 2.24330
Timestep Consumption Time: 2.44579
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.68910

Cumulative Model Updates: 103,012
Cumulative Timesteps: 859,118,592

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.71281
Policy Entropy: 3.13468
Value Function Loss: 0.00451

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08528
Policy Update Magnitude: 0.53673
Value Function Update Magnitude: 0.58075

Collected Steps per Second: 22,278.50185
Overall Steps per Second: 10,838.86647

Timestep Collection Time: 2.24557
Timestep Consumption Time: 2.37004
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.61561

Cumulative Model Updates: 103,018
Cumulative Timesteps: 859,168,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 859168620...
Checkpoint 859168620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.78590
Policy Entropy: 3.11942
Value Function Loss: 0.00500

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.54331
Value Function Update Magnitude: 0.58221

Collected Steps per Second: 21,788.28409
Overall Steps per Second: 10,728.87774

Timestep Collection Time: 2.29573
Timestep Consumption Time: 2.36645
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.66218

Cumulative Model Updates: 103,024
Cumulative Timesteps: 859,218,640

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995.66722
Policy Entropy: 3.13653
Value Function Loss: 0.00474

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.55780
Value Function Update Magnitude: 0.60242

Collected Steps per Second: 22,025.39022
Overall Steps per Second: 10,637.72240

Timestep Collection Time: 2.27138
Timestep Consumption Time: 2.43151
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.70289

Cumulative Model Updates: 103,030
Cumulative Timesteps: 859,268,668

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 859268668...
Checkpoint 859268668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.92451
Policy Entropy: 3.13321
Value Function Loss: 0.00496

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.55850
Value Function Update Magnitude: 0.63491

Collected Steps per Second: 22,191.98875
Overall Steps per Second: 10,784.24385

Timestep Collection Time: 2.25343
Timestep Consumption Time: 2.38371
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.63714

Cumulative Model Updates: 103,036
Cumulative Timesteps: 859,318,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,858.67429
Policy Entropy: 3.15821
Value Function Loss: 0.00455

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11594
Policy Update Magnitude: 0.54804
Value Function Update Magnitude: 0.63674

Collected Steps per Second: 22,325.37905
Overall Steps per Second: 10,720.34023

Timestep Collection Time: 2.23978
Timestep Consumption Time: 2.42462
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.66440

Cumulative Model Updates: 103,042
Cumulative Timesteps: 859,368,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 859368680...
Checkpoint 859368680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.45113
Policy Entropy: 3.14230
Value Function Loss: 0.00464

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.53937
Value Function Update Magnitude: 0.62476

Collected Steps per Second: 22,057.71825
Overall Steps per Second: 10,655.93859

Timestep Collection Time: 2.26787
Timestep Consumption Time: 2.42660
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.69447

Cumulative Model Updates: 103,048
Cumulative Timesteps: 859,418,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.20798
Policy Entropy: 3.14561
Value Function Loss: 0.00462

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.54154
Value Function Update Magnitude: 0.60625

Collected Steps per Second: 22,427.35330
Overall Steps per Second: 10,722.31831

Timestep Collection Time: 2.22960
Timestep Consumption Time: 2.43394
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.66354

Cumulative Model Updates: 103,054
Cumulative Timesteps: 859,468,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 859468708...
Checkpoint 859468708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728.25820
Policy Entropy: 3.12372
Value Function Loss: 0.00472

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.59683

Collected Steps per Second: 21,948.44472
Overall Steps per Second: 10,638.07182

Timestep Collection Time: 2.27870
Timestep Consumption Time: 2.42271
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.70142

Cumulative Model Updates: 103,060
Cumulative Timesteps: 859,518,722

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.42793
Policy Entropy: 3.12986
Value Function Loss: 0.00452

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.55099
Value Function Update Magnitude: 0.60750

Collected Steps per Second: 22,114.75299
Overall Steps per Second: 10,691.00272

Timestep Collection Time: 2.26157
Timestep Consumption Time: 2.41657
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.67814

Cumulative Model Updates: 103,066
Cumulative Timesteps: 859,568,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 859568736...
Checkpoint 859568736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.67360
Policy Entropy: 3.14616
Value Function Loss: 0.00432

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.53898
Value Function Update Magnitude: 0.60212

Collected Steps per Second: 22,377.93771
Overall Steps per Second: 10,814.69218

Timestep Collection Time: 2.23542
Timestep Consumption Time: 2.39014
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.62556

Cumulative Model Updates: 103,072
Cumulative Timesteps: 859,618,760

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.82625
Policy Entropy: 3.15799
Value Function Loss: 0.00424

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.53433
Value Function Update Magnitude: 0.59405

Collected Steps per Second: 22,304.28664
Overall Steps per Second: 10,721.42758

Timestep Collection Time: 2.24244
Timestep Consumption Time: 2.42261
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.66505

Cumulative Model Updates: 103,078
Cumulative Timesteps: 859,668,776

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 859668776...
Checkpoint 859668776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.75658
Policy Entropy: 3.14881
Value Function Loss: 0.00437

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.53434
Value Function Update Magnitude: 0.59959

Collected Steps per Second: 22,392.32343
Overall Steps per Second: 10,858.59446

Timestep Collection Time: 2.23300
Timestep Consumption Time: 2.37183
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.60483

Cumulative Model Updates: 103,084
Cumulative Timesteps: 859,718,778

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.31907
Policy Entropy: 3.14500
Value Function Loss: 0.00444

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.54053
Value Function Update Magnitude: 0.61631

Collected Steps per Second: 22,415.28255
Overall Steps per Second: 10,870.32897

Timestep Collection Time: 2.23133
Timestep Consumption Time: 2.36981
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.60115

Cumulative Model Updates: 103,090
Cumulative Timesteps: 859,768,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 859768794...
Checkpoint 859768794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 975.72158
Policy Entropy: 3.14274
Value Function Loss: 0.00438

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.55025
Value Function Update Magnitude: 0.62716

Collected Steps per Second: 22,086.12573
Overall Steps per Second: 10,670.75835

Timestep Collection Time: 2.26423
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.68645

Cumulative Model Updates: 103,096
Cumulative Timesteps: 859,818,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,343.68512
Policy Entropy: 3.15029
Value Function Loss: 0.00471

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.54746
Value Function Update Magnitude: 0.62100

Collected Steps per Second: 22,379.65533
Overall Steps per Second: 10,866.30852

Timestep Collection Time: 2.23507
Timestep Consumption Time: 2.36815
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.60322

Cumulative Model Updates: 103,102
Cumulative Timesteps: 859,868,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 859868822...
Checkpoint 859868822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.20094
Policy Entropy: 3.15878
Value Function Loss: 0.00488

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.55503
Value Function Update Magnitude: 0.61098

Collected Steps per Second: 21,868.90465
Overall Steps per Second: 10,733.64445

Timestep Collection Time: 2.28827
Timestep Consumption Time: 2.37389
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.66216

Cumulative Model Updates: 103,108
Cumulative Timesteps: 859,918,864

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.66584
Policy Entropy: 3.14063
Value Function Loss: 0.00525

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.56759
Value Function Update Magnitude: 0.62391

Collected Steps per Second: 22,889.55016
Overall Steps per Second: 10,798.66215

Timestep Collection Time: 2.18554
Timestep Consumption Time: 2.44707
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.63261

Cumulative Model Updates: 103,114
Cumulative Timesteps: 859,968,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 859968890...
Checkpoint 859968890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.19440
Policy Entropy: 3.14024
Value Function Loss: 0.00493

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.56350
Value Function Update Magnitude: 0.63099

Collected Steps per Second: 22,486.43117
Overall Steps per Second: 10,695.51504

Timestep Collection Time: 2.22490
Timestep Consumption Time: 2.45276
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.67766

Cumulative Model Updates: 103,120
Cumulative Timesteps: 860,018,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.76069
Policy Entropy: 3.14434
Value Function Loss: 0.00485

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.56247
Value Function Update Magnitude: 0.62599

Collected Steps per Second: 22,965.17085
Overall Steps per Second: 10,666.20152

Timestep Collection Time: 2.17808
Timestep Consumption Time: 2.51150
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.68958

Cumulative Model Updates: 103,126
Cumulative Timesteps: 860,068,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 860068940...
Checkpoint 860068940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.82255
Policy Entropy: 3.16184
Value Function Loss: 0.00473

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09790
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.62352

Collected Steps per Second: 22,204.88153
Overall Steps per Second: 10,823.40641

Timestep Collection Time: 2.25302
Timestep Consumption Time: 2.36919
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.62220

Cumulative Model Updates: 103,132
Cumulative Timesteps: 860,118,968

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 601.65462
Policy Entropy: 3.16088
Value Function Loss: 0.00503

Mean KL Divergence: 0.00777
SB3 Clip Fraction: 0.08449
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.63823

Collected Steps per Second: 22,976.04389
Overall Steps per Second: 10,667.63177

Timestep Collection Time: 2.17731
Timestep Consumption Time: 2.51220
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.68951

Cumulative Model Updates: 103,138
Cumulative Timesteps: 860,168,994

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 860168994...
Checkpoint 860168994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.22677
Policy Entropy: 3.15982
Value Function Loss: 0.00501

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08441
Policy Update Magnitude: 0.57025
Value Function Update Magnitude: 0.66379

Collected Steps per Second: 22,146.71316
Overall Steps per Second: 10,710.43173

Timestep Collection Time: 2.25821
Timestep Consumption Time: 2.41125
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.66947

Cumulative Model Updates: 103,144
Cumulative Timesteps: 860,219,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.60907
Policy Entropy: 3.13922
Value Function Loss: 0.00492

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09268
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.65125

Collected Steps per Second: 22,938.47791
Overall Steps per Second: 10,699.30720

Timestep Collection Time: 2.18044
Timestep Consumption Time: 2.49425
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.67470

Cumulative Model Updates: 103,150
Cumulative Timesteps: 860,269,022

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 860269022...
Checkpoint 860269022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.45992
Policy Entropy: 3.15236
Value Function Loss: 0.00492

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.56842
Value Function Update Magnitude: 0.65438

Collected Steps per Second: 22,441.35130
Overall Steps per Second: 10,690.32314

Timestep Collection Time: 2.22919
Timestep Consumption Time: 2.45037
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.67956

Cumulative Model Updates: 103,156
Cumulative Timesteps: 860,319,048

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,227.59102
Policy Entropy: 3.15827
Value Function Loss: 0.00490

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09034
Policy Update Magnitude: 0.56676
Value Function Update Magnitude: 0.66511

Collected Steps per Second: 23,260.98335
Overall Steps per Second: 10,872.43237

Timestep Collection Time: 2.14995
Timestep Consumption Time: 2.44975
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.59971

Cumulative Model Updates: 103,162
Cumulative Timesteps: 860,369,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 860369058...
Checkpoint 860369058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.61621
Policy Entropy: 3.17551
Value Function Loss: 0.00498

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09147
Policy Update Magnitude: 0.57132
Value Function Update Magnitude: 0.66842

Collected Steps per Second: 22,694.82203
Overall Steps per Second: 10,651.82054

Timestep Collection Time: 2.20376
Timestep Consumption Time: 2.49159
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.69535

Cumulative Model Updates: 103,168
Cumulative Timesteps: 860,419,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.58436
Policy Entropy: 3.16610
Value Function Loss: 0.00503

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08947
Policy Update Magnitude: 0.57048
Value Function Update Magnitude: 0.64806

Collected Steps per Second: 23,090.80831
Overall Steps per Second: 10,849.41414

Timestep Collection Time: 2.16666
Timestep Consumption Time: 2.44465
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.61131

Cumulative Model Updates: 103,174
Cumulative Timesteps: 860,469,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 860469102...
Checkpoint 860469102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.26303
Policy Entropy: 3.17932
Value Function Loss: 0.00492

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.08137
Policy Update Magnitude: 0.57382
Value Function Update Magnitude: 0.64669

Collected Steps per Second: 22,090.15368
Overall Steps per Second: 10,693.13067

Timestep Collection Time: 2.26372
Timestep Consumption Time: 2.41274
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.67646

Cumulative Model Updates: 103,180
Cumulative Timesteps: 860,519,108

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 991.23827
Policy Entropy: 3.18315
Value Function Loss: 0.00486

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.56668
Value Function Update Magnitude: 0.65127

Collected Steps per Second: 22,394.49499
Overall Steps per Second: 10,848.32185

Timestep Collection Time: 2.23314
Timestep Consumption Time: 2.37679
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.60993

Cumulative Model Updates: 103,186
Cumulative Timesteps: 860,569,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 860569118...
Checkpoint 860569118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.56643
Policy Entropy: 3.19179
Value Function Loss: 0.00508

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.56821
Value Function Update Magnitude: 0.64644

Collected Steps per Second: 21,783.80143
Overall Steps per Second: 10,723.22191

Timestep Collection Time: 2.29528
Timestep Consumption Time: 2.36749
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.66278

Cumulative Model Updates: 103,192
Cumulative Timesteps: 860,619,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.79523
Policy Entropy: 3.18899
Value Function Loss: 0.00504

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.57462
Value Function Update Magnitude: 0.65382

Collected Steps per Second: 22,168.32045
Overall Steps per Second: 10,764.46562

Timestep Collection Time: 2.25583
Timestep Consumption Time: 2.38982
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.64566

Cumulative Model Updates: 103,198
Cumulative Timesteps: 860,669,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 860669126...
Checkpoint 860669126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.56227
Policy Entropy: 3.18098
Value Function Loss: 0.00487

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09039
Policy Update Magnitude: 0.56895
Value Function Update Magnitude: 0.66569

Collected Steps per Second: 21,629.79988
Overall Steps per Second: 10,680.54197

Timestep Collection Time: 2.31200
Timestep Consumption Time: 2.37016
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.68216

Cumulative Model Updates: 103,204
Cumulative Timesteps: 860,719,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.37670
Policy Entropy: 3.17948
Value Function Loss: 0.00472

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.56784
Value Function Update Magnitude: 0.66812

Collected Steps per Second: 22,308.95996
Overall Steps per Second: 10,726.88302

Timestep Collection Time: 2.24242
Timestep Consumption Time: 2.42119
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.66361

Cumulative Model Updates: 103,210
Cumulative Timesteps: 860,769,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 860769160...
Checkpoint 860769160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.85794
Policy Entropy: 3.16836
Value Function Loss: 0.00467

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.66677

Collected Steps per Second: 23,067.24629
Overall Steps per Second: 10,865.77234

Timestep Collection Time: 2.16784
Timestep Consumption Time: 2.43432
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.60216

Cumulative Model Updates: 103,216
Cumulative Timesteps: 860,819,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.82427
Policy Entropy: 3.17378
Value Function Loss: 0.00490

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09047
Policy Update Magnitude: 0.56165
Value Function Update Magnitude: 0.66449

Collected Steps per Second: 22,379.84956
Overall Steps per Second: 10,831.45267

Timestep Collection Time: 2.23531
Timestep Consumption Time: 2.38327
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.61859

Cumulative Model Updates: 103,222
Cumulative Timesteps: 860,869,192

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 860869192...
Checkpoint 860869192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.40318
Policy Entropy: 3.16655
Value Function Loss: 0.00494

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.56259
Value Function Update Magnitude: 0.64440

Collected Steps per Second: 21,901.34098
Overall Steps per Second: 10,706.86043

Timestep Collection Time: 2.28379
Timestep Consumption Time: 2.38780
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.67158

Cumulative Model Updates: 103,228
Cumulative Timesteps: 860,919,210

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.76505
Policy Entropy: 3.17400
Value Function Loss: 0.00489

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.56179
Value Function Update Magnitude: 0.64381

Collected Steps per Second: 22,313.21318
Overall Steps per Second: 10,732.85475

Timestep Collection Time: 2.24100
Timestep Consumption Time: 2.41796
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.65897

Cumulative Model Updates: 103,234
Cumulative Timesteps: 860,969,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 860969214...
Checkpoint 860969214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,266.01948
Policy Entropy: 3.17297
Value Function Loss: 0.00478

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.10860
Policy Update Magnitude: 0.55444
Value Function Update Magnitude: 0.62753

Collected Steps per Second: 22,204.93169
Overall Steps per Second: 10,782.62208

Timestep Collection Time: 2.25184
Timestep Consumption Time: 2.38543
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.63728

Cumulative Model Updates: 103,240
Cumulative Timesteps: 861,019,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.38227
Policy Entropy: 3.16290
Value Function Loss: 0.00493

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.55292
Value Function Update Magnitude: 0.62442

Collected Steps per Second: 22,417.00742
Overall Steps per Second: 10,889.85952

Timestep Collection Time: 2.23161
Timestep Consumption Time: 2.36221
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.59382

Cumulative Model Updates: 103,246
Cumulative Timesteps: 861,069,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 861069242...
Checkpoint 861069242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 729.33754
Policy Entropy: 3.14083
Value Function Loss: 0.00487

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.55664
Value Function Update Magnitude: 0.62658

Collected Steps per Second: 22,090.23627
Overall Steps per Second: 10,687.14839

Timestep Collection Time: 2.26435
Timestep Consumption Time: 2.41604
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.68039

Cumulative Model Updates: 103,252
Cumulative Timesteps: 861,119,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909.99101
Policy Entropy: 3.13597
Value Function Loss: 0.00485

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10636
Policy Update Magnitude: 0.55684
Value Function Update Magnitude: 0.63019

Collected Steps per Second: 22,455.31734
Overall Steps per Second: 10,852.56239

Timestep Collection Time: 2.22718
Timestep Consumption Time: 2.38113
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.60831

Cumulative Model Updates: 103,258
Cumulative Timesteps: 861,169,274

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 861169274...
Checkpoint 861169274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.41963
Policy Entropy: 3.14834
Value Function Loss: 0.00481

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.55798
Value Function Update Magnitude: 0.61811

Collected Steps per Second: 21,665.47633
Overall Steps per Second: 10,662.66961

Timestep Collection Time: 2.30930
Timestep Consumption Time: 2.38296
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.69226

Cumulative Model Updates: 103,264
Cumulative Timesteps: 861,219,306

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,262.39090
Policy Entropy: 3.15763
Value Function Loss: 0.00492

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.56125
Value Function Update Magnitude: 0.61648

Collected Steps per Second: 22,447.74280
Overall Steps per Second: 10,737.34061

Timestep Collection Time: 2.22829
Timestep Consumption Time: 2.43022
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.65851

Cumulative Model Updates: 103,270
Cumulative Timesteps: 861,269,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 861269326...
Checkpoint 861269326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.21072
Policy Entropy: 3.17471
Value Function Loss: 0.00459

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.54527
Value Function Update Magnitude: 0.61813

Collected Steps per Second: 22,232.55155
Overall Steps per Second: 10,831.84154

Timestep Collection Time: 2.24904
Timestep Consumption Time: 2.36716
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.61620

Cumulative Model Updates: 103,276
Cumulative Timesteps: 861,319,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.54218
Policy Entropy: 3.17867
Value Function Loss: 0.00458

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.53622
Value Function Update Magnitude: 0.61829

Collected Steps per Second: 22,328.89440
Overall Steps per Second: 10,734.71432

Timestep Collection Time: 2.23997
Timestep Consumption Time: 2.41931
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.65928

Cumulative Model Updates: 103,282
Cumulative Timesteps: 861,369,344

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 861369344...
Checkpoint 861369344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.29315
Policy Entropy: 3.18088
Value Function Loss: 0.00456

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11145
Policy Update Magnitude: 0.53419
Value Function Update Magnitude: 0.62163

Collected Steps per Second: 22,014.90905
Overall Steps per Second: 10,783.86566

Timestep Collection Time: 2.27210
Timestep Consumption Time: 2.36631
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 4.63841

Cumulative Model Updates: 103,288
Cumulative Timesteps: 861,419,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 720.96763
Policy Entropy: 3.16135
Value Function Loss: 0.00462

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10397
Policy Update Magnitude: 0.53592
Value Function Update Magnitude: 0.61703

Collected Steps per Second: 23,024.74767
Overall Steps per Second: 10,665.03671

Timestep Collection Time: 2.17218
Timestep Consumption Time: 2.51734
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.68953

Cumulative Model Updates: 103,294
Cumulative Timesteps: 861,469,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 861469378...
Checkpoint 861469378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,660.48342
Policy Entropy: 3.14746
Value Function Loss: 0.00462

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.54320
Value Function Update Magnitude: 0.61597

Collected Steps per Second: 23,190.73053
Overall Steps per Second: 10,864.33837

Timestep Collection Time: 2.15802
Timestep Consumption Time: 2.44843
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.60645

Cumulative Model Updates: 103,300
Cumulative Timesteps: 861,519,424

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 797.22068
Policy Entropy: 3.14566
Value Function Loss: 0.00485

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08705
Policy Update Magnitude: 0.55290
Value Function Update Magnitude: 0.61994

Collected Steps per Second: 22,773.54864
Overall Steps per Second: 10,609.37753

Timestep Collection Time: 2.19597
Timestep Consumption Time: 2.51779
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.71375

Cumulative Model Updates: 103,306
Cumulative Timesteps: 861,569,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 861569434...
Checkpoint 861569434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.10327
Policy Entropy: 3.15567
Value Function Loss: 0.00475

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.55372
Value Function Update Magnitude: 0.63632

Collected Steps per Second: 22,071.74389
Overall Steps per Second: 10,602.08790

Timestep Collection Time: 2.26597
Timestep Consumption Time: 2.45140
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.71737

Cumulative Model Updates: 103,312
Cumulative Timesteps: 861,619,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.37319
Policy Entropy: 3.16642
Value Function Loss: 0.00463

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.55538
Value Function Update Magnitude: 0.64131

Collected Steps per Second: 22,419.72577
Overall Steps per Second: 10,865.36649

Timestep Collection Time: 2.23107
Timestep Consumption Time: 2.37255
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60362

Cumulative Model Updates: 103,318
Cumulative Timesteps: 861,669,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 861669468...
Checkpoint 861669468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,857.38595
Policy Entropy: 3.17685
Value Function Loss: 0.00463

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.55092
Value Function Update Magnitude: 0.64101

Collected Steps per Second: 22,736.95066
Overall Steps per Second: 10,676.15582

Timestep Collection Time: 2.19994
Timestep Consumption Time: 2.48526
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.68521

Cumulative Model Updates: 103,324
Cumulative Timesteps: 861,719,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.74456
Policy Entropy: 3.16900
Value Function Loss: 0.00500

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.55296
Value Function Update Magnitude: 0.63799

Collected Steps per Second: 22,152.84042
Overall Steps per Second: 10,806.45469

Timestep Collection Time: 2.25759
Timestep Consumption Time: 2.37039
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.62797

Cumulative Model Updates: 103,330
Cumulative Timesteps: 861,769,500

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 861769500...
Checkpoint 861769500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.18112
Policy Entropy: 3.15564
Value Function Loss: 0.00492

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.56384
Value Function Update Magnitude: 0.61766

Collected Steps per Second: 21,849.82577
Overall Steps per Second: 10,714.05690

Timestep Collection Time: 2.28844
Timestep Consumption Time: 2.37851
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.66695

Cumulative Model Updates: 103,336
Cumulative Timesteps: 861,819,502

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,855.85640
Policy Entropy: 3.16265
Value Function Loss: 0.00475

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10529
Policy Update Magnitude: 0.55925
Value Function Update Magnitude: 0.60076

Collected Steps per Second: 22,391.76099
Overall Steps per Second: 10,823.92948

Timestep Collection Time: 2.23359
Timestep Consumption Time: 2.38710
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.62069

Cumulative Model Updates: 103,342
Cumulative Timesteps: 861,869,516

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 861869516...
Checkpoint 861869516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.67482
Policy Entropy: 3.17349
Value Function Loss: 0.00470

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.55682
Value Function Update Magnitude: 0.60369

Collected Steps per Second: 21,930.75273
Overall Steps per Second: 10,773.13314

Timestep Collection Time: 2.27999
Timestep Consumption Time: 2.36137
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.64136

Cumulative Model Updates: 103,348
Cumulative Timesteps: 861,919,518

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,364.81179
Policy Entropy: 3.18576
Value Function Loss: 0.00476

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.56229
Value Function Update Magnitude: 0.61593

Collected Steps per Second: 22,301.67618
Overall Steps per Second: 10,788.29100

Timestep Collection Time: 2.24306
Timestep Consumption Time: 2.39382
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.63688

Cumulative Model Updates: 103,354
Cumulative Timesteps: 861,969,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 861969542...
Checkpoint 861969542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.19725
Policy Entropy: 3.18013
Value Function Loss: 0.00492

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 0.61469

Collected Steps per Second: 21,814.22020
Overall Steps per Second: 10,755.89258

Timestep Collection Time: 2.29236
Timestep Consumption Time: 2.35681
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.64917

Cumulative Model Updates: 103,360
Cumulative Timesteps: 862,019,548

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.74222
Policy Entropy: 3.17783
Value Function Loss: 0.00475

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.55328
Value Function Update Magnitude: 0.60274

Collected Steps per Second: 22,164.52070
Overall Steps per Second: 10,798.01809

Timestep Collection Time: 2.25694
Timestep Consumption Time: 2.37576
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.63270

Cumulative Model Updates: 103,366
Cumulative Timesteps: 862,069,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 862069572...
Checkpoint 862069572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.43851
Policy Entropy: 3.17547
Value Function Loss: 0.00487

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.55818
Value Function Update Magnitude: 0.61897

Collected Steps per Second: 22,255.03381
Overall Steps per Second: 10,731.48778

Timestep Collection Time: 2.24785
Timestep Consumption Time: 2.41376
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.66161

Cumulative Model Updates: 103,372
Cumulative Timesteps: 862,119,598

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.75393
Policy Entropy: 3.17862
Value Function Loss: 0.00489

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.56836
Value Function Update Magnitude: 0.63728

Collected Steps per Second: 22,836.26336
Overall Steps per Second: 10,652.53952

Timestep Collection Time: 2.18976
Timestep Consumption Time: 2.50452
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.69428

Cumulative Model Updates: 103,378
Cumulative Timesteps: 862,169,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 862169604...
Checkpoint 862169604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.74611
Policy Entropy: 3.16974
Value Function Loss: 0.00490

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.56867
Value Function Update Magnitude: 0.64920

Collected Steps per Second: 22,793.25041
Overall Steps per Second: 10,756.00687

Timestep Collection Time: 2.19451
Timestep Consumption Time: 2.45592
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.65042

Cumulative Model Updates: 103,384
Cumulative Timesteps: 862,219,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.68185
Policy Entropy: 3.16076
Value Function Loss: 0.00500

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.65720

Collected Steps per Second: 22,206.25990
Overall Steps per Second: 10,669.79196

Timestep Collection Time: 2.25225
Timestep Consumption Time: 2.43519
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.68744

Cumulative Model Updates: 103,390
Cumulative Timesteps: 862,269,638

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 862269638...
Checkpoint 862269638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.06053
Policy Entropy: 3.16063
Value Function Loss: 0.00464

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09942
Policy Update Magnitude: 0.56680
Value Function Update Magnitude: 0.65813

Collected Steps per Second: 22,874.11284
Overall Steps per Second: 10,681.24744

Timestep Collection Time: 2.18631
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.68204

Cumulative Model Updates: 103,396
Cumulative Timesteps: 862,319,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.48882
Policy Entropy: 3.17746
Value Function Loss: 0.00464

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09578
Policy Update Magnitude: 0.55012
Value Function Update Magnitude: 0.65043

Collected Steps per Second: 23,127.39131
Overall Steps per Second: 10,778.95103

Timestep Collection Time: 2.16194
Timestep Consumption Time: 2.47673
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.63867

Cumulative Model Updates: 103,402
Cumulative Timesteps: 862,369,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 862369648...
Checkpoint 862369648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009.32539
Policy Entropy: 3.16625
Value Function Loss: 0.00482

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.55717
Value Function Update Magnitude: 0.65428

Collected Steps per Second: 22,788.23527
Overall Steps per Second: 10,590.95146

Timestep Collection Time: 2.19464
Timestep Consumption Time: 2.52750
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.72214

Cumulative Model Updates: 103,408
Cumulative Timesteps: 862,419,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.61683
Policy Entropy: 3.15592
Value Function Loss: 0.00504

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.65449

Collected Steps per Second: 23,110.23800
Overall Steps per Second: 10,675.85033

Timestep Collection Time: 2.16380
Timestep Consumption Time: 2.52023
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.68403

Cumulative Model Updates: 103,414
Cumulative Timesteps: 862,469,666

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 862469666...
Checkpoint 862469666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.59868
Policy Entropy: 3.14452
Value Function Loss: 0.00515

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.56979
Value Function Update Magnitude: 0.66019

Collected Steps per Second: 22,086.17610
Overall Steps per Second: 10,791.09651

Timestep Collection Time: 2.26449
Timestep Consumption Time: 2.37025
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.63475

Cumulative Model Updates: 103,420
Cumulative Timesteps: 862,519,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.44080
Policy Entropy: 3.15563
Value Function Loss: 0.00502

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.56982
Value Function Update Magnitude: 0.66874

Collected Steps per Second: 21,783.52988
Overall Steps per Second: 10,554.12111

Timestep Collection Time: 2.29595
Timestep Consumption Time: 2.44286
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.73881

Cumulative Model Updates: 103,426
Cumulative Timesteps: 862,569,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 862569694...
Checkpoint 862569694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.60463
Policy Entropy: 3.15828
Value Function Loss: 0.00476

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09565
Policy Update Magnitude: 0.56416
Value Function Update Magnitude: 0.64830

Collected Steps per Second: 21,800.19595
Overall Steps per Second: 10,637.89749

Timestep Collection Time: 2.29493
Timestep Consumption Time: 2.40806
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.70300

Cumulative Model Updates: 103,432
Cumulative Timesteps: 862,619,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,133.98838
Policy Entropy: 3.13884
Value Function Loss: 0.00472

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.55983
Value Function Update Magnitude: 0.62948

Collected Steps per Second: 22,448.88385
Overall Steps per Second: 10,862.41318

Timestep Collection Time: 2.22755
Timestep Consumption Time: 2.37603
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.60358

Cumulative Model Updates: 103,438
Cumulative Timesteps: 862,669,730

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 862669730...
Checkpoint 862669730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.04471
Policy Entropy: 3.15128
Value Function Loss: 0.00462

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.55915
Value Function Update Magnitude: 0.61692

Collected Steps per Second: 22,091.49158
Overall Steps per Second: 10,697.39084

Timestep Collection Time: 2.26413
Timestep Consumption Time: 2.41159
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.67572

Cumulative Model Updates: 103,444
Cumulative Timesteps: 862,719,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.03386
Policy Entropy: 3.15052
Value Function Loss: 0.00461

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10770
Policy Update Magnitude: 0.55060
Value Function Update Magnitude: 0.60199

Collected Steps per Second: 21,902.99396
Overall Steps per Second: 10,590.29311

Timestep Collection Time: 2.28325
Timestep Consumption Time: 2.43900
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.72225

Cumulative Model Updates: 103,450
Cumulative Timesteps: 862,769,758

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 862769758...
Checkpoint 862769758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.88410
Policy Entropy: 3.16138
Value Function Loss: 0.00480

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.55015
Value Function Update Magnitude: 0.59715

Collected Steps per Second: 22,210.56782
Overall Steps per Second: 10,699.30138

Timestep Collection Time: 2.25208
Timestep Consumption Time: 2.42299
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.67507

Cumulative Model Updates: 103,456
Cumulative Timesteps: 862,819,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.23326
Policy Entropy: 3.14417
Value Function Loss: 0.00501

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.12448
Policy Update Magnitude: 0.57119
Value Function Update Magnitude: 0.62415

Collected Steps per Second: 22,009.78803
Overall Steps per Second: 10,786.32699

Timestep Collection Time: 2.27190
Timestep Consumption Time: 2.36397
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.63587

Cumulative Model Updates: 103,462
Cumulative Timesteps: 862,869,782

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 862869782...
Checkpoint 862869782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.63278
Policy Entropy: 3.15526
Value Function Loss: 0.00491

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.11797
Policy Update Magnitude: 0.57220
Value Function Update Magnitude: 0.64613

Collected Steps per Second: 22,122.71394
Overall Steps per Second: 10,612.12969

Timestep Collection Time: 2.26139
Timestep Consumption Time: 2.45284
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.71423

Cumulative Model Updates: 103,468
Cumulative Timesteps: 862,919,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.74339
Policy Entropy: 3.16494
Value Function Loss: 0.00470

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10843
Policy Update Magnitude: 0.56491
Value Function Update Magnitude: 0.64905

Collected Steps per Second: 22,293.35851
Overall Steps per Second: 10,841.75573

Timestep Collection Time: 2.24399
Timestep Consumption Time: 2.37021
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.61420

Cumulative Model Updates: 103,474
Cumulative Timesteps: 862,969,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 862969836...
Checkpoint 862969836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.10809
Policy Entropy: 3.16270
Value Function Loss: 0.00456

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09238
Policy Update Magnitude: 0.55927
Value Function Update Magnitude: 0.63404

Collected Steps per Second: 21,492.18153
Overall Steps per Second: 10,621.82884

Timestep Collection Time: 2.32643
Timestep Consumption Time: 2.38086
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.70729

Cumulative Model Updates: 103,480
Cumulative Timesteps: 863,019,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.60806
Policy Entropy: 3.17710
Value Function Loss: 0.00453

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09745
Policy Update Magnitude: 0.55724
Value Function Update Magnitude: 0.62926

Collected Steps per Second: 22,472.20399
Overall Steps per Second: 10,858.24970

Timestep Collection Time: 2.22515
Timestep Consumption Time: 2.38001
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.60516

Cumulative Model Updates: 103,486
Cumulative Timesteps: 863,069,840

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 863069840...
Checkpoint 863069840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.12308
Policy Entropy: 3.18377
Value Function Loss: 0.00469

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08019
Policy Update Magnitude: 0.56042
Value Function Update Magnitude: 0.60939

Collected Steps per Second: 21,967.67131
Overall Steps per Second: 10,791.41207

Timestep Collection Time: 2.27707
Timestep Consumption Time: 2.35828
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.63535

Cumulative Model Updates: 103,492
Cumulative Timesteps: 863,119,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,938.21274
Policy Entropy: 3.18339
Value Function Loss: 0.00450

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08451
Policy Update Magnitude: 0.55412
Value Function Update Magnitude: 0.58773

Collected Steps per Second: 22,428.41392
Overall Steps per Second: 10,814.67994

Timestep Collection Time: 2.23003
Timestep Consumption Time: 2.39480
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.62482

Cumulative Model Updates: 103,498
Cumulative Timesteps: 863,169,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 863169878...
Checkpoint 863169878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691.75808
Policy Entropy: 3.17162
Value Function Loss: 0.00463

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08464
Policy Update Magnitude: 0.55165
Value Function Update Magnitude: 0.57488

Collected Steps per Second: 21,841.13349
Overall Steps per Second: 10,672.00492

Timestep Collection Time: 2.28981
Timestep Consumption Time: 2.39647
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.68628

Cumulative Model Updates: 103,504
Cumulative Timesteps: 863,219,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 848.43367
Policy Entropy: 3.16756
Value Function Loss: 0.00441

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.56202

Collected Steps per Second: 21,990.74395
Overall Steps per Second: 10,620.71635

Timestep Collection Time: 2.27468
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.70985

Cumulative Model Updates: 103,510
Cumulative Timesteps: 863,269,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 863269912...
Checkpoint 863269912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.29398
Policy Entropy: 3.17528
Value Function Loss: 0.00446

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09306
Policy Update Magnitude: 0.55026
Value Function Update Magnitude: 0.58341

Collected Steps per Second: 22,313.33192
Overall Steps per Second: 10,673.61695

Timestep Collection Time: 2.24189
Timestep Consumption Time: 2.44481
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.68670

Cumulative Model Updates: 103,516
Cumulative Timesteps: 863,319,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.60101
Policy Entropy: 3.16973
Value Function Loss: 0.00436

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.09016
Policy Update Magnitude: 0.55492
Value Function Update Magnitude: 0.57885

Collected Steps per Second: 22,125.06411
Overall Steps per Second: 10,710.49778

Timestep Collection Time: 2.26097
Timestep Consumption Time: 2.40959
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.67056

Cumulative Model Updates: 103,522
Cumulative Timesteps: 863,369,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 863369960...
Checkpoint 863369960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.67304
Policy Entropy: 3.15740
Value Function Loss: 0.00461

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.59363

Collected Steps per Second: 22,112.29952
Overall Steps per Second: 10,629.08065

Timestep Collection Time: 2.26118
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.70408

Cumulative Model Updates: 103,528
Cumulative Timesteps: 863,419,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,979.01481
Policy Entropy: 3.15239
Value Function Loss: 0.00449

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09463
Policy Update Magnitude: 0.55419
Value Function Update Magnitude: 0.61256

Collected Steps per Second: 22,260.82145
Overall Steps per Second: 10,847.99114

Timestep Collection Time: 2.24691
Timestep Consumption Time: 2.36390
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.61081

Cumulative Model Updates: 103,534
Cumulative Timesteps: 863,469,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 863469978...
Checkpoint 863469978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.84799
Policy Entropy: 3.15328
Value Function Loss: 0.00437

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.53982
Value Function Update Magnitude: 0.58797

Collected Steps per Second: 22,090.35273
Overall Steps per Second: 10,731.29270

Timestep Collection Time: 2.26443
Timestep Consumption Time: 2.39689
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.66132

Cumulative Model Updates: 103,540
Cumulative Timesteps: 863,520,000

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.02960
Policy Entropy: 3.16182
Value Function Loss: 0.00445

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08753
Policy Update Magnitude: 0.53774
Value Function Update Magnitude: 0.55859

Collected Steps per Second: 21,939.56356
Overall Steps per Second: 10,638.85970

Timestep Collection Time: 2.27990
Timestep Consumption Time: 2.42173
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.70163

Cumulative Model Updates: 103,546
Cumulative Timesteps: 863,570,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 863570020...
Checkpoint 863570020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.23280
Policy Entropy: 3.17546
Value Function Loss: 0.00452

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.54676
Value Function Update Magnitude: 0.55831

Collected Steps per Second: 22,359.78507
Overall Steps per Second: 10,826.71331

Timestep Collection Time: 2.23741
Timestep Consumption Time: 2.38338
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.62079

Cumulative Model Updates: 103,552
Cumulative Timesteps: 863,620,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 735.45642
Policy Entropy: 3.18715
Value Function Loss: 0.00447

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.54116
Value Function Update Magnitude: 0.57425

Collected Steps per Second: 23,108.58539
Overall Steps per Second: 10,842.66010

Timestep Collection Time: 2.16370
Timestep Consumption Time: 2.44772
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.61141

Cumulative Model Updates: 103,558
Cumulative Timesteps: 863,670,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 863670048...
Checkpoint 863670048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.84852
Policy Entropy: 3.19770
Value Function Loss: 0.00421

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.53111
Value Function Update Magnitude: 0.56157

Collected Steps per Second: 22,178.26453
Overall Steps per Second: 10,774.13200

Timestep Collection Time: 2.25545
Timestep Consumption Time: 2.38734
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.64279

Cumulative Model Updates: 103,564
Cumulative Timesteps: 863,720,070

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,243.01756
Policy Entropy: 3.18437
Value Function Loss: 0.00433

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.52698
Value Function Update Magnitude: 0.55013

Collected Steps per Second: 22,144.24397
Overall Steps per Second: 10,776.61759

Timestep Collection Time: 2.25792
Timestep Consumption Time: 2.38175
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.63967

Cumulative Model Updates: 103,570
Cumulative Timesteps: 863,770,070

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 863770070...
Checkpoint 863770070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 853.04147
Policy Entropy: 3.17763
Value Function Loss: 0.00443

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.54091
Value Function Update Magnitude: 0.55342

Collected Steps per Second: 22,433.00681
Overall Steps per Second: 10,703.34815

Timestep Collection Time: 2.23002
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.67386

Cumulative Model Updates: 103,576
Cumulative Timesteps: 863,820,096

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.48529
Policy Entropy: 3.16059
Value Function Loss: 0.00464

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.55466
Value Function Update Magnitude: 0.57069

Collected Steps per Second: 22,745.04468
Overall Steps per Second: 10,564.73736

Timestep Collection Time: 2.19907
Timestep Consumption Time: 2.53536
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.73443

Cumulative Model Updates: 103,582
Cumulative Timesteps: 863,870,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 863870114...
Checkpoint 863870114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,496.30720
Policy Entropy: 3.16149
Value Function Loss: 0.00478

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.12011
Policy Update Magnitude: 0.56145
Value Function Update Magnitude: 0.58117

Collected Steps per Second: 22,817.48652
Overall Steps per Second: 10,643.33670

Timestep Collection Time: 2.19209
Timestep Consumption Time: 2.50738
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.69947

Cumulative Model Updates: 103,588
Cumulative Timesteps: 863,920,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.99811
Policy Entropy: 3.16515
Value Function Loss: 0.00488

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10904
Policy Update Magnitude: 0.56413
Value Function Update Magnitude: 0.61311

Collected Steps per Second: 22,971.76285
Overall Steps per Second: 10,775.01524

Timestep Collection Time: 2.17859
Timestep Consumption Time: 2.46605
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.64463

Cumulative Model Updates: 103,594
Cumulative Timesteps: 863,970,178

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 863970178...
Checkpoint 863970178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.06156
Policy Entropy: 3.18738
Value Function Loss: 0.00460

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12109
Policy Update Magnitude: 0.56134
Value Function Update Magnitude: 0.63165

Collected Steps per Second: 22,203.54791
Overall Steps per Second: 10,715.52070

Timestep Collection Time: 2.25324
Timestep Consumption Time: 2.41568
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.66893

Cumulative Model Updates: 103,600
Cumulative Timesteps: 864,020,208

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.26257
Policy Entropy: 3.17929
Value Function Loss: 0.00483

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.56280
Value Function Update Magnitude: 0.64506

Collected Steps per Second: 22,861.77072
Overall Steps per Second: 10,733.55787

Timestep Collection Time: 2.18749
Timestep Consumption Time: 2.47172
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.65922

Cumulative Model Updates: 103,606
Cumulative Timesteps: 864,070,218

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 864070218...
Checkpoint 864070218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.64105
Policy Entropy: 3.17875
Value Function Loss: 0.00459

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.56515
Value Function Update Magnitude: 0.64287

Collected Steps per Second: 22,918.89853
Overall Steps per Second: 10,815.43777

Timestep Collection Time: 2.18213
Timestep Consumption Time: 2.44200
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.62413

Cumulative Model Updates: 103,612
Cumulative Timesteps: 864,120,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.68031
Policy Entropy: 3.16248
Value Function Loss: 0.00475

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.56475
Value Function Update Magnitude: 0.62004

Collected Steps per Second: 22,717.73184
Overall Steps per Second: 10,654.20616

Timestep Collection Time: 2.20224
Timestep Consumption Time: 2.49355
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.69580

Cumulative Model Updates: 103,618
Cumulative Timesteps: 864,170,260

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 864170260...
Checkpoint 864170260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.46000
Policy Entropy: 3.15822
Value Function Loss: 0.00488

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.56927
Value Function Update Magnitude: 0.60586

Collected Steps per Second: 22,925.31554
Overall Steps per Second: 10,785.67690

Timestep Collection Time: 2.18195
Timestep Consumption Time: 2.45586
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.63782

Cumulative Model Updates: 103,624
Cumulative Timesteps: 864,220,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.62050
Policy Entropy: 3.15798
Value Function Loss: 0.00484

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.57186
Value Function Update Magnitude: 0.60512

Collected Steps per Second: 22,656.98070
Overall Steps per Second: 10,593.88971

Timestep Collection Time: 2.20806
Timestep Consumption Time: 2.51428
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.72234

Cumulative Model Updates: 103,630
Cumulative Timesteps: 864,270,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 864270310...
Checkpoint 864270310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.47997
Policy Entropy: 3.15723
Value Function Loss: 0.00506

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.57019
Value Function Update Magnitude: 0.61416

Collected Steps per Second: 22,860.38199
Overall Steps per Second: 10,641.53836

Timestep Collection Time: 2.18824
Timestep Consumption Time: 2.51258
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.70082

Cumulative Model Updates: 103,636
Cumulative Timesteps: 864,320,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 841.47556
Policy Entropy: 3.16749
Value Function Loss: 0.00483

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09059
Policy Update Magnitude: 0.57276
Value Function Update Magnitude: 0.65207

Collected Steps per Second: 23,056.29750
Overall Steps per Second: 10,798.53695

Timestep Collection Time: 2.16878
Timestep Consumption Time: 2.46185
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.63063

Cumulative Model Updates: 103,642
Cumulative Timesteps: 864,370,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 864370338...
Checkpoint 864370338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.84425
Policy Entropy: 3.16014
Value Function Loss: 0.00471

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09093
Policy Update Magnitude: 0.57082
Value Function Update Magnitude: 0.65371

Collected Steps per Second: 22,832.21767
Overall Steps per Second: 10,714.44824

Timestep Collection Time: 2.19033
Timestep Consumption Time: 2.47720
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.66753

Cumulative Model Updates: 103,648
Cumulative Timesteps: 864,420,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 564.62160
Policy Entropy: 3.15909
Value Function Loss: 0.00475

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.08336
Policy Update Magnitude: 0.56947
Value Function Update Magnitude: 0.63865

Collected Steps per Second: 22,628.77702
Overall Steps per Second: 10,607.10253

Timestep Collection Time: 2.21002
Timestep Consumption Time: 2.50475
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.71477

Cumulative Model Updates: 103,654
Cumulative Timesteps: 864,470,358

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 864470358...
Checkpoint 864470358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775.51574
Policy Entropy: 3.14583
Value Function Loss: 0.00467

Mean KL Divergence: 0.00722
SB3 Clip Fraction: 0.07715
Policy Update Magnitude: 0.56785
Value Function Update Magnitude: 0.62269

Collected Steps per Second: 22,985.42181
Overall Steps per Second: 10,876.79815

Timestep Collection Time: 2.17590
Timestep Consumption Time: 2.42233
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.59823

Cumulative Model Updates: 103,660
Cumulative Timesteps: 864,520,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.80130
Policy Entropy: 3.15054
Value Function Loss: 0.00502

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08972
Policy Update Magnitude: 0.56335
Value Function Update Magnitude: 0.62067

Collected Steps per Second: 22,899.79811
Overall Steps per Second: 10,634.46147

Timestep Collection Time: 2.18351
Timestep Consumption Time: 2.51837
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.70188

Cumulative Model Updates: 103,666
Cumulative Timesteps: 864,570,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 864570374...
Checkpoint 864570374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.57075
Policy Entropy: 3.14703
Value Function Loss: 0.00490

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.56596
Value Function Update Magnitude: 0.62383

Collected Steps per Second: 22,916.70732
Overall Steps per Second: 10,643.72563

Timestep Collection Time: 2.18312
Timestep Consumption Time: 2.51730
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.70042

Cumulative Model Updates: 103,672
Cumulative Timesteps: 864,620,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.09754
Policy Entropy: 3.15221
Value Function Loss: 0.00510

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.57324
Value Function Update Magnitude: 0.61937

Collected Steps per Second: 23,101.69494
Overall Steps per Second: 10,868.85938

Timestep Collection Time: 2.16486
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.60140

Cumulative Model Updates: 103,678
Cumulative Timesteps: 864,670,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 864670416...
Checkpoint 864670416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.71741
Policy Entropy: 3.14539
Value Function Loss: 0.00493

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08945
Policy Update Magnitude: 0.57718
Value Function Update Magnitude: 0.62005

Collected Steps per Second: 23,063.05309
Overall Steps per Second: 10,708.54181

Timestep Collection Time: 2.16849
Timestep Consumption Time: 2.50180
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.67029

Cumulative Model Updates: 103,684
Cumulative Timesteps: 864,720,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.32417
Policy Entropy: 3.13186
Value Function Loss: 0.00491

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.58029
Value Function Update Magnitude: 0.62420

Collected Steps per Second: 22,651.53871
Overall Steps per Second: 10,748.76787

Timestep Collection Time: 2.20833
Timestep Consumption Time: 2.44542
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.65374

Cumulative Model Updates: 103,690
Cumulative Timesteps: 864,770,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 864770450...
Checkpoint 864770450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.19119
Policy Entropy: 3.14194
Value Function Loss: 0.00495

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10383
Policy Update Magnitude: 0.57770
Value Function Update Magnitude: 0.63834

Collected Steps per Second: 22,810.28849
Overall Steps per Second: 10,659.05567

Timestep Collection Time: 2.19208
Timestep Consumption Time: 2.49895
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.69103

Cumulative Model Updates: 103,696
Cumulative Timesteps: 864,820,452

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 856.85438
Policy Entropy: 3.14882
Value Function Loss: 0.00476

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.57993
Value Function Update Magnitude: 0.64248

Collected Steps per Second: 22,977.23943
Overall Steps per Second: 10,806.19763

Timestep Collection Time: 2.17615
Timestep Consumption Time: 2.45101
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.62716

Cumulative Model Updates: 103,702
Cumulative Timesteps: 864,870,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 864870454...
Checkpoint 864870454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.38972
Policy Entropy: 3.15977
Value Function Loss: 0.00480

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10285
Policy Update Magnitude: 0.57717
Value Function Update Magnitude: 0.64986

Collected Steps per Second: 22,525.49871
Overall Steps per Second: 10,724.42466

Timestep Collection Time: 2.22033
Timestep Consumption Time: 2.44323
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.66356

Cumulative Model Updates: 103,708
Cumulative Timesteps: 864,920,468

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,782.14231
Policy Entropy: 3.16161
Value Function Loss: 0.00440

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.56973
Value Function Update Magnitude: 0.64766

Collected Steps per Second: 22,951.02440
Overall Steps per Second: 10,702.92894

Timestep Collection Time: 2.17960
Timestep Consumption Time: 2.49426
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.67386

Cumulative Model Updates: 103,714
Cumulative Timesteps: 864,970,492

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 864970492...
Checkpoint 864970492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.09952
Policy Entropy: 3.17188
Value Function Loss: 0.00450

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10992
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.62163

Collected Steps per Second: 22,269.70246
Overall Steps per Second: 10,850.12107

Timestep Collection Time: 2.24547
Timestep Consumption Time: 2.36332
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.60880

Cumulative Model Updates: 103,720
Cumulative Timesteps: 865,020,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 651.52238
Policy Entropy: 3.16658
Value Function Loss: 0.00480

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.57325
Value Function Update Magnitude: 0.61679

Collected Steps per Second: 22,239.63019
Overall Steps per Second: 10,716.38493

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.41809
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.66687

Cumulative Model Updates: 103,726
Cumulative Timesteps: 865,070,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 865070510...
Checkpoint 865070510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593.02439
Policy Entropy: 3.16436
Value Function Loss: 0.00499

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09956
Policy Update Magnitude: 0.57944
Value Function Update Magnitude: 0.65769

Collected Steps per Second: 23,056.77742
Overall Steps per Second: 10,832.54004

Timestep Collection Time: 2.16882
Timestep Consumption Time: 2.44746
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.61628

Cumulative Model Updates: 103,732
Cumulative Timesteps: 865,120,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,136.33281
Policy Entropy: 3.17394
Value Function Loss: 0.00483

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11799
Policy Update Magnitude: 0.57510
Value Function Update Magnitude: 0.66384

Collected Steps per Second: 22,652.09340
Overall Steps per Second: 10,579.24585

Timestep Collection Time: 2.20854
Timestep Consumption Time: 2.52034
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.72888

Cumulative Model Updates: 103,738
Cumulative Timesteps: 865,170,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 865170544...
Checkpoint 865170544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.92913
Policy Entropy: 3.16037
Value Function Loss: 0.00477

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.57658
Value Function Update Magnitude: 0.66711

Collected Steps per Second: 22,564.59912
Overall Steps per Second: 10,901.06038

Timestep Collection Time: 2.21630
Timestep Consumption Time: 2.37132
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.58763

Cumulative Model Updates: 103,744
Cumulative Timesteps: 865,220,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.33259
Policy Entropy: 3.15294
Value Function Loss: 0.00474

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.58319
Value Function Update Magnitude: 0.68149

Collected Steps per Second: 23,173.19737
Overall Steps per Second: 10,748.71897

Timestep Collection Time: 2.15853
Timestep Consumption Time: 2.49505
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.65358

Cumulative Model Updates: 103,750
Cumulative Timesteps: 865,270,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 865270574...
Checkpoint 865270574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.67153
Policy Entropy: 3.15681
Value Function Loss: 0.00465

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11231
Policy Update Magnitude: 0.57878
Value Function Update Magnitude: 0.66349

Collected Steps per Second: 23,150.56738
Overall Steps per Second: 10,845.03498

Timestep Collection Time: 2.16150
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.61409

Cumulative Model Updates: 103,756
Cumulative Timesteps: 865,320,614

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.77628
Policy Entropy: 3.16736
Value Function Loss: 0.00470

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.12783
Policy Update Magnitude: 0.57466
Value Function Update Magnitude: 0.65197

Collected Steps per Second: 22,440.01844
Overall Steps per Second: 10,513.04580

Timestep Collection Time: 2.22896
Timestep Consumption Time: 2.52874
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.75771

Cumulative Model Updates: 103,762
Cumulative Timesteps: 865,370,632

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 865370632...
Checkpoint 865370632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,809.10723
Policy Entropy: 3.17859
Value Function Loss: 0.00460

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.14088
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.64282

Collected Steps per Second: 22,824.04852
Overall Steps per Second: 10,628.37720

Timestep Collection Time: 2.19190
Timestep Consumption Time: 2.51512
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.70702

Cumulative Model Updates: 103,768
Cumulative Timesteps: 865,420,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.50290
Policy Entropy: 3.17392
Value Function Loss: 0.00467

Mean KL Divergence: 0.01504
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.55853
Value Function Update Magnitude: 0.61597

Collected Steps per Second: 22,124.94375
Overall Steps per Second: 10,697.08290

Timestep Collection Time: 2.26098
Timestep Consumption Time: 2.41544
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.67642

Cumulative Model Updates: 103,774
Cumulative Timesteps: 865,470,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 865470684...
Checkpoint 865470684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,231.59800
Policy Entropy: 3.17103
Value Function Loss: 0.00496

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.14555
Policy Update Magnitude: 0.55869
Value Function Update Magnitude: 0.59579

Collected Steps per Second: 22,159.58517
Overall Steps per Second: 10,809.67538

Timestep Collection Time: 2.25681
Timestep Consumption Time: 2.36960
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.62641

Cumulative Model Updates: 103,780
Cumulative Timesteps: 865,520,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.35778
Policy Entropy: 3.17207
Value Function Loss: 0.00490

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.56384
Value Function Update Magnitude: 0.61036

Collected Steps per Second: 22,782.71299
Overall Steps per Second: 10,643.19563

Timestep Collection Time: 2.19552
Timestep Consumption Time: 2.50419
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.69972

Cumulative Model Updates: 103,786
Cumulative Timesteps: 865,570,714

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 865570714...
Checkpoint 865570714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.24946
Policy Entropy: 3.16504
Value Function Loss: 0.00478

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.56504
Value Function Update Magnitude: 0.62298

Collected Steps per Second: 22,081.85555
Overall Steps per Second: 10,670.71840

Timestep Collection Time: 2.26485
Timestep Consumption Time: 2.42200
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.68684

Cumulative Model Updates: 103,792
Cumulative Timesteps: 865,620,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.87127
Policy Entropy: 3.17455
Value Function Loss: 0.00442

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11950
Policy Update Magnitude: 0.56512
Value Function Update Magnitude: 0.60645

Collected Steps per Second: 21,989.91063
Overall Steps per Second: 10,755.81570

Timestep Collection Time: 2.27477
Timestep Consumption Time: 2.37592
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.65069

Cumulative Model Updates: 103,798
Cumulative Timesteps: 865,670,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 865670748...
Checkpoint 865670748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.47494
Policy Entropy: 3.15624
Value Function Loss: 0.00454

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.55914
Value Function Update Magnitude: 0.59641

Collected Steps per Second: 22,190.82235
Overall Steps per Second: 10,651.22536

Timestep Collection Time: 2.25372
Timestep Consumption Time: 2.44170
PPO Batch Consumption Time: 0.29525
Total Iteration Time: 4.69542

Cumulative Model Updates: 103,804
Cumulative Timesteps: 865,720,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,923.06446
Policy Entropy: 3.15782
Value Function Loss: 0.00444

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.56099
Value Function Update Magnitude: 0.61063

Collected Steps per Second: 22,191.56694
Overall Steps per Second: 10,783.59907

Timestep Collection Time: 2.25446
Timestep Consumption Time: 2.38499
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.63945

Cumulative Model Updates: 103,810
Cumulative Timesteps: 865,770,790

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 865770790...
Checkpoint 865770790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.44671
Policy Entropy: 3.15894
Value Function Loss: 0.00434

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.55818
Value Function Update Magnitude: 0.60505

Collected Steps per Second: 22,253.64410
Overall Steps per Second: 10,718.76935

Timestep Collection Time: 2.24691
Timestep Consumption Time: 2.41799
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.66490

Cumulative Model Updates: 103,816
Cumulative Timesteps: 865,820,792

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600.34037
Policy Entropy: 3.14767
Value Function Loss: 0.00424

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.58091

Collected Steps per Second: 22,145.40939
Overall Steps per Second: 10,661.01968

Timestep Collection Time: 2.25798
Timestep Consumption Time: 2.43237
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69036

Cumulative Model Updates: 103,822
Cumulative Timesteps: 865,870,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 865870796...
Checkpoint 865870796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,521.03258
Policy Entropy: 3.14890
Value Function Loss: 0.00430

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.55292
Value Function Update Magnitude: 0.57918

Collected Steps per Second: 22,250.43464
Overall Steps per Second: 10,651.92295

Timestep Collection Time: 2.24724
Timestep Consumption Time: 2.44694
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.69418

Cumulative Model Updates: 103,828
Cumulative Timesteps: 865,920,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649.21889
Policy Entropy: 3.16061
Value Function Loss: 0.00440

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.55237
Value Function Update Magnitude: 0.59206

Collected Steps per Second: 23,235.56659
Overall Steps per Second: 10,728.99243

Timestep Collection Time: 2.15222
Timestep Consumption Time: 2.50880
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.66102

Cumulative Model Updates: 103,834
Cumulative Timesteps: 865,970,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 865970806...
Checkpoint 865970806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690.21470
Policy Entropy: 3.16818
Value Function Loss: 0.00482

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09378
Policy Update Magnitude: 0.55341
Value Function Update Magnitude: 0.61936

Collected Steps per Second: 22,121.21053
Overall Steps per Second: 10,593.09967

Timestep Collection Time: 2.26163
Timestep Consumption Time: 2.46126
PPO Batch Consumption Time: 0.29794
Total Iteration Time: 4.72289

Cumulative Model Updates: 103,840
Cumulative Timesteps: 866,020,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.61112
Policy Entropy: 3.17802
Value Function Loss: 0.00490

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09418
Policy Update Magnitude: 0.56402
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 22,115.92288
Overall Steps per Second: 10,676.59096

Timestep Collection Time: 2.26154
Timestep Consumption Time: 2.42310
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.68464

Cumulative Model Updates: 103,846
Cumulative Timesteps: 866,070,852

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 866070852...
Checkpoint 866070852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.68205
Policy Entropy: 3.16672
Value Function Loss: 0.00455

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.56226
Value Function Update Magnitude: 0.61090

Collected Steps per Second: 22,143.71948
Overall Steps per Second: 10,806.37955

Timestep Collection Time: 2.25807
Timestep Consumption Time: 2.36901
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.62708

Cumulative Model Updates: 103,852
Cumulative Timesteps: 866,120,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.17253
Policy Entropy: 3.16952
Value Function Loss: 0.00413

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.54836
Value Function Update Magnitude: 0.56869

Collected Steps per Second: 22,081.27667
Overall Steps per Second: 10,585.66611

Timestep Collection Time: 2.26481
Timestep Consumption Time: 2.45950
PPO Batch Consumption Time: 0.29584
Total Iteration Time: 4.72431

Cumulative Model Updates: 103,858
Cumulative Timesteps: 866,170,864

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 866170864...
Checkpoint 866170864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.24913
Policy Entropy: 3.15930
Value Function Loss: 0.00427

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.53567
Value Function Update Magnitude: 0.55149

Collected Steps per Second: 21,888.16413
Overall Steps per Second: 10,604.21022

Timestep Collection Time: 2.28571
Timestep Consumption Time: 2.43223
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.71794

Cumulative Model Updates: 103,864
Cumulative Timesteps: 866,220,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,111.17164
Policy Entropy: 3.16628
Value Function Loss: 0.00449

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.55366
Value Function Update Magnitude: 0.55914

Collected Steps per Second: 22,163.38768
Overall Steps per Second: 10,778.92238

Timestep Collection Time: 2.25688
Timestep Consumption Time: 2.38366
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.64054

Cumulative Model Updates: 103,870
Cumulative Timesteps: 866,270,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 866270914...
Checkpoint 866270914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.08983
Policy Entropy: 3.15225
Value Function Loss: 0.00465

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11131
Policy Update Magnitude: 0.56494
Value Function Update Magnitude: 0.58027

Collected Steps per Second: 22,029.45968
Overall Steps per Second: 10,770.41084

Timestep Collection Time: 2.27032
Timestep Consumption Time: 2.37332
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.64365

Cumulative Model Updates: 103,876
Cumulative Timesteps: 866,320,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.12038
Policy Entropy: 3.17887
Value Function Loss: 0.00465

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.56043
Value Function Update Magnitude: 0.59266

Collected Steps per Second: 21,983.93397
Overall Steps per Second: 10,651.64348

Timestep Collection Time: 2.27439
Timestep Consumption Time: 2.41972
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.69411

Cumulative Model Updates: 103,882
Cumulative Timesteps: 866,370,928

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 866370928...
Checkpoint 866370928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,507.11939
Policy Entropy: 3.17190
Value Function Loss: 0.00461

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10851
Policy Update Magnitude: 0.55649
Value Function Update Magnitude: 0.60071

Collected Steps per Second: 22,505.51640
Overall Steps per Second: 10,844.53531

Timestep Collection Time: 2.22310
Timestep Consumption Time: 2.39047
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.61357

Cumulative Model Updates: 103,888
Cumulative Timesteps: 866,420,960

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.01782
Policy Entropy: 3.18744
Value Function Loss: 0.00442

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09731
Policy Update Magnitude: 0.55375
Value Function Update Magnitude: 0.59788

Collected Steps per Second: 23,252.09451
Overall Steps per Second: 10,886.19604

Timestep Collection Time: 2.15086
Timestep Consumption Time: 2.44321
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.59407

Cumulative Model Updates: 103,894
Cumulative Timesteps: 866,470,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 866470972...
Checkpoint 866470972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.00118
Policy Entropy: 3.17672
Value Function Loss: 0.00433

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.54742
Value Function Update Magnitude: 0.58257

Collected Steps per Second: 22,193.81360
Overall Steps per Second: 10,737.31511

Timestep Collection Time: 2.25315
Timestep Consumption Time: 2.40407
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.65722

Cumulative Model Updates: 103,900
Cumulative Timesteps: 866,520,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.14869
Policy Entropy: 3.16628
Value Function Loss: 0.00447

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.54244
Value Function Update Magnitude: 0.58054

Collected Steps per Second: 22,093.11331
Overall Steps per Second: 10,808.14518

Timestep Collection Time: 2.26360
Timestep Consumption Time: 2.36346
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.62707

Cumulative Model Updates: 103,906
Cumulative Timesteps: 866,570,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 866570988...
Checkpoint 866570988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.76232
Policy Entropy: 3.16188
Value Function Loss: 0.00464

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.55525
Value Function Update Magnitude: 0.56654

Collected Steps per Second: 22,016.39057
Overall Steps per Second: 10,660.97490

Timestep Collection Time: 2.27149
Timestep Consumption Time: 2.41945
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.69094

Cumulative Model Updates: 103,912
Cumulative Timesteps: 866,620,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.59359
Policy Entropy: 3.16930
Value Function Loss: 0.00471

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.55508
Value Function Update Magnitude: 0.57348

Collected Steps per Second: 22,396.56904
Overall Steps per Second: 10,870.90189

Timestep Collection Time: 2.23284
Timestep Consumption Time: 2.36733
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.60017

Cumulative Model Updates: 103,918
Cumulative Timesteps: 866,671,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 866671006...
Checkpoint 866671006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.96912
Policy Entropy: 3.16939
Value Function Loss: 0.00471

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.55624
Value Function Update Magnitude: 0.58321

Collected Steps per Second: 21,791.54323
Overall Steps per Second: 10,705.51772

Timestep Collection Time: 2.29474
Timestep Consumption Time: 2.37631
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.67105

Cumulative Model Updates: 103,924
Cumulative Timesteps: 866,721,012

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.97418
Policy Entropy: 3.15512
Value Function Loss: 0.00467

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.55480
Value Function Update Magnitude: 0.61854

Collected Steps per Second: 22,226.64334
Overall Steps per Second: 10,684.72588

Timestep Collection Time: 2.25081
Timestep Consumption Time: 2.43139
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.68220

Cumulative Model Updates: 103,930
Cumulative Timesteps: 866,771,040

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 866771040...
Checkpoint 866771040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847.13517
Policy Entropy: 3.15122
Value Function Loss: 0.00441

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.55718
Value Function Update Magnitude: 0.61510

Collected Steps per Second: 23,147.67999
Overall Steps per Second: 10,879.77309

Timestep Collection Time: 2.16073
Timestep Consumption Time: 2.43642
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.59715

Cumulative Model Updates: 103,936
Cumulative Timesteps: 866,821,056

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.61345
Policy Entropy: 3.15188
Value Function Loss: 0.00443

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.55721
Value Function Update Magnitude: 0.60199

Collected Steps per Second: 22,852.64848
Overall Steps per Second: 10,674.86864

Timestep Collection Time: 2.18889
Timestep Consumption Time: 2.49707
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.68596

Cumulative Model Updates: 103,942
Cumulative Timesteps: 866,871,078

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 866871078...
Checkpoint 866871078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.92824
Policy Entropy: 3.17348
Value Function Loss: 0.00435

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.55506
Value Function Update Magnitude: 0.59100

Collected Steps per Second: 22,195.82862
Overall Steps per Second: 10,824.80678

Timestep Collection Time: 2.25358
Timestep Consumption Time: 2.36729
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.62087

Cumulative Model Updates: 103,948
Cumulative Timesteps: 866,921,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.97019
Policy Entropy: 3.17981
Value Function Loss: 0.00435

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09933
Policy Update Magnitude: 0.54876
Value Function Update Magnitude: 0.59620

Collected Steps per Second: 22,894.96933
Overall Steps per Second: 10,669.82600

Timestep Collection Time: 2.18598
Timestep Consumption Time: 2.50463
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.69061

Cumulative Model Updates: 103,954
Cumulative Timesteps: 866,971,146

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 866971146...
Checkpoint 866971146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.12925
Policy Entropy: 3.19577
Value Function Loss: 0.00422

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08778
Policy Update Magnitude: 0.54362
Value Function Update Magnitude: 0.58198

Collected Steps per Second: 22,018.50599
Overall Steps per Second: 10,632.74755

Timestep Collection Time: 2.27136
Timestep Consumption Time: 2.43222
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.70358

Cumulative Model Updates: 103,960
Cumulative Timesteps: 867,021,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.00167
Policy Entropy: 3.19349
Value Function Loss: 0.00426

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.09103
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.57685

Collected Steps per Second: 22,298.32818
Overall Steps per Second: 10,801.88000

Timestep Collection Time: 2.24322
Timestep Consumption Time: 2.38746
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.63068

Cumulative Model Updates: 103,966
Cumulative Timesteps: 867,071,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 867071178...
Checkpoint 867071178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.30686
Policy Entropy: 3.19504
Value Function Loss: 0.00450

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.55565
Value Function Update Magnitude: 0.58468

Collected Steps per Second: 22,378.08733
Overall Steps per Second: 10,672.50339

Timestep Collection Time: 2.23558
Timestep Consumption Time: 2.45198
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.68756

Cumulative Model Updates: 103,972
Cumulative Timesteps: 867,121,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,820.37619
Policy Entropy: 3.17877
Value Function Loss: 0.00481

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09506
Policy Update Magnitude: 0.56433
Value Function Update Magnitude: 0.61678

Collected Steps per Second: 22,741.86887
Overall Steps per Second: 10,767.06719

Timestep Collection Time: 2.19859
Timestep Consumption Time: 2.44520
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.64379

Cumulative Model Updates: 103,978
Cumulative Timesteps: 867,171,206

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 867171206...
Checkpoint 867171206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.01558
Policy Entropy: 3.17350
Value Function Loss: 0.00470

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09067
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.64131

Collected Steps per Second: 22,166.47890
Overall Steps per Second: 10,692.00732

Timestep Collection Time: 2.25701
Timestep Consumption Time: 2.42218
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.67920

Cumulative Model Updates: 103,984
Cumulative Timesteps: 867,221,236

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.67346
Policy Entropy: 3.16571
Value Function Loss: 0.00466

Mean KL Divergence: 0.00762
SB3 Clip Fraction: 0.08314
Policy Update Magnitude: 0.55937
Value Function Update Magnitude: 0.62613

Collected Steps per Second: 23,262.78274
Overall Steps per Second: 10,872.36264

Timestep Collection Time: 2.14979
Timestep Consumption Time: 2.44995
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.59974

Cumulative Model Updates: 103,990
Cumulative Timesteps: 867,271,246

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 867271246...
Checkpoint 867271246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.92078
Policy Entropy: 3.17854
Value Function Loss: 0.00452

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08916
Policy Update Magnitude: 0.56112
Value Function Update Magnitude: 0.60187

Collected Steps per Second: 22,489.83328
Overall Steps per Second: 10,722.82919

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.44040
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.66425

Cumulative Model Updates: 103,996
Cumulative Timesteps: 867,321,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.96512
Policy Entropy: 3.17602
Value Function Loss: 0.00451

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08516
Policy Update Magnitude: 0.55522
Value Function Update Magnitude: 0.60494

Collected Steps per Second: 22,383.35717
Overall Steps per Second: 10,827.55149

Timestep Collection Time: 2.23443
Timestep Consumption Time: 2.38471
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.61914

Cumulative Model Updates: 104,002
Cumulative Timesteps: 867,371,274

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 867371274...
Checkpoint 867371274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 868.75843
Policy Entropy: 3.17845
Value Function Loss: 0.00461

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08241
Policy Update Magnitude: 0.56214
Value Function Update Magnitude: 0.61783

Collected Steps per Second: 22,910.40913
Overall Steps per Second: 10,713.89942

Timestep Collection Time: 2.18250
Timestep Consumption Time: 2.48452
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.66702

Cumulative Model Updates: 104,008
Cumulative Timesteps: 867,421,276

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,635.14132
Policy Entropy: 3.16333
Value Function Loss: 0.00460

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09283
Policy Update Magnitude: 0.57542
Value Function Update Magnitude: 0.63452

Collected Steps per Second: 23,129.55242
Overall Steps per Second: 10,839.51337

Timestep Collection Time: 2.16174
Timestep Consumption Time: 2.45102
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.61275

Cumulative Model Updates: 104,014
Cumulative Timesteps: 867,471,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 867471276...
Checkpoint 867471276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.07125
Policy Entropy: 3.17036
Value Function Loss: 0.00471

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.63629

Collected Steps per Second: 22,550.79360
Overall Steps per Second: 10,763.39445

Timestep Collection Time: 2.21855
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.64816

Cumulative Model Updates: 104,020
Cumulative Timesteps: 867,521,306

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.02612
Policy Entropy: 3.16728
Value Function Loss: 0.00469

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08936
Policy Update Magnitude: 0.56257
Value Function Update Magnitude: 0.64838

Collected Steps per Second: 22,802.18342
Overall Steps per Second: 10,766.12175

Timestep Collection Time: 2.19304
Timestep Consumption Time: 2.45172
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.64476

Cumulative Model Updates: 104,026
Cumulative Timesteps: 867,571,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 867571312...
Checkpoint 867571312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.31642
Policy Entropy: 3.15577
Value Function Loss: 0.00458

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09006
Policy Update Magnitude: 0.56383
Value Function Update Magnitude: 0.65378

Collected Steps per Second: 22,403.09151
Overall Steps per Second: 10,667.25459

Timestep Collection Time: 2.23228
Timestep Consumption Time: 2.45590
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.68818

Cumulative Model Updates: 104,032
Cumulative Timesteps: 867,621,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,124.89166
Policy Entropy: 3.14080
Value Function Loss: 0.00487

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10743
Policy Update Magnitude: 0.56970
Value Function Update Magnitude: 0.65642

Collected Steps per Second: 22,701.35194
Overall Steps per Second: 10,592.38366

Timestep Collection Time: 2.20295
Timestep Consumption Time: 2.51836
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.72132

Cumulative Model Updates: 104,038
Cumulative Timesteps: 867,671,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 867671332...
Checkpoint 867671332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.59168
Policy Entropy: 3.13673
Value Function Loss: 0.00487

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10552
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.66202

Collected Steps per Second: 22,865.72748
Overall Steps per Second: 10,590.76571

Timestep Collection Time: 2.18677
Timestep Consumption Time: 2.53452
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.72128

Cumulative Model Updates: 104,044
Cumulative Timesteps: 867,721,334

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.94471
Policy Entropy: 3.14886
Value Function Loss: 0.00513

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.58715
Value Function Update Magnitude: 0.66023

Collected Steps per Second: 22,983.02997
Overall Steps per Second: 10,805.11435

Timestep Collection Time: 2.17552
Timestep Consumption Time: 2.45192
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.62744

Cumulative Model Updates: 104,050
Cumulative Timesteps: 867,771,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 867771334...
Checkpoint 867771334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.25783
Policy Entropy: 3.17038
Value Function Loss: 0.00496

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11298
Policy Update Magnitude: 0.58436
Value Function Update Magnitude: 0.65478

Collected Steps per Second: 22,713.65285
Overall Steps per Second: 10,679.86171

Timestep Collection Time: 2.20150
Timestep Consumption Time: 2.48059
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.68208

Cumulative Model Updates: 104,056
Cumulative Timesteps: 867,821,338

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.63382
Policy Entropy: 3.18377
Value Function Loss: 0.00482

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11059
Policy Update Magnitude: 0.57544
Value Function Update Magnitude: 0.62772

Collected Steps per Second: 23,122.38663
Overall Steps per Second: 10,862.39701

Timestep Collection Time: 2.16327
Timestep Consumption Time: 2.44161
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.60488

Cumulative Model Updates: 104,062
Cumulative Timesteps: 867,871,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 867871358...
Checkpoint 867871358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.90022
Policy Entropy: 3.18322
Value Function Loss: 0.00468

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10715
Policy Update Magnitude: 0.56658
Value Function Update Magnitude: 0.61750

Collected Steps per Second: 22,789.79334
Overall Steps per Second: 10,691.31528

Timestep Collection Time: 2.19440
Timestep Consumption Time: 2.48322
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.67763

Cumulative Model Updates: 104,068
Cumulative Timesteps: 867,921,368

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.14813
Policy Entropy: 3.18420
Value Function Loss: 0.00476

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09468
Policy Update Magnitude: 0.56037
Value Function Update Magnitude: 0.61623

Collected Steps per Second: 22,961.05021
Overall Steps per Second: 10,698.01512

Timestep Collection Time: 2.17882
Timestep Consumption Time: 2.49756
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.67638

Cumulative Model Updates: 104,074
Cumulative Timesteps: 867,971,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 867971396...
Checkpoint 867971396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.25421
Policy Entropy: 3.17375
Value Function Loss: 0.00463

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.56527
Value Function Update Magnitude: 0.63457

Collected Steps per Second: 22,597.71331
Overall Steps per Second: 10,652.83295

Timestep Collection Time: 2.21350
Timestep Consumption Time: 2.48197
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.69546

Cumulative Model Updates: 104,080
Cumulative Timesteps: 868,021,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.15144
Policy Entropy: 3.16809
Value Function Loss: 0.00487

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08737
Policy Update Magnitude: 0.57040
Value Function Update Magnitude: 0.64657

Collected Steps per Second: 23,434.18825
Overall Steps per Second: 10,777.36837

Timestep Collection Time: 2.13491
Timestep Consumption Time: 2.50722
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.64214

Cumulative Model Updates: 104,086
Cumulative Timesteps: 868,071,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 868071446...
Checkpoint 868071446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,310.71906
Policy Entropy: 3.16218
Value Function Loss: 0.00473

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.08954
Policy Update Magnitude: 0.57762
Value Function Update Magnitude: 0.65757

Collected Steps per Second: 22,774.40151
Overall Steps per Second: 10,671.52082

Timestep Collection Time: 2.19606
Timestep Consumption Time: 2.49062
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.68668

Cumulative Model Updates: 104,092
Cumulative Timesteps: 868,121,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.71795
Policy Entropy: 3.15705
Value Function Loss: 0.00479

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.57954
Value Function Update Magnitude: 0.65584

Collected Steps per Second: 22,305.88899
Overall Steps per Second: 10,789.52392

Timestep Collection Time: 2.24326
Timestep Consumption Time: 2.39438
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.63765

Cumulative Model Updates: 104,098
Cumulative Timesteps: 868,171,498

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 868171498...
Checkpoint 868171498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.95702
Policy Entropy: 3.15792
Value Function Loss: 0.00488

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09317
Policy Update Magnitude: 0.57961
Value Function Update Magnitude: 0.68347

Collected Steps per Second: 22,257.01256
Overall Steps per Second: 10,654.60710

Timestep Collection Time: 2.24711
Timestep Consumption Time: 2.44701
PPO Batch Consumption Time: 0.29696
Total Iteration Time: 4.69412

Cumulative Model Updates: 104,104
Cumulative Timesteps: 868,221,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.25228
Policy Entropy: 3.14885
Value Function Loss: 0.00461

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08869
Policy Update Magnitude: 0.57698
Value Function Update Magnitude: 0.68314

Collected Steps per Second: 22,064.26452
Overall Steps per Second: 10,687.49304

Timestep Collection Time: 2.26710
Timestep Consumption Time: 2.41332
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.68042

Cumulative Model Updates: 104,110
Cumulative Timesteps: 868,271,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 868271534...
Checkpoint 868271534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.68538
Policy Entropy: 3.15427
Value Function Loss: 0.00473

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08565
Policy Update Magnitude: 0.56995
Value Function Update Magnitude: 0.64527

Collected Steps per Second: 22,247.74541
Overall Steps per Second: 10,867.05883

Timestep Collection Time: 2.24859
Timestep Consumption Time: 2.35487
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.60345

Cumulative Model Updates: 104,116
Cumulative Timesteps: 868,321,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.24171
Policy Entropy: 3.15538
Value Function Loss: 0.00462

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10584
Policy Update Magnitude: 0.55819
Value Function Update Magnitude: 0.62575

Collected Steps per Second: 22,021.16911
Overall Steps per Second: 10,685.36056

Timestep Collection Time: 2.27145
Timestep Consumption Time: 2.40972
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.68117

Cumulative Model Updates: 104,122
Cumulative Timesteps: 868,371,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 868371580...
Checkpoint 868371580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756.99588
Policy Entropy: 3.16275
Value Function Loss: 0.00448

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.55025
Value Function Update Magnitude: 0.62235

Collected Steps per Second: 22,002.51584
Overall Steps per Second: 10,730.24325

Timestep Collection Time: 2.27256
Timestep Consumption Time: 2.38735
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.65991

Cumulative Model Updates: 104,128
Cumulative Timesteps: 868,421,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.11997
Policy Entropy: 3.14658
Value Function Loss: 0.00467

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.61160

Collected Steps per Second: 22,406.86190
Overall Steps per Second: 10,737.47704

Timestep Collection Time: 2.23164
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.65696

Cumulative Model Updates: 104,134
Cumulative Timesteps: 868,471,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 868471586...
Checkpoint 868471586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,861.85663
Policy Entropy: 3.14177
Value Function Loss: 0.00482

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10136
Policy Update Magnitude: 0.55818
Value Function Update Magnitude: 0.62033

Collected Steps per Second: 21,983.77379
Overall Steps per Second: 10,640.00641

Timestep Collection Time: 2.27468
Timestep Consumption Time: 2.42513
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.69981

Cumulative Model Updates: 104,140
Cumulative Timesteps: 868,521,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.84898
Policy Entropy: 3.13021
Value Function Loss: 0.00496

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10002
Policy Update Magnitude: 0.56750
Value Function Update Magnitude: 0.64599

Collected Steps per Second: 23,131.28159
Overall Steps per Second: 10,707.32618

Timestep Collection Time: 2.16157
Timestep Consumption Time: 2.50812
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.66970

Cumulative Model Updates: 104,146
Cumulative Timesteps: 868,571,592

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 868571592...
Checkpoint 868571592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.42834
Policy Entropy: 3.14657
Value Function Loss: 0.00463

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.56649
Value Function Update Magnitude: 0.65874

Collected Steps per Second: 22,856.24954
Overall Steps per Second: 10,637.77053

Timestep Collection Time: 2.18767
Timestep Consumption Time: 2.51275
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.70042

Cumulative Model Updates: 104,152
Cumulative Timesteps: 868,621,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.25865
Policy Entropy: 3.14941
Value Function Loss: 0.00456

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08923
Policy Update Magnitude: 0.56189
Value Function Update Magnitude: 0.64480

Collected Steps per Second: 23,026.30503
Overall Steps per Second: 10,805.81694

Timestep Collection Time: 2.17160
Timestep Consumption Time: 2.45590
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.62751

Cumulative Model Updates: 104,158
Cumulative Timesteps: 868,671,598

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 868671598...
Checkpoint 868671598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,473.35725
Policy Entropy: 3.15730
Value Function Loss: 0.00444

Mean KL Divergence: 0.00807
SB3 Clip Fraction: 0.09000
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.63358

Collected Steps per Second: 22,760.37434
Overall Steps per Second: 10,797.37244

Timestep Collection Time: 2.19750
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.63224

Cumulative Model Updates: 104,164
Cumulative Timesteps: 868,721,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.18113
Policy Entropy: 3.15214
Value Function Loss: 0.00454

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08907
Policy Update Magnitude: 0.55748
Value Function Update Magnitude: 0.63421

Collected Steps per Second: 22,949.40360
Overall Steps per Second: 10,802.75911

Timestep Collection Time: 2.17897
Timestep Consumption Time: 2.45004
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.62900

Cumulative Model Updates: 104,170
Cumulative Timesteps: 868,771,620

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 868771620...
Checkpoint 868771620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.49327
Policy Entropy: 3.15666
Value Function Loss: 0.00463

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.08770
Policy Update Magnitude: 0.56151
Value Function Update Magnitude: 0.63736

Collected Steps per Second: 22,073.34883
Overall Steps per Second: 10,589.85393

Timestep Collection Time: 2.26527
Timestep Consumption Time: 2.45642
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.72169

Cumulative Model Updates: 104,176
Cumulative Timesteps: 868,821,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.76220
Policy Entropy: 3.14443
Value Function Loss: 0.00455

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.56959
Value Function Update Magnitude: 0.65901

Collected Steps per Second: 23,148.09352
Overall Steps per Second: 10,713.24015

Timestep Collection Time: 2.16121
Timestep Consumption Time: 2.50852
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.66974

Cumulative Model Updates: 104,182
Cumulative Timesteps: 868,871,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 868871650...
Checkpoint 868871650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.59865
Policy Entropy: 3.15303
Value Function Loss: 0.00472

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08532
Policy Update Magnitude: 0.58021
Value Function Update Magnitude: 0.65088

Collected Steps per Second: 22,844.31919
Overall Steps per Second: 10,703.53448

Timestep Collection Time: 2.18917
Timestep Consumption Time: 2.48312
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.67229

Cumulative Model Updates: 104,188
Cumulative Timesteps: 868,921,660

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,908.22047
Policy Entropy: 3.14680
Value Function Loss: 0.00476

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09206
Policy Update Magnitude: 0.58557
Value Function Update Magnitude: 0.63771

Collected Steps per Second: 23,006.53845
Overall Steps per Second: 10,713.90150

Timestep Collection Time: 2.17434
Timestep Consumption Time: 2.49474
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.66907

Cumulative Model Updates: 104,194
Cumulative Timesteps: 868,971,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 868971684...
Checkpoint 868971684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.47309
Policy Entropy: 3.14614
Value Function Loss: 0.00473

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09396
Policy Update Magnitude: 0.57044
Value Function Update Magnitude: 0.62789

Collected Steps per Second: 22,892.77511
Overall Steps per Second: 10,616.31423

Timestep Collection Time: 2.18479
Timestep Consumption Time: 2.52645
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.71124

Cumulative Model Updates: 104,200
Cumulative Timesteps: 869,021,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.59409
Policy Entropy: 3.15529
Value Function Loss: 0.00459

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.55472
Value Function Update Magnitude: 0.62323

Collected Steps per Second: 23,224.05412
Overall Steps per Second: 10,857.02550

Timestep Collection Time: 2.15337
Timestep Consumption Time: 2.45286
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.60623

Cumulative Model Updates: 104,206
Cumulative Timesteps: 869,071,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 869071710...
Checkpoint 869071710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.85752
Policy Entropy: 3.13873
Value Function Loss: 0.00467

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08908
Policy Update Magnitude: 0.55722
Value Function Update Magnitude: 0.62278

Collected Steps per Second: 22,337.43703
Overall Steps per Second: 10,653.74178

Timestep Collection Time: 2.23947
Timestep Consumption Time: 2.45597
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.69544

Cumulative Model Updates: 104,212
Cumulative Timesteps: 869,121,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.36998
Policy Entropy: 3.13935
Value Function Loss: 0.00505

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.58101
Value Function Update Magnitude: 0.63451

Collected Steps per Second: 23,425.12552
Overall Steps per Second: 10,886.45103

Timestep Collection Time: 2.13557
Timestep Consumption Time: 2.45968
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.59525

Cumulative Model Updates: 104,218
Cumulative Timesteps: 869,171,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 869171760...
Checkpoint 869171760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.03404
Policy Entropy: 3.14294
Value Function Loss: 0.00506

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.58484
Value Function Update Magnitude: 0.63824

Collected Steps per Second: 22,386.28729
Overall Steps per Second: 10,714.15491

Timestep Collection Time: 2.23449
Timestep Consumption Time: 2.43428
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.66878

Cumulative Model Updates: 104,224
Cumulative Timesteps: 869,221,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.06817
Policy Entropy: 3.14356
Value Function Loss: 0.00488

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.57963
Value Function Update Magnitude: 0.63322

Collected Steps per Second: 23,349.10274
Overall Steps per Second: 10,900.66778

Timestep Collection Time: 2.14261
Timestep Consumption Time: 2.44683
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.58944

Cumulative Model Updates: 104,230
Cumulative Timesteps: 869,271,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 869271810...
Checkpoint 869271810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.00897
Policy Entropy: 3.13465
Value Function Loss: 0.00463

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09233
Policy Update Magnitude: 0.58012
Value Function Update Magnitude: 0.62454

Collected Steps per Second: 22,648.62469
Overall Steps per Second: 10,641.72550

Timestep Collection Time: 2.20817
Timestep Consumption Time: 2.49144
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.69961

Cumulative Model Updates: 104,236
Cumulative Timesteps: 869,321,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.64066
Policy Entropy: 3.12442
Value Function Loss: 0.00472

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.57310
Value Function Update Magnitude: 0.62911

Collected Steps per Second: 23,050.79598
Overall Steps per Second: 10,799.24260

Timestep Collection Time: 2.17034
Timestep Consumption Time: 2.46221
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.63255

Cumulative Model Updates: 104,242
Cumulative Timesteps: 869,371,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 869371850...
Checkpoint 869371850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 837.79997
Policy Entropy: 3.13892
Value Function Loss: 0.00444

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.56695
Value Function Update Magnitude: 0.62368

Collected Steps per Second: 22,687.11241
Overall Steps per Second: 10,787.12904

Timestep Collection Time: 2.20389
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.63515

Cumulative Model Updates: 104,248
Cumulative Timesteps: 869,421,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.67930
Policy Entropy: 3.14553
Value Function Loss: 0.00453

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11598
Policy Update Magnitude: 0.55604
Value Function Update Magnitude: 0.61041

Collected Steps per Second: 22,189.70780
Overall Steps per Second: 10,812.69983

Timestep Collection Time: 2.25384
Timestep Consumption Time: 2.37146
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.62530

Cumulative Model Updates: 104,254
Cumulative Timesteps: 869,471,862

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 869471862...
Checkpoint 869471862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.03758
Policy Entropy: 3.14850
Value Function Loss: 0.00448

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10801
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.61027

Collected Steps per Second: 22,101.63765
Overall Steps per Second: 10,664.76077

Timestep Collection Time: 2.26228
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.68834

Cumulative Model Updates: 104,260
Cumulative Timesteps: 869,521,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.76401
Policy Entropy: 3.13034
Value Function Loss: 0.00483

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11778
Policy Update Magnitude: 0.55775
Value Function Update Magnitude: 0.61760

Collected Steps per Second: 21,843.46648
Overall Steps per Second: 10,575.62217

Timestep Collection Time: 2.29011
Timestep Consumption Time: 2.44001
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.73012

Cumulative Model Updates: 104,266
Cumulative Timesteps: 869,571,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 869571886...
Checkpoint 869571886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.20334
Policy Entropy: 3.11344
Value Function Loss: 0.00487

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.57539
Value Function Update Magnitude: 0.64463

Collected Steps per Second: 21,645.08815
Overall Steps per Second: 10,515.38616

Timestep Collection Time: 2.31073
Timestep Consumption Time: 2.44573
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.75646

Cumulative Model Updates: 104,272
Cumulative Timesteps: 869,621,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,594.39899
Policy Entropy: 3.09654
Value Function Loss: 0.00491

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.57921
Value Function Update Magnitude: 0.65496

Collected Steps per Second: 23,344.14900
Overall Steps per Second: 10,894.42345

Timestep Collection Time: 2.14229
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.59042

Cumulative Model Updates: 104,278
Cumulative Timesteps: 869,671,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 869671912...
Checkpoint 869671912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 934.34555
Policy Entropy: 3.11384
Value Function Loss: 0.00446

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.57127
Value Function Update Magnitude: 0.65031

Collected Steps per Second: 22,062.54295
Overall Steps per Second: 10,695.14142

Timestep Collection Time: 2.26692
Timestep Consumption Time: 2.40941
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.67633

Cumulative Model Updates: 104,284
Cumulative Timesteps: 869,721,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.74170
Policy Entropy: 3.11921
Value Function Loss: 0.00449

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.56446
Value Function Update Magnitude: 0.62278

Collected Steps per Second: 23,405.23474
Overall Steps per Second: 10,879.58744

Timestep Collection Time: 2.13739
Timestep Consumption Time: 2.46077
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.59815

Cumulative Model Updates: 104,290
Cumulative Timesteps: 869,771,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 869771952...
Checkpoint 869771952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.37515
Policy Entropy: 3.12580
Value Function Loss: 0.00437

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.56633
Value Function Update Magnitude: 0.60639

Collected Steps per Second: 21,949.01341
Overall Steps per Second: 10,682.67728

Timestep Collection Time: 2.27883
Timestep Consumption Time: 2.40333
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.68216

Cumulative Model Updates: 104,296
Cumulative Timesteps: 869,821,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.03847
Policy Entropy: 3.11595
Value Function Loss: 0.00465

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11751
Policy Update Magnitude: 0.56844
Value Function Update Magnitude: 0.58503

Collected Steps per Second: 22,189.84637
Overall Steps per Second: 10,792.35654

Timestep Collection Time: 2.25346
Timestep Consumption Time: 2.37982
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.63328

Cumulative Model Updates: 104,302
Cumulative Timesteps: 869,871,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 869871974...
Checkpoint 869871974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.74924
Policy Entropy: 3.11834
Value Function Loss: 0.00492

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.57762
Value Function Update Magnitude: 0.58133

Collected Steps per Second: 22,443.94398
Overall Steps per Second: 10,714.95441

Timestep Collection Time: 2.22902
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.66899

Cumulative Model Updates: 104,308
Cumulative Timesteps: 869,922,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.80392
Policy Entropy: 3.11160
Value Function Loss: 0.00495

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.57837
Value Function Update Magnitude: 0.60049

Collected Steps per Second: 22,113.87003
Overall Steps per Second: 10,632.40284

Timestep Collection Time: 2.26166
Timestep Consumption Time: 2.44227
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.70392

Cumulative Model Updates: 104,314
Cumulative Timesteps: 869,972,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 869972016...
Checkpoint 869972016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.00242
Policy Entropy: 3.11766
Value Function Loss: 0.00517

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.58089
Value Function Update Magnitude: 0.61346

Collected Steps per Second: 22,363.22012
Overall Steps per Second: 10,855.64910

Timestep Collection Time: 2.23644
Timestep Consumption Time: 2.37075
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.60719

Cumulative Model Updates: 104,320
Cumulative Timesteps: 870,022,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.55943
Policy Entropy: 3.11828
Value Function Loss: 0.00493

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10877
Policy Update Magnitude: 0.57903
Value Function Update Magnitude: 0.62536

Collected Steps per Second: 22,152.00402
Overall Steps per Second: 10,630.78974

Timestep Collection Time: 2.25731
Timestep Consumption Time: 2.44638
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.70370

Cumulative Model Updates: 104,326
Cumulative Timesteps: 870,072,034

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 870072034...
Checkpoint 870072034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.69881
Policy Entropy: 3.12533
Value Function Loss: 0.00496

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.12132
Policy Update Magnitude: 0.57687
Value Function Update Magnitude: 0.62128

Collected Steps per Second: 22,895.16031
Overall Steps per Second: 10,660.68520

Timestep Collection Time: 2.18474
Timestep Consumption Time: 2.50726
PPO Batch Consumption Time: 0.29534
Total Iteration Time: 4.69201

Cumulative Model Updates: 104,332
Cumulative Timesteps: 870,122,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.95559
Policy Entropy: 3.12964
Value Function Loss: 0.00472

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.57801
Value Function Update Magnitude: 0.62067

Collected Steps per Second: 23,058.07129
Overall Steps per Second: 10,832.29905

Timestep Collection Time: 2.16870
Timestep Consumption Time: 2.44768
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.61638

Cumulative Model Updates: 104,338
Cumulative Timesteps: 870,172,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 870172060...
Checkpoint 870172060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.79874
Policy Entropy: 3.13239
Value Function Loss: 0.00466

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.57047
Value Function Update Magnitude: 0.62149

Collected Steps per Second: 22,511.95593
Overall Steps per Second: 10,598.64610

Timestep Collection Time: 2.22122
Timestep Consumption Time: 2.49674
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.71796

Cumulative Model Updates: 104,344
Cumulative Timesteps: 870,222,064

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.93257
Policy Entropy: 3.12495
Value Function Loss: 0.00481

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.57116
Value Function Update Magnitude: 0.61216

Collected Steps per Second: 22,906.87618
Overall Steps per Second: 10,703.65512

Timestep Collection Time: 2.18362
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.67317

Cumulative Model Updates: 104,350
Cumulative Timesteps: 870,272,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 870272084...
Checkpoint 870272084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.21406
Policy Entropy: 3.12256
Value Function Loss: 0.00467

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.62602

Collected Steps per Second: 21,813.66964
Overall Steps per Second: 10,597.55267

Timestep Collection Time: 2.29278
Timestep Consumption Time: 2.42661
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.71939

Cumulative Model Updates: 104,356
Cumulative Timesteps: 870,322,098

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.72865
Policy Entropy: 3.12422
Value Function Loss: 0.00465

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.57061
Value Function Update Magnitude: 0.64104

Collected Steps per Second: 22,559.63939
Overall Steps per Second: 10,689.29813

Timestep Collection Time: 2.21670
Timestep Consumption Time: 2.46162
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.67832

Cumulative Model Updates: 104,362
Cumulative Timesteps: 870,372,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 870372106...
Checkpoint 870372106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,564.82204
Policy Entropy: 3.13060
Value Function Loss: 0.00464

Mean KL Divergence: 0.00772
SB3 Clip Fraction: 0.08636
Policy Update Magnitude: 0.57748
Value Function Update Magnitude: 0.64392

Collected Steps per Second: 22,085.27713
Overall Steps per Second: 10,655.67654

Timestep Collection Time: 2.26431
Timestep Consumption Time: 2.42877
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.69309

Cumulative Model Updates: 104,368
Cumulative Timesteps: 870,422,114

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.85654
Policy Entropy: 3.12810
Value Function Loss: 0.00467

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.08221
Policy Update Magnitude: 0.58039
Value Function Update Magnitude: 0.65048

Collected Steps per Second: 23,295.77021
Overall Steps per Second: 10,890.65414

Timestep Collection Time: 2.14700
Timestep Consumption Time: 2.44556
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.59256

Cumulative Model Updates: 104,374
Cumulative Timesteps: 870,472,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 870472130...
Checkpoint 870472130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,515.41225
Policy Entropy: 3.12426
Value Function Loss: 0.00475

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.58342
Value Function Update Magnitude: 0.64837

Collected Steps per Second: 22,542.26190
Overall Steps per Second: 10,698.23929

Timestep Collection Time: 2.21832
Timestep Consumption Time: 2.45590
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.67423

Cumulative Model Updates: 104,380
Cumulative Timesteps: 870,522,136

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.42786
Policy Entropy: 3.12621
Value Function Loss: 0.00454

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.57852
Value Function Update Magnitude: 0.63815

Collected Steps per Second: 23,091.42741
Overall Steps per Second: 10,779.24255

Timestep Collection Time: 2.16583
Timestep Consumption Time: 2.47383
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.63966

Cumulative Model Updates: 104,386
Cumulative Timesteps: 870,572,148

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 870572148...
Checkpoint 870572148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.04910
Policy Entropy: 3.12263
Value Function Loss: 0.00451

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.57348
Value Function Update Magnitude: 0.63097

Collected Steps per Second: 22,740.27600
Overall Steps per Second: 10,755.67197

Timestep Collection Time: 2.19962
Timestep Consumption Time: 2.45095
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.65057

Cumulative Model Updates: 104,392
Cumulative Timesteps: 870,622,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.82110
Policy Entropy: 3.11640
Value Function Loss: 0.00499

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.58054
Value Function Update Magnitude: 0.65905

Collected Steps per Second: 23,215.45575
Overall Steps per Second: 10,842.28709

Timestep Collection Time: 2.15408
Timestep Consumption Time: 2.45823
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.61231

Cumulative Model Updates: 104,398
Cumulative Timesteps: 870,672,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 870672176...
Checkpoint 870672176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.89157
Policy Entropy: 3.11119
Value Function Loss: 0.00463

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.58086
Value Function Update Magnitude: 0.68503

Collected Steps per Second: 22,446.60552
Overall Steps per Second: 10,655.44603

Timestep Collection Time: 2.22876
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.69506

Cumulative Model Updates: 104,404
Cumulative Timesteps: 870,722,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.15263
Policy Entropy: 3.10923
Value Function Loss: 0.00488

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.57809
Value Function Update Magnitude: 0.68676

Collected Steps per Second: 23,127.20071
Overall Steps per Second: 10,865.21048

Timestep Collection Time: 2.16282
Timestep Consumption Time: 2.44086
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.60368

Cumulative Model Updates: 104,410
Cumulative Timesteps: 870,772,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 870772224...
Checkpoint 870772224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.30103
Policy Entropy: 3.11728
Value Function Loss: 0.00467

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.57841
Value Function Update Magnitude: 0.67033

Collected Steps per Second: 22,042.92523
Overall Steps per Second: 10,705.16377

Timestep Collection Time: 2.26948
Timestep Consumption Time: 2.40359
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.67307

Cumulative Model Updates: 104,416
Cumulative Timesteps: 870,822,250

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.08604
Policy Entropy: 3.10968
Value Function Loss: 0.00506

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11182
Policy Update Magnitude: 0.58573
Value Function Update Magnitude: 0.67639

Collected Steps per Second: 23,086.27261
Overall Steps per Second: 10,858.79246

Timestep Collection Time: 2.16605
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.60512

Cumulative Model Updates: 104,422
Cumulative Timesteps: 870,872,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 870872256...
Checkpoint 870872256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 752.55429
Policy Entropy: 3.12624
Value Function Loss: 0.00506

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11618
Policy Update Magnitude: 0.59049
Value Function Update Magnitude: 0.68960

Collected Steps per Second: 22,367.22079
Overall Steps per Second: 10,712.98396

Timestep Collection Time: 2.23559
Timestep Consumption Time: 2.43201
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.66761

Cumulative Model Updates: 104,428
Cumulative Timesteps: 870,922,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.28086
Policy Entropy: 3.12393
Value Function Loss: 0.00516

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11135
Policy Update Magnitude: 0.59354
Value Function Update Magnitude: 0.69437

Collected Steps per Second: 23,308.77939
Overall Steps per Second: 10,864.50216

Timestep Collection Time: 2.14563
Timestep Consumption Time: 2.45762
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.60325

Cumulative Model Updates: 104,434
Cumulative Timesteps: 870,972,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 870972272...
Checkpoint 870972272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.26866
Policy Entropy: 3.11236
Value Function Loss: 0.00524

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.59645
Value Function Update Magnitude: 0.70618

Collected Steps per Second: 22,653.41355
Overall Steps per Second: 10,674.14395

Timestep Collection Time: 2.20770
Timestep Consumption Time: 2.47764
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.68534

Cumulative Model Updates: 104,440
Cumulative Timesteps: 871,022,284

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,485.47634
Policy Entropy: 3.09674
Value Function Loss: 0.00528

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.60272
Value Function Update Magnitude: 0.71383

Collected Steps per Second: 23,006.89922
Overall Steps per Second: 10,827.82986

Timestep Collection Time: 2.17344
Timestep Consumption Time: 2.44466
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.61810

Cumulative Model Updates: 104,446
Cumulative Timesteps: 871,072,288

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 871072288...
Checkpoint 871072288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.05064
Policy Entropy: 3.11022
Value Function Loss: 0.00517

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.59119
Value Function Update Magnitude: 0.69034

Collected Steps per Second: 22,296.62455
Overall Steps per Second: 10,653.02539

Timestep Collection Time: 2.24321
Timestep Consumption Time: 2.45179
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.69500

Cumulative Model Updates: 104,452
Cumulative Timesteps: 871,122,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.87164
Policy Entropy: 3.13476
Value Function Loss: 0.00527

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.58429
Value Function Update Magnitude: 0.67287

Collected Steps per Second: 22,742.45302
Overall Steps per Second: 10,595.12431

Timestep Collection Time: 2.19932
Timestep Consumption Time: 2.52153
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.72085

Cumulative Model Updates: 104,458
Cumulative Timesteps: 871,172,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 871172322...
Checkpoint 871172322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.74273
Policy Entropy: 3.14580
Value Function Loss: 0.00516

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.58583
Value Function Update Magnitude: 0.66533

Collected Steps per Second: 22,477.50666
Overall Steps per Second: 10,575.06425

Timestep Collection Time: 2.22569
Timestep Consumption Time: 2.50506
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.73075

Cumulative Model Updates: 104,464
Cumulative Timesteps: 871,222,350

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.83262
Policy Entropy: 3.15901
Value Function Loss: 0.00524

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.57617
Value Function Update Magnitude: 0.65037

Collected Steps per Second: 23,071.99533
Overall Steps per Second: 10,841.97287

Timestep Collection Time: 2.16904
Timestep Consumption Time: 2.44673
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.61577

Cumulative Model Updates: 104,470
Cumulative Timesteps: 871,272,394

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 871272394...
Checkpoint 871272394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 948.88678
Policy Entropy: 3.13620
Value Function Loss: 0.00490

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.56782
Value Function Update Magnitude: 0.63762

Collected Steps per Second: 22,621.90123
Overall Steps per Second: 10,726.39496

Timestep Collection Time: 2.21140
Timestep Consumption Time: 2.45243
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.66382

Cumulative Model Updates: 104,476
Cumulative Timesteps: 871,322,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.86789
Policy Entropy: 3.14013
Value Function Loss: 0.00471

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10593
Policy Update Magnitude: 0.55975
Value Function Update Magnitude: 0.62646

Collected Steps per Second: 22,931.12138
Overall Steps per Second: 10,784.18707

Timestep Collection Time: 2.18062
Timestep Consumption Time: 2.45617
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.63679

Cumulative Model Updates: 104,482
Cumulative Timesteps: 871,372,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 871372424...
Checkpoint 871372424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.99168
Policy Entropy: 3.12072
Value Function Loss: 0.00476

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10794
Policy Update Magnitude: 0.56896
Value Function Update Magnitude: 0.62251

Collected Steps per Second: 22,830.85851
Overall Steps per Second: 10,778.78696

Timestep Collection Time: 2.19124
Timestep Consumption Time: 2.45009
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.64134

Cumulative Model Updates: 104,488
Cumulative Timesteps: 871,422,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.64492
Policy Entropy: 3.11139
Value Function Loss: 0.00515

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11891
Policy Update Magnitude: 0.58868
Value Function Update Magnitude: 0.64843

Collected Steps per Second: 23,104.37393
Overall Steps per Second: 10,849.92997

Timestep Collection Time: 2.16600
Timestep Consumption Time: 2.44638
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.61238

Cumulative Model Updates: 104,494
Cumulative Timesteps: 871,472,496

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 871472496...
Checkpoint 871472496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.78112
Policy Entropy: 3.09821
Value Function Loss: 0.00537

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.59287
Value Function Update Magnitude: 0.66159

Collected Steps per Second: 22,410.05006
Overall Steps per Second: 10,697.91374

Timestep Collection Time: 2.23168
Timestep Consumption Time: 2.44325
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.67493

Cumulative Model Updates: 104,500
Cumulative Timesteps: 871,522,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.53352
Policy Entropy: 3.09786
Value Function Loss: 0.00556

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12223
Policy Update Magnitude: 0.59178
Value Function Update Magnitude: 0.65153

Collected Steps per Second: 23,037.45878
Overall Steps per Second: 10,841.49857

Timestep Collection Time: 2.17168
Timestep Consumption Time: 2.44300
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.61468

Cumulative Model Updates: 104,506
Cumulative Timesteps: 871,572,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 871572538...
Checkpoint 871572538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.53770
Policy Entropy: 3.10177
Value Function Loss: 0.00539

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.59275
Value Function Update Magnitude: 0.64699

Collected Steps per Second: 22,544.91481
Overall Steps per Second: 10,677.05788

Timestep Collection Time: 2.21833
Timestep Consumption Time: 2.46573
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.68406

Cumulative Model Updates: 104,512
Cumulative Timesteps: 871,622,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.23424
Policy Entropy: 3.10829
Value Function Loss: 0.00553

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.59890
Value Function Update Magnitude: 0.65426

Collected Steps per Second: 23,028.20267
Overall Steps per Second: 10,810.37071

Timestep Collection Time: 2.17255
Timestep Consumption Time: 2.45541
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.62796

Cumulative Model Updates: 104,518
Cumulative Timesteps: 871,672,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 871672580...
Checkpoint 871672580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.84695
Policy Entropy: 3.10498
Value Function Loss: 0.00542

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.60143
Value Function Update Magnitude: 0.66403

Collected Steps per Second: 22,490.22107
Overall Steps per Second: 10,714.82678

Timestep Collection Time: 2.22363
Timestep Consumption Time: 2.44373
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.66736

Cumulative Model Updates: 104,524
Cumulative Timesteps: 871,722,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.24813
Policy Entropy: 3.11326
Value Function Loss: 0.00555

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.60151
Value Function Update Magnitude: 0.65955

Collected Steps per Second: 22,696.86332
Overall Steps per Second: 10,674.77540

Timestep Collection Time: 2.20356
Timestep Consumption Time: 2.48169
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.68525

Cumulative Model Updates: 104,530
Cumulative Timesteps: 871,772,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 871772604...
Checkpoint 871772604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.21299
Policy Entropy: 3.10248
Value Function Loss: 0.00558

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.60531
Value Function Update Magnitude: 0.66296

Collected Steps per Second: 22,989.39439
Overall Steps per Second: 10,888.07944

Timestep Collection Time: 2.17561
Timestep Consumption Time: 2.41804
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.59365

Cumulative Model Updates: 104,536
Cumulative Timesteps: 871,822,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.88356
Policy Entropy: 3.11785
Value Function Loss: 0.00537

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.60221
Value Function Update Magnitude: 0.65747

Collected Steps per Second: 22,233.20136
Overall Steps per Second: 10,486.32974

Timestep Collection Time: 2.25033
Timestep Consumption Time: 2.52084
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.77116

Cumulative Model Updates: 104,542
Cumulative Timesteps: 871,872,652

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 871872652...
Checkpoint 871872652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.68489
Policy Entropy: 3.11999
Value Function Loss: 0.00535

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.59847
Value Function Update Magnitude: 0.63712

Collected Steps per Second: 22,556.15594
Overall Steps per Second: 10,683.30257

Timestep Collection Time: 2.21687
Timestep Consumption Time: 2.46371
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.68058

Cumulative Model Updates: 104,548
Cumulative Timesteps: 871,922,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.91964
Policy Entropy: 3.14282
Value Function Loss: 0.00493

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.59225
Value Function Update Magnitude: 0.61584

Collected Steps per Second: 22,718.81609
Overall Steps per Second: 10,602.68700

Timestep Collection Time: 2.20188
Timestep Consumption Time: 2.51617
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.71805

Cumulative Model Updates: 104,554
Cumulative Timesteps: 871,972,680

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 871972680...
Checkpoint 871972680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,493.82410
Policy Entropy: 3.15793
Value Function Loss: 0.00503

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.60804

Collected Steps per Second: 22,831.94014
Overall Steps per Second: 10,821.71738

Timestep Collection Time: 2.19097
Timestep Consumption Time: 2.43159
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.62256

Cumulative Model Updates: 104,560
Cumulative Timesteps: 872,022,704

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.45241
Policy Entropy: 3.15997
Value Function Loss: 0.00506

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.57560
Value Function Update Magnitude: 0.62007

Collected Steps per Second: 23,135.51052
Overall Steps per Second: 10,815.70679

Timestep Collection Time: 2.16230
Timestep Consumption Time: 2.46301
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.62531

Cumulative Model Updates: 104,566
Cumulative Timesteps: 872,072,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 872072730...
Checkpoint 872072730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.64645
Policy Entropy: 3.14853
Value Function Loss: 0.00515

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.57551
Value Function Update Magnitude: 0.64899

Collected Steps per Second: 22,665.01238
Overall Steps per Second: 10,796.21189

Timestep Collection Time: 2.20719
Timestep Consumption Time: 2.42647
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.63366

Cumulative Model Updates: 104,572
Cumulative Timesteps: 872,122,756

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.27058
Policy Entropy: 3.13745
Value Function Loss: 0.00526

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10289
Policy Update Magnitude: 0.58203
Value Function Update Magnitude: 0.64436

Collected Steps per Second: 22,905.65350
Overall Steps per Second: 10,838.75027

Timestep Collection Time: 2.18339
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.61419

Cumulative Model Updates: 104,578
Cumulative Timesteps: 872,172,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 872172768...
Checkpoint 872172768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.74711
Policy Entropy: 3.13915
Value Function Loss: 0.00501

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10330
Policy Update Magnitude: 0.58308
Value Function Update Magnitude: 0.63440

Collected Steps per Second: 22,373.95660
Overall Steps per Second: 10,713.07422

Timestep Collection Time: 2.23546
Timestep Consumption Time: 2.43323
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.66869

Cumulative Model Updates: 104,584
Cumulative Timesteps: 872,222,784

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 893.89146
Policy Entropy: 3.14072
Value Function Loss: 0.00468

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10506
Policy Update Magnitude: 0.57134
Value Function Update Magnitude: 0.61389

Collected Steps per Second: 22,946.94127
Overall Steps per Second: 10,861.25197

Timestep Collection Time: 2.17903
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.60371

Cumulative Model Updates: 104,590
Cumulative Timesteps: 872,272,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 872272786...
Checkpoint 872272786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.72498
Policy Entropy: 3.14210
Value Function Loss: 0.00464

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09675
Policy Update Magnitude: 0.56163
Value Function Update Magnitude: 0.60528

Collected Steps per Second: 22,316.62272
Overall Steps per Second: 10,764.96043

Timestep Collection Time: 2.24057
Timestep Consumption Time: 2.40431
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.64488

Cumulative Model Updates: 104,596
Cumulative Timesteps: 872,322,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.33953
Policy Entropy: 3.16363
Value Function Loss: 0.00455

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09897
Policy Update Magnitude: 0.56651
Value Function Update Magnitude: 0.62540

Collected Steps per Second: 23,142.90177
Overall Steps per Second: 10,896.77489

Timestep Collection Time: 2.16066
Timestep Consumption Time: 2.42822
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.58888

Cumulative Model Updates: 104,602
Cumulative Timesteps: 872,372,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 872372792...
Checkpoint 872372792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,423.18284
Policy Entropy: 3.16833
Value Function Loss: 0.00477

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08637
Policy Update Magnitude: 0.56853
Value Function Update Magnitude: 0.63830

Collected Steps per Second: 22,715.55797
Overall Steps per Second: 10,615.55802

Timestep Collection Time: 2.20157
Timestep Consumption Time: 2.50944
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.71101

Cumulative Model Updates: 104,608
Cumulative Timesteps: 872,422,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.50772
Policy Entropy: 3.16051
Value Function Loss: 0.00489

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.57422
Value Function Update Magnitude: 0.64983

Collected Steps per Second: 23,035.29132
Overall Steps per Second: 10,848.31912

Timestep Collection Time: 2.17136
Timestep Consumption Time: 2.43930
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.61067

Cumulative Model Updates: 104,614
Cumulative Timesteps: 872,472,820

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 872472820...
Checkpoint 872472820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742.77855
Policy Entropy: 3.13908
Value Function Loss: 0.00519

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.57243
Value Function Update Magnitude: 0.65704

Collected Steps per Second: 22,333.09640
Overall Steps per Second: 10,737.24572

Timestep Collection Time: 2.23964
Timestep Consumption Time: 2.41873
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.65836

Cumulative Model Updates: 104,620
Cumulative Timesteps: 872,522,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755.61617
Policy Entropy: 3.12973
Value Function Loss: 0.00520

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.57761
Value Function Update Magnitude: 0.65800

Collected Steps per Second: 22,976.57728
Overall Steps per Second: 10,823.78671

Timestep Collection Time: 2.17735
Timestep Consumption Time: 2.44469
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.62204

Cumulative Model Updates: 104,626
Cumulative Timesteps: 872,572,866

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 872572866...
Checkpoint 872572866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.94828
Policy Entropy: 3.13658
Value Function Loss: 0.00514

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.57728
Value Function Update Magnitude: 0.65209

Collected Steps per Second: 22,570.79831
Overall Steps per Second: 10,637.47924

Timestep Collection Time: 2.21587
Timestep Consumption Time: 2.48581
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.70168

Cumulative Model Updates: 104,632
Cumulative Timesteps: 872,622,880

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 923.38524
Policy Entropy: 3.13929
Value Function Loss: 0.00501

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.57634
Value Function Update Magnitude: 0.64488

Collected Steps per Second: 23,017.32172
Overall Steps per Second: 10,884.37091

Timestep Collection Time: 2.17289
Timestep Consumption Time: 2.42214
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.59503

Cumulative Model Updates: 104,638
Cumulative Timesteps: 872,672,894

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 872672894...
Checkpoint 872672894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.76765
Policy Entropy: 3.14855
Value Function Loss: 0.00500

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10310
Policy Update Magnitude: 0.57186
Value Function Update Magnitude: 0.64643

Collected Steps per Second: 22,352.12575
Overall Steps per Second: 10,713.89686

Timestep Collection Time: 2.23773
Timestep Consumption Time: 2.43079
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.66852

Cumulative Model Updates: 104,644
Cumulative Timesteps: 872,722,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 790.17341
Policy Entropy: 3.13692
Value Function Loss: 0.00509

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11822
Policy Update Magnitude: 0.57432
Value Function Update Magnitude: 0.64265

Collected Steps per Second: 23,031.39643
Overall Steps per Second: 10,874.63212

Timestep Collection Time: 2.17104
Timestep Consumption Time: 2.42700
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.59804

Cumulative Model Updates: 104,650
Cumulative Timesteps: 872,772,914

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 872772914...
Checkpoint 872772914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627.23201
Policy Entropy: 3.14305
Value Function Loss: 0.00531

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10751
Policy Update Magnitude: 0.58870
Value Function Update Magnitude: 0.66221

Collected Steps per Second: 22,687.04007
Overall Steps per Second: 10,665.28397

Timestep Collection Time: 2.20496
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.69036

Cumulative Model Updates: 104,656
Cumulative Timesteps: 872,822,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 557.24555
Policy Entropy: 3.13600
Value Function Loss: 0.00520

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.58949
Value Function Update Magnitude: 0.67239

Collected Steps per Second: 23,047.01178
Overall Steps per Second: 10,868.98731

Timestep Collection Time: 2.17052
Timestep Consumption Time: 2.43193
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.60245

Cumulative Model Updates: 104,662
Cumulative Timesteps: 872,872,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 872872962...
Checkpoint 872872962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.93398
Policy Entropy: 3.16040
Value Function Loss: 0.00527

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.08757
Policy Update Magnitude: 0.57872
Value Function Update Magnitude: 0.65734

Collected Steps per Second: 22,839.98211
Overall Steps per Second: 10,698.04337

Timestep Collection Time: 2.18958
Timestep Consumption Time: 2.48511
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.67469

Cumulative Model Updates: 104,668
Cumulative Timesteps: 872,922,972

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 680.50695
Policy Entropy: 3.15876
Value Function Loss: 0.00502

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08613
Policy Update Magnitude: 0.57709
Value Function Update Magnitude: 0.64435

Collected Steps per Second: 22,882.04585
Overall Steps per Second: 10,815.49246

Timestep Collection Time: 2.18512
Timestep Consumption Time: 2.43788
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.62300

Cumulative Model Updates: 104,674
Cumulative Timesteps: 872,972,972

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 872972972...
Checkpoint 872972972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,004.56767
Policy Entropy: 3.16094
Value Function Loss: 0.00496

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.58104
Value Function Update Magnitude: 0.65787

Collected Steps per Second: 22,708.76199
Overall Steps per Second: 10,718.63863

Timestep Collection Time: 2.20179
Timestep Consumption Time: 2.46298
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.66477

Cumulative Model Updates: 104,680
Cumulative Timesteps: 873,022,972

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,604.54528
Policy Entropy: 3.14493
Value Function Loss: 0.00515

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.58763
Value Function Update Magnitude: 0.66668

Collected Steps per Second: 22,901.50165
Overall Steps per Second: 10,910.82526

Timestep Collection Time: 2.18370
Timestep Consumption Time: 2.39982
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.58352

Cumulative Model Updates: 104,686
Cumulative Timesteps: 873,072,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 873072982...
Checkpoint 873072982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.05865
Policy Entropy: 3.14819
Value Function Loss: 0.00530

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09995
Policy Update Magnitude: 0.59343
Value Function Update Magnitude: 0.70567

Collected Steps per Second: 22,163.95476
Overall Steps per Second: 10,658.59098

Timestep Collection Time: 2.25619
Timestep Consumption Time: 2.43543
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.69161

Cumulative Model Updates: 104,692
Cumulative Timesteps: 873,122,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.92752
Policy Entropy: 3.15002
Value Function Loss: 0.00522

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.59614
Value Function Update Magnitude: 0.71637

Collected Steps per Second: 21,860.56885
Overall Steps per Second: 10,564.72373

Timestep Collection Time: 2.28796
Timestep Consumption Time: 2.44629
PPO Batch Consumption Time: 0.29363
Total Iteration Time: 4.73425

Cumulative Model Updates: 104,698
Cumulative Timesteps: 873,173,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 873173004...
Checkpoint 873173004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,339.93708
Policy Entropy: 3.13630
Value Function Loss: 0.00523

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.60163
Value Function Update Magnitude: 0.72310

Collected Steps per Second: 22,317.97808
Overall Steps per Second: 10,851.75586

Timestep Collection Time: 2.24088
Timestep Consumption Time: 2.36777
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.60866

Cumulative Model Updates: 104,704
Cumulative Timesteps: 873,223,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792.11596
Policy Entropy: 3.13247
Value Function Loss: 0.00505

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.59974
Value Function Update Magnitude: 0.72051

Collected Steps per Second: 22,121.35994
Overall Steps per Second: 10,638.08808

Timestep Collection Time: 2.26053
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.70066

Cumulative Model Updates: 104,710
Cumulative Timesteps: 873,273,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 873273022...
Checkpoint 873273022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.90954
Policy Entropy: 3.13354
Value Function Loss: 0.00520

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.59091
Value Function Update Magnitude: 0.71179

Collected Steps per Second: 21,993.32005
Overall Steps per Second: 10,583.71436

Timestep Collection Time: 2.27451
Timestep Consumption Time: 2.45200
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 4.72651

Cumulative Model Updates: 104,716
Cumulative Timesteps: 873,323,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.24539
Policy Entropy: 3.13746
Value Function Loss: 0.00520

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.58043
Value Function Update Magnitude: 0.69460

Collected Steps per Second: 22,062.22706
Overall Steps per Second: 10,790.66361

Timestep Collection Time: 2.26668
Timestep Consumption Time: 2.36770
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.63438

Cumulative Model Updates: 104,722
Cumulative Timesteps: 873,373,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 873373054...
Checkpoint 873373054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.68068
Policy Entropy: 3.13227
Value Function Loss: 0.00516

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10287
Policy Update Magnitude: 0.58275
Value Function Update Magnitude: 0.67210

Collected Steps per Second: 21,985.95629
Overall Steps per Second: 10,763.94344

Timestep Collection Time: 2.27500
Timestep Consumption Time: 2.37181
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.64681

Cumulative Model Updates: 104,728
Cumulative Timesteps: 873,423,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.79230
Policy Entropy: 3.12629
Value Function Loss: 0.00486

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.58272
Value Function Update Magnitude: 0.64237

Collected Steps per Second: 23,136.07605
Overall Steps per Second: 10,829.67419

Timestep Collection Time: 2.16216
Timestep Consumption Time: 2.45700
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.61916

Cumulative Model Updates: 104,734
Cumulative Timesteps: 873,473,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 873473096...
Checkpoint 873473096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.30053
Policy Entropy: 3.13300
Value Function Loss: 0.00466

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.57388
Value Function Update Magnitude: 0.62466

Collected Steps per Second: 22,715.68225
Overall Steps per Second: 10,711.45299

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.46737
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.66902

Cumulative Model Updates: 104,740
Cumulative Timesteps: 873,523,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 847.93645
Policy Entropy: 3.14665
Value Function Loss: 0.00474

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11658
Policy Update Magnitude: 0.57269
Value Function Update Magnitude: 0.63029

Collected Steps per Second: 23,239.71216
Overall Steps per Second: 10,849.01928

Timestep Collection Time: 2.15201
Timestep Consumption Time: 2.45781
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.60982

Cumulative Model Updates: 104,746
Cumulative Timesteps: 873,573,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 873573120...
Checkpoint 873573120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.91100
Policy Entropy: 3.14817
Value Function Loss: 0.00486

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11052
Policy Update Magnitude: 0.57528
Value Function Update Magnitude: 0.63995

Collected Steps per Second: 22,768.96247
Overall Steps per Second: 10,687.42951

Timestep Collection Time: 2.19615
Timestep Consumption Time: 2.48262
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.67877

Cumulative Model Updates: 104,752
Cumulative Timesteps: 873,623,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.70351
Policy Entropy: 3.14880
Value Function Loss: 0.00490

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10515
Policy Update Magnitude: 0.57178
Value Function Update Magnitude: 0.62409

Collected Steps per Second: 23,074.51677
Overall Steps per Second: 10,835.63388

Timestep Collection Time: 2.16802
Timestep Consumption Time: 2.44878
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.61680

Cumulative Model Updates: 104,758
Cumulative Timesteps: 873,673,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 873673150...
Checkpoint 873673150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.40635
Policy Entropy: 3.14795
Value Function Loss: 0.00497

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11560
Policy Update Magnitude: 0.57063
Value Function Update Magnitude: 0.60629

Collected Steps per Second: 22,716.09485
Overall Steps per Second: 10,721.25433

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.46403
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.66643

Cumulative Model Updates: 104,764
Cumulative Timesteps: 873,723,180

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.72244
Policy Entropy: 3.14076
Value Function Loss: 0.00500

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10142
Policy Update Magnitude: 0.57527
Value Function Update Magnitude: 0.60688

Collected Steps per Second: 23,340.44096
Overall Steps per Second: 10,856.70356

Timestep Collection Time: 2.14220
Timestep Consumption Time: 2.46324
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.60545

Cumulative Model Updates: 104,770
Cumulative Timesteps: 873,773,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 873773180...
Checkpoint 873773180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.90421
Policy Entropy: 3.14004
Value Function Loss: 0.00487

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.57887
Value Function Update Magnitude: 0.60811

Collected Steps per Second: 22,738.04780
Overall Steps per Second: 10,656.59072

Timestep Collection Time: 2.19931
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.69268

Cumulative Model Updates: 104,776
Cumulative Timesteps: 873,823,188

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.97765
Policy Entropy: 3.12476
Value Function Loss: 0.00510

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08744
Policy Update Magnitude: 0.58382
Value Function Update Magnitude: 0.60983

Collected Steps per Second: 23,041.26457
Overall Steps per Second: 10,858.61511

Timestep Collection Time: 2.17158
Timestep Consumption Time: 2.43637
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.60795

Cumulative Model Updates: 104,782
Cumulative Timesteps: 873,873,224

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 873873224...
Checkpoint 873873224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.80168
Policy Entropy: 3.13383
Value Function Loss: 0.00512

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.58385
Value Function Update Magnitude: 0.62735

Collected Steps per Second: 22,615.54345
Overall Steps per Second: 10,768.17202

Timestep Collection Time: 2.21131
Timestep Consumption Time: 2.43293
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.64424

Cumulative Model Updates: 104,788
Cumulative Timesteps: 873,923,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.41014
Policy Entropy: 3.13178
Value Function Loss: 0.00533

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.58283
Value Function Update Magnitude: 0.64416

Collected Steps per Second: 22,976.02252
Overall Steps per Second: 10,828.94012

Timestep Collection Time: 2.17653
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.61800

Cumulative Model Updates: 104,794
Cumulative Timesteps: 873,973,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 873973242...
Checkpoint 873973242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.13824
Policy Entropy: 3.14492
Value Function Loss: 0.00535

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.58260
Value Function Update Magnitude: 0.63325

Collected Steps per Second: 22,534.95787
Overall Steps per Second: 10,641.00669

Timestep Collection Time: 2.21886
Timestep Consumption Time: 2.48013
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.69899

Cumulative Model Updates: 104,800
Cumulative Timesteps: 874,023,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.23001
Policy Entropy: 3.14506
Value Function Loss: 0.00508

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08764
Policy Update Magnitude: 0.58032
Value Function Update Magnitude: 0.61760

Collected Steps per Second: 23,072.10413
Overall Steps per Second: 10,843.56727

Timestep Collection Time: 2.16773
Timestep Consumption Time: 2.44459
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.61232

Cumulative Model Updates: 104,806
Cumulative Timesteps: 874,073,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 874073258...
Checkpoint 874073258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.15052
Policy Entropy: 3.14266
Value Function Loss: 0.00507

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.57743
Value Function Update Magnitude: 0.61261

Collected Steps per Second: 22,517.54144
Overall Steps per Second: 10,671.69626

Timestep Collection Time: 2.22147
Timestep Consumption Time: 2.46588
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.68735

Cumulative Model Updates: 104,812
Cumulative Timesteps: 874,123,280

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.68161
Policy Entropy: 3.14443
Value Function Loss: 0.00519

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10325
Policy Update Magnitude: 0.58543
Value Function Update Magnitude: 0.62570

Collected Steps per Second: 23,110.84466
Overall Steps per Second: 10,727.83027

Timestep Collection Time: 2.16375
Timestep Consumption Time: 2.49759
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.66133

Cumulative Model Updates: 104,818
Cumulative Timesteps: 874,173,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 874173286...
Checkpoint 874173286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.09887
Policy Entropy: 3.15849
Value Function Loss: 0.00495

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.58549
Value Function Update Magnitude: 0.64227

Collected Steps per Second: 22,839.72725
Overall Steps per Second: 10,798.93162

Timestep Collection Time: 2.19022
Timestep Consumption Time: 2.44209
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.63231

Cumulative Model Updates: 104,824
Cumulative Timesteps: 874,223,310

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.82802
Policy Entropy: 3.15170
Value Function Loss: 0.00483

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.57195
Value Function Update Magnitude: 0.63627

Collected Steps per Second: 22,670.72016
Overall Steps per Second: 10,560.71247

Timestep Collection Time: 2.20619
Timestep Consumption Time: 2.52985
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.73604

Cumulative Model Updates: 104,830
Cumulative Timesteps: 874,273,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 874273326...
Checkpoint 874273326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.01428
Policy Entropy: 3.14931
Value Function Loss: 0.00464

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.56331
Value Function Update Magnitude: 0.63111

Collected Steps per Second: 22,374.30632
Overall Steps per Second: 10,643.46859

Timestep Collection Time: 2.23587
Timestep Consumption Time: 2.46429
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.70016

Cumulative Model Updates: 104,836
Cumulative Timesteps: 874,323,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.59746
Policy Entropy: 3.14661
Value Function Loss: 0.00476

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.09108
Policy Update Magnitude: 0.56003
Value Function Update Magnitude: 0.62012

Collected Steps per Second: 22,870.56138
Overall Steps per Second: 10,780.15062

Timestep Collection Time: 2.18683
Timestep Consumption Time: 2.45262
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.63945

Cumulative Model Updates: 104,842
Cumulative Timesteps: 874,373,366

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 874373366...
Checkpoint 874373366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.00164
Policy Entropy: 3.15672
Value Function Loss: 0.00494

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09374
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 22,821.01236
Overall Steps per Second: 10,720.93268

Timestep Collection Time: 2.19193
Timestep Consumption Time: 2.47390
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.66583

Cumulative Model Updates: 104,848
Cumulative Timesteps: 874,423,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,355.48207
Policy Entropy: 3.15910
Value Function Loss: 0.00497

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.56858
Value Function Update Magnitude: 0.62455

Collected Steps per Second: 22,762.22572
Overall Steps per Second: 10,629.17788

Timestep Collection Time: 2.19724
Timestep Consumption Time: 2.50811
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.70535

Cumulative Model Updates: 104,854
Cumulative Timesteps: 874,473,402

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 874473402...
Checkpoint 874473402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.71606
Policy Entropy: 3.14916
Value Function Loss: 0.00503

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.08591
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 22,846.02100
Overall Steps per Second: 10,712.50498

Timestep Collection Time: 2.18874
Timestep Consumption Time: 2.47908
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.66782

Cumulative Model Updates: 104,860
Cumulative Timesteps: 874,523,406

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.68249
Policy Entropy: 3.15045
Value Function Loss: 0.00482

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.58072
Value Function Update Magnitude: 0.64692

Collected Steps per Second: 22,829.83625
Overall Steps per Second: 10,692.30151

Timestep Collection Time: 2.19099
Timestep Consumption Time: 2.48714
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.67813

Cumulative Model Updates: 104,866
Cumulative Timesteps: 874,573,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 874573426...
Checkpoint 874573426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.77977
Policy Entropy: 3.14215
Value Function Loss: 0.00470

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.57509
Value Function Update Magnitude: 0.64183

Collected Steps per Second: 22,894.78783
Overall Steps per Second: 10,611.50725

Timestep Collection Time: 2.18486
Timestep Consumption Time: 2.52908
PPO Batch Consumption Time: 0.29733
Total Iteration Time: 4.71394

Cumulative Model Updates: 104,872
Cumulative Timesteps: 874,623,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 974.63397
Policy Entropy: 3.14190
Value Function Loss: 0.00470

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.57463
Value Function Update Magnitude: 0.63915

Collected Steps per Second: 22,861.87628
Overall Steps per Second: 10,683.37018

Timestep Collection Time: 2.18748
Timestep Consumption Time: 2.49362
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.68111

Cumulative Model Updates: 104,878
Cumulative Timesteps: 874,673,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 874673458...
Checkpoint 874673458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.23835
Policy Entropy: 3.13963
Value Function Loss: 0.00469

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.57392
Value Function Update Magnitude: 0.64787

Collected Steps per Second: 22,807.43491
Overall Steps per Second: 10,798.80824

Timestep Collection Time: 2.19297
Timestep Consumption Time: 2.43865
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.63162

Cumulative Model Updates: 104,884
Cumulative Timesteps: 874,723,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.15261
Policy Entropy: 3.14624
Value Function Loss: 0.00480

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10533
Policy Update Magnitude: 0.57746
Value Function Update Magnitude: 0.63176

Collected Steps per Second: 22,939.12216
Overall Steps per Second: 10,620.01138

Timestep Collection Time: 2.18012
Timestep Consumption Time: 2.52892
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.70903

Cumulative Model Updates: 104,890
Cumulative Timesteps: 874,773,484

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 874773484...
Checkpoint 874773484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.01864
Policy Entropy: 3.13444
Value Function Loss: 0.00484

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.57787
Value Function Update Magnitude: 0.61484

Collected Steps per Second: 22,926.32534
Overall Steps per Second: 10,685.55919

Timestep Collection Time: 2.18090
Timestep Consumption Time: 2.49831
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.67921

Cumulative Model Updates: 104,896
Cumulative Timesteps: 874,823,484

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.72457
Policy Entropy: 3.12885
Value Function Loss: 0.00506

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.58039
Value Function Update Magnitude: 0.60309

Collected Steps per Second: 23,076.72605
Overall Steps per Second: 10,775.25044

Timestep Collection Time: 2.16686
Timestep Consumption Time: 2.47378
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.64063

Cumulative Model Updates: 104,902
Cumulative Timesteps: 874,873,488

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 874873488...
Checkpoint 874873488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.42200
Policy Entropy: 3.11943
Value Function Loss: 0.00489

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11465
Policy Update Magnitude: 0.58346
Value Function Update Magnitude: 0.60812

Collected Steps per Second: 22,869.91400
Overall Steps per Second: 10,606.75383

Timestep Collection Time: 2.18672
Timestep Consumption Time: 2.52820
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.71492

Cumulative Model Updates: 104,908
Cumulative Timesteps: 874,923,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.28484
Policy Entropy: 3.10593
Value Function Loss: 0.00489

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.58255
Value Function Update Magnitude: 0.61224

Collected Steps per Second: 22,875.45283
Overall Steps per Second: 10,669.18580

Timestep Collection Time: 2.18697
Timestep Consumption Time: 2.50204
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.68902

Cumulative Model Updates: 104,914
Cumulative Timesteps: 874,973,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 874973526...
Checkpoint 874973526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 826.52818
Policy Entropy: 3.11912
Value Function Loss: 0.00475

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.58216
Value Function Update Magnitude: 0.60958

Collected Steps per Second: 23,158.76966
Overall Steps per Second: 10,843.01339

Timestep Collection Time: 2.15910
Timestep Consumption Time: 2.45235
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.61145

Cumulative Model Updates: 104,920
Cumulative Timesteps: 875,023,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.92022
Policy Entropy: 3.11346
Value Function Loss: 0.00510

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09540
Policy Update Magnitude: 0.58906
Value Function Update Magnitude: 0.61551

Collected Steps per Second: 23,075.23529
Overall Steps per Second: 10,698.80767

Timestep Collection Time: 2.16761
Timestep Consumption Time: 2.50750
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.67510

Cumulative Model Updates: 104,926
Cumulative Timesteps: 875,073,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 875073546...
Checkpoint 875073546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 958.30704
Policy Entropy: 3.13552
Value Function Loss: 0.00495

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09113
Policy Update Magnitude: 0.58266
Value Function Update Magnitude: 0.62035

Collected Steps per Second: 23,033.42846
Overall Steps per Second: 10,807.02270

Timestep Collection Time: 2.17093
Timestep Consumption Time: 2.45606
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.62699

Cumulative Model Updates: 104,932
Cumulative Timesteps: 875,123,550

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.87987
Policy Entropy: 3.12791
Value Function Loss: 0.00484

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.58000
Value Function Update Magnitude: 0.62622

Collected Steps per Second: 22,942.11873
Overall Steps per Second: 10,666.36484

Timestep Collection Time: 2.18036
Timestep Consumption Time: 2.50934
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.68970

Cumulative Model Updates: 104,938
Cumulative Timesteps: 875,173,572

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 875173572...
Checkpoint 875173572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.27841
Policy Entropy: 3.13668
Value Function Loss: 0.00461

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.56809
Value Function Update Magnitude: 0.61600

Collected Steps per Second: 22,981.89938
Overall Steps per Second: 10,692.96594

Timestep Collection Time: 2.17623
Timestep Consumption Time: 2.50105
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.67728

Cumulative Model Updates: 104,944
Cumulative Timesteps: 875,223,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.06806
Policy Entropy: 3.13414
Value Function Loss: 0.00476

Mean KL Divergence: 0.01312
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.56591
Value Function Update Magnitude: 0.61409

Collected Steps per Second: 22,891.66967
Overall Steps per Second: 10,713.25515

Timestep Collection Time: 2.18464
Timestep Consumption Time: 2.48341
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.66805

Cumulative Model Updates: 104,950
Cumulative Timesteps: 875,273,596

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 875273596...
Checkpoint 875273596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 744.77560
Policy Entropy: 3.12348
Value Function Loss: 0.00538

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.13778
Policy Update Magnitude: 0.58721
Value Function Update Magnitude: 0.63354

Collected Steps per Second: 22,733.32364
Overall Steps per Second: 10,697.40092

Timestep Collection Time: 2.20065
Timestep Consumption Time: 2.47600
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.67665

Cumulative Model Updates: 104,956
Cumulative Timesteps: 875,323,624

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 937.30212
Policy Entropy: 3.12353
Value Function Loss: 0.00546

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.60357
Value Function Update Magnitude: 0.65410

Collected Steps per Second: 23,058.42958
Overall Steps per Second: 10,811.20400

Timestep Collection Time: 2.16962
Timestep Consumption Time: 2.45780
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.62742

Cumulative Model Updates: 104,962
Cumulative Timesteps: 875,373,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 875373652...
Checkpoint 875373652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.57643
Policy Entropy: 3.11458
Value Function Loss: 0.00548

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.13563
Policy Update Magnitude: 0.60066
Value Function Update Magnitude: 0.66042

Collected Steps per Second: 21,594.31645
Overall Steps per Second: 10,271.49034

Timestep Collection Time: 2.31561
Timestep Consumption Time: 2.55262
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.86823

Cumulative Model Updates: 104,968
Cumulative Timesteps: 875,423,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 887.82463
Policy Entropy: 3.11849
Value Function Loss: 0.00524

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.13325
Policy Update Magnitude: 0.59019
Value Function Update Magnitude: 0.64381

Collected Steps per Second: 22,769.40088
Overall Steps per Second: 10,640.95442

Timestep Collection Time: 2.19654
Timestep Consumption Time: 2.50360
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.70014

Cumulative Model Updates: 104,974
Cumulative Timesteps: 875,473,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 875473670...
Checkpoint 875473670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.07020
Policy Entropy: 3.11263
Value Function Loss: 0.00513

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11305
Policy Update Magnitude: 0.58716
Value Function Update Magnitude: 0.63761

Collected Steps per Second: 22,893.26181
Overall Steps per Second: 10,680.31679

Timestep Collection Time: 2.18510
Timestep Consumption Time: 2.49866
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68376

Cumulative Model Updates: 104,980
Cumulative Timesteps: 875,523,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.40828
Policy Entropy: 3.12113
Value Function Loss: 0.00498

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.58383
Value Function Update Magnitude: 0.62194

Collected Steps per Second: 23,200.38307
Overall Steps per Second: 10,694.58355

Timestep Collection Time: 2.15626
Timestep Consumption Time: 2.52144
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.67769

Cumulative Model Updates: 104,986
Cumulative Timesteps: 875,573,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 875573720...
Checkpoint 875573720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.75723
Policy Entropy: 3.14288
Value Function Loss: 0.00479

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08975
Policy Update Magnitude: 0.58539
Value Function Update Magnitude: 0.61636

Collected Steps per Second: 23,123.93923
Overall Steps per Second: 10,671.84230

Timestep Collection Time: 2.16269
Timestep Consumption Time: 2.52347
PPO Batch Consumption Time: 0.29601
Total Iteration Time: 4.68616

Cumulative Model Updates: 104,992
Cumulative Timesteps: 875,623,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,840.31184
Policy Entropy: 3.14199
Value Function Loss: 0.00470

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.08817
Policy Update Magnitude: 0.58028
Value Function Update Magnitude: 0.61518

Collected Steps per Second: 22,797.08525
Overall Steps per Second: 10,792.18336

Timestep Collection Time: 2.19458
Timestep Consumption Time: 2.44118
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.63576

Cumulative Model Updates: 104,998
Cumulative Timesteps: 875,673,760

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 875673760...
Checkpoint 875673760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.39328
Policy Entropy: 3.14364
Value Function Loss: 0.00484

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.08135
Policy Update Magnitude: 0.57501
Value Function Update Magnitude: 0.62950

Collected Steps per Second: 22,919.95876
Overall Steps per Second: 10,728.26633

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.66245

Cumulative Model Updates: 105,004
Cumulative Timesteps: 875,723,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.36283
Policy Entropy: 3.13041
Value Function Loss: 0.00500

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.58805
Value Function Update Magnitude: 0.63419

Collected Steps per Second: 22,600.91921
Overall Steps per Second: 10,632.02407

Timestep Collection Time: 2.21230
Timestep Consumption Time: 2.49047
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.70277

Cumulative Model Updates: 105,010
Cumulative Timesteps: 875,773,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 875773780...
Checkpoint 875773780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.62434
Policy Entropy: 3.13217
Value Function Loss: 0.00503

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09605
Policy Update Magnitude: 0.59164
Value Function Update Magnitude: 0.65002

Collected Steps per Second: 22,715.26385
Overall Steps per Second: 10,672.31805

Timestep Collection Time: 2.20178
Timestep Consumption Time: 2.48455
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.68633

Cumulative Model Updates: 105,016
Cumulative Timesteps: 875,823,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 925.56237
Policy Entropy: 3.13533
Value Function Loss: 0.00498

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.59081
Value Function Update Magnitude: 0.62857

Collected Steps per Second: 23,166.15084
Overall Steps per Second: 10,700.26338

Timestep Collection Time: 2.15927
Timestep Consumption Time: 2.51557
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.67484

Cumulative Model Updates: 105,022
Cumulative Timesteps: 875,873,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 875873816...
Checkpoint 875873816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,180.63693
Policy Entropy: 3.13469
Value Function Loss: 0.00475

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.57679
Value Function Update Magnitude: 0.61869

Collected Steps per Second: 22,671.35183
Overall Steps per Second: 10,646.22075

Timestep Collection Time: 2.20649
Timestep Consumption Time: 2.49227
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.69876

Cumulative Model Updates: 105,028
Cumulative Timesteps: 875,923,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.48478
Policy Entropy: 3.12581
Value Function Loss: 0.00495

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.08827
Policy Update Magnitude: 0.56695
Value Function Update Magnitude: 0.59327

Collected Steps per Second: 23,255.18245
Overall Steps per Second: 10,832.45490

Timestep Collection Time: 2.15066
Timestep Consumption Time: 2.46639
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.61705

Cumulative Model Updates: 105,034
Cumulative Timesteps: 875,973,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 875973854...
Checkpoint 875973854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.80713
Policy Entropy: 3.12610
Value Function Loss: 0.00510

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.57133
Value Function Update Magnitude: 0.58776

Collected Steps per Second: 22,897.15425
Overall Steps per Second: 10,717.43336

Timestep Collection Time: 2.18446
Timestep Consumption Time: 2.48251
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.66698

Cumulative Model Updates: 105,040
Cumulative Timesteps: 876,023,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 596.64160
Policy Entropy: 3.12483
Value Function Loss: 0.00528

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.57677
Value Function Update Magnitude: 0.59850

Collected Steps per Second: 22,558.58578
Overall Steps per Second: 10,574.86757

Timestep Collection Time: 2.21645
Timestep Consumption Time: 2.51174
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.72819

Cumulative Model Updates: 105,046
Cumulative Timesteps: 876,073,872

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 876073872...
Checkpoint 876073872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 853.87563
Policy Entropy: 3.14097
Value Function Loss: 0.00509

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08815
Policy Update Magnitude: 0.57262
Value Function Update Magnitude: 0.60924

Collected Steps per Second: 23,096.94982
Overall Steps per Second: 10,852.32251

Timestep Collection Time: 2.16487
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.60749

Cumulative Model Updates: 105,052
Cumulative Timesteps: 876,123,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 903.02197
Policy Entropy: 3.13043
Value Function Loss: 0.00510

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.58102
Value Function Update Magnitude: 0.60879

Collected Steps per Second: 22,754.96760
Overall Steps per Second: 10,558.12038

Timestep Collection Time: 2.19855
Timestep Consumption Time: 2.53979
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.73834

Cumulative Model Updates: 105,058
Cumulative Timesteps: 876,173,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 876173902...
Checkpoint 876173902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,833.94883
Policy Entropy: 3.13792
Value Function Loss: 0.00509

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.58152
Value Function Update Magnitude: 0.60555

Collected Steps per Second: 22,850.36951
Overall Steps per Second: 10,612.98262

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.52337
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.71178

Cumulative Model Updates: 105,064
Cumulative Timesteps: 876,223,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 850.35614
Policy Entropy: 3.14615
Value Function Loss: 0.00501

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09450
Policy Update Magnitude: 0.57605
Value Function Update Magnitude: 0.59851

Collected Steps per Second: 22,768.91581
Overall Steps per Second: 10,642.87054

Timestep Collection Time: 2.19615
Timestep Consumption Time: 2.50220
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.69836

Cumulative Model Updates: 105,070
Cumulative Timesteps: 876,273,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 876273912...
Checkpoint 876273912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 889.61924
Policy Entropy: 3.15386
Value Function Loss: 0.00495

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08697
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.59824

Collected Steps per Second: 22,755.41019
Overall Steps per Second: 10,633.91679

Timestep Collection Time: 2.19789
Timestep Consumption Time: 2.50536
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.70325

Cumulative Model Updates: 105,076
Cumulative Timesteps: 876,323,926

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.15507
Policy Entropy: 3.14045
Value Function Loss: 0.00514

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.59956

Collected Steps per Second: 22,966.26973
Overall Steps per Second: 10,760.54147

Timestep Collection Time: 2.17789
Timestep Consumption Time: 2.47039
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.64828

Cumulative Model Updates: 105,082
Cumulative Timesteps: 876,373,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 876373944...
Checkpoint 876373944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.76691
Policy Entropy: 3.13417
Value Function Loss: 0.00507

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.56998
Value Function Update Magnitude: 0.60028

Collected Steps per Second: 22,926.42219
Overall Steps per Second: 10,632.78802

Timestep Collection Time: 2.18141
Timestep Consumption Time: 2.52215
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.70356

Cumulative Model Updates: 105,088
Cumulative Timesteps: 876,423,956

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.19124
Policy Entropy: 3.13581
Value Function Loss: 0.00490

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08790
Policy Update Magnitude: 0.56641
Value Function Update Magnitude: 0.58805

Collected Steps per Second: 22,889.42498
Overall Steps per Second: 10,793.54477

Timestep Collection Time: 2.18538
Timestep Consumption Time: 2.44906
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.63444

Cumulative Model Updates: 105,094
Cumulative Timesteps: 876,473,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 876473978...
Checkpoint 876473978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.89175
Policy Entropy: 3.13536
Value Function Loss: 0.00478

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.08959
Policy Update Magnitude: 0.56754
Value Function Update Magnitude: 0.57252

Collected Steps per Second: 22,811.61215
Overall Steps per Second: 10,759.76069

Timestep Collection Time: 2.19266
Timestep Consumption Time: 2.45596
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.64862

Cumulative Model Updates: 105,100
Cumulative Timesteps: 876,523,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.16271
Policy Entropy: 3.14693
Value Function Loss: 0.00484

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.09289
Policy Update Magnitude: 0.56748
Value Function Update Magnitude: 0.58732

Collected Steps per Second: 22,711.69647
Overall Steps per Second: 10,629.41878

Timestep Collection Time: 2.20265
Timestep Consumption Time: 2.50372
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.70637

Cumulative Model Updates: 105,106
Cumulative Timesteps: 876,574,022

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 876574022...
Checkpoint 876574022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.06960
Policy Entropy: 3.14707
Value Function Loss: 0.00496

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10805
Policy Update Magnitude: 0.57267
Value Function Update Magnitude: 0.59886

Collected Steps per Second: 23,012.82748
Overall Steps per Second: 10,845.80678

Timestep Collection Time: 2.17279
Timestep Consumption Time: 2.43747
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.61026

Cumulative Model Updates: 105,112
Cumulative Timesteps: 876,624,024

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.91546
Policy Entropy: 3.16601
Value Function Loss: 0.00485

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.56802
Value Function Update Magnitude: 0.62017

Collected Steps per Second: 22,757.06746
Overall Steps per Second: 10,600.85518

Timestep Collection Time: 2.19738
Timestep Consumption Time: 2.51978
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.71717

Cumulative Model Updates: 105,118
Cumulative Timesteps: 876,674,030

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 876674030...
Checkpoint 876674030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.27975
Policy Entropy: 3.15796
Value Function Loss: 0.00492

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10514
Policy Update Magnitude: 0.56327
Value Function Update Magnitude: 0.61442

Collected Steps per Second: 22,890.71975
Overall Steps per Second: 10,664.63362

Timestep Collection Time: 2.18429
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.68839

Cumulative Model Updates: 105,124
Cumulative Timesteps: 876,724,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.14026
Policy Entropy: 3.14025
Value Function Loss: 0.00498

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.57301
Value Function Update Magnitude: 0.61040

Collected Steps per Second: 22,822.29406
Overall Steps per Second: 10,748.96213

Timestep Collection Time: 2.19154
Timestep Consumption Time: 2.46156
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.65310

Cumulative Model Updates: 105,130
Cumulative Timesteps: 876,774,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 876774046...
Checkpoint 876774046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.64030
Policy Entropy: 3.12467
Value Function Loss: 0.00501

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.58075
Value Function Update Magnitude: 0.61753

Collected Steps per Second: 23,187.21216
Overall Steps per Second: 10,683.83784

Timestep Collection Time: 2.15636
Timestep Consumption Time: 2.52361
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.67997

Cumulative Model Updates: 105,136
Cumulative Timesteps: 876,824,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.13162
Policy Entropy: 3.11056
Value Function Loss: 0.00471

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.58040
Value Function Update Magnitude: 0.62202

Collected Steps per Second: 22,950.07588
Overall Steps per Second: 10,726.17969

Timestep Collection Time: 2.17934
Timestep Consumption Time: 2.48364
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.66298

Cumulative Model Updates: 105,142
Cumulative Timesteps: 876,874,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 876874062...
Checkpoint 876874062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.58849
Policy Entropy: 3.11721
Value Function Loss: 0.00449

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09869
Policy Update Magnitude: 0.56937
Value Function Update Magnitude: 0.61515

Collected Steps per Second: 23,264.42223
Overall Steps per Second: 10,898.84693

Timestep Collection Time: 2.14963
Timestep Consumption Time: 2.43892
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.58856

Cumulative Model Updates: 105,148
Cumulative Timesteps: 876,924,072

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,906.58063
Policy Entropy: 3.11455
Value Function Loss: 0.00469

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08769
Policy Update Magnitude: 0.55816
Value Function Update Magnitude: 0.61221

Collected Steps per Second: 22,850.85535
Overall Steps per Second: 10,808.66894

Timestep Collection Time: 2.18810
Timestep Consumption Time: 2.43781
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.62592

Cumulative Model Updates: 105,154
Cumulative Timesteps: 876,974,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 876974072...
Checkpoint 876974072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.97559
Policy Entropy: 3.12742
Value Function Loss: 0.00490

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.55765
Value Function Update Magnitude: 0.62640

Collected Steps per Second: 22,675.89430
Overall Steps per Second: 10,718.29489

Timestep Collection Time: 2.20507
Timestep Consumption Time: 2.46003
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.66511

Cumulative Model Updates: 105,160
Cumulative Timesteps: 877,024,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.19491
Policy Entropy: 3.13093
Value Function Loss: 0.00523

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08987
Policy Update Magnitude: 0.57113
Value Function Update Magnitude: 0.63156

Collected Steps per Second: 22,941.20152
Overall Steps per Second: 10,816.85749

Timestep Collection Time: 2.17948
Timestep Consumption Time: 2.44293
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.62241

Cumulative Model Updates: 105,166
Cumulative Timesteps: 877,074,074

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 877074074...
Checkpoint 877074074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.69661
Policy Entropy: 3.15215
Value Function Loss: 0.00514

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09116
Policy Update Magnitude: 0.57893
Value Function Update Magnitude: 0.64264

Collected Steps per Second: 22,862.26216
Overall Steps per Second: 10,727.83599

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.66245

Cumulative Model Updates: 105,172
Cumulative Timesteps: 877,124,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.68623
Policy Entropy: 3.13738
Value Function Loss: 0.00532

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.58419
Value Function Update Magnitude: 0.65074

Collected Steps per Second: 23,262.44756
Overall Steps per Second: 10,863.19025

Timestep Collection Time: 2.14973
Timestep Consumption Time: 2.45371
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.60344

Cumulative Model Updates: 105,178
Cumulative Timesteps: 877,174,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 877174100...
Checkpoint 877174100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.08955
Policy Entropy: 3.13781
Value Function Loss: 0.00507

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09886
Policy Update Magnitude: 0.58633
Value Function Update Magnitude: 0.64362

Collected Steps per Second: 22,747.55765
Overall Steps per Second: 10,686.40242

Timestep Collection Time: 2.19857
Timestep Consumption Time: 2.48140
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.67997

Cumulative Model Updates: 105,184
Cumulative Timesteps: 877,224,112

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.91448
Policy Entropy: 3.13053
Value Function Loss: 0.00508

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09949
Policy Update Magnitude: 0.57667
Value Function Update Magnitude: 0.64354

Collected Steps per Second: 22,932.21523
Overall Steps per Second: 10,732.29211

Timestep Collection Time: 2.18060
Timestep Consumption Time: 2.47880
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.65940

Cumulative Model Updates: 105,190
Cumulative Timesteps: 877,274,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 877274118...
Checkpoint 877274118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.06166
Policy Entropy: 3.13072
Value Function Loss: 0.00508

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.57282
Value Function Update Magnitude: 0.62514

Collected Steps per Second: 22,831.26594
Overall Steps per Second: 10,822.00180

Timestep Collection Time: 2.19094
Timestep Consumption Time: 2.43131
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.62225

Cumulative Model Updates: 105,196
Cumulative Timesteps: 877,324,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.56096
Policy Entropy: 3.11682
Value Function Loss: 0.00522

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.57916
Value Function Update Magnitude: 0.62294

Collected Steps per Second: 23,010.96133
Overall Steps per Second: 10,786.58381

Timestep Collection Time: 2.17349
Timestep Consumption Time: 2.46320
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.63669

Cumulative Model Updates: 105,202
Cumulative Timesteps: 877,374,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 877374154...
Checkpoint 877374154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.30260
Policy Entropy: 3.12642
Value Function Loss: 0.00516

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09310
Policy Update Magnitude: 0.58296
Value Function Update Magnitude: 0.62401

Collected Steps per Second: 22,872.06374
Overall Steps per Second: 10,712.71067

Timestep Collection Time: 2.18738
Timestep Consumption Time: 2.48277
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.67015

Cumulative Model Updates: 105,208
Cumulative Timesteps: 877,424,184

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.36578
Policy Entropy: 3.11452
Value Function Loss: 0.00513

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.58413
Value Function Update Magnitude: 0.62510

Collected Steps per Second: 22,630.24304
Overall Steps per Second: 10,587.31793

Timestep Collection Time: 2.20961
Timestep Consumption Time: 2.51340
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.72301

Cumulative Model Updates: 105,214
Cumulative Timesteps: 877,474,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 877474188...
Checkpoint 877474188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.63302
Policy Entropy: 3.12753
Value Function Loss: 0.00494

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09771
Policy Update Magnitude: 0.58280
Value Function Update Magnitude: 0.63405

Collected Steps per Second: 22,985.60139
Overall Steps per Second: 10,689.97580

Timestep Collection Time: 2.17588
Timestep Consumption Time: 2.50270
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.67859

Cumulative Model Updates: 105,220
Cumulative Timesteps: 877,524,202

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.93510
Policy Entropy: 3.12554
Value Function Loss: 0.00486

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.57670
Value Function Update Magnitude: 0.63277

Collected Steps per Second: 22,930.85862
Overall Steps per Second: 10,785.74530

Timestep Collection Time: 2.18117
Timestep Consumption Time: 2.45607
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.63723

Cumulative Model Updates: 105,226
Cumulative Timesteps: 877,574,218

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 877574218...
Checkpoint 877574218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.23726
Policy Entropy: 3.11993
Value Function Loss: 0.00478

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10166
Policy Update Magnitude: 0.57969
Value Function Update Magnitude: 0.63245

Collected Steps per Second: 22,955.34430
Overall Steps per Second: 10,632.57508

Timestep Collection Time: 2.17875
Timestep Consumption Time: 2.52509
PPO Batch Consumption Time: 0.29703
Total Iteration Time: 4.70385

Cumulative Model Updates: 105,232
Cumulative Timesteps: 877,624,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.89110
Policy Entropy: 3.11527
Value Function Loss: 0.00493

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11321
Policy Update Magnitude: 0.58487
Value Function Update Magnitude: 0.61810

Collected Steps per Second: 22,773.73635
Overall Steps per Second: 10,661.88746

Timestep Collection Time: 2.19595
Timestep Consumption Time: 2.49459
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.69054

Cumulative Model Updates: 105,238
Cumulative Timesteps: 877,674,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 877674242...
Checkpoint 877674242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.93178
Policy Entropy: 3.12778
Value Function Loss: 0.00482

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.58237
Value Function Update Magnitude: 0.60490

Collected Steps per Second: 22,773.37678
Overall Steps per Second: 10,759.71408

Timestep Collection Time: 2.19730
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.65068

Cumulative Model Updates: 105,244
Cumulative Timesteps: 877,724,282

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.35531
Policy Entropy: 3.14483
Value Function Loss: 0.00494

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10581
Policy Update Magnitude: 0.57938
Value Function Update Magnitude: 0.58851

Collected Steps per Second: 22,678.72039
Overall Steps per Second: 10,542.24133

Timestep Collection Time: 2.20568
Timestep Consumption Time: 2.53923
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.74491

Cumulative Model Updates: 105,250
Cumulative Timesteps: 877,774,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 877774304...
Checkpoint 877774304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.21953
Policy Entropy: 3.15101
Value Function Loss: 0.00485

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.12054
Policy Update Magnitude: 0.57298
Value Function Update Magnitude: 0.59448

Collected Steps per Second: 22,771.05143
Overall Steps per Second: 10,569.43715

Timestep Collection Time: 2.19586
Timestep Consumption Time: 2.53495
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.73081

Cumulative Model Updates: 105,256
Cumulative Timesteps: 877,824,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420.59839
Policy Entropy: 3.14162
Value Function Loss: 0.00485

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11402
Policy Update Magnitude: 0.56559
Value Function Update Magnitude: 0.61357

Collected Steps per Second: 22,749.82392
Overall Steps per Second: 10,555.25026

Timestep Collection Time: 2.19914
Timestep Consumption Time: 2.54068
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.73982

Cumulative Model Updates: 105,262
Cumulative Timesteps: 877,874,336

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 877874336...
Checkpoint 877874336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.79978
Policy Entropy: 3.13238
Value Function Loss: 0.00479

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09809
Policy Update Magnitude: 0.56437
Value Function Update Magnitude: 0.62647

Collected Steps per Second: 22,811.30812
Overall Steps per Second: 10,626.67603

Timestep Collection Time: 2.19277
Timestep Consumption Time: 2.51425
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.70702

Cumulative Model Updates: 105,268
Cumulative Timesteps: 877,924,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.04768
Policy Entropy: 3.12812
Value Function Loss: 0.00513

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10191
Policy Update Magnitude: 0.57782
Value Function Update Magnitude: 0.63649

Collected Steps per Second: 22,823.03563
Overall Steps per Second: 10,796.85659

Timestep Collection Time: 2.19121
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.63190

Cumulative Model Updates: 105,274
Cumulative Timesteps: 877,974,366

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 877974366...
Checkpoint 877974366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.95015
Policy Entropy: 3.13596
Value Function Loss: 0.00509

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.57932
Value Function Update Magnitude: 0.64377

Collected Steps per Second: 22,780.28590
Overall Steps per Second: 10,712.41293

Timestep Collection Time: 2.19611
Timestep Consumption Time: 2.47399
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.67010

Cumulative Model Updates: 105,280
Cumulative Timesteps: 878,024,394

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,187.69208
Policy Entropy: 3.13419
Value Function Loss: 0.00514

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.65476

Collected Steps per Second: 22,651.64731
Overall Steps per Second: 10,670.33126

Timestep Collection Time: 2.20849
Timestep Consumption Time: 2.47983
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.68833

Cumulative Model Updates: 105,286
Cumulative Timesteps: 878,074,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 878074420...
Checkpoint 878074420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.94033
Policy Entropy: 3.13611
Value Function Loss: 0.00496

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.11006
Policy Update Magnitude: 0.56995
Value Function Update Magnitude: 0.66733

Collected Steps per Second: 23,229.78028
Overall Steps per Second: 10,859.78644

Timestep Collection Time: 2.15267
Timestep Consumption Time: 2.45203
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.60469

Cumulative Model Updates: 105,292
Cumulative Timesteps: 878,124,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.84096
Policy Entropy: 3.13541
Value Function Loss: 0.00496

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10837
Policy Update Magnitude: 0.56865
Value Function Update Magnitude: 0.66779

Collected Steps per Second: 23,057.37065
Overall Steps per Second: 10,873.50797

Timestep Collection Time: 2.16920
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.59980

Cumulative Model Updates: 105,298
Cumulative Timesteps: 878,174,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 878174442...
Checkpoint 878174442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 971.87106
Policy Entropy: 3.13221
Value Function Loss: 0.00472

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10284
Policy Update Magnitude: 0.56808
Value Function Update Magnitude: 0.65111

Collected Steps per Second: 22,774.04584
Overall Steps per Second: 10,700.25948

Timestep Collection Time: 2.19566
Timestep Consumption Time: 2.47750
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.67316

Cumulative Model Updates: 105,304
Cumulative Timesteps: 878,224,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.90819
Policy Entropy: 3.12288
Value Function Loss: 0.00449

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.55613
Value Function Update Magnitude: 0.61082

Collected Steps per Second: 22,757.80789
Overall Steps per Second: 10,840.53646

Timestep Collection Time: 2.19784
Timestep Consumption Time: 2.41614
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.61398

Cumulative Model Updates: 105,310
Cumulative Timesteps: 878,274,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 878274464...
Checkpoint 878274464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.47671
Policy Entropy: 3.12753
Value Function Loss: 0.00467

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.55802
Value Function Update Magnitude: 0.59625

Collected Steps per Second: 22,522.52962
Overall Steps per Second: 10,731.27852

Timestep Collection Time: 2.22053
Timestep Consumption Time: 2.43986
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.66040

Cumulative Model Updates: 105,316
Cumulative Timesteps: 878,324,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.84288
Policy Entropy: 3.12430
Value Function Loss: 0.00479

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.56963
Value Function Update Magnitude: 0.60214

Collected Steps per Second: 22,571.56577
Overall Steps per Second: 10,626.86253

Timestep Collection Time: 2.21633
Timestep Consumption Time: 2.49118
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.70750

Cumulative Model Updates: 105,322
Cumulative Timesteps: 878,374,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 878374502...
Checkpoint 878374502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,969.95839
Policy Entropy: 3.11768
Value Function Loss: 0.00499

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.57012
Value Function Update Magnitude: 0.59844

Collected Steps per Second: 22,976.79867
Overall Steps per Second: 10,828.11660

Timestep Collection Time: 2.17611
Timestep Consumption Time: 2.44150
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.61761

Cumulative Model Updates: 105,328
Cumulative Timesteps: 878,424,502

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694.24784
Policy Entropy: 3.10746
Value Function Loss: 0.00499

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10492
Policy Update Magnitude: 0.57002
Value Function Update Magnitude: 0.60001

Collected Steps per Second: 22,764.48391
Overall Steps per Second: 10,567.70950

Timestep Collection Time: 2.19790
Timestep Consumption Time: 2.53671
PPO Batch Consumption Time: 0.29654
Total Iteration Time: 4.73461

Cumulative Model Updates: 105,334
Cumulative Timesteps: 878,474,536

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 878474536...
Checkpoint 878474536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.53232
Policy Entropy: 3.09979
Value Function Loss: 0.00516

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11532
Policy Update Magnitude: 0.57196
Value Function Update Magnitude: 0.60123

Collected Steps per Second: 22,794.59180
Overall Steps per Second: 10,618.29480

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.51646
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.71093

Cumulative Model Updates: 105,340
Cumulative Timesteps: 878,524,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 880.55490
Policy Entropy: 3.08925
Value Function Loss: 0.00525

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12272
Policy Update Magnitude: 0.58760
Value Function Update Magnitude: 0.62165

Collected Steps per Second: 22,947.99154
Overall Steps per Second: 10,819.14662

Timestep Collection Time: 2.17962
Timestep Consumption Time: 2.44348
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.62310

Cumulative Model Updates: 105,346
Cumulative Timesteps: 878,574,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 878574576...
Checkpoint 878574576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,032.18026
Policy Entropy: 3.09039
Value Function Loss: 0.00505

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.59060
Value Function Update Magnitude: 0.65927

Collected Steps per Second: 22,492.62003
Overall Steps per Second: 10,740.45621

Timestep Collection Time: 2.22420
Timestep Consumption Time: 2.43371
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.65790

Cumulative Model Updates: 105,352
Cumulative Timesteps: 878,624,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.73094
Policy Entropy: 3.11163
Value Function Loss: 0.00479

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.58528
Value Function Update Magnitude: 0.67444

Collected Steps per Second: 22,577.67354
Overall Steps per Second: 10,660.14759

Timestep Collection Time: 2.21591
Timestep Consumption Time: 2.47727
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.69318

Cumulative Model Updates: 105,358
Cumulative Timesteps: 878,674,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 878674634...
Checkpoint 878674634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.13571
Policy Entropy: 3.12495
Value Function Loss: 0.00489

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09020
Policy Update Magnitude: 0.58379
Value Function Update Magnitude: 0.65689

Collected Steps per Second: 22,986.64650
Overall Steps per Second: 10,899.03295

Timestep Collection Time: 2.17613
Timestep Consumption Time: 2.41345
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.58958

Cumulative Model Updates: 105,364
Cumulative Timesteps: 878,724,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.16341
Policy Entropy: 3.12847
Value Function Loss: 0.00495

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.58660
Value Function Update Magnitude: 0.64876

Collected Steps per Second: 22,940.08880
Overall Steps per Second: 10,777.29651

Timestep Collection Time: 2.17968
Timestep Consumption Time: 2.45989
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.63957

Cumulative Model Updates: 105,370
Cumulative Timesteps: 878,774,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 878774658...
Checkpoint 878774658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.03340
Policy Entropy: 3.12098
Value Function Loss: 0.00514

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09888
Policy Update Magnitude: 0.58655
Value Function Update Magnitude: 0.64750

Collected Steps per Second: 22,574.84455
Overall Steps per Second: 10,703.03694

Timestep Collection Time: 2.21601
Timestep Consumption Time: 2.45799
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.67400

Cumulative Model Updates: 105,376
Cumulative Timesteps: 878,824,684

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.77180
Policy Entropy: 3.10896
Value Function Loss: 0.00498

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.58647
Value Function Update Magnitude: 0.64785

Collected Steps per Second: 22,620.05405
Overall Steps per Second: 10,684.20435

Timestep Collection Time: 2.21114
Timestep Consumption Time: 2.47017
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.68130

Cumulative Model Updates: 105,382
Cumulative Timesteps: 878,874,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 878874700...
Checkpoint 878874700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 914.29280
Policy Entropy: 3.11482
Value Function Loss: 0.00490

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09959
Policy Update Magnitude: 0.58050
Value Function Update Magnitude: 0.64571

Collected Steps per Second: 22,831.68265
Overall Steps per Second: 10,836.37791

Timestep Collection Time: 2.19134
Timestep Consumption Time: 2.42570
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.61704

Cumulative Model Updates: 105,388
Cumulative Timesteps: 878,924,732

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.50283
Policy Entropy: 3.11126
Value Function Loss: 0.00498

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11921
Policy Update Magnitude: 0.58032
Value Function Update Magnitude: 0.63000

Collected Steps per Second: 23,070.32839
Overall Steps per Second: 10,867.34188

Timestep Collection Time: 2.16841
Timestep Consumption Time: 2.43492
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.60333

Cumulative Model Updates: 105,394
Cumulative Timesteps: 878,974,758

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 878974758...
Checkpoint 878974758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 783.25023
Policy Entropy: 3.12131
Value Function Loss: 0.00535

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.58556
Value Function Update Magnitude: 0.62414

Collected Steps per Second: 22,799.37534
Overall Steps per Second: 10,779.67634

Timestep Collection Time: 2.19410
Timestep Consumption Time: 2.44649
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.64058

Cumulative Model Updates: 105,400
Cumulative Timesteps: 879,024,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.06225
Policy Entropy: 3.11303
Value Function Loss: 0.00578

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11533
Policy Update Magnitude: 0.60166
Value Function Update Magnitude: 0.64120

Collected Steps per Second: 22,663.15854
Overall Steps per Second: 10,799.35757

Timestep Collection Time: 2.20711
Timestep Consumption Time: 2.42465
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.63176

Cumulative Model Updates: 105,406
Cumulative Timesteps: 879,074,802

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 879074802...
Checkpoint 879074802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.11754
Policy Entropy: 3.10468
Value Function Loss: 0.00558

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.60607
Value Function Update Magnitude: 0.66079

Collected Steps per Second: 22,332.69609
Overall Steps per Second: 10,735.35623

Timestep Collection Time: 2.23977
Timestep Consumption Time: 2.41960
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.65937

Cumulative Model Updates: 105,412
Cumulative Timesteps: 879,124,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,255.50398
Policy Entropy: 3.09862
Value Function Loss: 0.00536

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11107
Policy Update Magnitude: 0.60114
Value Function Update Magnitude: 0.66319

Collected Steps per Second: 22,752.02953
Overall Steps per Second: 10,787.07152

Timestep Collection Time: 2.19866
Timestep Consumption Time: 2.43874
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.63740

Cumulative Model Updates: 105,418
Cumulative Timesteps: 879,174,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 879174846...
Checkpoint 879174846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.03952
Policy Entropy: 3.10086
Value Function Loss: 0.00501

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.59790
Value Function Update Magnitude: 0.64397

Collected Steps per Second: 22,869.30827
Overall Steps per Second: 10,741.40862

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.46993
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 4.65749

Cumulative Model Updates: 105,424
Cumulative Timesteps: 879,224,874

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.14502
Policy Entropy: 3.08931
Value Function Loss: 0.00516

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.59618
Value Function Update Magnitude: 0.62584

Collected Steps per Second: 22,674.98766
Overall Steps per Second: 10,700.38586

Timestep Collection Time: 2.20613
Timestep Consumption Time: 2.46884
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.67497

Cumulative Model Updates: 105,430
Cumulative Timesteps: 879,274,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 879274898...
Checkpoint 879274898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.00503
Policy Entropy: 3.09608
Value Function Loss: 0.00493

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.60012
Value Function Update Magnitude: 0.62256

Collected Steps per Second: 23,083.33385
Overall Steps per Second: 10,911.59703

Timestep Collection Time: 2.16762
Timestep Consumption Time: 2.41796
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.58558

Cumulative Model Updates: 105,436
Cumulative Timesteps: 879,324,934

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.09894
Policy Entropy: 3.08878
Value Function Loss: 0.00503

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10855
Policy Update Magnitude: 0.59642
Value Function Update Magnitude: 0.61641

Collected Steps per Second: 22,958.08261
Overall Steps per Second: 10,862.00158

Timestep Collection Time: 2.17832
Timestep Consumption Time: 2.42581
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.60412

Cumulative Model Updates: 105,442
Cumulative Timesteps: 879,374,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 879374944...
Checkpoint 879374944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,553.63435
Policy Entropy: 3.09284
Value Function Loss: 0.00500

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10214
Policy Update Magnitude: 0.58936
Value Function Update Magnitude: 0.60126

Collected Steps per Second: 22,772.98975
Overall Steps per Second: 10,654.14721

Timestep Collection Time: 2.19567
Timestep Consumption Time: 2.49752
PPO Batch Consumption Time: 0.29656
Total Iteration Time: 4.69320

Cumulative Model Updates: 105,448
Cumulative Timesteps: 879,424,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 673.35167
Policy Entropy: 3.10106
Value Function Loss: 0.00512

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.59431
Value Function Update Magnitude: 0.59732

Collected Steps per Second: 22,747.47316
Overall Steps per Second: 10,812.20115

Timestep Collection Time: 2.19831
Timestep Consumption Time: 2.42665
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.62496

Cumulative Model Updates: 105,454
Cumulative Timesteps: 879,474,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 879474952...
Checkpoint 879474952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.33898
Policy Entropy: 3.10803
Value Function Loss: 0.00517

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.60086
Value Function Update Magnitude: 0.59128

Collected Steps per Second: 22,578.82494
Overall Steps per Second: 10,696.77506

Timestep Collection Time: 2.21579
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.67711

Cumulative Model Updates: 105,460
Cumulative Timesteps: 879,524,982

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 757.92856
Policy Entropy: 3.11971
Value Function Loss: 0.00519

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.59941
Value Function Update Magnitude: 0.61207

Collected Steps per Second: 23,062.04739
Overall Steps per Second: 10,853.24623

Timestep Collection Time: 2.16910
Timestep Consumption Time: 2.44002
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.60913

Cumulative Model Updates: 105,466
Cumulative Timesteps: 879,575,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 879575006...
Checkpoint 879575006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.67236
Policy Entropy: 3.09404
Value Function Loss: 0.00527

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.59930
Value Function Update Magnitude: 0.62339

Collected Steps per Second: 22,522.66044
Overall Steps per Second: 10,678.57908

Timestep Collection Time: 2.22087
Timestep Consumption Time: 2.46327
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.68414

Cumulative Model Updates: 105,472
Cumulative Timesteps: 879,625,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 658.44053
Policy Entropy: 3.09148
Value Function Loss: 0.00565

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12125
Policy Update Magnitude: 0.61474
Value Function Update Magnitude: 0.64066

Collected Steps per Second: 23,110.16407
Overall Steps per Second: 10,870.09949

Timestep Collection Time: 2.16459
Timestep Consumption Time: 2.43739
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.60198

Cumulative Model Updates: 105,478
Cumulative Timesteps: 879,675,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 879675050...
Checkpoint 879675050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 652.08866
Policy Entropy: 3.09402
Value Function Loss: 0.00549

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.14023
Policy Update Magnitude: 0.62151
Value Function Update Magnitude: 0.64887

Collected Steps per Second: 22,478.17900
Overall Steps per Second: 10,729.55825

Timestep Collection Time: 2.22465
Timestep Consumption Time: 2.43594
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.66058

Cumulative Model Updates: 105,484
Cumulative Timesteps: 879,725,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.51640
Policy Entropy: 3.09793
Value Function Loss: 0.00542

Mean KL Divergence: 0.01541
SB3 Clip Fraction: 0.13947
Policy Update Magnitude: 0.60461
Value Function Update Magnitude: 0.64481

Collected Steps per Second: 22,539.42812
Overall Steps per Second: 10,653.33566

Timestep Collection Time: 2.21940
Timestep Consumption Time: 2.47622
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.69562

Cumulative Model Updates: 105,490
Cumulative Timesteps: 879,775,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 879775080...
Checkpoint 879775080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.33760
Policy Entropy: 3.09270
Value Function Loss: 0.00523

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.60080
Value Function Update Magnitude: 0.63089

Collected Steps per Second: 23,235.65237
Overall Steps per Second: 10,879.45099

Timestep Collection Time: 2.15307
Timestep Consumption Time: 2.44532
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.59839

Cumulative Model Updates: 105,496
Cumulative Timesteps: 879,825,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.51583
Policy Entropy: 3.09766
Value Function Loss: 0.00528

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.59871
Value Function Update Magnitude: 0.62666

Collected Steps per Second: 22,878.61645
Overall Steps per Second: 10,824.10060

Timestep Collection Time: 2.18623
Timestep Consumption Time: 2.43475
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.62098

Cumulative Model Updates: 105,502
Cumulative Timesteps: 879,875,126

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 879875126...
Checkpoint 879875126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.86002
Policy Entropy: 3.11571
Value Function Loss: 0.00518

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.13963
Policy Update Magnitude: 0.59231
Value Function Update Magnitude: 0.61934

Collected Steps per Second: 22,670.00418
Overall Steps per Second: 10,725.81365

Timestep Collection Time: 2.20635
Timestep Consumption Time: 2.45698
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.66333

Cumulative Model Updates: 105,508
Cumulative Timesteps: 879,925,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810.33485
Policy Entropy: 3.12706
Value Function Loss: 0.00511

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.13038
Policy Update Magnitude: 0.58693
Value Function Update Magnitude: 0.60439

Collected Steps per Second: 22,889.83137
Overall Steps per Second: 10,841.25753

Timestep Collection Time: 2.18569
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.61478

Cumulative Model Updates: 105,514
Cumulative Timesteps: 879,975,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 879975174...
Checkpoint 879975174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.85733
Policy Entropy: 3.11405
Value Function Loss: 0.00508

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.58433
Value Function Update Magnitude: 0.59137

Collected Steps per Second: 22,742.48197
Overall Steps per Second: 10,714.53489

Timestep Collection Time: 2.19932
Timestep Consumption Time: 2.46892
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.66824

Cumulative Model Updates: 105,520
Cumulative Timesteps: 880,025,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.71908
Policy Entropy: 3.10616
Value Function Loss: 0.00498

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.58460
Value Function Update Magnitude: 0.59339

Collected Steps per Second: 22,760.41694
Overall Steps per Second: 10,838.33531

Timestep Collection Time: 2.19715
Timestep Consumption Time: 2.41684
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.61399

Cumulative Model Updates: 105,526
Cumulative Timesteps: 880,075,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 880075200...
Checkpoint 880075200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.81864
Policy Entropy: 3.09728
Value Function Loss: 0.00505

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.58917
Value Function Update Magnitude: 0.59611

Collected Steps per Second: 22,575.82052
Overall Steps per Second: 10,705.62929

Timestep Collection Time: 2.21591
Timestep Consumption Time: 2.45696
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.67287

Cumulative Model Updates: 105,532
Cumulative Timesteps: 880,125,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.71096
Policy Entropy: 3.08911
Value Function Loss: 0.00502

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.08602
Policy Update Magnitude: 0.59697
Value Function Update Magnitude: 0.60854

Collected Steps per Second: 23,140.80126
Overall Steps per Second: 10,895.30273

Timestep Collection Time: 2.16172
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.59134

Cumulative Model Updates: 105,538
Cumulative Timesteps: 880,175,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 880175250...
Checkpoint 880175250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.50752
Policy Entropy: 3.09515
Value Function Loss: 0.00509

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10016
Policy Update Magnitude: 0.59569
Value Function Update Magnitude: 0.61075

Collected Steps per Second: 22,479.75575
Overall Steps per Second: 10,669.66268

Timestep Collection Time: 2.22467
Timestep Consumption Time: 2.46245
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.68712

Cumulative Model Updates: 105,544
Cumulative Timesteps: 880,225,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.34647
Policy Entropy: 3.12100
Value Function Loss: 0.00487

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12319
Policy Update Magnitude: 0.59590
Value Function Update Magnitude: 0.60952

Collected Steps per Second: 22,991.24957
Overall Steps per Second: 10,861.27670

Timestep Collection Time: 2.17500
Timestep Consumption Time: 2.42906
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.60406

Cumulative Model Updates: 105,550
Cumulative Timesteps: 880,275,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 880275266...
Checkpoint 880275266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 790.88455
Policy Entropy: 3.13930
Value Function Loss: 0.00524

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11459
Policy Update Magnitude: 0.59292
Value Function Update Magnitude: 0.61567

Collected Steps per Second: 22,619.69422
Overall Steps per Second: 10,690.99994

Timestep Collection Time: 2.21082
Timestep Consumption Time: 2.46676
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.67758

Cumulative Model Updates: 105,556
Cumulative Timesteps: 880,325,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,851.61439
Policy Entropy: 3.13398
Value Function Loss: 0.00534

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12067
Policy Update Magnitude: 0.59557
Value Function Update Magnitude: 0.64921

Collected Steps per Second: 22,969.17135
Overall Steps per Second: 10,833.99789

Timestep Collection Time: 2.17883
Timestep Consumption Time: 2.44051
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.61935

Cumulative Model Updates: 105,562
Cumulative Timesteps: 880,375,320

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 880375320...
Checkpoint 880375320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.22591
Policy Entropy: 3.11812
Value Function Loss: 0.00519

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11271
Policy Update Magnitude: 0.59461
Value Function Update Magnitude: 0.66155

Collected Steps per Second: 22,580.56971
Overall Steps per Second: 10,678.53999

Timestep Collection Time: 2.21465
Timestep Consumption Time: 2.46839
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.68304

Cumulative Model Updates: 105,568
Cumulative Timesteps: 880,425,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.32335
Policy Entropy: 3.12957
Value Function Loss: 0.00478

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11096
Policy Update Magnitude: 0.58158
Value Function Update Magnitude: 0.63890

Collected Steps per Second: 22,803.36867
Overall Steps per Second: 10,811.64859

Timestep Collection Time: 2.19275
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.62483

Cumulative Model Updates: 105,574
Cumulative Timesteps: 880,475,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 880475330...
Checkpoint 880475330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.93876
Policy Entropy: 3.11415
Value Function Loss: 0.00464

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.58366
Value Function Update Magnitude: 0.61924

Collected Steps per Second: 22,873.19404
Overall Steps per Second: 10,757.70564

Timestep Collection Time: 2.18658
Timestep Consumption Time: 2.46256
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.64913

Cumulative Model Updates: 105,580
Cumulative Timesteps: 880,525,344

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.52538
Policy Entropy: 3.12565
Value Function Loss: 0.00492

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11134
Policy Update Magnitude: 0.59019
Value Function Update Magnitude: 0.61936

Collected Steps per Second: 22,917.40384
Overall Steps per Second: 10,830.89164

Timestep Collection Time: 2.18175
Timestep Consumption Time: 2.43468
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.61643

Cumulative Model Updates: 105,586
Cumulative Timesteps: 880,575,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 880575344...
Checkpoint 880575344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.11571
Policy Entropy: 3.10311
Value Function Loss: 0.00520

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.59325
Value Function Update Magnitude: 0.61759

Collected Steps per Second: 22,744.78851
Overall Steps per Second: 10,678.87272

Timestep Collection Time: 2.19919
Timestep Consumption Time: 2.48483
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.68402

Cumulative Model Updates: 105,592
Cumulative Timesteps: 880,625,364

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,121.70098
Policy Entropy: 3.10848
Value Function Loss: 0.00535

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.60230
Value Function Update Magnitude: 0.62160

Collected Steps per Second: 22,616.28137
Overall Steps per Second: 10,685.09501

Timestep Collection Time: 2.21221
Timestep Consumption Time: 2.47020
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.68241

Cumulative Model Updates: 105,598
Cumulative Timesteps: 880,675,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 880675396...
Checkpoint 880675396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775.04981
Policy Entropy: 3.10394
Value Function Loss: 0.00519

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.60812
Value Function Update Magnitude: 0.62594

Collected Steps per Second: 22,855.85791
Overall Steps per Second: 10,785.59521

Timestep Collection Time: 2.18797
Timestep Consumption Time: 2.44858
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.63655

Cumulative Model Updates: 105,604
Cumulative Timesteps: 880,725,404

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,936.53639
Policy Entropy: 3.10690
Value Function Loss: 0.00505

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.60305
Value Function Update Magnitude: 0.62989

Collected Steps per Second: 23,047.58827
Overall Steps per Second: 10,890.63019

Timestep Collection Time: 2.17012
Timestep Consumption Time: 2.42245
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.59257

Cumulative Model Updates: 105,610
Cumulative Timesteps: 880,775,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 880775420...
Checkpoint 880775420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 851.96887
Policy Entropy: 3.10836
Value Function Loss: 0.00519

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11495
Policy Update Magnitude: 0.60317
Value Function Update Magnitude: 0.63947

Collected Steps per Second: 22,682.90176
Overall Steps per Second: 10,747.31353

Timestep Collection Time: 2.20466
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.65307

Cumulative Model Updates: 105,616
Cumulative Timesteps: 880,825,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 950.26318
Policy Entropy: 3.10809
Value Function Loss: 0.00506

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10590
Policy Update Magnitude: 0.60551
Value Function Update Magnitude: 0.64761

Collected Steps per Second: 22,834.50336
Overall Steps per Second: 10,809.20905

Timestep Collection Time: 2.19046
Timestep Consumption Time: 2.43689
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.62735

Cumulative Model Updates: 105,622
Cumulative Timesteps: 880,875,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 880875446...
Checkpoint 880875446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.30550
Policy Entropy: 3.09689
Value Function Loss: 0.00507

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.59863
Value Function Update Magnitude: 0.62286

Collected Steps per Second: 22,812.94539
Overall Steps per Second: 10,757.62491

Timestep Collection Time: 2.19183
Timestep Consumption Time: 2.45623
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.64805

Cumulative Model Updates: 105,628
Cumulative Timesteps: 880,925,448

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.75866
Policy Entropy: 3.09894
Value Function Loss: 0.00516

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.60169
Value Function Update Magnitude: 0.60699

Collected Steps per Second: 23,039.38951
Overall Steps per Second: 10,831.31830

Timestep Collection Time: 2.17028
Timestep Consumption Time: 2.44614
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.61643

Cumulative Model Updates: 105,634
Cumulative Timesteps: 880,975,450

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 880975450...
Checkpoint 880975450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.76755
Policy Entropy: 3.11428
Value Function Loss: 0.00488

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.60155
Value Function Update Magnitude: 0.60323

Collected Steps per Second: 22,565.49400
Overall Steps per Second: 10,698.41191

Timestep Collection Time: 2.21648
Timestep Consumption Time: 2.45860
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.67509

Cumulative Model Updates: 105,640
Cumulative Timesteps: 881,025,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 997.20720
Policy Entropy: 3.12514
Value Function Loss: 0.00496

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.59245
Value Function Update Magnitude: 0.60359

Collected Steps per Second: 22,884.44886
Overall Steps per Second: 10,820.92352

Timestep Collection Time: 2.18585
Timestep Consumption Time: 2.43686
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.62271

Cumulative Model Updates: 105,646
Cumulative Timesteps: 881,075,488

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 881075488...
Checkpoint 881075488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.24026
Policy Entropy: 3.12960
Value Function Loss: 0.00509

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09777
Policy Update Magnitude: 0.59625
Value Function Update Magnitude: 0.61940

Collected Steps per Second: 22,577.55311
Overall Steps per Second: 10,689.86001

Timestep Collection Time: 2.21494
Timestep Consumption Time: 2.46313
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.67808

Cumulative Model Updates: 105,652
Cumulative Timesteps: 881,125,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,119.24969
Policy Entropy: 3.10991
Value Function Loss: 0.00559

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.60294
Value Function Update Magnitude: 0.64864

Collected Steps per Second: 22,882.43986
Overall Steps per Second: 10,835.57148

Timestep Collection Time: 2.18578
Timestep Consumption Time: 2.43013
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.61591

Cumulative Model Updates: 105,658
Cumulative Timesteps: 881,175,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 881175512...
Checkpoint 881175512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.86524
Policy Entropy: 3.12337
Value Function Loss: 0.00541

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.60319
Value Function Update Magnitude: 0.64698

Collected Steps per Second: 22,600.56608
Overall Steps per Second: 10,771.71430

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.43042
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.64364

Cumulative Model Updates: 105,664
Cumulative Timesteps: 881,225,532

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 851.35276
Policy Entropy: 3.11676
Value Function Loss: 0.00518

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08611
Policy Update Magnitude: 0.60041
Value Function Update Magnitude: 0.63954

Collected Steps per Second: 22,837.37457
Overall Steps per Second: 10,928.40615

Timestep Collection Time: 2.18948
Timestep Consumption Time: 2.38593
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.57542

Cumulative Model Updates: 105,670
Cumulative Timesteps: 881,275,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 881275534...
Checkpoint 881275534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.60348
Policy Entropy: 3.13510
Value Function Loss: 0.00492

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.59347
Value Function Update Magnitude: 0.61315

Collected Steps per Second: 22,158.06336
Overall Steps per Second: 10,636.87763

Timestep Collection Time: 2.25742
Timestep Consumption Time: 2.44509
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.70251

Cumulative Model Updates: 105,676
Cumulative Timesteps: 881,325,554

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.35575
Policy Entropy: 3.12808
Value Function Loss: 0.00528

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.60228
Value Function Update Magnitude: 0.63233

Collected Steps per Second: 22,346.40366
Overall Steps per Second: 10,837.44133

Timestep Collection Time: 2.23803
Timestep Consumption Time: 2.37671
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.61474

Cumulative Model Updates: 105,682
Cumulative Timesteps: 881,375,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 881375566...
Checkpoint 881375566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 856.84888
Policy Entropy: 3.13051
Value Function Loss: 0.00531

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.60117
Value Function Update Magnitude: 0.66674

Collected Steps per Second: 21,830.01973
Overall Steps per Second: 10,636.72858

Timestep Collection Time: 2.29070
Timestep Consumption Time: 2.41056
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.70126

Cumulative Model Updates: 105,688
Cumulative Timesteps: 881,425,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.87352
Policy Entropy: 3.12347
Value Function Loss: 0.00531

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.60050
Value Function Update Magnitude: 0.66039

Collected Steps per Second: 22,268.52891
Overall Steps per Second: 10,703.07470

Timestep Collection Time: 2.24604
Timestep Consumption Time: 2.42701
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.67305

Cumulative Model Updates: 105,694
Cumulative Timesteps: 881,475,588

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 881475588...
Checkpoint 881475588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 818.27753
Policy Entropy: 3.12818
Value Function Loss: 0.00512

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.59765
Value Function Update Magnitude: 0.63920

Collected Steps per Second: 22,054.23712
Overall Steps per Second: 10,796.78531

Timestep Collection Time: 2.26741
Timestep Consumption Time: 2.36415
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.63156

Cumulative Model Updates: 105,700
Cumulative Timesteps: 881,525,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 970.68450
Policy Entropy: 3.11551
Value Function Loss: 0.00506

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.59687
Value Function Update Magnitude: 0.61002

Collected Steps per Second: 23,160.94966
Overall Steps per Second: 10,719.55190

Timestep Collection Time: 2.15976
Timestep Consumption Time: 2.50667
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.66643

Cumulative Model Updates: 105,706
Cumulative Timesteps: 881,575,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 881575616...
Checkpoint 881575616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.92419
Policy Entropy: 3.12490
Value Function Loss: 0.00514

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09183
Policy Update Magnitude: 0.59661
Value Function Update Magnitude: 0.60321

Collected Steps per Second: 22,837.66372
Overall Steps per Second: 10,814.56687

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.43520
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.62561

Cumulative Model Updates: 105,712
Cumulative Timesteps: 881,625,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.71155
Policy Entropy: 3.14057
Value Function Loss: 0.00507

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.58723
Value Function Update Magnitude: 0.61195

Collected Steps per Second: 22,393.07883
Overall Steps per Second: 10,557.44808

Timestep Collection Time: 2.23310
Timestep Consumption Time: 2.50346
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.73656

Cumulative Model Updates: 105,718
Cumulative Timesteps: 881,675,646

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 881675646...
Checkpoint 881675646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.06074
Policy Entropy: 3.14703
Value Function Loss: 0.00498

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.57730
Value Function Update Magnitude: 0.62105

Collected Steps per Second: 22,731.83599
Overall Steps per Second: 10,625.37703

Timestep Collection Time: 2.20088
Timestep Consumption Time: 2.50766
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.70854

Cumulative Model Updates: 105,724
Cumulative Timesteps: 881,725,676

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.55588
Policy Entropy: 3.13070
Value Function Loss: 0.00489

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.56858
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 23,042.01710
Overall Steps per Second: 10,808.79171

Timestep Collection Time: 2.17056
Timestep Consumption Time: 2.45660
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.62716

Cumulative Model Updates: 105,730
Cumulative Timesteps: 881,775,690

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 881775690...
Checkpoint 881775690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.30223
Policy Entropy: 3.12137
Value Function Loss: 0.00503

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.57839
Value Function Update Magnitude: 0.62190

Collected Steps per Second: 22,646.41033
Overall Steps per Second: 10,671.18999

Timestep Collection Time: 2.20892
Timestep Consumption Time: 2.47885
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.68776

Cumulative Model Updates: 105,736
Cumulative Timesteps: 881,825,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.40663
Policy Entropy: 3.13797
Value Function Loss: 0.00477

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.58472
Value Function Update Magnitude: 0.61746

Collected Steps per Second: 23,001.31150
Overall Steps per Second: 10,710.67372

Timestep Collection Time: 2.17431
Timestep Consumption Time: 2.49505
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.66936

Cumulative Model Updates: 105,742
Cumulative Timesteps: 881,875,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 881875726...
Checkpoint 881875726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 785.94702
Policy Entropy: 3.14977
Value Function Loss: 0.00463

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.61233

Collected Steps per Second: 22,926.75296
Overall Steps per Second: 10,801.50669

Timestep Collection Time: 2.18182
Timestep Consumption Time: 2.44920
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.63102

Cumulative Model Updates: 105,748
Cumulative Timesteps: 881,925,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789.01412
Policy Entropy: 3.14055
Value Function Loss: 0.00465

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.57398
Value Function Update Magnitude: 0.61036

Collected Steps per Second: 23,090.76822
Overall Steps per Second: 10,712.14470

Timestep Collection Time: 2.16571
Timestep Consumption Time: 2.50263
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.66835

Cumulative Model Updates: 105,754
Cumulative Timesteps: 881,975,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 881975756...
Checkpoint 881975756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,482.09602
Policy Entropy: 3.13622
Value Function Loss: 0.00478

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.57265
Value Function Update Magnitude: 0.61741

Collected Steps per Second: 22,485.29137
Overall Steps per Second: 10,513.75980

Timestep Collection Time: 2.22448
Timestep Consumption Time: 2.53291
PPO Batch Consumption Time: 0.29559
Total Iteration Time: 4.75738

Cumulative Model Updates: 105,760
Cumulative Timesteps: 882,025,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.47237
Policy Entropy: 3.12429
Value Function Loss: 0.00494

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.57248
Value Function Update Magnitude: 0.61558

Collected Steps per Second: 23,378.04253
Overall Steps per Second: 10,905.58512

Timestep Collection Time: 2.13902
Timestep Consumption Time: 2.44634
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.58536

Cumulative Model Updates: 105,766
Cumulative Timesteps: 882,075,780

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 882075780...
Checkpoint 882075780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.52550
Policy Entropy: 3.13434
Value Function Loss: 0.00513

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.12039
Policy Update Magnitude: 0.57997
Value Function Update Magnitude: 0.61556

Collected Steps per Second: 22,697.48301
Overall Steps per Second: 10,595.50231

Timestep Collection Time: 2.20386
Timestep Consumption Time: 2.51720
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.72106

Cumulative Model Updates: 105,772
Cumulative Timesteps: 882,125,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.16532
Policy Entropy: 3.14842
Value Function Loss: 0.00518

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12060
Policy Update Magnitude: 0.58097
Value Function Update Magnitude: 0.60474

Collected Steps per Second: 23,342.44093
Overall Steps per Second: 10,866.78271

Timestep Collection Time: 2.14228
Timestep Consumption Time: 2.45945
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.60173

Cumulative Model Updates: 105,778
Cumulative Timesteps: 882,175,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 882175808...
Checkpoint 882175808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.17948
Policy Entropy: 3.16635
Value Function Loss: 0.00512

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.58154
Value Function Update Magnitude: 0.60617

Collected Steps per Second: 22,407.25764
Overall Steps per Second: 10,683.02714

Timestep Collection Time: 2.23178
Timestep Consumption Time: 2.44929
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.68107

Cumulative Model Updates: 105,784
Cumulative Timesteps: 882,225,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.21701
Policy Entropy: 3.16320
Value Function Loss: 0.00510

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.58456
Value Function Update Magnitude: 0.62219

Collected Steps per Second: 23,068.35609
Overall Steps per Second: 10,821.80368

Timestep Collection Time: 2.16825
Timestep Consumption Time: 2.45371
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.62197

Cumulative Model Updates: 105,790
Cumulative Timesteps: 882,275,834

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 882275834...
Checkpoint 882275834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 948.01782
Policy Entropy: 3.14580
Value Function Loss: 0.00510

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.59094
Value Function Update Magnitude: 0.62364

Collected Steps per Second: 22,737.68347
Overall Steps per Second: 10,715.57867

Timestep Collection Time: 2.19943
Timestep Consumption Time: 2.46760
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.66704

Cumulative Model Updates: 105,796
Cumulative Timesteps: 882,325,844

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.52995
Policy Entropy: 3.13511
Value Function Loss: 0.00504

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.59279
Value Function Update Magnitude: 0.63877

Collected Steps per Second: 22,589.16773
Overall Steps per Second: 10,550.04980

Timestep Collection Time: 2.21416
Timestep Consumption Time: 2.52667
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.74083

Cumulative Model Updates: 105,802
Cumulative Timesteps: 882,375,860

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 882375860...
Checkpoint 882375860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.35767
Policy Entropy: 3.14770
Value Function Loss: 0.00479

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.58568
Value Function Update Magnitude: 0.62581

Collected Steps per Second: 22,624.23686
Overall Steps per Second: 10,585.52749

Timestep Collection Time: 2.21055
Timestep Consumption Time: 2.51401
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 4.72456

Cumulative Model Updates: 105,808
Cumulative Timesteps: 882,425,872

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,205.24229
Policy Entropy: 3.17025
Value Function Loss: 0.00480

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09372
Policy Update Magnitude: 0.57702
Value Function Update Magnitude: 0.60232

Collected Steps per Second: 22,811.08366
Overall Steps per Second: 10,794.47933

Timestep Collection Time: 2.19271
Timestep Consumption Time: 2.44096
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.63366

Cumulative Model Updates: 105,814
Cumulative Timesteps: 882,475,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 882475890...
Checkpoint 882475890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 648.09842
Policy Entropy: 3.19165
Value Function Loss: 0.00481

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.08570
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.59904

Collected Steps per Second: 22,737.46967
Overall Steps per Second: 10,729.10334

Timestep Collection Time: 2.19919
Timestep Consumption Time: 2.46141
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.66059

Cumulative Model Updates: 105,820
Cumulative Timesteps: 882,525,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.96308
Policy Entropy: 3.18202
Value Function Loss: 0.00492

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08671
Policy Update Magnitude: 0.58176
Value Function Update Magnitude: 0.59370

Collected Steps per Second: 22,865.43947
Overall Steps per Second: 10,698.95803

Timestep Collection Time: 2.18802
Timestep Consumption Time: 2.48814
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.67616

Cumulative Model Updates: 105,826
Cumulative Timesteps: 882,575,924

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 882575924...
Checkpoint 882575924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.99981
Policy Entropy: 3.16552
Value Function Loss: 0.00492

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.57988
Value Function Update Magnitude: 0.58610

Collected Steps per Second: 22,902.15072
Overall Steps per Second: 10,760.95897

Timestep Collection Time: 2.18329
Timestep Consumption Time: 2.46332
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.64661

Cumulative Model Updates: 105,832
Cumulative Timesteps: 882,625,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.68481
Policy Entropy: 3.15614
Value Function Loss: 0.00502

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10595
Policy Update Magnitude: 0.58333
Value Function Update Magnitude: 0.57847

Collected Steps per Second: 23,276.55127
Overall Steps per Second: 10,742.30897

Timestep Collection Time: 2.14903
Timestep Consumption Time: 2.50751
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.65654

Cumulative Model Updates: 105,838
Cumulative Timesteps: 882,675,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 882675948...
Checkpoint 882675948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.20693
Policy Entropy: 3.15744
Value Function Loss: 0.00516

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.59020
Value Function Update Magnitude: 0.58242

Collected Steps per Second: 22,037.21572
Overall Steps per Second: 10,669.20026

Timestep Collection Time: 2.27025
Timestep Consumption Time: 2.41895
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.68920

Cumulative Model Updates: 105,844
Cumulative Timesteps: 882,725,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.72390
Policy Entropy: 3.17171
Value Function Loss: 0.00498

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.59307
Value Function Update Magnitude: 0.60676

Collected Steps per Second: 23,505.48469
Overall Steps per Second: 10,781.59258

Timestep Collection Time: 2.12725
Timestep Consumption Time: 2.51047
PPO Batch Consumption Time: 0.29485
Total Iteration Time: 4.63772

Cumulative Model Updates: 105,850
Cumulative Timesteps: 882,775,980

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 882775980...
Checkpoint 882775980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.63154
Policy Entropy: 3.17584
Value Function Loss: 0.00502

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.58737
Value Function Update Magnitude: 0.60985

Collected Steps per Second: 22,452.22550
Overall Steps per Second: 10,523.32545

Timestep Collection Time: 2.22749
Timestep Consumption Time: 2.52500
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.75249

Cumulative Model Updates: 105,856
Cumulative Timesteps: 882,825,992

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.76092
Policy Entropy: 3.16918
Value Function Loss: 0.00479

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.58197
Value Function Update Magnitude: 0.60492

Collected Steps per Second: 22,791.71945
Overall Steps per Second: 10,674.22170

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.49060
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.68456

Cumulative Model Updates: 105,862
Cumulative Timesteps: 882,875,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 882875996...
Checkpoint 882875996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.91116
Policy Entropy: 3.15933
Value Function Loss: 0.00478

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10216
Policy Update Magnitude: 0.57575
Value Function Update Magnitude: 0.59467

Collected Steps per Second: 22,983.17176
Overall Steps per Second: 10,834.49132

Timestep Collection Time: 2.17603
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.61600

Cumulative Model Updates: 105,868
Cumulative Timesteps: 882,926,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.80289
Policy Entropy: 3.16002
Value Function Loss: 0.00493

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.58063
Value Function Update Magnitude: 0.56706

Collected Steps per Second: 22,782.64776
Overall Steps per Second: 10,567.49707

Timestep Collection Time: 2.19544
Timestep Consumption Time: 2.53775
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.73319

Cumulative Model Updates: 105,874
Cumulative Timesteps: 882,976,026

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 882976026...
Checkpoint 882976026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,251.43216
Policy Entropy: 3.16332
Value Function Loss: 0.00494

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.57960
Value Function Update Magnitude: 0.56647

Collected Steps per Second: 22,762.92386
Overall Steps per Second: 10,598.34688

Timestep Collection Time: 2.19673
Timestep Consumption Time: 2.52136
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.71809

Cumulative Model Updates: 105,880
Cumulative Timesteps: 883,026,030

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 687.99633
Policy Entropy: 3.17339
Value Function Loss: 0.00504

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.58733
Value Function Update Magnitude: 0.59119

Collected Steps per Second: 22,885.29683
Overall Steps per Second: 10,848.90020

Timestep Collection Time: 2.18586
Timestep Consumption Time: 2.42512
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.61097

Cumulative Model Updates: 105,886
Cumulative Timesteps: 883,076,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 883076054...
Checkpoint 883076054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 773.98375
Policy Entropy: 3.17752
Value Function Loss: 0.00480

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08881
Policy Update Magnitude: 0.58170
Value Function Update Magnitude: 0.59403

Collected Steps per Second: 22,702.79076
Overall Steps per Second: 10,688.74380

Timestep Collection Time: 2.20255
Timestep Consumption Time: 2.47564
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.67819

Cumulative Model Updates: 105,892
Cumulative Timesteps: 883,126,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.11479
Policy Entropy: 3.17744
Value Function Loss: 0.00509

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09043
Policy Update Magnitude: 0.57754
Value Function Update Magnitude: 0.58719

Collected Steps per Second: 23,357.28320
Overall Steps per Second: 10,912.45099

Timestep Collection Time: 2.14092
Timestep Consumption Time: 2.44156
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.58247

Cumulative Model Updates: 105,898
Cumulative Timesteps: 883,176,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 883176064...
Checkpoint 883176064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.62225
Policy Entropy: 3.16364
Value Function Loss: 0.00525

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.59192
Value Function Update Magnitude: 0.61548

Collected Steps per Second: 22,533.12551
Overall Steps per Second: 10,663.15677

Timestep Collection Time: 2.21975
Timestep Consumption Time: 2.47098
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.69073

Cumulative Model Updates: 105,904
Cumulative Timesteps: 883,226,082

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 748.61970
Policy Entropy: 3.15069
Value Function Loss: 0.00538

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10197
Policy Update Magnitude: 0.60531
Value Function Update Magnitude: 0.65055

Collected Steps per Second: 23,351.43513
Overall Steps per Second: 10,892.36708

Timestep Collection Time: 2.14205
Timestep Consumption Time: 2.45015
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.59221

Cumulative Model Updates: 105,910
Cumulative Timesteps: 883,276,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 883276102...
Checkpoint 883276102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.51325
Policy Entropy: 3.16211
Value Function Loss: 0.00556

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.60961
Value Function Update Magnitude: 0.64934

Collected Steps per Second: 22,791.77613
Overall Steps per Second: 10,668.07105

Timestep Collection Time: 2.19456
Timestep Consumption Time: 2.49401
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.68857

Cumulative Model Updates: 105,916
Cumulative Timesteps: 883,326,120

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.03019
Policy Entropy: 3.16710
Value Function Loss: 0.00528

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09954
Policy Update Magnitude: 0.59962
Value Function Update Magnitude: 0.65800

Collected Steps per Second: 22,938.55631
Overall Steps per Second: 10,786.06600

Timestep Collection Time: 2.18000
Timestep Consumption Time: 2.45617
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.63617

Cumulative Model Updates: 105,922
Cumulative Timesteps: 883,376,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 883376126...
Checkpoint 883376126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.40892
Policy Entropy: 3.16200
Value Function Loss: 0.00544

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10145
Policy Update Magnitude: 0.60088
Value Function Update Magnitude: 0.65614

Collected Steps per Second: 22,517.10291
Overall Steps per Second: 10,698.84946

Timestep Collection Time: 2.22124
Timestep Consumption Time: 2.45365
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.67490

Cumulative Model Updates: 105,928
Cumulative Timesteps: 883,426,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,192.19257
Policy Entropy: 3.15443
Value Function Loss: 0.00517

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.60177
Value Function Update Magnitude: 0.67908

Collected Steps per Second: 22,835.67458
Overall Steps per Second: 10,627.63307

Timestep Collection Time: 2.19061
Timestep Consumption Time: 2.51637
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.70697

Cumulative Model Updates: 105,934
Cumulative Timesteps: 883,476,166

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 883476166...
Checkpoint 883476166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.96921
Policy Entropy: 3.15016
Value Function Loss: 0.00505

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.59259
Value Function Update Magnitude: 0.68160

Collected Steps per Second: 23,107.35858
Overall Steps per Second: 10,852.28939

Timestep Collection Time: 2.16468
Timestep Consumption Time: 2.44449
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.60917

Cumulative Model Updates: 105,940
Cumulative Timesteps: 883,526,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.36944
Policy Entropy: 3.15806
Value Function Loss: 0.00496

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.58213
Value Function Update Magnitude: 0.65786

Collected Steps per Second: 23,154.45616
Overall Steps per Second: 10,713.55802

Timestep Collection Time: 2.15958
Timestep Consumption Time: 2.50777
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.66736

Cumulative Model Updates: 105,946
Cumulative Timesteps: 883,576,190

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 883576190...
Checkpoint 883576190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.68560
Policy Entropy: 3.15806
Value Function Loss: 0.00532

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.59014
Value Function Update Magnitude: 0.65318

Collected Steps per Second: 22,783.21819
Overall Steps per Second: 10,662.93906

Timestep Collection Time: 2.19556
Timestep Consumption Time: 2.49564
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.69120

Cumulative Model Updates: 105,952
Cumulative Timesteps: 883,626,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.83886
Policy Entropy: 3.16950
Value Function Loss: 0.00528

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.59129
Value Function Update Magnitude: 0.64764

Collected Steps per Second: 23,284.59154
Overall Steps per Second: 10,745.18411

Timestep Collection Time: 2.14734
Timestep Consumption Time: 2.50590
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.65325

Cumulative Model Updates: 105,958
Cumulative Timesteps: 883,676,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 883676212...
Checkpoint 883676212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.52286
Policy Entropy: 3.15620
Value Function Loss: 0.00532

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09750
Policy Update Magnitude: 0.59125
Value Function Update Magnitude: 0.61470

Collected Steps per Second: 22,728.81476
Overall Steps per Second: 10,627.50990

Timestep Collection Time: 2.20047
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.70609

Cumulative Model Updates: 105,964
Cumulative Timesteps: 883,726,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 916.09360
Policy Entropy: 3.14533
Value Function Loss: 0.00541

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10241
Policy Update Magnitude: 0.59579
Value Function Update Magnitude: 0.60061

Collected Steps per Second: 23,182.35047
Overall Steps per Second: 10,864.08845

Timestep Collection Time: 2.15845
Timestep Consumption Time: 2.44736
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.60582

Cumulative Model Updates: 105,970
Cumulative Timesteps: 883,776,264

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 883776264...
Checkpoint 883776264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.40911
Policy Entropy: 3.13039
Value Function Loss: 0.00557

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.59761
Value Function Update Magnitude: 0.61407

Collected Steps per Second: 22,416.08265
Overall Steps per Second: 10,685.85660

Timestep Collection Time: 2.23143
Timestep Consumption Time: 2.44952
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.68095

Cumulative Model Updates: 105,976
Cumulative Timesteps: 883,826,284

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.05521
Policy Entropy: 3.13433
Value Function Loss: 0.00543

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09965
Policy Update Magnitude: 0.58982
Value Function Update Magnitude: 0.62766

Collected Steps per Second: 23,075.04378
Overall Steps per Second: 10,824.34620

Timestep Collection Time: 2.16693
Timestep Consumption Time: 2.45247
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.61940

Cumulative Model Updates: 105,982
Cumulative Timesteps: 883,876,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 883876286...
Checkpoint 883876286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.16642
Policy Entropy: 3.13437
Value Function Loss: 0.00512

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11027
Policy Update Magnitude: 0.58872
Value Function Update Magnitude: 0.63248

Collected Steps per Second: 22,605.36783
Overall Steps per Second: 10,782.52355

Timestep Collection Time: 2.21301
Timestep Consumption Time: 2.42653
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.63954

Cumulative Model Updates: 105,988
Cumulative Timesteps: 883,926,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.97581
Policy Entropy: 3.14380
Value Function Loss: 0.00514

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10278
Policy Update Magnitude: 0.58469
Value Function Update Magnitude: 0.63115

Collected Steps per Second: 23,481.06067
Overall Steps per Second: 10,849.36356

Timestep Collection Time: 2.13006
Timestep Consumption Time: 2.47998
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.61004

Cumulative Model Updates: 105,994
Cumulative Timesteps: 883,976,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 883976328...
Checkpoint 883976328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.21065
Policy Entropy: 3.13674
Value Function Loss: 0.00507

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.58836
Value Function Update Magnitude: 0.63364

Collected Steps per Second: 22,514.46862
Overall Steps per Second: 10,651.59248

Timestep Collection Time: 2.22124
Timestep Consumption Time: 2.47383
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.69507

Cumulative Model Updates: 106,000
Cumulative Timesteps: 884,026,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.78294
Policy Entropy: 3.14116
Value Function Loss: 0.00504

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11277
Policy Update Magnitude: 0.58693
Value Function Update Magnitude: 0.64882

Collected Steps per Second: 22,614.12158
Overall Steps per Second: 10,565.71563

Timestep Collection Time: 2.21225
Timestep Consumption Time: 2.52269
PPO Batch Consumption Time: 0.29431
Total Iteration Time: 4.73494

Cumulative Model Updates: 106,006
Cumulative Timesteps: 884,076,366

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 884076366...
Checkpoint 884076366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,570.81191
Policy Entropy: 3.14770
Value Function Loss: 0.00478

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.10059
Policy Update Magnitude: 0.58313
Value Function Update Magnitude: 0.63783

Collected Steps per Second: 22,891.08510
Overall Steps per Second: 10,710.43578

Timestep Collection Time: 2.18496
Timestep Consumption Time: 2.48488
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.66984

Cumulative Model Updates: 106,012
Cumulative Timesteps: 884,126,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.06171
Policy Entropy: 3.15895
Value Function Loss: 0.00489

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.57326
Value Function Update Magnitude: 0.61705

Collected Steps per Second: 22,917.68556
Overall Steps per Second: 10,710.48769

Timestep Collection Time: 2.18251
Timestep Consumption Time: 2.48750
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.67000

Cumulative Model Updates: 106,018
Cumulative Timesteps: 884,176,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 884176400...
Checkpoint 884176400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.04387
Policy Entropy: 3.15797
Value Function Loss: 0.00515

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.57553
Value Function Update Magnitude: 0.63435

Collected Steps per Second: 22,683.48658
Overall Steps per Second: 10,623.92038

Timestep Collection Time: 2.20478
Timestep Consumption Time: 2.50271
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.70749

Cumulative Model Updates: 106,024
Cumulative Timesteps: 884,226,412

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.86614
Policy Entropy: 3.15383
Value Function Loss: 0.00516

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.58016
Value Function Update Magnitude: 0.65728

Collected Steps per Second: 22,876.07377
Overall Steps per Second: 10,723.22053

Timestep Collection Time: 2.18648
Timestep Consumption Time: 2.47798
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.66446

Cumulative Model Updates: 106,030
Cumulative Timesteps: 884,276,430

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 884276430...
Checkpoint 884276430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.73951
Policy Entropy: 3.15773
Value Function Loss: 0.00509

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10959
Policy Update Magnitude: 0.58051
Value Function Update Magnitude: 0.63721

Collected Steps per Second: 22,809.95542
Overall Steps per Second: 10,773.86940

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.45001
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.64309

Cumulative Model Updates: 106,036
Cumulative Timesteps: 884,326,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.09031
Policy Entropy: 3.16069
Value Function Loss: 0.00495

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09495
Policy Update Magnitude: 0.57506
Value Function Update Magnitude: 0.61184

Collected Steps per Second: 23,042.39488
Overall Steps per Second: 10,715.02564

Timestep Collection Time: 2.17087
Timestep Consumption Time: 2.49753
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.66840

Cumulative Model Updates: 106,042
Cumulative Timesteps: 884,376,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 884376476...
Checkpoint 884376476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.98455
Policy Entropy: 3.15749
Value Function Loss: 0.00486

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.57372
Value Function Update Magnitude: 0.61039

Collected Steps per Second: 22,597.88447
Overall Steps per Second: 10,588.67995

Timestep Collection Time: 2.21269
Timestep Consumption Time: 2.50953
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.72221

Cumulative Model Updates: 106,048
Cumulative Timesteps: 884,426,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.16635
Policy Entropy: 3.14708
Value Function Loss: 0.00475

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.57339
Value Function Update Magnitude: 0.61911

Collected Steps per Second: 23,057.13618
Overall Steps per Second: 10,740.52273

Timestep Collection Time: 2.16931
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.65694

Cumulative Model Updates: 106,054
Cumulative Timesteps: 884,476,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 884476496...
Checkpoint 884476496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.93502
Policy Entropy: 3.14396
Value Function Loss: 0.00482

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09694
Policy Update Magnitude: 0.57213
Value Function Update Magnitude: 0.60741

Collected Steps per Second: 22,277.98969
Overall Steps per Second: 10,638.40240

Timestep Collection Time: 2.24536
Timestep Consumption Time: 2.45667
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.70202

Cumulative Model Updates: 106,060
Cumulative Timesteps: 884,526,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,793.12046
Policy Entropy: 3.15758
Value Function Loss: 0.00465

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.56845
Value Function Update Magnitude: 0.59524

Collected Steps per Second: 22,972.92256
Overall Steps per Second: 10,831.62809

Timestep Collection Time: 2.17682
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.61685

Cumulative Model Updates: 106,066
Cumulative Timesteps: 884,576,526

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 884576526...
Checkpoint 884576526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 812.42844
Policy Entropy: 3.15936
Value Function Loss: 0.00489

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.58106

Collected Steps per Second: 22,494.28751
Overall Steps per Second: 10,723.84978

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.44089
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.66474

Cumulative Model Updates: 106,072
Cumulative Timesteps: 884,626,550

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.27051
Policy Entropy: 3.15166
Value Function Loss: 0.00495

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.10926
Policy Update Magnitude: 0.56533
Value Function Update Magnitude: 0.58901

Collected Steps per Second: 23,059.99652
Overall Steps per Second: 10,883.60960

Timestep Collection Time: 2.16869
Timestep Consumption Time: 2.42629
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.59498

Cumulative Model Updates: 106,078
Cumulative Timesteps: 884,676,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 884676560...
Checkpoint 884676560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.24619
Policy Entropy: 3.15358
Value Function Loss: 0.00516

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11867
Policy Update Magnitude: 0.56488
Value Function Update Magnitude: 0.58395

Collected Steps per Second: 22,297.54221
Overall Steps per Second: 10,739.66425

Timestep Collection Time: 2.24267
Timestep Consumption Time: 2.41353
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.65620

Cumulative Model Updates: 106,084
Cumulative Timesteps: 884,726,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 875.85884
Policy Entropy: 3.15782
Value Function Loss: 0.00500

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.57293
Value Function Update Magnitude: 0.57990

Collected Steps per Second: 22,775.63684
Overall Steps per Second: 10,782.81755

Timestep Collection Time: 2.19603
Timestep Consumption Time: 2.44246
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.63849

Cumulative Model Updates: 106,090
Cumulative Timesteps: 884,776,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 884776582...
Checkpoint 884776582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 908.39793
Policy Entropy: 3.15517
Value Function Loss: 0.00508

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.57138
Value Function Update Magnitude: 0.57900

Collected Steps per Second: 22,852.72415
Overall Steps per Second: 10,684.39028

Timestep Collection Time: 2.18810
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.68010

Cumulative Model Updates: 106,096
Cumulative Timesteps: 884,826,586

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.52091
Policy Entropy: 3.15190
Value Function Loss: 0.00487

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10486
Policy Update Magnitude: 0.57345
Value Function Update Magnitude: 0.58739

Collected Steps per Second: 21,293.85887
Overall Steps per Second: 10,456.16619

Timestep Collection Time: 2.34875
Timestep Consumption Time: 2.43445
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.78321

Cumulative Model Updates: 106,102
Cumulative Timesteps: 884,876,600

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 884876600...
Checkpoint 884876600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,511.48417
Policy Entropy: 3.14451
Value Function Loss: 0.00481

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10580
Policy Update Magnitude: 0.57526
Value Function Update Magnitude: 0.59039

Collected Steps per Second: 22,581.50880
Overall Steps per Second: 10,671.72021

Timestep Collection Time: 2.21456
Timestep Consumption Time: 2.47147
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.68603

Cumulative Model Updates: 106,108
Cumulative Timesteps: 884,926,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.23332
Policy Entropy: 3.15538
Value Function Loss: 0.00437

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09417
Policy Update Magnitude: 0.57115
Value Function Update Magnitude: 0.59307

Collected Steps per Second: 23,215.08350
Overall Steps per Second: 10,954.92910

Timestep Collection Time: 2.15506
Timestep Consumption Time: 2.41183
PPO Batch Consumption Time: 0.27974
Total Iteration Time: 4.56689

Cumulative Model Updates: 106,114
Cumulative Timesteps: 884,976,638

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 884976638...
Checkpoint 884976638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,145.49192
Policy Entropy: 3.14359
Value Function Loss: 0.00458

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.55701
Value Function Update Magnitude: 0.58195

Collected Steps per Second: 22,510.47197
Overall Steps per Second: 10,585.87579

Timestep Collection Time: 2.22243
Timestep Consumption Time: 2.50349
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.72592

Cumulative Model Updates: 106,120
Cumulative Timesteps: 885,026,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.20583
Policy Entropy: 3.15336
Value Function Loss: 0.00459

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09137
Policy Update Magnitude: 0.55566
Value Function Update Magnitude: 0.58175

Collected Steps per Second: 23,396.46789
Overall Steps per Second: 10,920.75921

Timestep Collection Time: 2.13716
Timestep Consumption Time: 2.44146
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.57862

Cumulative Model Updates: 106,126
Cumulative Timesteps: 885,076,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 885076668...
Checkpoint 885076668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,705.58437
Policy Entropy: 3.12726
Value Function Loss: 0.00479

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.59578

Collected Steps per Second: 22,729.06451
Overall Steps per Second: 10,665.51718

Timestep Collection Time: 2.20071
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.68988

Cumulative Model Updates: 106,132
Cumulative Timesteps: 885,126,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 707.23368
Policy Entropy: 3.11543
Value Function Loss: 0.00490

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09161
Policy Update Magnitude: 0.58097
Value Function Update Magnitude: 0.59971

Collected Steps per Second: 22,981.16000
Overall Steps per Second: 10,841.23685

Timestep Collection Time: 2.17657
Timestep Consumption Time: 2.43730
PPO Batch Consumption Time: 0.28389
Total Iteration Time: 4.61386

Cumulative Model Updates: 106,138
Cumulative Timesteps: 885,176,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 885176708...
Checkpoint 885176708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.92973
Policy Entropy: 3.10845
Value Function Loss: 0.00488

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.57827
Value Function Update Magnitude: 0.58408

Collected Steps per Second: 22,453.82352
Overall Steps per Second: 10,668.64045

Timestep Collection Time: 2.22724
Timestep Consumption Time: 2.46033
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.68757

Cumulative Model Updates: 106,144
Cumulative Timesteps: 885,226,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.93308
Policy Entropy: 3.11617
Value Function Loss: 0.00496

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10917
Policy Update Magnitude: 0.56727
Value Function Update Magnitude: 0.57100

Collected Steps per Second: 22,890.98853
Overall Steps per Second: 10,820.76558

Timestep Collection Time: 2.18531
Timestep Consumption Time: 2.43765
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.62296

Cumulative Model Updates: 106,150
Cumulative Timesteps: 885,276,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 885276742...
Checkpoint 885276742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093.86426
Policy Entropy: 3.12552
Value Function Loss: 0.00508

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12564
Policy Update Magnitude: 0.56798
Value Function Update Magnitude: 0.56739

Collected Steps per Second: 22,817.09333
Overall Steps per Second: 10,694.69308

Timestep Collection Time: 2.19151
Timestep Consumption Time: 2.48408
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.67559

Cumulative Model Updates: 106,156
Cumulative Timesteps: 885,326,746

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.45083
Policy Entropy: 3.13027
Value Function Loss: 0.00512

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 0.57073
Value Function Update Magnitude: 0.58171

Collected Steps per Second: 22,889.09633
Overall Steps per Second: 10,847.71722

Timestep Collection Time: 2.18532
Timestep Consumption Time: 2.42579
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.61111

Cumulative Model Updates: 106,162
Cumulative Timesteps: 885,376,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 885376766...
Checkpoint 885376766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.88589
Policy Entropy: 3.13085
Value Function Loss: 0.00544

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.57921
Value Function Update Magnitude: 0.58447

Collected Steps per Second: 22,596.17609
Overall Steps per Second: 10,712.20045

Timestep Collection Time: 2.21294
Timestep Consumption Time: 2.45501
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.66795

Cumulative Model Updates: 106,168
Cumulative Timesteps: 885,426,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.15883
Policy Entropy: 3.12104
Value Function Loss: 0.00528

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.58155
Value Function Update Magnitude: 0.58591

Collected Steps per Second: 22,443.87394
Overall Steps per Second: 10,604.98674

Timestep Collection Time: 2.22858
Timestep Consumption Time: 2.48788
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.71646

Cumulative Model Updates: 106,174
Cumulative Timesteps: 885,476,788

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 885476788...
Checkpoint 885476788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.10635
Policy Entropy: 3.10920
Value Function Loss: 0.00528

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.57498
Value Function Update Magnitude: 0.58892

Collected Steps per Second: 23,024.11944
Overall Steps per Second: 10,882.36584

Timestep Collection Time: 2.17242
Timestep Consumption Time: 2.42383
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.59624

Cumulative Model Updates: 106,180
Cumulative Timesteps: 885,526,806

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 952.05413
Policy Entropy: 3.10087
Value Function Loss: 0.00517

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11309
Policy Update Magnitude: 0.57439
Value Function Update Magnitude: 0.59821

Collected Steps per Second: 22,821.81571
Overall Steps per Second: 10,691.45752

Timestep Collection Time: 2.19150
Timestep Consumption Time: 2.48644
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.67794

Cumulative Model Updates: 106,186
Cumulative Timesteps: 885,576,820

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 885576820...
Checkpoint 885576820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,271.06218
Policy Entropy: 3.11468
Value Function Loss: 0.00492

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.56908
Value Function Update Magnitude: 0.58938

Collected Steps per Second: 22,638.80614
Overall Steps per Second: 10,679.49772

Timestep Collection Time: 2.20975
Timestep Consumption Time: 2.47456
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.68430

Cumulative Model Updates: 106,192
Cumulative Timesteps: 885,626,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.20977
Policy Entropy: 3.11338
Value Function Loss: 0.00472

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.57039
Value Function Update Magnitude: 0.58305

Collected Steps per Second: 23,347.06269
Overall Steps per Second: 10,800.77822

Timestep Collection Time: 2.14237
Timestep Consumption Time: 2.48859
PPO Batch Consumption Time: 0.29488
Total Iteration Time: 4.63096

Cumulative Model Updates: 106,198
Cumulative Timesteps: 885,676,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 885676864...
Checkpoint 885676864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.90040
Policy Entropy: 3.12936
Value Function Loss: 0.00462

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09142
Policy Update Magnitude: 0.57297
Value Function Update Magnitude: 0.58659

Collected Steps per Second: 22,601.32245
Overall Steps per Second: 10,626.28528

Timestep Collection Time: 2.21253
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.70588

Cumulative Model Updates: 106,204
Cumulative Timesteps: 885,726,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 966.17843
Policy Entropy: 3.12096
Value Function Loss: 0.00475

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.57246
Value Function Update Magnitude: 0.59500

Collected Steps per Second: 22,896.12915
Overall Steps per Second: 10,837.11596

Timestep Collection Time: 2.18439
Timestep Consumption Time: 2.43068
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.61507

Cumulative Model Updates: 106,210
Cumulative Timesteps: 885,776,884

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 885776884...
Checkpoint 885776884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.00126
Policy Entropy: 3.12295
Value Function Loss: 0.00471

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.57204
Value Function Update Magnitude: 0.60232

Collected Steps per Second: 22,574.44871
Overall Steps per Second: 10,647.68574

Timestep Collection Time: 2.21516
Timestep Consumption Time: 2.48126
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.69642

Cumulative Model Updates: 106,216
Cumulative Timesteps: 885,826,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.25410
Policy Entropy: 3.11265
Value Function Loss: 0.00483

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.57800
Value Function Update Magnitude: 0.58076

Collected Steps per Second: 23,072.35357
Overall Steps per Second: 10,849.75356

Timestep Collection Time: 2.16805
Timestep Consumption Time: 2.44238
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.61043

Cumulative Model Updates: 106,222
Cumulative Timesteps: 885,876,912

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 885876912...
Checkpoint 885876912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 895.01563
Policy Entropy: 3.12430
Value Function Loss: 0.00472

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10471
Policy Update Magnitude: 0.57875
Value Function Update Magnitude: 0.57673

Collected Steps per Second: 22,715.70150
Overall Steps per Second: 10,708.96767

Timestep Collection Time: 2.20138
Timestep Consumption Time: 2.46816
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.66954

Cumulative Model Updates: 106,228
Cumulative Timesteps: 885,926,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.99535
Policy Entropy: 3.12326
Value Function Loss: 0.00491

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11467
Policy Update Magnitude: 0.57309
Value Function Update Magnitude: 0.57835

Collected Steps per Second: 23,156.15171
Overall Steps per Second: 10,914.80051

Timestep Collection Time: 2.15934
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.58112

Cumulative Model Updates: 106,234
Cumulative Timesteps: 885,976,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 885976920...
Checkpoint 885976920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.92322
Policy Entropy: 3.11827
Value Function Loss: 0.00498

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.57880
Value Function Update Magnitude: 0.56240

Collected Steps per Second: 22,639.64559
Overall Steps per Second: 10,613.72831

Timestep Collection Time: 2.20887
Timestep Consumption Time: 2.50277
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.71163

Cumulative Model Updates: 106,240
Cumulative Timesteps: 886,026,928

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.98209
Policy Entropy: 3.12801
Value Function Loss: 0.00507

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11796
Policy Update Magnitude: 0.58283
Value Function Update Magnitude: 0.57441

Collected Steps per Second: 22,877.42758
Overall Steps per Second: 10,836.52593

Timestep Collection Time: 2.18591
Timestep Consumption Time: 2.42885
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.61476

Cumulative Model Updates: 106,246
Cumulative Timesteps: 886,076,936

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 886076936...
Checkpoint 886076936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.35321
Policy Entropy: 3.12030
Value Function Loss: 0.00500

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.58302
Value Function Update Magnitude: 0.58886

Collected Steps per Second: 22,953.45634
Overall Steps per Second: 10,720.79694

Timestep Collection Time: 2.17998
Timestep Consumption Time: 2.48740
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.66738

Cumulative Model Updates: 106,252
Cumulative Timesteps: 886,126,974

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770.30776
Policy Entropy: 3.13323
Value Function Loss: 0.00500

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.57361
Value Function Update Magnitude: 0.58830

Collected Steps per Second: 23,045.14433
Overall Steps per Second: 10,885.13263

Timestep Collection Time: 2.17061
Timestep Consumption Time: 2.42483
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.59544

Cumulative Model Updates: 106,258
Cumulative Timesteps: 886,176,996

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 886176996...
Checkpoint 886176996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.58523
Policy Entropy: 3.13437
Value Function Loss: 0.00506

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.57464
Value Function Update Magnitude: 0.58719

Collected Steps per Second: 22,462.47119
Overall Steps per Second: 10,640.71258

Timestep Collection Time: 2.22745
Timestep Consumption Time: 2.47468
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.70213

Cumulative Model Updates: 106,264
Cumulative Timesteps: 886,227,030

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.49818
Policy Entropy: 3.12898
Value Function Loss: 0.00494

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09230
Policy Update Magnitude: 0.58061
Value Function Update Magnitude: 0.60194

Collected Steps per Second: 22,924.54272
Overall Steps per Second: 10,836.95645

Timestep Collection Time: 2.18212
Timestep Consumption Time: 2.43394
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.61606

Cumulative Model Updates: 106,270
Cumulative Timesteps: 886,277,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 886277054...
Checkpoint 886277054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.38346
Policy Entropy: 3.11981
Value Function Loss: 0.00495

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.58189
Value Function Update Magnitude: 0.60164

Collected Steps per Second: 22,716.53916
Overall Steps per Second: 10,744.13168

Timestep Collection Time: 2.20104
Timestep Consumption Time: 2.45266
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.65370

Cumulative Model Updates: 106,276
Cumulative Timesteps: 886,327,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,830.34397
Policy Entropy: 3.11923
Value Function Loss: 0.00487

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.57699
Value Function Update Magnitude: 0.59147

Collected Steps per Second: 23,058.43867
Overall Steps per Second: 10,856.31661

Timestep Collection Time: 2.16927
Timestep Consumption Time: 2.43818
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.60746

Cumulative Model Updates: 106,282
Cumulative Timesteps: 886,377,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 886377074...
Checkpoint 886377074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.03341
Policy Entropy: 3.12961
Value Function Loss: 0.00475

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.56909
Value Function Update Magnitude: 0.56710

Collected Steps per Second: 22,475.07594
Overall Steps per Second: 10,682.53339

Timestep Collection Time: 2.22602
Timestep Consumption Time: 2.45732
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.68335

Cumulative Model Updates: 106,288
Cumulative Timesteps: 886,427,104

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728.25746
Policy Entropy: 3.13341
Value Function Loss: 0.00484

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.57124
Value Function Update Magnitude: 0.56486

Collected Steps per Second: 23,092.44850
Overall Steps per Second: 10,860.28228

Timestep Collection Time: 2.16642
Timestep Consumption Time: 2.44009
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.60651

Cumulative Model Updates: 106,294
Cumulative Timesteps: 886,477,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 886477132...
Checkpoint 886477132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,411.69273
Policy Entropy: 3.12971
Value Function Loss: 0.00479

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 0.57640
Value Function Update Magnitude: 0.57483

Collected Steps per Second: 22,575.85730
Overall Steps per Second: 10,702.90856

Timestep Collection Time: 2.21582
Timestep Consumption Time: 2.45805
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.67387

Cumulative Model Updates: 106,300
Cumulative Timesteps: 886,527,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.75373
Policy Entropy: 3.13171
Value Function Loss: 0.00494

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10243
Policy Update Magnitude: 0.57611
Value Function Update Magnitude: 0.56801

Collected Steps per Second: 22,663.61518
Overall Steps per Second: 10,771.48505

Timestep Collection Time: 2.20644
Timestep Consumption Time: 2.43600
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.64244

Cumulative Model Updates: 106,306
Cumulative Timesteps: 886,577,162

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 886577162...
Checkpoint 886577162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.53355
Policy Entropy: 3.12367
Value Function Loss: 0.00473

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09223
Policy Update Magnitude: 0.57596
Value Function Update Magnitude: 0.58581

Collected Steps per Second: 22,567.85223
Overall Steps per Second: 10,798.38985

Timestep Collection Time: 2.21793
Timestep Consumption Time: 2.41739
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.63532

Cumulative Model Updates: 106,312
Cumulative Timesteps: 886,627,216

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.03653
Policy Entropy: 3.12732
Value Function Loss: 0.00491

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09215
Policy Update Magnitude: 0.57671
Value Function Update Magnitude: 0.59135

Collected Steps per Second: 22,761.52365
Overall Steps per Second: 10,792.16941

Timestep Collection Time: 2.19669
Timestep Consumption Time: 2.43630
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.63299

Cumulative Model Updates: 106,318
Cumulative Timesteps: 886,677,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 886677216...
Checkpoint 886677216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.84590
Policy Entropy: 3.12278
Value Function Loss: 0.00490

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.08551
Policy Update Magnitude: 0.58733
Value Function Update Magnitude: 0.59732

Collected Steps per Second: 22,765.91482
Overall Steps per Second: 10,720.87993

Timestep Collection Time: 2.19697
Timestep Consumption Time: 2.46832
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.66529

Cumulative Model Updates: 106,324
Cumulative Timesteps: 886,727,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.01486
Policy Entropy: 3.13197
Value Function Loss: 0.00483

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.58968
Value Function Update Magnitude: 0.61016

Collected Steps per Second: 23,109.00604
Overall Steps per Second: 10,871.31380

Timestep Collection Time: 2.16400
Timestep Consumption Time: 2.43599
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.60000

Cumulative Model Updates: 106,330
Cumulative Timesteps: 886,777,240

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 886777240...
Checkpoint 886777240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.01493
Policy Entropy: 3.14239
Value Function Loss: 0.00486

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09951
Policy Update Magnitude: 0.57982
Value Function Update Magnitude: 0.60722

Collected Steps per Second: 22,457.10089
Overall Steps per Second: 10,675.96574

Timestep Collection Time: 2.22682
Timestep Consumption Time: 2.45734
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.68417

Cumulative Model Updates: 106,336
Cumulative Timesteps: 886,827,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 766.37943
Policy Entropy: 3.13121
Value Function Loss: 0.00469

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10490
Policy Update Magnitude: 0.57750
Value Function Update Magnitude: 0.60087

Collected Steps per Second: 22,937.78725
Overall Steps per Second: 10,882.06026

Timestep Collection Time: 2.18112
Timestep Consumption Time: 2.41636
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.59747

Cumulative Model Updates: 106,342
Cumulative Timesteps: 886,877,278

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 886877278...
Checkpoint 886877278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,062.59404
Policy Entropy: 3.13337
Value Function Loss: 0.00493

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.58107
Value Function Update Magnitude: 0.59917

Collected Steps per Second: 22,692.81511
Overall Steps per Second: 10,799.33210

Timestep Collection Time: 2.20475
Timestep Consumption Time: 2.42813
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.63288

Cumulative Model Updates: 106,348
Cumulative Timesteps: 886,927,310

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,303.05197
Policy Entropy: 3.12752
Value Function Loss: 0.00461

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11323
Policy Update Magnitude: 0.57274
Value Function Update Magnitude: 0.59273

Collected Steps per Second: 22,594.29521
Overall Steps per Second: 10,778.96856

Timestep Collection Time: 2.21304
Timestep Consumption Time: 2.42581
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.63885

Cumulative Model Updates: 106,354
Cumulative Timesteps: 886,977,312

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 886977312...
Checkpoint 886977312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.64973
Policy Entropy: 3.13355
Value Function Loss: 0.00485

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.57617

Collected Steps per Second: 21,879.38245
Overall Steps per Second: 10,644.20867

Timestep Collection Time: 2.28654
Timestep Consumption Time: 2.41348
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.70002

Cumulative Model Updates: 106,360
Cumulative Timesteps: 887,027,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994.87723
Policy Entropy: 3.12806
Value Function Loss: 0.00474

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.56857
Value Function Update Magnitude: 0.58197

Collected Steps per Second: 22,404.59807
Overall Steps per Second: 10,865.54910

Timestep Collection Time: 2.23293
Timestep Consumption Time: 2.37134
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.60428

Cumulative Model Updates: 106,366
Cumulative Timesteps: 887,077,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 887077368...
Checkpoint 887077368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 970.05259
Policy Entropy: 3.12805
Value Function Loss: 0.00476

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09435
Policy Update Magnitude: 0.57507
Value Function Update Magnitude: 0.57740

Collected Steps per Second: 21,912.62770
Overall Steps per Second: 10,707.64522

Timestep Collection Time: 2.28316
Timestep Consumption Time: 2.38920
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.67236

Cumulative Model Updates: 106,372
Cumulative Timesteps: 887,127,398

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.15990
Policy Entropy: 3.12350
Value Function Loss: 0.00482

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.57582
Value Function Update Magnitude: 0.59776

Collected Steps per Second: 22,209.92877
Overall Steps per Second: 10,776.23221

Timestep Collection Time: 2.25161
Timestep Consumption Time: 2.38898
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.64058

Cumulative Model Updates: 106,378
Cumulative Timesteps: 887,177,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 887177406...
Checkpoint 887177406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.63196
Policy Entropy: 3.12474
Value Function Loss: 0.00497

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.58363
Value Function Update Magnitude: 0.63207

Collected Steps per Second: 21,992.59915
Overall Steps per Second: 10,739.36026

Timestep Collection Time: 2.27376
Timestep Consumption Time: 2.38256
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.65633

Cumulative Model Updates: 106,384
Cumulative Timesteps: 887,227,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.91224
Policy Entropy: 3.12525
Value Function Loss: 0.00485

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.58622
Value Function Update Magnitude: 0.62518

Collected Steps per Second: 22,055.19462
Overall Steps per Second: 10,633.33163

Timestep Collection Time: 2.26713
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.70238

Cumulative Model Updates: 106,390
Cumulative Timesteps: 887,277,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 887277414...
Checkpoint 887277414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.53194
Policy Entropy: 3.13363
Value Function Loss: 0.00482

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11636
Policy Update Magnitude: 0.57405
Value Function Update Magnitude: 0.61324

Collected Steps per Second: 23,246.35615
Overall Steps per Second: 10,909.01380

Timestep Collection Time: 2.15105
Timestep Consumption Time: 2.43269
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.58373

Cumulative Model Updates: 106,396
Cumulative Timesteps: 887,327,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.72164
Policy Entropy: 3.14967
Value Function Loss: 0.00497

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10518
Policy Update Magnitude: 0.57229
Value Function Update Magnitude: 0.59860

Collected Steps per Second: 22,967.03534
Overall Steps per Second: 10,801.48869

Timestep Collection Time: 2.17782
Timestep Consumption Time: 2.45284
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.63066

Cumulative Model Updates: 106,402
Cumulative Timesteps: 887,377,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 887377436...
Checkpoint 887377436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 572.89124
Policy Entropy: 3.15969
Value Function Loss: 0.00526

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09914
Policy Update Magnitude: 0.58879
Value Function Update Magnitude: 0.59586

Collected Steps per Second: 23,021.35966
Overall Steps per Second: 10,735.26290

Timestep Collection Time: 2.17242
Timestep Consumption Time: 2.48625
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.65867

Cumulative Model Updates: 106,408
Cumulative Timesteps: 887,427,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.32616
Policy Entropy: 3.16249
Value Function Loss: 0.00529

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09403
Policy Update Magnitude: 0.59295
Value Function Update Magnitude: 0.60097

Collected Steps per Second: 22,684.90919
Overall Steps per Second: 10,638.11627

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.49807
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.70403

Cumulative Model Updates: 106,414
Cumulative Timesteps: 887,477,490

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 887477490...
Checkpoint 887477490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.10413
Policy Entropy: 3.15410
Value Function Loss: 0.00503

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.58205
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 22,956.41466
Overall Steps per Second: 10,818.23552

Timestep Collection Time: 2.17900
Timestep Consumption Time: 2.44486
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.62386

Cumulative Model Updates: 106,420
Cumulative Timesteps: 887,527,512

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.14857
Policy Entropy: 3.14847
Value Function Loss: 0.00489

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10033
Policy Update Magnitude: 0.57787
Value Function Update Magnitude: 0.59702

Collected Steps per Second: 22,705.70008
Overall Steps per Second: 10,563.11287

Timestep Collection Time: 2.20218
Timestep Consumption Time: 2.53146
PPO Batch Consumption Time: 0.29661
Total Iteration Time: 4.73364

Cumulative Model Updates: 106,426
Cumulative Timesteps: 887,577,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 887577514...
Checkpoint 887577514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.89531
Policy Entropy: 3.15029
Value Function Loss: 0.00471

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09465
Policy Update Magnitude: 0.57080
Value Function Update Magnitude: 0.60458

Collected Steps per Second: 22,754.69078
Overall Steps per Second: 10,620.72319

Timestep Collection Time: 2.19779
Timestep Consumption Time: 2.51093
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.70872

Cumulative Model Updates: 106,432
Cumulative Timesteps: 887,627,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,076.10542
Policy Entropy: 3.16899
Value Function Loss: 0.00444

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.09007
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.58340

Collected Steps per Second: 23,090.19997
Overall Steps per Second: 10,852.77398

Timestep Collection Time: 2.16681
Timestep Consumption Time: 2.44326
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.61007

Cumulative Model Updates: 106,438
Cumulative Timesteps: 887,677,556

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 887677556...
Checkpoint 887677556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.04561
Policy Entropy: 3.16120
Value Function Loss: 0.00435

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08397
Policy Update Magnitude: 0.55151
Value Function Update Magnitude: 0.55582

Collected Steps per Second: 22,764.63559
Overall Steps per Second: 10,742.77110

Timestep Collection Time: 2.19700
Timestep Consumption Time: 2.45859
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.65560

Cumulative Model Updates: 106,444
Cumulative Timesteps: 887,727,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.38022
Policy Entropy: 3.15553
Value Function Loss: 0.00447

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08691
Policy Update Magnitude: 0.54999
Value Function Update Magnitude: 0.55902

Collected Steps per Second: 23,079.84181
Overall Steps per Second: 10,817.76486

Timestep Collection Time: 2.16769
Timestep Consumption Time: 2.45711
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.62480

Cumulative Model Updates: 106,450
Cumulative Timesteps: 887,777,600

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 887777600...
Checkpoint 887777600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917.31446
Policy Entropy: 3.14177
Value Function Loss: 0.00440

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.55341
Value Function Update Magnitude: 0.56661

Collected Steps per Second: 22,685.91632
Overall Steps per Second: 10,697.90103

Timestep Collection Time: 2.20445
Timestep Consumption Time: 2.47030
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.67475

Cumulative Model Updates: 106,456
Cumulative Timesteps: 887,827,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.68624
Policy Entropy: 3.14167
Value Function Loss: 0.00455

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09219
Policy Update Magnitude: 0.55856
Value Function Update Magnitude: 0.57579

Collected Steps per Second: 22,962.17469
Overall Steps per Second: 10,802.77043

Timestep Collection Time: 2.17880
Timestep Consumption Time: 2.45242
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.63122

Cumulative Model Updates: 106,462
Cumulative Timesteps: 887,877,640

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 887877640...
Checkpoint 887877640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.09407
Policy Entropy: 3.12784
Value Function Loss: 0.00481

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08656
Policy Update Magnitude: 0.57154
Value Function Update Magnitude: 0.58960

Collected Steps per Second: 22,838.72282
Overall Steps per Second: 10,742.12069

Timestep Collection Time: 2.18979
Timestep Consumption Time: 2.46590
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.65569

Cumulative Model Updates: 106,468
Cumulative Timesteps: 887,927,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.68212
Policy Entropy: 3.13753
Value Function Loss: 0.00476

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.57444
Value Function Update Magnitude: 0.60187

Collected Steps per Second: 22,825.18181
Overall Steps per Second: 10,677.08188

Timestep Collection Time: 2.19074
Timestep Consumption Time: 2.49256
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.68330

Cumulative Model Updates: 106,474
Cumulative Timesteps: 887,977,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 887977656...
Checkpoint 887977656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,767.75414
Policy Entropy: 3.12936
Value Function Loss: 0.00492

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.57416
Value Function Update Magnitude: 0.63417

Collected Steps per Second: 22,864.42270
Overall Steps per Second: 10,813.74525

Timestep Collection Time: 2.18812
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.62652

Cumulative Model Updates: 106,480
Cumulative Timesteps: 888,027,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.72676
Policy Entropy: 3.14104
Value Function Loss: 0.00476

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09836
Policy Update Magnitude: 0.57761
Value Function Update Magnitude: 0.64744

Collected Steps per Second: 22,773.31519
Overall Steps per Second: 10,650.99908

Timestep Collection Time: 2.19555
Timestep Consumption Time: 2.49884
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.69440

Cumulative Model Updates: 106,486
Cumulative Timesteps: 888,077,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 888077686...
Checkpoint 888077686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,224.69096
Policy Entropy: 3.12652
Value Function Loss: 0.00494

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.57524
Value Function Update Magnitude: 0.63929

Collected Steps per Second: 22,726.38878
Overall Steps per Second: 10,670.85178

Timestep Collection Time: 2.20088
Timestep Consumption Time: 2.48647
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.68735

Cumulative Model Updates: 106,492
Cumulative Timesteps: 888,127,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.42072
Policy Entropy: 3.12868
Value Function Loss: 0.00473

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.10086
Policy Update Magnitude: 0.57136
Value Function Update Magnitude: 0.61997

Collected Steps per Second: 22,888.48612
Overall Steps per Second: 10,710.81942

Timestep Collection Time: 2.18477
Timestep Consumption Time: 2.48397
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.66874

Cumulative Model Updates: 106,498
Cumulative Timesteps: 888,177,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 888177710...
Checkpoint 888177710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.64562
Policy Entropy: 3.11843
Value Function Loss: 0.00480

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10026
Policy Update Magnitude: 0.57504
Value Function Update Magnitude: 0.61767

Collected Steps per Second: 22,565.14957
Overall Steps per Second: 10,669.10799

Timestep Collection Time: 2.21643
Timestep Consumption Time: 2.47131
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.68774

Cumulative Model Updates: 106,504
Cumulative Timesteps: 888,227,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,530.76002
Policy Entropy: 3.11675
Value Function Loss: 0.00479

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.57556
Value Function Update Magnitude: 0.61803

Collected Steps per Second: 23,084.61594
Overall Steps per Second: 10,825.18950

Timestep Collection Time: 2.16724
Timestep Consumption Time: 2.45438
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.62163

Cumulative Model Updates: 106,510
Cumulative Timesteps: 888,277,754

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 888277754...
Checkpoint 888277754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.25423
Policy Entropy: 3.11962
Value Function Loss: 0.00483

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.56947
Value Function Update Magnitude: 0.60916

Collected Steps per Second: 22,503.10440
Overall Steps per Second: 10,685.53831

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.45839
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.68128

Cumulative Model Updates: 106,516
Cumulative Timesteps: 888,327,776

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.78937
Policy Entropy: 3.12114
Value Function Loss: 0.00503

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10268
Policy Update Magnitude: 0.56834
Value Function Update Magnitude: 0.60125

Collected Steps per Second: 22,822.47285
Overall Steps per Second: 10,631.20053

Timestep Collection Time: 2.19117
Timestep Consumption Time: 2.51272
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.70389

Cumulative Model Updates: 106,522
Cumulative Timesteps: 888,377,784

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 888377784...
Checkpoint 888377784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.03792
Policy Entropy: 3.13177
Value Function Loss: 0.00468

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.57143
Value Function Update Magnitude: 0.59402

Collected Steps per Second: 23,075.79951
Overall Steps per Second: 10,870.15648

Timestep Collection Time: 2.16755
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.60141

Cumulative Model Updates: 106,528
Cumulative Timesteps: 888,427,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,756.53535
Policy Entropy: 3.14353
Value Function Loss: 0.00427

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.55168
Value Function Update Magnitude: 0.57672

Collected Steps per Second: 22,303.41968
Overall Steps per Second: 10,696.13659

Timestep Collection Time: 2.24306
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.67720

Cumulative Model Updates: 106,534
Cumulative Timesteps: 888,477,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 888477830...
Checkpoint 888477830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.62447
Policy Entropy: 3.16631
Value Function Loss: 0.00388

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09234
Policy Update Magnitude: 0.53054
Value Function Update Magnitude: 0.53846

Collected Steps per Second: 23,312.63362
Overall Steps per Second: 10,891.61021

Timestep Collection Time: 2.14588
Timestep Consumption Time: 2.44720
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.59308

Cumulative Model Updates: 106,540
Cumulative Timesteps: 888,527,856

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.76996
Policy Entropy: 3.14230
Value Function Loss: 0.00420

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.53961
Value Function Update Magnitude: 0.53988

Collected Steps per Second: 23,059.89067
Overall Steps per Second: 10,698.74874

Timestep Collection Time: 2.16939
Timestep Consumption Time: 2.50648
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.67587

Cumulative Model Updates: 106,546
Cumulative Timesteps: 888,577,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 888577882...
Checkpoint 888577882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.72161
Policy Entropy: 3.11488
Value Function Loss: 0.00465

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.56349
Value Function Update Magnitude: 0.58552

Collected Steps per Second: 23,113.77024
Overall Steps per Second: 10,840.50650

Timestep Collection Time: 2.16339
Timestep Consumption Time: 2.44931
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.61270

Cumulative Model Updates: 106,552
Cumulative Timesteps: 888,627,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.01157
Policy Entropy: 3.08898
Value Function Loss: 0.00471

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.57325
Value Function Update Magnitude: 0.62582

Collected Steps per Second: 22,511.97814
Overall Steps per Second: 10,556.81824

Timestep Collection Time: 2.22184
Timestep Consumption Time: 2.51614
PPO Batch Consumption Time: 0.29475
Total Iteration Time: 4.73798

Cumulative Model Updates: 106,558
Cumulative Timesteps: 888,677,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 888677904...
Checkpoint 888677904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 705.02071
Policy Entropy: 3.10163
Value Function Loss: 0.00477

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.56754
Value Function Update Magnitude: 0.62684

Collected Steps per Second: 22,884.26665
Overall Steps per Second: 10,598.14207

Timestep Collection Time: 2.18596
Timestep Consumption Time: 2.53412
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.72007

Cumulative Model Updates: 106,564
Cumulative Timesteps: 888,727,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.98630
Policy Entropy: 3.11336
Value Function Loss: 0.00468

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.56612
Value Function Update Magnitude: 0.61418

Collected Steps per Second: 22,947.14133
Overall Steps per Second: 10,803.07571

Timestep Collection Time: 2.17962
Timestep Consumption Time: 2.45017
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.62979

Cumulative Model Updates: 106,570
Cumulative Timesteps: 888,777,944

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 888777944...
Checkpoint 888777944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,044.75841
Policy Entropy: 3.11962
Value Function Loss: 0.00458

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.55477
Value Function Update Magnitude: 0.59645

Collected Steps per Second: 21,957.81635
Overall Steps per Second: 10,753.45384

Timestep Collection Time: 2.27855
Timestep Consumption Time: 2.37409
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.65264

Cumulative Model Updates: 106,576
Cumulative Timesteps: 888,827,976

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.18356
Policy Entropy: 3.10131
Value Function Loss: 0.00464

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.55625
Value Function Update Magnitude: 0.56615

Collected Steps per Second: 23,031.33659
Overall Steps per Second: 10,794.83762

Timestep Collection Time: 2.17208
Timestep Consumption Time: 2.46217
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.63425

Cumulative Model Updates: 106,582
Cumulative Timesteps: 888,878,002

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 888878002...
Checkpoint 888878002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.47116
Policy Entropy: 3.10767
Value Function Loss: 0.00447

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10189
Policy Update Magnitude: 0.55821
Value Function Update Magnitude: 0.55352

Collected Steps per Second: 22,840.32620
Overall Steps per Second: 10,759.25468

Timestep Collection Time: 2.19007
Timestep Consumption Time: 2.45913
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.64921

Cumulative Model Updates: 106,588
Cumulative Timesteps: 888,928,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.21765
Policy Entropy: 3.10520
Value Function Loss: 0.00466

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.56100
Value Function Update Magnitude: 0.54785

Collected Steps per Second: 22,031.68540
Overall Steps per Second: 10,655.36888

Timestep Collection Time: 2.27028
Timestep Consumption Time: 2.42388
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.69416

Cumulative Model Updates: 106,594
Cumulative Timesteps: 888,978,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 888978042...
Checkpoint 888978042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.19572
Policy Entropy: 3.11186
Value Function Loss: 0.00470

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10894
Policy Update Magnitude: 0.55664
Value Function Update Magnitude: 0.55029

Collected Steps per Second: 22,207.49281
Overall Steps per Second: 10,820.52449

Timestep Collection Time: 2.25203
Timestep Consumption Time: 2.36992
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.62196

Cumulative Model Updates: 106,600
Cumulative Timesteps: 889,028,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.79382
Policy Entropy: 3.11169
Value Function Loss: 0.00473

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.56253
Value Function Update Magnitude: 0.57841

Collected Steps per Second: 23,092.51360
Overall Steps per Second: 10,725.09878

Timestep Collection Time: 2.16650
Timestep Consumption Time: 2.49826
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.66476

Cumulative Model Updates: 106,606
Cumulative Timesteps: 889,078,084

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 889078084...
Checkpoint 889078084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 784.70546
Policy Entropy: 3.11272
Value Function Loss: 0.00476

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.57648
Value Function Update Magnitude: 0.58249

Collected Steps per Second: 23,183.89179
Overall Steps per Second: 10,881.15921

Timestep Collection Time: 2.15779
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.59749

Cumulative Model Updates: 106,612
Cumulative Timesteps: 889,128,110

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.14529
Policy Entropy: 3.11381
Value Function Loss: 0.00495

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11793
Policy Update Magnitude: 0.57490
Value Function Update Magnitude: 0.56969

Collected Steps per Second: 22,888.62043
Overall Steps per Second: 10,804.15762

Timestep Collection Time: 2.18467
Timestep Consumption Time: 2.44355
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.62822

Cumulative Model Updates: 106,618
Cumulative Timesteps: 889,178,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 889178114...
Checkpoint 889178114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.54673
Policy Entropy: 3.11895
Value Function Loss: 0.00457

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11549
Policy Update Magnitude: 0.56409
Value Function Update Magnitude: 0.56900

Collected Steps per Second: 22,208.74004
Overall Steps per Second: 10,733.87688

Timestep Collection Time: 2.25137
Timestep Consumption Time: 2.40678
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.65815

Cumulative Model Updates: 106,624
Cumulative Timesteps: 889,228,114

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691.75725
Policy Entropy: 3.10365
Value Function Loss: 0.00477

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11316
Policy Update Magnitude: 0.56571
Value Function Update Magnitude: 0.54819

Collected Steps per Second: 22,946.72364
Overall Steps per Second: 10,721.34913

Timestep Collection Time: 2.17940
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.66452

Cumulative Model Updates: 106,630
Cumulative Timesteps: 889,278,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 889278124...
Checkpoint 889278124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,876.34284
Policy Entropy: 3.10444
Value Function Loss: 0.00490

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.57556
Value Function Update Magnitude: 0.56282

Collected Steps per Second: 22,975.32266
Overall Steps per Second: 10,828.70295

Timestep Collection Time: 2.17729
Timestep Consumption Time: 2.44228
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.61957

Cumulative Model Updates: 106,636
Cumulative Timesteps: 889,328,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.34292
Policy Entropy: 3.09839
Value Function Loss: 0.00508

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.58217
Value Function Update Magnitude: 0.59401

Collected Steps per Second: 22,882.90791
Overall Steps per Second: 10,823.09595

Timestep Collection Time: 2.18617
Timestep Consumption Time: 2.43598
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.62215

Cumulative Model Updates: 106,642
Cumulative Timesteps: 889,378,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 889378174...
Checkpoint 889378174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 726.10258
Policy Entropy: 3.08333
Value Function Loss: 0.00518

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.58896
Value Function Update Magnitude: 0.59517

Collected Steps per Second: 22,755.79780
Overall Steps per Second: 10,757.00862

Timestep Collection Time: 2.19838
Timestep Consumption Time: 2.45216
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.65055

Cumulative Model Updates: 106,648
Cumulative Timesteps: 889,428,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 995.51879
Policy Entropy: 3.08426
Value Function Loss: 0.00505

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.12129
Policy Update Magnitude: 0.58533
Value Function Update Magnitude: 0.59316

Collected Steps per Second: 22,426.71274
Overall Steps per Second: 10,855.88866

Timestep Collection Time: 2.23002
Timestep Consumption Time: 2.37688
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.60690

Cumulative Model Updates: 106,654
Cumulative Timesteps: 889,478,212

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 889478212...
Checkpoint 889478212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.00220
Policy Entropy: 3.08299
Value Function Loss: 0.00506

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10468
Policy Update Magnitude: 0.58156
Value Function Update Magnitude: 0.58802

Collected Steps per Second: 22,130.84057
Overall Steps per Second: 10,681.11380

Timestep Collection Time: 2.26056
Timestep Consumption Time: 2.42323
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.68378

Cumulative Model Updates: 106,660
Cumulative Timesteps: 889,528,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,431.93513
Policy Entropy: 3.09577
Value Function Loss: 0.00483

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.58160
Value Function Update Magnitude: 0.59599

Collected Steps per Second: 22,199.14978
Overall Steps per Second: 10,783.85892

Timestep Collection Time: 2.25252
Timestep Consumption Time: 2.38441
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.63693

Cumulative Model Updates: 106,666
Cumulative Timesteps: 889,578,244

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 889578244...
Checkpoint 889578244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.92089
Policy Entropy: 3.10716
Value Function Loss: 0.00511

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09097
Policy Update Magnitude: 0.59236
Value Function Update Magnitude: 0.61446

Collected Steps per Second: 22,671.57565
Overall Steps per Second: 10,784.82603

Timestep Collection Time: 2.20638
Timestep Consumption Time: 2.43181
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.63818

Cumulative Model Updates: 106,672
Cumulative Timesteps: 889,628,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.99579
Policy Entropy: 3.11738
Value Function Loss: 0.00494

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09513
Policy Update Magnitude: 0.59277
Value Function Update Magnitude: 0.63711

Collected Steps per Second: 22,218.06105
Overall Steps per Second: 10,799.84320

Timestep Collection Time: 2.25150
Timestep Consumption Time: 2.38042
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.63192

Cumulative Model Updates: 106,678
Cumulative Timesteps: 889,678,290

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 889678290...
Checkpoint 889678290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.77782
Policy Entropy: 3.11100
Value Function Loss: 0.00495

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.58746
Value Function Update Magnitude: 0.63690

Collected Steps per Second: 22,880.48147
Overall Steps per Second: 10,724.29278

Timestep Collection Time: 2.18527
Timestep Consumption Time: 2.47704
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.66231

Cumulative Model Updates: 106,684
Cumulative Timesteps: 889,728,290

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.14020
Policy Entropy: 3.11581
Value Function Loss: 0.00454

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.57558
Value Function Update Magnitude: 0.62837

Collected Steps per Second: 22,961.75505
Overall Steps per Second: 10,795.96106

Timestep Collection Time: 2.17762
Timestep Consumption Time: 2.45393
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.63155

Cumulative Model Updates: 106,690
Cumulative Timesteps: 889,778,292

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 889778292...
Checkpoint 889778292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.25376
Policy Entropy: 3.11724
Value Function Loss: 0.00473

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10956
Policy Update Magnitude: 0.56816
Value Function Update Magnitude: 0.60856

Collected Steps per Second: 22,835.65680
Overall Steps per Second: 10,740.79316

Timestep Collection Time: 2.18965
Timestep Consumption Time: 2.46569
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.65534

Cumulative Model Updates: 106,696
Cumulative Timesteps: 889,828,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 726.63129
Policy Entropy: 3.12070
Value Function Loss: 0.00467

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.56597
Value Function Update Magnitude: 0.60690

Collected Steps per Second: 22,955.85179
Overall Steps per Second: 10,830.39595

Timestep Collection Time: 2.17931
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.61922

Cumulative Model Updates: 106,702
Cumulative Timesteps: 889,878,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 889878322...
Checkpoint 889878322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.04602
Policy Entropy: 3.11670
Value Function Loss: 0.00482

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.56961
Value Function Update Magnitude: 0.60787

Collected Steps per Second: 22,470.65155
Overall Steps per Second: 10,720.09550

Timestep Collection Time: 2.22655
Timestep Consumption Time: 2.44057
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.66712

Cumulative Model Updates: 106,708
Cumulative Timesteps: 889,928,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.51449
Policy Entropy: 3.11808
Value Function Loss: 0.00446

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.56254
Value Function Update Magnitude: 0.58653

Collected Steps per Second: 22,925.47420
Overall Steps per Second: 10,828.41088

Timestep Collection Time: 2.18194
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.61951

Cumulative Model Updates: 106,714
Cumulative Timesteps: 889,978,376

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 889978376...
Checkpoint 889978376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.99428
Policy Entropy: 3.12699
Value Function Loss: 0.00435

Mean KL Divergence: 0.00773
SB3 Clip Fraction: 0.08406
Policy Update Magnitude: 0.55162
Value Function Update Magnitude: 0.57035

Collected Steps per Second: 22,840.28959
Overall Steps per Second: 10,708.49066

Timestep Collection Time: 2.18911
Timestep Consumption Time: 2.48008
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.66919

Cumulative Model Updates: 106,720
Cumulative Timesteps: 890,028,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.26468
Policy Entropy: 3.11902
Value Function Loss: 0.00455

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08899
Policy Update Magnitude: 0.55582
Value Function Update Magnitude: 0.57472

Collected Steps per Second: 23,196.43779
Overall Steps per Second: 10,838.83489

Timestep Collection Time: 2.15731
Timestep Consumption Time: 2.45960
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.61692

Cumulative Model Updates: 106,726
Cumulative Timesteps: 890,078,418

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 890078418...
Checkpoint 890078418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.51675
Policy Entropy: 3.11940
Value Function Loss: 0.00473

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.57558
Value Function Update Magnitude: 0.60499

Collected Steps per Second: 22,590.38049
Overall Steps per Second: 10,723.61085

Timestep Collection Time: 2.21369
Timestep Consumption Time: 2.44967
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.66335

Cumulative Model Updates: 106,732
Cumulative Timesteps: 890,128,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.46952
Policy Entropy: 3.10169
Value Function Loss: 0.00491

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.58119
Value Function Update Magnitude: 0.62055

Collected Steps per Second: 23,025.27431
Overall Steps per Second: 10,809.93164

Timestep Collection Time: 2.17240
Timestep Consumption Time: 2.45483
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.62723

Cumulative Model Updates: 106,738
Cumulative Timesteps: 890,178,446

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 890178446...
Checkpoint 890178446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.16230
Policy Entropy: 3.11497
Value Function Loss: 0.00473

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09999
Policy Update Magnitude: 0.57545
Value Function Update Magnitude: 0.62773

Collected Steps per Second: 22,014.27830
Overall Steps per Second: 10,812.18418

Timestep Collection Time: 2.27253
Timestep Consumption Time: 2.35448
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.62700

Cumulative Model Updates: 106,744
Cumulative Timesteps: 890,228,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 881.16403
Policy Entropy: 3.11662
Value Function Loss: 0.00482

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.56669
Value Function Update Magnitude: 0.61022

Collected Steps per Second: 22,952.72293
Overall Steps per Second: 10,796.08582

Timestep Collection Time: 2.17918
Timestep Consumption Time: 2.45380
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.63298

Cumulative Model Updates: 106,750
Cumulative Timesteps: 890,278,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 890278492...
Checkpoint 890278492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.96170
Policy Entropy: 3.13698
Value Function Loss: 0.00472

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.57077
Value Function Update Magnitude: 0.60845

Collected Steps per Second: 22,946.18187
Overall Steps per Second: 10,732.89027

Timestep Collection Time: 2.18023
Timestep Consumption Time: 2.48095
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.66119

Cumulative Model Updates: 106,756
Cumulative Timesteps: 890,328,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 845.98474
Policy Entropy: 3.13315
Value Function Loss: 0.00470

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.57922
Value Function Update Magnitude: 0.63327

Collected Steps per Second: 22,697.44274
Overall Steps per Second: 10,625.14131

Timestep Collection Time: 2.20324
Timestep Consumption Time: 2.50333
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.70657

Cumulative Model Updates: 106,762
Cumulative Timesteps: 890,378,528

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 890378528...
Checkpoint 890378528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.84909
Policy Entropy: 3.15040
Value Function Loss: 0.00454

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.57287
Value Function Update Magnitude: 0.65497

Collected Steps per Second: 23,292.60867
Overall Steps per Second: 10,915.06624

Timestep Collection Time: 2.14781
Timestep Consumption Time: 2.43558
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.58339

Cumulative Model Updates: 106,768
Cumulative Timesteps: 890,428,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.43650
Policy Entropy: 3.14835
Value Function Loss: 0.00455

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.56905
Value Function Update Magnitude: 0.65530

Collected Steps per Second: 22,877.41141
Overall Steps per Second: 10,698.52530

Timestep Collection Time: 2.18574
Timestep Consumption Time: 2.48818
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.67392

Cumulative Model Updates: 106,774
Cumulative Timesteps: 890,478,560

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 890478560...
Checkpoint 890478560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 569.90140
Policy Entropy: 3.15151
Value Function Loss: 0.00487

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.57466
Value Function Update Magnitude: 0.66326

Collected Steps per Second: 23,214.77089
Overall Steps per Second: 10,837.67772

Timestep Collection Time: 2.15423
Timestep Consumption Time: 2.46023
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.61446

Cumulative Model Updates: 106,780
Cumulative Timesteps: 890,528,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.32077
Policy Entropy: 3.15449
Value Function Loss: 0.00486

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.57577
Value Function Update Magnitude: 0.66283

Collected Steps per Second: 22,591.52729
Overall Steps per Second: 10,631.79335

Timestep Collection Time: 2.21348
Timestep Consumption Time: 2.48996
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.70344

Cumulative Model Updates: 106,786
Cumulative Timesteps: 890,578,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 890578576...
Checkpoint 890578576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.69595
Policy Entropy: 3.15875
Value Function Loss: 0.00488

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.56394
Value Function Update Magnitude: 0.63112

Collected Steps per Second: 22,859.96237
Overall Steps per Second: 10,785.43488

Timestep Collection Time: 2.18802
Timestep Consumption Time: 2.44953
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.63755

Cumulative Model Updates: 106,792
Cumulative Timesteps: 890,628,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.96938
Policy Entropy: 3.14999
Value Function Loss: 0.00499

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.56650
Value Function Update Magnitude: 0.61938

Collected Steps per Second: 23,129.28034
Overall Steps per Second: 10,717.02403

Timestep Collection Time: 2.16185
Timestep Consumption Time: 2.50381
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.66566

Cumulative Model Updates: 106,798
Cumulative Timesteps: 890,678,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 890678596...
Checkpoint 890678596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 721.68283
Policy Entropy: 3.13027
Value Function Loss: 0.00507

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.57904
Value Function Update Magnitude: 0.64603

Collected Steps per Second: 22,961.81210
Overall Steps per Second: 10,748.97444

Timestep Collection Time: 2.17840
Timestep Consumption Time: 2.47507
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.65347

Cumulative Model Updates: 106,804
Cumulative Timesteps: 890,728,616

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.80915
Policy Entropy: 3.13436
Value Function Loss: 0.00495

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.58402
Value Function Update Magnitude: 0.63692

Collected Steps per Second: 23,217.37608
Overall Steps per Second: 10,684.69298

Timestep Collection Time: 2.15485
Timestep Consumption Time: 2.52755
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.68240

Cumulative Model Updates: 106,810
Cumulative Timesteps: 890,778,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 890778646...
Checkpoint 890778646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.33023
Policy Entropy: 3.13070
Value Function Loss: 0.00507

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.57827
Value Function Update Magnitude: 0.62561

Collected Steps per Second: 22,833.92713
Overall Steps per Second: 10,626.55852

Timestep Collection Time: 2.19113
Timestep Consumption Time: 2.51708
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.70820

Cumulative Model Updates: 106,816
Cumulative Timesteps: 890,828,678

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,528.30538
Policy Entropy: 3.15606
Value Function Loss: 0.00482

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10580
Policy Update Magnitude: 0.57276
Value Function Update Magnitude: 0.62139

Collected Steps per Second: 23,073.54131
Overall Steps per Second: 10,811.32893

Timestep Collection Time: 2.16750
Timestep Consumption Time: 2.45838
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.62589

Cumulative Model Updates: 106,822
Cumulative Timesteps: 890,878,690

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 890878690...
Checkpoint 890878690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640.16113
Policy Entropy: 3.13572
Value Function Loss: 0.00483

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11804
Policy Update Magnitude: 0.56444
Value Function Update Magnitude: 0.61692

Collected Steps per Second: 22,877.63585
Overall Steps per Second: 10,709.64551

Timestep Collection Time: 2.18589
Timestep Consumption Time: 2.48355
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.66944

Cumulative Model Updates: 106,828
Cumulative Timesteps: 890,928,698

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.57788
Policy Entropy: 3.13912
Value Function Loss: 0.00474

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10896
Policy Update Magnitude: 0.56208
Value Function Update Magnitude: 0.59388

Collected Steps per Second: 22,823.88796
Overall Steps per Second: 10,646.11999

Timestep Collection Time: 2.19121
Timestep Consumption Time: 2.50646
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.69767

Cumulative Model Updates: 106,834
Cumulative Timesteps: 890,978,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 890978710...
Checkpoint 890978710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,027.56796
Policy Entropy: 3.12450
Value Function Loss: 0.00487

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.56401
Value Function Update Magnitude: 0.58635

Collected Steps per Second: 23,352.96298
Overall Steps per Second: 10,928.64155

Timestep Collection Time: 2.14200
Timestep Consumption Time: 2.43515
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.57715

Cumulative Model Updates: 106,840
Cumulative Timesteps: 891,028,732

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.67002
Policy Entropy: 3.12904
Value Function Loss: 0.00492

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.55808
Value Function Update Magnitude: 0.57896

Collected Steps per Second: 22,670.31903
Overall Steps per Second: 10,652.62933

Timestep Collection Time: 2.20650
Timestep Consumption Time: 2.48924
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.69574

Cumulative Model Updates: 106,846
Cumulative Timesteps: 891,078,754

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 891078754...
Checkpoint 891078754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 861.61846
Policy Entropy: 3.11363
Value Function Loss: 0.00502

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.56609
Value Function Update Magnitude: 0.60210

Collected Steps per Second: 23,164.05306
Overall Steps per Second: 10,858.28511

Timestep Collection Time: 2.15852
Timestep Consumption Time: 2.44626
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.60478

Cumulative Model Updates: 106,852
Cumulative Timesteps: 891,128,754

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.82223
Policy Entropy: 3.10101
Value Function Loss: 0.00496

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.57398
Value Function Update Magnitude: 0.62286

Collected Steps per Second: 22,912.29432
Overall Steps per Second: 10,698.01089

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.49283
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.67620

Cumulative Model Updates: 106,858
Cumulative Timesteps: 891,178,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 891178780...
Checkpoint 891178780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.85314
Policy Entropy: 3.10285
Value Function Loss: 0.00507

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11846
Policy Update Magnitude: 0.58275
Value Function Update Magnitude: 0.61781

Collected Steps per Second: 22,996.64245
Overall Steps per Second: 10,788.94558

Timestep Collection Time: 2.17519
Timestep Consumption Time: 2.46123
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.63641

Cumulative Model Updates: 106,864
Cumulative Timesteps: 891,228,802

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.51175
Policy Entropy: 3.11688
Value Function Loss: 0.00475

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.57885
Value Function Update Magnitude: 0.61317

Collected Steps per Second: 22,913.53429
Overall Steps per Second: 10,666.74653

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.50565
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.68803

Cumulative Model Updates: 106,870
Cumulative Timesteps: 891,278,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 891278808...
Checkpoint 891278808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 866.43059
Policy Entropy: 3.10911
Value Function Loss: 0.00474

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11815
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.60157

Collected Steps per Second: 22,867.22124
Overall Steps per Second: 10,636.82938

Timestep Collection Time: 2.18697
Timestep Consumption Time: 2.51462
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.70159

Cumulative Model Updates: 106,876
Cumulative Timesteps: 891,328,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.73100
Policy Entropy: 3.10815
Value Function Loss: 0.00489

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11362
Policy Update Magnitude: 0.58132
Value Function Update Magnitude: 0.59421

Collected Steps per Second: 23,186.96506
Overall Steps per Second: 10,804.55816

Timestep Collection Time: 2.15751
Timestep Consumption Time: 2.47258
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.63008

Cumulative Model Updates: 106,882
Cumulative Timesteps: 891,378,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 891378844...
Checkpoint 891378844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.82550
Policy Entropy: 3.09690
Value Function Loss: 0.00517

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12186
Policy Update Magnitude: 0.58692
Value Function Update Magnitude: 0.62131

Collected Steps per Second: 23,042.05433
Overall Steps per Second: 10,659.29559

Timestep Collection Time: 2.17029
Timestep Consumption Time: 2.52120
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.69149

Cumulative Model Updates: 106,888
Cumulative Timesteps: 891,428,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.39703
Policy Entropy: 3.10130
Value Function Loss: 0.00482

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11072
Policy Update Magnitude: 0.57612
Value Function Update Magnitude: 0.64363

Collected Steps per Second: 22,816.37300
Overall Steps per Second: 10,762.84830

Timestep Collection Time: 2.19176
Timestep Consumption Time: 2.45459
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.64635

Cumulative Model Updates: 106,894
Cumulative Timesteps: 891,478,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 891478860...
Checkpoint 891478860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780.70650
Policy Entropy: 3.11940
Value Function Loss: 0.00457

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09499
Policy Update Magnitude: 0.56123
Value Function Update Magnitude: 0.61642

Collected Steps per Second: 22,641.13079
Overall Steps per Second: 10,717.62634

Timestep Collection Time: 2.20846
Timestep Consumption Time: 2.45694
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.66540

Cumulative Model Updates: 106,900
Cumulative Timesteps: 891,528,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.38887
Policy Entropy: 3.11002
Value Function Loss: 0.00464

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.55626
Value Function Update Magnitude: 0.60266

Collected Steps per Second: 22,890.42204
Overall Steps per Second: 10,655.59127

Timestep Collection Time: 2.18563
Timestep Consumption Time: 2.50956
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.69519

Cumulative Model Updates: 106,906
Cumulative Timesteps: 891,578,892

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 891578892...
Checkpoint 891578892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 983.72553
Policy Entropy: 3.11246
Value Function Loss: 0.00489

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.56409
Value Function Update Magnitude: 0.60545

Collected Steps per Second: 23,124.96337
Overall Steps per Second: 10,814.57358

Timestep Collection Time: 2.16338
Timestep Consumption Time: 2.46260
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.62598

Cumulative Model Updates: 106,912
Cumulative Timesteps: 891,628,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.25651
Policy Entropy: 3.11088
Value Function Loss: 0.00528

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.62359

Collected Steps per Second: 22,802.61795
Overall Steps per Second: 10,606.87875

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.52139
PPO Batch Consumption Time: 0.29664
Total Iteration Time: 4.71430

Cumulative Model Updates: 106,918
Cumulative Timesteps: 891,678,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 891678924...
Checkpoint 891678924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.03819
Policy Entropy: 3.11553
Value Function Loss: 0.00524

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.58390
Value Function Update Magnitude: 0.63165

Collected Steps per Second: 22,645.17280
Overall Steps per Second: 10,589.90551

Timestep Collection Time: 2.20851
Timestep Consumption Time: 2.51410
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.72261

Cumulative Model Updates: 106,924
Cumulative Timesteps: 891,728,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.70920
Policy Entropy: 3.11799
Value Function Loss: 0.00480

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.61924

Collected Steps per Second: 22,839.00139
Overall Steps per Second: 10,676.63796

Timestep Collection Time: 2.19003
Timestep Consumption Time: 2.49478
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.68481

Cumulative Model Updates: 106,930
Cumulative Timesteps: 891,778,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 891778954...
Checkpoint 891778954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,178.32428
Policy Entropy: 3.10633
Value Function Loss: 0.00449

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09349
Policy Update Magnitude: 0.56191
Value Function Update Magnitude: 0.59626

Collected Steps per Second: 22,922.30831
Overall Steps per Second: 10,795.21646

Timestep Collection Time: 2.18180
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.63279

Cumulative Model Updates: 106,936
Cumulative Timesteps: 891,828,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.73778
Policy Entropy: 3.10524
Value Function Loss: 0.00456

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.55832
Value Function Update Magnitude: 0.58159

Collected Steps per Second: 23,088.25436
Overall Steps per Second: 10,742.50730

Timestep Collection Time: 2.16630
Timestep Consumption Time: 2.48960
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.65590

Cumulative Model Updates: 106,942
Cumulative Timesteps: 891,878,982

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 891878982...
Checkpoint 891878982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.39920
Policy Entropy: 3.10529
Value Function Loss: 0.00467

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.56570
Value Function Update Magnitude: 0.59830

Collected Steps per Second: 22,902.73136
Overall Steps per Second: 10,797.52037

Timestep Collection Time: 2.18341
Timestep Consumption Time: 2.44784
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.63125

Cumulative Model Updates: 106,948
Cumulative Timesteps: 891,928,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.40423
Policy Entropy: 3.09740
Value Function Loss: 0.00463

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10217
Policy Update Magnitude: 0.56848
Value Function Update Magnitude: 0.60786

Collected Steps per Second: 22,400.85707
Overall Steps per Second: 10,553.27127

Timestep Collection Time: 2.23384
Timestep Consumption Time: 2.50781
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.74166

Cumulative Model Updates: 106,954
Cumulative Timesteps: 891,979,028

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 891979028...
Checkpoint 891979028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 978.14175
Policy Entropy: 3.10067
Value Function Loss: 0.00489

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10125
Policy Update Magnitude: 0.56754
Value Function Update Magnitude: 0.60001

Collected Steps per Second: 22,686.70948
Overall Steps per Second: 10,672.50893

Timestep Collection Time: 2.20402
Timestep Consumption Time: 2.48110
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.68512

Cumulative Model Updates: 106,960
Cumulative Timesteps: 892,029,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.29995
Policy Entropy: 3.09442
Value Function Loss: 0.00484

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.57604
Value Function Update Magnitude: 0.60766

Collected Steps per Second: 23,013.01710
Overall Steps per Second: 10,900.12671

Timestep Collection Time: 2.17399
Timestep Consumption Time: 2.41587
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.58985

Cumulative Model Updates: 106,966
Cumulative Timesteps: 892,079,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 892079060...
Checkpoint 892079060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.30890
Policy Entropy: 3.08864
Value Function Loss: 0.00493

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.57441
Value Function Update Magnitude: 0.60126

Collected Steps per Second: 22,773.86660
Overall Steps per Second: 10,632.39092

Timestep Collection Time: 2.19664
Timestep Consumption Time: 2.50842
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.70506

Cumulative Model Updates: 106,972
Cumulative Timesteps: 892,129,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.55343
Policy Entropy: 3.08912
Value Function Loss: 0.00483

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.14526
Policy Update Magnitude: 0.57061
Value Function Update Magnitude: 0.60418

Collected Steps per Second: 22,484.30030
Overall Steps per Second: 10,501.98418

Timestep Collection Time: 2.22449
Timestep Consumption Time: 2.53804
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.76253

Cumulative Model Updates: 106,978
Cumulative Timesteps: 892,179,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 892179102...
Checkpoint 892179102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 828.79498
Policy Entropy: 3.09356
Value Function Loss: 0.00480

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.14493
Policy Update Magnitude: 0.57203
Value Function Update Magnitude: 0.60804

Collected Steps per Second: 22,561.01387
Overall Steps per Second: 10,547.39904

Timestep Collection Time: 2.21666
Timestep Consumption Time: 2.52480
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.74145

Cumulative Model Updates: 106,984
Cumulative Timesteps: 892,229,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.57490
Policy Entropy: 3.10678
Value Function Loss: 0.00485

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.57405
Value Function Update Magnitude: 0.60975

Collected Steps per Second: 22,599.39689
Overall Steps per Second: 10,679.51493

Timestep Collection Time: 2.21342
Timestep Consumption Time: 2.47050
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.68392

Cumulative Model Updates: 106,990
Cumulative Timesteps: 892,279,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 892279134...
Checkpoint 892279134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 786.25442
Policy Entropy: 3.10392
Value Function Loss: 0.00487

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.57206
Value Function Update Magnitude: 0.61408

Collected Steps per Second: 23,322.49686
Overall Steps per Second: 10,887.55570

Timestep Collection Time: 2.14402
Timestep Consumption Time: 2.44874
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.59277

Cumulative Model Updates: 106,996
Cumulative Timesteps: 892,329,138

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.58628
Policy Entropy: 3.09826
Value Function Loss: 0.00479

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10446
Policy Update Magnitude: 0.57452
Value Function Update Magnitude: 0.60151

Collected Steps per Second: 22,757.76942
Overall Steps per Second: 10,785.15925

Timestep Collection Time: 2.19890
Timestep Consumption Time: 2.44100
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.63989

Cumulative Model Updates: 107,002
Cumulative Timesteps: 892,379,180

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 892379180...
Checkpoint 892379180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,794.78649
Policy Entropy: 3.11215
Value Function Loss: 0.00470

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.57911
Value Function Update Magnitude: 0.60179

Collected Steps per Second: 22,619.50282
Overall Steps per Second: 10,744.10601

Timestep Collection Time: 2.21172
Timestep Consumption Time: 2.44460
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.65632

Cumulative Model Updates: 107,008
Cumulative Timesteps: 892,429,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.61149
Policy Entropy: 3.09903
Value Function Loss: 0.00466

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11541
Policy Update Magnitude: 0.57404
Value Function Update Magnitude: 0.58593

Collected Steps per Second: 23,177.39304
Overall Steps per Second: 10,880.88261

Timestep Collection Time: 2.15866
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.59816

Cumulative Model Updates: 107,014
Cumulative Timesteps: 892,479,240

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 892479240...
Checkpoint 892479240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.24028
Policy Entropy: 3.10264
Value Function Loss: 0.00496

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10998
Policy Update Magnitude: 0.57143
Value Function Update Magnitude: 0.56760

Collected Steps per Second: 22,549.51013
Overall Steps per Second: 10,719.33253

Timestep Collection Time: 2.21832
Timestep Consumption Time: 2.44820
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.66652

Cumulative Model Updates: 107,020
Cumulative Timesteps: 892,529,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,415.53967
Policy Entropy: 3.09632
Value Function Loss: 0.00510

Mean KL Divergence: 0.01136
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.57413
Value Function Update Magnitude: 0.58552

Collected Steps per Second: 23,018.48658
Overall Steps per Second: 10,837.19944

Timestep Collection Time: 2.17304
Timestep Consumption Time: 2.44255
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.61558

Cumulative Model Updates: 107,026
Cumulative Timesteps: 892,579,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 892579282...
Checkpoint 892579282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.27704
Policy Entropy: 3.10040
Value Function Loss: 0.00518

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.12100
Policy Update Magnitude: 0.57936
Value Function Update Magnitude: 0.62789

Collected Steps per Second: 22,596.24370
Overall Steps per Second: 10,723.16246

Timestep Collection Time: 2.21311
Timestep Consumption Time: 2.45044
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.66355

Cumulative Model Updates: 107,032
Cumulative Timesteps: 892,629,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.53371
Policy Entropy: 3.09182
Value Function Loss: 0.00495

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.57665
Value Function Update Magnitude: 0.62752

Collected Steps per Second: 23,149.28899
Overall Steps per Second: 10,928.30422

Timestep Collection Time: 2.16093
Timestep Consumption Time: 2.41654
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.57747

Cumulative Model Updates: 107,038
Cumulative Timesteps: 892,679,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 892679314...
Checkpoint 892679314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.41443
Policy Entropy: 3.08711
Value Function Loss: 0.00488

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11141
Policy Update Magnitude: 0.57227
Value Function Update Magnitude: 0.61330

Collected Steps per Second: 22,878.73402
Overall Steps per Second: 10,714.57304

Timestep Collection Time: 2.18640
Timestep Consumption Time: 2.48220
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.66859

Cumulative Model Updates: 107,044
Cumulative Timesteps: 892,729,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.47390
Policy Entropy: 3.08713
Value Function Loss: 0.00487

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.56865
Value Function Update Magnitude: 0.62145

Collected Steps per Second: 22,920.61020
Overall Steps per Second: 10,781.04109

Timestep Collection Time: 2.18205
Timestep Consumption Time: 2.45702
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.63907

Cumulative Model Updates: 107,050
Cumulative Timesteps: 892,779,350

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 892779350...
Checkpoint 892779350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.69856
Policy Entropy: 3.09309
Value Function Loss: 0.00466

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.56201
Value Function Update Magnitude: 0.63871

Collected Steps per Second: 22,750.24128
Overall Steps per Second: 10,629.77891

Timestep Collection Time: 2.19866
Timestep Consumption Time: 2.50699
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.70565

Cumulative Model Updates: 107,056
Cumulative Timesteps: 892,829,370

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 715.97996
Policy Entropy: 3.09613
Value Function Loss: 0.00492

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10605
Policy Update Magnitude: 0.56221
Value Function Update Magnitude: 0.64233

Collected Steps per Second: 22,988.79733
Overall Steps per Second: 10,881.78622

Timestep Collection Time: 2.17602
Timestep Consumption Time: 2.42102
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.59704

Cumulative Model Updates: 107,062
Cumulative Timesteps: 892,879,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 892879394...
Checkpoint 892879394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.35951
Policy Entropy: 3.09037
Value Function Loss: 0.00478

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.57178
Value Function Update Magnitude: 0.66047

Collected Steps per Second: 22,609.79488
Overall Steps per Second: 10,696.67347

Timestep Collection Time: 2.21214
Timestep Consumption Time: 2.46371
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.67585

Cumulative Model Updates: 107,068
Cumulative Timesteps: 892,929,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.50703
Policy Entropy: 3.08492
Value Function Loss: 0.00488

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.57547
Value Function Update Magnitude: 0.67391

Collected Steps per Second: 22,696.49149
Overall Steps per Second: 10,695.86122

Timestep Collection Time: 2.20360
Timestep Consumption Time: 2.47241
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.67601

Cumulative Model Updates: 107,074
Cumulative Timesteps: 892,979,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 892979424...
Checkpoint 892979424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,732.80979
Policy Entropy: 3.09503
Value Function Loss: 0.00475

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11681
Policy Update Magnitude: 0.57230
Value Function Update Magnitude: 0.66264

Collected Steps per Second: 23,180.80808
Overall Steps per Second: 10,847.62409

Timestep Collection Time: 2.15747
Timestep Consumption Time: 2.45294
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.61041

Cumulative Model Updates: 107,080
Cumulative Timesteps: 893,029,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,610.03062
Policy Entropy: 3.10761
Value Function Loss: 0.00484

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09998
Policy Update Magnitude: 0.56562
Value Function Update Magnitude: 0.63723

Collected Steps per Second: 23,037.45865
Overall Steps per Second: 10,873.84674

Timestep Collection Time: 2.17047
Timestep Consumption Time: 2.42791
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.59837

Cumulative Model Updates: 107,086
Cumulative Timesteps: 893,079,438

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 893079438...
Checkpoint 893079438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.52724
Policy Entropy: 3.11722
Value Function Loss: 0.00496

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.56063
Value Function Update Magnitude: 0.62108

Collected Steps per Second: 22,805.62872
Overall Steps per Second: 10,657.59924

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.49905
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.69149

Cumulative Model Updates: 107,092
Cumulative Timesteps: 893,129,438

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,387.26684
Policy Entropy: 3.10032
Value Function Loss: 0.00501

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10745
Policy Update Magnitude: 0.56886
Value Function Update Magnitude: 0.65677

Collected Steps per Second: 23,111.39033
Overall Steps per Second: 10,817.24156

Timestep Collection Time: 2.16413
Timestep Consumption Time: 2.45960
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.62373

Cumulative Model Updates: 107,098
Cumulative Timesteps: 893,179,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 893179454...
Checkpoint 893179454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.02774
Policy Entropy: 3.09384
Value Function Loss: 0.00484

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.56973
Value Function Update Magnitude: 0.65952

Collected Steps per Second: 22,998.67145
Overall Steps per Second: 10,740.67637

Timestep Collection Time: 2.17500
Timestep Consumption Time: 2.48225
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.65725

Cumulative Model Updates: 107,104
Cumulative Timesteps: 893,229,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,863.90631
Policy Entropy: 3.08545
Value Function Loss: 0.00465

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.56555
Value Function Update Magnitude: 0.60979

Collected Steps per Second: 23,005.62945
Overall Steps per Second: 10,843.11162

Timestep Collection Time: 2.17538
Timestep Consumption Time: 2.44008
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.61546

Cumulative Model Updates: 107,110
Cumulative Timesteps: 893,279,522

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 893279522...
Checkpoint 893279522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.91215
Policy Entropy: 3.07772
Value Function Loss: 0.00488

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12692
Policy Update Magnitude: 0.56064
Value Function Update Magnitude: 0.60037

Collected Steps per Second: 22,652.48448
Overall Steps per Second: 10,760.54477

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.44041
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.64865

Cumulative Model Updates: 107,116
Cumulative Timesteps: 893,329,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.55329
Policy Entropy: 3.06293
Value Function Loss: 0.00497

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.57023
Value Function Update Magnitude: 0.60885

Collected Steps per Second: 22,520.48655
Overall Steps per Second: 10,767.44003

Timestep Collection Time: 2.22020
Timestep Consumption Time: 2.42343
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.64363

Cumulative Model Updates: 107,122
Cumulative Timesteps: 893,379,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 893379544...
Checkpoint 893379544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 903.32142
Policy Entropy: 3.07388
Value Function Loss: 0.00491

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.57770
Value Function Update Magnitude: 0.59846

Collected Steps per Second: 22,706.22002
Overall Steps per Second: 10,755.07740

Timestep Collection Time: 2.20248
Timestep Consumption Time: 2.44742
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.64990

Cumulative Model Updates: 107,128
Cumulative Timesteps: 893,429,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.76309
Policy Entropy: 3.07449
Value Function Loss: 0.00502

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11545
Policy Update Magnitude: 0.57757
Value Function Update Magnitude: 0.58748

Collected Steps per Second: 22,735.61360
Overall Steps per Second: 10,793.20820

Timestep Collection Time: 2.19919
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.63254

Cumulative Model Updates: 107,134
Cumulative Timesteps: 893,479,554

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 893479554...
Checkpoint 893479554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 823.35655
Policy Entropy: 3.08254
Value Function Loss: 0.00511

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.57952
Value Function Update Magnitude: 0.61501

Collected Steps per Second: 22,850.99971
Overall Steps per Second: 10,758.39244

Timestep Collection Time: 2.18818
Timestep Consumption Time: 2.45954
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.64772

Cumulative Model Updates: 107,140
Cumulative Timesteps: 893,529,556

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,006.36951
Policy Entropy: 3.08153
Value Function Loss: 0.00505

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.57527
Value Function Update Magnitude: 0.62916

Collected Steps per Second: 22,764.11588
Overall Steps per Second: 10,794.50930

Timestep Collection Time: 2.19697
Timestep Consumption Time: 2.43613
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.63310

Cumulative Model Updates: 107,146
Cumulative Timesteps: 893,579,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 893579568...
Checkpoint 893579568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.62281
Policy Entropy: 3.09306
Value Function Loss: 0.00495

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.57034
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 22,707.23817
Overall Steps per Second: 10,719.54432

Timestep Collection Time: 2.20256
Timestep Consumption Time: 2.46313
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.66568

Cumulative Model Updates: 107,152
Cumulative Timesteps: 893,629,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.93739
Policy Entropy: 3.09799
Value Function Loss: 0.00477

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.56454
Value Function Update Magnitude: 0.57700

Collected Steps per Second: 22,997.15166
Overall Steps per Second: 10,868.11160

Timestep Collection Time: 2.17470
Timestep Consumption Time: 2.42702
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.60172

Cumulative Model Updates: 107,158
Cumulative Timesteps: 893,679,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 893679594...
Checkpoint 893679594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.20499
Policy Entropy: 3.10466
Value Function Loss: 0.00463

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09325
Policy Update Magnitude: 0.56150
Value Function Update Magnitude: 0.56946

Collected Steps per Second: 22,431.48788
Overall Steps per Second: 10,724.98459

Timestep Collection Time: 2.22928
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.66257

Cumulative Model Updates: 107,164
Cumulative Timesteps: 893,729,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,315.86392
Policy Entropy: 3.10202
Value Function Loss: 0.00463

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.55518
Value Function Update Magnitude: 0.55984

Collected Steps per Second: 22,966.75501
Overall Steps per Second: 10,811.91432

Timestep Collection Time: 2.17776
Timestep Consumption Time: 2.44825
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.62601

Cumulative Model Updates: 107,170
Cumulative Timesteps: 893,779,616

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 893779616...
Checkpoint 893779616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.64782
Policy Entropy: 3.11331
Value Function Loss: 0.00467

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.55229
Value Function Update Magnitude: 0.55658

Collected Steps per Second: 22,774.60062
Overall Steps per Second: 10,712.88287

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.66858

Cumulative Model Updates: 107,176
Cumulative Timesteps: 893,829,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.98444
Policy Entropy: 3.10966
Value Function Loss: 0.00468

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08968
Policy Update Magnitude: 0.55099
Value Function Update Magnitude: 0.54865

Collected Steps per Second: 23,034.10922
Overall Steps per Second: 10,858.08472

Timestep Collection Time: 2.17200
Timestep Consumption Time: 2.43563
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.60763

Cumulative Model Updates: 107,182
Cumulative Timesteps: 893,879,660

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 893879660...
Checkpoint 893879660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.09067
Policy Entropy: 3.11343
Value Function Loss: 0.00459

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.55410
Value Function Update Magnitude: 0.54935

Collected Steps per Second: 22,513.43198
Overall Steps per Second: 10,694.97887

Timestep Collection Time: 2.22214
Timestep Consumption Time: 2.45557
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.67771

Cumulative Model Updates: 107,188
Cumulative Timesteps: 893,929,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.56900
Policy Entropy: 3.10172
Value Function Loss: 0.00486

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.55898
Value Function Update Magnitude: 0.56064

Collected Steps per Second: 22,668.75940
Overall Steps per Second: 10,902.85464

Timestep Collection Time: 2.20630
Timestep Consumption Time: 2.38094
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.58724

Cumulative Model Updates: 107,194
Cumulative Timesteps: 893,979,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 893979702...
Checkpoint 893979702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.30217
Policy Entropy: 3.10119
Value Function Loss: 0.00511

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.56425
Value Function Update Magnitude: 0.55606

Collected Steps per Second: 22,265.99656
Overall Steps per Second: 10,677.56736

Timestep Collection Time: 2.24612
Timestep Consumption Time: 2.43772
PPO Batch Consumption Time: 0.29666
Total Iteration Time: 4.68384

Cumulative Model Updates: 107,200
Cumulative Timesteps: 894,029,714

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.80065
Policy Entropy: 3.09786
Value Function Loss: 0.00525

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.56659
Value Function Update Magnitude: 0.57331

Collected Steps per Second: 22,452.46710
Overall Steps per Second: 10,851.95932

Timestep Collection Time: 2.22719
Timestep Consumption Time: 2.38082
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.60802

Cumulative Model Updates: 107,206
Cumulative Timesteps: 894,079,720

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 894079720...
Checkpoint 894079720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.82127
Policy Entropy: 3.10653
Value Function Loss: 0.00511

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.56791
Value Function Update Magnitude: 0.59346

Collected Steps per Second: 21,936.59499
Overall Steps per Second: 10,660.64545

Timestep Collection Time: 2.28030
Timestep Consumption Time: 2.41191
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.69221

Cumulative Model Updates: 107,212
Cumulative Timesteps: 894,129,742

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 560.68664
Policy Entropy: 3.11182
Value Function Loss: 0.00501

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08876
Policy Update Magnitude: 0.56938
Value Function Update Magnitude: 0.60814

Collected Steps per Second: 22,094.92360
Overall Steps per Second: 10,687.41201

Timestep Collection Time: 2.26323
Timestep Consumption Time: 2.41573
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.67896

Cumulative Model Updates: 107,218
Cumulative Timesteps: 894,179,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 894179748...
Checkpoint 894179748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.23780
Policy Entropy: 3.12472
Value Function Loss: 0.00510

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.56843
Value Function Update Magnitude: 0.60331

Collected Steps per Second: 22,220.15106
Overall Steps per Second: 10,808.11454

Timestep Collection Time: 2.25102
Timestep Consumption Time: 2.37680
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.62782

Cumulative Model Updates: 107,224
Cumulative Timesteps: 894,229,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.68046
Policy Entropy: 3.13069
Value Function Loss: 0.00490

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.56058
Value Function Update Magnitude: 0.59996

Collected Steps per Second: 22,720.00491
Overall Steps per Second: 10,624.81051

Timestep Collection Time: 2.20211
Timestep Consumption Time: 2.50687
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.70898

Cumulative Model Updates: 107,230
Cumulative Timesteps: 894,279,798

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 894279798...
Checkpoint 894279798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.20825
Policy Entropy: 3.12773
Value Function Loss: 0.00482

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.55706
Value Function Update Magnitude: 0.61137

Collected Steps per Second: 23,039.11610
Overall Steps per Second: 10,716.44211

Timestep Collection Time: 2.17074
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.66685

Cumulative Model Updates: 107,236
Cumulative Timesteps: 894,329,810

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.98119
Policy Entropy: 3.11577
Value Function Loss: 0.00476

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.55750
Value Function Update Magnitude: 0.60889

Collected Steps per Second: 23,322.57802
Overall Steps per Second: 10,696.84319

Timestep Collection Time: 2.14427
Timestep Consumption Time: 2.53094
PPO Batch Consumption Time: 0.29701
Total Iteration Time: 4.67521

Cumulative Model Updates: 107,242
Cumulative Timesteps: 894,379,820

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 894379820...
Checkpoint 894379820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.80447
Policy Entropy: 3.10799
Value Function Loss: 0.00487

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.60722

Collected Steps per Second: 22,723.82194
Overall Steps per Second: 10,626.98872

Timestep Collection Time: 2.20042
Timestep Consumption Time: 2.50477
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.70519

Cumulative Model Updates: 107,248
Cumulative Timesteps: 894,429,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.06069
Policy Entropy: 3.11022
Value Function Loss: 0.00512

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09257
Policy Update Magnitude: 0.57343
Value Function Update Magnitude: 0.61566

Collected Steps per Second: 23,161.53090
Overall Steps per Second: 10,845.92676

Timestep Collection Time: 2.15884
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.61021

Cumulative Model Updates: 107,254
Cumulative Timesteps: 894,479,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 894479824...
Checkpoint 894479824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.52003
Policy Entropy: 3.10571
Value Function Loss: 0.00490

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10399
Policy Update Magnitude: 0.57534
Value Function Update Magnitude: 0.63437

Collected Steps per Second: 22,720.46339
Overall Steps per Second: 10,773.64936

Timestep Collection Time: 2.20119
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.64207

Cumulative Model Updates: 107,260
Cumulative Timesteps: 894,529,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,810.87018
Policy Entropy: 3.10569
Value Function Loss: 0.00468

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11768
Policy Update Magnitude: 0.56160
Value Function Update Magnitude: 0.61288

Collected Steps per Second: 23,119.25024
Overall Steps per Second: 10,804.08428

Timestep Collection Time: 2.16279
Timestep Consumption Time: 2.46528
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.62806

Cumulative Model Updates: 107,266
Cumulative Timesteps: 894,579,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 894579838...
Checkpoint 894579838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.09547
Policy Entropy: 3.09986
Value Function Loss: 0.00494

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.11511
Policy Update Magnitude: 0.55897
Value Function Update Magnitude: 0.59582

Collected Steps per Second: 23,006.39253
Overall Steps per Second: 10,656.11798

Timestep Collection Time: 2.17357
Timestep Consumption Time: 2.51913
PPO Batch Consumption Time: 0.29587
Total Iteration Time: 4.69270

Cumulative Model Updates: 107,272
Cumulative Timesteps: 894,629,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 834.48117
Policy Entropy: 3.09031
Value Function Loss: 0.00482

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.56730
Value Function Update Magnitude: 0.58704

Collected Steps per Second: 23,241.72082
Overall Steps per Second: 10,850.81713

Timestep Collection Time: 2.15130
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.60795

Cumulative Model Updates: 107,278
Cumulative Timesteps: 894,679,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 894679844...
Checkpoint 894679844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.83881
Policy Entropy: 3.08406
Value Function Loss: 0.00507

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11673
Policy Update Magnitude: 0.57060
Value Function Update Magnitude: 0.59811

Collected Steps per Second: 22,383.04764
Overall Steps per Second: 10,710.26758

Timestep Collection Time: 2.23446
Timestep Consumption Time: 2.43527
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.66972

Cumulative Model Updates: 107,284
Cumulative Timesteps: 894,729,858

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.11948
Policy Entropy: 3.11577
Value Function Loss: 0.00469

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11492
Policy Update Magnitude: 0.57038
Value Function Update Magnitude: 0.59992

Collected Steps per Second: 22,900.01273
Overall Steps per Second: 10,805.95292

Timestep Collection Time: 2.18340
Timestep Consumption Time: 2.44367
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.62708

Cumulative Model Updates: 107,290
Cumulative Timesteps: 894,779,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 894779858...
Checkpoint 894779858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,691.21102
Policy Entropy: 3.12376
Value Function Loss: 0.00481

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.56435
Value Function Update Magnitude: 0.58349

Collected Steps per Second: 22,847.89403
Overall Steps per Second: 10,764.25361

Timestep Collection Time: 2.18839
Timestep Consumption Time: 2.45662
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.64500

Cumulative Model Updates: 107,296
Cumulative Timesteps: 894,829,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.30707
Policy Entropy: 3.12552
Value Function Loss: 0.00497

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10911
Policy Update Magnitude: 0.56876
Value Function Update Magnitude: 0.58448

Collected Steps per Second: 23,031.93917
Overall Steps per Second: 10,850.11833

Timestep Collection Time: 2.17185
Timestep Consumption Time: 2.43842
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.61027

Cumulative Model Updates: 107,302
Cumulative Timesteps: 894,879,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 894879880...
Checkpoint 894879880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.02038
Policy Entropy: 3.10740
Value Function Loss: 0.00506

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.57069
Value Function Update Magnitude: 0.60868

Collected Steps per Second: 22,823.67307
Overall Steps per Second: 10,681.34599

Timestep Collection Time: 2.19176
Timestep Consumption Time: 2.49155
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.68330

Cumulative Model Updates: 107,308
Cumulative Timesteps: 894,929,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.35805
Policy Entropy: 3.09784
Value Function Loss: 0.00484

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09948
Policy Update Magnitude: 0.56514
Value Function Update Magnitude: 0.61479

Collected Steps per Second: 21,974.14001
Overall Steps per Second: 10,640.15764

Timestep Collection Time: 2.27595
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.70031

Cumulative Model Updates: 107,314
Cumulative Timesteps: 894,979,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 894979916...
Checkpoint 894979916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.85807
Policy Entropy: 3.08637
Value Function Loss: 0.00478

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.56221
Value Function Update Magnitude: 0.61812

Collected Steps per Second: 22,485.97695
Overall Steps per Second: 10,493.70919

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.54166
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.76571

Cumulative Model Updates: 107,320
Cumulative Timesteps: 895,029,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.11017
Policy Entropy: 3.09240
Value Function Loss: 0.00474

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.56146
Value Function Update Magnitude: 0.61351

Collected Steps per Second: 23,327.78439
Overall Steps per Second: 10,850.64095

Timestep Collection Time: 2.14371
Timestep Consumption Time: 2.46505
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.60876

Cumulative Model Updates: 107,326
Cumulative Timesteps: 895,079,934

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 895079934...
Checkpoint 895079934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.46743
Policy Entropy: 3.09448
Value Function Loss: 0.00489

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.56865
Value Function Update Magnitude: 0.60582

Collected Steps per Second: 22,614.77314
Overall Steps per Second: 10,684.88900

Timestep Collection Time: 2.21227
Timestep Consumption Time: 2.47004
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.68231

Cumulative Model Updates: 107,332
Cumulative Timesteps: 895,129,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.67088
Policy Entropy: 3.12056
Value Function Loss: 0.00483

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.56770
Value Function Update Magnitude: 0.58669

Collected Steps per Second: 23,172.51929
Overall Steps per Second: 10,827.19951

Timestep Collection Time: 2.15894
Timestep Consumption Time: 2.46165
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.62059

Cumulative Model Updates: 107,338
Cumulative Timesteps: 895,179,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 895179992...
Checkpoint 895179992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,346.69568
Policy Entropy: 3.11925
Value Function Loss: 0.00470

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09070
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.56812

Collected Steps per Second: 22,931.74475
Overall Steps per Second: 10,705.56534

Timestep Collection Time: 2.18099
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.67178

Cumulative Model Updates: 107,344
Cumulative Timesteps: 895,230,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,269.28335
Policy Entropy: 3.11240
Value Function Loss: 0.00435

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.08509
Policy Update Magnitude: 0.55376
Value Function Update Magnitude: 0.54351

Collected Steps per Second: 23,422.65584
Overall Steps per Second: 10,873.18298

Timestep Collection Time: 2.13562
Timestep Consumption Time: 2.46487
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.60049

Cumulative Model Updates: 107,350
Cumulative Timesteps: 895,280,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 895280028...
Checkpoint 895280028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,629.63471
Policy Entropy: 3.09772
Value Function Loss: 0.00441

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09278
Policy Update Magnitude: 0.54588
Value Function Update Magnitude: 0.51849

Collected Steps per Second: 22,827.40170
Overall Steps per Second: 10,672.19734

Timestep Collection Time: 2.19079
Timestep Consumption Time: 2.49522
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.68601

Cumulative Model Updates: 107,356
Cumulative Timesteps: 895,330,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,522.61820
Policy Entropy: 3.10619
Value Function Loss: 0.00433

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09218
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.52078

Collected Steps per Second: 22,217.07856
Overall Steps per Second: 10,810.32986

Timestep Collection Time: 2.25088
Timestep Consumption Time: 2.37506
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.62595

Cumulative Model Updates: 107,362
Cumulative Timesteps: 895,380,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 895380046...
Checkpoint 895380046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,808.42270
Policy Entropy: 3.09771
Value Function Loss: 0.00463

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.54644
Value Function Update Magnitude: 0.54471

Collected Steps per Second: 22,200.24937
Overall Steps per Second: 10,733.48645

Timestep Collection Time: 2.25349
Timestep Consumption Time: 2.40744
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.66093

Cumulative Model Updates: 107,368
Cumulative Timesteps: 895,430,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.95147
Policy Entropy: 3.08838
Value Function Loss: 0.00448

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11841
Policy Update Magnitude: 0.54682
Value Function Update Magnitude: 0.54876

Collected Steps per Second: 22,489.35355
Overall Steps per Second: 10,881.20108

Timestep Collection Time: 2.22407
Timestep Consumption Time: 2.37266
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.59674

Cumulative Model Updates: 107,374
Cumulative Timesteps: 895,480,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 895480092...
Checkpoint 895480092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796.25787
Policy Entropy: 3.07977
Value Function Loss: 0.00496

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12649
Policy Update Magnitude: 0.55640
Value Function Update Magnitude: 0.55787

Collected Steps per Second: 21,761.63797
Overall Steps per Second: 10,648.58266

Timestep Collection Time: 2.29826
Timestep Consumption Time: 2.39851
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.69678

Cumulative Model Updates: 107,380
Cumulative Timesteps: 895,530,106

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.70892
Policy Entropy: 3.10483
Value Function Loss: 0.00481

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.56825
Value Function Update Magnitude: 0.58880

Collected Steps per Second: 22,982.36915
Overall Steps per Second: 10,802.56952

Timestep Collection Time: 2.17575
Timestep Consumption Time: 2.45314
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.62890

Cumulative Model Updates: 107,386
Cumulative Timesteps: 895,580,110

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 895580110...
Checkpoint 895580110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644.97698
Policy Entropy: 3.10165
Value Function Loss: 0.00504

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12174
Policy Update Magnitude: 0.56731
Value Function Update Magnitude: 0.61722

Collected Steps per Second: 21,946.18402
Overall Steps per Second: 10,763.27832

Timestep Collection Time: 2.27885
Timestep Consumption Time: 2.36769
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.64654

Cumulative Model Updates: 107,392
Cumulative Timesteps: 895,630,122

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.13964
Policy Entropy: 3.10853
Value Function Loss: 0.00504

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.56156
Value Function Update Magnitude: 0.61125

Collected Steps per Second: 22,643.47984
Overall Steps per Second: 10,901.85346

Timestep Collection Time: 2.20929
Timestep Consumption Time: 2.37947
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.58876

Cumulative Model Updates: 107,398
Cumulative Timesteps: 895,680,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 895680148...
Checkpoint 895680148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.13885
Policy Entropy: 3.10108
Value Function Loss: 0.00500

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.12562
Policy Update Magnitude: 0.55509
Value Function Update Magnitude: 0.59963

Collected Steps per Second: 21,660.01897
Overall Steps per Second: 10,660.77124

Timestep Collection Time: 2.30849
Timestep Consumption Time: 2.38179
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.69028

Cumulative Model Updates: 107,404
Cumulative Timesteps: 895,730,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,614.79348
Policy Entropy: 3.11920
Value Function Loss: 0.00480

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.54921
Value Function Update Magnitude: 0.59966

Collected Steps per Second: 23,183.67536
Overall Steps per Second: 10,808.26284

Timestep Collection Time: 2.15686
Timestep Consumption Time: 2.46960
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.62646

Cumulative Model Updates: 107,410
Cumulative Timesteps: 895,780,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 895780154...
Checkpoint 895780154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 896.37961
Policy Entropy: 3.12449
Value Function Loss: 0.00471

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11620
Policy Update Magnitude: 0.55336
Value Function Update Magnitude: 0.60665

Collected Steps per Second: 22,135.12938
Overall Steps per Second: 10,725.41787

Timestep Collection Time: 2.25894
Timestep Consumption Time: 2.40307
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.66201

Cumulative Model Updates: 107,416
Cumulative Timesteps: 895,830,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.45408
Policy Entropy: 3.13052
Value Function Loss: 0.00446

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.55474
Value Function Update Magnitude: 0.62707

Collected Steps per Second: 22,630.66141
Overall Steps per Second: 10,914.44375

Timestep Collection Time: 2.20939
Timestep Consumption Time: 2.37169
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.58109

Cumulative Model Updates: 107,422
Cumulative Timesteps: 895,880,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 895880156...
Checkpoint 895880156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,328.24636
Policy Entropy: 3.11785
Value Function Loss: 0.00450

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09187
Policy Update Magnitude: 0.55688
Value Function Update Magnitude: 0.59526

Collected Steps per Second: 22,171.88155
Overall Steps per Second: 10,652.74585

Timestep Collection Time: 2.25583
Timestep Consumption Time: 2.43930
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.69513

Cumulative Model Updates: 107,428
Cumulative Timesteps: 895,930,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.83982
Policy Entropy: 3.11999
Value Function Loss: 0.00475

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10093
Policy Update Magnitude: 0.56482
Value Function Update Magnitude: 0.60003

Collected Steps per Second: 22,469.20649
Overall Steps per Second: 10,858.26351

Timestep Collection Time: 2.22589
Timestep Consumption Time: 2.38019
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.60608

Cumulative Model Updates: 107,434
Cumulative Timesteps: 895,980,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 895980186...
Checkpoint 895980186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.12127
Policy Entropy: 3.11543
Value Function Loss: 0.00491

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.60605

Collected Steps per Second: 22,179.49001
Overall Steps per Second: 10,650.56249

Timestep Collection Time: 2.25560
Timestep Consumption Time: 2.44162
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.69722

Cumulative Model Updates: 107,440
Cumulative Timesteps: 896,030,214

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.76672
Policy Entropy: 3.12670
Value Function Loss: 0.00495

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.56750
Value Function Update Magnitude: 0.59898

Collected Steps per Second: 22,409.20551
Overall Steps per Second: 10,888.50757

Timestep Collection Time: 2.23230
Timestep Consumption Time: 2.36190
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.59420

Cumulative Model Updates: 107,446
Cumulative Timesteps: 896,080,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 896080238...
Checkpoint 896080238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 870.28348
Policy Entropy: 3.13249
Value Function Loss: 0.00493

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.56527
Value Function Update Magnitude: 0.61994

Collected Steps per Second: 22,111.41561
Overall Steps per Second: 10,682.50498

Timestep Collection Time: 2.26200
Timestep Consumption Time: 2.42005
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68205

Cumulative Model Updates: 107,452
Cumulative Timesteps: 896,130,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.11079
Policy Entropy: 3.13257
Value Function Loss: 0.00492

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.57251
Value Function Update Magnitude: 0.61740

Collected Steps per Second: 23,106.84999
Overall Steps per Second: 10,848.73444

Timestep Collection Time: 2.16481
Timestep Consumption Time: 2.44605
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.61086

Cumulative Model Updates: 107,458
Cumulative Timesteps: 896,180,276

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 896180276...
Checkpoint 896180276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.93442
Policy Entropy: 3.13728
Value Function Loss: 0.00486

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.56655
Value Function Update Magnitude: 0.59739

Collected Steps per Second: 22,744.05630
Overall Steps per Second: 10,689.75414

Timestep Collection Time: 2.19926
Timestep Consumption Time: 2.47999
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.67925

Cumulative Model Updates: 107,464
Cumulative Timesteps: 896,230,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.55860
Policy Entropy: 3.13240
Value Function Loss: 0.00496

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.56293
Value Function Update Magnitude: 0.58572

Collected Steps per Second: 23,304.52413
Overall Steps per Second: 10,883.35207

Timestep Collection Time: 2.14654
Timestep Consumption Time: 2.44984
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.59638

Cumulative Model Updates: 107,470
Cumulative Timesteps: 896,280,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 896280320...
Checkpoint 896280320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.49796
Policy Entropy: 3.13545
Value Function Loss: 0.00492

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09811
Policy Update Magnitude: 0.56190
Value Function Update Magnitude: 0.58987

Collected Steps per Second: 22,580.03674
Overall Steps per Second: 10,659.58796

Timestep Collection Time: 2.21461
Timestep Consumption Time: 2.47656
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.69118

Cumulative Model Updates: 107,476
Cumulative Timesteps: 896,330,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.43803
Policy Entropy: 3.13627
Value Function Loss: 0.00481

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.56414
Value Function Update Magnitude: 0.58227

Collected Steps per Second: 22,240.63673
Overall Steps per Second: 10,814.47332

Timestep Collection Time: 2.24823
Timestep Consumption Time: 2.37539
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.62362

Cumulative Model Updates: 107,482
Cumulative Timesteps: 896,380,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 896380328...
Checkpoint 896380328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 848.36324
Policy Entropy: 3.13543
Value Function Loss: 0.00498

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.56434
Value Function Update Magnitude: 0.57586

Collected Steps per Second: 21,953.88525
Overall Steps per Second: 10,775.21638

Timestep Collection Time: 2.27796
Timestep Consumption Time: 2.36325
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.64121

Cumulative Model Updates: 107,488
Cumulative Timesteps: 896,430,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.42732
Policy Entropy: 3.14548
Value Function Loss: 0.00492

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11675
Policy Update Magnitude: 0.56056
Value Function Update Magnitude: 0.57645

Collected Steps per Second: 22,182.65001
Overall Steps per Second: 10,780.83091

Timestep Collection Time: 2.25501
Timestep Consumption Time: 2.38490
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.63990

Cumulative Model Updates: 107,494
Cumulative Timesteps: 896,480,360

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 896480360...
Checkpoint 896480360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.09677
Policy Entropy: 3.13258
Value Function Loss: 0.00480

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.55584
Value Function Update Magnitude: 0.59121

Collected Steps per Second: 21,898.60330
Overall Steps per Second: 10,747.51220

Timestep Collection Time: 2.28435
Timestep Consumption Time: 2.37013
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.65447

Cumulative Model Updates: 107,500
Cumulative Timesteps: 896,530,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,463.26825
Policy Entropy: 3.14889
Value Function Loss: 0.00463

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11429
Policy Update Magnitude: 0.55620
Value Function Update Magnitude: 0.59765

Collected Steps per Second: 22,105.07170
Overall Steps per Second: 10,680.96888

Timestep Collection Time: 2.26292
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.68328

Cumulative Model Updates: 107,506
Cumulative Timesteps: 896,580,406

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 896580406...
Checkpoint 896580406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.79694
Policy Entropy: 3.14977
Value Function Loss: 0.00444

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.55601
Value Function Update Magnitude: 0.58506

Collected Steps per Second: 22,298.43158
Overall Steps per Second: 10,822.12421

Timestep Collection Time: 2.24437
Timestep Consumption Time: 2.38004
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.62442

Cumulative Model Updates: 107,512
Cumulative Timesteps: 896,630,452

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.14878
Policy Entropy: 3.15997
Value Function Loss: 0.00455

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08816
Policy Update Magnitude: 0.55426
Value Function Update Magnitude: 0.57116

Collected Steps per Second: 22,443.91903
Overall Steps per Second: 10,890.74036

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.36394
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.59234

Cumulative Model Updates: 107,518
Cumulative Timesteps: 896,680,466

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 896680466...
Checkpoint 896680466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.74868
Policy Entropy: 3.14621
Value Function Loss: 0.00461

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09165
Policy Update Magnitude: 0.55895
Value Function Update Magnitude: 0.56787

Collected Steps per Second: 22,869.57117
Overall Steps per Second: 10,703.80205

Timestep Collection Time: 2.18745
Timestep Consumption Time: 2.48622
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.67367

Cumulative Model Updates: 107,524
Cumulative Timesteps: 896,730,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,700.90229
Policy Entropy: 3.12655
Value Function Loss: 0.00483

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09419
Policy Update Magnitude: 0.56616
Value Function Update Magnitude: 0.58203

Collected Steps per Second: 22,987.19759
Overall Steps per Second: 10,819.11636

Timestep Collection Time: 2.17556
Timestep Consumption Time: 2.44682
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.62237

Cumulative Model Updates: 107,530
Cumulative Timesteps: 896,780,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 896780502...
Checkpoint 896780502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 943.54861
Policy Entropy: 3.10758
Value Function Loss: 0.00493

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.57876
Value Function Update Magnitude: 0.60370

Collected Steps per Second: 22,896.17847
Overall Steps per Second: 10,740.80278

Timestep Collection Time: 2.18491
Timestep Consumption Time: 2.47266
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.65757

Cumulative Model Updates: 107,536
Cumulative Timesteps: 896,830,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.26978
Policy Entropy: 3.10381
Value Function Loss: 0.00466

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09281
Policy Update Magnitude: 0.57162
Value Function Update Magnitude: 0.61825

Collected Steps per Second: 23,000.04299
Overall Steps per Second: 10,817.11003

Timestep Collection Time: 2.17487
Timestep Consumption Time: 2.44947
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.62434

Cumulative Model Updates: 107,542
Cumulative Timesteps: 896,880,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 896880550...
Checkpoint 896880550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.50422
Policy Entropy: 3.10847
Value Function Loss: 0.00471

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.57278
Value Function Update Magnitude: 0.62496

Collected Steps per Second: 22,408.97563
Overall Steps per Second: 10,672.49543

Timestep Collection Time: 2.23232
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.68719

Cumulative Model Updates: 107,548
Cumulative Timesteps: 896,930,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924.24089
Policy Entropy: 3.12310
Value Function Loss: 0.00488

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.57895
Value Function Update Magnitude: 0.61617

Collected Steps per Second: 23,188.64392
Overall Steps per Second: 10,844.36139

Timestep Collection Time: 2.15700
Timestep Consumption Time: 2.45535
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.61235

Cumulative Model Updates: 107,554
Cumulative Timesteps: 896,980,592

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 896980592...
Checkpoint 896980592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.49612
Policy Entropy: 3.12968
Value Function Loss: 0.00487

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09946
Policy Update Magnitude: 0.57516
Value Function Update Magnitude: 0.62062

Collected Steps per Second: 22,430.20162
Overall Steps per Second: 10,724.43501

Timestep Collection Time: 2.22976
Timestep Consumption Time: 2.43379
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.66356

Cumulative Model Updates: 107,560
Cumulative Timesteps: 897,030,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,721.03890
Policy Entropy: 3.13571
Value Function Loss: 0.00503

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09207
Policy Update Magnitude: 0.56803
Value Function Update Magnitude: 0.62072

Collected Steps per Second: 23,164.81400
Overall Steps per Second: 10,827.51101

Timestep Collection Time: 2.15983
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.62082

Cumulative Model Updates: 107,566
Cumulative Timesteps: 897,080,638

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 897080638...
Checkpoint 897080638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.18140
Policy Entropy: 3.13120
Value Function Loss: 0.00522

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.09117
Policy Update Magnitude: 0.57227
Value Function Update Magnitude: 0.62509

Collected Steps per Second: 22,751.44805
Overall Steps per Second: 10,816.15811

Timestep Collection Time: 2.19881
Timestep Consumption Time: 2.42631
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.62512

Cumulative Model Updates: 107,572
Cumulative Timesteps: 897,130,664

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.29100
Policy Entropy: 3.11643
Value Function Loss: 0.00507

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.57411
Value Function Update Magnitude: 0.63321

Collected Steps per Second: 22,380.59975
Overall Steps per Second: 10,821.10282

Timestep Collection Time: 2.23542
Timestep Consumption Time: 2.38796
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.62337

Cumulative Model Updates: 107,578
Cumulative Timesteps: 897,180,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 897180694...
Checkpoint 897180694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.47593
Policy Entropy: 3.11150
Value Function Loss: 0.00513

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.57412
Value Function Update Magnitude: 0.63579

Collected Steps per Second: 22,905.83078
Overall Steps per Second: 10,656.95984

Timestep Collection Time: 2.18399
Timestep Consumption Time: 2.51022
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.69421

Cumulative Model Updates: 107,584
Cumulative Timesteps: 897,230,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.87496
Policy Entropy: 3.11567
Value Function Loss: 0.00483

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.08836
Policy Update Magnitude: 0.57694
Value Function Update Magnitude: 0.64461

Collected Steps per Second: 23,013.46264
Overall Steps per Second: 10,712.42853

Timestep Collection Time: 2.17377
Timestep Consumption Time: 2.49613
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.66990

Cumulative Model Updates: 107,590
Cumulative Timesteps: 897,280,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 897280746...
Checkpoint 897280746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,569.13832
Policy Entropy: 3.11971
Value Function Loss: 0.00494

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.58185
Value Function Update Magnitude: 0.65561

Collected Steps per Second: 22,765.58338
Overall Steps per Second: 10,709.29975

Timestep Collection Time: 2.19770
Timestep Consumption Time: 2.47412
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.67183

Cumulative Model Updates: 107,596
Cumulative Timesteps: 897,330,778

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,698.14476
Policy Entropy: 3.10607
Value Function Loss: 0.00479

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11150
Policy Update Magnitude: 0.57828
Value Function Update Magnitude: 0.66710

Collected Steps per Second: 23,054.70030
Overall Steps per Second: 10,690.12603

Timestep Collection Time: 2.16902
Timestep Consumption Time: 2.50876
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.67777

Cumulative Model Updates: 107,602
Cumulative Timesteps: 897,380,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 897380784...
Checkpoint 897380784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754.23734
Policy Entropy: 3.10422
Value Function Loss: 0.00480

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11620
Policy Update Magnitude: 0.57321
Value Function Update Magnitude: 0.66665

Collected Steps per Second: 22,863.58103
Overall Steps per Second: 10,601.17494

Timestep Collection Time: 2.18802
Timestep Consumption Time: 2.53089
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.71891

Cumulative Model Updates: 107,608
Cumulative Timesteps: 897,430,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,788.88373
Policy Entropy: 3.09178
Value Function Loss: 0.00465

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.64892

Collected Steps per Second: 23,014.67593
Overall Steps per Second: 10,808.48132

Timestep Collection Time: 2.17340
Timestep Consumption Time: 2.45445
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.62785

Cumulative Model Updates: 107,614
Cumulative Timesteps: 897,480,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 897480830...
Checkpoint 897480830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.97356
Policy Entropy: 3.11083
Value Function Loss: 0.00445

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.56098
Value Function Update Magnitude: 0.62448

Collected Steps per Second: 21,819.43434
Overall Steps per Second: 10,719.53490

Timestep Collection Time: 2.29181
Timestep Consumption Time: 2.37313
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.66494

Cumulative Model Updates: 107,620
Cumulative Timesteps: 897,530,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.91732
Policy Entropy: 3.10576
Value Function Loss: 0.00461

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.56271
Value Function Update Magnitude: 0.62606

Collected Steps per Second: 23,157.41199
Overall Steps per Second: 10,853.47657

Timestep Collection Time: 2.16043
Timestep Consumption Time: 2.44915
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.60958

Cumulative Model Updates: 107,626
Cumulative Timesteps: 897,580,866

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 897580866...
Checkpoint 897580866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,852.57524
Policy Entropy: 3.10266
Value Function Loss: 0.00482

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11736
Policy Update Magnitude: 0.56653
Value Function Update Magnitude: 0.64325

Collected Steps per Second: 22,003.68766
Overall Steps per Second: 10,678.84071

Timestep Collection Time: 2.27353
Timestep Consumption Time: 2.41106
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.68459

Cumulative Model Updates: 107,632
Cumulative Timesteps: 897,630,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.15264
Policy Entropy: 3.10112
Value Function Loss: 0.00491

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.57392
Value Function Update Magnitude: 0.63595

Collected Steps per Second: 23,065.47794
Overall Steps per Second: 10,807.90015

Timestep Collection Time: 2.16800
Timestep Consumption Time: 2.45880
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.62680

Cumulative Model Updates: 107,638
Cumulative Timesteps: 897,680,898

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 897680898...
Checkpoint 897680898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.81343
Policy Entropy: 3.08882
Value Function Loss: 0.00509

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.57813
Value Function Update Magnitude: 0.63449

Collected Steps per Second: 22,539.75375
Overall Steps per Second: 10,736.27594

Timestep Collection Time: 2.21955
Timestep Consumption Time: 2.44017
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.65972

Cumulative Model Updates: 107,644
Cumulative Timesteps: 897,730,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.54455
Policy Entropy: 3.09957
Value Function Loss: 0.00505

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10676
Policy Update Magnitude: 0.58060
Value Function Update Magnitude: 0.64225

Collected Steps per Second: 23,084.87629
Overall Steps per Second: 10,812.33153

Timestep Collection Time: 2.16661
Timestep Consumption Time: 2.45922
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.62583

Cumulative Model Updates: 107,650
Cumulative Timesteps: 897,780,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 897780942...
Checkpoint 897780942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.02974
Policy Entropy: 3.09532
Value Function Loss: 0.00510

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.10982
Policy Update Magnitude: 0.58785
Value Function Update Magnitude: 0.63077

Collected Steps per Second: 22,967.55756
Overall Steps per Second: 10,760.19419

Timestep Collection Time: 2.17812
Timestep Consumption Time: 2.47106
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.64917

Cumulative Model Updates: 107,656
Cumulative Timesteps: 897,830,968

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.46406
Policy Entropy: 3.09582
Value Function Loss: 0.00497

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.58239
Value Function Update Magnitude: 0.62431

Collected Steps per Second: 22,785.38614
Overall Steps per Second: 10,668.45636

Timestep Collection Time: 2.19535
Timestep Consumption Time: 2.49342
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.68878

Cumulative Model Updates: 107,662
Cumulative Timesteps: 897,880,990

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 897880990...
Checkpoint 897880990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.34450
Policy Entropy: 3.10509
Value Function Loss: 0.00500

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11122
Policy Update Magnitude: 0.58072
Value Function Update Magnitude: 0.62478

Collected Steps per Second: 23,279.21118
Overall Steps per Second: 10,913.64376

Timestep Collection Time: 2.14784
Timestep Consumption Time: 2.43358
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.58142

Cumulative Model Updates: 107,668
Cumulative Timesteps: 897,930,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.83812
Policy Entropy: 3.09984
Value Function Loss: 0.00538

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.12028
Policy Update Magnitude: 0.59390
Value Function Update Magnitude: 0.63800

Collected Steps per Second: 23,017.82358
Overall Steps per Second: 10,824.73575

Timestep Collection Time: 2.17223
Timestep Consumption Time: 2.44682
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.61905

Cumulative Model Updates: 107,674
Cumulative Timesteps: 897,980,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 897980990...
Checkpoint 897980990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 871.58765
Policy Entropy: 3.10714
Value Function Loss: 0.00543

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.59568
Value Function Update Magnitude: 0.64740

Collected Steps per Second: 22,654.20782
Overall Steps per Second: 10,677.32316

Timestep Collection Time: 2.20815
Timestep Consumption Time: 2.47691
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.68507

Cumulative Model Updates: 107,680
Cumulative Timesteps: 898,031,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,870.32311
Policy Entropy: 3.10632
Value Function Loss: 0.00522

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11770
Policy Update Magnitude: 0.58865
Value Function Update Magnitude: 0.63881

Collected Steps per Second: 23,284.56823
Overall Steps per Second: 10,885.54387

Timestep Collection Time: 2.14803
Timestep Consumption Time: 2.44669
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.59472

Cumulative Model Updates: 107,686
Cumulative Timesteps: 898,081,030

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 898081030...
Checkpoint 898081030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.79094
Policy Entropy: 3.09961
Value Function Loss: 0.00483

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.57333
Value Function Update Magnitude: 0.62290

Collected Steps per Second: 22,468.40714
Overall Steps per Second: 10,711.63426

Timestep Collection Time: 2.22668
Timestep Consumption Time: 2.44394
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.67062

Cumulative Model Updates: 107,692
Cumulative Timesteps: 898,131,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 799.51990
Policy Entropy: 3.07744
Value Function Loss: 0.00487

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.56887
Value Function Update Magnitude: 0.61631

Collected Steps per Second: 23,228.25043
Overall Steps per Second: 10,847.31310

Timestep Collection Time: 2.15376
Timestep Consumption Time: 2.45826
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.61202

Cumulative Model Updates: 107,698
Cumulative Timesteps: 898,181,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 898181088...
Checkpoint 898181088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 799.11151
Policy Entropy: 3.08577
Value Function Loss: 0.00470

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.57435
Value Function Update Magnitude: 0.61737

Collected Steps per Second: 22,400.80432
Overall Steps per Second: 10,722.91628

Timestep Collection Time: 2.23313
Timestep Consumption Time: 2.43201
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.66515

Cumulative Model Updates: 107,704
Cumulative Timesteps: 898,231,112

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.51050
Policy Entropy: 3.09373
Value Function Loss: 0.00478

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.57522
Value Function Update Magnitude: 0.61601

Collected Steps per Second: 23,277.41930
Overall Steps per Second: 10,861.77543

Timestep Collection Time: 2.14826
Timestep Consumption Time: 2.45559
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.60385

Cumulative Model Updates: 107,710
Cumulative Timesteps: 898,281,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 898281118...
Checkpoint 898281118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.48864
Policy Entropy: 3.10710
Value Function Loss: 0.00485

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.56904
Value Function Update Magnitude: 0.62982

Collected Steps per Second: 22,490.90429
Overall Steps per Second: 10,649.31597

Timestep Collection Time: 2.22410
Timestep Consumption Time: 2.47310
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.69720

Cumulative Model Updates: 107,716
Cumulative Timesteps: 898,331,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.97292
Policy Entropy: 3.10237
Value Function Loss: 0.00497

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.64373

Collected Steps per Second: 23,106.03011
Overall Steps per Second: 10,802.16518

Timestep Collection Time: 2.16472
Timestep Consumption Time: 2.46565
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.63037

Cumulative Model Updates: 107,722
Cumulative Timesteps: 898,381,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 898381158...
Checkpoint 898381158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.42202
Policy Entropy: 3.11687
Value Function Loss: 0.00517

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10059
Policy Update Magnitude: 0.56960
Value Function Update Magnitude: 0.61787

Collected Steps per Second: 22,880.45852
Overall Steps per Second: 10,768.47771

Timestep Collection Time: 2.18614
Timestep Consumption Time: 2.45889
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.64504

Cumulative Model Updates: 107,728
Cumulative Timesteps: 898,431,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.68557
Policy Entropy: 3.12369
Value Function Loss: 0.00516

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09107
Policy Update Magnitude: 0.57462
Value Function Update Magnitude: 0.60284

Collected Steps per Second: 23,194.32922
Overall Steps per Second: 10,846.72231

Timestep Collection Time: 2.15622
Timestep Consumption Time: 2.45458
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.61079

Cumulative Model Updates: 107,734
Cumulative Timesteps: 898,481,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 898481190...
Checkpoint 898481190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704.64127
Policy Entropy: 3.12501
Value Function Loss: 0.00539

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.58035
Value Function Update Magnitude: 0.63273

Collected Steps per Second: 22,695.45721
Overall Steps per Second: 10,692.43410

Timestep Collection Time: 2.20361
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.67733

Cumulative Model Updates: 107,740
Cumulative Timesteps: 898,531,202

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.67906
Policy Entropy: 3.12535
Value Function Loss: 0.00511

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.58469
Value Function Update Magnitude: 0.65522

Collected Steps per Second: 23,259.69716
Overall Steps per Second: 10,891.47655

Timestep Collection Time: 2.14999
Timestep Consumption Time: 2.44150
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.59148

Cumulative Model Updates: 107,746
Cumulative Timesteps: 898,581,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 898581210...
Checkpoint 898581210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.44692
Policy Entropy: 3.11384
Value Function Loss: 0.00496

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.57789
Value Function Update Magnitude: 0.66118

Collected Steps per Second: 22,680.25208
Overall Steps per Second: 10,678.97720

Timestep Collection Time: 2.20474
Timestep Consumption Time: 2.47773
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.68247

Cumulative Model Updates: 107,752
Cumulative Timesteps: 898,631,214

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.82868
Policy Entropy: 3.11991
Value Function Loss: 0.00507

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09453
Policy Update Magnitude: 0.57740
Value Function Update Magnitude: 0.65121

Collected Steps per Second: 23,300.92421
Overall Steps per Second: 10,951.54831

Timestep Collection Time: 2.14704
Timestep Consumption Time: 2.42108
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.56812

Cumulative Model Updates: 107,758
Cumulative Timesteps: 898,681,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 898681242...
Checkpoint 898681242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.17069
Policy Entropy: 3.11188
Value Function Loss: 0.00515

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10361
Policy Update Magnitude: 0.57899
Value Function Update Magnitude: 0.65364

Collected Steps per Second: 22,387.35695
Overall Steps per Second: 10,604.50063

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.71687

Cumulative Model Updates: 107,764
Cumulative Timesteps: 898,731,262

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.68132
Policy Entropy: 3.12297
Value Function Loss: 0.00513

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.57543
Value Function Update Magnitude: 0.65307

Collected Steps per Second: 23,350.15382
Overall Steps per Second: 10,918.86722

Timestep Collection Time: 2.14243
Timestep Consumption Time: 2.43918
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.58161

Cumulative Model Updates: 107,770
Cumulative Timesteps: 898,781,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 898781288...
Checkpoint 898781288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.21264
Policy Entropy: 3.12026
Value Function Loss: 0.00506

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.57417
Value Function Update Magnitude: 0.65686

Collected Steps per Second: 22,787.18126
Overall Steps per Second: 10,609.81076

Timestep Collection Time: 2.19422
Timestep Consumption Time: 2.51840
PPO Batch Consumption Time: 0.29233
Total Iteration Time: 4.71262

Cumulative Model Updates: 107,776
Cumulative Timesteps: 898,831,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.47261
Policy Entropy: 3.11976
Value Function Loss: 0.00528

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.58407
Value Function Update Magnitude: 0.65939

Collected Steps per Second: 23,430.61051
Overall Steps per Second: 10,892.44977

Timestep Collection Time: 2.13584
Timestep Consumption Time: 2.45854
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.59438

Cumulative Model Updates: 107,782
Cumulative Timesteps: 898,881,332

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 898881332...
Checkpoint 898881332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.17656
Policy Entropy: 3.12187
Value Function Loss: 0.00500

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.58123
Value Function Update Magnitude: 0.66373

Collected Steps per Second: 22,445.42587
Overall Steps per Second: 10,752.13893

Timestep Collection Time: 2.22825
Timestep Consumption Time: 2.42329
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.65154

Cumulative Model Updates: 107,788
Cumulative Timesteps: 898,931,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 864.02114
Policy Entropy: 3.12951
Value Function Loss: 0.00476

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09032
Policy Update Magnitude: 0.56782
Value Function Update Magnitude: 0.63409

Collected Steps per Second: 22,905.39146
Overall Steps per Second: 10,763.33627

Timestep Collection Time: 2.18298
Timestep Consumption Time: 2.46261
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.64559

Cumulative Model Updates: 107,794
Cumulative Timesteps: 898,981,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 898981348...
Checkpoint 898981348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.20201
Policy Entropy: 3.13258
Value Function Loss: 0.00472

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08701
Policy Update Magnitude: 0.55211
Value Function Update Magnitude: 0.62589

Collected Steps per Second: 22,834.99379
Overall Steps per Second: 10,716.68093

Timestep Collection Time: 2.19015
Timestep Consumption Time: 2.47660
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.66674

Cumulative Model Updates: 107,800
Cumulative Timesteps: 899,031,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,645.00408
Policy Entropy: 3.13188
Value Function Loss: 0.00499

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.08982
Policy Update Magnitude: 0.56187
Value Function Update Magnitude: 0.62365

Collected Steps per Second: 23,042.65060
Overall Steps per Second: 10,801.08275

Timestep Collection Time: 2.17102
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.63157

Cumulative Model Updates: 107,806
Cumulative Timesteps: 899,081,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 899081386...
Checkpoint 899081386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.64525
Policy Entropy: 3.14153
Value Function Loss: 0.00501

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.08806
Policy Update Magnitude: 0.56514
Value Function Update Magnitude: 0.63216

Collected Steps per Second: 22,879.28420
Overall Steps per Second: 10,730.69578

Timestep Collection Time: 2.18678
Timestep Consumption Time: 2.47573
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.66251

Cumulative Model Updates: 107,812
Cumulative Timesteps: 899,131,418

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,170.35083
Policy Entropy: 3.14433
Value Function Loss: 0.00473

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08463
Policy Update Magnitude: 0.55845
Value Function Update Magnitude: 0.62702

Collected Steps per Second: 22,885.38641
Overall Steps per Second: 10,704.87686

Timestep Collection Time: 2.18524
Timestep Consumption Time: 2.48647
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.67170

Cumulative Model Updates: 107,818
Cumulative Timesteps: 899,181,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 899181428...
Checkpoint 899181428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 779.39685
Policy Entropy: 3.13301
Value Function Loss: 0.00484

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.55989
Value Function Update Magnitude: 0.61742

Collected Steps per Second: 22,933.77839
Overall Steps per Second: 10,802.94252

Timestep Collection Time: 2.18193
Timestep Consumption Time: 2.45014
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.63207

Cumulative Model Updates: 107,824
Cumulative Timesteps: 899,231,468

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.22390
Policy Entropy: 3.11750
Value Function Loss: 0.00482

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.56818
Value Function Update Magnitude: 0.61799

Collected Steps per Second: 22,857.42915
Overall Steps per Second: 10,691.00378

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.48946
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.67702

Cumulative Model Updates: 107,830
Cumulative Timesteps: 899,281,470

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 899281470...
Checkpoint 899281470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.16630
Policy Entropy: 3.11103
Value Function Loss: 0.00481

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.56447
Value Function Update Magnitude: 0.62385

Collected Steps per Second: 22,569.13031
Overall Steps per Second: 10,632.05834

Timestep Collection Time: 2.21674
Timestep Consumption Time: 2.48884
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.70558

Cumulative Model Updates: 107,836
Cumulative Timesteps: 899,331,500

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.51445
Policy Entropy: 3.11304
Value Function Loss: 0.00497

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11387
Policy Update Magnitude: 0.56658
Value Function Update Magnitude: 0.62468

Collected Steps per Second: 23,210.24160
Overall Steps per Second: 10,717.23375

Timestep Collection Time: 2.15543
Timestep Consumption Time: 2.51257
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.66800

Cumulative Model Updates: 107,842
Cumulative Timesteps: 899,381,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 899381528...
Checkpoint 899381528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 696.12530
Policy Entropy: 3.09894
Value Function Loss: 0.00503

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.57807
Value Function Update Magnitude: 0.64279

Collected Steps per Second: 22,767.60597
Overall Steps per Second: 10,657.10240

Timestep Collection Time: 2.19698
Timestep Consumption Time: 2.49660
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.69358

Cumulative Model Updates: 107,848
Cumulative Timesteps: 899,431,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.60772
Policy Entropy: 3.08693
Value Function Loss: 0.00506

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.58418
Value Function Update Magnitude: 0.65746

Collected Steps per Second: 23,164.52245
Overall Steps per Second: 10,852.90997

Timestep Collection Time: 2.15856
Timestep Consumption Time: 2.44868
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.60724

Cumulative Model Updates: 107,854
Cumulative Timesteps: 899,481,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 899481550...
Checkpoint 899481550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.42916
Policy Entropy: 3.08189
Value Function Loss: 0.00499

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11163
Policy Update Magnitude: 0.57928
Value Function Update Magnitude: 0.66618

Collected Steps per Second: 22,695.52470
Overall Steps per Second: 10,737.79896

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.45376
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.65719

Cumulative Model Updates: 107,860
Cumulative Timesteps: 899,531,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 918.87489
Policy Entropy: 3.09518
Value Function Loss: 0.00476

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.57697
Value Function Update Magnitude: 0.66378

Collected Steps per Second: 23,037.68610
Overall Steps per Second: 10,776.17083

Timestep Collection Time: 2.17123
Timestep Consumption Time: 2.47050
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.64172

Cumulative Model Updates: 107,866
Cumulative Timesteps: 899,581,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 899581578...
Checkpoint 899581578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.88866
Policy Entropy: 3.09566
Value Function Loss: 0.00468

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.64220

Collected Steps per Second: 22,918.97150
Overall Steps per Second: 10,720.84423

Timestep Collection Time: 2.18273
Timestep Consumption Time: 2.48350
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.66624

Cumulative Model Updates: 107,872
Cumulative Timesteps: 899,631,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 818.69032
Policy Entropy: 3.09517
Value Function Loss: 0.00477

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08666
Policy Update Magnitude: 0.56065
Value Function Update Magnitude: 0.62621

Collected Steps per Second: 22,937.91248
Overall Steps per Second: 10,785.98477

Timestep Collection Time: 2.18102
Timestep Consumption Time: 2.45722
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.63824

Cumulative Model Updates: 107,878
Cumulative Timesteps: 899,681,632

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 899681632...
Checkpoint 899681632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.05952
Policy Entropy: 3.08986
Value Function Loss: 0.00495

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10773
Policy Update Magnitude: 0.56782
Value Function Update Magnitude: 0.62174

Collected Steps per Second: 22,582.67778
Overall Steps per Second: 10,727.78022

Timestep Collection Time: 2.21533
Timestep Consumption Time: 2.44808
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.66341

Cumulative Model Updates: 107,884
Cumulative Timesteps: 899,731,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 798.47261
Policy Entropy: 3.08885
Value Function Loss: 0.00482

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.56725
Value Function Update Magnitude: 0.61593

Collected Steps per Second: 22,561.47359
Overall Steps per Second: 10,511.15276

Timestep Collection Time: 2.21750
Timestep Consumption Time: 2.54221
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.75971

Cumulative Model Updates: 107,890
Cumulative Timesteps: 899,781,690

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 899781690...
Checkpoint 899781690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.51303
Policy Entropy: 3.08903
Value Function Loss: 0.00495

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.57515
Value Function Update Magnitude: 0.61086

Collected Steps per Second: 22,736.04055
Overall Steps per Second: 10,622.46687

Timestep Collection Time: 2.19942
Timestep Consumption Time: 2.50815
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.70757

Cumulative Model Updates: 107,896
Cumulative Timesteps: 899,831,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.60611
Policy Entropy: 3.07562
Value Function Loss: 0.00478

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.57428
Value Function Update Magnitude: 0.61789

Collected Steps per Second: 23,181.43135
Overall Steps per Second: 10,816.44788

Timestep Collection Time: 2.15811
Timestep Consumption Time: 2.46707
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.62518

Cumulative Model Updates: 107,902
Cumulative Timesteps: 899,881,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 899881724...
Checkpoint 899881724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.29991
Policy Entropy: 3.05031
Value Function Loss: 0.00508

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.58063
Value Function Update Magnitude: 0.63260

Collected Steps per Second: 22,261.17314
Overall Steps per Second: 10,645.36278

Timestep Collection Time: 2.24750
Timestep Consumption Time: 2.45239
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.69989

Cumulative Model Updates: 107,908
Cumulative Timesteps: 899,931,756

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 790.15542
Policy Entropy: 3.06867
Value Function Loss: 0.00498

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10458
Policy Update Magnitude: 0.58364
Value Function Update Magnitude: 0.62241

Collected Steps per Second: 23,003.16420
Overall Steps per Second: 10,699.52568

Timestep Collection Time: 2.17379
Timestep Consumption Time: 2.49969
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.67348

Cumulative Model Updates: 107,914
Cumulative Timesteps: 899,981,760

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 899981760...
Checkpoint 899981760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651.47246
Policy Entropy: 3.08210
Value Function Loss: 0.00510

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11853
Policy Update Magnitude: 0.58070
Value Function Update Magnitude: 0.60760

Collected Steps per Second: 22,821.07893
Overall Steps per Second: 10,676.05409

Timestep Collection Time: 2.19122
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.68394

Cumulative Model Updates: 107,920
Cumulative Timesteps: 900,031,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.03839
Policy Entropy: 3.08581
Value Function Loss: 0.00538

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.58285
Value Function Update Magnitude: 0.60721

Collected Steps per Second: 23,420.42797
Overall Steps per Second: 10,752.35959

Timestep Collection Time: 2.13489
Timestep Consumption Time: 2.51525
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.65014

Cumulative Model Updates: 107,926
Cumulative Timesteps: 900,081,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 900081766...
Checkpoint 900081766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.85235
Policy Entropy: 3.08280
Value Function Loss: 0.00528

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12490
Policy Update Magnitude: 0.58954
Value Function Update Magnitude: 0.63213

Collected Steps per Second: 22,493.21915
Overall Steps per Second: 10,634.74372

Timestep Collection Time: 2.22325
Timestep Consumption Time: 2.47908
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.70232

Cumulative Model Updates: 107,932
Cumulative Timesteps: 900,131,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.34597
Policy Entropy: 3.07498
Value Function Loss: 0.00508

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.58001
Value Function Update Magnitude: 0.64087

Collected Steps per Second: 23,111.90629
Overall Steps per Second: 10,801.78254

Timestep Collection Time: 2.16460
Timestep Consumption Time: 2.46686
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.63146

Cumulative Model Updates: 107,938
Cumulative Timesteps: 900,181,802

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 900181802...
Checkpoint 900181802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.08294
Policy Entropy: 3.09733
Value Function Loss: 0.00497

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.57045
Value Function Update Magnitude: 0.63364

Collected Steps per Second: 22,774.08990
Overall Steps per Second: 10,748.83985

Timestep Collection Time: 2.19679
Timestep Consumption Time: 2.45766
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.65446

Cumulative Model Updates: 107,944
Cumulative Timesteps: 900,231,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.96087
Policy Entropy: 3.09419
Value Function Loss: 0.00469

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10257
Policy Update Magnitude: 0.56898
Value Function Update Magnitude: 0.62228

Collected Steps per Second: 23,253.32866
Overall Steps per Second: 10,857.51208

Timestep Collection Time: 2.15126
Timestep Consumption Time: 2.45606
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.60732

Cumulative Model Updates: 107,950
Cumulative Timesteps: 900,281,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 900281856...
Checkpoint 900281856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.59125
Policy Entropy: 3.08213
Value Function Loss: 0.00483

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09879
Policy Update Magnitude: 0.57055
Value Function Update Magnitude: 0.62286

Collected Steps per Second: 22,717.91435
Overall Steps per Second: 10,675.53355

Timestep Collection Time: 2.20099
Timestep Consumption Time: 2.48280
PPO Batch Consumption Time: 0.28952
Total Iteration Time: 4.68379

Cumulative Model Updates: 107,956
Cumulative Timesteps: 900,331,858

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.91452
Policy Entropy: 3.08805
Value Function Loss: 0.00463

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.57120
Value Function Update Magnitude: 0.61511

Collected Steps per Second: 23,040.19948
Overall Steps per Second: 10,819.10702

Timestep Collection Time: 2.17012
Timestep Consumption Time: 2.45133
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.62145

Cumulative Model Updates: 107,962
Cumulative Timesteps: 900,381,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 900381858...
Checkpoint 900381858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.24232
Policy Entropy: 3.08136
Value Function Loss: 0.00506

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.57611
Value Function Update Magnitude: 0.60859

Collected Steps per Second: 22,885.30971
Overall Steps per Second: 10,694.39089

Timestep Collection Time: 2.18551
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.67684

Cumulative Model Updates: 107,968
Cumulative Timesteps: 900,431,874

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.20991
Policy Entropy: 3.09597
Value Function Loss: 0.00520

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09581
Policy Update Magnitude: 0.58155
Value Function Update Magnitude: 0.62539

Collected Steps per Second: 22,931.87034
Overall Steps per Second: 10,713.31486

Timestep Collection Time: 2.18124
Timestep Consumption Time: 2.48771
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.66896

Cumulative Model Updates: 107,974
Cumulative Timesteps: 900,481,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 900481894...
Checkpoint 900481894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.23356
Policy Entropy: 3.09166
Value Function Loss: 0.00518

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.57759
Value Function Update Magnitude: 0.65162

Collected Steps per Second: 22,517.56458
Overall Steps per Second: 10,594.88354

Timestep Collection Time: 2.22093
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.72020

Cumulative Model Updates: 107,980
Cumulative Timesteps: 900,531,904

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.64931
Policy Entropy: 3.08469
Value Function Loss: 0.00504

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.57949
Value Function Update Magnitude: 0.63207

Collected Steps per Second: 23,283.45710
Overall Steps per Second: 10,724.22153

Timestep Collection Time: 2.14848
Timestep Consumption Time: 2.51610
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.66458

Cumulative Model Updates: 107,986
Cumulative Timesteps: 900,581,928

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 900581928...
Checkpoint 900581928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.81766
Policy Entropy: 3.08122
Value Function Loss: 0.00536

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.58862
Value Function Update Magnitude: 0.63593

Collected Steps per Second: 22,324.26925
Overall Steps per Second: 10,656.15671

Timestep Collection Time: 2.24025
Timestep Consumption Time: 2.45300
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.69325

Cumulative Model Updates: 107,992
Cumulative Timesteps: 900,631,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.74511
Policy Entropy: 3.09353
Value Function Loss: 0.00509

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.58219
Value Function Update Magnitude: 0.63303

Collected Steps per Second: 23,119.25058
Overall Steps per Second: 10,819.29238

Timestep Collection Time: 2.16313
Timestep Consumption Time: 2.45917
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.62230

Cumulative Model Updates: 107,998
Cumulative Timesteps: 900,681,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 900681950...
Checkpoint 900681950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 663.98845
Policy Entropy: 3.11268
Value Function Loss: 0.00516

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.58124
Value Function Update Magnitude: 0.61313

Collected Steps per Second: 22,533.19288
Overall Steps per Second: 10,752.20215

Timestep Collection Time: 2.21904
Timestep Consumption Time: 2.43136
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.65040

Cumulative Model Updates: 108,004
Cumulative Timesteps: 900,731,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 779.86145
Policy Entropy: 3.10647
Value Function Loss: 0.00492

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.58468
Value Function Update Magnitude: 0.60316

Collected Steps per Second: 22,904.13851
Overall Steps per Second: 10,822.38927

Timestep Collection Time: 2.18345
Timestep Consumption Time: 2.43753
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.62098

Cumulative Model Updates: 108,010
Cumulative Timesteps: 900,781,962

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 900781962...
Checkpoint 900781962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.84921
Policy Entropy: 3.09977
Value Function Loss: 0.00487

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09452
Policy Update Magnitude: 0.58130
Value Function Update Magnitude: 0.59314

Collected Steps per Second: 22,868.76675
Overall Steps per Second: 10,649.52683

Timestep Collection Time: 2.18761
Timestep Consumption Time: 2.51006
PPO Batch Consumption Time: 0.29612
Total Iteration Time: 4.69767

Cumulative Model Updates: 108,016
Cumulative Timesteps: 900,831,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.69155
Policy Entropy: 3.10057
Value Function Loss: 0.00475

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.58064

Collected Steps per Second: 23,077.81402
Overall Steps per Second: 10,843.19524

Timestep Collection Time: 2.16710
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.61229

Cumulative Model Updates: 108,022
Cumulative Timesteps: 900,882,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 900882002...
Checkpoint 900882002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679.96685
Policy Entropy: 3.10926
Value Function Loss: 0.00481

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09786
Policy Update Magnitude: 0.56821
Value Function Update Magnitude: 0.58286

Collected Steps per Second: 22,498.80933
Overall Steps per Second: 10,779.67245

Timestep Collection Time: 2.22270
Timestep Consumption Time: 2.41641
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.63910

Cumulative Model Updates: 108,028
Cumulative Timesteps: 900,932,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,060.41300
Policy Entropy: 3.10547
Value Function Loss: 0.00470

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10996
Policy Update Magnitude: 0.57104
Value Function Update Magnitude: 0.58184

Collected Steps per Second: 23,012.55885
Overall Steps per Second: 10,884.90111

Timestep Collection Time: 2.17316
Timestep Consumption Time: 2.42128
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.59444

Cumulative Model Updates: 108,034
Cumulative Timesteps: 900,982,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 900982020...
Checkpoint 900982020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,278.89149
Policy Entropy: 3.10373
Value Function Loss: 0.00460

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10113
Policy Update Magnitude: 0.56034
Value Function Update Magnitude: 0.56639

Collected Steps per Second: 22,833.30373
Overall Steps per Second: 10,676.22214

Timestep Collection Time: 2.19040
Timestep Consumption Time: 2.49422
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.68462

Cumulative Model Updates: 108,040
Cumulative Timesteps: 901,032,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.98349
Policy Entropy: 3.11313
Value Function Loss: 0.00474

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 0.55922
Value Function Update Magnitude: 0.57189

Collected Steps per Second: 22,859.35441
Overall Steps per Second: 10,838.54862

Timestep Collection Time: 2.18799
Timestep Consumption Time: 2.42665
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.61464

Cumulative Model Updates: 108,046
Cumulative Timesteps: 901,082,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 901082050...
Checkpoint 901082050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,527.74068
Policy Entropy: 3.11239
Value Function Loss: 0.00466

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.56191
Value Function Update Magnitude: 0.56825

Collected Steps per Second: 22,508.79739
Overall Steps per Second: 10,649.32541

Timestep Collection Time: 2.22171
Timestep Consumption Time: 2.47418
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.69588

Cumulative Model Updates: 108,052
Cumulative Timesteps: 901,132,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.13603
Policy Entropy: 3.11443
Value Function Loss: 0.00484

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10154
Policy Update Magnitude: 0.55376
Value Function Update Magnitude: 0.56510

Collected Steps per Second: 23,029.77741
Overall Steps per Second: 10,806.75488

Timestep Collection Time: 2.17232
Timestep Consumption Time: 2.45701
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.62933

Cumulative Model Updates: 108,058
Cumulative Timesteps: 901,182,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 901182086...
Checkpoint 901182086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.39467
Policy Entropy: 3.09465
Value Function Loss: 0.00473

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.54964
Value Function Update Magnitude: 0.58821

Collected Steps per Second: 22,598.61369
Overall Steps per Second: 10,681.78623

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.46844
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.68105

Cumulative Model Updates: 108,064
Cumulative Timesteps: 901,232,088

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,628.89399
Policy Entropy: 3.08335
Value Function Loss: 0.00458

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.55235
Value Function Update Magnitude: 0.61628

Collected Steps per Second: 23,179.26945
Overall Steps per Second: 10,683.78761

Timestep Collection Time: 2.15822
Timestep Consumption Time: 2.52420
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.68242

Cumulative Model Updates: 108,070
Cumulative Timesteps: 901,282,114

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 901282114...
Checkpoint 901282114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.14927
Policy Entropy: 3.09305
Value Function Loss: 0.00474

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.63271

Collected Steps per Second: 22,578.39736
Overall Steps per Second: 10,623.26511

Timestep Collection Time: 2.21521
Timestep Consumption Time: 2.49294
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.70816

Cumulative Model Updates: 108,076
Cumulative Timesteps: 901,332,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.28759
Policy Entropy: 3.08051
Value Function Loss: 0.00476

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11577
Policy Update Magnitude: 0.55797
Value Function Update Magnitude: 0.64688

Collected Steps per Second: 22,983.73147
Overall Steps per Second: 10,736.23149

Timestep Collection Time: 2.17545
Timestep Consumption Time: 2.48168
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.65713

Cumulative Model Updates: 108,082
Cumulative Timesteps: 901,382,130

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 901382130...
Checkpoint 901382130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,259.21747
Policy Entropy: 3.08619
Value Function Loss: 0.00481

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10119
Policy Update Magnitude: 0.56069
Value Function Update Magnitude: 0.63056

Collected Steps per Second: 22,844.48817
Overall Steps per Second: 10,687.85028

Timestep Collection Time: 2.18950
Timestep Consumption Time: 2.49039
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.67989

Cumulative Model Updates: 108,088
Cumulative Timesteps: 901,432,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 795.03600
Policy Entropy: 3.06810
Value Function Loss: 0.00484

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.56403
Value Function Update Magnitude: 0.60638

Collected Steps per Second: 22,888.04460
Overall Steps per Second: 10,815.58674

Timestep Collection Time: 2.18551
Timestep Consumption Time: 2.43948
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.62499

Cumulative Model Updates: 108,094
Cumulative Timesteps: 901,482,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 901482170...
Checkpoint 901482170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.94592
Policy Entropy: 3.07142
Value Function Loss: 0.00487

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.56697
Value Function Update Magnitude: 0.60204

Collected Steps per Second: 22,612.78904
Overall Steps per Second: 10,682.78166

Timestep Collection Time: 2.21167
Timestep Consumption Time: 2.46988
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.68155

Cumulative Model Updates: 108,100
Cumulative Timesteps: 901,532,182

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.79076
Policy Entropy: 3.06984
Value Function Loss: 0.00511

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.57553
Value Function Update Magnitude: 0.60848

Collected Steps per Second: 23,021.96543
Overall Steps per Second: 10,853.51212

Timestep Collection Time: 2.17314
Timestep Consumption Time: 2.43643
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.60957

Cumulative Model Updates: 108,106
Cumulative Timesteps: 901,582,212

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 901582212...
Checkpoint 901582212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.86348
Policy Entropy: 3.05526
Value Function Loss: 0.00532

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11475
Policy Update Magnitude: 0.59347
Value Function Update Magnitude: 0.65409

Collected Steps per Second: 22,835.45097
Overall Steps per Second: 10,680.65215

Timestep Collection Time: 2.19089
Timestep Consumption Time: 2.49328
PPO Batch Consumption Time: 0.29358
Total Iteration Time: 4.68417

Cumulative Model Updates: 108,112
Cumulative Timesteps: 901,632,242

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.62794
Policy Entropy: 3.04130
Value Function Loss: 0.00527

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.60265
Value Function Update Magnitude: 0.67003

Collected Steps per Second: 22,828.60221
Overall Steps per Second: 10,857.78758

Timestep Collection Time: 2.19076
Timestep Consumption Time: 2.41533
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.60609

Cumulative Model Updates: 108,118
Cumulative Timesteps: 901,682,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 901682254...
Checkpoint 901682254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.38016
Policy Entropy: 3.05240
Value Function Loss: 0.00539

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.11761
Policy Update Magnitude: 0.60254
Value Function Update Magnitude: 0.65007

Collected Steps per Second: 22,575.45511
Overall Steps per Second: 10,684.13655

Timestep Collection Time: 2.21559
Timestep Consumption Time: 2.46593
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.68152

Cumulative Model Updates: 108,124
Cumulative Timesteps: 901,732,272

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.20931
Policy Entropy: 3.06230
Value Function Loss: 0.00542

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11487
Policy Update Magnitude: 0.60015
Value Function Update Magnitude: 0.64410

Collected Steps per Second: 22,926.59776
Overall Steps per Second: 10,862.17452

Timestep Collection Time: 2.18166
Timestep Consumption Time: 2.42313
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.60479

Cumulative Model Updates: 108,130
Cumulative Timesteps: 901,782,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 901782290...
Checkpoint 901782290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.67522
Policy Entropy: 3.06307
Value Function Loss: 0.00533

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.59479
Value Function Update Magnitude: 0.65772

Collected Steps per Second: 22,599.28977
Overall Steps per Second: 10,720.03678

Timestep Collection Time: 2.21299
Timestep Consumption Time: 2.45229
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.66528

Cumulative Model Updates: 108,136
Cumulative Timesteps: 901,832,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.37544
Policy Entropy: 3.05658
Value Function Loss: 0.00496

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13640
Policy Update Magnitude: 0.58479
Value Function Update Magnitude: 0.65607

Collected Steps per Second: 23,050.94262
Overall Steps per Second: 10,856.16894

Timestep Collection Time: 2.17006
Timestep Consumption Time: 2.43764
PPO Batch Consumption Time: 0.28410
Total Iteration Time: 4.60770

Cumulative Model Updates: 108,142
Cumulative Timesteps: 901,882,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 901882324...
Checkpoint 901882324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.83518
Policy Entropy: 3.06611
Value Function Loss: 0.00494

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.14070
Policy Update Magnitude: 0.57892
Value Function Update Magnitude: 0.64682

Collected Steps per Second: 22,623.77442
Overall Steps per Second: 10,684.53494

Timestep Collection Time: 2.21113
Timestep Consumption Time: 2.47078
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.68191

Cumulative Model Updates: 108,148
Cumulative Timesteps: 901,932,348

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.70637
Policy Entropy: 3.10589
Value Function Loss: 0.00457

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.11769
Policy Update Magnitude: 0.56472
Value Function Update Magnitude: 0.62671

Collected Steps per Second: 22,970.74808
Overall Steps per Second: 10,819.02896

Timestep Collection Time: 2.17720
Timestep Consumption Time: 2.44539
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.62260

Cumulative Model Updates: 108,154
Cumulative Timesteps: 901,982,360

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 901982360...
Checkpoint 901982360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.81577
Policy Entropy: 3.10190
Value Function Loss: 0.00469

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.56081
Value Function Update Magnitude: 0.61626

Collected Steps per Second: 22,525.84696
Overall Steps per Second: 10,698.16261

Timestep Collection Time: 2.22012
Timestep Consumption Time: 2.45452
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.67463

Cumulative Model Updates: 108,160
Cumulative Timesteps: 902,032,370

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.05594
Policy Entropy: 3.10878
Value Function Loss: 0.00469

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.56533
Value Function Update Magnitude: 0.61448

Collected Steps per Second: 22,871.91253
Overall Steps per Second: 10,829.55101

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.43178
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.61866

Cumulative Model Updates: 108,166
Cumulative Timesteps: 902,082,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 902082388...
Checkpoint 902082388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.55270
Policy Entropy: 3.09092
Value Function Loss: 0.00513

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.57142
Value Function Update Magnitude: 0.61224

Collected Steps per Second: 22,439.92059
Overall Steps per Second: 10,766.46286

Timestep Collection Time: 2.22924
Timestep Consumption Time: 2.41704
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.64628

Cumulative Model Updates: 108,172
Cumulative Timesteps: 902,132,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,090.14536
Policy Entropy: 3.09251
Value Function Loss: 0.00515

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.57963
Value Function Update Magnitude: 0.62783

Collected Steps per Second: 22,650.00435
Overall Steps per Second: 10,772.42302

Timestep Collection Time: 2.20989
Timestep Consumption Time: 2.43660
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.64649

Cumulative Model Updates: 108,178
Cumulative Timesteps: 902,182,466

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 902182466...
Checkpoint 902182466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.95723
Policy Entropy: 3.08584
Value Function Loss: 0.00510

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.58036
Value Function Update Magnitude: 0.63754

Collected Steps per Second: 22,776.47613
Overall Steps per Second: 10,742.80295

Timestep Collection Time: 2.19525
Timestep Consumption Time: 2.45903
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.65428

Cumulative Model Updates: 108,184
Cumulative Timesteps: 902,232,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.74094
Policy Entropy: 3.09774
Value Function Loss: 0.00501

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.64542

Collected Steps per Second: 22,670.45073
Overall Steps per Second: 10,728.34165

Timestep Collection Time: 2.20613
Timestep Consumption Time: 2.45573
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.66186

Cumulative Model Updates: 108,190
Cumulative Timesteps: 902,282,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 902282480...
Checkpoint 902282480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.09266
Policy Entropy: 3.10748
Value Function Loss: 0.00492

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.56848
Value Function Update Magnitude: 0.63525

Collected Steps per Second: 22,667.29807
Overall Steps per Second: 10,806.00181

Timestep Collection Time: 2.20714
Timestep Consumption Time: 2.42269
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.62983

Cumulative Model Updates: 108,196
Cumulative Timesteps: 902,332,510

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.81818
Policy Entropy: 3.11781
Value Function Loss: 0.00498

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.56997
Value Function Update Magnitude: 0.61517

Collected Steps per Second: 23,027.08967
Overall Steps per Second: 10,896.46075

Timestep Collection Time: 2.17248
Timestep Consumption Time: 2.41855
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.59103

Cumulative Model Updates: 108,202
Cumulative Timesteps: 902,382,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 902382536...
Checkpoint 902382536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.04317
Policy Entropy: 3.12919
Value Function Loss: 0.00521

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.57456
Value Function Update Magnitude: 0.62374

Collected Steps per Second: 22,668.84386
Overall Steps per Second: 10,683.36081

Timestep Collection Time: 2.20602
Timestep Consumption Time: 2.47490
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.68092

Cumulative Model Updates: 108,208
Cumulative Timesteps: 902,432,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.48603
Policy Entropy: 3.12212
Value Function Loss: 0.00511

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.58305
Value Function Update Magnitude: 0.64790

Collected Steps per Second: 22,783.16730
Overall Steps per Second: 10,796.75403

Timestep Collection Time: 2.19504
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.63195

Cumulative Model Updates: 108,214
Cumulative Timesteps: 902,482,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 902482554...
Checkpoint 902482554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.70477
Policy Entropy: 3.11569
Value Function Loss: 0.00505

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.58281
Value Function Update Magnitude: 0.65415

Collected Steps per Second: 22,606.02024
Overall Steps per Second: 10,821.05179

Timestep Collection Time: 2.21242
Timestep Consumption Time: 2.40950
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.62192

Cumulative Model Updates: 108,220
Cumulative Timesteps: 902,532,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,424.38766
Policy Entropy: 3.10248
Value Function Loss: 0.00492

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.57779
Value Function Update Magnitude: 0.64356

Collected Steps per Second: 22,877.09661
Overall Steps per Second: 10,807.37833

Timestep Collection Time: 2.18585
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.62702

Cumulative Model Updates: 108,226
Cumulative Timesteps: 902,582,574

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 902582574...
Checkpoint 902582574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.67422
Policy Entropy: 3.10042
Value Function Loss: 0.00501

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.57803
Value Function Update Magnitude: 0.64024

Collected Steps per Second: 22,916.05257
Overall Steps per Second: 10,719.60525

Timestep Collection Time: 2.18310
Timestep Consumption Time: 2.48386
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.66696

Cumulative Model Updates: 108,232
Cumulative Timesteps: 902,632,602

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.21379
Policy Entropy: 3.08570
Value Function Loss: 0.00491

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10034
Policy Update Magnitude: 0.57341
Value Function Update Magnitude: 0.64592

Collected Steps per Second: 23,099.13716
Overall Steps per Second: 10,856.10380

Timestep Collection Time: 2.16571
Timestep Consumption Time: 2.44239
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.60810

Cumulative Model Updates: 108,238
Cumulative Timesteps: 902,682,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 902682628...
Checkpoint 902682628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.00101
Policy Entropy: 3.09662
Value Function Loss: 0.00491

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11381
Policy Update Magnitude: 0.56628
Value Function Update Magnitude: 0.62760

Collected Steps per Second: 22,672.01749
Overall Steps per Second: 10,677.41776

Timestep Collection Time: 2.20571
Timestep Consumption Time: 2.47781
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.68353

Cumulative Model Updates: 108,244
Cumulative Timesteps: 902,732,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.32402
Policy Entropy: 3.10337
Value Function Loss: 0.00513

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.56935
Value Function Update Magnitude: 0.61212

Collected Steps per Second: 22,994.65285
Overall Steps per Second: 10,839.07495

Timestep Collection Time: 2.17503
Timestep Consumption Time: 2.43920
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.61423

Cumulative Model Updates: 108,250
Cumulative Timesteps: 902,782,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 902782650...
Checkpoint 902782650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.16284
Policy Entropy: 3.10341
Value Function Loss: 0.00505

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.60751

Collected Steps per Second: 22,980.30152
Overall Steps per Second: 10,671.30126

Timestep Collection Time: 2.17578
Timestep Consumption Time: 2.50969
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.68546

Cumulative Model Updates: 108,256
Cumulative Timesteps: 902,832,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.02705
Policy Entropy: 3.11718
Value Function Loss: 0.00510

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10623
Policy Update Magnitude: 0.56882
Value Function Update Magnitude: 0.60692

Collected Steps per Second: 22,856.64154
Overall Steps per Second: 10,866.35491

Timestep Collection Time: 2.18851
Timestep Consumption Time: 2.41487
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.60338

Cumulative Model Updates: 108,262
Cumulative Timesteps: 902,882,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 902882672...
Checkpoint 902882672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.27896
Policy Entropy: 3.12201
Value Function Loss: 0.00492

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10015
Policy Update Magnitude: 0.57899
Value Function Update Magnitude: 0.60518

Collected Steps per Second: 22,784.60745
Overall Steps per Second: 10,740.61671

Timestep Collection Time: 2.19473
Timestep Consumption Time: 2.46106
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.65578

Cumulative Model Updates: 108,268
Cumulative Timesteps: 902,932,678

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.14545
Policy Entropy: 3.13765
Value Function Loss: 0.00490

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09699
Policy Update Magnitude: 0.57745
Value Function Update Magnitude: 0.60302

Collected Steps per Second: 22,789.81457
Overall Steps per Second: 10,833.84346

Timestep Collection Time: 2.19537
Timestep Consumption Time: 2.42275
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.61812

Cumulative Model Updates: 108,274
Cumulative Timesteps: 902,982,710

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 902982710...
Checkpoint 902982710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 859.67934
Policy Entropy: 3.14174
Value Function Loss: 0.00502

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.57125
Value Function Update Magnitude: 0.60407

Collected Steps per Second: 22,724.20211
Overall Steps per Second: 10,707.97731

Timestep Collection Time: 2.20047
Timestep Consumption Time: 2.46932
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.66979

Cumulative Model Updates: 108,280
Cumulative Timesteps: 903,032,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.81582
Policy Entropy: 3.13424
Value Function Loss: 0.00495

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.56691
Value Function Update Magnitude: 0.60185

Collected Steps per Second: 22,809.26306
Overall Steps per Second: 10,814.85691

Timestep Collection Time: 2.19244
Timestep Consumption Time: 2.43157
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.62401

Cumulative Model Updates: 108,286
Cumulative Timesteps: 903,082,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 903082722...
Checkpoint 903082722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808.08453
Policy Entropy: 3.13781
Value Function Loss: 0.00501

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.55614
Value Function Update Magnitude: 0.59764

Collected Steps per Second: 22,504.44568
Overall Steps per Second: 10,691.92460

Timestep Collection Time: 2.22249
Timestep Consumption Time: 2.45543
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.67792

Cumulative Model Updates: 108,292
Cumulative Timesteps: 903,132,738

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,725.93504
Policy Entropy: 3.11844
Value Function Loss: 0.00494

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.55820
Value Function Update Magnitude: 0.59935

Collected Steps per Second: 23,190.26671
Overall Steps per Second: 10,885.23832

Timestep Collection Time: 2.15634
Timestep Consumption Time: 2.43759
PPO Batch Consumption Time: 0.28311
Total Iteration Time: 4.59393

Cumulative Model Updates: 108,298
Cumulative Timesteps: 903,182,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 903182744...
Checkpoint 903182744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.40467
Policy Entropy: 3.10171
Value Function Loss: 0.00514

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.57007
Value Function Update Magnitude: 0.62010

Collected Steps per Second: 22,835.39695
Overall Steps per Second: 10,707.74633

Timestep Collection Time: 2.19081
Timestep Consumption Time: 2.48132
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.67213

Cumulative Model Updates: 108,304
Cumulative Timesteps: 903,232,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.94960
Policy Entropy: 3.09055
Value Function Loss: 0.00500

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10331
Policy Update Magnitude: 0.57172
Value Function Update Magnitude: 0.61845

Collected Steps per Second: 22,857.04359
Overall Steps per Second: 10,819.99014

Timestep Collection Time: 2.18751
Timestep Consumption Time: 2.43357
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.62108

Cumulative Model Updates: 108,310
Cumulative Timesteps: 903,282,772

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 903282772...
Checkpoint 903282772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.97463
Policy Entropy: 3.11025
Value Function Loss: 0.00497

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10431
Policy Update Magnitude: 0.57000
Value Function Update Magnitude: 0.58335

Collected Steps per Second: 22,692.97262
Overall Steps per Second: 10,734.87742

Timestep Collection Time: 2.20394
Timestep Consumption Time: 2.45508
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.65902

Cumulative Model Updates: 108,316
Cumulative Timesteps: 903,332,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.97172
Policy Entropy: 3.12009
Value Function Loss: 0.00477

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.08995
Policy Update Magnitude: 0.56281
Value Function Update Magnitude: 0.57285

Collected Steps per Second: 23,198.86631
Overall Steps per Second: 10,902.01622

Timestep Collection Time: 2.15657
Timestep Consumption Time: 2.43249
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.58906

Cumulative Model Updates: 108,322
Cumulative Timesteps: 903,382,816

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 903382816...
Checkpoint 903382816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.58553
Policy Entropy: 3.12428
Value Function Loss: 0.00505

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09637
Policy Update Magnitude: 0.56660
Value Function Update Magnitude: 0.57016

Collected Steps per Second: 23,053.93905
Overall Steps per Second: 10,679.19068

Timestep Collection Time: 2.16987
Timestep Consumption Time: 2.51438
PPO Batch Consumption Time: 0.29572
Total Iteration Time: 4.68425

Cumulative Model Updates: 108,328
Cumulative Timesteps: 903,432,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.62636
Policy Entropy: 3.12312
Value Function Loss: 0.00497

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.56876
Value Function Update Magnitude: 0.57505

Collected Steps per Second: 22,710.19053
Overall Steps per Second: 10,790.40563

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.43209
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.63375

Cumulative Model Updates: 108,334
Cumulative Timesteps: 903,482,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 903482840...
Checkpoint 903482840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.73961
Policy Entropy: 3.11658
Value Function Loss: 0.00523

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.58565

Collected Steps per Second: 22,904.94229
Overall Steps per Second: 10,716.88033

Timestep Collection Time: 2.18398
Timestep Consumption Time: 2.48379
PPO Batch Consumption Time: 0.28697
Total Iteration Time: 4.66778

Cumulative Model Updates: 108,340
Cumulative Timesteps: 903,532,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.22984
Policy Entropy: 3.11113
Value Function Loss: 0.00499

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10019
Policy Update Magnitude: 0.56432
Value Function Update Magnitude: 0.60744

Collected Steps per Second: 22,933.79271
Overall Steps per Second: 10,689.94846

Timestep Collection Time: 2.18150
Timestep Consumption Time: 2.49860
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.68010

Cumulative Model Updates: 108,346
Cumulative Timesteps: 903,582,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 903582894...
Checkpoint 903582894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.62678
Policy Entropy: 3.10094
Value Function Loss: 0.00519

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.57282
Value Function Update Magnitude: 0.62817

Collected Steps per Second: 23,137.83846
Overall Steps per Second: 10,851.47752

Timestep Collection Time: 2.16131
Timestep Consumption Time: 2.44710
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.60840

Cumulative Model Updates: 108,352
Cumulative Timesteps: 903,632,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.03283
Policy Entropy: 3.10543
Value Function Loss: 0.00498

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.58286
Value Function Update Magnitude: 0.63021

Collected Steps per Second: 23,016.09585
Overall Steps per Second: 10,881.52938

Timestep Collection Time: 2.17361
Timestep Consumption Time: 2.42391
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.59752

Cumulative Model Updates: 108,358
Cumulative Timesteps: 903,682,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 903682930...
Checkpoint 903682930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.92982
Policy Entropy: 3.10757
Value Function Loss: 0.00486

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.57545
Value Function Update Magnitude: 0.62345

Collected Steps per Second: 22,514.12027
Overall Steps per Second: 10,668.74980

Timestep Collection Time: 2.22189
Timestep Consumption Time: 2.46694
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.68883

Cumulative Model Updates: 108,364
Cumulative Timesteps: 903,732,954

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.78684
Policy Entropy: 3.10402
Value Function Loss: 0.00453

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.56168
Value Function Update Magnitude: 0.61181

Collected Steps per Second: 23,121.57226
Overall Steps per Second: 10,846.34578

Timestep Collection Time: 2.16248
Timestep Consumption Time: 2.44736
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.60985

Cumulative Model Updates: 108,370
Cumulative Timesteps: 903,782,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 903782954...
Checkpoint 903782954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,366.95193
Policy Entropy: 3.09920
Value Function Loss: 0.00433

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08839
Policy Update Magnitude: 0.55844
Value Function Update Magnitude: 0.60042

Collected Steps per Second: 22,759.50412
Overall Steps per Second: 10,727.18458

Timestep Collection Time: 2.19803
Timestep Consumption Time: 2.46545
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.66348

Cumulative Model Updates: 108,376
Cumulative Timesteps: 903,832,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,091.55184
Policy Entropy: 3.11177
Value Function Loss: 0.00488

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.55839
Value Function Update Magnitude: 0.61141

Collected Steps per Second: 22,608.70965
Overall Steps per Second: 10,781.37899

Timestep Collection Time: 2.21198
Timestep Consumption Time: 2.42657
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.63855

Cumulative Model Updates: 108,382
Cumulative Timesteps: 903,882,990

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 903882990...
Checkpoint 903882990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 891.00433
Policy Entropy: 3.12263
Value Function Loss: 0.00503

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.61729

Collected Steps per Second: 22,309.37387
Overall Steps per Second: 10,717.71655

Timestep Collection Time: 2.24220
Timestep Consumption Time: 2.42503
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.66723

Cumulative Model Updates: 108,388
Cumulative Timesteps: 903,933,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.52220
Policy Entropy: 3.11926
Value Function Loss: 0.00529

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.63004

Collected Steps per Second: 22,909.43192
Overall Steps per Second: 10,835.43659

Timestep Collection Time: 2.18390
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.61744

Cumulative Model Updates: 108,394
Cumulative Timesteps: 903,983,044

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 903983044...
Checkpoint 903983044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,449.15674
Policy Entropy: 3.11641
Value Function Loss: 0.00476

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.57113
Value Function Update Magnitude: 0.63128

Collected Steps per Second: 22,924.64297
Overall Steps per Second: 10,745.67062

Timestep Collection Time: 2.18219
Timestep Consumption Time: 2.47326
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.65546

Cumulative Model Updates: 108,400
Cumulative Timesteps: 904,033,070

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.48314
Policy Entropy: 3.12457
Value Function Loss: 0.00469

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12181
Policy Update Magnitude: 0.56842
Value Function Update Magnitude: 0.63551

Collected Steps per Second: 22,766.19614
Overall Steps per Second: 10,827.38428

Timestep Collection Time: 2.19721
Timestep Consumption Time: 2.42275
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.61995

Cumulative Model Updates: 108,406
Cumulative Timesteps: 904,083,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 904083092...
Checkpoint 904083092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.63137
Policy Entropy: 3.13947
Value Function Loss: 0.00482

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.12687
Policy Update Magnitude: 0.56129
Value Function Update Magnitude: 0.63845

Collected Steps per Second: 22,653.53058
Overall Steps per Second: 10,740.52675

Timestep Collection Time: 2.20831
Timestep Consumption Time: 2.44938
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.65769

Cumulative Model Updates: 108,412
Cumulative Timesteps: 904,133,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.23883
Policy Entropy: 3.13235
Value Function Loss: 0.00476

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11624
Policy Update Magnitude: 0.55628
Value Function Update Magnitude: 0.63109

Collected Steps per Second: 23,046.93154
Overall Steps per Second: 10,825.75017

Timestep Collection Time: 2.16992
Timestep Consumption Time: 2.44962
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.61954

Cumulative Model Updates: 108,418
Cumulative Timesteps: 904,183,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 904183128...
Checkpoint 904183128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.19876
Policy Entropy: 3.13330
Value Function Loss: 0.00470

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.55643
Value Function Update Magnitude: 0.63010

Collected Steps per Second: 22,836.12759
Overall Steps per Second: 10,704.73014

Timestep Collection Time: 2.18986
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.67158

Cumulative Model Updates: 108,424
Cumulative Timesteps: 904,233,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.32065
Policy Entropy: 3.11684
Value Function Loss: 0.00476

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.57092
Value Function Update Magnitude: 0.64144

Collected Steps per Second: 22,622.80172
Overall Steps per Second: 10,711.65588

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.45775
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.66800

Cumulative Model Updates: 108,430
Cumulative Timesteps: 904,283,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 904283138...
Checkpoint 904283138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.47673
Policy Entropy: 3.14604
Value Function Loss: 0.00489

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09420
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.65533

Collected Steps per Second: 22,649.95711
Overall Steps per Second: 10,794.25895

Timestep Collection Time: 2.20777
Timestep Consumption Time: 2.42487
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.63265

Cumulative Model Updates: 108,436
Cumulative Timesteps: 904,333,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712.41108
Policy Entropy: 3.13667
Value Function Loss: 0.00499

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.57241
Value Function Update Magnitude: 0.65390

Collected Steps per Second: 23,258.43603
Overall Steps per Second: 10,887.41627

Timestep Collection Time: 2.15079
Timestep Consumption Time: 2.44387
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.59466

Cumulative Model Updates: 108,442
Cumulative Timesteps: 904,383,168

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 904383168...
Checkpoint 904383168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.79239
Policy Entropy: 3.14699
Value Function Loss: 0.00469

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.56526
Value Function Update Magnitude: 0.64878

Collected Steps per Second: 22,791.33120
Overall Steps per Second: 10,686.94286

Timestep Collection Time: 2.19487
Timestep Consumption Time: 2.48598
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.68085

Cumulative Model Updates: 108,448
Cumulative Timesteps: 904,433,192

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.51037
Policy Entropy: 3.13514
Value Function Loss: 0.00475

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09640
Policy Update Magnitude: 0.55491
Value Function Update Magnitude: 0.63239

Collected Steps per Second: 23,011.10232
Overall Steps per Second: 10,840.95613

Timestep Collection Time: 2.17417
Timestep Consumption Time: 2.44074
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.61491

Cumulative Model Updates: 108,454
Cumulative Timesteps: 904,483,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 904483222...
Checkpoint 904483222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.91343
Policy Entropy: 3.14278
Value Function Loss: 0.00492

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09096
Policy Update Magnitude: 0.56054
Value Function Update Magnitude: 0.63999

Collected Steps per Second: 22,152.51988
Overall Steps per Second: 10,666.51586

Timestep Collection Time: 2.25798
Timestep Consumption Time: 2.43146
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.68944

Cumulative Model Updates: 108,460
Cumulative Timesteps: 904,533,242

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.71155
Policy Entropy: 3.12709
Value Function Loss: 0.00523

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.57495
Value Function Update Magnitude: 0.63987

Collected Steps per Second: 22,940.31432
Overall Steps per Second: 10,706.48343

Timestep Collection Time: 2.18053
Timestep Consumption Time: 2.49159
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.67212

Cumulative Model Updates: 108,466
Cumulative Timesteps: 904,583,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 904583264...
Checkpoint 904583264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 906.98162
Policy Entropy: 3.12305
Value Function Loss: 0.00519

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10276
Policy Update Magnitude: 0.58087
Value Function Update Magnitude: 0.65238

Collected Steps per Second: 22,961.76363
Overall Steps per Second: 10,845.22439

Timestep Collection Time: 2.17849
Timestep Consumption Time: 2.43386
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.61235

Cumulative Model Updates: 108,472
Cumulative Timesteps: 904,633,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.51147
Policy Entropy: 3.11635
Value Function Loss: 0.00492

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.56809
Value Function Update Magnitude: 0.63858

Collected Steps per Second: 22,563.01020
Overall Steps per Second: 10,551.45183

Timestep Collection Time: 2.21717
Timestep Consumption Time: 2.52398
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.74115

Cumulative Model Updates: 108,478
Cumulative Timesteps: 904,683,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 904683312...
Checkpoint 904683312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,639.02696
Policy Entropy: 3.10892
Value Function Loss: 0.00496

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.56609
Value Function Update Magnitude: 0.61291

Collected Steps per Second: 22,643.27821
Overall Steps per Second: 10,602.78175

Timestep Collection Time: 2.20940
Timestep Consumption Time: 2.50899
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.71838

Cumulative Model Updates: 108,484
Cumulative Timesteps: 904,733,340

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.43908
Policy Entropy: 3.11241
Value Function Loss: 0.00480

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09815
Policy Update Magnitude: 0.56728
Value Function Update Magnitude: 0.60929

Collected Steps per Second: 22,654.68777
Overall Steps per Second: 10,694.35159

Timestep Collection Time: 2.20723
Timestep Consumption Time: 2.46851
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.67574

Cumulative Model Updates: 108,490
Cumulative Timesteps: 904,783,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 904783344...
Checkpoint 904783344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.04398
Policy Entropy: 3.09895
Value Function Loss: 0.00486

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.55453
Value Function Update Magnitude: 0.60433

Collected Steps per Second: 22,893.11252
Overall Steps per Second: 10,839.31412

Timestep Collection Time: 2.18476
Timestep Consumption Time: 2.42955
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.61431

Cumulative Model Updates: 108,496
Cumulative Timesteps: 904,833,360

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.32395
Policy Entropy: 3.09311
Value Function Loss: 0.00487

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.55504
Value Function Update Magnitude: 0.59446

Collected Steps per Second: 22,625.60448
Overall Steps per Second: 10,726.30197

Timestep Collection Time: 2.21006
Timestep Consumption Time: 2.45175
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.66181

Cumulative Model Updates: 108,502
Cumulative Timesteps: 904,883,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 904883364...
Checkpoint 904883364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.46773
Policy Entropy: 3.09131
Value Function Loss: 0.00452

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.55099
Value Function Update Magnitude: 0.58923

Collected Steps per Second: 22,788.08502
Overall Steps per Second: 10,811.56679

Timestep Collection Time: 2.19483
Timestep Consumption Time: 2.43133
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.62616

Cumulative Model Updates: 108,508
Cumulative Timesteps: 904,933,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.57647
Policy Entropy: 3.09907
Value Function Loss: 0.00446

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08832
Policy Update Magnitude: 0.54771
Value Function Update Magnitude: 0.56661

Collected Steps per Second: 22,895.44528
Overall Steps per Second: 10,837.45164

Timestep Collection Time: 2.18454
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.61511

Cumulative Model Updates: 108,514
Cumulative Timesteps: 904,983,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 904983396...
Checkpoint 904983396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.16021
Policy Entropy: 3.11189
Value Function Loss: 0.00448

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.54710
Value Function Update Magnitude: 0.55169

Collected Steps per Second: 22,637.90543
Overall Steps per Second: 10,795.19509

Timestep Collection Time: 2.20886
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.63206

Cumulative Model Updates: 108,520
Cumulative Timesteps: 905,033,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.89804
Policy Entropy: 3.10423
Value Function Loss: 0.00478

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.54995
Value Function Update Magnitude: 0.54842

Collected Steps per Second: 23,112.91510
Overall Steps per Second: 10,905.21576

Timestep Collection Time: 2.16390
Timestep Consumption Time: 2.42235
PPO Batch Consumption Time: 0.28027
Total Iteration Time: 4.58625

Cumulative Model Updates: 108,526
Cumulative Timesteps: 905,083,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 905083414...
Checkpoint 905083414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.13205
Policy Entropy: 3.10167
Value Function Loss: 0.00516

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.56047
Value Function Update Magnitude: 0.58431

Collected Steps per Second: 22,642.07624
Overall Steps per Second: 10,626.94424

Timestep Collection Time: 2.20898
Timestep Consumption Time: 2.49754
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.70653

Cumulative Model Updates: 108,532
Cumulative Timesteps: 905,133,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,322.83932
Policy Entropy: 3.10294
Value Function Loss: 0.00512

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.56799
Value Function Update Magnitude: 0.61604

Collected Steps per Second: 22,934.70059
Overall Steps per Second: 10,831.42915

Timestep Collection Time: 2.18045
Timestep Consumption Time: 2.43648
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.61693

Cumulative Model Updates: 108,538
Cumulative Timesteps: 905,183,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 905183438...
Checkpoint 905183438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.74650
Policy Entropy: 3.10099
Value Function Loss: 0.00484

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11225
Policy Update Magnitude: 0.56606
Value Function Update Magnitude: 0.61039

Collected Steps per Second: 22,756.58079
Overall Steps per Second: 10,641.94728

Timestep Collection Time: 2.19805
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.70027

Cumulative Model Updates: 108,544
Cumulative Timesteps: 905,233,458

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.07826
Policy Entropy: 3.09543
Value Function Loss: 0.00498

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10629
Policy Update Magnitude: 0.56620
Value Function Update Magnitude: 0.58892

Collected Steps per Second: 22,474.98480
Overall Steps per Second: 10,539.17450

Timestep Collection Time: 2.22550
Timestep Consumption Time: 2.52042
PPO Batch Consumption Time: 0.29649
Total Iteration Time: 4.74591

Cumulative Model Updates: 108,550
Cumulative Timesteps: 905,283,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 905283476...
Checkpoint 905283476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.60448
Policy Entropy: 3.08922
Value Function Loss: 0.00519

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.57718

Collected Steps per Second: 22,934.40691
Overall Steps per Second: 10,732.58708

Timestep Collection Time: 2.18013
Timestep Consumption Time: 2.47858
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.65871

Cumulative Model Updates: 108,556
Cumulative Timesteps: 905,333,476

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.17931
Policy Entropy: 3.09274
Value Function Loss: 0.00531

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09489
Policy Update Magnitude: 0.57727
Value Function Update Magnitude: 0.57974

Collected Steps per Second: 22,860.45994
Overall Steps per Second: 10,788.87578

Timestep Collection Time: 2.18849
Timestep Consumption Time: 2.44869
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.63718

Cumulative Model Updates: 108,562
Cumulative Timesteps: 905,383,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 905383506...
Checkpoint 905383506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.45608
Policy Entropy: 3.08806
Value Function Loss: 0.00472

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.57083
Value Function Update Magnitude: 0.57337

Collected Steps per Second: 22,712.66445
Overall Steps per Second: 10,637.62116

Timestep Collection Time: 2.20221
Timestep Consumption Time: 2.49978
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.70199

Cumulative Model Updates: 108,568
Cumulative Timesteps: 905,433,524

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,982.51199
Policy Entropy: 3.10339
Value Function Loss: 0.00478

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11126
Policy Update Magnitude: 0.56481
Value Function Update Magnitude: 0.58176

Collected Steps per Second: 22,738.16093
Overall Steps per Second: 10,807.26085

Timestep Collection Time: 2.19921
Timestep Consumption Time: 2.42786
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.62707

Cumulative Model Updates: 108,574
Cumulative Timesteps: 905,483,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 905483530...
Checkpoint 905483530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,504.09414
Policy Entropy: 3.10109
Value Function Loss: 0.00460

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10591
Policy Update Magnitude: 0.56204
Value Function Update Magnitude: 0.57789

Collected Steps per Second: 22,820.98552
Overall Steps per Second: 10,698.59530

Timestep Collection Time: 2.19175
Timestep Consumption Time: 2.48344
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.67519

Cumulative Model Updates: 108,580
Cumulative Timesteps: 905,533,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.67921
Policy Entropy: 3.10506
Value Function Loss: 0.00466

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.55778
Value Function Update Magnitude: 0.58155

Collected Steps per Second: 22,823.19749
Overall Steps per Second: 10,816.16891

Timestep Collection Time: 2.19102
Timestep Consumption Time: 2.43225
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.62326

Cumulative Model Updates: 108,586
Cumulative Timesteps: 905,583,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 905583554...
Checkpoint 905583554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,149.55512
Policy Entropy: 3.09456
Value Function Loss: 0.00475

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.55908
Value Function Update Magnitude: 0.58235

Collected Steps per Second: 22,859.64924
Overall Steps per Second: 10,764.01985

Timestep Collection Time: 2.18779
Timestep Consumption Time: 2.45843
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.64622

Cumulative Model Updates: 108,592
Cumulative Timesteps: 905,633,566

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 976.56148
Policy Entropy: 3.10142
Value Function Loss: 0.00466

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.56077
Value Function Update Magnitude: 0.59177

Collected Steps per Second: 23,058.49454
Overall Steps per Second: 10,880.58768

Timestep Collection Time: 2.16892
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.59644

Cumulative Model Updates: 108,598
Cumulative Timesteps: 905,683,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 905683578...
Checkpoint 905683578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,489.36856
Policy Entropy: 3.10641
Value Function Loss: 0.00464

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11090
Policy Update Magnitude: 0.54889
Value Function Update Magnitude: 0.59773

Collected Steps per Second: 22,826.46813
Overall Steps per Second: 10,678.13981

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.49252
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.68340

Cumulative Model Updates: 108,604
Cumulative Timesteps: 905,733,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.49334
Policy Entropy: 3.10132
Value Function Loss: 0.00461

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11399
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.58917

Collected Steps per Second: 22,886.31376
Overall Steps per Second: 10,811.57121

Timestep Collection Time: 2.18480
Timestep Consumption Time: 2.44006
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.62486

Cumulative Model Updates: 108,610
Cumulative Timesteps: 905,783,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 905783590...
Checkpoint 905783590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.54025
Policy Entropy: 3.11607
Value Function Loss: 0.00454

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.54955
Value Function Update Magnitude: 0.59883

Collected Steps per Second: 22,850.14969
Overall Steps per Second: 10,689.77504

Timestep Collection Time: 2.18826
Timestep Consumption Time: 2.48930
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.67755

Cumulative Model Updates: 108,616
Cumulative Timesteps: 905,833,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,835.76210
Policy Entropy: 3.11829
Value Function Loss: 0.00454

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10919
Policy Update Magnitude: 0.54933
Value Function Update Magnitude: 0.60443

Collected Steps per Second: 22,742.14296
Overall Steps per Second: 10,669.88005

Timestep Collection Time: 2.19918
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.68740

Cumulative Model Updates: 108,622
Cumulative Timesteps: 905,883,606

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 905883606...
Checkpoint 905883606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,133.88113
Policy Entropy: 3.10521
Value Function Loss: 0.00457

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.55931
Value Function Update Magnitude: 0.61990

Collected Steps per Second: 23,158.02321
Overall Steps per Second: 10,907.24044

Timestep Collection Time: 2.15986
Timestep Consumption Time: 2.42591
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.58576

Cumulative Model Updates: 108,628
Cumulative Timesteps: 905,933,624

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.98439
Policy Entropy: 3.10559
Value Function Loss: 0.00485

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10792
Policy Update Magnitude: 0.56111
Value Function Update Magnitude: 0.60085

Collected Steps per Second: 22,910.30177
Overall Steps per Second: 10,810.14657

Timestep Collection Time: 2.18330
Timestep Consumption Time: 2.44384
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.62713

Cumulative Model Updates: 108,634
Cumulative Timesteps: 905,983,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 905983644...
Checkpoint 905983644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.14929
Policy Entropy: 3.11341
Value Function Loss: 0.00493

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09849
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.60058

Collected Steps per Second: 23,058.82988
Overall Steps per Second: 10,722.92666

Timestep Collection Time: 2.16949
Timestep Consumption Time: 2.49584
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.66533

Cumulative Model Updates: 108,640
Cumulative Timesteps: 906,033,670

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960.49776
Policy Entropy: 3.13853
Value Function Loss: 0.00513

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.08920
Policy Update Magnitude: 0.56527
Value Function Update Magnitude: 0.60830

Collected Steps per Second: 22,726.47013
Overall Steps per Second: 10,967.94939

Timestep Collection Time: 2.20025
Timestep Consumption Time: 2.35885
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.55910

Cumulative Model Updates: 108,646
Cumulative Timesteps: 906,083,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 906083674...
Checkpoint 906083674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.86704
Policy Entropy: 3.13545
Value Function Loss: 0.00496

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.55211
Value Function Update Magnitude: 0.57676

Collected Steps per Second: 22,106.09219
Overall Steps per Second: 10,646.56360

Timestep Collection Time: 2.26327
Timestep Consumption Time: 2.43609
PPO Batch Consumption Time: 0.29695
Total Iteration Time: 4.69936

Cumulative Model Updates: 108,652
Cumulative Timesteps: 906,133,706

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 718.43235
Policy Entropy: 3.12931
Value Function Loss: 0.00513

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09678
Policy Update Magnitude: 0.55341
Value Function Update Magnitude: 0.56897

Collected Steps per Second: 22,245.81897
Overall Steps per Second: 10,790.23336

Timestep Collection Time: 2.24833
Timestep Consumption Time: 2.38697
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.63530

Cumulative Model Updates: 108,658
Cumulative Timesteps: 906,183,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 906183722...
Checkpoint 906183722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.12575
Policy Entropy: 3.12022
Value Function Loss: 0.00498

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.55570
Value Function Update Magnitude: 0.56943

Collected Steps per Second: 22,075.70412
Overall Steps per Second: 10,705.99066

Timestep Collection Time: 2.26557
Timestep Consumption Time: 2.40602
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.67159

Cumulative Model Updates: 108,664
Cumulative Timesteps: 906,233,736

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.01540
Policy Entropy: 3.12901
Value Function Loss: 0.00494

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.55344
Value Function Update Magnitude: 0.57110

Collected Steps per Second: 22,326.88748
Overall Steps per Second: 10,843.92014

Timestep Collection Time: 2.23954
Timestep Consumption Time: 2.37152
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.61106

Cumulative Model Updates: 108,670
Cumulative Timesteps: 906,283,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 906283738...
Checkpoint 906283738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.21409
Policy Entropy: 3.13970
Value Function Loss: 0.00456

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09141
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.56490

Collected Steps per Second: 21,905.38864
Overall Steps per Second: 10,724.64658

Timestep Collection Time: 2.28318
Timestep Consumption Time: 2.38028
PPO Batch Consumption Time: 0.28421
Total Iteration Time: 4.66346

Cumulative Model Updates: 108,676
Cumulative Timesteps: 906,333,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.97565
Policy Entropy: 3.13442
Value Function Loss: 0.00459

Mean KL Divergence: 0.00841
SB3 Clip Fraction: 0.09130
Policy Update Magnitude: 0.54295
Value Function Update Magnitude: 0.56299

Collected Steps per Second: 22,455.80609
Overall Steps per Second: 10,836.84556

Timestep Collection Time: 2.22793
Timestep Consumption Time: 2.38873
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.61666

Cumulative Model Updates: 108,682
Cumulative Timesteps: 906,383,782

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 906383782...
Checkpoint 906383782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.56544
Policy Entropy: 3.12364
Value Function Loss: 0.00508

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.55790
Value Function Update Magnitude: 0.59095

Collected Steps per Second: 22,862.46325
Overall Steps per Second: 10,685.99475

Timestep Collection Time: 2.18717
Timestep Consumption Time: 2.49223
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.67940

Cumulative Model Updates: 108,688
Cumulative Timesteps: 906,433,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.87548
Policy Entropy: 3.10525
Value Function Loss: 0.00537

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.57165
Value Function Update Magnitude: 0.61942

Collected Steps per Second: 22,003.15382
Overall Steps per Second: 10,639.91947

Timestep Collection Time: 2.27267
Timestep Consumption Time: 2.42717
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.69985

Cumulative Model Updates: 108,694
Cumulative Timesteps: 906,483,792

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 906483792...
Checkpoint 906483792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.87165
Policy Entropy: 3.10378
Value Function Loss: 0.00528

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10195
Policy Update Magnitude: 0.57259
Value Function Update Magnitude: 0.62473

Collected Steps per Second: 22,386.37685
Overall Steps per Second: 10,856.62609

Timestep Collection Time: 2.23413
Timestep Consumption Time: 2.37265
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.60677

Cumulative Model Updates: 108,700
Cumulative Timesteps: 906,533,806

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.01264
Policy Entropy: 3.11078
Value Function Loss: 0.00486

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09808
Policy Update Magnitude: 0.56880
Value Function Update Magnitude: 0.62518

Collected Steps per Second: 21,996.20026
Overall Steps per Second: 10,616.22979

Timestep Collection Time: 2.27357
Timestep Consumption Time: 2.43714
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.71071

Cumulative Model Updates: 108,706
Cumulative Timesteps: 906,583,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 906583816...
Checkpoint 906583816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816.36850
Policy Entropy: 3.11722
Value Function Loss: 0.00484

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.56114
Value Function Update Magnitude: 0.63450

Collected Steps per Second: 22,326.18057
Overall Steps per Second: 10,740.82445

Timestep Collection Time: 2.24060
Timestep Consumption Time: 2.41677
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.65737

Cumulative Model Updates: 108,712
Cumulative Timesteps: 906,633,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.83224
Policy Entropy: 3.11145
Value Function Loss: 0.00508

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.57015
Value Function Update Magnitude: 0.64427

Collected Steps per Second: 22,235.55961
Overall Steps per Second: 10,726.53296

Timestep Collection Time: 2.24865
Timestep Consumption Time: 2.41269
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.66134

Cumulative Model Updates: 108,718
Cumulative Timesteps: 906,683,840

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 906683840...
Checkpoint 906683840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.15869
Policy Entropy: 3.10674
Value Function Loss: 0.00525

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11263
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.65407

Collected Steps per Second: 22,944.47488
Overall Steps per Second: 10,651.57478

Timestep Collection Time: 2.17961
Timestep Consumption Time: 2.51547
PPO Batch Consumption Time: 0.29700
Total Iteration Time: 4.69508

Cumulative Model Updates: 108,724
Cumulative Timesteps: 906,733,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.94274
Policy Entropy: 3.11639
Value Function Loss: 0.00494

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.56757
Value Function Update Magnitude: 0.65841

Collected Steps per Second: 23,394.22372
Overall Steps per Second: 10,845.20332

Timestep Collection Time: 2.13848
Timestep Consumption Time: 2.47444
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.61291

Cumulative Model Updates: 108,730
Cumulative Timesteps: 906,783,878

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 906783878...
Checkpoint 906783878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.10902
Policy Entropy: 3.13247
Value Function Loss: 0.00478

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09922
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.64383

Collected Steps per Second: 21,936.59646
Overall Steps per Second: 10,652.25983

Timestep Collection Time: 2.27948
Timestep Consumption Time: 2.41474
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.69422

Cumulative Model Updates: 108,736
Cumulative Timesteps: 906,833,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,750.69339
Policy Entropy: 3.13961
Value Function Loss: 0.00480

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10260
Policy Update Magnitude: 0.55828
Value Function Update Magnitude: 0.64069

Collected Steps per Second: 23,287.53151
Overall Steps per Second: 10,862.37093

Timestep Collection Time: 2.14810
Timestep Consumption Time: 2.45715
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.60526

Cumulative Model Updates: 108,742
Cumulative Timesteps: 906,883,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 906883906...
Checkpoint 906883906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,137.32110
Policy Entropy: 3.13121
Value Function Loss: 0.00514

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.56598
Value Function Update Magnitude: 0.63857

Collected Steps per Second: 22,726.51671
Overall Steps per Second: 10,717.13468

Timestep Collection Time: 2.20051
Timestep Consumption Time: 2.46585
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.66636

Cumulative Model Updates: 108,748
Cumulative Timesteps: 906,933,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.07648
Policy Entropy: 3.13519
Value Function Loss: 0.00494

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11269
Policy Update Magnitude: 0.56813
Value Function Update Magnitude: 0.63170

Collected Steps per Second: 23,202.92519
Overall Steps per Second: 10,842.54601

Timestep Collection Time: 2.15516
Timestep Consumption Time: 2.45686
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.61202

Cumulative Model Updates: 108,754
Cumulative Timesteps: 906,983,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 906983922...
Checkpoint 906983922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.80604
Policy Entropy: 3.13527
Value Function Loss: 0.00495

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.55271
Value Function Update Magnitude: 0.63586

Collected Steps per Second: 22,113.97912
Overall Steps per Second: 10,625.05732

Timestep Collection Time: 2.26110
Timestep Consumption Time: 2.44494
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.70605

Cumulative Model Updates: 108,760
Cumulative Timesteps: 907,033,924

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,605.65311
Policy Entropy: 3.15246
Value Function Loss: 0.00477

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.55153
Value Function Update Magnitude: 0.62089

Collected Steps per Second: 22,045.45457
Overall Steps per Second: 10,651.77143

Timestep Collection Time: 2.26831
Timestep Consumption Time: 2.42630
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.69462

Cumulative Model Updates: 108,766
Cumulative Timesteps: 907,083,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 907083930...
Checkpoint 907083930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.74212
Policy Entropy: 3.14646
Value Function Loss: 0.00472

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09522
Policy Update Magnitude: 0.55168
Value Function Update Magnitude: 0.61517

Collected Steps per Second: 22,322.69907
Overall Steps per Second: 10,855.55276

Timestep Collection Time: 2.24005
Timestep Consumption Time: 2.36625
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.60631

Cumulative Model Updates: 108,772
Cumulative Timesteps: 907,133,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,421.54837
Policy Entropy: 3.13685
Value Function Loss: 0.00452

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.08534
Policy Update Magnitude: 0.54740
Value Function Update Magnitude: 0.59386

Collected Steps per Second: 21,961.95483
Overall Steps per Second: 10,537.80253

Timestep Collection Time: 2.27739
Timestep Consumption Time: 2.46895
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.74634

Cumulative Model Updates: 108,778
Cumulative Timesteps: 907,183,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 907183950...
Checkpoint 907183950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.66162
Policy Entropy: 3.13306
Value Function Loss: 0.00442

Mean KL Divergence: 0.00808
SB3 Clip Fraction: 0.08720
Policy Update Magnitude: 0.54034
Value Function Update Magnitude: 0.57900

Collected Steps per Second: 22,292.85781
Overall Steps per Second: 10,664.47758

Timestep Collection Time: 2.24404
Timestep Consumption Time: 2.44686
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.69090

Cumulative Model Updates: 108,784
Cumulative Timesteps: 907,233,976

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.39570
Policy Entropy: 3.13262
Value Function Loss: 0.00471

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.54443
Value Function Update Magnitude: 0.59339

Collected Steps per Second: 22,857.05617
Overall Steps per Second: 10,806.37549

Timestep Collection Time: 2.18847
Timestep Consumption Time: 2.44046
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.62893

Cumulative Model Updates: 108,790
Cumulative Timesteps: 907,283,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 907283998...
Checkpoint 907283998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,275.25442
Policy Entropy: 3.13713
Value Function Loss: 0.00461

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.54629
Value Function Update Magnitude: 0.60718

Collected Steps per Second: 21,838.78767
Overall Steps per Second: 10,721.64027

Timestep Collection Time: 2.28987
Timestep Consumption Time: 2.37434
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.66421

Cumulative Model Updates: 108,796
Cumulative Timesteps: 907,334,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.13829
Policy Entropy: 3.14135
Value Function Loss: 0.00475

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11822
Policy Update Magnitude: 0.55432
Value Function Update Magnitude: 0.61435

Collected Steps per Second: 22,303.12019
Overall Steps per Second: 10,837.48905

Timestep Collection Time: 2.24283
Timestep Consumption Time: 2.37282
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.61564

Cumulative Model Updates: 108,802
Cumulative Timesteps: 907,384,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 907384028...
Checkpoint 907384028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.94327
Policy Entropy: 3.11029
Value Function Loss: 0.00471

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10875
Policy Update Magnitude: 0.56139
Value Function Update Magnitude: 0.63072

Collected Steps per Second: 22,238.06766
Overall Steps per Second: 10,701.87876

Timestep Collection Time: 2.24867
Timestep Consumption Time: 2.42397
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.67264

Cumulative Model Updates: 108,808
Cumulative Timesteps: 907,434,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.27710
Policy Entropy: 3.11364
Value Function Loss: 0.00496

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.56637
Value Function Update Magnitude: 0.64232

Collected Steps per Second: 22,956.12787
Overall Steps per Second: 10,713.00120

Timestep Collection Time: 2.17894
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.66909

Cumulative Model Updates: 108,814
Cumulative Timesteps: 907,484,054

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 907484054...
Checkpoint 907484054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 948.84275
Policy Entropy: 3.11003
Value Function Loss: 0.00491

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10665
Policy Update Magnitude: 0.56857
Value Function Update Magnitude: 0.64628

Collected Steps per Second: 23,119.00087
Overall Steps per Second: 10,901.23708

Timestep Collection Time: 2.16350
Timestep Consumption Time: 2.42478
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.58829

Cumulative Model Updates: 108,820
Cumulative Timesteps: 907,534,072

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.43898
Policy Entropy: 3.11748
Value Function Loss: 0.00488

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10103
Policy Update Magnitude: 0.56808
Value Function Update Magnitude: 0.66033

Collected Steps per Second: 22,322.33235
Overall Steps per Second: 10,779.33859

Timestep Collection Time: 2.24009
Timestep Consumption Time: 2.39879
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.63887

Cumulative Model Updates: 108,826
Cumulative Timesteps: 907,584,076

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 907584076...
Checkpoint 907584076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.61103
Policy Entropy: 3.11550
Value Function Loss: 0.00479

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.57545
Value Function Update Magnitude: 0.66837

Collected Steps per Second: 22,808.90841
Overall Steps per Second: 10,750.90932

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.45963
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.65263

Cumulative Model Updates: 108,832
Cumulative Timesteps: 907,634,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.97348
Policy Entropy: 3.12410
Value Function Loss: 0.00488

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.56990
Value Function Update Magnitude: 0.65859

Collected Steps per Second: 22,761.98612
Overall Steps per Second: 10,780.04225

Timestep Collection Time: 2.19682
Timestep Consumption Time: 2.44175
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.63857

Cumulative Model Updates: 108,838
Cumulative Timesteps: 907,684,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 907684100...
Checkpoint 907684100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.54781
Policy Entropy: 3.13755
Value Function Loss: 0.00484

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.57358
Value Function Update Magnitude: 0.65341

Collected Steps per Second: 22,630.60416
Overall Steps per Second: 10,769.56188

Timestep Collection Time: 2.21046
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.64494

Cumulative Model Updates: 108,844
Cumulative Timesteps: 907,734,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.97427
Policy Entropy: 3.12513
Value Function Loss: 0.00516

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.58171
Value Function Update Magnitude: 0.67368

Collected Steps per Second: 22,784.20673
Overall Steps per Second: 10,772.63647

Timestep Collection Time: 2.19477
Timestep Consumption Time: 2.44718
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.64195

Cumulative Model Updates: 108,850
Cumulative Timesteps: 907,784,130

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 907784130...
Checkpoint 907784130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940.92080
Policy Entropy: 3.11738
Value Function Loss: 0.00506

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.58118
Value Function Update Magnitude: 0.67737

Collected Steps per Second: 23,050.31592
Overall Steps per Second: 10,733.07983

Timestep Collection Time: 2.16934
Timestep Consumption Time: 2.48953
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.65887

Cumulative Model Updates: 108,856
Cumulative Timesteps: 907,834,134

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.80100
Policy Entropy: 3.12068
Value Function Loss: 0.00529

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.58686
Value Function Update Magnitude: 0.67173

Collected Steps per Second: 22,659.03448
Overall Steps per Second: 10,626.57427

Timestep Collection Time: 2.20777
Timestep Consumption Time: 2.49986
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.70763

Cumulative Model Updates: 108,862
Cumulative Timesteps: 907,884,160

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 907884160...
Checkpoint 907884160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.44800
Policy Entropy: 3.14096
Value Function Loss: 0.00475

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11515
Policy Update Magnitude: 0.57603
Value Function Update Magnitude: 0.67413

Collected Steps per Second: 22,858.70968
Overall Steps per Second: 10,697.53900

Timestep Collection Time: 2.18823
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.67584

Cumulative Model Updates: 108,868
Cumulative Timesteps: 907,934,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.55999
Policy Entropy: 3.14185
Value Function Loss: 0.00483

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.56072
Value Function Update Magnitude: 0.64956

Collected Steps per Second: 23,151.12290
Overall Steps per Second: 10,671.45062

Timestep Collection Time: 2.16015
Timestep Consumption Time: 2.52618
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.68634

Cumulative Model Updates: 108,874
Cumulative Timesteps: 907,984,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 907984190...
Checkpoint 907984190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 764.11667
Policy Entropy: 3.14781
Value Function Loss: 0.00477

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.11196
Policy Update Magnitude: 0.56156
Value Function Update Magnitude: 0.63813

Collected Steps per Second: 22,955.59349
Overall Steps per Second: 10,634.29976

Timestep Collection Time: 2.17821
Timestep Consumption Time: 2.52375
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.70196

Cumulative Model Updates: 108,880
Cumulative Timesteps: 908,034,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.07052
Policy Entropy: 3.13716
Value Function Loss: 0.00487

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.56310
Value Function Update Magnitude: 0.62835

Collected Steps per Second: 22,930.98678
Overall Steps per Second: 10,797.96075

Timestep Collection Time: 2.18063
Timestep Consumption Time: 2.45024
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.63087

Cumulative Model Updates: 108,886
Cumulative Timesteps: 908,084,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 908084196...
Checkpoint 908084196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.99160
Policy Entropy: 3.15130
Value Function Loss: 0.00490

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.56396
Value Function Update Magnitude: 0.63042

Collected Steps per Second: 22,822.10453
Overall Steps per Second: 10,742.00895

Timestep Collection Time: 2.19156
Timestep Consumption Time: 2.46455
PPO Batch Consumption Time: 0.28515
Total Iteration Time: 4.65611

Cumulative Model Updates: 108,892
Cumulative Timesteps: 908,134,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.64234
Policy Entropy: 3.15091
Value Function Loss: 0.00484

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.57409
Value Function Update Magnitude: 0.62800

Collected Steps per Second: 23,176.82129
Overall Steps per Second: 10,844.24853

Timestep Collection Time: 2.15810
Timestep Consumption Time: 2.45429
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.61240

Cumulative Model Updates: 108,898
Cumulative Timesteps: 908,184,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 908184230...
Checkpoint 908184230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,561.60311
Policy Entropy: 3.14682
Value Function Loss: 0.00479

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09680
Policy Update Magnitude: 0.57021
Value Function Update Magnitude: 0.63486

Collected Steps per Second: 22,903.43055
Overall Steps per Second: 10,720.89374

Timestep Collection Time: 2.18430
Timestep Consumption Time: 2.48210
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.66640

Cumulative Model Updates: 108,904
Cumulative Timesteps: 908,234,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.71770
Policy Entropy: 3.11690
Value Function Loss: 0.00460

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.56463
Value Function Update Magnitude: 0.61967

Collected Steps per Second: 22,798.93392
Overall Steps per Second: 10,639.27669

Timestep Collection Time: 2.19308
Timestep Consumption Time: 2.50648
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.69957

Cumulative Model Updates: 108,910
Cumulative Timesteps: 908,284,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 908284258...
Checkpoint 908284258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.18908
Policy Entropy: 3.08883
Value Function Loss: 0.00501

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.56712
Value Function Update Magnitude: 0.62293

Collected Steps per Second: 22,991.05068
Overall Steps per Second: 10,859.41916

Timestep Collection Time: 2.17606
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.60706

Cumulative Model Updates: 108,916
Cumulative Timesteps: 908,334,288

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.79904
Policy Entropy: 3.09063
Value Function Loss: 0.00534

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12763
Policy Update Magnitude: 0.57573
Value Function Update Magnitude: 0.63514

Collected Steps per Second: 23,086.01785
Overall Steps per Second: 10,703.58936

Timestep Collection Time: 2.16633
Timestep Consumption Time: 2.50612
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.67245

Cumulative Model Updates: 108,922
Cumulative Timesteps: 908,384,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 908384300...
Checkpoint 908384300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.69967
Policy Entropy: 3.12081
Value Function Loss: 0.00577

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.58158
Value Function Update Magnitude: 0.63691

Collected Steps per Second: 23,090.84348
Overall Steps per Second: 10,835.53027

Timestep Collection Time: 2.16666
Timestep Consumption Time: 2.45056
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.61722

Cumulative Model Updates: 108,928
Cumulative Timesteps: 908,434,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792.68262
Policy Entropy: 3.15285
Value Function Loss: 0.00555

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.57430
Value Function Update Magnitude: 0.60872

Collected Steps per Second: 22,608.02281
Overall Steps per Second: 10,579.18667

Timestep Collection Time: 2.21205
Timestep Consumption Time: 2.51516
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.72721

Cumulative Model Updates: 108,934
Cumulative Timesteps: 908,484,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 908484340...
Checkpoint 908484340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507.23111
Policy Entropy: 3.16716
Value Function Loss: 0.00575

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.56822
Value Function Update Magnitude: 0.59576

Collected Steps per Second: 22,817.70565
Overall Steps per Second: 10,594.58609

Timestep Collection Time: 2.19216
Timestep Consumption Time: 2.52912
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.72128

Cumulative Model Updates: 108,940
Cumulative Timesteps: 908,534,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369.08459
Policy Entropy: 3.17852
Value Function Loss: 0.00573

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.56615
Value Function Update Magnitude: 0.62011

Collected Steps per Second: 22,868.36892
Overall Steps per Second: 10,801.37053

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.44389
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.63145

Cumulative Model Updates: 108,946
Cumulative Timesteps: 908,584,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 908584386...
Checkpoint 908584386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,080.43858
Policy Entropy: 3.16310
Value Function Loss: 0.00591

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.10084
Policy Update Magnitude: 0.57054
Value Function Update Magnitude: 0.61453

Collected Steps per Second: 22,802.19913
Overall Steps per Second: 10,725.64381

Timestep Collection Time: 2.19312
Timestep Consumption Time: 2.46935
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.66247

Cumulative Model Updates: 108,952
Cumulative Timesteps: 908,634,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.28372
Policy Entropy: 3.16418
Value Function Loss: 0.00564

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.57358
Value Function Update Magnitude: 0.61053

Collected Steps per Second: 23,056.78769
Overall Steps per Second: 10,843.16793

Timestep Collection Time: 2.16977
Timestep Consumption Time: 2.44401
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.61378

Cumulative Model Updates: 108,958
Cumulative Timesteps: 908,684,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 908684422...
Checkpoint 908684422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020.08242
Policy Entropy: 3.15214
Value Function Loss: 0.00537

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.56691
Value Function Update Magnitude: 0.58461

Collected Steps per Second: 22,997.29654
Overall Steps per Second: 10,743.96526

Timestep Collection Time: 2.17521
Timestep Consumption Time: 2.48080
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.65601

Cumulative Model Updates: 108,964
Cumulative Timesteps: 908,734,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.44797
Policy Entropy: 3.15070
Value Function Loss: 0.00508

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.56214
Value Function Update Magnitude: 0.57894

Collected Steps per Second: 23,193.59073
Overall Steps per Second: 10,833.98866

Timestep Collection Time: 2.15698
Timestep Consumption Time: 2.46071
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.61769

Cumulative Model Updates: 108,970
Cumulative Timesteps: 908,784,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 908784474...
Checkpoint 908784474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.10294
Policy Entropy: 3.13326
Value Function Loss: 0.00490

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.56400
Value Function Update Magnitude: 0.58910

Collected Steps per Second: 22,684.39060
Overall Steps per Second: 10,695.96474

Timestep Collection Time: 2.20504
Timestep Consumption Time: 2.47149
PPO Batch Consumption Time: 0.28484
Total Iteration Time: 4.67653

Cumulative Model Updates: 108,976
Cumulative Timesteps: 908,834,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011.74399
Policy Entropy: 3.11552
Value Function Loss: 0.00489

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.56633
Value Function Update Magnitude: 0.59614

Collected Steps per Second: 22,725.27084
Overall Steps per Second: 10,615.48565

Timestep Collection Time: 2.20019
Timestep Consumption Time: 2.50991
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.71010

Cumulative Model Updates: 108,982
Cumulative Timesteps: 908,884,494

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 908884494...
Checkpoint 908884494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 984.72681
Policy Entropy: 3.11309
Value Function Loss: 0.00488

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.57033
Value Function Update Magnitude: 0.62053

Collected Steps per Second: 22,982.98226
Overall Steps per Second: 10,714.13957

Timestep Collection Time: 2.17587
Timestep Consumption Time: 2.49161
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.66748

Cumulative Model Updates: 108,988
Cumulative Timesteps: 908,934,502

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,580.46073
Policy Entropy: 3.11788
Value Function Loss: 0.00494

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.56323
Value Function Update Magnitude: 0.62317

Collected Steps per Second: 22,959.88068
Overall Steps per Second: 10,672.40505

Timestep Collection Time: 2.17806
Timestep Consumption Time: 2.50767
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.68573

Cumulative Model Updates: 108,994
Cumulative Timesteps: 908,984,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 908984510...
Checkpoint 908984510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.42996
Policy Entropy: 3.11743
Value Function Loss: 0.00500

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.11632
Policy Update Magnitude: 0.56009
Value Function Update Magnitude: 0.62089

Collected Steps per Second: 23,074.98082
Overall Steps per Second: 10,666.83361

Timestep Collection Time: 2.16798
Timestep Consumption Time: 2.52189
PPO Batch Consumption Time: 0.29665
Total Iteration Time: 4.68986

Cumulative Model Updates: 109,000
Cumulative Timesteps: 909,034,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,279.01682
Policy Entropy: 3.12296
Value Function Loss: 0.00538

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11403
Policy Update Magnitude: 0.56472
Value Function Update Magnitude: 0.62783

Collected Steps per Second: 22,873.40679
Overall Steps per Second: 10,801.77944

Timestep Collection Time: 2.18664
Timestep Consumption Time: 2.44370
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.63035

Cumulative Model Updates: 109,006
Cumulative Timesteps: 909,084,552

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 909084552...
Checkpoint 909084552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,683.44301
Policy Entropy: 3.12480
Value Function Loss: 0.00539

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.57217
Value Function Update Magnitude: 0.62532

Collected Steps per Second: 22,682.48221
Overall Steps per Second: 10,719.87357

Timestep Collection Time: 2.20496
Timestep Consumption Time: 2.46058
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.66554

Cumulative Model Updates: 109,012
Cumulative Timesteps: 909,134,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.58445
Policy Entropy: 3.14016
Value Function Loss: 0.00527

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.57216
Value Function Update Magnitude: 0.61664

Collected Steps per Second: 22,814.33436
Overall Steps per Second: 10,575.50274

Timestep Collection Time: 2.19257
Timestep Consumption Time: 2.53742
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.72999

Cumulative Model Updates: 109,018
Cumulative Timesteps: 909,184,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 909184588...
Checkpoint 909184588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,537.65619
Policy Entropy: 3.14748
Value Function Loss: 0.00490

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.55641
Value Function Update Magnitude: 0.60067

Collected Steps per Second: 22,921.63561
Overall Steps per Second: 10,697.24425

Timestep Collection Time: 2.18231
Timestep Consumption Time: 2.49385
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.67616

Cumulative Model Updates: 109,024
Cumulative Timesteps: 909,234,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.68200
Policy Entropy: 3.15054
Value Function Loss: 0.00480

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.55153
Value Function Update Magnitude: 0.60772

Collected Steps per Second: 22,976.31006
Overall Steps per Second: 10,745.20583

Timestep Collection Time: 2.17676
Timestep Consumption Time: 2.47778
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.65454

Cumulative Model Updates: 109,030
Cumulative Timesteps: 909,284,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 909284624...
Checkpoint 909284624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.98373
Policy Entropy: 3.13354
Value Function Loss: 0.00495

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09337
Policy Update Magnitude: 0.55920
Value Function Update Magnitude: 0.61126

Collected Steps per Second: 22,664.90574
Overall Steps per Second: 10,624.09135

Timestep Collection Time: 2.20702
Timestep Consumption Time: 2.50133
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.70836

Cumulative Model Updates: 109,036
Cumulative Timesteps: 909,334,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.77041
Policy Entropy: 3.11429
Value Function Loss: 0.00503

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.56808
Value Function Update Magnitude: 0.62549

Collected Steps per Second: 23,205.82613
Overall Steps per Second: 10,844.43713

Timestep Collection Time: 2.15480
Timestep Consumption Time: 2.45622
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.61103

Cumulative Model Updates: 109,042
Cumulative Timesteps: 909,384,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 909384650...
Checkpoint 909384650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,586.20370
Policy Entropy: 3.11330
Value Function Loss: 0.00495

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.56790
Value Function Update Magnitude: 0.62735

Collected Steps per Second: 22,647.74209
Overall Steps per Second: 10,748.60278

Timestep Collection Time: 2.20773
Timestep Consumption Time: 2.44404
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.65177

Cumulative Model Updates: 109,048
Cumulative Timesteps: 909,434,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.81231
Policy Entropy: 3.10869
Value Function Loss: 0.00483

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.56509
Value Function Update Magnitude: 0.60382

Collected Steps per Second: 23,090.11987
Overall Steps per Second: 10,806.36546

Timestep Collection Time: 2.16673
Timestep Consumption Time: 2.46295
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.62968

Cumulative Model Updates: 109,054
Cumulative Timesteps: 909,484,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 909484680...
Checkpoint 909484680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,982.37490
Policy Entropy: 3.10378
Value Function Loss: 0.00493

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.57018
Value Function Update Magnitude: 0.60360

Collected Steps per Second: 22,443.89106
Overall Steps per Second: 10,751.98758

Timestep Collection Time: 2.22858
Timestep Consumption Time: 2.42340
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.65198

Cumulative Model Updates: 109,060
Cumulative Timesteps: 909,534,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.77323
Policy Entropy: 3.09791
Value Function Loss: 0.00487

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10752
Policy Update Magnitude: 0.56708
Value Function Update Magnitude: 0.60409

Collected Steps per Second: 22,994.71864
Overall Steps per Second: 10,793.60422

Timestep Collection Time: 2.17493
Timestep Consumption Time: 2.45855
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.63348

Cumulative Model Updates: 109,066
Cumulative Timesteps: 909,584,710

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 909584710...
Checkpoint 909584710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.73119
Policy Entropy: 3.10779
Value Function Loss: 0.00481

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.56244
Value Function Update Magnitude: 0.60148

Collected Steps per Second: 22,881.74051
Overall Steps per Second: 10,644.79209

Timestep Collection Time: 2.18576
Timestep Consumption Time: 2.51269
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.69845

Cumulative Model Updates: 109,072
Cumulative Timesteps: 909,634,724

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142.48747
Policy Entropy: 3.10549
Value Function Loss: 0.00455

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09248
Policy Update Magnitude: 0.56337
Value Function Update Magnitude: 0.60845

Collected Steps per Second: 23,094.32888
Overall Steps per Second: 10,738.25987

Timestep Collection Time: 2.16590
Timestep Consumption Time: 2.49221
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.65811

Cumulative Model Updates: 109,078
Cumulative Timesteps: 909,684,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 909684744...
Checkpoint 909684744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.34519
Policy Entropy: 3.10566
Value Function Loss: 0.00453

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09225
Policy Update Magnitude: 0.56605
Value Function Update Magnitude: 0.60349

Collected Steps per Second: 22,899.65824
Overall Steps per Second: 10,800.57607

Timestep Collection Time: 2.18414
Timestep Consumption Time: 2.44673
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.63086

Cumulative Model Updates: 109,084
Cumulative Timesteps: 909,734,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.02094
Policy Entropy: 3.10691
Value Function Loss: 0.00448

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.56734
Value Function Update Magnitude: 0.60582

Collected Steps per Second: 22,940.68551
Overall Steps per Second: 10,695.25348

Timestep Collection Time: 2.18058
Timestep Consumption Time: 2.49663
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.67721

Cumulative Model Updates: 109,090
Cumulative Timesteps: 909,784,784

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 909784784...
Checkpoint 909784784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 790.49864
Policy Entropy: 3.12292
Value Function Loss: 0.00476

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10684
Policy Update Magnitude: 0.56932
Value Function Update Magnitude: 0.59849

Collected Steps per Second: 22,974.73785
Overall Steps per Second: 10,798.23287

Timestep Collection Time: 2.17648
Timestep Consumption Time: 2.45428
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.63076

Cumulative Model Updates: 109,096
Cumulative Timesteps: 909,834,788

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 832.22045
Policy Entropy: 3.13190
Value Function Loss: 0.00507

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11188
Policy Update Magnitude: 0.56943
Value Function Update Magnitude: 0.58954

Collected Steps per Second: 23,072.26126
Overall Steps per Second: 10,733.01380

Timestep Collection Time: 2.16736
Timestep Consumption Time: 2.49172
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.65908

Cumulative Model Updates: 109,102
Cumulative Timesteps: 909,884,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 909884794...
Checkpoint 909884794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.82537
Policy Entropy: 3.12272
Value Function Loss: 0.00504

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11201
Policy Update Magnitude: 0.56234
Value Function Update Magnitude: 0.59834

Collected Steps per Second: 22,720.08642
Overall Steps per Second: 10,637.19480

Timestep Collection Time: 2.20210
Timestep Consumption Time: 2.50139
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.70350

Cumulative Model Updates: 109,108
Cumulative Timesteps: 909,934,826

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,342.42259
Policy Entropy: 3.11212
Value Function Loss: 0.00490

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.55867
Value Function Update Magnitude: 0.58913

Collected Steps per Second: 23,248.10763
Overall Steps per Second: 10,740.73807

Timestep Collection Time: 2.15106
Timestep Consumption Time: 2.50486
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.65592

Cumulative Model Updates: 109,114
Cumulative Timesteps: 909,984,834

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 909984834...
Checkpoint 909984834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,641.36175
Policy Entropy: 3.11774
Value Function Loss: 0.00468

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.55571
Value Function Update Magnitude: 0.56616

Collected Steps per Second: 22,612.89204
Overall Steps per Second: 10,659.15292

Timestep Collection Time: 2.21122
Timestep Consumption Time: 2.47978
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.69099

Cumulative Model Updates: 109,120
Cumulative Timesteps: 910,034,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.15510
Policy Entropy: 3.12762
Value Function Loss: 0.00457

Mean KL Divergence: 0.00802
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.55201
Value Function Update Magnitude: 0.55998

Collected Steps per Second: 22,747.88628
Overall Steps per Second: 10,630.22636

Timestep Collection Time: 2.19924
Timestep Consumption Time: 2.50697
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.70620

Cumulative Model Updates: 109,126
Cumulative Timesteps: 910,084,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 910084864...
Checkpoint 910084864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,422.66623
Policy Entropy: 3.11700
Value Function Loss: 0.00472

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.55526
Value Function Update Magnitude: 0.56105

Collected Steps per Second: 23,233.00519
Overall Steps per Second: 10,892.27952

Timestep Collection Time: 2.15289
Timestep Consumption Time: 2.43917
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.59206

Cumulative Model Updates: 109,132
Cumulative Timesteps: 910,134,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 914.56433
Policy Entropy: 3.09485
Value Function Loss: 0.00525

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10362
Policy Update Magnitude: 0.57512
Value Function Update Magnitude: 0.57419

Collected Steps per Second: 22,613.84766
Overall Steps per Second: 10,591.11171

Timestep Collection Time: 2.21121
Timestep Consumption Time: 2.51011
PPO Batch Consumption Time: 0.29384
Total Iteration Time: 4.72132

Cumulative Model Updates: 109,138
Cumulative Timesteps: 910,184,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 910184886...
Checkpoint 910184886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,816.44522
Policy Entropy: 3.08471
Value Function Loss: 0.00518

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.58558
Value Function Update Magnitude: 0.60097

Collected Steps per Second: 23,071.25601
Overall Steps per Second: 10,714.10522

Timestep Collection Time: 2.16772
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.66787

Cumulative Model Updates: 109,144
Cumulative Timesteps: 910,234,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.08846
Policy Entropy: 3.09421
Value Function Loss: 0.00527

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.13148
Policy Update Magnitude: 0.57612
Value Function Update Magnitude: 0.60766

Collected Steps per Second: 23,134.67544
Overall Steps per Second: 10,703.55799

Timestep Collection Time: 2.16195
Timestep Consumption Time: 2.51089
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.67284

Cumulative Model Updates: 109,150
Cumulative Timesteps: 910,284,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 910284914...
Checkpoint 910284914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,443.36257
Policy Entropy: 3.08962
Value Function Loss: 0.00491

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11882
Policy Update Magnitude: 0.57180
Value Function Update Magnitude: 0.60999

Collected Steps per Second: 22,872.45647
Overall Steps per Second: 10,611.17757

Timestep Collection Time: 2.18726
Timestep Consumption Time: 2.52739
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.71465

Cumulative Model Updates: 109,156
Cumulative Timesteps: 910,334,942

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.15956
Policy Entropy: 3.08844
Value Function Loss: 0.00489

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10737
Policy Update Magnitude: 0.56746
Value Function Update Magnitude: 0.60466

Collected Steps per Second: 23,094.87696
Overall Steps per Second: 10,846.00697

Timestep Collection Time: 2.16585
Timestep Consumption Time: 2.44599
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.61184

Cumulative Model Updates: 109,162
Cumulative Timesteps: 910,384,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 910384962...
Checkpoint 910384962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.15016
Policy Entropy: 3.09257
Value Function Loss: 0.00487

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.56826
Value Function Update Magnitude: 0.59287

Collected Steps per Second: 22,644.58520
Overall Steps per Second: 10,739.98519

Timestep Collection Time: 2.20936
Timestep Consumption Time: 2.44894
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.65829

Cumulative Model Updates: 109,168
Cumulative Timesteps: 910,434,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 876.88920
Policy Entropy: 3.09590
Value Function Loss: 0.00478

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11212
Policy Update Magnitude: 0.56480
Value Function Update Magnitude: 0.59555

Collected Steps per Second: 22,969.94615
Overall Steps per Second: 10,818.08952

Timestep Collection Time: 2.17702
Timestep Consumption Time: 2.44542
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.62244

Cumulative Model Updates: 109,174
Cumulative Timesteps: 910,484,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 910484998...
Checkpoint 910484998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,526.59945
Policy Entropy: 3.11572
Value Function Loss: 0.00490

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10991
Policy Update Magnitude: 0.56348
Value Function Update Magnitude: 0.60707

Collected Steps per Second: 22,592.53496
Overall Steps per Second: 10,765.99309

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.43113
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.64425

Cumulative Model Updates: 109,180
Cumulative Timesteps: 910,534,998

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.61952
Policy Entropy: 3.12181
Value Function Loss: 0.00465

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.56201
Value Function Update Magnitude: 0.60671

Collected Steps per Second: 23,159.52006
Overall Steps per Second: 10,836.47093

Timestep Collection Time: 2.15911
Timestep Consumption Time: 2.45531
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.61442

Cumulative Model Updates: 109,186
Cumulative Timesteps: 910,585,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 910585002...
Checkpoint 910585002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 771.00007
Policy Entropy: 3.12591
Value Function Loss: 0.00473

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.11621
Policy Update Magnitude: 0.56156
Value Function Update Magnitude: 0.61628

Collected Steps per Second: 22,608.39765
Overall Steps per Second: 10,678.86246

Timestep Collection Time: 2.21183
Timestep Consumption Time: 2.47088
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.68271

Cumulative Model Updates: 109,192
Cumulative Timesteps: 910,635,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.69364
Policy Entropy: 3.10829
Value Function Loss: 0.00473

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.61687

Collected Steps per Second: 23,068.84212
Overall Steps per Second: 10,812.98426

Timestep Collection Time: 2.16873
Timestep Consumption Time: 2.45812
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.62684

Cumulative Model Updates: 109,198
Cumulative Timesteps: 910,685,038

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 910685038...
Checkpoint 910685038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.57824
Policy Entropy: 3.10048
Value Function Loss: 0.00466

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.55778
Value Function Update Magnitude: 0.60545

Collected Steps per Second: 22,846.82138
Overall Steps per Second: 10,725.15036

Timestep Collection Time: 2.18928
Timestep Consumption Time: 2.47434
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.66362

Cumulative Model Updates: 109,204
Cumulative Timesteps: 910,735,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.78900
Policy Entropy: 3.10474
Value Function Loss: 0.00457

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.55486
Value Function Update Magnitude: 0.60959

Collected Steps per Second: 23,042.62088
Overall Steps per Second: 10,825.75382

Timestep Collection Time: 2.17102
Timestep Consumption Time: 2.45000
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.62102

Cumulative Model Updates: 109,210
Cumulative Timesteps: 910,785,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 910785082...
Checkpoint 910785082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,274.54167
Policy Entropy: 3.11576
Value Function Loss: 0.00431

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.54755
Value Function Update Magnitude: 0.60450

Collected Steps per Second: 22,705.62196
Overall Steps per Second: 10,730.04572

Timestep Collection Time: 2.20315
Timestep Consumption Time: 2.45889
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.66205

Cumulative Model Updates: 109,216
Cumulative Timesteps: 910,835,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 857.39518
Policy Entropy: 3.12492
Value Function Loss: 0.00424

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.54448
Value Function Update Magnitude: 0.56164

Collected Steps per Second: 22,955.27054
Overall Steps per Second: 10,801.89783

Timestep Collection Time: 2.17876
Timestep Consumption Time: 2.45135
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.63011

Cumulative Model Updates: 109,222
Cumulative Timesteps: 910,885,120

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 910885120...
Checkpoint 910885120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.29018
Policy Entropy: 3.12300
Value Function Loss: 0.00434

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09247
Policy Update Magnitude: 0.54041
Value Function Update Magnitude: 0.56123

Collected Steps per Second: 22,762.85714
Overall Steps per Second: 10,709.79829

Timestep Collection Time: 2.19753
Timestep Consumption Time: 2.47315
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.67068

Cumulative Model Updates: 109,228
Cumulative Timesteps: 910,935,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,395.01680
Policy Entropy: 3.09304
Value Function Loss: 0.00452

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09375
Policy Update Magnitude: 0.54809
Value Function Update Magnitude: 0.57701

Collected Steps per Second: 23,006.33249
Overall Steps per Second: 10,833.64110

Timestep Collection Time: 2.17418
Timestep Consumption Time: 2.44292
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.61710

Cumulative Model Updates: 109,234
Cumulative Timesteps: 910,985,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 910985162...
Checkpoint 910985162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.38837
Policy Entropy: 3.07537
Value Function Loss: 0.00497

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09980
Policy Update Magnitude: 0.56289
Value Function Update Magnitude: 0.57801

Collected Steps per Second: 22,403.01201
Overall Steps per Second: 10,657.66493

Timestep Collection Time: 2.23202
Timestep Consumption Time: 2.45981
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.69183

Cumulative Model Updates: 109,240
Cumulative Timesteps: 911,035,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.01168
Policy Entropy: 3.06649
Value Function Loss: 0.00489

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.56916
Value Function Update Magnitude: 0.60316

Collected Steps per Second: 23,074.13295
Overall Steps per Second: 10,777.07787

Timestep Collection Time: 2.16754
Timestep Consumption Time: 2.47324
PPO Batch Consumption Time: 0.28911
Total Iteration Time: 4.64078

Cumulative Model Updates: 109,246
Cumulative Timesteps: 911,085,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 911085180...
Checkpoint 911085180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,552.15991
Policy Entropy: 3.06678
Value Function Loss: 0.00475

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10783
Policy Update Magnitude: 0.56641
Value Function Update Magnitude: 0.60528

Collected Steps per Second: 21,824.51421
Overall Steps per Second: 10,662.39228

Timestep Collection Time: 2.29228
Timestep Consumption Time: 2.39972
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.69201

Cumulative Model Updates: 109,252
Cumulative Timesteps: 911,135,208

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,053.45951
Policy Entropy: 3.07041
Value Function Loss: 0.00465

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.55799
Value Function Update Magnitude: 0.60719

Collected Steps per Second: 22,503.64504
Overall Steps per Second: 10,701.10239

Timestep Collection Time: 2.22213
Timestep Consumption Time: 2.45085
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.67298

Cumulative Model Updates: 109,258
Cumulative Timesteps: 911,185,214

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 911185214...
Checkpoint 911185214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,521.21593
Policy Entropy: 3.07942
Value Function Loss: 0.00482

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.56189
Value Function Update Magnitude: 0.60225

Collected Steps per Second: 22,572.78471
Overall Steps per Second: 10,567.07608

Timestep Collection Time: 2.21550
Timestep Consumption Time: 2.51712
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.73262

Cumulative Model Updates: 109,264
Cumulative Timesteps: 911,235,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.60563
Policy Entropy: 3.08141
Value Function Loss: 0.00475

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.11375
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.59603

Collected Steps per Second: 22,984.42960
Overall Steps per Second: 10,832.65538

Timestep Collection Time: 2.17582
Timestep Consumption Time: 2.44078
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.61660

Cumulative Model Updates: 109,270
Cumulative Timesteps: 911,285,234

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 911285234...
Checkpoint 911285234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,071.35802
Policy Entropy: 3.07366
Value Function Loss: 0.00473

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.55623
Value Function Update Magnitude: 0.61398

Collected Steps per Second: 22,085.89282
Overall Steps per Second: 10,737.06693

Timestep Collection Time: 2.26461
Timestep Consumption Time: 2.39364
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.65826

Cumulative Model Updates: 109,276
Cumulative Timesteps: 911,335,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.70643
Policy Entropy: 3.08677
Value Function Loss: 0.00456

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.55097
Value Function Update Magnitude: 0.60894

Collected Steps per Second: 22,368.24335
Overall Steps per Second: 10,821.51746

Timestep Collection Time: 2.23692
Timestep Consumption Time: 2.38683
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.62375

Cumulative Model Updates: 109,282
Cumulative Timesteps: 911,385,286

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 911385286...
Checkpoint 911385286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.72279
Policy Entropy: 3.08782
Value Function Loss: 0.00450

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.54862
Value Function Update Magnitude: 0.59599

Collected Steps per Second: 21,892.29267
Overall Steps per Second: 10,614.36129

Timestep Collection Time: 2.28455
Timestep Consumption Time: 2.42737
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.71192

Cumulative Model Updates: 109,288
Cumulative Timesteps: 911,435,300

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.48317
Policy Entropy: 3.09361
Value Function Loss: 0.00452

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.54501
Value Function Update Magnitude: 0.60245

Collected Steps per Second: 22,116.61606
Overall Steps per Second: 10,648.86507

Timestep Collection Time: 2.26111
Timestep Consumption Time: 2.43498
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.69609

Cumulative Model Updates: 109,294
Cumulative Timesteps: 911,485,308

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 911485308...
Checkpoint 911485308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.70800
Policy Entropy: 3.10694
Value Function Loss: 0.00449

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10332
Policy Update Magnitude: 0.54261
Value Function Update Magnitude: 0.61736

Collected Steps per Second: 22,223.42354
Overall Steps per Second: 10,707.96538

Timestep Collection Time: 2.25123
Timestep Consumption Time: 2.42099
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.67222

Cumulative Model Updates: 109,300
Cumulative Timesteps: 911,535,338

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.02616
Policy Entropy: 3.10522
Value Function Loss: 0.00449

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10024
Policy Update Magnitude: 0.54592
Value Function Update Magnitude: 0.61876

Collected Steps per Second: 22,541.19934
Overall Steps per Second: 10,745.71562

Timestep Collection Time: 2.21887
Timestep Consumption Time: 2.43564
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.65451

Cumulative Model Updates: 109,306
Cumulative Timesteps: 911,585,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 911585354...
Checkpoint 911585354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,600.27502
Policy Entropy: 3.10518
Value Function Loss: 0.00441

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09571
Policy Update Magnitude: 0.54106
Value Function Update Magnitude: 0.60659

Collected Steps per Second: 21,667.38608
Overall Steps per Second: 10,569.77706

Timestep Collection Time: 2.30789
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.73104

Cumulative Model Updates: 109,312
Cumulative Timesteps: 911,635,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,991.37749
Policy Entropy: 3.10978
Value Function Loss: 0.00468

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09053
Policy Update Magnitude: 0.54384
Value Function Update Magnitude: 0.59840

Collected Steps per Second: 22,148.85324
Overall Steps per Second: 10,685.53640

Timestep Collection Time: 2.25827
Timestep Consumption Time: 2.42264
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.68091

Cumulative Model Updates: 109,318
Cumulative Timesteps: 911,685,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 911685378...
Checkpoint 911685378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,701.36260
Policy Entropy: 3.11339
Value Function Loss: 0.00483

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09365
Policy Update Magnitude: 0.55118
Value Function Update Magnitude: 0.59023

Collected Steps per Second: 22,107.77401
Overall Steps per Second: 10,684.80909

Timestep Collection Time: 2.26210
Timestep Consumption Time: 2.41838
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.68048

Cumulative Model Updates: 109,324
Cumulative Timesteps: 911,735,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,669.89407
Policy Entropy: 3.10823
Value Function Loss: 0.00472

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.57761

Collected Steps per Second: 22,615.57755
Overall Steps per Second: 10,740.71226

Timestep Collection Time: 2.21140
Timestep Consumption Time: 2.44491
PPO Batch Consumption Time: 0.29652
Total Iteration Time: 4.65630

Cumulative Model Updates: 109,330
Cumulative Timesteps: 911,785,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 911785400...
Checkpoint 911785400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,981.91003
Policy Entropy: 3.10336
Value Function Loss: 0.00443

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10840
Policy Update Magnitude: 0.53849
Value Function Update Magnitude: 0.55951

Collected Steps per Second: 21,820.82835
Overall Steps per Second: 10,590.04309

Timestep Collection Time: 2.29267
Timestep Consumption Time: 2.43139
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.72406

Cumulative Model Updates: 109,336
Cumulative Timesteps: 911,835,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.99257
Policy Entropy: 3.10059
Value Function Loss: 0.00424

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11015
Policy Update Magnitude: 0.52911
Value Function Update Magnitude: 0.53984

Collected Steps per Second: 22,307.95035
Overall Steps per Second: 10,819.56542

Timestep Collection Time: 2.24171
Timestep Consumption Time: 2.38029
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.62200

Cumulative Model Updates: 109,342
Cumulative Timesteps: 911,885,436

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 911885436...
Checkpoint 911885436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,363.91152
Policy Entropy: 3.09483
Value Function Loss: 0.00420

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.53147
Value Function Update Magnitude: 0.53356

Collected Steps per Second: 21,889.26797
Overall Steps per Second: 10,784.88186

Timestep Collection Time: 2.28422
Timestep Consumption Time: 2.35189
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.63612

Cumulative Model Updates: 109,348
Cumulative Timesteps: 911,935,436

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.76158
Policy Entropy: 3.12097
Value Function Loss: 0.00410

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10077
Policy Update Magnitude: 0.52664
Value Function Update Magnitude: 0.53430

Collected Steps per Second: 22,299.12725
Overall Steps per Second: 10,807.50410

Timestep Collection Time: 2.24242
Timestep Consumption Time: 2.38437
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.62679

Cumulative Model Updates: 109,354
Cumulative Timesteps: 911,985,440

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 911985440...
Checkpoint 911985440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.56278
Policy Entropy: 3.12761
Value Function Loss: 0.00407

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10164
Policy Update Magnitude: 0.52427
Value Function Update Magnitude: 0.52323

Collected Steps per Second: 22,072.72750
Overall Steps per Second: 10,688.52678

Timestep Collection Time: 2.26660
Timestep Consumption Time: 2.41412
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.68072

Cumulative Model Updates: 109,360
Cumulative Timesteps: 912,035,470

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,952.49997
Policy Entropy: 3.12550
Value Function Loss: 0.00436

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.52677
Value Function Update Magnitude: 0.52062

Collected Steps per Second: 22,252.94693
Overall Steps per Second: 10,823.57078

Timestep Collection Time: 2.24770
Timestep Consumption Time: 2.37351
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.62121

Cumulative Model Updates: 109,366
Cumulative Timesteps: 912,085,488

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 912085488...
Checkpoint 912085488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.34867
Policy Entropy: 3.11688
Value Function Loss: 0.00471

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.54273
Value Function Update Magnitude: 0.52854

Collected Steps per Second: 22,041.61069
Overall Steps per Second: 10,734.50216

Timestep Collection Time: 2.26925
Timestep Consumption Time: 2.39030
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.65955

Cumulative Model Updates: 109,372
Cumulative Timesteps: 912,135,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.40504
Policy Entropy: 3.11850
Value Function Loss: 0.00524

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12298
Policy Update Magnitude: 0.55425
Value Function Update Magnitude: 0.56943

Collected Steps per Second: 20,675.78480
Overall Steps per Second: 10,354.65083

Timestep Collection Time: 2.41955
Timestep Consumption Time: 2.41171
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.83126

Cumulative Model Updates: 109,378
Cumulative Timesteps: 912,185,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 912185532...
Checkpoint 912185532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.22438
Policy Entropy: 3.13603
Value Function Loss: 0.00495

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.55730
Value Function Update Magnitude: 0.59732

Collected Steps per Second: 20,497.24233
Overall Steps per Second: 10,270.39487

Timestep Collection Time: 2.44023
Timestep Consumption Time: 2.42988
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.87011

Cumulative Model Updates: 109,384
Cumulative Timesteps: 912,235,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,787.12789
Policy Entropy: 3.12006
Value Function Loss: 0.00476

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.55190
Value Function Update Magnitude: 0.58794

Collected Steps per Second: 22,265.87113
Overall Steps per Second: 10,700.28299

Timestep Collection Time: 2.24631
Timestep Consumption Time: 2.42796
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.67427

Cumulative Model Updates: 109,390
Cumulative Timesteps: 912,285,566

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 912285566...
Checkpoint 912285566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.62881
Policy Entropy: 3.12809
Value Function Loss: 0.00433

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.08677
Policy Update Magnitude: 0.54516
Value Function Update Magnitude: 0.58209

Collected Steps per Second: 22,286.16520
Overall Steps per Second: 10,828.39167

Timestep Collection Time: 2.24408
Timestep Consumption Time: 2.37452
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.61860

Cumulative Model Updates: 109,396
Cumulative Timesteps: 912,335,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.09239
Policy Entropy: 3.12161
Value Function Loss: 0.00442

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.09276
Policy Update Magnitude: 0.53843
Value Function Update Magnitude: 0.56923

Collected Steps per Second: 23,323.51508
Overall Steps per Second: 10,886.42607

Timestep Collection Time: 2.14410
Timestep Consumption Time: 2.44951
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.59361

Cumulative Model Updates: 109,402
Cumulative Timesteps: 912,385,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 912385586...
Checkpoint 912385586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.28437
Policy Entropy: 3.12601
Value Function Loss: 0.00439

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08719
Policy Update Magnitude: 0.53741
Value Function Update Magnitude: 0.56013

Collected Steps per Second: 21,761.50735
Overall Steps per Second: 10,688.19007

Timestep Collection Time: 2.29837
Timestep Consumption Time: 2.38119
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.67956

Cumulative Model Updates: 109,408
Cumulative Timesteps: 912,435,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.51790
Policy Entropy: 3.10826
Value Function Loss: 0.00455

Mean KL Divergence: 0.00798
SB3 Clip Fraction: 0.08481
Policy Update Magnitude: 0.54188
Value Function Update Magnitude: 0.56062

Collected Steps per Second: 23,161.84044
Overall Steps per Second: 10,861.89884

Timestep Collection Time: 2.15872
Timestep Consumption Time: 2.44452
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.60325

Cumulative Model Updates: 109,414
Cumulative Timesteps: 912,485,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 912485602...
Checkpoint 912485602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.72130
Policy Entropy: 3.10452
Value Function Loss: 0.00466

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.54241
Value Function Update Magnitude: 0.56299

Collected Steps per Second: 22,031.51129
Overall Steps per Second: 10,743.50248

Timestep Collection Time: 2.27048
Timestep Consumption Time: 2.38555
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.65602

Cumulative Model Updates: 109,420
Cumulative Timesteps: 912,535,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.72748
Policy Entropy: 3.10994
Value Function Loss: 0.00467

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.54131
Value Function Update Magnitude: 0.58012

Collected Steps per Second: 22,213.29013
Overall Steps per Second: 10,798.04294

Timestep Collection Time: 2.25181
Timestep Consumption Time: 2.38052
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.63232

Cumulative Model Updates: 109,426
Cumulative Timesteps: 912,585,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 912585644...
Checkpoint 912585644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,538.79015
Policy Entropy: 3.12137
Value Function Loss: 0.00471

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.53990
Value Function Update Magnitude: 0.60163

Collected Steps per Second: 22,437.38149
Overall Steps per Second: 10,685.42752

Timestep Collection Time: 2.22860
Timestep Consumption Time: 2.45104
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.67964

Cumulative Model Updates: 109,432
Cumulative Timesteps: 912,635,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 771.32640
Policy Entropy: 3.12823
Value Function Loss: 0.00434

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08855
Policy Update Magnitude: 0.53392
Value Function Update Magnitude: 0.58363

Collected Steps per Second: 22,928.13849
Overall Steps per Second: 10,698.00735

Timestep Collection Time: 2.18212
Timestep Consumption Time: 2.49464
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.67676

Cumulative Model Updates: 109,438
Cumulative Timesteps: 912,685,680

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 912685680...
Checkpoint 912685680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,596.61690
Policy Entropy: 3.11929
Value Function Loss: 0.00459

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10042
Policy Update Magnitude: 0.53481
Value Function Update Magnitude: 0.58113

Collected Steps per Second: 22,880.22033
Overall Steps per Second: 10,788.24282

Timestep Collection Time: 2.18573
Timestep Consumption Time: 2.44987
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.63560

Cumulative Model Updates: 109,444
Cumulative Timesteps: 912,735,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.07377
Policy Entropy: 3.10462
Value Function Loss: 0.00467

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10282
Policy Update Magnitude: 0.55123
Value Function Update Magnitude: 0.60619

Collected Steps per Second: 22,796.24524
Overall Steps per Second: 10,613.02987

Timestep Collection Time: 2.19448
Timestep Consumption Time: 2.51916
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.71364

Cumulative Model Updates: 109,450
Cumulative Timesteps: 912,785,716

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 912785716...
Checkpoint 912785716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.94331
Policy Entropy: 3.10387
Value Function Loss: 0.00488

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.55841
Value Function Update Magnitude: 0.65307

Collected Steps per Second: 21,760.94787
Overall Steps per Second: 10,579.14327

Timestep Collection Time: 2.29852
Timestep Consumption Time: 2.42946
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.72798

Cumulative Model Updates: 109,456
Cumulative Timesteps: 912,835,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.62066
Policy Entropy: 3.10652
Value Function Loss: 0.00481

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11121
Policy Update Magnitude: 0.55886
Value Function Update Magnitude: 0.67320

Collected Steps per Second: 23,190.56111
Overall Steps per Second: 10,870.84396

Timestep Collection Time: 2.15605
Timestep Consumption Time: 2.44341
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.59946

Cumulative Model Updates: 109,462
Cumulative Timesteps: 912,885,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 912885734...
Checkpoint 912885734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.93368
Policy Entropy: 3.10540
Value Function Loss: 0.00477

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.56074
Value Function Update Magnitude: 0.66850

Collected Steps per Second: 21,815.05058
Overall Steps per Second: 10,713.59342

Timestep Collection Time: 2.29337
Timestep Consumption Time: 2.37640
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.66977

Cumulative Model Updates: 109,468
Cumulative Timesteps: 912,935,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,471.98237
Policy Entropy: 3.10325
Value Function Loss: 0.00461

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.63996

Collected Steps per Second: 22,443.04154
Overall Steps per Second: 10,835.79237

Timestep Collection Time: 2.22893
Timestep Consumption Time: 2.38762
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.61655

Cumulative Model Updates: 109,474
Cumulative Timesteps: 912,985,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 912985788...
Checkpoint 912985788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.00337
Policy Entropy: 3.09686
Value Function Loss: 0.00458

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.56013
Value Function Update Magnitude: 0.61502

Collected Steps per Second: 22,330.15772
Overall Steps per Second: 10,633.68028

Timestep Collection Time: 2.24029
Timestep Consumption Time: 2.46420
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.70449

Cumulative Model Updates: 109,480
Cumulative Timesteps: 913,035,814

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 789.36050
Policy Entropy: 3.10811
Value Function Loss: 0.00440

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.11791
Policy Update Magnitude: 0.54831
Value Function Update Magnitude: 0.59923

Collected Steps per Second: 23,097.00725
Overall Steps per Second: 10,831.00863

Timestep Collection Time: 2.16504
Timestep Consumption Time: 2.45189
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.61693

Cumulative Model Updates: 109,486
Cumulative Timesteps: 913,085,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 913085820...
Checkpoint 913085820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.85717
Policy Entropy: 3.10054
Value Function Loss: 0.00429

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.54123
Value Function Update Magnitude: 0.60411

Collected Steps per Second: 22,056.01512
Overall Steps per Second: 10,778.08250

Timestep Collection Time: 2.26813
Timestep Consumption Time: 2.37332
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.64146

Cumulative Model Updates: 109,492
Cumulative Timesteps: 913,135,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.99536
Policy Entropy: 3.10432
Value Function Loss: 0.00426

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11213
Policy Update Magnitude: 0.54059
Value Function Update Magnitude: 0.63110

Collected Steps per Second: 22,528.22673
Overall Steps per Second: 10,836.94769

Timestep Collection Time: 2.21979
Timestep Consumption Time: 2.39479
PPO Batch Consumption Time: 0.28345
Total Iteration Time: 4.61458

Cumulative Model Updates: 109,498
Cumulative Timesteps: 913,185,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 913185854...
Checkpoint 913185854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.61777
Policy Entropy: 3.08697
Value Function Loss: 0.00470

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09904
Policy Update Magnitude: 0.55237
Value Function Update Magnitude: 0.63767

Collected Steps per Second: 22,647.95870
Overall Steps per Second: 10,711.45741

Timestep Collection Time: 2.20894
Timestep Consumption Time: 2.46157
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.67051

Cumulative Model Updates: 109,504
Cumulative Timesteps: 913,235,882

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.98967
Policy Entropy: 3.09569
Value Function Loss: 0.00472

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11408
Policy Update Magnitude: 0.56209
Value Function Update Magnitude: 0.63840

Collected Steps per Second: 22,691.49035
Overall Steps per Second: 10,646.73997

Timestep Collection Time: 2.20461
Timestep Consumption Time: 2.49410
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.69872

Cumulative Model Updates: 109,510
Cumulative Timesteps: 913,285,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 913285908...
Checkpoint 913285908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 865.96331
Policy Entropy: 3.10110
Value Function Loss: 0.00477

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09601
Policy Update Magnitude: 0.56669
Value Function Update Magnitude: 0.64095

Collected Steps per Second: 22,965.61609
Overall Steps per Second: 10,836.74040

Timestep Collection Time: 2.17786
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.61541

Cumulative Model Updates: 109,516
Cumulative Timesteps: 913,335,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.33027
Policy Entropy: 3.11327
Value Function Loss: 0.00514

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09011
Policy Update Magnitude: 0.57562
Value Function Update Magnitude: 0.65076

Collected Steps per Second: 22,714.01051
Overall Steps per Second: 10,609.11991

Timestep Collection Time: 2.20243
Timestep Consumption Time: 2.51295
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.71538

Cumulative Model Updates: 109,522
Cumulative Timesteps: 913,385,950

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 913385950...
Checkpoint 913385950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.13121
Policy Entropy: 3.11493
Value Function Loss: 0.00492

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10109
Policy Update Magnitude: 0.57526
Value Function Update Magnitude: 0.67150

Collected Steps per Second: 22,609.64739
Overall Steps per Second: 10,581.80861

Timestep Collection Time: 2.21180
Timestep Consumption Time: 2.51405
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.72585

Cumulative Model Updates: 109,528
Cumulative Timesteps: 913,435,958

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 922.00895
Policy Entropy: 3.12291
Value Function Loss: 0.00473

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09971
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.64909

Collected Steps per Second: 22,874.46332
Overall Steps per Second: 10,784.67621

Timestep Collection Time: 2.18602
Timestep Consumption Time: 2.45056
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.63658

Cumulative Model Updates: 109,534
Cumulative Timesteps: 913,485,962

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 913485962...
Checkpoint 913485962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.33815
Policy Entropy: 3.11621
Value Function Loss: 0.00446

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.54739
Value Function Update Magnitude: 0.63985

Collected Steps per Second: 22,456.03270
Overall Steps per Second: 10,682.26255

Timestep Collection Time: 2.22675
Timestep Consumption Time: 2.45428
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.68103

Cumulative Model Updates: 109,540
Cumulative Timesteps: 913,535,966

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.08541
Policy Entropy: 3.10843
Value Function Loss: 0.00464

Mean KL Divergence: 0.00794
SB3 Clip Fraction: 0.08544
Policy Update Magnitude: 0.54955
Value Function Update Magnitude: 0.64760

Collected Steps per Second: 23,408.16608
Overall Steps per Second: 10,877.12388

Timestep Collection Time: 2.13660
Timestep Consumption Time: 2.46149
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.59809

Cumulative Model Updates: 109,546
Cumulative Timesteps: 913,585,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 913585980...
Checkpoint 913585980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,334.05309
Policy Entropy: 3.08233
Value Function Loss: 0.00499

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08862
Policy Update Magnitude: 0.56190
Value Function Update Magnitude: 0.66157

Collected Steps per Second: 22,605.96671
Overall Steps per Second: 10,721.96064

Timestep Collection Time: 2.21287
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.66556

Cumulative Model Updates: 109,552
Cumulative Timesteps: 913,636,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 930.57512
Policy Entropy: 3.07695
Value Function Loss: 0.00508

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.56912
Value Function Update Magnitude: 0.68306

Collected Steps per Second: 23,150.61851
Overall Steps per Second: 10,833.11327

Timestep Collection Time: 2.16081
Timestep Consumption Time: 2.45689
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.61769

Cumulative Model Updates: 109,558
Cumulative Timesteps: 913,686,028

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 913686028...
Checkpoint 913686028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 820.45216
Policy Entropy: 3.08667
Value Function Loss: 0.00485

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.66995

Collected Steps per Second: 22,742.89563
Overall Steps per Second: 10,689.74827

Timestep Collection Time: 2.19884
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.67813

Cumulative Model Updates: 109,564
Cumulative Timesteps: 913,736,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.15843
Policy Entropy: 3.08904
Value Function Loss: 0.00481

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10836
Policy Update Magnitude: 0.56829
Value Function Update Magnitude: 0.66656

Collected Steps per Second: 23,102.93384
Overall Steps per Second: 10,800.39749

Timestep Collection Time: 2.16561
Timestep Consumption Time: 2.46681
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.63242

Cumulative Model Updates: 109,570
Cumulative Timesteps: 913,786,068

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 913786068...
Checkpoint 913786068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.14958
Policy Entropy: 3.09555
Value Function Loss: 0.00489

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.57170
Value Function Update Magnitude: 0.65793

Collected Steps per Second: 22,808.60216
Overall Steps per Second: 10,750.12078

Timestep Collection Time: 2.19268
Timestep Consumption Time: 2.45955
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.65223

Cumulative Model Updates: 109,576
Cumulative Timesteps: 913,836,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.90679
Policy Entropy: 3.10754
Value Function Loss: 0.00489

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.56710
Value Function Update Magnitude: 0.65270

Collected Steps per Second: 21,931.74667
Overall Steps per Second: 10,609.51359

Timestep Collection Time: 2.28071
Timestep Consumption Time: 2.43392
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.71464

Cumulative Model Updates: 109,582
Cumulative Timesteps: 913,886,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 913886100...
Checkpoint 913886100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.71295
Policy Entropy: 3.12412
Value Function Loss: 0.00508

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.56010
Value Function Update Magnitude: 0.63872

Collected Steps per Second: 22,418.98922
Overall Steps per Second: 10,868.34632

Timestep Collection Time: 2.23114
Timestep Consumption Time: 2.37121
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.60236

Cumulative Model Updates: 109,588
Cumulative Timesteps: 913,936,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.14645
Policy Entropy: 3.13294
Value Function Loss: 0.00478

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09078
Policy Update Magnitude: 0.55113
Value Function Update Magnitude: 0.64095

Collected Steps per Second: 22,360.02810
Overall Steps per Second: 10,719.34131

Timestep Collection Time: 2.23703
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.66633

Cumulative Model Updates: 109,594
Cumulative Timesteps: 913,986,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 913986140...
Checkpoint 913986140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,141.32149
Policy Entropy: 3.11857
Value Function Loss: 0.00482

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.55260
Value Function Update Magnitude: 0.61729

Collected Steps per Second: 22,725.87944
Overall Steps per Second: 10,627.73243

Timestep Collection Time: 2.20049
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.70543

Cumulative Model Updates: 109,600
Cumulative Timesteps: 914,036,148

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.14780
Policy Entropy: 3.09909
Value Function Loss: 0.00470

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.55559
Value Function Update Magnitude: 0.61200

Collected Steps per Second: 23,118.05667
Overall Steps per Second: 10,751.58002

Timestep Collection Time: 2.16385
Timestep Consumption Time: 2.48886
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.65271

Cumulative Model Updates: 109,606
Cumulative Timesteps: 914,086,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 914086172...
Checkpoint 914086172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,084.90799
Policy Entropy: 3.09978
Value Function Loss: 0.00460

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.11005
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.62745

Collected Steps per Second: 22,739.33015
Overall Steps per Second: 10,651.08346

Timestep Collection Time: 2.19989
Timestep Consumption Time: 2.49672
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.69661

Cumulative Model Updates: 109,612
Cumulative Timesteps: 914,136,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.58254
Policy Entropy: 3.08290
Value Function Loss: 0.00476

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10640
Policy Update Magnitude: 0.55025
Value Function Update Magnitude: 0.63009

Collected Steps per Second: 23,177.64246
Overall Steps per Second: 10,815.11872

Timestep Collection Time: 2.15837
Timestep Consumption Time: 2.46719
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.62556

Cumulative Model Updates: 109,618
Cumulative Timesteps: 914,186,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 914186222...
Checkpoint 914186222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 880.09912
Policy Entropy: 3.09310
Value Function Loss: 0.00477

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.11080
Policy Update Magnitude: 0.54880
Value Function Update Magnitude: 0.61328

Collected Steps per Second: 22,285.05939
Overall Steps per Second: 10,634.59490

Timestep Collection Time: 2.24428
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.70295

Cumulative Model Updates: 109,624
Cumulative Timesteps: 914,236,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.47571
Policy Entropy: 3.10210
Value Function Loss: 0.00464

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.54428
Value Function Update Magnitude: 0.60361

Collected Steps per Second: 23,188.20744
Overall Steps per Second: 10,734.30396

Timestep Collection Time: 2.15687
Timestep Consumption Time: 2.50240
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.65927

Cumulative Model Updates: 109,630
Cumulative Timesteps: 914,286,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 914286250...
Checkpoint 914286250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 766.51699
Policy Entropy: 3.10925
Value Function Loss: 0.00452

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.54086
Value Function Update Magnitude: 0.61170

Collected Steps per Second: 22,724.15726
Overall Steps per Second: 10,659.15508

Timestep Collection Time: 2.20162
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.69362

Cumulative Model Updates: 109,636
Cumulative Timesteps: 914,336,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.52563
Policy Entropy: 3.10769
Value Function Loss: 0.00472

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.55004
Value Function Update Magnitude: 0.64123

Collected Steps per Second: 23,179.18568
Overall Steps per Second: 10,689.57640

Timestep Collection Time: 2.15823
Timestep Consumption Time: 2.52166
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.67989

Cumulative Model Updates: 109,642
Cumulative Timesteps: 914,386,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 914386306...
Checkpoint 914386306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471.42850
Policy Entropy: 3.10546
Value Function Loss: 0.00498

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.55529
Value Function Update Magnitude: 0.65090

Collected Steps per Second: 22,515.97823
Overall Steps per Second: 10,619.13110

Timestep Collection Time: 2.22118
Timestep Consumption Time: 2.48843
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.70961

Cumulative Model Updates: 109,648
Cumulative Timesteps: 914,436,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.42423
Policy Entropy: 3.11858
Value Function Loss: 0.00491

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.55243
Value Function Update Magnitude: 0.64532

Collected Steps per Second: 23,058.64150
Overall Steps per Second: 10,826.98463

Timestep Collection Time: 2.16847
Timestep Consumption Time: 2.44980
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.61828

Cumulative Model Updates: 109,654
Cumulative Timesteps: 914,486,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 914486320...
Checkpoint 914486320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.41495
Policy Entropy: 3.11388
Value Function Loss: 0.00526

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.56261
Value Function Update Magnitude: 0.63842

Collected Steps per Second: 22,885.23172
Overall Steps per Second: 10,732.67980

Timestep Collection Time: 2.18490
Timestep Consumption Time: 2.47395
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.65886

Cumulative Model Updates: 109,660
Cumulative Timesteps: 914,536,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,003.31878
Policy Entropy: 3.11724
Value Function Loss: 0.00532

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11142
Policy Update Magnitude: 0.57141
Value Function Update Magnitude: 0.64934

Collected Steps per Second: 23,039.62625
Overall Steps per Second: 10,826.63861

Timestep Collection Time: 2.17026
Timestep Consumption Time: 2.44816
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.61842

Cumulative Model Updates: 109,666
Cumulative Timesteps: 914,586,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 914586324...
Checkpoint 914586324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.35079
Policy Entropy: 3.10030
Value Function Loss: 0.00530

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.10925
Policy Update Magnitude: 0.56972
Value Function Update Magnitude: 0.66408

Collected Steps per Second: 22,721.26425
Overall Steps per Second: 10,756.85880

Timestep Collection Time: 2.20181
Timestep Consumption Time: 2.44899
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.65080

Cumulative Model Updates: 109,672
Cumulative Timesteps: 914,636,352

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.42452
Policy Entropy: 3.11733
Value Function Loss: 0.00468

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.55977
Value Function Update Magnitude: 0.65324

Collected Steps per Second: 23,157.56072
Overall Steps per Second: 10,885.58855

Timestep Collection Time: 2.15999
Timestep Consumption Time: 2.43508
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.59507

Cumulative Model Updates: 109,678
Cumulative Timesteps: 914,686,372

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 914686372...
Checkpoint 914686372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.52783
Policy Entropy: 3.10471
Value Function Loss: 0.00480

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09936
Policy Update Magnitude: 0.55393
Value Function Update Magnitude: 0.65353

Collected Steps per Second: 22,898.93335
Overall Steps per Second: 10,626.27885

Timestep Collection Time: 2.18412
Timestep Consumption Time: 2.52251
PPO Batch Consumption Time: 0.29531
Total Iteration Time: 4.70663

Cumulative Model Updates: 109,684
Cumulative Timesteps: 914,736,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.05465
Policy Entropy: 3.10229
Value Function Loss: 0.00482

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.55739
Value Function Update Magnitude: 0.66465

Collected Steps per Second: 22,621.18684
Overall Steps per Second: 10,609.64591

Timestep Collection Time: 2.21120
Timestep Consumption Time: 2.50338
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.71458

Cumulative Model Updates: 109,690
Cumulative Timesteps: 914,786,406

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 914786406...
Checkpoint 914786406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.33662
Policy Entropy: 3.08327
Value Function Loss: 0.00471

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.55660
Value Function Update Magnitude: 0.66364

Collected Steps per Second: 22,685.21353
Overall Steps per Second: 10,636.09079

Timestep Collection Time: 2.20523
Timestep Consumption Time: 2.49819
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.70342

Cumulative Model Updates: 109,696
Cumulative Timesteps: 914,836,432

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,101.90304
Policy Entropy: 3.09541
Value Function Loss: 0.00462

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.11941
Policy Update Magnitude: 0.55589
Value Function Update Magnitude: 0.63817

Collected Steps per Second: 23,057.45527
Overall Steps per Second: 10,787.90837

Timestep Collection Time: 2.16910
Timestep Consumption Time: 2.46701
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.63612

Cumulative Model Updates: 109,702
Cumulative Timesteps: 914,886,446

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 914886446...
Checkpoint 914886446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.90921
Policy Entropy: 3.11495
Value Function Loss: 0.00457

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.55158
Value Function Update Magnitude: 0.61738

Collected Steps per Second: 22,813.03442
Overall Steps per Second: 10,652.51318

Timestep Collection Time: 2.19252
Timestep Consumption Time: 2.50290
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.69542

Cumulative Model Updates: 109,708
Cumulative Timesteps: 914,936,464

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.40414
Policy Entropy: 3.11213
Value Function Loss: 0.00484

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.55270
Value Function Update Magnitude: 0.62120

Collected Steps per Second: 22,886.80771
Overall Steps per Second: 10,765.92669

Timestep Collection Time: 2.18571
Timestep Consumption Time: 2.46080
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.64651

Cumulative Model Updates: 109,714
Cumulative Timesteps: 914,986,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 914986488...
Checkpoint 914986488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,320.67856
Policy Entropy: 3.12067
Value Function Loss: 0.00471

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.55800
Value Function Update Magnitude: 0.63797

Collected Steps per Second: 22,717.71423
Overall Steps per Second: 10,799.58174

Timestep Collection Time: 2.20128
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.63055

Cumulative Model Updates: 109,720
Cumulative Timesteps: 915,036,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.01653
Policy Entropy: 3.13005
Value Function Loss: 0.00461

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.55812
Value Function Update Magnitude: 0.64551

Collected Steps per Second: 22,833.79380
Overall Steps per Second: 10,768.81784

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.45389
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.64415

Cumulative Model Updates: 109,726
Cumulative Timesteps: 915,086,508

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 915086508...
Checkpoint 915086508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,158.83977
Policy Entropy: 3.13590
Value Function Loss: 0.00448

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.54507
Value Function Update Magnitude: 0.63904

Collected Steps per Second: 23,032.40618
Overall Steps per Second: 10,758.72771

Timestep Collection Time: 2.17216
Timestep Consumption Time: 2.47802
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.65018

Cumulative Model Updates: 109,732
Cumulative Timesteps: 915,136,538

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 977.65782
Policy Entropy: 3.13556
Value Function Loss: 0.00458

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09369
Policy Update Magnitude: 0.53560
Value Function Update Magnitude: 0.61259

Collected Steps per Second: 23,197.28169
Overall Steps per Second: 10,875.22213

Timestep Collection Time: 2.15663
Timestep Consumption Time: 2.44355
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.60018

Cumulative Model Updates: 109,738
Cumulative Timesteps: 915,186,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 915186566...
Checkpoint 915186566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730.61223
Policy Entropy: 3.14228
Value Function Loss: 0.00461

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.53824
Value Function Update Magnitude: 0.60723

Collected Steps per Second: 22,667.22550
Overall Steps per Second: 10,667.82832

Timestep Collection Time: 2.20698
Timestep Consumption Time: 2.48245
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.68943

Cumulative Model Updates: 109,744
Cumulative Timesteps: 915,236,592

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.45456
Policy Entropy: 3.14854
Value Function Loss: 0.00482

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.08050
Policy Update Magnitude: 0.54978
Value Function Update Magnitude: 0.60308

Collected Steps per Second: 23,078.44109
Overall Steps per Second: 10,861.85584

Timestep Collection Time: 2.16730
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.60492

Cumulative Model Updates: 109,750
Cumulative Timesteps: 915,286,610

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 915286610...
Checkpoint 915286610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 989.01484
Policy Entropy: 3.15307
Value Function Loss: 0.00485

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.08363
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.60861

Collected Steps per Second: 23,012.35308
Overall Steps per Second: 10,693.77855

Timestep Collection Time: 2.17379
Timestep Consumption Time: 2.50407
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.67786

Cumulative Model Updates: 109,756
Cumulative Timesteps: 915,336,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,013.78783
Policy Entropy: 3.15453
Value Function Loss: 0.00500

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09431
Policy Update Magnitude: 0.55889
Value Function Update Magnitude: 0.61186

Collected Steps per Second: 22,506.71572
Overall Steps per Second: 10,844.22455

Timestep Collection Time: 2.22236
Timestep Consumption Time: 2.39005
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.61241

Cumulative Model Updates: 109,762
Cumulative Timesteps: 915,386,652

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 915386652...
Checkpoint 915386652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.54841
Policy Entropy: 3.14754
Value Function Loss: 0.00523

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 0.56613
Value Function Update Magnitude: 0.62411

Collected Steps per Second: 21,956.00412
Overall Steps per Second: 10,706.06088

Timestep Collection Time: 2.27737
Timestep Consumption Time: 2.39307
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.67044

Cumulative Model Updates: 109,768
Cumulative Timesteps: 915,436,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,589.30815
Policy Entropy: 3.14871
Value Function Loss: 0.00495

Mean KL Divergence: 0.01550
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.56323
Value Function Update Magnitude: 0.64112

Collected Steps per Second: 22,452.67328
Overall Steps per Second: 10,848.65908

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.38243
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.60979

Cumulative Model Updates: 109,774
Cumulative Timesteps: 915,486,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 915486664...
Checkpoint 915486664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.61276
Policy Entropy: 3.14976
Value Function Loss: 0.00488

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.55546
Value Function Update Magnitude: 0.62685

Collected Steps per Second: 22,020.12424
Overall Steps per Second: 10,720.69454

Timestep Collection Time: 2.27092
Timestep Consumption Time: 2.39351
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.66444

Cumulative Model Updates: 109,780
Cumulative Timesteps: 915,536,670

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.40994
Policy Entropy: 3.15141
Value Function Loss: 0.00469

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.55370
Value Function Update Magnitude: 0.63813

Collected Steps per Second: 21,962.54221
Overall Steps per Second: 10,572.00196

Timestep Collection Time: 2.27706
Timestep Consumption Time: 2.45336
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.73042

Cumulative Model Updates: 109,786
Cumulative Timesteps: 915,586,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 915586680...
Checkpoint 915586680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.29890
Policy Entropy: 3.15411
Value Function Loss: 0.00475

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10795
Policy Update Magnitude: 0.55823
Value Function Update Magnitude: 0.61782

Collected Steps per Second: 22,086.91347
Overall Steps per Second: 10,714.15863

Timestep Collection Time: 2.26442
Timestep Consumption Time: 2.40361
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.66803

Cumulative Model Updates: 109,792
Cumulative Timesteps: 915,636,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.45543
Policy Entropy: 3.13459
Value Function Loss: 0.00476

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12423
Policy Update Magnitude: 0.55633
Value Function Update Magnitude: 0.61021

Collected Steps per Second: 22,379.90304
Overall Steps per Second: 10,672.67771

Timestep Collection Time: 2.23442
Timestep Consumption Time: 2.45101
PPO Batch Consumption Time: 0.29460
Total Iteration Time: 4.68542

Cumulative Model Updates: 109,798
Cumulative Timesteps: 915,686,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 915686700...
Checkpoint 915686700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.58704
Policy Entropy: 3.13472
Value Function Loss: 0.00482

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.62937

Collected Steps per Second: 22,184.39374
Overall Steps per Second: 10,615.64547

Timestep Collection Time: 2.25474
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.29720
Total Iteration Time: 4.71191

Cumulative Model Updates: 109,804
Cumulative Timesteps: 915,736,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 888.41888
Policy Entropy: 3.13197
Value Function Loss: 0.00473

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.11789
Policy Update Magnitude: 0.55680
Value Function Update Magnitude: 0.63400

Collected Steps per Second: 22,361.69660
Overall Steps per Second: 10,843.22843

Timestep Collection Time: 2.23597
Timestep Consumption Time: 2.37521
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.61117

Cumulative Model Updates: 109,810
Cumulative Timesteps: 915,786,720

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 915786720...
Checkpoint 915786720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.81081
Policy Entropy: 3.15634
Value Function Loss: 0.00488

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11374
Policy Update Magnitude: 0.55938
Value Function Update Magnitude: 0.63445

Collected Steps per Second: 22,048.90948
Overall Steps per Second: 10,754.63919

Timestep Collection Time: 2.26832
Timestep Consumption Time: 2.38214
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.65046

Cumulative Model Updates: 109,816
Cumulative Timesteps: 915,836,734

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.44490
Policy Entropy: 3.15681
Value Function Loss: 0.00508

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.56425
Value Function Update Magnitude: 0.64730

Collected Steps per Second: 22,502.86403
Overall Steps per Second: 10,899.94961

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.36647
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.58956

Cumulative Model Updates: 109,822
Cumulative Timesteps: 915,886,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 915886760...
Checkpoint 915886760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.89072
Policy Entropy: 3.16941
Value Function Loss: 0.00487

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.56512
Value Function Update Magnitude: 0.64696

Collected Steps per Second: 22,183.83130
Overall Steps per Second: 10,630.91321

Timestep Collection Time: 2.25534
Timestep Consumption Time: 2.45094
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.70627

Cumulative Model Updates: 109,828
Cumulative Timesteps: 915,936,792

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,105.72423
Policy Entropy: 3.16929
Value Function Loss: 0.00499

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.55658
Value Function Update Magnitude: 0.63207

Collected Steps per Second: 22,338.79421
Overall Steps per Second: 10,846.12248

Timestep Collection Time: 2.23862
Timestep Consumption Time: 2.37206
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.61068

Cumulative Model Updates: 109,834
Cumulative Timesteps: 915,986,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 915986800...
Checkpoint 915986800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.75465
Policy Entropy: 3.18937
Value Function Loss: 0.00436

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.54469
Value Function Update Magnitude: 0.60937

Collected Steps per Second: 21,931.74732
Overall Steps per Second: 10,701.92595

Timestep Collection Time: 2.28108
Timestep Consumption Time: 2.39360
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.67467

Cumulative Model Updates: 109,840
Cumulative Timesteps: 916,036,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,451.80769
Policy Entropy: 3.17028
Value Function Loss: 0.00447

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09300
Policy Update Magnitude: 0.53997
Value Function Update Magnitude: 0.59108

Collected Steps per Second: 22,501.79986
Overall Steps per Second: 10,873.93868

Timestep Collection Time: 2.22240
Timestep Consumption Time: 2.37649
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.59889

Cumulative Model Updates: 109,846
Cumulative Timesteps: 916,086,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 916086836...
Checkpoint 916086836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.43711
Policy Entropy: 3.16585
Value Function Loss: 0.00424

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.54038
Value Function Update Magnitude: 0.60239

Collected Steps per Second: 21,969.95314
Overall Steps per Second: 10,716.84010

Timestep Collection Time: 2.27684
Timestep Consumption Time: 2.39077
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.66761

Cumulative Model Updates: 109,852
Cumulative Timesteps: 916,136,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,740.35540
Policy Entropy: 3.14680
Value Function Loss: 0.00451

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.53985
Value Function Update Magnitude: 0.59945

Collected Steps per Second: 22,301.34740
Overall Steps per Second: 10,798.35360

Timestep Collection Time: 2.24202
Timestep Consumption Time: 2.38832
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.63034

Cumulative Model Updates: 109,858
Cumulative Timesteps: 916,186,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 916186858...
Checkpoint 916186858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 953.00425
Policy Entropy: 3.15212
Value Function Loss: 0.00459

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.54461
Value Function Update Magnitude: 0.60010

Collected Steps per Second: 22,246.15343
Overall Steps per Second: 10,711.52145

Timestep Collection Time: 2.24839
Timestep Consumption Time: 2.42116
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.66955

Cumulative Model Updates: 109,864
Cumulative Timesteps: 916,236,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.08238
Policy Entropy: 3.14414
Value Function Loss: 0.00476

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10761
Policy Update Magnitude: 0.55879
Value Function Update Magnitude: 0.62764

Collected Steps per Second: 22,150.41321
Overall Steps per Second: 10,685.82925

Timestep Collection Time: 2.25766
Timestep Consumption Time: 2.42219
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.67984

Cumulative Model Updates: 109,870
Cumulative Timesteps: 916,286,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 916286884...
Checkpoint 916286884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,512.50329
Policy Entropy: 3.15630
Value Function Loss: 0.00513

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11275
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.64381

Collected Steps per Second: 22,437.00062
Overall Steps per Second: 10,885.96375

Timestep Collection Time: 2.22926
Timestep Consumption Time: 2.36546
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.59472

Cumulative Model Updates: 109,876
Cumulative Timesteps: 916,336,902

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.34016
Policy Entropy: 3.15839
Value Function Loss: 0.00500

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.11693
Policy Update Magnitude: 0.57935
Value Function Update Magnitude: 0.64870

Collected Steps per Second: 22,004.06139
Overall Steps per Second: 10,637.50154

Timestep Collection Time: 2.27331
Timestep Consumption Time: 2.42911
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.70242

Cumulative Model Updates: 109,882
Cumulative Timesteps: 916,386,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 916386924...
Checkpoint 916386924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.66492
Policy Entropy: 3.16934
Value Function Loss: 0.00504

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.57648
Value Function Update Magnitude: 0.63494

Collected Steps per Second: 22,064.34187
Overall Steps per Second: 10,764.81345

Timestep Collection Time: 2.26637
Timestep Consumption Time: 2.37895
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.64532

Cumulative Model Updates: 109,888
Cumulative Timesteps: 916,436,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.08045
Policy Entropy: 3.16782
Value Function Loss: 0.00498

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10286
Policy Update Magnitude: 0.57726
Value Function Update Magnitude: 0.60998

Collected Steps per Second: 22,081.90917
Overall Steps per Second: 10,602.30379

Timestep Collection Time: 2.26484
Timestep Consumption Time: 2.45225
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 4.71709

Cumulative Model Updates: 109,894
Cumulative Timesteps: 916,486,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 916486942...
Checkpoint 916486942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 850.96064
Policy Entropy: 3.14433
Value Function Loss: 0.00518

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.57029
Value Function Update Magnitude: 0.61706

Collected Steps per Second: 22,794.07053
Overall Steps per Second: 10,564.99622

Timestep Collection Time: 2.19434
Timestep Consumption Time: 2.53997
PPO Batch Consumption Time: 0.29807
Total Iteration Time: 4.73431

Cumulative Model Updates: 109,900
Cumulative Timesteps: 916,536,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.78854
Policy Entropy: 3.14071
Value Function Loss: 0.00476

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.56354
Value Function Update Magnitude: 0.62489

Collected Steps per Second: 22,055.49448
Overall Steps per Second: 10,607.52624

Timestep Collection Time: 2.26792
Timestep Consumption Time: 2.44760
PPO Batch Consumption Time: 0.29483
Total Iteration Time: 4.71552

Cumulative Model Updates: 109,906
Cumulative Timesteps: 916,586,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 916586980...
Checkpoint 916586980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 932.52281
Policy Entropy: 3.12074
Value Function Loss: 0.00461

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11383
Policy Update Magnitude: 0.54927
Value Function Update Magnitude: 0.60696

Collected Steps per Second: 22,906.91195
Overall Steps per Second: 10,669.18041

Timestep Collection Time: 2.18371
Timestep Consumption Time: 2.50475
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.68846

Cumulative Model Updates: 109,912
Cumulative Timesteps: 916,637,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.53955
Policy Entropy: 3.13243
Value Function Loss: 0.00463

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.54616
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 23,236.35274
Overall Steps per Second: 10,781.23654

Timestep Collection Time: 2.15240
Timestep Consumption Time: 2.48658
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.63899

Cumulative Model Updates: 109,918
Cumulative Timesteps: 916,687,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 916687016...
Checkpoint 916687016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 898.55626
Policy Entropy: 3.13147
Value Function Loss: 0.00467

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.59457

Collected Steps per Second: 22,014.60514
Overall Steps per Second: 10,629.04690

Timestep Collection Time: 2.27331
Timestep Consumption Time: 2.43511
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.70842

Cumulative Model Updates: 109,924
Cumulative Timesteps: 916,737,062

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.29644
Policy Entropy: 3.14152
Value Function Loss: 0.00458

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09319
Policy Update Magnitude: 0.55064
Value Function Update Magnitude: 0.59236

Collected Steps per Second: 22,951.45361
Overall Steps per Second: 10,816.16696

Timestep Collection Time: 2.17947
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.62474

Cumulative Model Updates: 109,930
Cumulative Timesteps: 916,787,084

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 916787084...
Checkpoint 916787084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,116.39835
Policy Entropy: 3.14540
Value Function Loss: 0.00437

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.08942
Policy Update Magnitude: 0.55062
Value Function Update Magnitude: 0.58099

Collected Steps per Second: 22,126.65406
Overall Steps per Second: 10,749.90319

Timestep Collection Time: 2.26107
Timestep Consumption Time: 2.39292
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.65400

Cumulative Model Updates: 109,936
Cumulative Timesteps: 916,837,114

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,479.36223
Policy Entropy: 3.13703
Value Function Loss: 0.00440

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.08558
Policy Update Magnitude: 0.54928
Value Function Update Magnitude: 0.57858

Collected Steps per Second: 21,885.50288
Overall Steps per Second: 10,591.04250

Timestep Collection Time: 2.28562
Timestep Consumption Time: 2.43743
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.72305

Cumulative Model Updates: 109,942
Cumulative Timesteps: 916,887,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 916887136...
Checkpoint 916887136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.87000
Policy Entropy: 3.13816
Value Function Loss: 0.00451

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08365
Policy Update Magnitude: 0.55083
Value Function Update Magnitude: 0.58461

Collected Steps per Second: 22,329.80022
Overall Steps per Second: 10,833.02530

Timestep Collection Time: 2.24024
Timestep Consumption Time: 2.37750
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.61773

Cumulative Model Updates: 109,948
Cumulative Timesteps: 916,937,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.25784
Policy Entropy: 3.12201
Value Function Loss: 0.00480

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08504
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.60787

Collected Steps per Second: 22,633.44542
Overall Steps per Second: 10,563.82722

Timestep Collection Time: 2.20921
Timestep Consumption Time: 2.52411
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.73332

Cumulative Model Updates: 109,954
Cumulative Timesteps: 916,987,162

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 916987162...
Checkpoint 916987162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.12788
Policy Entropy: 3.11852
Value Function Loss: 0.00479

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08731
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.61969

Collected Steps per Second: 22,219.30845
Overall Steps per Second: 10,622.79626

Timestep Collection Time: 2.25138
Timestep Consumption Time: 2.45774
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.70912

Cumulative Model Updates: 109,960
Cumulative Timesteps: 917,037,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.00516
Policy Entropy: 3.12946
Value Function Loss: 0.00495

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.10746
Policy Update Magnitude: 0.58396
Value Function Update Magnitude: 0.63238

Collected Steps per Second: 22,198.20633
Overall Steps per Second: 10,700.68848

Timestep Collection Time: 2.25379
Timestep Consumption Time: 2.42161
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.67540

Cumulative Model Updates: 109,966
Cumulative Timesteps: 917,087,216

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 917087216...
Checkpoint 917087216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,127.60097
Policy Entropy: 3.16195
Value Function Loss: 0.00495

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.11669
Policy Update Magnitude: 0.57886
Value Function Update Magnitude: 0.61861

Collected Steps per Second: 21,314.01567
Overall Steps per Second: 10,418.18894

Timestep Collection Time: 2.34634
Timestep Consumption Time: 2.45392
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.80026

Cumulative Model Updates: 109,972
Cumulative Timesteps: 917,137,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,952.35210
Policy Entropy: 3.16278
Value Function Loss: 0.00494

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.11975
Policy Update Magnitude: 0.56520
Value Function Update Magnitude: 0.60444

Collected Steps per Second: 22,067.32475
Overall Steps per Second: 10,665.19609

Timestep Collection Time: 2.26706
Timestep Consumption Time: 2.42371
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.69077

Cumulative Model Updates: 109,978
Cumulative Timesteps: 917,187,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 917187254...
Checkpoint 917187254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.03827
Policy Entropy: 3.16206
Value Function Loss: 0.00476

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.56398
Value Function Update Magnitude: 0.59829

Collected Steps per Second: 22,217.17430
Overall Steps per Second: 10,783.86293

Timestep Collection Time: 2.25087
Timestep Consumption Time: 2.38643
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.63730

Cumulative Model Updates: 109,984
Cumulative Timesteps: 917,237,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.07202
Policy Entropy: 3.14169
Value Function Loss: 0.00456

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.55831
Value Function Update Magnitude: 0.58962

Collected Steps per Second: 22,332.25755
Overall Steps per Second: 10,674.33745

Timestep Collection Time: 2.23936
Timestep Consumption Time: 2.44571
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.68507

Cumulative Model Updates: 109,990
Cumulative Timesteps: 917,287,272

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 917287272...
Checkpoint 917287272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,769.03885
Policy Entropy: 3.13831
Value Function Loss: 0.00439

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.57910

Collected Steps per Second: 21,760.75625
Overall Steps per Second: 10,544.70820

Timestep Collection Time: 2.29918
Timestep Consumption Time: 2.44556
PPO Batch Consumption Time: 0.29436
Total Iteration Time: 4.74475

Cumulative Model Updates: 109,996
Cumulative Timesteps: 917,337,304

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.32251
Policy Entropy: 3.12481
Value Function Loss: 0.00454

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.54699
Value Function Update Magnitude: 0.57878

Collected Steps per Second: 21,946.83766
Overall Steps per Second: 10,604.82558

Timestep Collection Time: 2.27869
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.71578

Cumulative Model Updates: 110,002
Cumulative Timesteps: 917,387,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 917387314...
Checkpoint 917387314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.11333
Policy Entropy: 3.11030
Value Function Loss: 0.00475

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11825
Policy Update Magnitude: 0.55940
Value Function Update Magnitude: 0.60775

Collected Steps per Second: 22,024.10055
Overall Steps per Second: 10,667.06440

Timestep Collection Time: 2.27051
Timestep Consumption Time: 2.41738
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.68789

Cumulative Model Updates: 110,008
Cumulative Timesteps: 917,437,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.60355
Policy Entropy: 3.12398
Value Function Loss: 0.00481

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.56610
Value Function Update Magnitude: 0.61873

Collected Steps per Second: 22,334.88372
Overall Steps per Second: 10,724.28951

Timestep Collection Time: 2.23892
Timestep Consumption Time: 2.42395
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.66287

Cumulative Model Updates: 110,014
Cumulative Timesteps: 917,487,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 917487326...
Checkpoint 917487326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.79039
Policy Entropy: 3.13234
Value Function Loss: 0.00481

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.56898
Value Function Update Magnitude: 0.62393

Collected Steps per Second: 22,170.25228
Overall Steps per Second: 10,604.95191

Timestep Collection Time: 2.25699
Timestep Consumption Time: 2.46137
PPO Batch Consumption Time: 0.29725
Total Iteration Time: 4.71836

Cumulative Model Updates: 110,020
Cumulative Timesteps: 917,537,364

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.27527
Policy Entropy: 3.15405
Value Function Loss: 0.00459

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.55977
Value Function Update Magnitude: 0.61062

Collected Steps per Second: 22,101.58990
Overall Steps per Second: 10,658.34500

Timestep Collection Time: 2.26319
Timestep Consumption Time: 2.42985
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.69304

Cumulative Model Updates: 110,026
Cumulative Timesteps: 917,587,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 917587384...
Checkpoint 917587384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.75961
Policy Entropy: 3.15074
Value Function Loss: 0.00452

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.55665
Value Function Update Magnitude: 0.60068

Collected Steps per Second: 22,391.23206
Overall Steps per Second: 10,835.88420

Timestep Collection Time: 2.23337
Timestep Consumption Time: 2.38166
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.61504

Cumulative Model Updates: 110,032
Cumulative Timesteps: 917,637,392

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.13122
Policy Entropy: 3.15764
Value Function Loss: 0.00432

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.55277
Value Function Update Magnitude: 0.59534

Collected Steps per Second: 22,015.36488
Overall Steps per Second: 10,623.26956

Timestep Collection Time: 2.27114
Timestep Consumption Time: 2.43551
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.70665

Cumulative Model Updates: 110,038
Cumulative Timesteps: 917,687,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 917687392...
Checkpoint 917687392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.87867
Policy Entropy: 3.14419
Value Function Loss: 0.00450

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09533
Policy Update Magnitude: 0.55301
Value Function Update Magnitude: 0.57686

Collected Steps per Second: 22,112.45216
Overall Steps per Second: 10,625.31100

Timestep Collection Time: 2.26235
Timestep Consumption Time: 2.44585
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.70819

Cumulative Model Updates: 110,044
Cumulative Timesteps: 917,737,418

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.88170
Policy Entropy: 3.15329
Value Function Loss: 0.00449

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.54477
Value Function Update Magnitude: 0.56889

Collected Steps per Second: 22,377.98909
Overall Steps per Second: 10,855.91631

Timestep Collection Time: 2.23496
Timestep Consumption Time: 2.37211
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.60707

Cumulative Model Updates: 110,050
Cumulative Timesteps: 917,787,432

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 917787432...
Checkpoint 917787432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.73287
Policy Entropy: 3.14946
Value Function Loss: 0.00449

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08526
Policy Update Magnitude: 0.54770
Value Function Update Magnitude: 0.57929

Collected Steps per Second: 22,816.59924
Overall Steps per Second: 10,615.86964

Timestep Collection Time: 2.19226
Timestep Consumption Time: 2.51955
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.71181

Cumulative Model Updates: 110,056
Cumulative Timesteps: 917,837,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 873.07131
Policy Entropy: 3.17778
Value Function Loss: 0.00446

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 0.54810
Value Function Update Magnitude: 0.57418

Collected Steps per Second: 23,035.71757
Overall Steps per Second: 10,810.26288

Timestep Collection Time: 2.17124
Timestep Consumption Time: 2.45548
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.62671

Cumulative Model Updates: 110,062
Cumulative Timesteps: 917,887,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 917887468...
Checkpoint 917887468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.67419
Policy Entropy: 3.18060
Value Function Loss: 0.00461

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.55589
Value Function Update Magnitude: 0.58245

Collected Steps per Second: 22,148.09305
Overall Steps per Second: 10,710.48908

Timestep Collection Time: 2.25753
Timestep Consumption Time: 2.41079
PPO Batch Consumption Time: 0.28573
Total Iteration Time: 4.66832

Cumulative Model Updates: 110,068
Cumulative Timesteps: 917,937,468

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,002.82872
Policy Entropy: 3.18433
Value Function Loss: 0.00443

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.56056
Value Function Update Magnitude: 0.59121

Collected Steps per Second: 21,805.24599
Overall Steps per Second: 10,514.89395

Timestep Collection Time: 2.29440
Timestep Consumption Time: 2.46361
PPO Batch Consumption Time: 0.29719
Total Iteration Time: 4.75801

Cumulative Model Updates: 110,074
Cumulative Timesteps: 917,987,498

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 917987498...
Checkpoint 917987498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.49066
Policy Entropy: 3.17723
Value Function Loss: 0.00461

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09938
Policy Update Magnitude: 0.55454
Value Function Update Magnitude: 0.58206

Collected Steps per Second: 22,211.97039
Overall Steps per Second: 10,641.43137

Timestep Collection Time: 2.25239
Timestep Consumption Time: 2.44905
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.70144

Cumulative Model Updates: 110,080
Cumulative Timesteps: 918,037,528

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.25022
Policy Entropy: 3.18833
Value Function Loss: 0.00467

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.08885
Policy Update Magnitude: 0.55177
Value Function Update Magnitude: 0.56962

Collected Steps per Second: 21,871.32562
Overall Steps per Second: 10,603.70764

Timestep Collection Time: 2.28738
Timestep Consumption Time: 2.43059
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.71797

Cumulative Model Updates: 110,086
Cumulative Timesteps: 918,087,556

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 918087556...
Checkpoint 918087556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,305.36547
Policy Entropy: 3.16881
Value Function Loss: 0.00477

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.08453
Policy Update Magnitude: 0.54752
Value Function Update Magnitude: 0.57416

Collected Steps per Second: 22,341.92447
Overall Steps per Second: 10,844.62923

Timestep Collection Time: 2.23803
Timestep Consumption Time: 2.37273
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.61076

Cumulative Model Updates: 110,092
Cumulative Timesteps: 918,137,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.94467
Policy Entropy: 3.17490
Value Function Loss: 0.00453

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.08001
Policy Update Magnitude: 0.54436
Value Function Update Magnitude: 0.56597

Collected Steps per Second: 22,091.33091
Overall Steps per Second: 10,637.41261

Timestep Collection Time: 2.26424
Timestep Consumption Time: 2.43803
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.70227

Cumulative Model Updates: 110,098
Cumulative Timesteps: 918,187,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 918187578...
Checkpoint 918187578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.88362
Policy Entropy: 3.15790
Value Function Loss: 0.00448

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.08313
Policy Update Magnitude: 0.54919
Value Function Update Magnitude: 0.58758

Collected Steps per Second: 22,466.21289
Overall Steps per Second: 10,874.64114

Timestep Collection Time: 2.22699
Timestep Consumption Time: 2.37381
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.60080

Cumulative Model Updates: 110,104
Cumulative Timesteps: 918,237,610

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,427.27436
Policy Entropy: 3.15715
Value Function Loss: 0.00437

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.54712
Value Function Update Magnitude: 0.59844

Collected Steps per Second: 21,986.56924
Overall Steps per Second: 10,617.61234

Timestep Collection Time: 2.27539
Timestep Consumption Time: 2.43640
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.71179

Cumulative Model Updates: 110,110
Cumulative Timesteps: 918,287,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 918287638...
Checkpoint 918287638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.14352
Policy Entropy: 3.15084
Value Function Loss: 0.00447

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10345
Policy Update Magnitude: 0.54689
Value Function Update Magnitude: 0.57906

Collected Steps per Second: 22,158.67663
Overall Steps per Second: 10,646.76579

Timestep Collection Time: 2.25654
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.69645

Cumulative Model Updates: 110,116
Cumulative Timesteps: 918,337,640

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,650.63861
Policy Entropy: 3.15996
Value Function Loss: 0.00482

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.55332
Value Function Update Magnitude: 0.58221

Collected Steps per Second: 22,267.60261
Overall Steps per Second: 10,791.37537

Timestep Collection Time: 2.24541
Timestep Consumption Time: 2.38792
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.63333

Cumulative Model Updates: 110,122
Cumulative Timesteps: 918,387,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 918387640...
Checkpoint 918387640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 798.35077
Policy Entropy: 3.15455
Value Function Loss: 0.00493

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.55943
Value Function Update Magnitude: 0.61041

Collected Steps per Second: 22,027.86487
Overall Steps per Second: 10,690.29677

Timestep Collection Time: 2.27003
Timestep Consumption Time: 2.40748
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.67751

Cumulative Model Updates: 110,128
Cumulative Timesteps: 918,437,644

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.85592
Policy Entropy: 3.15174
Value Function Loss: 0.00477

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.55787
Value Function Update Magnitude: 0.62012

Collected Steps per Second: 22,279.34876
Overall Steps per Second: 10,813.87206

Timestep Collection Time: 2.24531
Timestep Consumption Time: 2.38060
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.62591

Cumulative Model Updates: 110,134
Cumulative Timesteps: 918,487,668

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 918487668...
Checkpoint 918487668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.41364
Policy Entropy: 3.14608
Value Function Loss: 0.00461

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10702
Policy Update Magnitude: 0.55180
Value Function Update Magnitude: 0.62255

Collected Steps per Second: 21,721.77351
Overall Steps per Second: 10,712.61932

Timestep Collection Time: 2.30368
Timestep Consumption Time: 2.36745
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.67113

Cumulative Model Updates: 110,140
Cumulative Timesteps: 918,537,708

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.33344
Policy Entropy: 3.14540
Value Function Loss: 0.00495

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.56475
Value Function Update Magnitude: 0.63223

Collected Steps per Second: 22,075.32219
Overall Steps per Second: 10,605.71331

Timestep Collection Time: 2.26534
Timestep Consumption Time: 2.44986
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.71519

Cumulative Model Updates: 110,146
Cumulative Timesteps: 918,587,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 918587716...
Checkpoint 918587716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.04204
Policy Entropy: 3.14952
Value Function Loss: 0.00488

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.57323
Value Function Update Magnitude: 0.64642

Collected Steps per Second: 22,157.99307
Overall Steps per Second: 10,703.65363

Timestep Collection Time: 2.25733
Timestep Consumption Time: 2.41565
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.67298

Cumulative Model Updates: 110,152
Cumulative Timesteps: 918,637,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.77803
Policy Entropy: 3.14505
Value Function Loss: 0.00476

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.56930
Value Function Update Magnitude: 0.64092

Collected Steps per Second: 22,351.94206
Overall Steps per Second: 10,738.31462

Timestep Collection Time: 2.23811
Timestep Consumption Time: 2.42054
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.65865

Cumulative Model Updates: 110,158
Cumulative Timesteps: 918,687,760

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 918687760...
Checkpoint 918687760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.24887
Policy Entropy: 3.15670
Value Function Loss: 0.00455

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.08863
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.60129

Collected Steps per Second: 22,360.94447
Overall Steps per Second: 10,671.45911

Timestep Collection Time: 2.23667
Timestep Consumption Time: 2.45004
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.68671

Cumulative Model Updates: 110,164
Cumulative Timesteps: 918,737,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.15273
Policy Entropy: 3.14918
Value Function Loss: 0.00449

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.55251
Value Function Update Magnitude: 0.60399

Collected Steps per Second: 21,980.04913
Overall Steps per Second: 10,747.76166

Timestep Collection Time: 2.27570
Timestep Consumption Time: 2.37829
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.65399

Cumulative Model Updates: 110,170
Cumulative Timesteps: 918,787,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 918787794...
Checkpoint 918787794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,916.99520
Policy Entropy: 3.15363
Value Function Loss: 0.00434

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.54518
Value Function Update Magnitude: 0.61181

Collected Steps per Second: 21,998.73090
Overall Steps per Second: 10,760.41083

Timestep Collection Time: 2.27295
Timestep Consumption Time: 2.37390
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.64685

Cumulative Model Updates: 110,176
Cumulative Timesteps: 918,837,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 737.18689
Policy Entropy: 3.14995
Value Function Loss: 0.00425

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08776
Policy Update Magnitude: 0.54278
Value Function Update Magnitude: 0.58902

Collected Steps per Second: 21,926.62833
Overall Steps per Second: 10,632.72493

Timestep Collection Time: 2.28134
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.70453

Cumulative Model Updates: 110,182
Cumulative Timesteps: 918,887,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 918887818...
Checkpoint 918887818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.80093
Policy Entropy: 3.12980
Value Function Loss: 0.00464

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09383
Policy Update Magnitude: 0.56094
Value Function Update Magnitude: 0.59877

Collected Steps per Second: 22,192.29425
Overall Steps per Second: 10,812.16691

Timestep Collection Time: 2.25348
Timestep Consumption Time: 2.37186
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.62534

Cumulative Model Updates: 110,188
Cumulative Timesteps: 918,937,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,091.64279
Policy Entropy: 3.13248
Value Function Loss: 0.00469

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.56762
Value Function Update Magnitude: 0.61380

Collected Steps per Second: 22,738.12111
Overall Steps per Second: 10,614.40487

Timestep Collection Time: 2.19974
Timestep Consumption Time: 2.51253
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.71228

Cumulative Model Updates: 110,194
Cumulative Timesteps: 918,987,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 918987846...
Checkpoint 918987846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.95826
Policy Entropy: 3.13988
Value Function Loss: 0.00467

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.56422
Value Function Update Magnitude: 0.59857

Collected Steps per Second: 22,188.93306
Overall Steps per Second: 10,649.35041

Timestep Collection Time: 2.25419
Timestep Consumption Time: 2.44263
PPO Batch Consumption Time: 0.29509
Total Iteration Time: 4.69681

Cumulative Model Updates: 110,200
Cumulative Timesteps: 919,037,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.93979
Policy Entropy: 3.15922
Value Function Loss: 0.00507

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08452
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.58753

Collected Steps per Second: 22,330.04550
Overall Steps per Second: 10,864.45377

Timestep Collection Time: 2.23967
Timestep Consumption Time: 2.36360
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.60327

Cumulative Model Updates: 110,206
Cumulative Timesteps: 919,087,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 919087876...
Checkpoint 919087876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,831.25912
Policy Entropy: 3.14649
Value Function Loss: 0.00519

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09653
Policy Update Magnitude: 0.56705
Value Function Update Magnitude: 0.58445

Collected Steps per Second: 22,075.30464
Overall Steps per Second: 10,634.96979

Timestep Collection Time: 2.26543
Timestep Consumption Time: 2.43698
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70241

Cumulative Model Updates: 110,212
Cumulative Timesteps: 919,137,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.81300
Policy Entropy: 3.12861
Value Function Loss: 0.00500

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09822
Policy Update Magnitude: 0.57620
Value Function Update Magnitude: 0.61101

Collected Steps per Second: 21,967.04030
Overall Steps per Second: 10,620.86004

Timestep Collection Time: 2.27632
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.70809

Cumulative Model Updates: 110,218
Cumulative Timesteps: 919,187,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 919187890...
Checkpoint 919187890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.34651
Policy Entropy: 3.10492
Value Function Loss: 0.00459

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.57843
Value Function Update Magnitude: 0.61704

Collected Steps per Second: 23,158.49937
Overall Steps per Second: 10,839.73005

Timestep Collection Time: 2.15912
Timestep Consumption Time: 2.45372
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.61285

Cumulative Model Updates: 110,224
Cumulative Timesteps: 919,237,892

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.62235
Policy Entropy: 3.12559
Value Function Loss: 0.00461

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.57684
Value Function Update Magnitude: 0.60820

Collected Steps per Second: 22,966.94830
Overall Steps per Second: 10,669.17095

Timestep Collection Time: 2.17713
Timestep Consumption Time: 2.50946
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.68659

Cumulative Model Updates: 110,230
Cumulative Timesteps: 919,287,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 919287894...
Checkpoint 919287894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.05304
Policy Entropy: 3.13210
Value Function Loss: 0.00489

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09525
Policy Update Magnitude: 0.58336
Value Function Update Magnitude: 0.62254

Collected Steps per Second: 23,239.82579
Overall Steps per Second: 10,880.32599

Timestep Collection Time: 2.15174
Timestep Consumption Time: 2.44426
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.59600

Cumulative Model Updates: 110,236
Cumulative Timesteps: 919,337,900

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 823.24079
Policy Entropy: 3.13661
Value Function Loss: 0.00488

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09140
Policy Update Magnitude: 0.58571
Value Function Update Magnitude: 0.62999

Collected Steps per Second: 22,863.92354
Overall Steps per Second: 10,652.35177

Timestep Collection Time: 2.18773
Timestep Consumption Time: 2.50795
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.69568

Cumulative Model Updates: 110,242
Cumulative Timesteps: 919,387,920

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 919387920...
Checkpoint 919387920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.50332
Policy Entropy: 3.12820
Value Function Loss: 0.00494

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09754
Policy Update Magnitude: 0.57824
Value Function Update Magnitude: 0.62282

Collected Steps per Second: 23,028.80032
Overall Steps per Second: 10,830.99886

Timestep Collection Time: 2.17119
Timestep Consumption Time: 2.44519
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.61638

Cumulative Model Updates: 110,248
Cumulative Timesteps: 919,437,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.85595
Policy Entropy: 3.13361
Value Function Loss: 0.00488

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.57310
Value Function Update Magnitude: 0.62930

Collected Steps per Second: 22,934.59110
Overall Steps per Second: 10,672.45745

Timestep Collection Time: 2.18029
Timestep Consumption Time: 2.50504
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.68533

Cumulative Model Updates: 110,254
Cumulative Timesteps: 919,487,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 919487924...
Checkpoint 919487924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.10413
Policy Entropy: 3.13783
Value Function Loss: 0.00465

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.56703
Value Function Update Magnitude: 0.63018

Collected Steps per Second: 22,151.57714
Overall Steps per Second: 10,659.79628

Timestep Collection Time: 2.25736
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.69090

Cumulative Model Updates: 110,260
Cumulative Timesteps: 919,537,928

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,916.99896
Policy Entropy: 3.13913
Value Function Loss: 0.00424

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.55946
Value Function Update Magnitude: 0.61819

Collected Steps per Second: 21,788.53023
Overall Steps per Second: 10,696.82139

Timestep Collection Time: 2.29534
Timestep Consumption Time: 2.38007
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.67541

Cumulative Model Updates: 110,266
Cumulative Timesteps: 919,587,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 919587940...
Checkpoint 919587940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.10780
Policy Entropy: 3.13427
Value Function Loss: 0.00425

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10735
Policy Update Magnitude: 0.54829
Value Function Update Magnitude: 0.59094

Collected Steps per Second: 22,011.33623
Overall Steps per Second: 10,667.92947

Timestep Collection Time: 2.27247
Timestep Consumption Time: 2.41635
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.68882

Cumulative Model Updates: 110,272
Cumulative Timesteps: 919,637,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.37988
Policy Entropy: 3.14167
Value Function Loss: 0.00449

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.10993
Policy Update Magnitude: 0.55074
Value Function Update Magnitude: 0.58664

Collected Steps per Second: 22,333.57810
Overall Steps per Second: 10,853.84028

Timestep Collection Time: 2.23995
Timestep Consumption Time: 2.36911
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.60906

Cumulative Model Updates: 110,278
Cumulative Timesteps: 919,687,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 919687986...
Checkpoint 919687986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,102.70343
Policy Entropy: 3.14074
Value Function Loss: 0.00462

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10620
Policy Update Magnitude: 0.55205
Value Function Update Magnitude: 0.59726

Collected Steps per Second: 22,323.96990
Overall Steps per Second: 10,797.61662

Timestep Collection Time: 2.24064
Timestep Consumption Time: 2.39186
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.63250

Cumulative Model Updates: 110,284
Cumulative Timesteps: 919,738,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.56414
Policy Entropy: 3.13429
Value Function Loss: 0.00472

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10977
Policy Update Magnitude: 0.55618
Value Function Update Magnitude: 0.60340

Collected Steps per Second: 22,285.49256
Overall Steps per Second: 10,807.16430

Timestep Collection Time: 2.24469
Timestep Consumption Time: 2.38409
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.62878

Cumulative Model Updates: 110,290
Cumulative Timesteps: 919,788,030

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 919788030...
Checkpoint 919788030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,741.67367
Policy Entropy: 3.13516
Value Function Loss: 0.00446

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10180
Policy Update Magnitude: 0.56024
Value Function Update Magnitude: 0.60236

Collected Steps per Second: 22,159.01245
Overall Steps per Second: 10,684.48622

Timestep Collection Time: 2.25714
Timestep Consumption Time: 2.42404
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.68118

Cumulative Model Updates: 110,296
Cumulative Timesteps: 919,838,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 731.49156
Policy Entropy: 3.14769
Value Function Loss: 0.00485

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.56292
Value Function Update Magnitude: 0.59805

Collected Steps per Second: 21,841.61363
Overall Steps per Second: 10,584.68670

Timestep Collection Time: 2.28994
Timestep Consumption Time: 2.43538
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.72532

Cumulative Model Updates: 110,302
Cumulative Timesteps: 919,888,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 919888062...
Checkpoint 919888062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,710.24465
Policy Entropy: 3.16522
Value Function Loss: 0.00473

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09150
Policy Update Magnitude: 0.56381
Value Function Update Magnitude: 0.61804

Collected Steps per Second: 22,077.99015
Overall Steps per Second: 10,664.29152

Timestep Collection Time: 2.26470
Timestep Consumption Time: 2.42385
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.68854

Cumulative Model Updates: 110,308
Cumulative Timesteps: 919,938,062

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.45305
Policy Entropy: 3.15813
Value Function Loss: 0.00468

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.08665
Policy Update Magnitude: 0.55987
Value Function Update Magnitude: 0.61236

Collected Steps per Second: 22,243.15504
Overall Steps per Second: 10,755.40115

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.40190
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.65069

Cumulative Model Updates: 110,314
Cumulative Timesteps: 919,988,082

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 919988082...
Checkpoint 919988082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730.87464
Policy Entropy: 3.14528
Value Function Loss: 0.00457

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.09064
Policy Update Magnitude: 0.55518
Value Function Update Magnitude: 0.58728

Collected Steps per Second: 22,239.78361
Overall Steps per Second: 10,621.48111

Timestep Collection Time: 2.24849
Timestep Consumption Time: 2.45951
PPO Batch Consumption Time: 0.29555
Total Iteration Time: 4.70801

Cumulative Model Updates: 110,320
Cumulative Timesteps: 920,038,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.94915
Policy Entropy: 3.13480
Value Function Loss: 0.00465

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.55262
Value Function Update Magnitude: 0.57844

Collected Steps per Second: 22,234.23760
Overall Steps per Second: 10,830.35228

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.36787
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.61666

Cumulative Model Updates: 110,326
Cumulative Timesteps: 920,088,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 920088088...
Checkpoint 920088088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.23918
Policy Entropy: 3.13729
Value Function Loss: 0.00478

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.55855
Value Function Update Magnitude: 0.57991

Collected Steps per Second: 22,815.07846
Overall Steps per Second: 10,702.08077

Timestep Collection Time: 2.19180
Timestep Consumption Time: 2.48075
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.67255

Cumulative Model Updates: 110,332
Cumulative Timesteps: 920,138,094

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.28134
Policy Entropy: 3.13736
Value Function Loss: 0.00482

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.56724
Value Function Update Magnitude: 0.59111

Collected Steps per Second: 23,163.47587
Overall Steps per Second: 10,851.27686

Timestep Collection Time: 2.15961
Timestep Consumption Time: 2.45036
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.60996

Cumulative Model Updates: 110,338
Cumulative Timesteps: 920,188,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 920188118...
Checkpoint 920188118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,041.05633
Policy Entropy: 3.15502
Value Function Loss: 0.00483

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.56542
Value Function Update Magnitude: 0.59045

Collected Steps per Second: 22,640.26208
Overall Steps per Second: 10,747.73751

Timestep Collection Time: 2.20845
Timestep Consumption Time: 2.44369
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.65214

Cumulative Model Updates: 110,344
Cumulative Timesteps: 920,238,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,432.59597
Policy Entropy: 3.13484
Value Function Loss: 0.00481

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.56328
Value Function Update Magnitude: 0.59440

Collected Steps per Second: 22,458.45556
Overall Steps per Second: 10,862.23685

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.37772
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.60494

Cumulative Model Updates: 110,350
Cumulative Timesteps: 920,288,138

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 920288138...
Checkpoint 920288138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,232.22641
Policy Entropy: 3.13033
Value Function Loss: 0.00463

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.56484
Value Function Update Magnitude: 0.59073

Collected Steps per Second: 22,019.57876
Overall Steps per Second: 10,685.10677

Timestep Collection Time: 2.27080
Timestep Consumption Time: 2.40880
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.67960

Cumulative Model Updates: 110,356
Cumulative Timesteps: 920,338,140

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.22956
Policy Entropy: 3.12148
Value Function Loss: 0.00444

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10424
Policy Update Magnitude: 0.56047
Value Function Update Magnitude: 0.57805

Collected Steps per Second: 21,900.89547
Overall Steps per Second: 10,603.51893

Timestep Collection Time: 2.28447
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.71843

Cumulative Model Updates: 110,362
Cumulative Timesteps: 920,388,172

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 920388172...
Checkpoint 920388172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,319.14482
Policy Entropy: 3.13888
Value Function Loss: 0.00438

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.55198
Value Function Update Magnitude: 0.57027

Collected Steps per Second: 22,227.72437
Overall Steps per Second: 10,718.52724

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.41644
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.66687

Cumulative Model Updates: 110,368
Cumulative Timesteps: 920,438,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 955.59877
Policy Entropy: 3.14028
Value Function Loss: 0.00446

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10421
Policy Update Magnitude: 0.54981
Value Function Update Magnitude: 0.57463

Collected Steps per Second: 22,603.78603
Overall Steps per Second: 10,738.05398

Timestep Collection Time: 2.21255
Timestep Consumption Time: 2.44490
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.65745

Cumulative Model Updates: 110,374
Cumulative Timesteps: 920,488,206

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 920488206...
Checkpoint 920488206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 971.98807
Policy Entropy: 3.14889
Value Function Loss: 0.00481

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.55270
Value Function Update Magnitude: 0.57523

Collected Steps per Second: 22,089.98058
Overall Steps per Second: 10,597.96255

Timestep Collection Time: 2.26365
Timestep Consumption Time: 2.45461
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.71827

Cumulative Model Updates: 110,380
Cumulative Timesteps: 920,538,210

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,913.73712
Policy Entropy: 3.13705
Value Function Loss: 0.00490

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.56447
Value Function Update Magnitude: 0.57411

Collected Steps per Second: 22,117.82632
Overall Steps per Second: 10,762.98849

Timestep Collection Time: 2.26107
Timestep Consumption Time: 2.38541
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.64648

Cumulative Model Updates: 110,386
Cumulative Timesteps: 920,588,220

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 920588220...
Checkpoint 920588220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.13659
Policy Entropy: 3.12638
Value Function Loss: 0.00507

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.57147
Value Function Update Magnitude: 0.57651

Collected Steps per Second: 22,180.16000
Overall Steps per Second: 10,717.28583

Timestep Collection Time: 2.25481
Timestep Consumption Time: 2.41167
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.66648

Cumulative Model Updates: 110,392
Cumulative Timesteps: 920,638,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 750.15302
Policy Entropy: 3.12423
Value Function Loss: 0.00500

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11796
Policy Update Magnitude: 0.57351
Value Function Update Magnitude: 0.60436

Collected Steps per Second: 22,954.68673
Overall Steps per Second: 10,726.42519

Timestep Collection Time: 2.17847
Timestep Consumption Time: 2.48348
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.66194

Cumulative Model Updates: 110,398
Cumulative Timesteps: 920,688,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 920688238...
Checkpoint 920688238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.80822
Policy Entropy: 3.13020
Value Function Loss: 0.00481

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.10519
Policy Update Magnitude: 0.57403
Value Function Update Magnitude: 0.61903

Collected Steps per Second: 22,746.31760
Overall Steps per Second: 10,760.28401

Timestep Collection Time: 2.19816
Timestep Consumption Time: 2.44856
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.64672

Cumulative Model Updates: 110,404
Cumulative Timesteps: 920,738,238

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.25023
Policy Entropy: 3.12474
Value Function Loss: 0.00492

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09736
Policy Update Magnitude: 0.57876
Value Function Update Magnitude: 0.62105

Collected Steps per Second: 22,887.20201
Overall Steps per Second: 10,670.65709

Timestep Collection Time: 2.18594
Timestep Consumption Time: 2.50262
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.68856

Cumulative Model Updates: 110,410
Cumulative Timesteps: 920,788,268

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 920788268...
Checkpoint 920788268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.62134
Policy Entropy: 3.13293
Value Function Loss: 0.00491

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.60843

Collected Steps per Second: 22,054.29906
Overall Steps per Second: 10,662.54102

Timestep Collection Time: 2.26822
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.69156

Cumulative Model Updates: 110,416
Cumulative Timesteps: 920,838,292

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.78578
Policy Entropy: 3.13905
Value Function Loss: 0.00471

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10114
Policy Update Magnitude: 0.56547
Value Function Update Magnitude: 0.59396

Collected Steps per Second: 22,422.17296
Overall Steps per Second: 10,774.80285

Timestep Collection Time: 2.23074
Timestep Consumption Time: 2.41139
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.64213

Cumulative Model Updates: 110,422
Cumulative Timesteps: 920,888,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 920888310...
Checkpoint 920888310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 818.93993
Policy Entropy: 3.14716
Value Function Loss: 0.00458

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.55816
Value Function Update Magnitude: 0.57572

Collected Steps per Second: 22,033.84277
Overall Steps per Second: 10,628.28226

Timestep Collection Time: 2.27069
Timestep Consumption Time: 2.43675
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.70744

Cumulative Model Updates: 110,428
Cumulative Timesteps: 920,938,342

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.09690
Policy Entropy: 3.15088
Value Function Loss: 0.00437

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.56656

Collected Steps per Second: 23,022.28384
Overall Steps per Second: 10,816.11742

Timestep Collection Time: 2.17294
Timestep Consumption Time: 2.45220
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.62513

Cumulative Model Updates: 110,434
Cumulative Timesteps: 920,988,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 920988368...
Checkpoint 920988368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.94226
Policy Entropy: 3.14915
Value Function Loss: 0.00454

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10872
Policy Update Magnitude: 0.55758
Value Function Update Magnitude: 0.56027

Collected Steps per Second: 22,686.69275
Overall Steps per Second: 10,805.97630

Timestep Collection Time: 2.20490
Timestep Consumption Time: 2.42420
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.62911

Cumulative Model Updates: 110,440
Cumulative Timesteps: 921,038,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.37171
Policy Entropy: 3.15093
Value Function Loss: 0.00452

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.56495
Value Function Update Magnitude: 0.55199

Collected Steps per Second: 22,955.23307
Overall Steps per Second: 10,804.51968

Timestep Collection Time: 2.17824
Timestep Consumption Time: 2.44964
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.62788

Cumulative Model Updates: 110,446
Cumulative Timesteps: 921,088,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 921088392...
Checkpoint 921088392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.20110
Policy Entropy: 3.15134
Value Function Loss: 0.00455

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11292
Policy Update Magnitude: 0.56240
Value Function Update Magnitude: 0.55501

Collected Steps per Second: 22,520.49921
Overall Steps per Second: 10,685.65602

Timestep Collection Time: 2.22073
Timestep Consumption Time: 2.45956
PPO Batch Consumption Time: 0.28534
Total Iteration Time: 4.68029

Cumulative Model Updates: 110,452
Cumulative Timesteps: 921,138,404

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.59983
Policy Entropy: 3.14634
Value Function Loss: 0.00460

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09884
Policy Update Magnitude: 0.55730
Value Function Update Magnitude: 0.55963

Collected Steps per Second: 21,794.66311
Overall Steps per Second: 10,559.22967

Timestep Collection Time: 2.29524
Timestep Consumption Time: 2.44223
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.73747

Cumulative Model Updates: 110,458
Cumulative Timesteps: 921,188,428

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 921188428...
Checkpoint 921188428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.29946
Policy Entropy: 3.15017
Value Function Loss: 0.00468

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.55675
Value Function Update Magnitude: 0.55850

Collected Steps per Second: 22,384.82105
Overall Steps per Second: 10,851.43461

Timestep Collection Time: 2.23375
Timestep Consumption Time: 2.37412
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.60787

Cumulative Model Updates: 110,464
Cumulative Timesteps: 921,238,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.51682
Policy Entropy: 3.15854
Value Function Loss: 0.00463

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10061
Policy Update Magnitude: 0.55577
Value Function Update Magnitude: 0.57381

Collected Steps per Second: 22,228.21405
Overall Steps per Second: 10,677.23200

Timestep Collection Time: 2.25047
Timestep Consumption Time: 2.43464
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.68511

Cumulative Model Updates: 110,470
Cumulative Timesteps: 921,288,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 921288454...
Checkpoint 921288454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.73509
Policy Entropy: 3.15207
Value Function Loss: 0.00438

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.11180
Policy Update Magnitude: 0.55186
Value Function Update Magnitude: 0.57745

Collected Steps per Second: 21,986.58670
Overall Steps per Second: 10,595.98485

Timestep Collection Time: 2.27511
Timestep Consumption Time: 2.44573
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.72084

Cumulative Model Updates: 110,476
Cumulative Timesteps: 921,338,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 915.31056
Policy Entropy: 3.15883
Value Function Loss: 0.00449

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.54896
Value Function Update Magnitude: 0.55599

Collected Steps per Second: 22,298.67229
Overall Steps per Second: 10,814.65983

Timestep Collection Time: 2.24300
Timestep Consumption Time: 2.38183
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.62483

Cumulative Model Updates: 110,482
Cumulative Timesteps: 921,388,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 921388492...
Checkpoint 921388492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,513.19578
Policy Entropy: 3.15927
Value Function Loss: 0.00454

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10267
Policy Update Magnitude: 0.55421
Value Function Update Magnitude: 0.54910

Collected Steps per Second: 22,014.96193
Overall Steps per Second: 10,663.37497

Timestep Collection Time: 2.27182
Timestep Consumption Time: 2.41844
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.69026

Cumulative Model Updates: 110,488
Cumulative Timesteps: 921,438,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,583.55177
Policy Entropy: 3.15430
Value Function Loss: 0.00453

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09577
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.53643

Collected Steps per Second: 22,409.71991
Overall Steps per Second: 10,850.20803

Timestep Collection Time: 2.23251
Timestep Consumption Time: 2.37846
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.61097

Cumulative Model Updates: 110,494
Cumulative Timesteps: 921,488,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 921488536...
Checkpoint 921488536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,233.02461
Policy Entropy: 3.14231
Value Function Loss: 0.00481

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08964
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.53824

Collected Steps per Second: 21,792.82163
Overall Steps per Second: 10,707.93264

Timestep Collection Time: 2.29525
Timestep Consumption Time: 2.37605
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.67130

Cumulative Model Updates: 110,500
Cumulative Timesteps: 921,538,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.38683
Policy Entropy: 3.12532
Value Function Loss: 0.00500

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11082
Policy Update Magnitude: 0.57179
Value Function Update Magnitude: 0.56099

Collected Steps per Second: 21,958.87704
Overall Steps per Second: 10,585.13163

Timestep Collection Time: 2.27817
Timestep Consumption Time: 2.44790
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.72606

Cumulative Model Updates: 110,506
Cumulative Timesteps: 921,588,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 921588582...
Checkpoint 921588582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.37576
Policy Entropy: 3.12781
Value Function Loss: 0.00495

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10376
Policy Update Magnitude: 0.57385
Value Function Update Magnitude: 0.57927

Collected Steps per Second: 22,258.56613
Overall Steps per Second: 10,747.44426

Timestep Collection Time: 2.24669
Timestep Consumption Time: 2.40633
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.65301

Cumulative Model Updates: 110,512
Cumulative Timesteps: 921,638,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.64741
Policy Entropy: 3.12691
Value Function Loss: 0.00472

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.56781
Value Function Update Magnitude: 0.58679

Collected Steps per Second: 22,423.52473
Overall Steps per Second: 10,688.72559

Timestep Collection Time: 2.23087
Timestep Consumption Time: 2.44920
PPO Batch Consumption Time: 0.29521
Total Iteration Time: 4.68007

Cumulative Model Updates: 110,518
Cumulative Timesteps: 921,688,614

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 921688614...
Checkpoint 921688614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.72645
Policy Entropy: 3.12467
Value Function Loss: 0.00443

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08706
Policy Update Magnitude: 0.56285
Value Function Update Magnitude: 0.58631

Collected Steps per Second: 22,817.16322
Overall Steps per Second: 10,613.52192

Timestep Collection Time: 2.19186
Timestep Consumption Time: 2.52024
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.71210

Cumulative Model Updates: 110,524
Cumulative Timesteps: 921,738,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.10107
Policy Entropy: 3.12465
Value Function Loss: 0.00457

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08324
Policy Update Magnitude: 0.56500
Value Function Update Magnitude: 0.56526

Collected Steps per Second: 23,164.09413
Overall Steps per Second: 10,844.12328

Timestep Collection Time: 2.15964
Timestep Consumption Time: 2.45355
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.61319

Cumulative Model Updates: 110,530
Cumulative Timesteps: 921,788,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 921788652...
Checkpoint 921788652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.85190
Policy Entropy: 3.12262
Value Function Loss: 0.00448

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.08979
Policy Update Magnitude: 0.55862
Value Function Update Magnitude: 0.55306

Collected Steps per Second: 22,694.37762
Overall Steps per Second: 10,749.14998

Timestep Collection Time: 2.20363
Timestep Consumption Time: 2.44883
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.65246

Cumulative Model Updates: 110,536
Cumulative Timesteps: 921,838,662

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.62958
Policy Entropy: 3.13213
Value Function Loss: 0.00464

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.56096
Value Function Update Magnitude: 0.55262

Collected Steps per Second: 23,204.58201
Overall Steps per Second: 10,895.18771

Timestep Collection Time: 2.15518
Timestep Consumption Time: 2.43492
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.59010

Cumulative Model Updates: 110,542
Cumulative Timesteps: 921,888,672

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 921888672...
Checkpoint 921888672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.64263
Policy Entropy: 3.12861
Value Function Loss: 0.00458

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.56471
Value Function Update Magnitude: 0.54626

Collected Steps per Second: 22,867.80443
Overall Steps per Second: 10,583.10819

Timestep Collection Time: 2.18762
Timestep Consumption Time: 2.53935
PPO Batch Consumption Time: 0.29651
Total Iteration Time: 4.72697

Cumulative Model Updates: 110,548
Cumulative Timesteps: 921,938,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.93571
Policy Entropy: 3.12267
Value Function Loss: 0.00487

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09267
Policy Update Magnitude: 0.57176
Value Function Update Magnitude: 0.56901

Collected Steps per Second: 23,101.23339
Overall Steps per Second: 10,865.19457

Timestep Collection Time: 2.16439
Timestep Consumption Time: 2.43746
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.60185

Cumulative Model Updates: 110,554
Cumulative Timesteps: 921,988,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 921988698...
Checkpoint 921988698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.87393
Policy Entropy: 3.12720
Value Function Loss: 0.00505

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09288
Policy Update Magnitude: 0.58529
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 22,531.54958
Overall Steps per Second: 10,713.45758

Timestep Collection Time: 2.21955
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.66796

Cumulative Model Updates: 110,560
Cumulative Timesteps: 922,038,708

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.91590
Policy Entropy: 3.12189
Value Function Loss: 0.00474

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.09711
Policy Update Magnitude: 0.58664
Value Function Update Magnitude: 0.61523

Collected Steps per Second: 23,320.47525
Overall Steps per Second: 10,880.44051

Timestep Collection Time: 2.14524
Timestep Consumption Time: 2.45274
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.59798

Cumulative Model Updates: 110,566
Cumulative Timesteps: 922,088,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 922088736...
Checkpoint 922088736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.37996
Policy Entropy: 3.13637
Value Function Loss: 0.00459

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.57136
Value Function Update Magnitude: 0.59970

Collected Steps per Second: 22,702.17544
Overall Steps per Second: 10,683.49384

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.47778
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.68030

Cumulative Model Updates: 110,572
Cumulative Timesteps: 922,138,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.69040
Policy Entropy: 3.13071
Value Function Loss: 0.00424

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.56316
Value Function Update Magnitude: 0.57601

Collected Steps per Second: 23,163.64031
Overall Steps per Second: 10,832.38272

Timestep Collection Time: 2.15925
Timestep Consumption Time: 2.45802
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.61727

Cumulative Model Updates: 110,578
Cumulative Timesteps: 922,188,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 922188754...
Checkpoint 922188754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.15304
Policy Entropy: 3.13659
Value Function Loss: 0.00428

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.55912
Value Function Update Magnitude: 0.56699

Collected Steps per Second: 22,429.29453
Overall Steps per Second: 10,736.04353

Timestep Collection Time: 2.22949
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.65777

Cumulative Model Updates: 110,584
Cumulative Timesteps: 922,238,760

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.17701
Policy Entropy: 3.13259
Value Function Loss: 0.00480

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.57008
Value Function Update Magnitude: 0.58323

Collected Steps per Second: 23,188.77237
Overall Steps per Second: 10,838.43954

Timestep Collection Time: 2.15708
Timestep Consumption Time: 2.45798
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.61506

Cumulative Model Updates: 110,590
Cumulative Timesteps: 922,288,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 922288780...
Checkpoint 922288780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.58847
Policy Entropy: 3.14352
Value Function Loss: 0.00495

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09321
Policy Update Magnitude: 0.57682
Value Function Update Magnitude: 0.62703

Collected Steps per Second: 22,642.28873
Overall Steps per Second: 10,659.42337

Timestep Collection Time: 2.20905
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.69237

Cumulative Model Updates: 110,596
Cumulative Timesteps: 922,338,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.94041
Policy Entropy: 3.14148
Value Function Loss: 0.00476

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09454
Policy Update Magnitude: 0.57353
Value Function Update Magnitude: 0.62590

Collected Steps per Second: 22,323.58307
Overall Steps per Second: 10,818.66798

Timestep Collection Time: 2.24095
Timestep Consumption Time: 2.38310
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.62404

Cumulative Model Updates: 110,602
Cumulative Timesteps: 922,388,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 922388824...
Checkpoint 922388824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.30464
Policy Entropy: 3.14150
Value Function Loss: 0.00484

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.57188
Value Function Update Magnitude: 0.59528

Collected Steps per Second: 22,836.63351
Overall Steps per Second: 10,698.17209

Timestep Collection Time: 2.19017
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.67519

Cumulative Model Updates: 110,608
Cumulative Timesteps: 922,438,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 615.16560
Policy Entropy: 3.14258
Value Function Loss: 0.00467

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.09050
Policy Update Magnitude: 0.56711
Value Function Update Magnitude: 0.56950

Collected Steps per Second: 22,822.63662
Overall Steps per Second: 10,675.53145

Timestep Collection Time: 2.19203
Timestep Consumption Time: 2.49420
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.68623

Cumulative Model Updates: 110,614
Cumulative Timesteps: 922,488,868

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 922488868...
Checkpoint 922488868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.67677
Policy Entropy: 3.14055
Value Function Loss: 0.00487

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.56402
Value Function Update Magnitude: 0.55199

Collected Steps per Second: 22,722.16126
Overall Steps per Second: 10,648.36944

Timestep Collection Time: 2.20094
Timestep Consumption Time: 2.49556
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.69649

Cumulative Model Updates: 110,620
Cumulative Timesteps: 922,538,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.29433
Policy Entropy: 3.13456
Value Function Loss: 0.00467

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11735
Policy Update Magnitude: 0.55667
Value Function Update Magnitude: 0.55689

Collected Steps per Second: 23,344.50402
Overall Steps per Second: 10,733.31467

Timestep Collection Time: 2.14329
Timestep Consumption Time: 2.51827
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.66156

Cumulative Model Updates: 110,626
Cumulative Timesteps: 922,588,912

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 922588912...
Checkpoint 922588912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.55319
Policy Entropy: 3.11352
Value Function Loss: 0.00470

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10630
Policy Update Magnitude: 0.55730
Value Function Update Magnitude: 0.56186

Collected Steps per Second: 22,708.52495
Overall Steps per Second: 10,628.39865

Timestep Collection Time: 2.20305
Timestep Consumption Time: 2.50396
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.70701

Cumulative Model Updates: 110,632
Cumulative Timesteps: 922,638,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,352.10099
Policy Entropy: 3.10513
Value Function Loss: 0.00488

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11555
Policy Update Magnitude: 0.56178
Value Function Update Magnitude: 0.57634

Collected Steps per Second: 23,405.64489
Overall Steps per Second: 10,893.78699

Timestep Collection Time: 2.13658
Timestep Consumption Time: 2.45393
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.59051

Cumulative Model Updates: 110,638
Cumulative Timesteps: 922,688,948

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 922688948...
Checkpoint 922688948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.55879
Policy Entropy: 3.11772
Value Function Loss: 0.00492

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.57653
Value Function Update Magnitude: 0.58828

Collected Steps per Second: 22,570.80361
Overall Steps per Second: 10,688.98179

Timestep Collection Time: 2.21605
Timestep Consumption Time: 2.46335
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.67940

Cumulative Model Updates: 110,644
Cumulative Timesteps: 922,738,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.14279
Policy Entropy: 3.13033
Value Function Loss: 0.00507

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.57687
Value Function Update Magnitude: 0.61224

Collected Steps per Second: 23,136.62210
Overall Steps per Second: 10,817.55435

Timestep Collection Time: 2.16237
Timestep Consumption Time: 2.46252
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.62489

Cumulative Model Updates: 110,650
Cumulative Timesteps: 922,788,996

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 922788996...
Checkpoint 922788996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 695.64241
Policy Entropy: 3.12597
Value Function Loss: 0.00496

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.58065
Value Function Update Magnitude: 0.61060

Collected Steps per Second: 22,672.69361
Overall Steps per Second: 10,684.70077

Timestep Collection Time: 2.20547
Timestep Consumption Time: 2.47449
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.67996

Cumulative Model Updates: 110,656
Cumulative Timesteps: 922,839,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.75617
Policy Entropy: 3.12970
Value Function Loss: 0.00483

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.57724
Value Function Update Magnitude: 0.61110

Collected Steps per Second: 22,982.48531
Overall Steps per Second: 10,726.70408

Timestep Collection Time: 2.17688
Timestep Consumption Time: 2.48719
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.66406

Cumulative Model Updates: 110,662
Cumulative Timesteps: 922,889,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 922889030...
Checkpoint 922889030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.56266
Policy Entropy: 3.12276
Value Function Loss: 0.00458

Mean KL Divergence: 0.01286
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.56808
Value Function Update Magnitude: 0.60151

Collected Steps per Second: 22,066.82895
Overall Steps per Second: 10,801.34214

Timestep Collection Time: 2.26648
Timestep Consumption Time: 2.36387
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.63035

Cumulative Model Updates: 110,668
Cumulative Timesteps: 922,939,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.37280
Policy Entropy: 3.12091
Value Function Loss: 0.00475

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.12053
Policy Update Magnitude: 0.56338
Value Function Update Magnitude: 0.58463

Collected Steps per Second: 21,910.82615
Overall Steps per Second: 10,548.35466

Timestep Collection Time: 2.28389
Timestep Consumption Time: 2.46016
PPO Batch Consumption Time: 0.29662
Total Iteration Time: 4.74406

Cumulative Model Updates: 110,674
Cumulative Timesteps: 922,989,086

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 922989086...
Checkpoint 922989086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.34079
Policy Entropy: 3.12073
Value Function Loss: 0.00492

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10475
Policy Update Magnitude: 0.57076
Value Function Update Magnitude: 0.59436

Collected Steps per Second: 22,111.20545
Overall Steps per Second: 10,622.16661

Timestep Collection Time: 2.26202
Timestep Consumption Time: 2.44662
PPO Batch Consumption Time: 0.29492
Total Iteration Time: 4.70864

Cumulative Model Updates: 110,680
Cumulative Timesteps: 923,039,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.42048
Policy Entropy: 3.12371
Value Function Loss: 0.00509

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.57487
Value Function Update Magnitude: 0.62229

Collected Steps per Second: 23,072.35141
Overall Steps per Second: 10,848.72803

Timestep Collection Time: 2.16753
Timestep Consumption Time: 2.44223
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.60976

Cumulative Model Updates: 110,686
Cumulative Timesteps: 923,089,112

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 923089112...
Checkpoint 923089112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.73049
Policy Entropy: 3.13578
Value Function Loss: 0.00469

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.56743
Value Function Update Magnitude: 0.62533

Collected Steps per Second: 21,815.60463
Overall Steps per Second: 10,688.07615

Timestep Collection Time: 2.29313
Timestep Consumption Time: 2.38741
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.68054

Cumulative Model Updates: 110,692
Cumulative Timesteps: 923,139,138

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.17564
Policy Entropy: 3.12009
Value Function Loss: 0.00477

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10350
Policy Update Magnitude: 0.56998
Value Function Update Magnitude: 0.60560

Collected Steps per Second: 22,340.92485
Overall Steps per Second: 10,865.44912

Timestep Collection Time: 2.23921
Timestep Consumption Time: 2.36493
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.60414

Cumulative Model Updates: 110,698
Cumulative Timesteps: 923,189,164

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 923189164...
Checkpoint 923189164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,574.44600
Policy Entropy: 3.10129
Value Function Loss: 0.00482

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11730
Policy Update Magnitude: 0.57521
Value Function Update Magnitude: 0.61197

Collected Steps per Second: 21,884.35950
Overall Steps per Second: 10,681.47677

Timestep Collection Time: 2.28501
Timestep Consumption Time: 2.39655
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.68156

Cumulative Model Updates: 110,704
Cumulative Timesteps: 923,239,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,521.15347
Policy Entropy: 3.10313
Value Function Loss: 0.00513

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.57669
Value Function Update Magnitude: 0.62714

Collected Steps per Second: 22,455.22319
Overall Steps per Second: 10,841.97238

Timestep Collection Time: 2.22808
Timestep Consumption Time: 2.38658
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.61466

Cumulative Model Updates: 110,710
Cumulative Timesteps: 923,289,202

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 923289202...
Checkpoint 923289202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 941.71074
Policy Entropy: 3.10843
Value Function Loss: 0.00519

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.57839
Value Function Update Magnitude: 0.62752

Collected Steps per Second: 22,585.53573
Overall Steps per Second: 10,731.90239

Timestep Collection Time: 2.21407
Timestep Consumption Time: 2.44549
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.65957

Cumulative Model Updates: 110,716
Cumulative Timesteps: 923,339,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.72934
Policy Entropy: 3.10685
Value Function Loss: 0.00518

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.57566
Value Function Update Magnitude: 0.62809

Collected Steps per Second: 22,344.94631
Overall Steps per Second: 10,818.38683

Timestep Collection Time: 2.23872
Timestep Consumption Time: 2.38526
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.62398

Cumulative Model Updates: 110,722
Cumulative Timesteps: 923,389,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 923389232...
Checkpoint 923389232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.19341
Policy Entropy: 3.10032
Value Function Loss: 0.00496

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.56964
Value Function Update Magnitude: 0.63111

Collected Steps per Second: 22,482.14291
Overall Steps per Second: 10,679.44899

Timestep Collection Time: 2.22505
Timestep Consumption Time: 2.45908
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.68414

Cumulative Model Updates: 110,728
Cumulative Timesteps: 923,439,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 923.29006
Policy Entropy: 3.09111
Value Function Loss: 0.00519

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.57610
Value Function Update Magnitude: 0.65267

Collected Steps per Second: 23,140.95661
Overall Steps per Second: 10,824.38667

Timestep Collection Time: 2.16110
Timestep Consumption Time: 2.45902
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.62012

Cumulative Model Updates: 110,734
Cumulative Timesteps: 923,489,266

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 923489266...
Checkpoint 923489266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.42599
Policy Entropy: 3.09959
Value Function Loss: 0.00499

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.57792
Value Function Update Magnitude: 0.65238

Collected Steps per Second: 22,330.78682
Overall Steps per Second: 10,672.55016

Timestep Collection Time: 2.23924
Timestep Consumption Time: 2.44605
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.68529

Cumulative Model Updates: 110,740
Cumulative Timesteps: 923,539,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,562.12331
Policy Entropy: 3.08372
Value Function Loss: 0.00496

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10808
Policy Update Magnitude: 0.57690
Value Function Update Magnitude: 0.63581

Collected Steps per Second: 22,262.84507
Overall Steps per Second: 10,691.03819

Timestep Collection Time: 2.24679
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.67868

Cumulative Model Updates: 110,746
Cumulative Timesteps: 923,589,290

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 923589290...
Checkpoint 923589290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,549.63664
Policy Entropy: 3.09018
Value Function Loss: 0.00496

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.11161
Policy Update Magnitude: 0.57949
Value Function Update Magnitude: 0.63284

Collected Steps per Second: 22,257.51559
Overall Steps per Second: 10,818.08456

Timestep Collection Time: 2.24751
Timestep Consumption Time: 2.37660
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.62411

Cumulative Model Updates: 110,752
Cumulative Timesteps: 923,639,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 959.19509
Policy Entropy: 3.09372
Value Function Loss: 0.00525

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.58257
Value Function Update Magnitude: 0.64304

Collected Steps per Second: 22,161.88232
Overall Steps per Second: 10,650.44744

Timestep Collection Time: 2.25703
Timestep Consumption Time: 2.43949
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.69652

Cumulative Model Updates: 110,758
Cumulative Timesteps: 923,689,334

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 923689334...
Checkpoint 923689334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,899.88209
Policy Entropy: 3.11021
Value Function Loss: 0.00534

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.58315
Value Function Update Magnitude: 0.65075

Collected Steps per Second: 21,868.48616
Overall Steps per Second: 10,577.39896

Timestep Collection Time: 2.28768
Timestep Consumption Time: 2.44203
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.72971

Cumulative Model Updates: 110,764
Cumulative Timesteps: 923,739,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 919.51111
Policy Entropy: 3.11134
Value Function Loss: 0.00521

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.57717
Value Function Update Magnitude: 0.63683

Collected Steps per Second: 21,854.21496
Overall Steps per Second: 10,615.43683

Timestep Collection Time: 2.28862
Timestep Consumption Time: 2.42301
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.71163

Cumulative Model Updates: 110,770
Cumulative Timesteps: 923,789,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 923789378...
Checkpoint 923789378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,183.86351
Policy Entropy: 3.11335
Value Function Loss: 0.00451

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.56311
Value Function Update Magnitude: 0.61155

Collected Steps per Second: 21,869.17135
Overall Steps per Second: 10,589.36534

Timestep Collection Time: 2.28687
Timestep Consumption Time: 2.43598
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.72285

Cumulative Model Updates: 110,776
Cumulative Timesteps: 923,839,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.77368
Policy Entropy: 3.10141
Value Function Loss: 0.00451

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.55844
Value Function Update Magnitude: 0.58290

Collected Steps per Second: 23,224.30775
Overall Steps per Second: 10,803.17424

Timestep Collection Time: 2.15395
Timestep Consumption Time: 2.47654
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.63049

Cumulative Model Updates: 110,782
Cumulative Timesteps: 923,889,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 923889414...
Checkpoint 923889414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,421.42478
Policy Entropy: 3.09696
Value Function Loss: 0.00455

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09647
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.58981

Collected Steps per Second: 21,892.96317
Overall Steps per Second: 10,634.57846

Timestep Collection Time: 2.28494
Timestep Consumption Time: 2.41897
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.70390

Cumulative Model Updates: 110,788
Cumulative Timesteps: 923,939,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.38949
Policy Entropy: 3.10176
Value Function Loss: 0.00464

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.56661
Value Function Update Magnitude: 0.61286

Collected Steps per Second: 22,794.64063
Overall Steps per Second: 10,899.97406

Timestep Collection Time: 2.19402
Timestep Consumption Time: 2.39424
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.58827

Cumulative Model Updates: 110,794
Cumulative Timesteps: 923,989,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 923989450...
Checkpoint 923989450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,648.20889
Policy Entropy: 3.10336
Value Function Loss: 0.00464

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11763
Policy Update Magnitude: 0.56129
Value Function Update Magnitude: 0.61813

Collected Steps per Second: 21,886.59125
Overall Steps per Second: 10,654.02768

Timestep Collection Time: 2.28478
Timestep Consumption Time: 2.40885
PPO Batch Consumption Time: 0.28734
Total Iteration Time: 4.69362

Cumulative Model Updates: 110,800
Cumulative Timesteps: 924,039,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.39738
Policy Entropy: 3.11449
Value Function Loss: 0.00483

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.61804

Collected Steps per Second: 22,180.76400
Overall Steps per Second: 10,790.98419

Timestep Collection Time: 2.25475
Timestep Consumption Time: 2.37986
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.63461

Cumulative Model Updates: 110,806
Cumulative Timesteps: 924,089,468

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 924089468...
Checkpoint 924089468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.97277
Policy Entropy: 3.10539
Value Function Loss: 0.00493

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11581
Policy Update Magnitude: 0.57239
Value Function Update Magnitude: 0.62495

Collected Steps per Second: 22,720.39952
Overall Steps per Second: 10,813.63808

Timestep Collection Time: 2.20190
Timestep Consumption Time: 2.42448
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.62638

Cumulative Model Updates: 110,812
Cumulative Timesteps: 924,139,496

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,600.34057
Policy Entropy: 3.11097
Value Function Loss: 0.00516

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.58060
Value Function Update Magnitude: 0.62315

Collected Steps per Second: 23,192.78926
Overall Steps per Second: 10,819.91696

Timestep Collection Time: 2.15593
Timestep Consumption Time: 2.46536
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.62129

Cumulative Model Updates: 110,818
Cumulative Timesteps: 924,189,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 924189498...
Checkpoint 924189498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,592.08544
Policy Entropy: 3.11995
Value Function Loss: 0.00507

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.58128
Value Function Update Magnitude: 0.62698

Collected Steps per Second: 23,040.69424
Overall Steps per Second: 10,633.29909

Timestep Collection Time: 2.17007
Timestep Consumption Time: 2.53214
PPO Batch Consumption Time: 0.29772
Total Iteration Time: 4.70221

Cumulative Model Updates: 110,824
Cumulative Timesteps: 924,239,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,165.48614
Policy Entropy: 3.12675
Value Function Loss: 0.00504

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.57571
Value Function Update Magnitude: 0.64551

Collected Steps per Second: 23,026.09756
Overall Steps per Second: 10,845.46782

Timestep Collection Time: 2.17362
Timestep Consumption Time: 2.44121
PPO Batch Consumption Time: 0.28180
Total Iteration Time: 4.61483

Cumulative Model Updates: 110,830
Cumulative Timesteps: 924,289,548

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 924289548...
Checkpoint 924289548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.26929
Policy Entropy: 3.13517
Value Function Loss: 0.00477

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10628
Policy Update Magnitude: 0.57111
Value Function Update Magnitude: 0.64609

Collected Steps per Second: 21,779.69600
Overall Steps per Second: 10,674.54342

Timestep Collection Time: 2.29618
Timestep Consumption Time: 2.38880
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.68498

Cumulative Model Updates: 110,836
Cumulative Timesteps: 924,339,558

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743.13627
Policy Entropy: 3.14611
Value Function Loss: 0.00463

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.10013
Policy Update Magnitude: 0.56260
Value Function Update Magnitude: 0.63711

Collected Steps per Second: 22,146.73278
Overall Steps per Second: 10,680.69072

Timestep Collection Time: 2.25821
Timestep Consumption Time: 2.42426
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.68247

Cumulative Model Updates: 110,842
Cumulative Timesteps: 924,389,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 924389570...
Checkpoint 924389570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.83337
Policy Entropy: 3.14995
Value Function Loss: 0.00481

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10058
Policy Update Magnitude: 0.56114
Value Function Update Magnitude: 0.62651

Collected Steps per Second: 22,981.19614
Overall Steps per Second: 10,802.11610

Timestep Collection Time: 2.17569
Timestep Consumption Time: 2.45303
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.62872

Cumulative Model Updates: 110,848
Cumulative Timesteps: 924,439,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.41069
Policy Entropy: 3.13469
Value Function Loss: 0.00494

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.56383
Value Function Update Magnitude: 0.64540

Collected Steps per Second: 23,108.02897
Overall Steps per Second: 10,724.00218

Timestep Collection Time: 2.16513
Timestep Consumption Time: 2.50029
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.66542

Cumulative Model Updates: 110,854
Cumulative Timesteps: 924,489,602

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 924489602...
Checkpoint 924489602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.06865
Policy Entropy: 3.12831
Value Function Loss: 0.00484

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.57598
Value Function Update Magnitude: 0.64369

Collected Steps per Second: 21,887.66323
Overall Steps per Second: 10,627.52873

Timestep Collection Time: 2.28467
Timestep Consumption Time: 2.42066
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.70533

Cumulative Model Updates: 110,860
Cumulative Timesteps: 924,539,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,487.97513
Policy Entropy: 3.13828
Value Function Loss: 0.00457

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10883
Policy Update Magnitude: 0.56309
Value Function Update Magnitude: 0.61551

Collected Steps per Second: 22,339.33691
Overall Steps per Second: 10,776.55097

Timestep Collection Time: 2.23883
Timestep Consumption Time: 2.40217
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.64100

Cumulative Model Updates: 110,866
Cumulative Timesteps: 924,589,622

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 924589622...
Checkpoint 924589622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,328.97546
Policy Entropy: 3.13203
Value Function Loss: 0.00451

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09472
Policy Update Magnitude: 0.55781
Value Function Update Magnitude: 0.60891

Collected Steps per Second: 21,897.23740
Overall Steps per Second: 10,635.40154

Timestep Collection Time: 2.28348
Timestep Consumption Time: 2.41798
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.70147

Cumulative Model Updates: 110,872
Cumulative Timesteps: 924,639,624

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.91642
Policy Entropy: 3.12356
Value Function Loss: 0.00444

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.55262
Value Function Update Magnitude: 0.61655

Collected Steps per Second: 22,023.59690
Overall Steps per Second: 10,658.80323

Timestep Collection Time: 2.27038
Timestep Consumption Time: 2.42076
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.69115

Cumulative Model Updates: 110,878
Cumulative Timesteps: 924,689,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 924689626...
Checkpoint 924689626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.31192
Policy Entropy: 3.12960
Value Function Loss: 0.00438

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11064
Policy Update Magnitude: 0.54940
Value Function Update Magnitude: 0.61143

Collected Steps per Second: 21,939.40402
Overall Steps per Second: 10,782.12385

Timestep Collection Time: 2.28010
Timestep Consumption Time: 2.35943
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.63953

Cumulative Model Updates: 110,884
Cumulative Timesteps: 924,739,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.45597
Policy Entropy: 3.13896
Value Function Loss: 0.00432

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.11734
Policy Update Magnitude: 0.54627
Value Function Update Magnitude: 0.59811

Collected Steps per Second: 21,995.72344
Overall Steps per Second: 10,572.92907

Timestep Collection Time: 2.27435
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.73152

Cumulative Model Updates: 110,890
Cumulative Timesteps: 924,789,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 924789676...
Checkpoint 924789676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.53430
Policy Entropy: 3.13354
Value Function Loss: 0.00433

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12604
Policy Update Magnitude: 0.53986
Value Function Update Magnitude: 0.58725

Collected Steps per Second: 22,111.12886
Overall Steps per Second: 10,579.83882

Timestep Collection Time: 2.26266
Timestep Consumption Time: 2.46614
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.72881

Cumulative Model Updates: 110,896
Cumulative Timesteps: 924,839,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.36023
Policy Entropy: 3.13026
Value Function Loss: 0.00443

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.58678

Collected Steps per Second: 22,145.81176
Overall Steps per Second: 10,690.52459

Timestep Collection Time: 2.25903
Timestep Consumption Time: 2.42063
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.67966

Cumulative Model Updates: 110,902
Cumulative Timesteps: 924,889,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 924889734...
Checkpoint 924889734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.44509
Policy Entropy: 3.13029
Value Function Loss: 0.00446

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10520
Policy Update Magnitude: 0.54678
Value Function Update Magnitude: 0.59096

Collected Steps per Second: 22,053.96536
Overall Steps per Second: 10,791.44196

Timestep Collection Time: 2.26771
Timestep Consumption Time: 2.36670
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.63441

Cumulative Model Updates: 110,908
Cumulative Timesteps: 924,939,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.74910
Policy Entropy: 3.12973
Value Function Loss: 0.00454

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.55211
Value Function Update Magnitude: 0.58226

Collected Steps per Second: 22,239.39444
Overall Steps per Second: 10,663.53606

Timestep Collection Time: 2.24898
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.69038

Cumulative Model Updates: 110,914
Cumulative Timesteps: 924,989,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 924989762...
Checkpoint 924989762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,379.42559
Policy Entropy: 3.12220
Value Function Loss: 0.00453

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09370
Policy Update Magnitude: 0.55224
Value Function Update Magnitude: 0.58045

Collected Steps per Second: 21,945.18293
Overall Steps per Second: 10,586.31374

Timestep Collection Time: 2.27932
Timestep Consumption Time: 2.44565
PPO Batch Consumption Time: 0.29541
Total Iteration Time: 4.72497

Cumulative Model Updates: 110,920
Cumulative Timesteps: 925,039,782

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,693.03058
Policy Entropy: 3.12971
Value Function Loss: 0.00462

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.55080
Value Function Update Magnitude: 0.58358

Collected Steps per Second: 22,448.23492
Overall Steps per Second: 10,876.08349

Timestep Collection Time: 2.22752
Timestep Consumption Time: 2.37009
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.59761

Cumulative Model Updates: 110,926
Cumulative Timesteps: 925,089,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 925089786...
Checkpoint 925089786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 988.63963
Policy Entropy: 3.13474
Value Function Loss: 0.00456

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.58339

Collected Steps per Second: 21,878.38924
Overall Steps per Second: 10,625.18419

Timestep Collection Time: 2.28600
Timestep Consumption Time: 2.42112
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.70712

Cumulative Model Updates: 110,932
Cumulative Timesteps: 925,139,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.80149
Policy Entropy: 3.13937
Value Function Loss: 0.00467

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.55448
Value Function Update Magnitude: 0.57993

Collected Steps per Second: 22,539.90785
Overall Steps per Second: 10,864.26794

Timestep Collection Time: 2.21918
Timestep Consumption Time: 2.38491
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.60408

Cumulative Model Updates: 110,938
Cumulative Timesteps: 925,189,820

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 925189820...
Checkpoint 925189820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.74945
Policy Entropy: 3.13729
Value Function Loss: 0.00464

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.55399
Value Function Update Magnitude: 0.59138

Collected Steps per Second: 21,725.74344
Overall Steps per Second: 10,679.82637

Timestep Collection Time: 2.30188
Timestep Consumption Time: 2.38078
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.68266

Cumulative Model Updates: 110,944
Cumulative Timesteps: 925,239,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.88628
Policy Entropy: 3.14728
Value Function Loss: 0.00469

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.55323
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 22,549.03057
Overall Steps per Second: 10,869.59616

Timestep Collection Time: 2.21792
Timestep Consumption Time: 2.38317
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.60109

Cumulative Model Updates: 110,950
Cumulative Timesteps: 925,289,842

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 925289842...
Checkpoint 925289842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.08106
Policy Entropy: 3.13752
Value Function Loss: 0.00466

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.55363
Value Function Update Magnitude: 0.59979

Collected Steps per Second: 21,949.64913
Overall Steps per Second: 10,701.13417

Timestep Collection Time: 2.27876
Timestep Consumption Time: 2.39532
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.67408

Cumulative Model Updates: 110,956
Cumulative Timesteps: 925,339,860

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,063.61059
Policy Entropy: 3.14297
Value Function Loss: 0.00436

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.54845
Value Function Update Magnitude: 0.56291

Collected Steps per Second: 22,118.78479
Overall Steps per Second: 10,677.66444

Timestep Collection Time: 2.26088
Timestep Consumption Time: 2.42254
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.68342

Cumulative Model Updates: 110,962
Cumulative Timesteps: 925,389,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 925389868...
Checkpoint 925389868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.89851
Policy Entropy: 3.15378
Value Function Loss: 0.00423

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.53646
Value Function Update Magnitude: 0.53735

Collected Steps per Second: 22,209.77344
Overall Steps per Second: 10,795.42033

Timestep Collection Time: 2.25207
Timestep Consumption Time: 2.38119
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.63326

Cumulative Model Updates: 110,968
Cumulative Timesteps: 925,439,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,929.09871
Policy Entropy: 3.14959
Value Function Loss: 0.00434

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.53253
Value Function Update Magnitude: 0.54058

Collected Steps per Second: 22,185.12580
Overall Steps per Second: 10,717.46955

Timestep Collection Time: 2.25502
Timestep Consumption Time: 2.41287
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.66789

Cumulative Model Updates: 110,974
Cumulative Timesteps: 925,489,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 925489914...
Checkpoint 925489914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.18307
Policy Entropy: 3.14990
Value Function Loss: 0.00438

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09520
Policy Update Magnitude: 0.54107
Value Function Update Magnitude: 0.56452

Collected Steps per Second: 21,855.99663
Overall Steps per Second: 10,584.81012

Timestep Collection Time: 2.28917
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.29504
Total Iteration Time: 4.72677

Cumulative Model Updates: 110,980
Cumulative Timesteps: 925,539,946

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.75764
Policy Entropy: 3.13703
Value Function Loss: 0.00463

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09806
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.58613

Collected Steps per Second: 22,108.63591
Overall Steps per Second: 10,812.86678

Timestep Collection Time: 2.26156
Timestep Consumption Time: 2.36256
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62412

Cumulative Model Updates: 110,986
Cumulative Timesteps: 925,589,946

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 925589946...
Checkpoint 925589946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,713.12184
Policy Entropy: 3.13846
Value Function Loss: 0.00476

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09060
Policy Update Magnitude: 0.56545
Value Function Update Magnitude: 0.59785

Collected Steps per Second: 21,958.17989
Overall Steps per Second: 10,574.93944

Timestep Collection Time: 2.27788
Timestep Consumption Time: 2.45199
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.72986

Cumulative Model Updates: 110,992
Cumulative Timesteps: 925,639,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.15779
Policy Entropy: 3.14469
Value Function Loss: 0.00483

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09033
Policy Update Magnitude: 0.57270
Value Function Update Magnitude: 0.60116

Collected Steps per Second: 22,500.20468
Overall Steps per Second: 10,816.81298

Timestep Collection Time: 2.22300
Timestep Consumption Time: 2.40110
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.62410

Cumulative Model Updates: 110,998
Cumulative Timesteps: 925,689,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 925689982...
Checkpoint 925689982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.81081
Policy Entropy: 3.14939
Value Function Loss: 0.00480

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.56771
Value Function Update Magnitude: 0.60956

Collected Steps per Second: 21,614.73273
Overall Steps per Second: 10,670.63257

Timestep Collection Time: 2.31379
Timestep Consumption Time: 2.37309
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.68688

Cumulative Model Updates: 111,004
Cumulative Timesteps: 925,739,994

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 644.34474
Policy Entropy: 3.15839
Value Function Loss: 0.00495

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09354
Policy Update Magnitude: 0.56745
Value Function Update Magnitude: 0.63619

Collected Steps per Second: 23,272.19382
Overall Steps per Second: 10,768.95153

Timestep Collection Time: 2.14969
Timestep Consumption Time: 2.49589
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.64558

Cumulative Model Updates: 111,010
Cumulative Timesteps: 925,790,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 925790022...
Checkpoint 925790022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946.69042
Policy Entropy: 3.14921
Value Function Loss: 0.00510

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.57661
Value Function Update Magnitude: 0.64868

Collected Steps per Second: 22,341.61021
Overall Steps per Second: 10,837.60391

Timestep Collection Time: 2.23816
Timestep Consumption Time: 2.37578
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.61394

Cumulative Model Updates: 111,016
Cumulative Timesteps: 925,840,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,766.97534
Policy Entropy: 3.14135
Value Function Loss: 0.00530

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11128
Policy Update Magnitude: 0.57859
Value Function Update Magnitude: 0.66280

Collected Steps per Second: 23,209.14143
Overall Steps per Second: 10,868.83668

Timestep Collection Time: 2.15544
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.60270

Cumulative Model Updates: 111,022
Cumulative Timesteps: 925,890,052

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 925890052...
Checkpoint 925890052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.05854
Policy Entropy: 3.13348
Value Function Loss: 0.00516

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.57685
Value Function Update Magnitude: 0.65818

Collected Steps per Second: 22,706.64703
Overall Steps per Second: 10,734.89829

Timestep Collection Time: 2.20323
Timestep Consumption Time: 2.45708
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.66031

Cumulative Model Updates: 111,028
Cumulative Timesteps: 925,940,080

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.49509
Policy Entropy: 3.12749
Value Function Loss: 0.00523

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.12168
Policy Update Magnitude: 0.57895
Value Function Update Magnitude: 0.65387

Collected Steps per Second: 22,443.77621
Overall Steps per Second: 10,834.50218

Timestep Collection Time: 2.22779
Timestep Consumption Time: 2.38710
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.61489

Cumulative Model Updates: 111,034
Cumulative Timesteps: 925,990,080

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 925990080...
Checkpoint 925990080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.56456
Policy Entropy: 3.13143
Value Function Loss: 0.00515

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.11616
Policy Update Magnitude: 0.57580
Value Function Update Magnitude: 0.64949

Collected Steps per Second: 22,073.72350
Overall Steps per Second: 10,687.23036

Timestep Collection Time: 2.26604
Timestep Consumption Time: 2.41431
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.68035

Cumulative Model Updates: 111,040
Cumulative Timesteps: 926,040,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.22663
Policy Entropy: 3.13358
Value Function Loss: 0.00512

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.57836
Value Function Update Magnitude: 0.64600

Collected Steps per Second: 22,918.90633
Overall Steps per Second: 10,682.71989

Timestep Collection Time: 2.18178
Timestep Consumption Time: 2.49905
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.68083

Cumulative Model Updates: 111,046
Cumulative Timesteps: 926,090,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 926090104...
Checkpoint 926090104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.23042
Policy Entropy: 3.14516
Value Function Loss: 0.00452

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.56561
Value Function Update Magnitude: 0.64241

Collected Steps per Second: 22,339.43791
Overall Steps per Second: 10,861.57825

Timestep Collection Time: 2.23954
Timestep Consumption Time: 2.36661
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.60614

Cumulative Model Updates: 111,052
Cumulative Timesteps: 926,140,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.18446
Policy Entropy: 3.16316
Value Function Loss: 0.00411

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.55131
Value Function Update Magnitude: 0.62215

Collected Steps per Second: 22,864.08100
Overall Steps per Second: 10,691.65743

Timestep Collection Time: 2.18684
Timestep Consumption Time: 2.48971
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.67654

Cumulative Model Updates: 111,058
Cumulative Timesteps: 926,190,134

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 926190134...
Checkpoint 926190134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,814.85865
Policy Entropy: 3.17867
Value Function Loss: 0.00424

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09208
Policy Update Magnitude: 0.54439
Value Function Update Magnitude: 0.60827

Collected Steps per Second: 22,315.39264
Overall Steps per Second: 10,857.04164

Timestep Collection Time: 2.24141
Timestep Consumption Time: 2.36555
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.60696

Cumulative Model Updates: 111,064
Cumulative Timesteps: 926,240,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,566.01213
Policy Entropy: 3.17211
Value Function Loss: 0.00457

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09099
Policy Update Magnitude: 0.55149
Value Function Update Magnitude: 0.62090

Collected Steps per Second: 22,084.94198
Overall Steps per Second: 10,686.42733

Timestep Collection Time: 2.26471
Timestep Consumption Time: 2.41562
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.68033

Cumulative Model Updates: 111,070
Cumulative Timesteps: 926,290,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 926290168...
Checkpoint 926290168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.47322
Policy Entropy: 3.16139
Value Function Loss: 0.00474

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09951
Policy Update Magnitude: 0.56080
Value Function Update Magnitude: 0.64413

Collected Steps per Second: 22,949.34306
Overall Steps per Second: 10,813.48977

Timestep Collection Time: 2.17889
Timestep Consumption Time: 2.44534
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.62422

Cumulative Model Updates: 111,076
Cumulative Timesteps: 926,340,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.29611
Policy Entropy: 3.14694
Value Function Loss: 0.00480

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.55627
Value Function Update Magnitude: 0.62518

Collected Steps per Second: 23,116.92568
Overall Steps per Second: 10,735.05216

Timestep Collection Time: 2.16413
Timestep Consumption Time: 2.49612
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.66025

Cumulative Model Updates: 111,082
Cumulative Timesteps: 926,390,200

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 926390200...
Checkpoint 926390200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,283.11979
Policy Entropy: 3.15474
Value Function Loss: 0.00466

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.55575
Value Function Update Magnitude: 0.61638

Collected Steps per Second: 22,278.98424
Overall Steps per Second: 10,843.66540

Timestep Collection Time: 2.24454
Timestep Consumption Time: 2.36700
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.61154

Cumulative Model Updates: 111,088
Cumulative Timesteps: 926,440,206

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,109.21708
Policy Entropy: 3.14995
Value Function Loss: 0.00481

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09360
Policy Update Magnitude: 0.55990
Value Function Update Magnitude: 0.63355

Collected Steps per Second: 22,324.79003
Overall Steps per Second: 10,715.79327

Timestep Collection Time: 2.24047
Timestep Consumption Time: 2.42722
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.66769

Cumulative Model Updates: 111,094
Cumulative Timesteps: 926,490,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 926490224...
Checkpoint 926490224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.85384
Policy Entropy: 3.14523
Value Function Loss: 0.00502

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10208
Policy Update Magnitude: 0.57676
Value Function Update Magnitude: 0.65727

Collected Steps per Second: 21,917.60362
Overall Steps per Second: 10,766.61729

Timestep Collection Time: 2.28182
Timestep Consumption Time: 2.36328
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.64510

Cumulative Model Updates: 111,100
Cumulative Timesteps: 926,540,236

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.78380
Policy Entropy: 3.15232
Value Function Loss: 0.00490

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09834
Policy Update Magnitude: 0.57444
Value Function Update Magnitude: 0.65754

Collected Steps per Second: 22,127.71861
Overall Steps per Second: 10,648.75167

Timestep Collection Time: 2.26051
Timestep Consumption Time: 2.43675
PPO Batch Consumption Time: 0.29480
Total Iteration Time: 4.69726

Cumulative Model Updates: 111,106
Cumulative Timesteps: 926,590,256

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 926590256...
Checkpoint 926590256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.64414
Policy Entropy: 3.14900
Value Function Loss: 0.00503

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10314
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.65199

Collected Steps per Second: 23,070.10423
Overall Steps per Second: 10,715.06212

Timestep Collection Time: 2.16809
Timestep Consumption Time: 2.49992
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.66801

Cumulative Model Updates: 111,112
Cumulative Timesteps: 926,640,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 804.06205
Policy Entropy: 3.15899
Value Function Loss: 0.00474

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10541
Policy Update Magnitude: 0.56616
Value Function Update Magnitude: 0.63253

Collected Steps per Second: 22,079.76403
Overall Steps per Second: 10,734.17430

Timestep Collection Time: 2.26524
Timestep Consumption Time: 2.39427
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.65951

Cumulative Model Updates: 111,118
Cumulative Timesteps: 926,690,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 926690290...
Checkpoint 926690290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,871.24087
Policy Entropy: 3.16149
Value Function Loss: 0.00488

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.56289
Value Function Update Magnitude: 0.64788

Collected Steps per Second: 21,807.44888
Overall Steps per Second: 10,644.70451

Timestep Collection Time: 2.29316
Timestep Consumption Time: 2.40476
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.69792

Cumulative Model Updates: 111,124
Cumulative Timesteps: 926,740,298

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.75477
Policy Entropy: 3.13882
Value Function Loss: 0.00488

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11294
Policy Update Magnitude: 0.56180
Value Function Update Magnitude: 0.66213

Collected Steps per Second: 22,077.68386
Overall Steps per Second: 10,803.68048

Timestep Collection Time: 2.26573
Timestep Consumption Time: 2.36436
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.63009

Cumulative Model Updates: 111,130
Cumulative Timesteps: 926,790,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 926790320...
Checkpoint 926790320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 879.75190
Policy Entropy: 3.14367
Value Function Loss: 0.00488

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.68039

Collected Steps per Second: 21,923.10532
Overall Steps per Second: 10,730.88601

Timestep Collection Time: 2.28070
Timestep Consumption Time: 2.37875
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.65945

Cumulative Model Updates: 111,136
Cumulative Timesteps: 926,840,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,771.63164
Policy Entropy: 3.13360
Value Function Loss: 0.00470

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.56655
Value Function Update Magnitude: 0.67221

Collected Steps per Second: 22,159.07460
Overall Steps per Second: 10,803.66430

Timestep Collection Time: 2.25686
Timestep Consumption Time: 2.37212
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.62899

Cumulative Model Updates: 111,142
Cumulative Timesteps: 926,890,330

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 926890330...
Checkpoint 926890330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,341.02345
Policy Entropy: 3.13891
Value Function Loss: 0.00482

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.56638
Value Function Update Magnitude: 0.65513

Collected Steps per Second: 21,749.98856
Overall Steps per Second: 10,682.73663

Timestep Collection Time: 2.29922
Timestep Consumption Time: 2.38198
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.68120

Cumulative Model Updates: 111,148
Cumulative Timesteps: 926,940,338

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.81505
Policy Entropy: 3.12267
Value Function Loss: 0.00495

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10027
Policy Update Magnitude: 0.56635
Value Function Update Magnitude: 0.64867

Collected Steps per Second: 22,814.10971
Overall Steps per Second: 10,621.67895

Timestep Collection Time: 2.19206
Timestep Consumption Time: 2.51623
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.70830

Cumulative Model Updates: 111,154
Cumulative Timesteps: 926,990,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 926990348...
Checkpoint 926990348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,819.36392
Policy Entropy: 3.13443
Value Function Loss: 0.00480

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09608
Policy Update Magnitude: 0.57350
Value Function Update Magnitude: 0.64902

Collected Steps per Second: 22,102.68989
Overall Steps per Second: 10,679.44486

Timestep Collection Time: 2.26217
Timestep Consumption Time: 2.41972
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.68189

Cumulative Model Updates: 111,160
Cumulative Timesteps: 927,040,348

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 926.48335
Policy Entropy: 3.12544
Value Function Loss: 0.00472

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.57387
Value Function Update Magnitude: 0.63797

Collected Steps per Second: 23,212.52147
Overall Steps per Second: 10,766.95300

Timestep Collection Time: 2.15522
Timestep Consumption Time: 2.49122
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.64644

Cumulative Model Updates: 111,166
Cumulative Timesteps: 927,090,376

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 927090376...
Checkpoint 927090376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 866.87971
Policy Entropy: 3.12567
Value Function Loss: 0.00461

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.57000
Value Function Update Magnitude: 0.64351

Collected Steps per Second: 22,827.96071
Overall Steps per Second: 10,664.44676

Timestep Collection Time: 2.19108
Timestep Consumption Time: 2.49908
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.69016

Cumulative Model Updates: 111,172
Cumulative Timesteps: 927,140,394

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.28668
Policy Entropy: 3.13050
Value Function Loss: 0.00483

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.57488
Value Function Update Magnitude: 0.64699

Collected Steps per Second: 23,069.73129
Overall Steps per Second: 10,794.41306

Timestep Collection Time: 2.16743
Timestep Consumption Time: 2.46478
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.63221

Cumulative Model Updates: 111,178
Cumulative Timesteps: 927,190,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 927190396...
Checkpoint 927190396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 826.85076
Policy Entropy: 3.13784
Value Function Loss: 0.00481

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10775
Policy Update Magnitude: 0.57817
Value Function Update Magnitude: 0.63854

Collected Steps per Second: 22,841.15591
Overall Steps per Second: 10,695.94951

Timestep Collection Time: 2.18964
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.67598

Cumulative Model Updates: 111,184
Cumulative Timesteps: 927,240,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,311.14703
Policy Entropy: 3.12954
Value Function Loss: 0.00486

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.57950
Value Function Update Magnitude: 0.64079

Collected Steps per Second: 22,188.15869
Overall Steps per Second: 10,814.92900

Timestep Collection Time: 2.25481
Timestep Consumption Time: 2.37121
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.62601

Cumulative Model Updates: 111,190
Cumulative Timesteps: 927,290,440

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 927290440...
Checkpoint 927290440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,753.23561
Policy Entropy: 3.12923
Value Function Loss: 0.00449

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10414
Policy Update Magnitude: 0.57049
Value Function Update Magnitude: 0.62206

Collected Steps per Second: 22,102.91058
Overall Steps per Second: 10,754.80284

Timestep Collection Time: 2.26287
Timestep Consumption Time: 2.38770
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.65057

Cumulative Model Updates: 111,196
Cumulative Timesteps: 927,340,456

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.12341
Policy Entropy: 3.12922
Value Function Loss: 0.00476

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09287
Policy Update Magnitude: 0.56877
Value Function Update Magnitude: 0.60462

Collected Steps per Second: 23,243.24427
Overall Steps per Second: 10,874.51551

Timestep Collection Time: 2.15228
Timestep Consumption Time: 2.44802
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.60030

Cumulative Model Updates: 111,202
Cumulative Timesteps: 927,390,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 927390482...
Checkpoint 927390482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.96306
Policy Entropy: 3.13337
Value Function Loss: 0.00484

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09747
Policy Update Magnitude: 0.57559
Value Function Update Magnitude: 0.61405

Collected Steps per Second: 22,845.54584
Overall Steps per Second: 10,646.96406

Timestep Collection Time: 2.18992
Timestep Consumption Time: 2.50907
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69899

Cumulative Model Updates: 111,208
Cumulative Timesteps: 927,440,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.76305
Policy Entropy: 3.13457
Value Function Loss: 0.00479

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.57623
Value Function Update Magnitude: 0.63674

Collected Steps per Second: 22,860.66420
Overall Steps per Second: 10,686.11858

Timestep Collection Time: 2.18813
Timestep Consumption Time: 2.49290
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.68103

Cumulative Model Updates: 111,214
Cumulative Timesteps: 927,490,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 927490534...
Checkpoint 927490534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.62208
Policy Entropy: 3.14236
Value Function Loss: 0.00482

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11023
Policy Update Magnitude: 0.57483
Value Function Update Magnitude: 0.63620

Collected Steps per Second: 22,474.50814
Overall Steps per Second: 10,587.83168

Timestep Collection Time: 2.22554
Timestep Consumption Time: 2.49856
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.72410

Cumulative Model Updates: 111,220
Cumulative Timesteps: 927,540,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 860.32488
Policy Entropy: 3.14006
Value Function Loss: 0.00486

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.58333
Value Function Update Magnitude: 0.62712

Collected Steps per Second: 23,202.03802
Overall Steps per Second: 10,740.38603

Timestep Collection Time: 2.15593
Timestep Consumption Time: 2.50144
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.65737

Cumulative Model Updates: 111,226
Cumulative Timesteps: 927,590,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 927590574...
Checkpoint 927590574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 785.66015
Policy Entropy: 3.12087
Value Function Loss: 0.00504

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.58474
Value Function Update Magnitude: 0.62340

Collected Steps per Second: 22,751.67764
Overall Steps per Second: 10,670.06138

Timestep Collection Time: 2.19861
Timestep Consumption Time: 2.48946
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.68807

Cumulative Model Updates: 111,232
Cumulative Timesteps: 927,640,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.82601
Policy Entropy: 3.11908
Value Function Loss: 0.00520

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10392
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.63617

Collected Steps per Second: 23,087.89332
Overall Steps per Second: 10,839.56988

Timestep Collection Time: 2.16607
Timestep Consumption Time: 2.44758
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.61365

Cumulative Model Updates: 111,238
Cumulative Timesteps: 927,690,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 927690606...
Checkpoint 927690606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,535.25309
Policy Entropy: 3.12757
Value Function Loss: 0.00533

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10784
Policy Update Magnitude: 0.59112
Value Function Update Magnitude: 0.64245

Collected Steps per Second: 21,959.36823
Overall Steps per Second: 10,686.42206

Timestep Collection Time: 2.27748
Timestep Consumption Time: 2.40248
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.67996

Cumulative Model Updates: 111,244
Cumulative Timesteps: 927,740,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.87054
Policy Entropy: 3.11781
Value Function Loss: 0.00522

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10833
Policy Update Magnitude: 0.59631
Value Function Update Magnitude: 0.65493

Collected Steps per Second: 22,104.00143
Overall Steps per Second: 10,674.50887

Timestep Collection Time: 2.26240
Timestep Consumption Time: 2.42241
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.68481

Cumulative Model Updates: 111,250
Cumulative Timesteps: 927,790,626

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 927790626...
Checkpoint 927790626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.43020
Policy Entropy: 3.11801
Value Function Loss: 0.00519

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.59593
Value Function Update Magnitude: 0.65972

Collected Steps per Second: 22,461.42432
Overall Steps per Second: 10,860.33298

Timestep Collection Time: 2.22666
Timestep Consumption Time: 2.37854
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.60520

Cumulative Model Updates: 111,256
Cumulative Timesteps: 927,840,640

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 799.12445
Policy Entropy: 3.11052
Value Function Loss: 0.00512

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10570
Policy Update Magnitude: 0.59664
Value Function Update Magnitude: 0.65238

Collected Steps per Second: 23,068.49761
Overall Steps per Second: 10,823.50547

Timestep Collection Time: 2.16815
Timestep Consumption Time: 2.45290
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.62105

Cumulative Model Updates: 111,262
Cumulative Timesteps: 927,890,656

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 927890656...
Checkpoint 927890656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.52195
Policy Entropy: 3.10419
Value Function Loss: 0.00534

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.12009
Policy Update Magnitude: 0.59385
Value Function Update Magnitude: 0.64230

Collected Steps per Second: 23,032.53163
Overall Steps per Second: 10,761.75150

Timestep Collection Time: 2.17171
Timestep Consumption Time: 2.47623
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.64794

Cumulative Model Updates: 111,268
Cumulative Timesteps: 927,940,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.21738
Policy Entropy: 3.09791
Value Function Loss: 0.00535

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.58955
Value Function Update Magnitude: 0.64811

Collected Steps per Second: 22,883.23344
Overall Steps per Second: 10,804.52390

Timestep Collection Time: 2.18632
Timestep Consumption Time: 2.44415
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.63047

Cumulative Model Updates: 111,274
Cumulative Timesteps: 927,990,706

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 927990706...
Checkpoint 927990706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 993.51665
Policy Entropy: 3.10515
Value Function Loss: 0.00511

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.58709
Value Function Update Magnitude: 0.64362

Collected Steps per Second: 22,964.41994
Overall Steps per Second: 10,725.15860

Timestep Collection Time: 2.17737
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.66212

Cumulative Model Updates: 111,280
Cumulative Timesteps: 928,040,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517.90000
Policy Entropy: 3.11217
Value Function Loss: 0.00467

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.57732
Value Function Update Magnitude: 0.62971

Collected Steps per Second: 22,967.17499
Overall Steps per Second: 10,711.05069

Timestep Collection Time: 2.17807
Timestep Consumption Time: 2.49225
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.67032

Cumulative Model Updates: 111,286
Cumulative Timesteps: 928,090,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 928090732...
Checkpoint 928090732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,064.72267
Policy Entropy: 3.11480
Value Function Loss: 0.00461

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.57255
Value Function Update Magnitude: 0.59716

Collected Steps per Second: 23,170.72391
Overall Steps per Second: 10,866.55699

Timestep Collection Time: 2.15919
Timestep Consumption Time: 2.44484
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.60403

Cumulative Model Updates: 111,292
Cumulative Timesteps: 928,140,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.57236
Policy Entropy: 3.10677
Value Function Loss: 0.00470

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10498
Policy Update Magnitude: 0.57345
Value Function Update Magnitude: 0.58256

Collected Steps per Second: 23,092.37652
Overall Steps per Second: 10,829.08141

Timestep Collection Time: 2.16591
Timestep Consumption Time: 2.45276
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.61867

Cumulative Model Updates: 111,298
Cumulative Timesteps: 928,190,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 928190778...
Checkpoint 928190778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,565.08007
Policy Entropy: 3.10011
Value Function Loss: 0.00477

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.56803
Value Function Update Magnitude: 0.59927

Collected Steps per Second: 22,521.47312
Overall Steps per Second: 10,720.31389

Timestep Collection Time: 2.22135
Timestep Consumption Time: 2.44531
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.66665

Cumulative Model Updates: 111,304
Cumulative Timesteps: 928,240,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.93315
Policy Entropy: 3.08849
Value Function Loss: 0.00486

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09197
Policy Update Magnitude: 0.57182
Value Function Update Magnitude: 0.59032

Collected Steps per Second: 22,630.08498
Overall Steps per Second: 10,620.77604

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.49911
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.70926

Cumulative Model Updates: 111,310
Cumulative Timesteps: 928,290,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 928290822...
Checkpoint 928290822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,446.60247
Policy Entropy: 3.08823
Value Function Loss: 0.00500

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10664
Policy Update Magnitude: 0.57573
Value Function Update Magnitude: 0.56434

Collected Steps per Second: 22,919.45194
Overall Steps per Second: 10,852.10535

Timestep Collection Time: 2.18164
Timestep Consumption Time: 2.42594
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.60759

Cumulative Model Updates: 111,316
Cumulative Timesteps: 928,340,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.61895
Policy Entropy: 3.09999
Value Function Loss: 0.00503

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.57246
Value Function Update Magnitude: 0.56325

Collected Steps per Second: 22,802.76719
Overall Steps per Second: 10,618.61906

Timestep Collection Time: 2.19342
Timestep Consumption Time: 2.51680
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.71022

Cumulative Model Updates: 111,322
Cumulative Timesteps: 928,390,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 928390840...
Checkpoint 928390840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.97012
Policy Entropy: 3.10843
Value Function Loss: 0.00506

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.57620
Value Function Update Magnitude: 0.58107

Collected Steps per Second: 22,883.37373
Overall Steps per Second: 10,667.49396

Timestep Collection Time: 2.18543
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.68807

Cumulative Model Updates: 111,328
Cumulative Timesteps: 928,440,850

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.82121
Policy Entropy: 3.12745
Value Function Loss: 0.00477

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.57175
Value Function Update Magnitude: 0.59949

Collected Steps per Second: 22,144.78440
Overall Steps per Second: 10,775.76432

Timestep Collection Time: 2.25850
Timestep Consumption Time: 2.38284
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.64134

Cumulative Model Updates: 111,334
Cumulative Timesteps: 928,490,864

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 928490864...
Checkpoint 928490864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,672.30872
Policy Entropy: 3.12560
Value Function Loss: 0.00472

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.57095
Value Function Update Magnitude: 0.59291

Collected Steps per Second: 22,146.60361
Overall Steps per Second: 10,641.74374

Timestep Collection Time: 2.25859
Timestep Consumption Time: 2.44177
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.70036

Cumulative Model Updates: 111,340
Cumulative Timesteps: 928,540,884

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 843.16196
Policy Entropy: 3.13892
Value Function Loss: 0.00468

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11593
Policy Update Magnitude: 0.57374
Value Function Update Magnitude: 0.60287

Collected Steps per Second: 23,049.02728
Overall Steps per Second: 10,823.34490

Timestep Collection Time: 2.16972
Timestep Consumption Time: 2.45085
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.62057

Cumulative Model Updates: 111,346
Cumulative Timesteps: 928,590,894

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 928590894...
Checkpoint 928590894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.23570
Policy Entropy: 3.13549
Value Function Loss: 0.00500

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.58016
Value Function Update Magnitude: 0.60710

Collected Steps per Second: 21,975.44595
Overall Steps per Second: 10,755.53216

Timestep Collection Time: 2.27627
Timestep Consumption Time: 2.37455
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.65082

Cumulative Model Updates: 111,352
Cumulative Timesteps: 928,640,916

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,226.94046
Policy Entropy: 3.12893
Value Function Loss: 0.00529

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11353
Policy Update Magnitude: 0.58211
Value Function Update Magnitude: 0.61267

Collected Steps per Second: 22,034.35254
Overall Steps per Second: 10,789.36509

Timestep Collection Time: 2.27055
Timestep Consumption Time: 2.36643
PPO Batch Consumption Time: 0.28187
Total Iteration Time: 4.63697

Cumulative Model Updates: 111,358
Cumulative Timesteps: 928,690,946

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 928690946...
Checkpoint 928690946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,002.29059
Policy Entropy: 3.12695
Value Function Loss: 0.00533

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.58367
Value Function Update Magnitude: 0.61301

Collected Steps per Second: 21,900.44201
Overall Steps per Second: 10,766.79150

Timestep Collection Time: 2.28370
Timestep Consumption Time: 2.36151
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.64521

Cumulative Model Updates: 111,364
Cumulative Timesteps: 928,740,960

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.97040
Policy Entropy: 3.11517
Value Function Loss: 0.00495

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.57991
Value Function Update Magnitude: 0.59310

Collected Steps per Second: 22,365.22797
Overall Steps per Second: 10,838.63846

Timestep Collection Time: 2.23579
Timestep Consumption Time: 2.37770
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.61349

Cumulative Model Updates: 111,370
Cumulative Timesteps: 928,790,964

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 928790964...
Checkpoint 928790964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.08183
Policy Entropy: 3.11347
Value Function Loss: 0.00506

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.58187

Collected Steps per Second: 22,864.86560
Overall Steps per Second: 10,672.41759

Timestep Collection Time: 2.18694
Timestep Consumption Time: 2.49841
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.68535

Cumulative Model Updates: 111,376
Cumulative Timesteps: 928,840,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 712.99798
Policy Entropy: 3.11894
Value Function Loss: 0.00465

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.58102
Value Function Update Magnitude: 0.57282

Collected Steps per Second: 23,050.02990
Overall Steps per Second: 10,815.82962

Timestep Collection Time: 2.17050
Timestep Consumption Time: 2.45513
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.62563

Cumulative Model Updates: 111,382
Cumulative Timesteps: 928,890,998

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 928890998...
Checkpoint 928890998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.50600
Policy Entropy: 3.10739
Value Function Loss: 0.00494

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11229
Policy Update Magnitude: 0.57857
Value Function Update Magnitude: 0.57891

Collected Steps per Second: 22,746.56728
Overall Steps per Second: 10,762.79323

Timestep Collection Time: 2.19893
Timestep Consumption Time: 2.44838
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.64731

Cumulative Model Updates: 111,388
Cumulative Timesteps: 928,941,016

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,094.53549
Policy Entropy: 3.11848
Value Function Loss: 0.00494

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.58011
Value Function Update Magnitude: 0.59703

Collected Steps per Second: 22,971.75503
Overall Steps per Second: 10,788.09062

Timestep Collection Time: 2.17702
Timestep Consumption Time: 2.45865
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.63567

Cumulative Model Updates: 111,394
Cumulative Timesteps: 928,991,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 928991026...
Checkpoint 928991026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,365.61968
Policy Entropy: 3.12166
Value Function Loss: 0.00514

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.59428
Value Function Update Magnitude: 0.61124

Collected Steps per Second: 23,023.85556
Overall Steps per Second: 10,718.77022

Timestep Collection Time: 2.17192
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.66527

Cumulative Model Updates: 111,400
Cumulative Timesteps: 929,041,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656.31993
Policy Entropy: 3.15976
Value Function Loss: 0.00505

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10249
Policy Update Magnitude: 0.59099
Value Function Update Magnitude: 0.60853

Collected Steps per Second: 22,817.06369
Overall Steps per Second: 10,640.53687

Timestep Collection Time: 2.19161
Timestep Consumption Time: 2.50797
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.69957

Cumulative Model Updates: 111,406
Cumulative Timesteps: 929,091,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 929091038...
Checkpoint 929091038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.31848
Policy Entropy: 3.16302
Value Function Loss: 0.00491

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.57925
Value Function Update Magnitude: 0.59715

Collected Steps per Second: 22,978.88958
Overall Steps per Second: 10,809.97673

Timestep Collection Time: 2.17617
Timestep Consumption Time: 2.44974
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.62591

Cumulative Model Updates: 111,412
Cumulative Timesteps: 929,141,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.40327
Policy Entropy: 3.16458
Value Function Loss: 0.00470

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.56871
Value Function Update Magnitude: 0.58766

Collected Steps per Second: 22,924.60518
Overall Steps per Second: 10,620.42956

Timestep Collection Time: 2.18159
Timestep Consumption Time: 2.52745
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.70904

Cumulative Model Updates: 111,418
Cumulative Timesteps: 929,191,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 929191056...
Checkpoint 929191056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.23561
Policy Entropy: 3.14872
Value Function Loss: 0.00473

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.56451
Value Function Update Magnitude: 0.58661

Collected Steps per Second: 23,056.00573
Overall Steps per Second: 10,640.47637

Timestep Collection Time: 2.16872
Timestep Consumption Time: 2.53051
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.69923

Cumulative Model Updates: 111,424
Cumulative Timesteps: 929,241,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,153.93167
Policy Entropy: 3.14841
Value Function Loss: 0.00467

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10511
Policy Update Magnitude: 0.56560
Value Function Update Magnitude: 0.58982

Collected Steps per Second: 22,932.41898
Overall Steps per Second: 10,810.18653

Timestep Collection Time: 2.18041
Timestep Consumption Time: 2.44505
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.62545

Cumulative Model Updates: 111,430
Cumulative Timesteps: 929,291,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 929291060...
Checkpoint 929291060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,909.40117
Policy Entropy: 3.16020
Value Function Loss: 0.00457

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.56609
Value Function Update Magnitude: 0.59212

Collected Steps per Second: 22,806.98827
Overall Steps per Second: 10,654.11854

Timestep Collection Time: 2.19354
Timestep Consumption Time: 2.50211
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.69565

Cumulative Model Updates: 111,436
Cumulative Timesteps: 929,341,088

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,381.29504
Policy Entropy: 3.14429
Value Function Loss: 0.00461

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.56293
Value Function Update Magnitude: 0.61549

Collected Steps per Second: 21,716.50656
Overall Steps per Second: 10,471.18818

Timestep Collection Time: 2.30240
Timestep Consumption Time: 2.47261
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.77501

Cumulative Model Updates: 111,442
Cumulative Timesteps: 929,391,088

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 929391088...
Checkpoint 929391088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.77138
Policy Entropy: 3.13985
Value Function Loss: 0.00483

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.57576
Value Function Update Magnitude: 0.64782

Collected Steps per Second: 22,080.01434
Overall Steps per Second: 10,639.17201

Timestep Collection Time: 2.26531
Timestep Consumption Time: 2.43600
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.70131

Cumulative Model Updates: 111,448
Cumulative Timesteps: 929,441,106

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,314.95841
Policy Entropy: 3.12960
Value Function Loss: 0.00495

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.57855
Value Function Update Magnitude: 0.63058

Collected Steps per Second: 22,078.62476
Overall Steps per Second: 10,686.07174

Timestep Collection Time: 2.26590
Timestep Consumption Time: 2.41571
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.68161

Cumulative Model Updates: 111,454
Cumulative Timesteps: 929,491,134

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 929491134...
Checkpoint 929491134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.35836
Policy Entropy: 3.15417
Value Function Loss: 0.00492

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.57240
Value Function Update Magnitude: 0.60665

Collected Steps per Second: 22,306.22394
Overall Steps per Second: 10,860.10097

Timestep Collection Time: 2.24189
Timestep Consumption Time: 2.36286
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.60475

Cumulative Model Updates: 111,460
Cumulative Timesteps: 929,541,142

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,162.57996
Policy Entropy: 3.16908
Value Function Loss: 0.00446

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.08648
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.59859

Collected Steps per Second: 22,208.59388
Overall Steps per Second: 10,690.09576

Timestep Collection Time: 2.25282
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68022

Cumulative Model Updates: 111,466
Cumulative Timesteps: 929,591,174

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 929591174...
Checkpoint 929591174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.16184
Policy Entropy: 3.19247
Value Function Loss: 0.00430

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.08533
Policy Update Magnitude: 0.54277
Value Function Update Magnitude: 0.58635

Collected Steps per Second: 22,616.62807
Overall Steps per Second: 10,871.87289

Timestep Collection Time: 2.21076
Timestep Consumption Time: 2.38826
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.59902

Cumulative Model Updates: 111,472
Cumulative Timesteps: 929,641,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.47340
Policy Entropy: 3.17615
Value Function Loss: 0.00452

Mean KL Divergence: 0.00817
SB3 Clip Fraction: 0.09015
Policy Update Magnitude: 0.54883
Value Function Update Magnitude: 0.60243

Collected Steps per Second: 21,899.54710
Overall Steps per Second: 10,626.55728

Timestep Collection Time: 2.28407
Timestep Consumption Time: 2.42301
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.70707

Cumulative Model Updates: 111,478
Cumulative Timesteps: 929,691,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 929691194...
Checkpoint 929691194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 523.92575
Policy Entropy: 3.16517
Value Function Loss: 0.00501

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.56081
Value Function Update Magnitude: 0.61581

Collected Steps per Second: 22,360.49155
Overall Steps per Second: 10,839.54298

Timestep Collection Time: 2.23609
Timestep Consumption Time: 2.37665
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.61274

Cumulative Model Updates: 111,484
Cumulative Timesteps: 929,741,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.82004
Policy Entropy: 3.15304
Value Function Loss: 0.00515

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09298
Policy Update Magnitude: 0.57032
Value Function Update Magnitude: 0.59670

Collected Steps per Second: 21,876.00766
Overall Steps per Second: 10,543.13131

Timestep Collection Time: 2.28561
Timestep Consumption Time: 2.45682
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.74242

Cumulative Model Updates: 111,490
Cumulative Timesteps: 929,791,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 929791194...
Checkpoint 929791194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,353.49850
Policy Entropy: 3.16214
Value Function Loss: 0.00535

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09535
Policy Update Magnitude: 0.56902
Value Function Update Magnitude: 0.56638

Collected Steps per Second: 22,318.68567
Overall Steps per Second: 10,653.25036

Timestep Collection Time: 2.24036
Timestep Consumption Time: 2.45323
PPO Batch Consumption Time: 0.29690
Total Iteration Time: 4.69359

Cumulative Model Updates: 111,496
Cumulative Timesteps: 929,841,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,678.50810
Policy Entropy: 3.16617
Value Function Loss: 0.00483

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09184
Policy Update Magnitude: 0.56012
Value Function Update Magnitude: 0.57799

Collected Steps per Second: 21,857.01434
Overall Steps per Second: 10,630.49598

Timestep Collection Time: 2.28878
Timestep Consumption Time: 2.41711
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.70590

Cumulative Model Updates: 111,502
Cumulative Timesteps: 929,891,222

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 929891222...
Checkpoint 929891222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,285.84049
Policy Entropy: 3.15757
Value Function Loss: 0.00463

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10177
Policy Update Magnitude: 0.55139
Value Function Update Magnitude: 0.59465

Collected Steps per Second: 22,235.16601
Overall Steps per Second: 10,814.88132

Timestep Collection Time: 2.24887
Timestep Consumption Time: 2.37476
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.62363

Cumulative Model Updates: 111,508
Cumulative Timesteps: 929,941,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.96209
Policy Entropy: 3.15900
Value Function Loss: 0.00439

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.55448
Value Function Update Magnitude: 0.59984

Collected Steps per Second: 22,322.35221
Overall Steps per Second: 10,707.98408

Timestep Collection Time: 2.24027
Timestep Consumption Time: 2.42989
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.67016

Cumulative Model Updates: 111,514
Cumulative Timesteps: 929,991,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 929991234...
Checkpoint 929991234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,059.58545
Policy Entropy: 3.15054
Value Function Loss: 0.00428

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.55305
Value Function Update Magnitude: 0.58801

Collected Steps per Second: 22,156.48215
Overall Steps per Second: 10,781.62862

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.38122
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.63826

Cumulative Model Updates: 111,520
Cumulative Timesteps: 930,041,242

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,815.99804
Policy Entropy: 3.15471
Value Function Loss: 0.00421

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.54861
Value Function Update Magnitude: 0.57998

Collected Steps per Second: 22,211.29590
Overall Steps per Second: 10,646.38492

Timestep Collection Time: 2.25165
Timestep Consumption Time: 2.44591
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.69756

Cumulative Model Updates: 111,526
Cumulative Timesteps: 930,091,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 930091254...
Checkpoint 930091254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,173.42349
Policy Entropy: 3.13381
Value Function Loss: 0.00452

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.08306
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 0.56645

Collected Steps per Second: 22,169.72834
Overall Steps per Second: 10,675.36787

Timestep Collection Time: 2.25677
Timestep Consumption Time: 2.42991
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.68668

Cumulative Model Updates: 111,532
Cumulative Timesteps: 930,141,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,316.84193
Policy Entropy: 3.13361
Value Function Loss: 0.00488

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.08976
Policy Update Magnitude: 0.56276
Value Function Update Magnitude: 0.59670

Collected Steps per Second: 22,231.07081
Overall Steps per Second: 10,803.18845

Timestep Collection Time: 2.25045
Timestep Consumption Time: 2.38059
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.63104

Cumulative Model Updates: 111,538
Cumulative Timesteps: 930,191,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 930191316...
Checkpoint 930191316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,402.38195
Policy Entropy: 3.12422
Value Function Loss: 0.00488

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09628
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.63538

Collected Steps per Second: 22,125.31387
Overall Steps per Second: 10,620.18428

Timestep Collection Time: 2.26058
Timestep Consumption Time: 2.44894
PPO Batch Consumption Time: 0.29459
Total Iteration Time: 4.70952

Cumulative Model Updates: 111,544
Cumulative Timesteps: 930,241,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 814.34581
Policy Entropy: 3.13137
Value Function Loss: 0.00481

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.56805
Value Function Update Magnitude: 0.63514

Collected Steps per Second: 22,973.25306
Overall Steps per Second: 10,802.19635

Timestep Collection Time: 2.17697
Timestep Consumption Time: 2.45283
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.62980

Cumulative Model Updates: 111,550
Cumulative Timesteps: 930,291,344

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 930291344...
Checkpoint 930291344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.61981
Policy Entropy: 3.13305
Value Function Loss: 0.00487

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09022
Policy Update Magnitude: 0.57644
Value Function Update Magnitude: 0.63425

Collected Steps per Second: 22,885.14890
Overall Steps per Second: 10,733.44015

Timestep Collection Time: 2.18500
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.65871

Cumulative Model Updates: 111,556
Cumulative Timesteps: 930,341,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,291.57393
Policy Entropy: 3.13621
Value Function Loss: 0.00492

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.57850
Value Function Update Magnitude: 0.64762

Collected Steps per Second: 22,922.22022
Overall Steps per Second: 10,670.45188

Timestep Collection Time: 2.18269
Timestep Consumption Time: 2.50615
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.68884

Cumulative Model Updates: 111,562
Cumulative Timesteps: 930,391,380

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 930391380...
Checkpoint 930391380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.95675
Policy Entropy: 3.12883
Value Function Loss: 0.00481

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.57751
Value Function Update Magnitude: 0.65524

Collected Steps per Second: 22,810.18111
Overall Steps per Second: 10,623.72665

Timestep Collection Time: 2.19262
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.70776

Cumulative Model Updates: 111,568
Cumulative Timesteps: 930,441,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.50864
Policy Entropy: 3.12071
Value Function Loss: 0.00478

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.57624
Value Function Update Magnitude: 0.65206

Collected Steps per Second: 22,982.34560
Overall Steps per Second: 10,747.80341

Timestep Collection Time: 2.17602
Timestep Consumption Time: 2.47703
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.65304

Cumulative Model Updates: 111,574
Cumulative Timesteps: 930,491,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 930491404...
Checkpoint 930491404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.24253
Policy Entropy: 3.11097
Value Function Loss: 0.00493

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11642
Policy Update Magnitude: 0.57687
Value Function Update Magnitude: 0.65452

Collected Steps per Second: 22,638.42924
Overall Steps per Second: 10,589.89484

Timestep Collection Time: 2.20863
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.72148

Cumulative Model Updates: 111,580
Cumulative Timesteps: 930,541,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694.18481
Policy Entropy: 3.11892
Value Function Loss: 0.00488

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.58022
Value Function Update Magnitude: 0.65575

Collected Steps per Second: 22,299.29509
Overall Steps per Second: 10,783.46511

Timestep Collection Time: 2.24339
Timestep Consumption Time: 2.39575
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.63914

Cumulative Model Updates: 111,586
Cumulative Timesteps: 930,591,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 930591430...
Checkpoint 930591430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,533.58210
Policy Entropy: 3.13062
Value Function Loss: 0.00467

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.57105
Value Function Update Magnitude: 0.65864

Collected Steps per Second: 22,748.09548
Overall Steps per Second: 10,791.49265

Timestep Collection Time: 2.19843
Timestep Consumption Time: 2.43578
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.63421

Cumulative Model Updates: 111,592
Cumulative Timesteps: 930,641,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.42447
Policy Entropy: 3.14319
Value Function Loss: 0.00450

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.55689
Value Function Update Magnitude: 0.65937

Collected Steps per Second: 22,234.11358
Overall Steps per Second: 10,812.53523

Timestep Collection Time: 2.24907
Timestep Consumption Time: 2.37575
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.62482

Cumulative Model Updates: 111,598
Cumulative Timesteps: 930,691,446

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 930691446...
Checkpoint 930691446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.08050
Policy Entropy: 3.14636
Value Function Loss: 0.00473

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.56251
Value Function Update Magnitude: 0.65015

Collected Steps per Second: 21,997.59599
Overall Steps per Second: 10,796.53571

Timestep Collection Time: 2.27370
Timestep Consumption Time: 2.35889
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.63260

Cumulative Model Updates: 111,604
Cumulative Timesteps: 930,741,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.74654
Policy Entropy: 3.13136
Value Function Loss: 0.00498

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.57445
Value Function Update Magnitude: 0.64742

Collected Steps per Second: 22,323.85214
Overall Steps per Second: 10,815.13245

Timestep Collection Time: 2.24083
Timestep Consumption Time: 2.38454
PPO Batch Consumption Time: 0.28183
Total Iteration Time: 4.62537

Cumulative Model Updates: 111,610
Cumulative Timesteps: 930,791,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 930791486...
Checkpoint 930791486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.39518
Policy Entropy: 3.13563
Value Function Loss: 0.00486

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.57339
Value Function Update Magnitude: 0.64227

Collected Steps per Second: 22,221.25661
Overall Steps per Second: 10,647.67562

Timestep Collection Time: 2.25073
Timestep Consumption Time: 2.44645
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.69718

Cumulative Model Updates: 111,616
Cumulative Timesteps: 930,841,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.06868
Policy Entropy: 3.14175
Value Function Loss: 0.00500

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.57723
Value Function Update Magnitude: 0.65041

Collected Steps per Second: 21,840.83263
Overall Steps per Second: 10,553.40858

Timestep Collection Time: 2.29030
Timestep Consumption Time: 2.44959
PPO Batch Consumption Time: 0.29581
Total Iteration Time: 4.73989

Cumulative Model Updates: 111,622
Cumulative Timesteps: 930,891,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 930891522...
Checkpoint 930891522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,260.53331
Policy Entropy: 3.14425
Value Function Loss: 0.00478

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09171
Policy Update Magnitude: 0.57738
Value Function Update Magnitude: 0.64827

Collected Steps per Second: 22,407.77737
Overall Steps per Second: 10,745.81970

Timestep Collection Time: 2.23199
Timestep Consumption Time: 2.42228
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.65427

Cumulative Model Updates: 111,628
Cumulative Timesteps: 930,941,536

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.53770
Policy Entropy: 3.13584
Value Function Loss: 0.00504

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.57769
Value Function Update Magnitude: 0.66972

Collected Steps per Second: 23,058.02200
Overall Steps per Second: 10,760.01408

Timestep Collection Time: 2.16931
Timestep Consumption Time: 2.47938
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.64869

Cumulative Model Updates: 111,634
Cumulative Timesteps: 930,991,556

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 930991556...
Checkpoint 930991556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,331.30914
Policy Entropy: 3.13242
Value Function Loss: 0.00471

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.57406
Value Function Update Magnitude: 0.65319

Collected Steps per Second: 22,896.77008
Overall Steps per Second: 10,636.76656

Timestep Collection Time: 2.18459
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.29563
Total Iteration Time: 4.70256

Cumulative Model Updates: 111,640
Cumulative Timesteps: 931,041,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 940.79468
Policy Entropy: 3.13794
Value Function Loss: 0.00473

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10510
Policy Update Magnitude: 0.57322
Value Function Update Magnitude: 0.62203

Collected Steps per Second: 22,605.18983
Overall Steps per Second: 10,596.26532

Timestep Collection Time: 2.21277
Timestep Consumption Time: 2.50776
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.72053

Cumulative Model Updates: 111,646
Cumulative Timesteps: 931,091,596

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 931091596...
Checkpoint 931091596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.73085
Policy Entropy: 3.13187
Value Function Loss: 0.00473

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.56668
Value Function Update Magnitude: 0.61043

Collected Steps per Second: 22,991.71920
Overall Steps per Second: 10,839.05460

Timestep Collection Time: 2.17548
Timestep Consumption Time: 2.43913
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.61461

Cumulative Model Updates: 111,652
Cumulative Timesteps: 931,141,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,541.00242
Policy Entropy: 3.14033
Value Function Loss: 0.00480

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.11244
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.60840

Collected Steps per Second: 21,674.67045
Overall Steps per Second: 10,553.38448

Timestep Collection Time: 2.30841
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.74104

Cumulative Model Updates: 111,658
Cumulative Timesteps: 931,191,648

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 931191648...
Checkpoint 931191648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.81525
Policy Entropy: 3.15354
Value Function Loss: 0.00489

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.08902
Policy Update Magnitude: 0.55919
Value Function Update Magnitude: 0.60663

Collected Steps per Second: 22,101.11224
Overall Steps per Second: 10,617.36843

Timestep Collection Time: 2.26342
Timestep Consumption Time: 2.44811
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.71153

Cumulative Model Updates: 111,664
Cumulative Timesteps: 931,241,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.72372
Policy Entropy: 3.14577
Value Function Loss: 0.00483

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.08212
Policy Update Magnitude: 0.56421
Value Function Update Magnitude: 0.60858

Collected Steps per Second: 22,408.47529
Overall Steps per Second: 10,841.42433

Timestep Collection Time: 2.23264
Timestep Consumption Time: 2.38207
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.61471

Cumulative Model Updates: 111,670
Cumulative Timesteps: 931,291,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 931291702...
Checkpoint 931291702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.84534
Policy Entropy: 3.13224
Value Function Loss: 0.00507

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08715
Policy Update Magnitude: 0.57874
Value Function Update Magnitude: 0.62959

Collected Steps per Second: 22,105.08019
Overall Steps per Second: 10,763.49057

Timestep Collection Time: 2.26265
Timestep Consumption Time: 2.38417
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.64682

Cumulative Model Updates: 111,676
Cumulative Timesteps: 931,341,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.66267
Policy Entropy: 3.11976
Value Function Loss: 0.00497

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.58208
Value Function Update Magnitude: 0.66335

Collected Steps per Second: 22,050.80708
Overall Steps per Second: 10,749.64164

Timestep Collection Time: 2.26758
Timestep Consumption Time: 2.38392
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.65150

Cumulative Model Updates: 111,682
Cumulative Timesteps: 931,391,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 931391720...
Checkpoint 931391720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490.63028
Policy Entropy: 3.13266
Value Function Loss: 0.00516

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11487
Policy Update Magnitude: 0.58398
Value Function Update Magnitude: 0.67082

Collected Steps per Second: 22,470.00693
Overall Steps per Second: 10,748.27527

Timestep Collection Time: 2.22572
Timestep Consumption Time: 2.42730
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.65303

Cumulative Model Updates: 111,688
Cumulative Timesteps: 931,441,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.13438
Policy Entropy: 3.14295
Value Function Loss: 0.00507

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09682
Policy Update Magnitude: 0.58993
Value Function Update Magnitude: 0.67211

Collected Steps per Second: 21,996.69843
Overall Steps per Second: 10,577.24839

Timestep Collection Time: 2.27389
Timestep Consumption Time: 2.45494
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.72883

Cumulative Model Updates: 111,694
Cumulative Timesteps: 931,491,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 931491750...
Checkpoint 931491750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,027.26952
Policy Entropy: 3.15067
Value Function Loss: 0.00480

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09336
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.66310

Collected Steps per Second: 22,471.45381
Overall Steps per Second: 10,754.10339

Timestep Collection Time: 2.22602
Timestep Consumption Time: 2.42541
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.65143

Cumulative Model Updates: 111,700
Cumulative Timesteps: 931,541,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.92119
Policy Entropy: 3.15700
Value Function Loss: 0.00469

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.56758
Value Function Update Magnitude: 0.63385

Collected Steps per Second: 22,304.60792
Overall Steps per Second: 10,745.07870

Timestep Collection Time: 2.24241
Timestep Consumption Time: 2.41238
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.65478

Cumulative Model Updates: 111,706
Cumulative Timesteps: 931,591,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 931591788...
Checkpoint 931591788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.82192
Policy Entropy: 3.14895
Value Function Loss: 0.00454

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09202
Policy Update Magnitude: 0.57068
Value Function Update Magnitude: 0.63554

Collected Steps per Second: 22,180.34749
Overall Steps per Second: 10,624.75821

Timestep Collection Time: 2.25551
Timestep Consumption Time: 2.45311
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.70862

Cumulative Model Updates: 111,712
Cumulative Timesteps: 931,641,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.34722
Policy Entropy: 3.14191
Value Function Loss: 0.00444

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.62011

Collected Steps per Second: 22,055.93823
Overall Steps per Second: 10,711.64679

Timestep Collection Time: 2.26733
Timestep Consumption Time: 2.40124
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.66856

Cumulative Model Updates: 111,718
Cumulative Timesteps: 931,691,824

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 931691824...
Checkpoint 931691824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.30684
Policy Entropy: 3.12226
Value Function Loss: 0.00478

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09216
Policy Update Magnitude: 0.57358
Value Function Update Magnitude: 0.61099

Collected Steps per Second: 22,234.45665
Overall Steps per Second: 10,838.27178

Timestep Collection Time: 2.24957
Timestep Consumption Time: 2.36537
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.61494

Cumulative Model Updates: 111,724
Cumulative Timesteps: 931,741,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,620.22671
Policy Entropy: 3.13137
Value Function Loss: 0.00492

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.57442
Value Function Update Magnitude: 0.61268

Collected Steps per Second: 22,172.85363
Overall Steps per Second: 10,794.44424

Timestep Collection Time: 2.25519
Timestep Consumption Time: 2.37719
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.63238

Cumulative Model Updates: 111,730
Cumulative Timesteps: 931,791,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 931791846...
Checkpoint 931791846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,510.46640
Policy Entropy: 3.13343
Value Function Loss: 0.00482

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.11174
Policy Update Magnitude: 0.57442
Value Function Update Magnitude: 0.59860

Collected Steps per Second: 21,598.50905
Overall Steps per Second: 10,638.54294

Timestep Collection Time: 2.31562
Timestep Consumption Time: 2.38558
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.70121

Cumulative Model Updates: 111,736
Cumulative Timesteps: 931,841,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,030.52971
Policy Entropy: 3.14489
Value Function Loss: 0.00470

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10259
Policy Update Magnitude: 0.57002
Value Function Update Magnitude: 0.60615

Collected Steps per Second: 22,205.21735
Overall Steps per Second: 10,636.47963

Timestep Collection Time: 2.25190
Timestep Consumption Time: 2.44928
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.70118

Cumulative Model Updates: 111,742
Cumulative Timesteps: 931,891,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 931891864...
Checkpoint 931891864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.57300
Policy Entropy: 3.13117
Value Function Loss: 0.00473

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09878
Policy Update Magnitude: 0.56698
Value Function Update Magnitude: 0.58544

Collected Steps per Second: 21,914.21107
Overall Steps per Second: 10,601.18342

Timestep Collection Time: 2.28308
Timestep Consumption Time: 2.43639
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.71947

Cumulative Model Updates: 111,748
Cumulative Timesteps: 931,941,896

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,057.66737
Policy Entropy: 3.12931
Value Function Loss: 0.00489

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10128
Policy Update Magnitude: 0.56733
Value Function Update Magnitude: 0.59702

Collected Steps per Second: 22,349.72279
Overall Steps per Second: 10,823.95794

Timestep Collection Time: 2.23725
Timestep Consumption Time: 2.38231
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.61957

Cumulative Model Updates: 111,754
Cumulative Timesteps: 931,991,898

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 931991898...
Checkpoint 931991898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,391.93428
Policy Entropy: 3.12598
Value Function Loss: 0.00483

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.56281
Value Function Update Magnitude: 0.59142

Collected Steps per Second: 21,916.62733
Overall Steps per Second: 10,679.96032

Timestep Collection Time: 2.28201
Timestep Consumption Time: 2.40096
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.68298

Cumulative Model Updates: 111,760
Cumulative Timesteps: 932,041,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,066.18754
Policy Entropy: 3.13700
Value Function Loss: 0.00454

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.55760
Value Function Update Magnitude: 0.57700

Collected Steps per Second: 21,854.67888
Overall Steps per Second: 10,589.83326

Timestep Collection Time: 2.28912
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.72415

Cumulative Model Updates: 111,766
Cumulative Timesteps: 932,091,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 932091940...
Checkpoint 932091940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.14792
Policy Entropy: 3.13082
Value Function Loss: 0.00440

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.55470
Value Function Update Magnitude: 0.57280

Collected Steps per Second: 22,284.03072
Overall Steps per Second: 10,717.15152

Timestep Collection Time: 2.24439
Timestep Consumption Time: 2.42234
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.66673

Cumulative Model Updates: 111,772
Cumulative Timesteps: 932,141,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,665.77952
Policy Entropy: 3.13385
Value Function Loss: 0.00453

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10236
Policy Update Magnitude: 0.56140
Value Function Update Magnitude: 0.57691

Collected Steps per Second: 22,333.31379
Overall Steps per Second: 10,669.47580

Timestep Collection Time: 2.23961
Timestep Consumption Time: 2.44834
PPO Batch Consumption Time: 0.29422
Total Iteration Time: 4.68795

Cumulative Model Updates: 111,778
Cumulative Timesteps: 932,191,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 932191972...
Checkpoint 932191972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,462.79234
Policy Entropy: 3.12831
Value Function Loss: 0.00447

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.55725
Value Function Update Magnitude: 0.58800

Collected Steps per Second: 22,117.73169
Overall Steps per Second: 10,623.50874

Timestep Collection Time: 2.26190
Timestep Consumption Time: 2.44728
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.70918

Cumulative Model Updates: 111,784
Cumulative Timesteps: 932,242,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.36159
Policy Entropy: 3.12817
Value Function Loss: 0.00501

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.56717
Value Function Update Magnitude: 0.61489

Collected Steps per Second: 22,542.50613
Overall Steps per Second: 10,567.93973

Timestep Collection Time: 2.21927
Timestep Consumption Time: 2.51467
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.73394

Cumulative Model Updates: 111,790
Cumulative Timesteps: 932,292,028

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 932292028...
Checkpoint 932292028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 765.81300
Policy Entropy: 3.13075
Value Function Loss: 0.00473

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.09092
Policy Update Magnitude: 0.58698
Value Function Update Magnitude: 0.65567

Collected Steps per Second: 22,287.16607
Overall Steps per Second: 10,720.93097

Timestep Collection Time: 2.24488
Timestep Consumption Time: 2.42188
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.66676

Cumulative Model Updates: 111,796
Cumulative Timesteps: 932,342,060

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.62837
Policy Entropy: 3.12447
Value Function Loss: 0.00483

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.57908
Value Function Update Magnitude: 0.65997

Collected Steps per Second: 22,448.51831
Overall Steps per Second: 10,756.02636

Timestep Collection Time: 2.22848
Timestep Consumption Time: 2.42250
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.65097

Cumulative Model Updates: 111,802
Cumulative Timesteps: 932,392,086

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 932392086...
Checkpoint 932392086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.07061
Policy Entropy: 3.12072
Value Function Loss: 0.00499

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11132
Policy Update Magnitude: 0.58396
Value Function Update Magnitude: 0.62566

Collected Steps per Second: 21,842.49582
Overall Steps per Second: 10,627.57161

Timestep Collection Time: 2.29040
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.70738

Cumulative Model Updates: 111,808
Cumulative Timesteps: 932,442,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.78691
Policy Entropy: 3.11213
Value Function Loss: 0.00518

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.59116
Value Function Update Magnitude: 0.63445

Collected Steps per Second: 23,175.00754
Overall Steps per Second: 10,862.10634

Timestep Collection Time: 2.15827
Timestep Consumption Time: 2.44654
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.60482

Cumulative Model Updates: 111,814
Cumulative Timesteps: 932,492,132

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 932492132...
Checkpoint 932492132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.16545
Policy Entropy: 3.10635
Value Function Loss: 0.00502

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.58802
Value Function Update Magnitude: 0.64097

Collected Steps per Second: 22,828.97023
Overall Steps per Second: 10,732.68147

Timestep Collection Time: 2.19090
Timestep Consumption Time: 2.46926
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.66016

Cumulative Model Updates: 111,820
Cumulative Timesteps: 932,542,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.08058
Policy Entropy: 3.12342
Value Function Loss: 0.00459

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09986
Policy Update Magnitude: 0.57258
Value Function Update Magnitude: 0.63284

Collected Steps per Second: 22,234.53917
Overall Steps per Second: 10,802.92356

Timestep Collection Time: 2.24893
Timestep Consumption Time: 2.37981
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.62875

Cumulative Model Updates: 111,826
Cumulative Timesteps: 932,592,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 932592152...
Checkpoint 932592152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.96695
Policy Entropy: 3.13678
Value Function Loss: 0.00461

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.56531
Value Function Update Magnitude: 0.62490

Collected Steps per Second: 22,772.25816
Overall Steps per Second: 10,696.27279

Timestep Collection Time: 2.19662
Timestep Consumption Time: 2.47996
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.67658

Cumulative Model Updates: 111,832
Cumulative Timesteps: 932,642,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 826.97484
Policy Entropy: 3.14748
Value Function Loss: 0.00459

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08950
Policy Update Magnitude: 0.56576
Value Function Update Magnitude: 0.62109

Collected Steps per Second: 22,969.27561
Overall Steps per Second: 10,838.15937

Timestep Collection Time: 2.17821
Timestep Consumption Time: 2.43807
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.61628

Cumulative Model Updates: 111,838
Cumulative Timesteps: 932,692,206

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 932692206...
Checkpoint 932692206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 783.07078
Policy Entropy: 3.14439
Value Function Loss: 0.00448

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.56643
Value Function Update Magnitude: 0.63201

Collected Steps per Second: 22,051.58687
Overall Steps per Second: 10,734.05803

Timestep Collection Time: 2.26786
Timestep Consumption Time: 2.39114
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.65900

Cumulative Model Updates: 111,844
Cumulative Timesteps: 932,742,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,016.21102
Policy Entropy: 3.13365
Value Function Loss: 0.00471

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.56649
Value Function Update Magnitude: 0.64150

Collected Steps per Second: 22,202.77036
Overall Steps per Second: 10,670.78102

Timestep Collection Time: 2.25251
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.68682

Cumulative Model Updates: 111,850
Cumulative Timesteps: 932,792,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 932792228...
Checkpoint 932792228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,685.41916
Policy Entropy: 3.12546
Value Function Loss: 0.00479

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09244
Policy Update Magnitude: 0.57140
Value Function Update Magnitude: 0.61199

Collected Steps per Second: 22,180.19906
Overall Steps per Second: 10,787.52188

Timestep Collection Time: 2.25489
Timestep Consumption Time: 2.38139
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.63628

Cumulative Model Updates: 111,856
Cumulative Timesteps: 932,842,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,124.12659
Policy Entropy: 3.13150
Value Function Loss: 0.00501

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09479
Policy Update Magnitude: 0.57310
Value Function Update Magnitude: 0.61020

Collected Steps per Second: 22,139.06620
Overall Steps per Second: 10,652.42345

Timestep Collection Time: 2.25899
Timestep Consumption Time: 2.43590
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.69489

Cumulative Model Updates: 111,862
Cumulative Timesteps: 932,892,254

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 932892254...
Checkpoint 932892254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,288.54588
Policy Entropy: 3.13990
Value Function Loss: 0.00494

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10661
Policy Update Magnitude: 0.57263
Value Function Update Magnitude: 0.62686

Collected Steps per Second: 22,227.23845
Overall Steps per Second: 10,728.78579

Timestep Collection Time: 2.25003
Timestep Consumption Time: 2.41145
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.66148

Cumulative Model Updates: 111,868
Cumulative Timesteps: 932,942,266

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.64271
Policy Entropy: 3.13891
Value Function Loss: 0.00469

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11242
Policy Update Magnitude: 0.56990
Value Function Update Magnitude: 0.63684

Collected Steps per Second: 22,337.83735
Overall Steps per Second: 10,689.70614

Timestep Collection Time: 2.23952
Timestep Consumption Time: 2.44031
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.67983

Cumulative Model Updates: 111,874
Cumulative Timesteps: 932,992,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 932992292...
Checkpoint 932992292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.17799
Policy Entropy: 3.12477
Value Function Loss: 0.00489

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.57093
Value Function Update Magnitude: 0.63602

Collected Steps per Second: 21,865.37530
Overall Steps per Second: 10,653.98310

Timestep Collection Time: 2.28764
Timestep Consumption Time: 2.40732
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.69496

Cumulative Model Updates: 111,880
Cumulative Timesteps: 933,042,312

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 776.14702
Policy Entropy: 3.12776
Value Function Loss: 0.00495

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.08914
Policy Update Magnitude: 0.58055
Value Function Update Magnitude: 0.63795

Collected Steps per Second: 23,078.88384
Overall Steps per Second: 10,841.22713

Timestep Collection Time: 2.16752
Timestep Consumption Time: 2.44672
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.61424

Cumulative Model Updates: 111,886
Cumulative Timesteps: 933,092,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 933092336...
Checkpoint 933092336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.23094
Policy Entropy: 3.13452
Value Function Loss: 0.00509

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.08781
Policy Update Magnitude: 0.58126
Value Function Update Magnitude: 0.66019

Collected Steps per Second: 22,857.47394
Overall Steps per Second: 10,728.94108

Timestep Collection Time: 2.18852
Timestep Consumption Time: 2.47401
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.66253

Cumulative Model Updates: 111,892
Cumulative Timesteps: 933,142,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837.61486
Policy Entropy: 3.14497
Value Function Loss: 0.00511

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.58986
Value Function Update Magnitude: 0.67888

Collected Steps per Second: 23,027.17658
Overall Steps per Second: 10,787.66084

Timestep Collection Time: 2.17135
Timestep Consumption Time: 2.46358
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.63493

Cumulative Model Updates: 111,898
Cumulative Timesteps: 933,192,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 933192360...
Checkpoint 933192360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,938.40568
Policy Entropy: 3.14501
Value Function Loss: 0.00507

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.59076
Value Function Update Magnitude: 0.67686

Collected Steps per Second: 22,497.74238
Overall Steps per Second: 10,691.38515

Timestep Collection Time: 2.22325
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.67835

Cumulative Model Updates: 111,904
Cumulative Timesteps: 933,242,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,115.58768
Policy Entropy: 3.13817
Value Function Loss: 0.00498

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09796
Policy Update Magnitude: 0.58569
Value Function Update Magnitude: 0.65440

Collected Steps per Second: 23,051.61856
Overall Steps per Second: 10,741.92950

Timestep Collection Time: 2.17061
Timestep Consumption Time: 2.48740
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.65801

Cumulative Model Updates: 111,910
Cumulative Timesteps: 933,292,414

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 933292414...
Checkpoint 933292414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.23450
Policy Entropy: 3.13596
Value Function Loss: 0.00474

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10073
Policy Update Magnitude: 0.57358
Value Function Update Magnitude: 0.63287

Collected Steps per Second: 22,595.47449
Overall Steps per Second: 10,632.20518

Timestep Collection Time: 2.21292
Timestep Consumption Time: 2.48996
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.70288

Cumulative Model Updates: 111,916
Cumulative Timesteps: 933,342,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.12434
Policy Entropy: 3.14128
Value Function Loss: 0.00480

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09873
Policy Update Magnitude: 0.56874
Value Function Update Magnitude: 0.62455

Collected Steps per Second: 23,308.06848
Overall Steps per Second: 10,711.08978

Timestep Collection Time: 2.14638
Timestep Consumption Time: 2.52429
PPO Batch Consumption Time: 0.29496
Total Iteration Time: 4.67067

Cumulative Model Updates: 111,922
Cumulative Timesteps: 933,392,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 933392444...
Checkpoint 933392444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.36378
Policy Entropy: 3.15010
Value Function Loss: 0.00476

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09955
Policy Update Magnitude: 0.56548
Value Function Update Magnitude: 0.60986

Collected Steps per Second: 22,667.57574
Overall Steps per Second: 10,615.78537

Timestep Collection Time: 2.20694
Timestep Consumption Time: 2.50548
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.71242

Cumulative Model Updates: 111,928
Cumulative Timesteps: 933,442,470

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.85698
Policy Entropy: 3.14148
Value Function Loss: 0.00487

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09701
Policy Update Magnitude: 0.56516
Value Function Update Magnitude: 0.61315

Collected Steps per Second: 22,876.19971
Overall Steps per Second: 10,821.16583

Timestep Collection Time: 2.18594
Timestep Consumption Time: 2.43519
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.62113

Cumulative Model Updates: 111,934
Cumulative Timesteps: 933,492,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 933492476...
Checkpoint 933492476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.66711
Policy Entropy: 3.14074
Value Function Loss: 0.00465

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09104
Policy Update Magnitude: 0.57530
Value Function Update Magnitude: 0.62436

Collected Steps per Second: 22,487.83917
Overall Steps per Second: 10,730.39918

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.43692
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.66096

Cumulative Model Updates: 111,940
Cumulative Timesteps: 933,542,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.26456
Policy Entropy: 3.12301
Value Function Loss: 0.00474

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10462
Policy Update Magnitude: 0.57316
Value Function Update Magnitude: 0.63263

Collected Steps per Second: 23,178.99257
Overall Steps per Second: 10,849.38492

Timestep Collection Time: 2.15756
Timestep Consumption Time: 2.45192
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.60948

Cumulative Model Updates: 111,946
Cumulative Timesteps: 933,592,500

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 933592500...
Checkpoint 933592500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,624.55891
Policy Entropy: 3.10975
Value Function Loss: 0.00479

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09551
Policy Update Magnitude: 0.57511
Value Function Update Magnitude: 0.65453

Collected Steps per Second: 22,316.95077
Overall Steps per Second: 10,610.58027

Timestep Collection Time: 2.24072
Timestep Consumption Time: 2.47212
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.71284

Cumulative Model Updates: 111,952
Cumulative Timesteps: 933,642,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.04643
Policy Entropy: 3.09551
Value Function Loss: 0.00467

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.58239
Value Function Update Magnitude: 0.66819

Collected Steps per Second: 23,278.25081
Overall Steps per Second: 10,891.11991

Timestep Collection Time: 2.14887
Timestep Consumption Time: 2.44404
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.59292

Cumulative Model Updates: 111,958
Cumulative Timesteps: 933,692,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 933692528...
Checkpoint 933692528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.32052
Policy Entropy: 3.11887
Value Function Loss: 0.00454

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.58014
Value Function Update Magnitude: 0.67183

Collected Steps per Second: 22,674.82515
Overall Steps per Second: 10,750.05778

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.44693
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.65281

Cumulative Model Updates: 111,964
Cumulative Timesteps: 933,742,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.22558
Policy Entropy: 3.13050
Value Function Loss: 0.00440

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.56072
Value Function Update Magnitude: 0.65327

Collected Steps per Second: 22,915.84046
Overall Steps per Second: 10,792.24234

Timestep Collection Time: 2.18242
Timestep Consumption Time: 2.45165
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.63407

Cumulative Model Updates: 111,970
Cumulative Timesteps: 933,792,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 933792558...
Checkpoint 933792558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.32373
Policy Entropy: 3.13269
Value Function Loss: 0.00452

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.55624
Value Function Update Magnitude: 0.64027

Collected Steps per Second: 22,669.17293
Overall Steps per Second: 10,768.86630

Timestep Collection Time: 2.20573
Timestep Consumption Time: 2.43747
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.64320

Cumulative Model Updates: 111,976
Cumulative Timesteps: 933,842,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.03284
Policy Entropy: 3.14370
Value Function Loss: 0.00471

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.12214
Policy Update Magnitude: 0.56269
Value Function Update Magnitude: 0.64665

Collected Steps per Second: 22,947.96856
Overall Steps per Second: 10,828.88369

Timestep Collection Time: 2.17884
Timestep Consumption Time: 2.43844
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.61728

Cumulative Model Updates: 111,982
Cumulative Timesteps: 933,892,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 933892560...
Checkpoint 933892560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.34516
Policy Entropy: 3.13895
Value Function Loss: 0.00485

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.56789
Value Function Update Magnitude: 0.65306

Collected Steps per Second: 22,903.84587
Overall Steps per Second: 10,712.37692

Timestep Collection Time: 2.18470
Timestep Consumption Time: 2.48635
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.67105

Cumulative Model Updates: 111,988
Cumulative Timesteps: 933,942,598

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,881.05903
Policy Entropy: 3.15428
Value Function Loss: 0.00511

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.08829
Policy Update Magnitude: 0.56582
Value Function Update Magnitude: 0.65427

Collected Steps per Second: 23,111.06462
Overall Steps per Second: 10,829.85637

Timestep Collection Time: 2.16416
Timestep Consumption Time: 2.45419
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.61834

Cumulative Model Updates: 111,994
Cumulative Timesteps: 933,992,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 933992614...
Checkpoint 933992614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.28380
Policy Entropy: 3.13394
Value Function Loss: 0.00502

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09424
Policy Update Magnitude: 0.57137
Value Function Update Magnitude: 0.65767

Collected Steps per Second: 21,885.78696
Overall Steps per Second: 10,736.09280

Timestep Collection Time: 2.28578
Timestep Consumption Time: 2.37383
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.65961

Cumulative Model Updates: 112,000
Cumulative Timesteps: 934,042,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.36963
Policy Entropy: 3.14078
Value Function Loss: 0.00501

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.65260

Collected Steps per Second: 21,721.56873
Overall Steps per Second: 10,564.75566

Timestep Collection Time: 2.30269
Timestep Consumption Time: 2.43173
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.73442

Cumulative Model Updates: 112,006
Cumulative Timesteps: 934,092,658

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 934092658...
Checkpoint 934092658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.71700
Policy Entropy: 3.13766
Value Function Loss: 0.00469

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09461
Policy Update Magnitude: 0.57259
Value Function Update Magnitude: 0.65305

Collected Steps per Second: 22,107.30536
Overall Steps per Second: 10,650.32368

Timestep Collection Time: 2.26314
Timestep Consumption Time: 2.43455
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.69770

Cumulative Model Updates: 112,012
Cumulative Timesteps: 934,142,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,911.29722
Policy Entropy: 3.14160
Value Function Loss: 0.00455

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.56659
Value Function Update Magnitude: 0.65274

Collected Steps per Second: 22,469.48692
Overall Steps per Second: 10,780.36708

Timestep Collection Time: 2.22569
Timestep Consumption Time: 2.41330
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.63899

Cumulative Model Updates: 112,018
Cumulative Timesteps: 934,192,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 934192700...
Checkpoint 934192700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 823.41346
Policy Entropy: 3.13890
Value Function Loss: 0.00474

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09310
Policy Update Magnitude: 0.56636
Value Function Update Magnitude: 0.64578

Collected Steps per Second: 22,693.04191
Overall Steps per Second: 10,603.35547

Timestep Collection Time: 2.20455
Timestep Consumption Time: 2.51358
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.71813

Cumulative Model Updates: 112,024
Cumulative Timesteps: 934,242,728

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.83954
Policy Entropy: 3.13055
Value Function Loss: 0.00476

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.57978
Value Function Update Magnitude: 0.63719

Collected Steps per Second: 23,395.19684
Overall Steps per Second: 10,863.40530

Timestep Collection Time: 2.13805
Timestep Consumption Time: 2.46640
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.60445

Cumulative Model Updates: 112,030
Cumulative Timesteps: 934,292,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 934292748...
Checkpoint 934292748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.82692
Policy Entropy: 3.12687
Value Function Loss: 0.00483

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.58741
Value Function Update Magnitude: 0.63005

Collected Steps per Second: 22,742.60745
Overall Steps per Second: 10,730.77247

Timestep Collection Time: 2.19852
Timestep Consumption Time: 2.46098
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.65950

Cumulative Model Updates: 112,036
Cumulative Timesteps: 934,342,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 772.76133
Policy Entropy: 3.12487
Value Function Loss: 0.00473

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.57375
Value Function Update Magnitude: 0.61313

Collected Steps per Second: 23,164.30907
Overall Steps per Second: 10,804.55071

Timestep Collection Time: 2.15970
Timestep Consumption Time: 2.47057
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.63027

Cumulative Model Updates: 112,042
Cumulative Timesteps: 934,392,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 934392776...
Checkpoint 934392776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.23915
Policy Entropy: 3.13924
Value Function Loss: 0.00475

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.56406
Value Function Update Magnitude: 0.59500

Collected Steps per Second: 22,598.39225
Overall Steps per Second: 10,782.64053

Timestep Collection Time: 2.21352
Timestep Consumption Time: 2.42560
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.63912

Cumulative Model Updates: 112,048
Cumulative Timesteps: 934,442,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.58865
Policy Entropy: 3.13163
Value Function Loss: 0.00501

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09490
Policy Update Magnitude: 0.56662
Value Function Update Magnitude: 0.59346

Collected Steps per Second: 23,144.30791
Overall Steps per Second: 10,881.01867

Timestep Collection Time: 2.16036
Timestep Consumption Time: 2.43480
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.59516

Cumulative Model Updates: 112,054
Cumulative Timesteps: 934,492,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 934492798...
Checkpoint 934492798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.90003
Policy Entropy: 3.14110
Value Function Loss: 0.00473

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.09148
Policy Update Magnitude: 0.56973
Value Function Update Magnitude: 0.60577

Collected Steps per Second: 22,862.64386
Overall Steps per Second: 10,645.24340

Timestep Collection Time: 2.18724
Timestep Consumption Time: 2.51026
PPO Batch Consumption Time: 0.29590
Total Iteration Time: 4.69750

Cumulative Model Updates: 112,060
Cumulative Timesteps: 934,542,804

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.86140
Policy Entropy: 3.13832
Value Function Loss: 0.00476

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10368
Policy Update Magnitude: 0.57218
Value Function Update Magnitude: 0.62013

Collected Steps per Second: 22,843.70359
Overall Steps per Second: 10,763.62424

Timestep Collection Time: 2.18957
Timestep Consumption Time: 2.45737
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.64695

Cumulative Model Updates: 112,066
Cumulative Timesteps: 934,592,822

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 934592822...
Checkpoint 934592822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.00200
Policy Entropy: 3.14448
Value Function Loss: 0.00455

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.56932
Value Function Update Magnitude: 0.62016

Collected Steps per Second: 22,247.85116
Overall Steps per Second: 10,632.58301

Timestep Collection Time: 2.24885
Timestep Consumption Time: 2.45669
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.70554

Cumulative Model Updates: 112,072
Cumulative Timesteps: 934,642,854

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 931.53945
Policy Entropy: 3.14100
Value Function Loss: 0.00473

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.56712
Value Function Update Magnitude: 0.61455

Collected Steps per Second: 22,067.06519
Overall Steps per Second: 10,625.15476

Timestep Collection Time: 2.26691
Timestep Consumption Time: 2.44116
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.70807

Cumulative Model Updates: 112,078
Cumulative Timesteps: 934,692,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 934692878...
Checkpoint 934692878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 876.27596
Policy Entropy: 3.14891
Value Function Loss: 0.00489

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09572
Policy Update Magnitude: 0.57407
Value Function Update Magnitude: 0.62241

Collected Steps per Second: 22,116.77007
Overall Steps per Second: 10,623.40493

Timestep Collection Time: 2.26154
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.29641
Total Iteration Time: 4.70828

Cumulative Model Updates: 112,084
Cumulative Timesteps: 934,742,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095.94888
Policy Entropy: 3.14925
Value Function Loss: 0.00490

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.58093
Value Function Update Magnitude: 0.62140

Collected Steps per Second: 22,429.01798
Overall Steps per Second: 10,885.72593

Timestep Collection Time: 2.22979
Timestep Consumption Time: 2.36448
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.59427

Cumulative Model Updates: 112,090
Cumulative Timesteps: 934,792,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 934792908...
Checkpoint 934792908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.32715
Policy Entropy: 3.14344
Value Function Loss: 0.00506

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.58223
Value Function Update Magnitude: 0.64448

Collected Steps per Second: 22,642.98369
Overall Steps per Second: 10,601.28677

Timestep Collection Time: 2.20898
Timestep Consumption Time: 2.50912
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.71811

Cumulative Model Updates: 112,096
Cumulative Timesteps: 934,842,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.90748
Policy Entropy: 3.14735
Value Function Loss: 0.00516

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.58947
Value Function Update Magnitude: 0.67848

Collected Steps per Second: 23,289.06186
Overall Steps per Second: 10,861.04949

Timestep Collection Time: 2.14813
Timestep Consumption Time: 2.45805
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.60618

Cumulative Model Updates: 112,102
Cumulative Timesteps: 934,892,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 934892954...
Checkpoint 934892954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.11593
Policy Entropy: 3.15262
Value Function Loss: 0.00534

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10183
Policy Update Magnitude: 0.58786
Value Function Update Magnitude: 0.68236

Collected Steps per Second: 22,724.56018
Overall Steps per Second: 10,719.30047

Timestep Collection Time: 2.20105
Timestep Consumption Time: 2.46511
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.66616

Cumulative Model Updates: 112,108
Cumulative Timesteps: 934,942,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,438.28161
Policy Entropy: 3.15725
Value Function Loss: 0.00543

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10341
Policy Update Magnitude: 0.58596
Value Function Update Magnitude: 0.67347

Collected Steps per Second: 23,390.39633
Overall Steps per Second: 10,882.71361

Timestep Collection Time: 2.13848
Timestep Consumption Time: 2.45780
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.59628

Cumulative Model Updates: 112,114
Cumulative Timesteps: 934,992,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 934992992...
Checkpoint 934992992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 947.11411
Policy Entropy: 3.16320
Value Function Loss: 0.00512

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10379
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.68013

Collected Steps per Second: 22,413.04188
Overall Steps per Second: 10,701.92400

Timestep Collection Time: 2.23084
Timestep Consumption Time: 2.44121
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.67206

Cumulative Model Updates: 112,120
Cumulative Timesteps: 935,042,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.62530
Policy Entropy: 3.16556
Value Function Loss: 0.00476

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.57265
Value Function Update Magnitude: 0.65900

Collected Steps per Second: 23,106.62050
Overall Steps per Second: 10,819.41343

Timestep Collection Time: 2.16483
Timestep Consumption Time: 2.45852
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.62336

Cumulative Model Updates: 112,126
Cumulative Timesteps: 935,093,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 935093014...
Checkpoint 935093014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,529.32691
Policy Entropy: 3.16224
Value Function Loss: 0.00453

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.56837
Value Function Update Magnitude: 0.63157

Collected Steps per Second: 22,773.77783
Overall Steps per Second: 10,663.30263

Timestep Collection Time: 2.19595
Timestep Consumption Time: 2.49397
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.68992

Cumulative Model Updates: 112,132
Cumulative Timesteps: 935,143,024

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 949.19281
Policy Entropy: 3.14933
Value Function Loss: 0.00498

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10631
Policy Update Magnitude: 0.57534
Value Function Update Magnitude: 0.61936

Collected Steps per Second: 23,138.30945
Overall Steps per Second: 10,832.74708

Timestep Collection Time: 2.16196
Timestep Consumption Time: 2.45589
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.61785

Cumulative Model Updates: 112,138
Cumulative Timesteps: 935,193,048

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 935193048...
Checkpoint 935193048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,938.72613
Policy Entropy: 3.13758
Value Function Loss: 0.00512

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.11990
Policy Update Magnitude: 0.58377
Value Function Update Magnitude: 0.63046

Collected Steps per Second: 22,618.95934
Overall Steps per Second: 10,703.65353

Timestep Collection Time: 2.21160
Timestep Consumption Time: 2.46195
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.67354

Cumulative Model Updates: 112,144
Cumulative Timesteps: 935,243,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.25953
Policy Entropy: 3.13618
Value Function Loss: 0.00509

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.63402

Collected Steps per Second: 23,211.95402
Overall Steps per Second: 10,893.99728

Timestep Collection Time: 2.15501
Timestep Consumption Time: 2.43669
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.59170

Cumulative Model Updates: 112,150
Cumulative Timesteps: 935,293,094

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 935293094...
Checkpoint 935293094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.90401
Policy Entropy: 3.13788
Value Function Loss: 0.00518

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11917
Policy Update Magnitude: 0.58235
Value Function Update Magnitude: 0.64606

Collected Steps per Second: 22,757.30366
Overall Steps per Second: 10,717.50240

Timestep Collection Time: 2.19842
Timestep Consumption Time: 2.46965
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.66807

Cumulative Model Updates: 112,156
Cumulative Timesteps: 935,343,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.02713
Policy Entropy: 3.14189
Value Function Loss: 0.00500

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.66295

Collected Steps per Second: 22,960.86338
Overall Steps per Second: 10,825.74533

Timestep Collection Time: 2.17832
Timestep Consumption Time: 2.44178
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.62010

Cumulative Model Updates: 112,162
Cumulative Timesteps: 935,393,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 935393140...
Checkpoint 935393140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.75532
Policy Entropy: 3.14512
Value Function Loss: 0.00504

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.58569
Value Function Update Magnitude: 0.67121

Collected Steps per Second: 22,575.76551
Overall Steps per Second: 10,744.88405

Timestep Collection Time: 2.21592
Timestep Consumption Time: 2.43988
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.65580

Cumulative Model Updates: 112,168
Cumulative Timesteps: 935,443,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844.21863
Policy Entropy: 3.14774
Value Function Loss: 0.00500

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09866
Policy Update Magnitude: 0.60602
Value Function Update Magnitude: 0.64655

Collected Steps per Second: 23,062.68383
Overall Steps per Second: 10,807.31345

Timestep Collection Time: 2.16844
Timestep Consumption Time: 2.45898
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.62742

Cumulative Model Updates: 112,174
Cumulative Timesteps: 935,493,176

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 935493176...
Checkpoint 935493176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 801.82199
Policy Entropy: 3.15919
Value Function Loss: 0.00483

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.08751
Policy Update Magnitude: 0.59073
Value Function Update Magnitude: 0.63849

Collected Steps per Second: 22,835.23097
Overall Steps per Second: 10,731.36647

Timestep Collection Time: 2.18986
Timestep Consumption Time: 2.46994
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.65980

Cumulative Model Updates: 112,180
Cumulative Timesteps: 935,543,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.89461
Policy Entropy: 3.15372
Value Function Loss: 0.00482

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.08808
Policy Update Magnitude: 0.58355
Value Function Update Magnitude: 0.63250

Collected Steps per Second: 23,159.46415
Overall Steps per Second: 10,823.09916

Timestep Collection Time: 2.16119
Timestep Consumption Time: 2.46336
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.62455

Cumulative Model Updates: 112,186
Cumulative Timesteps: 935,593,234

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 935593234...
Checkpoint 935593234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.06090
Policy Entropy: 3.14142
Value Function Loss: 0.00477

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08622
Policy Update Magnitude: 0.58221
Value Function Update Magnitude: 0.62910

Collected Steps per Second: 22,246.46602
Overall Steps per Second: 10,649.76832

Timestep Collection Time: 2.24800
Timestep Consumption Time: 2.44788
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.69588

Cumulative Model Updates: 112,192
Cumulative Timesteps: 935,643,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 942.62226
Policy Entropy: 3.14477
Value Function Loss: 0.00495

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09014
Policy Update Magnitude: 0.58285
Value Function Update Magnitude: 0.63501

Collected Steps per Second: 22,936.26062
Overall Steps per Second: 10,670.03792

Timestep Collection Time: 2.18004
Timestep Consumption Time: 2.50616
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.68621

Cumulative Model Updates: 112,198
Cumulative Timesteps: 935,693,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 935693246...
Checkpoint 935693246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.12139
Policy Entropy: 3.15430
Value Function Loss: 0.00506

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.57739
Value Function Update Magnitude: 0.63719

Collected Steps per Second: 23,009.05993
Overall Steps per Second: 10,854.34563

Timestep Collection Time: 2.17401
Timestep Consumption Time: 2.43446
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.60848

Cumulative Model Updates: 112,204
Cumulative Timesteps: 935,743,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,501.96179
Policy Entropy: 3.16767
Value Function Loss: 0.00506

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10038
Policy Update Magnitude: 0.57279
Value Function Update Magnitude: 0.62979

Collected Steps per Second: 22,271.81310
Overall Steps per Second: 10,696.04094

Timestep Collection Time: 2.24580
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.67631

Cumulative Model Updates: 112,210
Cumulative Timesteps: 935,793,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 935793286...
Checkpoint 935793286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.70003
Policy Entropy: 3.16476
Value Function Loss: 0.00519

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.58025
Value Function Update Magnitude: 0.63414

Collected Steps per Second: 22,897.78469
Overall Steps per Second: 10,677.66681

Timestep Collection Time: 2.18449
Timestep Consumption Time: 2.50005
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.68454

Cumulative Model Updates: 112,216
Cumulative Timesteps: 935,843,306

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,702.87735
Policy Entropy: 3.15539
Value Function Loss: 0.00514

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.58248
Value Function Update Magnitude: 0.63787

Collected Steps per Second: 22,985.20750
Overall Steps per Second: 10,708.90877

Timestep Collection Time: 2.17531
Timestep Consumption Time: 2.49370
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.66901

Cumulative Model Updates: 112,222
Cumulative Timesteps: 935,893,306

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 935893306...
Checkpoint 935893306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 920.50798
Policy Entropy: 3.15584
Value Function Loss: 0.00504

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.58186
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 22,841.81422
Overall Steps per Second: 10,612.57280

Timestep Collection Time: 2.18914
Timestep Consumption Time: 2.52263
PPO Batch Consumption Time: 0.29615
Total Iteration Time: 4.71177

Cumulative Model Updates: 112,228
Cumulative Timesteps: 935,943,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.19724
Policy Entropy: 3.15008
Value Function Loss: 0.00481

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09534
Policy Update Magnitude: 0.57377
Value Function Update Magnitude: 0.61696

Collected Steps per Second: 23,400.63933
Overall Steps per Second: 10,933.29998

Timestep Collection Time: 2.13738
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.57465

Cumulative Model Updates: 112,234
Cumulative Timesteps: 935,993,326

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 935993326...
Checkpoint 935993326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.92199
Policy Entropy: 3.15856
Value Function Loss: 0.00451

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.56367
Value Function Update Magnitude: 0.60330

Collected Steps per Second: 21,898.58489
Overall Steps per Second: 10,613.86062

Timestep Collection Time: 2.28398
Timestep Consumption Time: 2.42835
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.71233

Cumulative Model Updates: 112,240
Cumulative Timesteps: 936,043,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,543.05710
Policy Entropy: 3.16462
Value Function Loss: 0.00429

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.58309

Collected Steps per Second: 23,115.15761
Overall Steps per Second: 10,856.57387

Timestep Collection Time: 2.16343
Timestep Consumption Time: 2.44281
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.60624

Cumulative Model Updates: 112,246
Cumulative Timesteps: 936,093,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 936093350...
Checkpoint 936093350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 776.39935
Policy Entropy: 3.16318
Value Function Loss: 0.00439

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.56167
Value Function Update Magnitude: 0.56697

Collected Steps per Second: 22,695.64007
Overall Steps per Second: 10,720.19734

Timestep Collection Time: 2.20342
Timestep Consumption Time: 2.46142
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.66484

Cumulative Model Updates: 112,252
Cumulative Timesteps: 936,143,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 768.61929
Policy Entropy: 3.14939
Value Function Loss: 0.00463

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09263
Policy Update Magnitude: 0.57006
Value Function Update Magnitude: 0.59731

Collected Steps per Second: 23,350.40161
Overall Steps per Second: 10,919.23671

Timestep Collection Time: 2.14163
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.57981

Cumulative Model Updates: 112,258
Cumulative Timesteps: 936,193,366

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 936193366...
Checkpoint 936193366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.97921
Policy Entropy: 3.14166
Value Function Loss: 0.00481

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09260
Policy Update Magnitude: 0.57620
Value Function Update Magnitude: 0.60546

Collected Steps per Second: 22,603.59787
Overall Steps per Second: 10,634.92257

Timestep Collection Time: 2.21266
Timestep Consumption Time: 2.49015
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.70281

Cumulative Model Updates: 112,264
Cumulative Timesteps: 936,243,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,829.51657
Policy Entropy: 3.13913
Value Function Loss: 0.00496

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09364
Policy Update Magnitude: 0.57925
Value Function Update Magnitude: 0.58879

Collected Steps per Second: 22,905.57173
Overall Steps per Second: 10,779.00772

Timestep Collection Time: 2.18401
Timestep Consumption Time: 2.45705
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.64106

Cumulative Model Updates: 112,270
Cumulative Timesteps: 936,293,406

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 936293406...
Checkpoint 936293406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.86728
Policy Entropy: 3.14739
Value Function Loss: 0.00492

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.58122
Value Function Update Magnitude: 0.56894

Collected Steps per Second: 22,603.76516
Overall Steps per Second: 10,753.28751

Timestep Collection Time: 2.21229
Timestep Consumption Time: 2.43801
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.65030

Cumulative Model Updates: 112,276
Cumulative Timesteps: 936,343,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.34162
Policy Entropy: 3.13934
Value Function Loss: 0.00485

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.57367
Value Function Update Magnitude: 0.55673

Collected Steps per Second: 22,386.44159
Overall Steps per Second: 10,482.46465

Timestep Collection Time: 2.23358
Timestep Consumption Time: 2.53648
PPO Batch Consumption Time: 0.29655
Total Iteration Time: 4.77006

Cumulative Model Updates: 112,282
Cumulative Timesteps: 936,393,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 936393414...
Checkpoint 936393414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476.07996
Policy Entropy: 3.14470
Value Function Loss: 0.00457

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.09684
Policy Update Magnitude: 0.56460
Value Function Update Magnitude: 0.55669

Collected Steps per Second: 21,918.01905
Overall Steps per Second: 10,559.50625

Timestep Collection Time: 2.28187
Timestep Consumption Time: 2.45453
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.73640

Cumulative Model Updates: 112,288
Cumulative Timesteps: 936,443,428

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 866.13594
Policy Entropy: 3.14595
Value Function Loss: 0.00460

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.56417
Value Function Update Magnitude: 0.55526

Collected Steps per Second: 23,110.28721
Overall Steps per Second: 10,729.50601

Timestep Collection Time: 2.16423
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.66154

Cumulative Model Updates: 112,294
Cumulative Timesteps: 936,493,444

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 936493444...
Checkpoint 936493444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782.16272
Policy Entropy: 3.14967
Value Function Loss: 0.00469

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.56557
Value Function Update Magnitude: 0.56371

Collected Steps per Second: 22,271.77443
Overall Steps per Second: 10,821.66590

Timestep Collection Time: 2.24553
Timestep Consumption Time: 2.37594
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.62147

Cumulative Model Updates: 112,300
Cumulative Timesteps: 936,543,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,505.77328
Policy Entropy: 3.14926
Value Function Loss: 0.00503

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.57790
Value Function Update Magnitude: 0.56555

Collected Steps per Second: 23,031.13618
Overall Steps per Second: 10,718.68130

Timestep Collection Time: 2.17210
Timestep Consumption Time: 2.49508
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.66718

Cumulative Model Updates: 112,306
Cumulative Timesteps: 936,593,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 936593482...
Checkpoint 936593482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,177.60715
Policy Entropy: 3.14111
Value Function Loss: 0.00493

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09427
Policy Update Magnitude: 0.58640
Value Function Update Magnitude: 0.57644

Collected Steps per Second: 22,913.42772
Overall Steps per Second: 10,791.44598

Timestep Collection Time: 2.18326
Timestep Consumption Time: 2.45245
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.63571

Cumulative Model Updates: 112,312
Cumulative Timesteps: 936,643,508

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 697.73734
Policy Entropy: 3.13009
Value Function Loss: 0.00511

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 0.58184
Value Function Update Magnitude: 0.59588

Collected Steps per Second: 23,143.35738
Overall Steps per Second: 10,754.45208

Timestep Collection Time: 2.16079
Timestep Consumption Time: 2.48919
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.64998

Cumulative Model Updates: 112,318
Cumulative Timesteps: 936,693,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 936693516...
Checkpoint 936693516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 828.59694
Policy Entropy: 3.12914
Value Function Loss: 0.00511

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.13600
Policy Update Magnitude: 0.58299
Value Function Update Magnitude: 0.61258

Collected Steps per Second: 22,828.36621
Overall Steps per Second: 10,788.10188

Timestep Collection Time: 2.19122
Timestep Consumption Time: 2.44555
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.63677

Cumulative Model Updates: 112,324
Cumulative Timesteps: 936,743,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.36343
Policy Entropy: 3.12563
Value Function Loss: 0.00516

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.12533
Policy Update Magnitude: 0.58813
Value Function Update Magnitude: 0.61637

Collected Steps per Second: 23,495.20632
Overall Steps per Second: 10,901.79960

Timestep Collection Time: 2.12818
Timestep Consumption Time: 2.45840
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.58658

Cumulative Model Updates: 112,330
Cumulative Timesteps: 936,793,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 936793540...
Checkpoint 936793540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.80147
Policy Entropy: 3.12962
Value Function Loss: 0.00521

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.58905
Value Function Update Magnitude: 0.59464

Collected Steps per Second: 22,526.15772
Overall Steps per Second: 10,780.56995

Timestep Collection Time: 2.22053
Timestep Consumption Time: 2.41930
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.63983

Cumulative Model Updates: 112,336
Cumulative Timesteps: 936,843,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 853.13584
Policy Entropy: 3.14218
Value Function Loss: 0.00523

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10855
Policy Update Magnitude: 0.59378
Value Function Update Magnitude: 0.59607

Collected Steps per Second: 23,185.20609
Overall Steps per Second: 10,847.96887

Timestep Collection Time: 2.15672
Timestep Consumption Time: 2.45281
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.60953

Cumulative Model Updates: 112,342
Cumulative Timesteps: 936,893,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 936893564...
Checkpoint 936893564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 987.18498
Policy Entropy: 3.12150
Value Function Loss: 0.00525

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.59490
Value Function Update Magnitude: 0.61783

Collected Steps per Second: 22,958.15660
Overall Steps per Second: 10,659.68936

Timestep Collection Time: 2.17901
Timestep Consumption Time: 2.51400
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.69301

Cumulative Model Updates: 112,348
Cumulative Timesteps: 936,943,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.41696
Policy Entropy: 3.11619
Value Function Loss: 0.00531

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.60077
Value Function Update Magnitude: 0.61564

Collected Steps per Second: 22,672.69549
Overall Steps per Second: 10,602.25731

Timestep Collection Time: 2.20609
Timestep Consumption Time: 2.51158
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.71767

Cumulative Model Updates: 112,354
Cumulative Timesteps: 936,993,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 936993608...
Checkpoint 936993608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,654.93848
Policy Entropy: 3.11340
Value Function Loss: 0.00509

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11583
Policy Update Magnitude: 0.59637
Value Function Update Magnitude: 0.60317

Collected Steps per Second: 22,164.60609
Overall Steps per Second: 10,679.99461

Timestep Collection Time: 2.25612
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.68221

Cumulative Model Updates: 112,360
Cumulative Timesteps: 937,043,614

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.53073
Policy Entropy: 3.12984
Value Function Loss: 0.00503

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.59115
Value Function Update Magnitude: 0.60282

Collected Steps per Second: 23,218.19070
Overall Steps per Second: 10,726.94527

Timestep Collection Time: 2.15435
Timestep Consumption Time: 2.50868
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.66302

Cumulative Model Updates: 112,366
Cumulative Timesteps: 937,093,634

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 937093634...
Checkpoint 937093634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 832.59138
Policy Entropy: 3.14495
Value Function Loss: 0.00487

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10594
Policy Update Magnitude: 0.58205
Value Function Update Magnitude: 0.59365

Collected Steps per Second: 22,902.89188
Overall Steps per Second: 10,632.91655

Timestep Collection Time: 2.18444
Timestep Consumption Time: 2.52076
PPO Batch Consumption Time: 0.29569
Total Iteration Time: 4.70520

Cumulative Model Updates: 112,372
Cumulative Timesteps: 937,143,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,139.30272
Policy Entropy: 3.15095
Value Function Loss: 0.00498

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.57725
Value Function Update Magnitude: 0.58495

Collected Steps per Second: 21,956.34937
Overall Steps per Second: 10,628.74105

Timestep Collection Time: 2.27725
Timestep Consumption Time: 2.42698
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.70423

Cumulative Model Updates: 112,378
Cumulative Timesteps: 937,193,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 937193664...
Checkpoint 937193664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.42132
Policy Entropy: 3.13888
Value Function Loss: 0.00489

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10171
Policy Update Magnitude: 0.57321
Value Function Update Magnitude: 0.57784

Collected Steps per Second: 22,782.20165
Overall Steps per Second: 10,776.23413

Timestep Collection Time: 2.19470
Timestep Consumption Time: 2.44514
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.63984

Cumulative Model Updates: 112,384
Cumulative Timesteps: 937,243,664

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.04842
Policy Entropy: 3.13846
Value Function Loss: 0.00483

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09410
Policy Update Magnitude: 0.57079
Value Function Update Magnitude: 0.57365

Collected Steps per Second: 23,070.55790
Overall Steps per Second: 10,677.42832

Timestep Collection Time: 2.16865
Timestep Consumption Time: 2.51712
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.68577

Cumulative Model Updates: 112,390
Cumulative Timesteps: 937,293,696

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 937293696...
Checkpoint 937293696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 768.81400
Policy Entropy: 3.14471
Value Function Loss: 0.00499

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.57343
Value Function Update Magnitude: 0.58186

Collected Steps per Second: 22,100.67123
Overall Steps per Second: 10,657.31534

Timestep Collection Time: 2.26283
Timestep Consumption Time: 2.42972
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.69255

Cumulative Model Updates: 112,396
Cumulative Timesteps: 937,343,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.14757
Policy Entropy: 3.14400
Value Function Loss: 0.00489

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.57571
Value Function Update Magnitude: 0.60425

Collected Steps per Second: 22,622.95110
Overall Steps per Second: 10,768.82497

Timestep Collection Time: 2.21014
Timestep Consumption Time: 2.43289
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.64303

Cumulative Model Updates: 112,402
Cumulative Timesteps: 937,393,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 937393706...
Checkpoint 937393706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 980.91160
Policy Entropy: 3.14348
Value Function Loss: 0.00505

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.08943
Policy Update Magnitude: 0.58090
Value Function Update Magnitude: 0.60832

Collected Steps per Second: 21,709.55873
Overall Steps per Second: 10,637.21563

Timestep Collection Time: 2.30369
Timestep Consumption Time: 2.39792
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.70161

Cumulative Model Updates: 112,408
Cumulative Timesteps: 937,443,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.90109
Policy Entropy: 3.14721
Value Function Loss: 0.00508

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.58539
Value Function Update Magnitude: 0.61173

Collected Steps per Second: 23,011.94843
Overall Steps per Second: 10,835.81418

Timestep Collection Time: 2.17287
Timestep Consumption Time: 2.44164
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.61451

Cumulative Model Updates: 112,414
Cumulative Timesteps: 937,493,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 937493720...
Checkpoint 937493720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 902.15037
Policy Entropy: 3.15033
Value Function Loss: 0.00509

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10148
Policy Update Magnitude: 0.58361
Value Function Update Magnitude: 0.60935

Collected Steps per Second: 22,707.20552
Overall Steps per Second: 10,779.55352

Timestep Collection Time: 2.20283
Timestep Consumption Time: 2.43744
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.64027

Cumulative Model Updates: 112,420
Cumulative Timesteps: 937,543,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.21866
Policy Entropy: 3.14638
Value Function Loss: 0.00516

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.59827

Collected Steps per Second: 23,091.62752
Overall Steps per Second: 10,810.32370

Timestep Collection Time: 2.16633
Timestep Consumption Time: 2.46110
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.62743

Cumulative Model Updates: 112,426
Cumulative Timesteps: 937,593,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 937593764...
Checkpoint 937593764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,030.90732
Policy Entropy: 3.15490
Value Function Loss: 0.00523

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11041
Policy Update Magnitude: 0.57913
Value Function Update Magnitude: 0.59961

Collected Steps per Second: 22,762.83241
Overall Steps per Second: 10,709.58999

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.47294
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.67021

Cumulative Model Updates: 112,432
Cumulative Timesteps: 937,643,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.21335
Policy Entropy: 3.14802
Value Function Loss: 0.00508

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.57596
Value Function Update Magnitude: 0.59443

Collected Steps per Second: 23,208.43349
Overall Steps per Second: 10,874.60423

Timestep Collection Time: 2.15568
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.60063

Cumulative Model Updates: 112,438
Cumulative Timesteps: 937,693,810

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 937693810...
Checkpoint 937693810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.16142
Policy Entropy: 3.15881
Value Function Loss: 0.00506

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12157
Policy Update Magnitude: 0.57752
Value Function Update Magnitude: 0.58333

Collected Steps per Second: 22,974.47224
Overall Steps per Second: 10,685.56526

Timestep Collection Time: 2.17755
Timestep Consumption Time: 2.50428
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.68183

Cumulative Model Updates: 112,444
Cumulative Timesteps: 937,743,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,258.81525
Policy Entropy: 3.14860
Value Function Loss: 0.00503

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.57534
Value Function Update Magnitude: 0.59032

Collected Steps per Second: 22,946.27848
Overall Steps per Second: 10,807.31046

Timestep Collection Time: 2.17961
Timestep Consumption Time: 2.44818
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.62779

Cumulative Model Updates: 112,450
Cumulative Timesteps: 937,793,852

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 937793852...
Checkpoint 937793852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 992.68884
Policy Entropy: 3.14748
Value Function Loss: 0.00541

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.14301
Policy Update Magnitude: 0.59216
Value Function Update Magnitude: 0.60573

Collected Steps per Second: 22,434.01077
Overall Steps per Second: 10,677.47296

Timestep Collection Time: 2.22920
Timestep Consumption Time: 2.45449
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.68369

Cumulative Model Updates: 112,456
Cumulative Timesteps: 937,843,862

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.89603
Policy Entropy: 3.12566
Value Function Loss: 0.00555

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.60411
Value Function Update Magnitude: 0.61528

Collected Steps per Second: 23,145.16202
Overall Steps per Second: 10,861.64488

Timestep Collection Time: 2.16045
Timestep Consumption Time: 2.44327
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.60372

Cumulative Model Updates: 112,462
Cumulative Timesteps: 937,893,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 937893866...
Checkpoint 937893866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.22231
Policy Entropy: 3.11966
Value Function Loss: 0.00558

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11582
Policy Update Magnitude: 0.60728
Value Function Update Magnitude: 0.60440

Collected Steps per Second: 22,493.07111
Overall Steps per Second: 10,670.31488

Timestep Collection Time: 2.22308
Timestep Consumption Time: 2.46319
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.68627

Cumulative Model Updates: 112,468
Cumulative Timesteps: 937,943,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.35327
Policy Entropy: 3.09813
Value Function Loss: 0.00533

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11641
Policy Update Magnitude: 0.59829
Value Function Update Magnitude: 0.59261

Collected Steps per Second: 23,468.66624
Overall Steps per Second: 10,900.37080

Timestep Collection Time: 2.13144
Timestep Consumption Time: 2.45758
PPO Batch Consumption Time: 0.28362
Total Iteration Time: 4.58902

Cumulative Model Updates: 112,474
Cumulative Timesteps: 937,993,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 937993892...
Checkpoint 937993892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.01659
Policy Entropy: 3.09543
Value Function Loss: 0.00535

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10915
Policy Update Magnitude: 0.60147
Value Function Update Magnitude: 0.60099

Collected Steps per Second: 22,557.94058
Overall Steps per Second: 10,750.50727

Timestep Collection Time: 2.21740
Timestep Consumption Time: 2.43540
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.65280

Cumulative Model Updates: 112,480
Cumulative Timesteps: 938,043,912

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 973.11821
Policy Entropy: 3.11495
Value Function Loss: 0.00509

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11437
Policy Update Magnitude: 0.60577
Value Function Update Magnitude: 0.60895

Collected Steps per Second: 23,210.41483
Overall Steps per Second: 10,860.18696

Timestep Collection Time: 2.15464
Timestep Consumption Time: 2.45026
PPO Batch Consumption Time: 0.28228
Total Iteration Time: 4.60489

Cumulative Model Updates: 112,486
Cumulative Timesteps: 938,093,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 938093922...
Checkpoint 938093922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.66050
Policy Entropy: 3.13483
Value Function Loss: 0.00506

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.60022
Value Function Update Magnitude: 0.59318

Collected Steps per Second: 22,645.75232
Overall Steps per Second: 10,684.15315

Timestep Collection Time: 2.20907
Timestep Consumption Time: 2.47319
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.68226

Cumulative Model Updates: 112,492
Cumulative Timesteps: 938,143,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,304.11212
Policy Entropy: 3.14345
Value Function Loss: 0.00504

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.59431
Value Function Update Magnitude: 0.59548

Collected Steps per Second: 23,007.53780
Overall Steps per Second: 10,795.71266

Timestep Collection Time: 2.17407
Timestep Consumption Time: 2.45925
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.63332

Cumulative Model Updates: 112,498
Cumulative Timesteps: 938,193,968

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 938193968...
Checkpoint 938193968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,385.02077
Policy Entropy: 3.13560
Value Function Loss: 0.00472

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.58823
Value Function Update Magnitude: 0.59398

Collected Steps per Second: 22,378.69742
Overall Steps per Second: 10,677.36774

Timestep Collection Time: 2.23507
Timestep Consumption Time: 2.44942
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.68449

Cumulative Model Updates: 112,504
Cumulative Timesteps: 938,243,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.15736
Policy Entropy: 3.14305
Value Function Loss: 0.00480

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10340
Policy Update Magnitude: 0.58074
Value Function Update Magnitude: 0.58823

Collected Steps per Second: 22,907.52273
Overall Steps per Second: 10,670.39996

Timestep Collection Time: 2.18278
Timestep Consumption Time: 2.50327
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.68605

Cumulative Model Updates: 112,510
Cumulative Timesteps: 938,293,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 938293988...
Checkpoint 938293988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,313.32504
Policy Entropy: 3.14142
Value Function Loss: 0.00487

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11241
Policy Update Magnitude: 0.58528
Value Function Update Magnitude: 0.58401

Collected Steps per Second: 23,137.15081
Overall Steps per Second: 10,857.85193

Timestep Collection Time: 2.16172
Timestep Consumption Time: 2.44472
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.60644

Cumulative Model Updates: 112,516
Cumulative Timesteps: 938,344,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.19833
Policy Entropy: 3.12345
Value Function Loss: 0.00534

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11744
Policy Update Magnitude: 0.59185
Value Function Update Magnitude: 0.59994

Collected Steps per Second: 22,935.85449
Overall Steps per Second: 10,659.54053

Timestep Collection Time: 2.18069
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.69213

Cumulative Model Updates: 112,522
Cumulative Timesteps: 938,394,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 938394020...
Checkpoint 938394020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.62670
Policy Entropy: 3.12674
Value Function Loss: 0.00526

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11782
Policy Update Magnitude: 0.59308
Value Function Update Magnitude: 0.61760

Collected Steps per Second: 22,852.29177
Overall Steps per Second: 10,626.26786

Timestep Collection Time: 2.18814
Timestep Consumption Time: 2.51756
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.70570

Cumulative Model Updates: 112,528
Cumulative Timesteps: 938,444,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.42506
Policy Entropy: 3.11125
Value Function Loss: 0.00520

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11057
Policy Update Magnitude: 0.59585
Value Function Update Magnitude: 0.62237

Collected Steps per Second: 22,983.33210
Overall Steps per Second: 10,760.90092

Timestep Collection Time: 2.17592
Timestep Consumption Time: 2.47146
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.64738

Cumulative Model Updates: 112,534
Cumulative Timesteps: 938,494,034

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 938494034...
Checkpoint 938494034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738.58595
Policy Entropy: 3.11072
Value Function Loss: 0.00522

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11405
Policy Update Magnitude: 0.59952
Value Function Update Magnitude: 0.61150

Collected Steps per Second: 22,770.54849
Overall Steps per Second: 10,637.89297

Timestep Collection Time: 2.19591
Timestep Consumption Time: 2.50446
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.70037

Cumulative Model Updates: 112,540
Cumulative Timesteps: 938,544,036

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.33648
Policy Entropy: 3.10202
Value Function Loss: 0.00519

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.60474
Value Function Update Magnitude: 0.60541

Collected Steps per Second: 22,919.62842
Overall Steps per Second: 10,657.68559

Timestep Collection Time: 2.18276
Timestep Consumption Time: 2.51132
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.69408

Cumulative Model Updates: 112,546
Cumulative Timesteps: 938,594,064

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 938594064...
Checkpoint 938594064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.47875
Policy Entropy: 3.11432
Value Function Loss: 0.00517

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.11497
Policy Update Magnitude: 0.60225
Value Function Update Magnitude: 0.60862

Collected Steps per Second: 22,752.09982
Overall Steps per Second: 10,669.89491

Timestep Collection Time: 2.19848
Timestep Consumption Time: 2.48948
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.68796

Cumulative Model Updates: 112,552
Cumulative Timesteps: 938,644,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 780.34456
Policy Entropy: 3.12430
Value Function Loss: 0.00522

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.59579
Value Function Update Magnitude: 0.61419

Collected Steps per Second: 23,228.31389
Overall Steps per Second: 10,659.55535

Timestep Collection Time: 2.15298
Timestep Consumption Time: 2.53859
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.69157

Cumulative Model Updates: 112,558
Cumulative Timesteps: 938,694,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 938694094...
Checkpoint 938694094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.13705
Policy Entropy: 3.13130
Value Function Loss: 0.00538

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.13199
Policy Update Magnitude: 0.59896
Value Function Update Magnitude: 0.60684

Collected Steps per Second: 22,690.35510
Overall Steps per Second: 10,669.17614

Timestep Collection Time: 2.20411
Timestep Consumption Time: 2.48341
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.68752

Cumulative Model Updates: 112,564
Cumulative Timesteps: 938,744,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 967.20236
Policy Entropy: 3.12920
Value Function Loss: 0.00533

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.60107
Value Function Update Magnitude: 0.59880

Collected Steps per Second: 22,805.85512
Overall Steps per Second: 10,788.81969

Timestep Collection Time: 2.19338
Timestep Consumption Time: 2.44308
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.63647

Cumulative Model Updates: 112,570
Cumulative Timesteps: 938,794,128

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 938794128...
Checkpoint 938794128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.17768
Policy Entropy: 3.13185
Value Function Loss: 0.00527

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12354
Policy Update Magnitude: 0.59900
Value Function Update Magnitude: 0.58737

Collected Steps per Second: 22,463.98519
Overall Steps per Second: 10,774.97633

Timestep Collection Time: 2.22623
Timestep Consumption Time: 2.41508
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.64131

Cumulative Model Updates: 112,576
Cumulative Timesteps: 938,844,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.08572
Policy Entropy: 3.10812
Value Function Loss: 0.00533

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.60399
Value Function Update Magnitude: 0.60321

Collected Steps per Second: 23,075.24757
Overall Steps per Second: 10,913.18248

Timestep Collection Time: 2.16743
Timestep Consumption Time: 2.41547
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.58290

Cumulative Model Updates: 112,582
Cumulative Timesteps: 938,894,152

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 938894152...
Checkpoint 938894152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 959.43741
Policy Entropy: 3.10361
Value Function Loss: 0.00561

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.12082
Policy Update Magnitude: 0.61931
Value Function Update Magnitude: 0.64650

Collected Steps per Second: 22,689.22177
Overall Steps per Second: 10,640.88863

Timestep Collection Time: 2.20404
Timestep Consumption Time: 2.49557
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.69961

Cumulative Model Updates: 112,588
Cumulative Timesteps: 938,944,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 764.38905
Policy Entropy: 3.10092
Value Function Loss: 0.00534

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11822
Policy Update Magnitude: 0.61958
Value Function Update Magnitude: 0.63962

Collected Steps per Second: 22,837.00632
Overall Steps per Second: 10,819.29864

Timestep Collection Time: 2.19030
Timestep Consumption Time: 2.43292
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.62322

Cumulative Model Updates: 112,594
Cumulative Timesteps: 938,994,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 938994180...
Checkpoint 938994180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,371.66476
Policy Entropy: 3.10550
Value Function Loss: 0.00534

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.11759
Policy Update Magnitude: 0.60948
Value Function Update Magnitude: 0.62001

Collected Steps per Second: 22,533.33621
Overall Steps per Second: 10,660.64739

Timestep Collection Time: 2.21920
Timestep Consumption Time: 2.47151
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.69071

Cumulative Model Updates: 112,600
Cumulative Timesteps: 939,044,186

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.23880
Policy Entropy: 3.11456
Value Function Loss: 0.00518

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.10815
Policy Update Magnitude: 0.60008
Value Function Update Magnitude: 0.60546

Collected Steps per Second: 23,139.53116
Overall Steps per Second: 10,923.72024

Timestep Collection Time: 2.16089
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.57738

Cumulative Model Updates: 112,606
Cumulative Timesteps: 939,094,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 939094188...
Checkpoint 939094188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.22182
Policy Entropy: 3.11539
Value Function Loss: 0.00510

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.59739
Value Function Update Magnitude: 0.60550

Collected Steps per Second: 22,817.22796
Overall Steps per Second: 10,684.25037

Timestep Collection Time: 2.19238
Timestep Consumption Time: 2.48965
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.68203

Cumulative Model Updates: 112,612
Cumulative Timesteps: 939,144,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.08094
Policy Entropy: 3.12051
Value Function Loss: 0.00518

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.59736
Value Function Update Magnitude: 0.62102

Collected Steps per Second: 23,084.49861
Overall Steps per Second: 10,857.43785

Timestep Collection Time: 2.16700
Timestep Consumption Time: 2.44035
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.60735

Cumulative Model Updates: 112,618
Cumulative Timesteps: 939,194,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 939194236...
Checkpoint 939194236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,266.09927
Policy Entropy: 3.11548
Value Function Loss: 0.00542

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.60210
Value Function Update Magnitude: 0.64535

Collected Steps per Second: 22,412.88750
Overall Steps per Second: 10,666.80138

Timestep Collection Time: 2.23095
Timestep Consumption Time: 2.45668
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.68763

Cumulative Model Updates: 112,624
Cumulative Timesteps: 939,244,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.20989
Policy Entropy: 3.12575
Value Function Loss: 0.00541

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.60577
Value Function Update Magnitude: 0.66469

Collected Steps per Second: 23,030.44029
Overall Steps per Second: 10,867.40233

Timestep Collection Time: 2.17147
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.60184

Cumulative Model Updates: 112,630
Cumulative Timesteps: 939,294,248

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 939294248...
Checkpoint 939294248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.69408
Policy Entropy: 3.12113
Value Function Loss: 0.00539

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.60124
Value Function Update Magnitude: 0.66643

Collected Steps per Second: 22,635.06572
Overall Steps per Second: 10,726.72926

Timestep Collection Time: 2.21002
Timestep Consumption Time: 2.45347
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.66349

Cumulative Model Updates: 112,636
Cumulative Timesteps: 939,344,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.29440
Policy Entropy: 3.12352
Value Function Loss: 0.00541

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.59853
Value Function Update Magnitude: 0.65251

Collected Steps per Second: 22,776.89322
Overall Steps per Second: 10,783.48116

Timestep Collection Time: 2.19521
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.63672

Cumulative Model Updates: 112,642
Cumulative Timesteps: 939,394,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 939394272...
Checkpoint 939394272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 926.75922
Policy Entropy: 3.11488
Value Function Loss: 0.00541

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09903
Policy Update Magnitude: 0.60040
Value Function Update Magnitude: 0.64647

Collected Steps per Second: 22,783.84536
Overall Steps per Second: 10,715.81599

Timestep Collection Time: 2.19533
Timestep Consumption Time: 2.47235
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.66768

Cumulative Model Updates: 112,648
Cumulative Timesteps: 939,444,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,946.09663
Policy Entropy: 3.09174
Value Function Loss: 0.00559

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.60486
Value Function Update Magnitude: 0.65344

Collected Steps per Second: 23,004.48445
Overall Steps per Second: 10,860.86571

Timestep Collection Time: 2.17445
Timestep Consumption Time: 2.43126
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.60571

Cumulative Model Updates: 112,654
Cumulative Timesteps: 939,494,312

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 939494312...
Checkpoint 939494312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.06801
Policy Entropy: 3.09590
Value Function Loss: 0.00535

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10080
Policy Update Magnitude: 0.60501
Value Function Update Magnitude: 0.66621

Collected Steps per Second: 22,837.57301
Overall Steps per Second: 10,683.85903

Timestep Collection Time: 2.19043
Timestep Consumption Time: 2.49178
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.68220

Cumulative Model Updates: 112,660
Cumulative Timesteps: 939,544,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.19922
Policy Entropy: 3.11114
Value Function Loss: 0.00497

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.59959
Value Function Update Magnitude: 0.65530

Collected Steps per Second: 22,404.70509
Overall Steps per Second: 10,628.78266

Timestep Collection Time: 2.23248
Timestep Consumption Time: 2.47342
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.70590

Cumulative Model Updates: 112,666
Cumulative Timesteps: 939,594,354

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 939594354...
Checkpoint 939594354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 802.76745
Policy Entropy: 3.12883
Value Function Loss: 0.00483

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09772
Policy Update Magnitude: 0.58811
Value Function Update Magnitude: 0.62314

Collected Steps per Second: 22,683.44337
Overall Steps per Second: 10,683.30561

Timestep Collection Time: 2.20478
Timestep Consumption Time: 2.47654
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.68132

Cumulative Model Updates: 112,672
Cumulative Timesteps: 939,644,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.97859
Policy Entropy: 3.12904
Value Function Loss: 0.00495

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09538
Policy Update Magnitude: 0.58535
Value Function Update Magnitude: 0.62146

Collected Steps per Second: 22,854.08288
Overall Steps per Second: 10,732.12624

Timestep Collection Time: 2.18788
Timestep Consumption Time: 2.47122
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.65910

Cumulative Model Updates: 112,678
Cumulative Timesteps: 939,694,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 939694368...
Checkpoint 939694368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.18643
Policy Entropy: 3.12400
Value Function Loss: 0.00507

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10343
Policy Update Magnitude: 0.58819
Value Function Update Magnitude: 0.63274

Collected Steps per Second: 22,751.46350
Overall Steps per Second: 10,645.55035

Timestep Collection Time: 2.19872
Timestep Consumption Time: 2.50034
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.69905

Cumulative Model Updates: 112,684
Cumulative Timesteps: 939,744,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 602.83927
Policy Entropy: 3.12952
Value Function Loss: 0.00497

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11794
Policy Update Magnitude: 0.58600
Value Function Update Magnitude: 0.64932

Collected Steps per Second: 22,957.05057
Overall Steps per Second: 10,832.68621

Timestep Collection Time: 2.17920
Timestep Consumption Time: 2.43905
PPO Batch Consumption Time: 0.28385
Total Iteration Time: 4.61825

Cumulative Model Updates: 112,690
Cumulative Timesteps: 939,794,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 939794420...
Checkpoint 939794420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.27875
Policy Entropy: 3.13382
Value Function Loss: 0.00478

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.11458
Policy Update Magnitude: 0.58288
Value Function Update Magnitude: 0.64043

Collected Steps per Second: 22,626.65072
Overall Steps per Second: 10,662.00892

Timestep Collection Time: 2.21005
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.69011

Cumulative Model Updates: 112,696
Cumulative Timesteps: 939,844,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,252.25400
Policy Entropy: 3.14952
Value Function Loss: 0.00475

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.57943
Value Function Update Magnitude: 0.61868

Collected Steps per Second: 22,695.83793
Overall Steps per Second: 10,686.34685

Timestep Collection Time: 2.20384
Timestep Consumption Time: 2.47671
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.68055

Cumulative Model Updates: 112,702
Cumulative Timesteps: 939,894,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 939894444...
Checkpoint 939894444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 725.03547
Policy Entropy: 3.15509
Value Function Loss: 0.00504

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11699
Policy Update Magnitude: 0.58463
Value Function Update Magnitude: 0.62085

Collected Steps per Second: 22,804.38687
Overall Steps per Second: 10,864.55183

Timestep Collection Time: 2.19282
Timestep Consumption Time: 2.40985
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.60267

Cumulative Model Updates: 112,708
Cumulative Timesteps: 939,944,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,731.92039
Policy Entropy: 3.16529
Value Function Loss: 0.00467

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.57685
Value Function Update Magnitude: 0.61969

Collected Steps per Second: 22,734.84970
Overall Steps per Second: 10,803.28376

Timestep Collection Time: 2.20015
Timestep Consumption Time: 2.42993
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.63007

Cumulative Model Updates: 112,714
Cumulative Timesteps: 939,994,470

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 939994470...
Checkpoint 939994470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,031.88190
Policy Entropy: 3.16779
Value Function Loss: 0.00458

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.56348
Value Function Update Magnitude: 0.60188

Collected Steps per Second: 22,681.54543
Overall Steps per Second: 10,737.34545

Timestep Collection Time: 2.20532
Timestep Consumption Time: 2.45319
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.65851

Cumulative Model Updates: 112,720
Cumulative Timesteps: 940,044,490

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.79936
Policy Entropy: 3.15660
Value Function Loss: 0.00448

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.56340
Value Function Update Magnitude: 0.57800

Collected Steps per Second: 22,835.94529
Overall Steps per Second: 10,798.59970

Timestep Collection Time: 2.18979
Timestep Consumption Time: 2.44099
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.63079

Cumulative Model Updates: 112,726
Cumulative Timesteps: 940,094,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 940094496...
Checkpoint 940094496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.76990
Policy Entropy: 3.13884
Value Function Loss: 0.00459

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.08807
Policy Update Magnitude: 0.57005
Value Function Update Magnitude: 0.57981

Collected Steps per Second: 23,043.82754
Overall Steps per Second: 10,733.05454

Timestep Collection Time: 2.17108
Timestep Consumption Time: 2.49022
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.66130

Cumulative Model Updates: 112,732
Cumulative Timesteps: 940,144,526

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.21148
Policy Entropy: 3.13124
Value Function Loss: 0.00497

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.08548
Policy Update Magnitude: 0.57991
Value Function Update Magnitude: 0.60446

Collected Steps per Second: 22,921.18911
Overall Steps per Second: 10,828.98549

Timestep Collection Time: 2.18217
Timestep Consumption Time: 2.43673
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.61890

Cumulative Model Updates: 112,738
Cumulative Timesteps: 940,194,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 940194544...
Checkpoint 940194544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.92242
Policy Entropy: 3.13462
Value Function Loss: 0.00504

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09035
Policy Update Magnitude: 0.59048
Value Function Update Magnitude: 0.61985

Collected Steps per Second: 22,768.16793
Overall Steps per Second: 10,743.58096

Timestep Collection Time: 2.19719
Timestep Consumption Time: 2.45917
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.65636

Cumulative Model Updates: 112,744
Cumulative Timesteps: 940,244,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.12719
Policy Entropy: 3.14703
Value Function Loss: 0.00500

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.58811
Value Function Update Magnitude: 0.62086

Collected Steps per Second: 22,768.77419
Overall Steps per Second: 10,817.81102

Timestep Collection Time: 2.19625
Timestep Consumption Time: 2.42631
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.62256

Cumulative Model Updates: 112,750
Cumulative Timesteps: 940,294,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 940294576...
Checkpoint 940294576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 819.87660
Policy Entropy: 3.13894
Value Function Loss: 0.00504

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.58828
Value Function Update Magnitude: 0.61178

Collected Steps per Second: 22,703.67550
Overall Steps per Second: 10,707.09258

Timestep Collection Time: 2.20317
Timestep Consumption Time: 2.46850
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.67167

Cumulative Model Updates: 112,756
Cumulative Timesteps: 940,344,596

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.09006
Policy Entropy: 3.12632
Value Function Loss: 0.00515

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11592
Policy Update Magnitude: 0.59221
Value Function Update Magnitude: 0.62862

Collected Steps per Second: 22,864.95375
Overall Steps per Second: 10,826.62946

Timestep Collection Time: 2.18771
Timestep Consumption Time: 2.43256
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.62027

Cumulative Model Updates: 112,762
Cumulative Timesteps: 940,394,618

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 940394618...
Checkpoint 940394618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,294.11572
Policy Entropy: 3.10302
Value Function Loss: 0.00506

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11514
Policy Update Magnitude: 0.59309
Value Function Update Magnitude: 0.61536

Collected Steps per Second: 22,640.47146
Overall Steps per Second: 10,702.97663

Timestep Collection Time: 2.20967
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.67421

Cumulative Model Updates: 112,768
Cumulative Timesteps: 940,444,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,523.34938
Policy Entropy: 3.12570
Value Function Loss: 0.00489

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09475
Policy Update Magnitude: 0.58284
Value Function Update Magnitude: 0.59706

Collected Steps per Second: 23,110.73807
Overall Steps per Second: 10,873.48495

Timestep Collection Time: 2.16358
Timestep Consumption Time: 2.43494
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.59853

Cumulative Model Updates: 112,774
Cumulative Timesteps: 940,494,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 940494648...
Checkpoint 940494648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.94207
Policy Entropy: 3.13257
Value Function Loss: 0.00499

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.11046
Policy Update Magnitude: 0.57697
Value Function Update Magnitude: 0.58063

Collected Steps per Second: 22,625.27218
Overall Steps per Second: 10,740.00156

Timestep Collection Time: 2.21169
Timestep Consumption Time: 2.44753
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.65922

Cumulative Model Updates: 112,780
Cumulative Timesteps: 940,544,688

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,599.14606
Policy Entropy: 3.15281
Value Function Loss: 0.00492

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.57762
Value Function Update Magnitude: 0.58295

Collected Steps per Second: 23,069.58185
Overall Steps per Second: 10,843.17619

Timestep Collection Time: 2.16805
Timestep Consumption Time: 2.44462
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.61267

Cumulative Model Updates: 112,786
Cumulative Timesteps: 940,594,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 940594704...
Checkpoint 940594704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.74648
Policy Entropy: 3.14634
Value Function Loss: 0.00489

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09552
Policy Update Magnitude: 0.57446
Value Function Update Magnitude: 0.58771

Collected Steps per Second: 22,760.42305
Overall Steps per Second: 10,730.56418

Timestep Collection Time: 2.19811
Timestep Consumption Time: 2.46427
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.66238

Cumulative Model Updates: 112,792
Cumulative Timesteps: 940,644,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.66355
Policy Entropy: 3.14004
Value Function Loss: 0.00484

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.56906
Value Function Update Magnitude: 0.58806

Collected Steps per Second: 22,879.71117
Overall Steps per Second: 10,837.18019

Timestep Collection Time: 2.18552
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.28296
Total Iteration Time: 4.61412

Cumulative Model Updates: 112,798
Cumulative Timesteps: 940,694,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 940694738...
Checkpoint 940694738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,922.54965
Policy Entropy: 3.13350
Value Function Loss: 0.00470

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.59367

Collected Steps per Second: 22,753.75679
Overall Steps per Second: 10,692.14096

Timestep Collection Time: 2.19841
Timestep Consumption Time: 2.47998
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.67839

Cumulative Model Updates: 112,804
Cumulative Timesteps: 940,744,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.55144
Policy Entropy: 3.13686
Value Function Loss: 0.00475

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.57379
Value Function Update Magnitude: 0.60455

Collected Steps per Second: 22,692.48036
Overall Steps per Second: 10,619.91598

Timestep Collection Time: 2.20346
Timestep Consumption Time: 2.50486
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.70832

Cumulative Model Updates: 112,810
Cumulative Timesteps: 940,794,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 940794762...
Checkpoint 940794762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.58526
Policy Entropy: 3.12827
Value Function Loss: 0.00457

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09445
Policy Update Magnitude: 0.56819
Value Function Update Magnitude: 0.61625

Collected Steps per Second: 22,775.54670
Overall Steps per Second: 10,822.81189

Timestep Collection Time: 2.19674
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.62283

Cumulative Model Updates: 112,816
Cumulative Timesteps: 940,844,794

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.85934
Policy Entropy: 3.13721
Value Function Loss: 0.00474

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09515
Policy Update Magnitude: 0.57074
Value Function Update Magnitude: 0.60969

Collected Steps per Second: 22,872.17926
Overall Steps per Second: 10,737.56350

Timestep Collection Time: 2.18624
Timestep Consumption Time: 2.47069
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.65692

Cumulative Model Updates: 112,822
Cumulative Timesteps: 940,894,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 940894798...
Checkpoint 940894798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.13777
Policy Entropy: 3.12998
Value Function Loss: 0.00481

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09151
Policy Update Magnitude: 0.58131
Value Function Update Magnitude: 0.62098

Collected Steps per Second: 22,792.74275
Overall Steps per Second: 10,808.94107

Timestep Collection Time: 2.19386
Timestep Consumption Time: 2.43231
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.62617

Cumulative Model Updates: 112,828
Cumulative Timesteps: 940,944,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 956.47545
Policy Entropy: 3.14096
Value Function Loss: 0.00488

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.58090
Value Function Update Magnitude: 0.61657

Collected Steps per Second: 23,000.02501
Overall Steps per Second: 10,739.96495

Timestep Collection Time: 2.17487
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.65756

Cumulative Model Updates: 112,834
Cumulative Timesteps: 940,994,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 940994824...
Checkpoint 940994824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,176.66404
Policy Entropy: 3.14202
Value Function Loss: 0.00504

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.58175
Value Function Update Magnitude: 0.61711

Collected Steps per Second: 22,655.58633
Overall Steps per Second: 10,774.57841

Timestep Collection Time: 2.20696
Timestep Consumption Time: 2.43359
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.64055

Cumulative Model Updates: 112,840
Cumulative Timesteps: 941,044,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553.07571
Policy Entropy: 3.12941
Value Function Loss: 0.00527

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10040
Policy Update Magnitude: 0.58600
Value Function Update Magnitude: 0.63179

Collected Steps per Second: 23,139.66052
Overall Steps per Second: 10,939.65960

Timestep Collection Time: 2.16192
Timestep Consumption Time: 2.41099
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.57290

Cumulative Model Updates: 112,846
Cumulative Timesteps: 941,094,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 941094850...
Checkpoint 941094850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.77065
Policy Entropy: 3.13930
Value Function Loss: 0.00519

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.57945
Value Function Update Magnitude: 0.65125

Collected Steps per Second: 22,615.06735
Overall Steps per Second: 10,743.49159

Timestep Collection Time: 2.21171
Timestep Consumption Time: 2.44394
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.65566

Cumulative Model Updates: 112,852
Cumulative Timesteps: 941,144,868

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,734.55948
Policy Entropy: 3.13824
Value Function Loss: 0.00505

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.57322
Value Function Update Magnitude: 0.63315

Collected Steps per Second: 22,999.53944
Overall Steps per Second: 10,843.75459

Timestep Collection Time: 2.17474
Timestep Consumption Time: 2.43787
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.61261

Cumulative Model Updates: 112,858
Cumulative Timesteps: 941,194,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 941194886...
Checkpoint 941194886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,786.51776
Policy Entropy: 3.13540
Value Function Loss: 0.00473

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09847
Policy Update Magnitude: 0.57728
Value Function Update Magnitude: 0.60815

Collected Steps per Second: 22,527.44815
Overall Steps per Second: 10,666.18186

Timestep Collection Time: 2.21996
Timestep Consumption Time: 2.46869
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.68865

Cumulative Model Updates: 112,864
Cumulative Timesteps: 941,244,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 566.48103
Policy Entropy: 3.12621
Value Function Loss: 0.00479

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09911
Policy Update Magnitude: 0.57892
Value Function Update Magnitude: 0.60681

Collected Steps per Second: 22,825.48582
Overall Steps per Second: 10,820.28065

Timestep Collection Time: 2.19185
Timestep Consumption Time: 2.43188
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.62372

Cumulative Model Updates: 112,870
Cumulative Timesteps: 941,294,926

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 941294926...
Checkpoint 941294926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,779.71341
Policy Entropy: 3.13269
Value Function Loss: 0.00478

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.57508
Value Function Update Magnitude: 0.60402

Collected Steps per Second: 23,064.09101
Overall Steps per Second: 10,753.62552

Timestep Collection Time: 2.16831
Timestep Consumption Time: 2.48222
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.65052

Cumulative Model Updates: 112,876
Cumulative Timesteps: 941,344,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,196.10608
Policy Entropy: 3.14726
Value Function Loss: 0.00517

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11000
Policy Update Magnitude: 0.57911
Value Function Update Magnitude: 0.60669

Collected Steps per Second: 22,833.81618
Overall Steps per Second: 10,819.60767

Timestep Collection Time: 2.19070
Timestep Consumption Time: 2.43257
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.62327

Cumulative Model Updates: 112,882
Cumulative Timesteps: 941,394,958

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 941394958...
Checkpoint 941394958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.98706
Policy Entropy: 3.13456
Value Function Loss: 0.00489

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.58422
Value Function Update Magnitude: 0.63576

Collected Steps per Second: 22,940.30576
Overall Steps per Second: 10,690.61542

Timestep Collection Time: 2.18009
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.29411
Total Iteration Time: 4.67812

Cumulative Model Updates: 112,888
Cumulative Timesteps: 941,444,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.89778
Policy Entropy: 3.12247
Value Function Loss: 0.00486

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.11170
Policy Update Magnitude: 0.57968
Value Function Update Magnitude: 0.65484

Collected Steps per Second: 22,682.83375
Overall Steps per Second: 10,692.86453

Timestep Collection Time: 2.20502
Timestep Consumption Time: 2.47250
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.67751

Cumulative Model Updates: 112,894
Cumulative Timesteps: 941,494,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 941494986...
Checkpoint 941494986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.39645
Policy Entropy: 3.12202
Value Function Loss: 0.00464

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11128
Policy Update Magnitude: 0.57745
Value Function Update Magnitude: 0.63898

Collected Steps per Second: 22,843.52070
Overall Steps per Second: 10,853.10912

Timestep Collection Time: 2.19038
Timestep Consumption Time: 2.41991
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.61029

Cumulative Model Updates: 112,900
Cumulative Timesteps: 941,545,022

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,752.56082
Policy Entropy: 3.12380
Value Function Loss: 0.00514

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10987
Policy Update Magnitude: 0.59442
Value Function Update Magnitude: 0.63522

Collected Steps per Second: 22,610.85266
Overall Steps per Second: 10,572.32587

Timestep Collection Time: 2.21168
Timestep Consumption Time: 2.51840
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.73008

Cumulative Model Updates: 112,906
Cumulative Timesteps: 941,595,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 941595030...
Checkpoint 941595030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,117.09810
Policy Entropy: 3.10547
Value Function Loss: 0.00512

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.59541
Value Function Update Magnitude: 0.67810

Collected Steps per Second: 22,823.63276
Overall Steps per Second: 10,598.06194

Timestep Collection Time: 2.19185
Timestep Consumption Time: 2.52845
PPO Batch Consumption Time: 0.29679
Total Iteration Time: 4.72030

Cumulative Model Updates: 112,912
Cumulative Timesteps: 941,645,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.97017
Policy Entropy: 3.10728
Value Function Loss: 0.00501

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10582
Policy Update Magnitude: 0.59510
Value Function Update Magnitude: 0.66689

Collected Steps per Second: 23,104.19213
Overall Steps per Second: 10,894.51518

Timestep Collection Time: 2.16515
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.59167

Cumulative Model Updates: 112,918
Cumulative Timesteps: 941,695,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 941695080...
Checkpoint 941695080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.77605
Policy Entropy: 3.09492
Value Function Loss: 0.00501

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09751
Policy Update Magnitude: 0.59436
Value Function Update Magnitude: 0.64466

Collected Steps per Second: 22,861.42831
Overall Steps per Second: 10,618.74152

Timestep Collection Time: 2.18840
Timestep Consumption Time: 2.52308
PPO Batch Consumption Time: 0.29497
Total Iteration Time: 4.71148

Cumulative Model Updates: 112,924
Cumulative Timesteps: 941,745,110

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,747.70658
Policy Entropy: 3.10232
Value Function Loss: 0.00488

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.58873
Value Function Update Magnitude: 0.63363

Collected Steps per Second: 22,682.12036
Overall Steps per Second: 10,577.89057

Timestep Collection Time: 2.20456
Timestep Consumption Time: 2.52266
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.72722

Cumulative Model Updates: 112,930
Cumulative Timesteps: 941,795,114

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 941795114...
Checkpoint 941795114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 760.72888
Policy Entropy: 3.10227
Value Function Loss: 0.00512

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.58577
Value Function Update Magnitude: 0.62048

Collected Steps per Second: 22,609.26364
Overall Steps per Second: 10,690.68220

Timestep Collection Time: 2.21193
Timestep Consumption Time: 2.46598
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.67791

Cumulative Model Updates: 112,936
Cumulative Timesteps: 941,845,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.08475
Policy Entropy: 3.11566
Value Function Loss: 0.00495

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.58631
Value Function Update Magnitude: 0.62953

Collected Steps per Second: 22,940.53555
Overall Steps per Second: 10,741.96696

Timestep Collection Time: 2.18086
Timestep Consumption Time: 2.47658
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.65743

Cumulative Model Updates: 112,942
Cumulative Timesteps: 941,895,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 941895154...
Checkpoint 941895154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.07709
Policy Entropy: 3.11898
Value Function Loss: 0.00494

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.58389
Value Function Update Magnitude: 0.61881

Collected Steps per Second: 23,102.24146
Overall Steps per Second: 10,781.53400

Timestep Collection Time: 2.16447
Timestep Consumption Time: 2.47346
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.63793

Cumulative Model Updates: 112,948
Cumulative Timesteps: 941,945,158

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.30460
Policy Entropy: 3.13360
Value Function Loss: 0.00491

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09804
Policy Update Magnitude: 0.58244
Value Function Update Magnitude: 0.61796

Collected Steps per Second: 23,010.74781
Overall Steps per Second: 10,756.39351

Timestep Collection Time: 2.17368
Timestep Consumption Time: 2.47639
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.65007

Cumulative Model Updates: 112,954
Cumulative Timesteps: 941,995,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 941995176...
Checkpoint 941995176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.75160
Policy Entropy: 3.13583
Value Function Loss: 0.00487

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09672
Policy Update Magnitude: 0.57869
Value Function Update Magnitude: 0.60614

Collected Steps per Second: 22,817.87324
Overall Steps per Second: 10,664.76328

Timestep Collection Time: 2.19232
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.29602
Total Iteration Time: 4.69059

Cumulative Model Updates: 112,960
Cumulative Timesteps: 942,045,200

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,200.40877
Policy Entropy: 3.13237
Value Function Loss: 0.00498

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.57976
Value Function Update Magnitude: 0.59707

Collected Steps per Second: 22,297.57341
Overall Steps per Second: 10,546.05245

Timestep Collection Time: 2.24401
Timestep Consumption Time: 2.50051
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.74452

Cumulative Model Updates: 112,966
Cumulative Timesteps: 942,095,236

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 942095236...
Checkpoint 942095236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.23950
Policy Entropy: 3.13093
Value Function Loss: 0.00508

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.57637
Value Function Update Magnitude: 0.60937

Collected Steps per Second: 22,641.82036
Overall Steps per Second: 10,674.48432

Timestep Collection Time: 2.20883
Timestep Consumption Time: 2.47636
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.68519

Cumulative Model Updates: 112,972
Cumulative Timesteps: 942,145,248

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.90748
Policy Entropy: 3.12245
Value Function Loss: 0.00524

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.58173
Value Function Update Magnitude: 0.63204

Collected Steps per Second: 23,013.54488
Overall Steps per Second: 10,767.12736

Timestep Collection Time: 2.17324
Timestep Consumption Time: 2.47182
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.64506

Cumulative Model Updates: 112,978
Cumulative Timesteps: 942,195,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 942195262...
Checkpoint 942195262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.90632
Policy Entropy: 3.10773
Value Function Loss: 0.00524

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10436
Policy Update Magnitude: 0.58395
Value Function Update Magnitude: 0.63370

Collected Steps per Second: 22,872.11602
Overall Steps per Second: 10,651.90715

Timestep Collection Time: 2.18738
Timestep Consumption Time: 2.50943
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.69681

Cumulative Model Updates: 112,984
Cumulative Timesteps: 942,245,292

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.88135
Policy Entropy: 3.11558
Value Function Loss: 0.00519

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10603
Policy Update Magnitude: 0.58305
Value Function Update Magnitude: 0.61968

Collected Steps per Second: 22,807.32173
Overall Steps per Second: 10,796.53573

Timestep Collection Time: 2.19280
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.63223

Cumulative Model Updates: 112,990
Cumulative Timesteps: 942,295,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 942295304...
Checkpoint 942295304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.52378
Policy Entropy: 3.11291
Value Function Loss: 0.00520

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.58396
Value Function Update Magnitude: 0.60889

Collected Steps per Second: 22,612.19480
Overall Steps per Second: 10,760.42054

Timestep Collection Time: 2.21261
Timestep Consumption Time: 2.43702
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.64963

Cumulative Model Updates: 112,996
Cumulative Timesteps: 942,345,336

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551.26145
Policy Entropy: 3.11585
Value Function Loss: 0.00523

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09095
Policy Update Magnitude: 0.59033
Value Function Update Magnitude: 0.61735

Collected Steps per Second: 22,899.30957
Overall Steps per Second: 10,807.29275

Timestep Collection Time: 2.18382
Timestep Consumption Time: 2.44342
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.62725

Cumulative Model Updates: 113,002
Cumulative Timesteps: 942,395,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 942395344...
Checkpoint 942395344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,585.45288
Policy Entropy: 3.10914
Value Function Loss: 0.00505

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.58716
Value Function Update Magnitude: 0.61857

Collected Steps per Second: 22,638.57040
Overall Steps per Second: 10,668.32936

Timestep Collection Time: 2.20995
Timestep Consumption Time: 2.47964
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.68958

Cumulative Model Updates: 113,008
Cumulative Timesteps: 942,445,374

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.83341
Policy Entropy: 3.11230
Value Function Loss: 0.00494

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.57313
Value Function Update Magnitude: 0.59868

Collected Steps per Second: 22,853.30221
Overall Steps per Second: 10,722.92202

Timestep Collection Time: 2.18892
Timestep Consumption Time: 2.47623
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.66515

Cumulative Model Updates: 113,014
Cumulative Timesteps: 942,495,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 942495398...
Checkpoint 942495398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,368.94013
Policy Entropy: 3.11861
Value Function Loss: 0.00494

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.57125
Value Function Update Magnitude: 0.58614

Collected Steps per Second: 22,969.02424
Overall Steps per Second: 10,915.39580

Timestep Collection Time: 2.17737
Timestep Consumption Time: 2.40442
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.58179

Cumulative Model Updates: 113,020
Cumulative Timesteps: 942,545,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,174.66187
Policy Entropy: 3.11302
Value Function Loss: 0.00528

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.57885
Value Function Update Magnitude: 0.59023

Collected Steps per Second: 22,897.98994
Overall Steps per Second: 10,802.11830

Timestep Collection Time: 2.18403
Timestep Consumption Time: 2.44561
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.62965

Cumulative Model Updates: 113,026
Cumulative Timesteps: 942,595,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 942595420...
Checkpoint 942595420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.95426
Policy Entropy: 3.11793
Value Function Loss: 0.00515

Mean KL Divergence: 0.01187
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.58149
Value Function Update Magnitude: 0.58089

Collected Steps per Second: 22,732.18485
Overall Steps per Second: 10,700.80519

Timestep Collection Time: 2.20049
Timestep Consumption Time: 2.47411
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.67460

Cumulative Model Updates: 113,032
Cumulative Timesteps: 942,645,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.87157
Policy Entropy: 3.11081
Value Function Loss: 0.00529

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12263
Policy Update Magnitude: 0.58139
Value Function Update Magnitude: 0.58185

Collected Steps per Second: 22,550.40713
Overall Steps per Second: 10,657.78664

Timestep Collection Time: 2.21788
Timestep Consumption Time: 2.47484
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.69272

Cumulative Model Updates: 113,038
Cumulative Timesteps: 942,695,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 942695456...
Checkpoint 942695456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.17119
Policy Entropy: 3.09371
Value Function Loss: 0.00527

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.58790
Value Function Update Magnitude: 0.60365

Collected Steps per Second: 22,830.37075
Overall Steps per Second: 10,819.83365

Timestep Collection Time: 2.19077
Timestep Consumption Time: 2.43186
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.62262

Cumulative Model Updates: 113,044
Cumulative Timesteps: 942,745,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.50029
Policy Entropy: 3.08243
Value Function Loss: 0.00525

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.59243
Value Function Update Magnitude: 0.61731

Collected Steps per Second: 22,594.45083
Overall Steps per Second: 10,641.96058

Timestep Collection Time: 2.21426
Timestep Consumption Time: 2.48694
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.70120

Cumulative Model Updates: 113,050
Cumulative Timesteps: 942,795,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 942795502...
Checkpoint 942795502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.16406
Policy Entropy: 3.09310
Value Function Loss: 0.00492

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.11415
Policy Update Magnitude: 0.58428
Value Function Update Magnitude: 0.61682

Collected Steps per Second: 22,984.99892
Overall Steps per Second: 10,765.19503

Timestep Collection Time: 2.17638
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.64683

Cumulative Model Updates: 113,056
Cumulative Timesteps: 942,845,526

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.66646
Policy Entropy: 3.09696
Value Function Loss: 0.00494

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11704
Policy Update Magnitude: 0.57834
Value Function Update Magnitude: 0.60541

Collected Steps per Second: 23,010.36295
Overall Steps per Second: 10,693.91556

Timestep Collection Time: 2.17293
Timestep Consumption Time: 2.50262
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.67556

Cumulative Model Updates: 113,062
Cumulative Timesteps: 942,895,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 942895526...
Checkpoint 942895526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.87946
Policy Entropy: 3.10629
Value Function Loss: 0.00501

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.57935
Value Function Update Magnitude: 0.59198

Collected Steps per Second: 22,906.64669
Overall Steps per Second: 10,690.97028

Timestep Collection Time: 2.18303
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29605
Total Iteration Time: 4.67741

Cumulative Model Updates: 113,068
Cumulative Timesteps: 942,945,532

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.76746
Policy Entropy: 3.09200
Value Function Loss: 0.00545

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.58557
Value Function Update Magnitude: 0.58670

Collected Steps per Second: 22,812.44269
Overall Steps per Second: 10,779.30965

Timestep Collection Time: 2.19249
Timestep Consumption Time: 2.44751
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.64000

Cumulative Model Updates: 113,074
Cumulative Timesteps: 942,995,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 942995548...
Checkpoint 942995548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,156.51970
Policy Entropy: 3.10665
Value Function Loss: 0.00551

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11840
Policy Update Magnitude: 0.58793
Value Function Update Magnitude: 0.59691

Collected Steps per Second: 22,675.86240
Overall Steps per Second: 10,692.22424

Timestep Collection Time: 2.20534
Timestep Consumption Time: 2.47170
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.67704

Cumulative Model Updates: 113,080
Cumulative Timesteps: 943,045,556

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 985.23686
Policy Entropy: 3.11565
Value Function Loss: 0.00509

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11671
Policy Update Magnitude: 0.58601
Value Function Update Magnitude: 0.60349

Collected Steps per Second: 22,998.37987
Overall Steps per Second: 10,830.41338

Timestep Collection Time: 2.17520
Timestep Consumption Time: 2.44383
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.61903

Cumulative Model Updates: 113,086
Cumulative Timesteps: 943,095,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 943095582...
Checkpoint 943095582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,397.80567
Policy Entropy: 3.12115
Value Function Loss: 0.00495

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.09981
Policy Update Magnitude: 0.57690
Value Function Update Magnitude: 0.58596

Collected Steps per Second: 23,015.63430
Overall Steps per Second: 10,701.17445

Timestep Collection Time: 2.17331
Timestep Consumption Time: 2.50095
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.67425

Cumulative Model Updates: 113,092
Cumulative Timesteps: 943,145,602

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,436.19065
Policy Entropy: 3.11817
Value Function Loss: 0.00510

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.58090
Value Function Update Magnitude: 0.58635

Collected Steps per Second: 22,859.83346
Overall Steps per Second: 10,809.77577

Timestep Collection Time: 2.18751
Timestep Consumption Time: 2.43849
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.62600

Cumulative Model Updates: 113,098
Cumulative Timesteps: 943,195,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 943195608...
Checkpoint 943195608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,045.87803
Policy Entropy: 3.10982
Value Function Loss: 0.00509

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.58038
Value Function Update Magnitude: 0.60427

Collected Steps per Second: 22,807.37421
Overall Steps per Second: 10,765.06785

Timestep Collection Time: 2.19333
Timestep Consumption Time: 2.45356
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.64688

Cumulative Model Updates: 113,104
Cumulative Timesteps: 943,245,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,130.05734
Policy Entropy: 3.11074
Value Function Loss: 0.00483

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.57826
Value Function Update Magnitude: 0.60658

Collected Steps per Second: 22,821.21497
Overall Steps per Second: 10,657.08504

Timestep Collection Time: 2.19112
Timestep Consumption Time: 2.50097
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.69209

Cumulative Model Updates: 113,110
Cumulative Timesteps: 943,295,636

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 943295636...
Checkpoint 943295636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.42066
Policy Entropy: 3.09326
Value Function Loss: 0.00465

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.56485
Value Function Update Magnitude: 0.59884

Collected Steps per Second: 23,044.49293
Overall Steps per Second: 10,796.33245

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.46306
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.63417

Cumulative Model Updates: 113,116
Cumulative Timesteps: 943,345,668

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,776.80611
Policy Entropy: 3.09314
Value Function Loss: 0.00459

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09919
Policy Update Magnitude: 0.56667
Value Function Update Magnitude: 0.58249

Collected Steps per Second: 22,540.02427
Overall Steps per Second: 10,539.53001

Timestep Collection Time: 2.21934
Timestep Consumption Time: 2.52698
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.74632

Cumulative Model Updates: 113,122
Cumulative Timesteps: 943,395,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 943395692...
Checkpoint 943395692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 803.79203
Policy Entropy: 3.09872
Value Function Loss: 0.00466

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.56966
Value Function Update Magnitude: 0.58895

Collected Steps per Second: 22,526.99288
Overall Steps per Second: 10,635.94218

Timestep Collection Time: 2.21983
Timestep Consumption Time: 2.48178
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.70161

Cumulative Model Updates: 113,128
Cumulative Timesteps: 943,445,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,299.60328
Policy Entropy: 3.09611
Value Function Loss: 0.00471

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10062
Policy Update Magnitude: 0.57113
Value Function Update Magnitude: 0.60541

Collected Steps per Second: 23,198.15836
Overall Steps per Second: 10,831.43543

Timestep Collection Time: 2.15655
Timestep Consumption Time: 2.46223
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.61878

Cumulative Model Updates: 113,134
Cumulative Timesteps: 943,495,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 943495726...
Checkpoint 943495726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.49075
Policy Entropy: 3.09757
Value Function Loss: 0.00499

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10717
Policy Update Magnitude: 0.57228
Value Function Update Magnitude: 0.61190

Collected Steps per Second: 22,742.90614
Overall Steps per Second: 10,745.13046

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.45596
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.65550

Cumulative Model Updates: 113,140
Cumulative Timesteps: 943,545,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.11104
Policy Entropy: 3.09708
Value Function Loss: 0.00501

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10835
Policy Update Magnitude: 0.57450
Value Function Update Magnitude: 0.60528

Collected Steps per Second: 22,810.28159
Overall Steps per Second: 10,810.75311

Timestep Collection Time: 2.19322
Timestep Consumption Time: 2.43439
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.62761

Cumulative Model Updates: 113,146
Cumulative Timesteps: 943,595,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 943595778...
Checkpoint 943595778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,824.25832
Policy Entropy: 3.10645
Value Function Loss: 0.00505

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.57744
Value Function Update Magnitude: 0.60459

Collected Steps per Second: 22,821.07571
Overall Steps per Second: 10,742.74934

Timestep Collection Time: 2.19166
Timestep Consumption Time: 2.46413
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.65579

Cumulative Model Updates: 113,152
Cumulative Timesteps: 943,645,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 675.43689
Policy Entropy: 3.09510
Value Function Loss: 0.00501

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10759
Policy Update Magnitude: 0.57822
Value Function Update Magnitude: 0.59559

Collected Steps per Second: 22,967.00885
Overall Steps per Second: 10,820.64246

Timestep Collection Time: 2.17834
Timestep Consumption Time: 2.44523
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.62357

Cumulative Model Updates: 113,158
Cumulative Timesteps: 943,695,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 943695824...
Checkpoint 943695824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.42775
Policy Entropy: 3.08606
Value Function Loss: 0.00483

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.57480
Value Function Update Magnitude: 0.59414

Collected Steps per Second: 22,757.07726
Overall Steps per Second: 10,721.41622

Timestep Collection Time: 2.19712
Timestep Consumption Time: 2.46644
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.66356

Cumulative Model Updates: 113,164
Cumulative Timesteps: 943,745,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.99413
Policy Entropy: 3.08071
Value Function Loss: 0.00478

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.59437

Collected Steps per Second: 22,831.16383
Overall Steps per Second: 10,792.96670

Timestep Collection Time: 2.19069
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.63413

Cumulative Model Updates: 113,170
Cumulative Timesteps: 943,795,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 943795840...
Checkpoint 943795840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.99290
Policy Entropy: 3.09058
Value Function Loss: 0.00450

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.56330
Value Function Update Magnitude: 0.58645

Collected Steps per Second: 22,951.32719
Overall Steps per Second: 10,721.73768

Timestep Collection Time: 2.17905
Timestep Consumption Time: 2.48550
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.66454

Cumulative Model Updates: 113,176
Cumulative Timesteps: 943,845,852

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.72360
Policy Entropy: 3.09738
Value Function Loss: 0.00489

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.58504

Collected Steps per Second: 23,088.68319
Overall Steps per Second: 10,888.95635

Timestep Collection Time: 2.16678
Timestep Consumption Time: 2.42760
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.59438

Cumulative Model Updates: 113,182
Cumulative Timesteps: 943,895,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 943895880...
Checkpoint 943895880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,424.65926
Policy Entropy: 3.09473
Value Function Loss: 0.00489

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.57286
Value Function Update Magnitude: 0.58942

Collected Steps per Second: 22,770.13579
Overall Steps per Second: 10,678.36969

Timestep Collection Time: 2.19595
Timestep Consumption Time: 2.48660
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.68255

Cumulative Model Updates: 113,188
Cumulative Timesteps: 943,945,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.62551
Policy Entropy: 3.10082
Value Function Loss: 0.00471

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10820
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.59923

Collected Steps per Second: 22,947.26681
Overall Steps per Second: 10,860.60393

Timestep Collection Time: 2.17917
Timestep Consumption Time: 2.42518
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.60435

Cumulative Model Updates: 113,194
Cumulative Timesteps: 943,995,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 943995888...
Checkpoint 943995888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 923.63972
Policy Entropy: 3.11374
Value Function Loss: 0.00462

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.55147
Value Function Update Magnitude: 0.56961

Collected Steps per Second: 22,878.57373
Overall Steps per Second: 10,630.54113

Timestep Collection Time: 2.18633
Timestep Consumption Time: 2.51899
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 4.70531

Cumulative Model Updates: 113,200
Cumulative Timesteps: 944,045,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.20409
Policy Entropy: 3.11699
Value Function Loss: 0.00483

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11199
Policy Update Magnitude: 0.55730
Value Function Update Magnitude: 0.56719

Collected Steps per Second: 22,930.06984
Overall Steps per Second: 10,864.78415

Timestep Collection Time: 2.18072
Timestep Consumption Time: 2.42168
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.60239

Cumulative Model Updates: 113,206
Cumulative Timesteps: 944,095,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 944095912...
Checkpoint 944095912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,426.84139
Policy Entropy: 3.09945
Value Function Loss: 0.00499

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10614
Policy Update Magnitude: 0.58059
Value Function Update Magnitude: 0.59367

Collected Steps per Second: 22,534.39334
Overall Steps per Second: 10,759.44491

Timestep Collection Time: 2.21927
Timestep Consumption Time: 2.42874
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.64801

Cumulative Model Updates: 113,212
Cumulative Timesteps: 944,145,922

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.99218
Policy Entropy: 3.08973
Value Function Loss: 0.00505

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.58895
Value Function Update Magnitude: 0.61813

Collected Steps per Second: 22,938.31865
Overall Steps per Second: 10,840.52208

Timestep Collection Time: 2.18080
Timestep Consumption Time: 2.43373
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.61454

Cumulative Model Updates: 113,218
Cumulative Timesteps: 944,195,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 944195946...
Checkpoint 944195946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.83796
Policy Entropy: 3.08494
Value Function Loss: 0.00477

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.58134
Value Function Update Magnitude: 0.62724

Collected Steps per Second: 22,793.62264
Overall Steps per Second: 10,682.28777

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.48745
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.68139

Cumulative Model Updates: 113,224
Cumulative Timesteps: 944,245,954

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,949.03351
Policy Entropy: 3.06841
Value Function Loss: 0.00508

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.58767
Value Function Update Magnitude: 0.60167

Collected Steps per Second: 22,970.39470
Overall Steps per Second: 10,840.67203

Timestep Collection Time: 2.17750
Timestep Consumption Time: 2.43642
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.61392

Cumulative Model Updates: 113,230
Cumulative Timesteps: 944,295,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 944295972...
Checkpoint 944295972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.27869
Policy Entropy: 3.08431
Value Function Loss: 0.00499

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11717
Policy Update Magnitude: 0.58645
Value Function Update Magnitude: 0.59665

Collected Steps per Second: 22,629.34204
Overall Steps per Second: 10,729.02516

Timestep Collection Time: 2.21005
Timestep Consumption Time: 2.45132
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.66137

Cumulative Model Updates: 113,236
Cumulative Timesteps: 944,345,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998.04564
Policy Entropy: 3.09351
Value Function Loss: 0.00506

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10291
Policy Update Magnitude: 0.58307
Value Function Update Magnitude: 0.59877

Collected Steps per Second: 22,687.30312
Overall Steps per Second: 10,788.24764

Timestep Collection Time: 2.20520
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.63745

Cumulative Model Updates: 113,242
Cumulative Timesteps: 944,396,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 944396014...
Checkpoint 944396014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 840.47538
Policy Entropy: 3.10819
Value Function Loss: 0.00483

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.58161
Value Function Update Magnitude: 0.60485

Collected Steps per Second: 22,886.11264
Overall Steps per Second: 10,738.28767

Timestep Collection Time: 2.18482
Timestep Consumption Time: 2.47160
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.65642

Cumulative Model Updates: 113,248
Cumulative Timesteps: 944,446,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 921.01136
Policy Entropy: 3.09670
Value Function Loss: 0.00479

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.58269
Value Function Update Magnitude: 0.60660

Collected Steps per Second: 22,798.29205
Overall Steps per Second: 10,810.33784

Timestep Collection Time: 2.19367
Timestep Consumption Time: 2.43264
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.62631

Cumulative Model Updates: 113,254
Cumulative Timesteps: 944,496,028

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 944496028...
Checkpoint 944496028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 997.45671
Policy Entropy: 3.09405
Value Function Loss: 0.00485

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10427
Policy Update Magnitude: 0.57924
Value Function Update Magnitude: 0.59665

Collected Steps per Second: 22,839.29433
Overall Steps per Second: 10,736.82912

Timestep Collection Time: 2.18947
Timestep Consumption Time: 2.46796
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.65743

Cumulative Model Updates: 113,260
Cumulative Timesteps: 944,546,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 980.49925
Policy Entropy: 3.07899
Value Function Loss: 0.00527

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10335
Policy Update Magnitude: 0.58303
Value Function Update Magnitude: 0.60868

Collected Steps per Second: 22,256.61043
Overall Steps per Second: 10,542.46810

Timestep Collection Time: 2.24715
Timestep Consumption Time: 2.49690
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.74405

Cumulative Model Updates: 113,266
Cumulative Timesteps: 944,596,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 944596048...
Checkpoint 944596048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.41568
Policy Entropy: 3.07587
Value Function Loss: 0.00535

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.58528
Value Function Update Magnitude: 0.63197

Collected Steps per Second: 22,721.84014
Overall Steps per Second: 10,635.91950

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.50243
PPO Batch Consumption Time: 0.29608
Total Iteration Time: 4.70462

Cumulative Model Updates: 113,272
Cumulative Timesteps: 944,646,086

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.16124
Policy Entropy: 3.05984
Value Function Loss: 0.00539

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.58709
Value Function Update Magnitude: 0.63544

Collected Steps per Second: 22,773.15183
Overall Steps per Second: 10,837.10118

Timestep Collection Time: 2.19653
Timestep Consumption Time: 2.41928
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.61581

Cumulative Model Updates: 113,278
Cumulative Timesteps: 944,696,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 944696108...
Checkpoint 944696108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.67878
Policy Entropy: 3.07795
Value Function Loss: 0.00509

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09720
Policy Update Magnitude: 0.58390
Value Function Update Magnitude: 0.63876

Collected Steps per Second: 22,726.85653
Overall Steps per Second: 10,637.16522

Timestep Collection Time: 2.20066
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.29678
Total Iteration Time: 4.70182

Cumulative Model Updates: 113,284
Cumulative Timesteps: 944,746,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,276.48423
Policy Entropy: 3.08016
Value Function Loss: 0.00478

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10175
Policy Update Magnitude: 0.57560
Value Function Update Magnitude: 0.63503

Collected Steps per Second: 22,844.10474
Overall Steps per Second: 10,748.97685

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.46345
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.65272

Cumulative Model Updates: 113,290
Cumulative Timesteps: 944,796,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 944796134...
Checkpoint 944796134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,085.39952
Policy Entropy: 3.08946
Value Function Loss: 0.00474

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10909
Policy Update Magnitude: 0.57191
Value Function Update Magnitude: 0.61961

Collected Steps per Second: 22,730.11182
Overall Steps per Second: 10,864.92964

Timestep Collection Time: 2.20061
Timestep Consumption Time: 2.40320
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.60380

Cumulative Model Updates: 113,296
Cumulative Timesteps: 944,846,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,081.22792
Policy Entropy: 3.06757
Value Function Loss: 0.00494

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.57197
Value Function Update Magnitude: 0.60640

Collected Steps per Second: 23,006.92716
Overall Steps per Second: 10,869.98489

Timestep Collection Time: 2.17326
Timestep Consumption Time: 2.42656
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.59982

Cumulative Model Updates: 113,302
Cumulative Timesteps: 944,896,154

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 944896154...
Checkpoint 944896154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 922.76900
Policy Entropy: 3.05656
Value Function Loss: 0.00519

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.57349
Value Function Update Magnitude: 0.61518

Collected Steps per Second: 22,839.08281
Overall Steps per Second: 10,719.75330

Timestep Collection Time: 2.19028
Timestep Consumption Time: 2.47624
PPO Batch Consumption Time: 0.29412
Total Iteration Time: 4.66653

Cumulative Model Updates: 113,308
Cumulative Timesteps: 944,946,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,301.49946
Policy Entropy: 3.05014
Value Function Loss: 0.00517

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.14549
Policy Update Magnitude: 0.57968
Value Function Update Magnitude: 0.62046

Collected Steps per Second: 22,888.58479
Overall Steps per Second: 10,822.53681

Timestep Collection Time: 2.18554
Timestep Consumption Time: 2.43666
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.62221

Cumulative Model Updates: 113,314
Cumulative Timesteps: 944,996,202

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 944996202...
Checkpoint 944996202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 982.49080
Policy Entropy: 3.05922
Value Function Loss: 0.00510

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.13629
Policy Update Magnitude: 0.58052
Value Function Update Magnitude: 0.61455

Collected Steps per Second: 22,975.95602
Overall Steps per Second: 11,001.73760

Timestep Collection Time: 2.17654
Timestep Consumption Time: 2.36893
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.54546

Cumulative Model Updates: 113,320
Cumulative Timesteps: 945,046,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.65862
Policy Entropy: 3.07067
Value Function Loss: 0.00513

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.57712
Value Function Update Magnitude: 0.60769

Collected Steps per Second: 22,159.42394
Overall Steps per Second: 10,649.41746

Timestep Collection Time: 2.25647
Timestep Consumption Time: 2.43881
PPO Batch Consumption Time: 0.29376
Total Iteration Time: 4.69528

Cumulative Model Updates: 113,326
Cumulative Timesteps: 945,096,212

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 945096212...
Checkpoint 945096212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.40825
Policy Entropy: 3.09056
Value Function Loss: 0.00507

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.58086
Value Function Update Magnitude: 0.61588

Collected Steps per Second: 22,592.44410
Overall Steps per Second: 10,911.02355

Timestep Collection Time: 2.21313
Timestep Consumption Time: 2.36939
PPO Batch Consumption Time: 0.28299
Total Iteration Time: 4.58252

Cumulative Model Updates: 113,332
Cumulative Timesteps: 945,146,212

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.81263
Policy Entropy: 3.08295
Value Function Loss: 0.00554

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11479
Policy Update Magnitude: 0.58875
Value Function Update Magnitude: 0.62044

Collected Steps per Second: 21,726.92095
Overall Steps per Second: 10,514.13118

Timestep Collection Time: 2.30184
Timestep Consumption Time: 2.45480
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.75665

Cumulative Model Updates: 113,338
Cumulative Timesteps: 945,196,224

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 945196224...
Checkpoint 945196224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.76391
Policy Entropy: 3.09242
Value Function Loss: 0.00550

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.11787
Policy Update Magnitude: 0.59017
Value Function Update Magnitude: 0.62783

Collected Steps per Second: 22,087.92608
Overall Steps per Second: 10,632.38200

Timestep Collection Time: 2.26395
Timestep Consumption Time: 2.43923
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.70318

Cumulative Model Updates: 113,344
Cumulative Timesteps: 945,246,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770.03369
Policy Entropy: 3.09760
Value Function Loss: 0.00555

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.59141
Value Function Update Magnitude: 0.63619

Collected Steps per Second: 22,338.36209
Overall Steps per Second: 10,837.15776

Timestep Collection Time: 2.23893
Timestep Consumption Time: 2.37612
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.61505

Cumulative Model Updates: 113,350
Cumulative Timesteps: 945,296,244

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 945296244...
Checkpoint 945296244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.91742
Policy Entropy: 3.11262
Value Function Loss: 0.00500

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10039
Policy Update Magnitude: 0.58229
Value Function Update Magnitude: 0.62232

Collected Steps per Second: 21,952.97365
Overall Steps per Second: 10,762.14186

Timestep Collection Time: 2.27823
Timestep Consumption Time: 2.36898
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.64722

Cumulative Model Updates: 113,356
Cumulative Timesteps: 945,346,258

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 794.67629
Policy Entropy: 3.11663
Value Function Loss: 0.00495

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.10041
Policy Update Magnitude: 0.56911
Value Function Update Magnitude: 0.61137

Collected Steps per Second: 23,109.60168
Overall Steps per Second: 10,814.44213

Timestep Collection Time: 2.16430
Timestep Consumption Time: 2.46063
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.62493

Cumulative Model Updates: 113,362
Cumulative Timesteps: 945,396,274

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 945396274...
Checkpoint 945396274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.28689
Policy Entropy: 3.10992
Value Function Loss: 0.00487

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.59798

Collected Steps per Second: 22,701.25814
Overall Steps per Second: 10,666.05852

Timestep Collection Time: 2.20279
Timestep Consumption Time: 2.48554
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.68833

Cumulative Model Updates: 113,368
Cumulative Timesteps: 945,446,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,340.59297
Policy Entropy: 3.11984
Value Function Loss: 0.00501

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10035
Policy Update Magnitude: 0.56866
Value Function Update Magnitude: 0.61415

Collected Steps per Second: 23,368.52533
Overall Steps per Second: 10,924.97042

Timestep Collection Time: 2.14074
Timestep Consumption Time: 2.43831
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.57905

Cumulative Model Updates: 113,374
Cumulative Timesteps: 945,496,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 945496306...
Checkpoint 945496306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.76028
Policy Entropy: 3.10940
Value Function Loss: 0.00529

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10288
Policy Update Magnitude: 0.58172
Value Function Update Magnitude: 0.62615

Collected Steps per Second: 22,739.05943
Overall Steps per Second: 10,676.39262

Timestep Collection Time: 2.20009
Timestep Consumption Time: 2.48576
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.68585

Cumulative Model Updates: 113,380
Cumulative Timesteps: 945,546,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.10222
Policy Entropy: 3.11183
Value Function Loss: 0.00533

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11522
Policy Update Magnitude: 0.57471
Value Function Update Magnitude: 0.61998

Collected Steps per Second: 22,042.74235
Overall Steps per Second: 10,757.85811

Timestep Collection Time: 2.26886
Timestep Consumption Time: 2.38002
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.64888

Cumulative Model Updates: 113,386
Cumulative Timesteps: 945,596,346

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 945596346...
Checkpoint 945596346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.52413
Policy Entropy: 3.08726
Value Function Loss: 0.00514

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12097
Policy Update Magnitude: 0.56994
Value Function Update Magnitude: 0.62074

Collected Steps per Second: 22,106.65780
Overall Steps per Second: 10,731.19314

Timestep Collection Time: 2.26258
Timestep Consumption Time: 2.39842
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.66099

Cumulative Model Updates: 113,392
Cumulative Timesteps: 945,646,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,230.42313
Policy Entropy: 3.08954
Value Function Loss: 0.00491

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.56511
Value Function Update Magnitude: 0.61394

Collected Steps per Second: 22,717.95048
Overall Steps per Second: 10,646.80864

Timestep Collection Time: 2.20099
Timestep Consumption Time: 2.49544
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.69643

Cumulative Model Updates: 113,398
Cumulative Timesteps: 945,696,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 945696366...
Checkpoint 945696366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,877.57945
Policy Entropy: 3.09132
Value Function Loss: 0.00495

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.56529
Value Function Update Magnitude: 0.61589

Collected Steps per Second: 22,836.91144
Overall Steps per Second: 10,667.02721

Timestep Collection Time: 2.19031
Timestep Consumption Time: 2.49890
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.68922

Cumulative Model Updates: 113,404
Cumulative Timesteps: 945,746,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,048.78281
Policy Entropy: 3.11226
Value Function Loss: 0.00552

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11095
Policy Update Magnitude: 0.57397
Value Function Update Magnitude: 0.62294

Collected Steps per Second: 22,845.58795
Overall Steps per Second: 10,747.58827

Timestep Collection Time: 2.18861
Timestep Consumption Time: 2.46360
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.65221

Cumulative Model Updates: 113,410
Cumulative Timesteps: 945,796,386

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 945796386...
Checkpoint 945796386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.51089
Policy Entropy: 3.11918
Value Function Loss: 0.00537

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.57851
Value Function Update Magnitude: 0.65333

Collected Steps per Second: 22,683.68142
Overall Steps per Second: 10,588.03409

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.51889
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.72382

Cumulative Model Updates: 113,416
Cumulative Timesteps: 945,846,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,032.18562
Policy Entropy: 3.13083
Value Function Loss: 0.00525

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.57222
Value Function Update Magnitude: 0.64718

Collected Steps per Second: 22,415.46646
Overall Steps per Second: 10,905.84208

Timestep Collection Time: 2.23060
Timestep Consumption Time: 2.35410
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.58470

Cumulative Model Updates: 113,422
Cumulative Timesteps: 945,896,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 945896402...
Checkpoint 945896402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,208.87952
Policy Entropy: 3.11887
Value Function Loss: 0.00493

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10355
Policy Update Magnitude: 0.56489
Value Function Update Magnitude: 0.62758

Collected Steps per Second: 22,597.85448
Overall Steps per Second: 10,656.88331

Timestep Collection Time: 2.21410
Timestep Consumption Time: 2.48089
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.69499

Cumulative Model Updates: 113,428
Cumulative Timesteps: 945,946,436

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.38646
Policy Entropy: 3.12628
Value Function Loss: 0.00480

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09262
Policy Update Magnitude: 0.55907
Value Function Update Magnitude: 0.63196

Collected Steps per Second: 23,170.31091
Overall Steps per Second: 10,835.21014

Timestep Collection Time: 2.15880
Timestep Consumption Time: 2.45763
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.61643

Cumulative Model Updates: 113,434
Cumulative Timesteps: 945,996,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 945996456...
Checkpoint 945996456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,178.28586
Policy Entropy: 3.11847
Value Function Loss: 0.00477

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.56009
Value Function Update Magnitude: 0.62108

Collected Steps per Second: 22,767.04413
Overall Steps per Second: 10,734.23641

Timestep Collection Time: 2.19624
Timestep Consumption Time: 2.46193
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.65818

Cumulative Model Updates: 113,440
Cumulative Timesteps: 946,046,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.87635
Policy Entropy: 3.12781
Value Function Loss: 0.00512

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10396
Policy Update Magnitude: 0.56530
Value Function Update Magnitude: 0.61581

Collected Steps per Second: 22,904.23565
Overall Steps per Second: 10,768.60556

Timestep Collection Time: 2.18370
Timestep Consumption Time: 2.46091
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.64461

Cumulative Model Updates: 113,446
Cumulative Timesteps: 946,096,474

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 946096474...
Checkpoint 946096474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.28649
Policy Entropy: 3.13030
Value Function Loss: 0.00523

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11696
Policy Update Magnitude: 0.56654
Value Function Update Magnitude: 0.62534

Collected Steps per Second: 22,736.29088
Overall Steps per Second: 10,801.42642

Timestep Collection Time: 2.20036
Timestep Consumption Time: 2.43125
PPO Batch Consumption Time: 0.27950
Total Iteration Time: 4.63161

Cumulative Model Updates: 113,452
Cumulative Timesteps: 946,146,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.98949
Policy Entropy: 3.12512
Value Function Loss: 0.00527

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.56735
Value Function Update Magnitude: 0.62926

Collected Steps per Second: 23,150.10174
Overall Steps per Second: 10,871.83858

Timestep Collection Time: 2.16008
Timestep Consumption Time: 2.43951
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.59959

Cumulative Model Updates: 113,458
Cumulative Timesteps: 946,196,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 946196508...
Checkpoint 946196508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.14749
Policy Entropy: 3.11972
Value Function Loss: 0.00511

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10777
Policy Update Magnitude: 0.56703
Value Function Update Magnitude: 0.61185

Collected Steps per Second: 22,764.52791
Overall Steps per Second: 10,639.52640

Timestep Collection Time: 2.19640
Timestep Consumption Time: 2.50306
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.69946

Cumulative Model Updates: 113,464
Cumulative Timesteps: 946,246,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.89473
Policy Entropy: 3.10805
Value Function Loss: 0.00523

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 0.56504
Value Function Update Magnitude: 0.59931

Collected Steps per Second: 22,958.90618
Overall Steps per Second: 10,794.17774

Timestep Collection Time: 2.17780
Timestep Consumption Time: 2.45432
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.63213

Cumulative Model Updates: 113,470
Cumulative Timesteps: 946,296,508

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 946296508...
Checkpoint 946296508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.42928
Policy Entropy: 3.09823
Value Function Loss: 0.00518

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.12166
Policy Update Magnitude: 0.57503
Value Function Update Magnitude: 0.59478

Collected Steps per Second: 22,573.27273
Overall Steps per Second: 10,668.67833

Timestep Collection Time: 2.21510
Timestep Consumption Time: 2.47171
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.68680

Cumulative Model Updates: 113,476
Cumulative Timesteps: 946,346,510

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 938.79746
Policy Entropy: 3.09617
Value Function Loss: 0.00505

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.10962
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.59569

Collected Steps per Second: 22,752.53244
Overall Steps per Second: 10,651.53077

Timestep Collection Time: 2.19852
Timestep Consumption Time: 2.49770
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.69623

Cumulative Model Updates: 113,482
Cumulative Timesteps: 946,396,532

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 946396532...
Checkpoint 946396532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.38263
Policy Entropy: 3.08525
Value Function Loss: 0.00523

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09891
Policy Update Magnitude: 0.58038
Value Function Update Magnitude: 0.60908

Collected Steps per Second: 23,090.87499
Overall Steps per Second: 10,748.59943

Timestep Collection Time: 2.16640
Timestep Consumption Time: 2.48760
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.65400

Cumulative Model Updates: 113,488
Cumulative Timesteps: 946,446,556

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.21219
Policy Entropy: 3.07847
Value Function Loss: 0.00501

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10347
Policy Update Magnitude: 0.57992
Value Function Update Magnitude: 0.62534

Collected Steps per Second: 22,947.25385
Overall Steps per Second: 10,708.77110

Timestep Collection Time: 2.17943
Timestep Consumption Time: 2.49076
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.67019

Cumulative Model Updates: 113,494
Cumulative Timesteps: 946,496,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 946496568...
Checkpoint 946496568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700.38974
Policy Entropy: 3.09937
Value Function Loss: 0.00486

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.56903
Value Function Update Magnitude: 0.60908

Collected Steps per Second: 22,850.66501
Overall Steps per Second: 10,633.81776

Timestep Collection Time: 2.18873
Timestep Consumption Time: 2.51456
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.70330

Cumulative Model Updates: 113,500
Cumulative Timesteps: 946,546,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,717.46712
Policy Entropy: 3.10792
Value Function Loss: 0.00488

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.56700
Value Function Update Magnitude: 0.60593

Collected Steps per Second: 22,970.04395
Overall Steps per Second: 10,812.25276

Timestep Collection Time: 2.17710
Timestep Consumption Time: 2.44803
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.62512

Cumulative Model Updates: 113,506
Cumulative Timesteps: 946,596,590

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 946596590...
Checkpoint 946596590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.15512
Policy Entropy: 3.12085
Value Function Loss: 0.00496

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10312
Policy Update Magnitude: 0.57073
Value Function Update Magnitude: 0.61225

Collected Steps per Second: 22,624.10793
Overall Steps per Second: 10,717.85936

Timestep Collection Time: 2.21074
Timestep Consumption Time: 2.45586
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.66660

Cumulative Model Updates: 113,512
Cumulative Timesteps: 946,646,606

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.56166
Policy Entropy: 3.09915
Value Function Loss: 0.00514

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10887
Policy Update Magnitude: 0.56860
Value Function Update Magnitude: 0.61982

Collected Steps per Second: 23,172.81626
Overall Steps per Second: 10,846.19089

Timestep Collection Time: 2.15856
Timestep Consumption Time: 2.45319
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.61176

Cumulative Model Updates: 113,518
Cumulative Timesteps: 946,696,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 946696626...
Checkpoint 946696626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 669.87060
Policy Entropy: 3.10975
Value Function Loss: 0.00511

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.11220
Policy Update Magnitude: 0.57109
Value Function Update Magnitude: 0.61156

Collected Steps per Second: 22,571.75106
Overall Steps per Second: 10,776.27899

Timestep Collection Time: 2.21622
Timestep Consumption Time: 2.42583
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.64205

Cumulative Model Updates: 113,524
Cumulative Timesteps: 946,746,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800.16875
Policy Entropy: 3.10658
Value Function Loss: 0.00531

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.57466
Value Function Update Magnitude: 0.60627

Collected Steps per Second: 22,816.60422
Overall Steps per Second: 10,744.15589

Timestep Collection Time: 2.19191
Timestep Consumption Time: 2.46290
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.65481

Cumulative Model Updates: 113,530
Cumulative Timesteps: 946,796,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 946796662...
Checkpoint 946796662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.66974
Policy Entropy: 3.12108
Value Function Loss: 0.00523

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.08901
Policy Update Magnitude: 0.57822
Value Function Update Magnitude: 0.61720

Collected Steps per Second: 22,916.10455
Overall Steps per Second: 10,727.51668

Timestep Collection Time: 2.18222
Timestep Consumption Time: 2.47944
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.66166

Cumulative Model Updates: 113,536
Cumulative Timesteps: 946,846,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 850.49065
Policy Entropy: 3.10976
Value Function Loss: 0.00510

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.57723
Value Function Update Magnitude: 0.62547

Collected Steps per Second: 23,168.08103
Overall Steps per Second: 10,822.82891

Timestep Collection Time: 2.15840
Timestep Consumption Time: 2.46202
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.62042

Cumulative Model Updates: 113,542
Cumulative Timesteps: 946,896,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 946896676...
Checkpoint 946896676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.62933
Policy Entropy: 3.10930
Value Function Loss: 0.00504

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.57777
Value Function Update Magnitude: 0.61954

Collected Steps per Second: 22,831.00332
Overall Steps per Second: 10,711.28695

Timestep Collection Time: 2.19018
Timestep Consumption Time: 2.47817
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.66835

Cumulative Model Updates: 113,548
Cumulative Timesteps: 946,946,680

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,555.75281
Policy Entropy: 3.10952
Value Function Loss: 0.00506

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.11848
Policy Update Magnitude: 0.57405
Value Function Update Magnitude: 0.61269

Collected Steps per Second: 22,803.82560
Overall Steps per Second: 10,652.91408

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.50184
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.69524

Cumulative Model Updates: 113,554
Cumulative Timesteps: 946,996,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 946996698...
Checkpoint 946996698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.75215
Policy Entropy: 3.11385
Value Function Loss: 0.00495

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.57272
Value Function Update Magnitude: 0.61518

Collected Steps per Second: 23,008.52581
Overall Steps per Second: 10,800.43189

Timestep Collection Time: 2.17311
Timestep Consumption Time: 2.45634
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.62944

Cumulative Model Updates: 113,560
Cumulative Timesteps: 947,046,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.36825
Policy Entropy: 3.11004
Value Function Loss: 0.00499

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.57635
Value Function Update Magnitude: 0.60883

Collected Steps per Second: 22,845.87029
Overall Steps per Second: 10,579.58556

Timestep Collection Time: 2.18989
Timestep Consumption Time: 2.53903
PPO Batch Consumption Time: 0.29622
Total Iteration Time: 4.72892

Cumulative Model Updates: 113,566
Cumulative Timesteps: 947,096,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 947096728...
Checkpoint 947096728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.46496
Policy Entropy: 3.09534
Value Function Loss: 0.00494

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10374
Policy Update Magnitude: 0.57860
Value Function Update Magnitude: 0.61028

Collected Steps per Second: 22,430.05978
Overall Steps per Second: 10,579.90236

Timestep Collection Time: 2.22978
Timestep Consumption Time: 2.49749
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.72726

Cumulative Model Updates: 113,572
Cumulative Timesteps: 947,146,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.84798
Policy Entropy: 3.09091
Value Function Loss: 0.00483

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.57388
Value Function Update Magnitude: 0.60982

Collected Steps per Second: 22,786.12222
Overall Steps per Second: 10,817.76913

Timestep Collection Time: 2.19458
Timestep Consumption Time: 2.42800
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.62258

Cumulative Model Updates: 113,578
Cumulative Timesteps: 947,196,748

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 947196748...
Checkpoint 947196748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.05308
Policy Entropy: 3.09686
Value Function Loss: 0.00463

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10433
Policy Update Magnitude: 0.55999
Value Function Update Magnitude: 0.59220

Collected Steps per Second: 22,715.93202
Overall Steps per Second: 10,765.16928

Timestep Collection Time: 2.20224
Timestep Consumption Time: 2.44478
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.64702

Cumulative Model Updates: 113,584
Cumulative Timesteps: 947,246,774

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 958.36911
Policy Entropy: 3.09888
Value Function Loss: 0.00466

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.55271
Value Function Update Magnitude: 0.58955

Collected Steps per Second: 23,051.33629
Overall Steps per Second: 10,896.52839

Timestep Collection Time: 2.16942
Timestep Consumption Time: 2.41993
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.58935

Cumulative Model Updates: 113,590
Cumulative Timesteps: 947,296,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 947296782...
Checkpoint 947296782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,325.99852
Policy Entropy: 3.08766
Value Function Loss: 0.00469

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.55769
Value Function Update Magnitude: 0.59415

Collected Steps per Second: 22,637.07284
Overall Steps per Second: 10,667.39855

Timestep Collection Time: 2.21009
Timestep Consumption Time: 2.47990
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.68999

Cumulative Model Updates: 113,596
Cumulative Timesteps: 947,346,812

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 940.33708
Policy Entropy: 3.09191
Value Function Loss: 0.00510

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.56988
Value Function Update Magnitude: 0.60176

Collected Steps per Second: 22,840.49676
Overall Steps per Second: 10,807.73536

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.43761
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.62706

Cumulative Model Updates: 113,602
Cumulative Timesteps: 947,396,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 947396820...
Checkpoint 947396820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.15216
Policy Entropy: 3.10771
Value Function Loss: 0.00522

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09792
Policy Update Magnitude: 0.57583
Value Function Update Magnitude: 0.61310

Collected Steps per Second: 22,604.79064
Overall Steps per Second: 10,706.17083

Timestep Collection Time: 2.21272
Timestep Consumption Time: 2.45917
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.67189

Cumulative Model Updates: 113,608
Cumulative Timesteps: 947,446,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.96082
Policy Entropy: 3.11535
Value Function Loss: 0.00503

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.56988
Value Function Update Magnitude: 0.62432

Collected Steps per Second: 22,986.74304
Overall Steps per Second: 10,841.55735

Timestep Collection Time: 2.17534
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.61225

Cumulative Model Updates: 113,614
Cumulative Timesteps: 947,496,842

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 947496842...
Checkpoint 947496842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.06562
Policy Entropy: 3.12692
Value Function Loss: 0.00475

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09719
Policy Update Magnitude: 0.55853
Value Function Update Magnitude: 0.60407

Collected Steps per Second: 22,595.74886
Overall Steps per Second: 10,760.48728

Timestep Collection Time: 2.21413
Timestep Consumption Time: 2.43528
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.64942

Cumulative Model Updates: 113,620
Cumulative Timesteps: 947,546,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.55998
Policy Entropy: 3.12223
Value Function Loss: 0.00480

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10045
Policy Update Magnitude: 0.55769
Value Function Update Magnitude: 0.61339

Collected Steps per Second: 23,074.62745
Overall Steps per Second: 10,900.68994

Timestep Collection Time: 2.16766
Timestep Consumption Time: 2.42085
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.58852

Cumulative Model Updates: 113,626
Cumulative Timesteps: 947,596,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 947596890...
Checkpoint 947596890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,760.34470
Policy Entropy: 3.11759
Value Function Loss: 0.00478

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10932
Policy Update Magnitude: 0.56686
Value Function Update Magnitude: 0.64244

Collected Steps per Second: 22,835.20808
Overall Steps per Second: 10,591.63912

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.53201
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.72240

Cumulative Model Updates: 113,632
Cumulative Timesteps: 947,646,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,582.39984
Policy Entropy: 3.10030
Value Function Loss: 0.00472

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.11573
Policy Update Magnitude: 0.56760
Value Function Update Magnitude: 0.65160

Collected Steps per Second: 22,917.36782
Overall Steps per Second: 10,702.78062

Timestep Collection Time: 2.18271
Timestep Consumption Time: 2.49103
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.67374

Cumulative Model Updates: 113,638
Cumulative Timesteps: 947,696,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 947696930...
Checkpoint 947696930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,458.79064
Policy Entropy: 3.08114
Value Function Loss: 0.00478

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.57064
Value Function Update Magnitude: 0.63687

Collected Steps per Second: 22,657.50277
Overall Steps per Second: 10,782.68091

Timestep Collection Time: 2.20686
Timestep Consumption Time: 2.43039
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.63725

Cumulative Model Updates: 113,644
Cumulative Timesteps: 947,746,932

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,398.85154
Policy Entropy: 3.08500
Value Function Loss: 0.00490

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11920
Policy Update Magnitude: 0.57806
Value Function Update Magnitude: 0.64054

Collected Steps per Second: 23,048.42127
Overall Steps per Second: 10,880.73484

Timestep Collection Time: 2.16961
Timestep Consumption Time: 2.42622
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.59583

Cumulative Model Updates: 113,650
Cumulative Timesteps: 947,796,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 947796938...
Checkpoint 947796938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.99378
Policy Entropy: 3.07516
Value Function Loss: 0.00499

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.57623
Value Function Update Magnitude: 0.65071

Collected Steps per Second: 22,528.15344
Overall Steps per Second: 10,765.20237

Timestep Collection Time: 2.22069
Timestep Consumption Time: 2.42651
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.64720

Cumulative Model Updates: 113,656
Cumulative Timesteps: 947,846,966

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,079.28367
Policy Entropy: 3.07935
Value Function Loss: 0.00521

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.57218
Value Function Update Magnitude: 0.66009

Collected Steps per Second: 23,124.08474
Overall Steps per Second: 10,902.87594

Timestep Collection Time: 2.16346
Timestep Consumption Time: 2.42506
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.58851

Cumulative Model Updates: 113,662
Cumulative Timesteps: 947,896,994

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 947896994...
Checkpoint 947896994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.54253
Policy Entropy: 3.09054
Value Function Loss: 0.00531

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.12007
Policy Update Magnitude: 0.58132
Value Function Update Magnitude: 0.66861

Collected Steps per Second: 22,407.47655
Overall Steps per Second: 10,649.85149

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.46478
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.69734

Cumulative Model Updates: 113,668
Cumulative Timesteps: 947,947,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033.63976
Policy Entropy: 3.09751
Value Function Loss: 0.00540

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10144
Policy Update Magnitude: 0.58951
Value Function Update Magnitude: 0.66806

Collected Steps per Second: 23,010.65145
Overall Steps per Second: 10,846.58401

Timestep Collection Time: 2.17421
Timestep Consumption Time: 2.43830
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.61251

Cumulative Model Updates: 113,674
Cumulative Timesteps: 947,997,050

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 947997050...
Checkpoint 947997050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742.20679
Policy Entropy: 3.09464
Value Function Loss: 0.00538

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11007
Policy Update Magnitude: 0.59135
Value Function Update Magnitude: 0.65906

Collected Steps per Second: 22,690.47497
Overall Steps per Second: 10,691.62725

Timestep Collection Time: 2.20357
Timestep Consumption Time: 2.47299
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.67656

Cumulative Model Updates: 113,680
Cumulative Timesteps: 948,047,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.13437
Policy Entropy: 3.10428
Value Function Loss: 0.00514

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10146
Policy Update Magnitude: 0.58320
Value Function Update Magnitude: 0.64407

Collected Steps per Second: 23,019.20199
Overall Steps per Second: 10,845.98722

Timestep Collection Time: 2.17332
Timestep Consumption Time: 2.43927
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.61258

Cumulative Model Updates: 113,686
Cumulative Timesteps: 948,097,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 948097078...
Checkpoint 948097078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,359.68603
Policy Entropy: 3.11243
Value Function Loss: 0.00500

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.57377
Value Function Update Magnitude: 0.62877

Collected Steps per Second: 22,782.29884
Overall Steps per Second: 10,711.21174

Timestep Collection Time: 2.19495
Timestep Consumption Time: 2.47362
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.66857

Cumulative Model Updates: 113,692
Cumulative Timesteps: 948,147,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.81421
Policy Entropy: 3.11029
Value Function Loss: 0.00521

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10008
Policy Update Magnitude: 0.57857
Value Function Update Magnitude: 0.61600

Collected Steps per Second: 23,081.59608
Overall Steps per Second: 10,859.14132

Timestep Collection Time: 2.16744
Timestep Consumption Time: 2.43955
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.60699

Cumulative Model Updates: 113,698
Cumulative Timesteps: 948,197,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 948197112...
Checkpoint 948197112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.41904
Policy Entropy: 3.08867
Value Function Loss: 0.00541

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10317
Policy Update Magnitude: 0.59221
Value Function Update Magnitude: 0.62750

Collected Steps per Second: 22,741.17992
Overall Steps per Second: 10,759.98068

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.44966
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.64964

Cumulative Model Updates: 113,704
Cumulative Timesteps: 948,247,142

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,396.17805
Policy Entropy: 3.09193
Value Function Loss: 0.00539

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.09737
Policy Update Magnitude: 0.59842
Value Function Update Magnitude: 0.62726

Collected Steps per Second: 22,435.75166
Overall Steps per Second: 10,893.19233

Timestep Collection Time: 2.22939
Timestep Consumption Time: 2.36229
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.59168

Cumulative Model Updates: 113,710
Cumulative Timesteps: 948,297,160

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 948297160...
Checkpoint 948297160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.08363
Policy Entropy: 3.11036
Value Function Loss: 0.00534

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10914
Policy Update Magnitude: 0.59013
Value Function Update Magnitude: 0.62830

Collected Steps per Second: 22,151.68351
Overall Steps per Second: 10,625.44309

Timestep Collection Time: 2.25843
Timestep Consumption Time: 2.44989
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 4.70832

Cumulative Model Updates: 113,716
Cumulative Timesteps: 948,347,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.53378
Policy Entropy: 3.10004
Value Function Loss: 0.00534

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10357
Policy Update Magnitude: 0.58551
Value Function Update Magnitude: 0.63512

Collected Steps per Second: 22,034.23054
Overall Steps per Second: 10,770.00057

Timestep Collection Time: 2.27019
Timestep Consumption Time: 2.37437
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.64457

Cumulative Model Updates: 113,722
Cumulative Timesteps: 948,397,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 948397210...
Checkpoint 948397210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.69983
Policy Entropy: 3.09344
Value Function Loss: 0.00539

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.11831
Policy Update Magnitude: 0.59447
Value Function Update Magnitude: 0.65450

Collected Steps per Second: 21,965.85485
Overall Steps per Second: 10,729.37916

Timestep Collection Time: 2.27672
Timestep Consumption Time: 2.38432
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.66103

Cumulative Model Updates: 113,728
Cumulative Timesteps: 948,447,220

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,297.97581
Policy Entropy: 3.08286
Value Function Loss: 0.00554

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11749
Policy Update Magnitude: 0.59920
Value Function Update Magnitude: 0.66270

Collected Steps per Second: 23,188.75142
Overall Steps per Second: 10,845.97758

Timestep Collection Time: 2.15699
Timestep Consumption Time: 2.45467
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.61166

Cumulative Model Updates: 113,734
Cumulative Timesteps: 948,497,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 948497238...
Checkpoint 948497238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.42398
Policy Entropy: 3.08500
Value Function Loss: 0.00555

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11408
Policy Update Magnitude: 0.59538
Value Function Update Magnitude: 0.67475

Collected Steps per Second: 22,471.48090
Overall Steps per Second: 10,734.18295

Timestep Collection Time: 2.22513
Timestep Consumption Time: 2.43307
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.65820

Cumulative Model Updates: 113,740
Cumulative Timesteps: 948,547,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 756.15714
Policy Entropy: 3.07803
Value Function Loss: 0.00571

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.59706
Value Function Update Magnitude: 0.67786

Collected Steps per Second: 23,017.57734
Overall Steps per Second: 10,803.24320

Timestep Collection Time: 2.17347
Timestep Consumption Time: 2.45736
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.63083

Cumulative Model Updates: 113,746
Cumulative Timesteps: 948,597,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 948597268...
Checkpoint 948597268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,122.19244
Policy Entropy: 3.08005
Value Function Loss: 0.00542

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.59882
Value Function Update Magnitude: 0.66712

Collected Steps per Second: 22,751.96189
Overall Steps per Second: 10,695.71283

Timestep Collection Time: 2.19796
Timestep Consumption Time: 2.47755
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.67552

Cumulative Model Updates: 113,752
Cumulative Timesteps: 948,647,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 929.49033
Policy Entropy: 3.08584
Value Function Loss: 0.00536

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.58943
Value Function Update Magnitude: 0.66714

Collected Steps per Second: 23,025.31795
Overall Steps per Second: 10,711.02543

Timestep Collection Time: 2.17213
Timestep Consumption Time: 2.49726
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.66939

Cumulative Model Updates: 113,758
Cumulative Timesteps: 948,697,290

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 948697290...
Checkpoint 948697290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,163.11014
Policy Entropy: 3.08876
Value Function Loss: 0.00515

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.58398
Value Function Update Magnitude: 0.66387

Collected Steps per Second: 22,834.56167
Overall Steps per Second: 10,808.92705

Timestep Collection Time: 2.18984
Timestep Consumption Time: 2.43634
PPO Batch Consumption Time: 0.28203
Total Iteration Time: 4.62618

Cumulative Model Updates: 113,764
Cumulative Timesteps: 948,747,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 759.61104
Policy Entropy: 3.07239
Value Function Loss: 0.00564

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.59033
Value Function Update Magnitude: 0.66193

Collected Steps per Second: 22,915.22882
Overall Steps per Second: 10,666.31756

Timestep Collection Time: 2.18309
Timestep Consumption Time: 2.50700
PPO Batch Consumption Time: 0.29272
Total Iteration Time: 4.69009

Cumulative Model Updates: 113,770
Cumulative Timesteps: 948,797,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 948797320...
Checkpoint 948797320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.30982
Policy Entropy: 3.06533
Value Function Loss: 0.00568

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.11342
Policy Update Magnitude: 0.59802
Value Function Update Magnitude: 0.67059

Collected Steps per Second: 22,825.17475
Overall Steps per Second: 10,662.84738

Timestep Collection Time: 2.19083
Timestep Consumption Time: 2.49892
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.68974

Cumulative Model Updates: 113,776
Cumulative Timesteps: 948,847,326

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.11294
Policy Entropy: 3.06595
Value Function Loss: 0.00568

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.59866
Value Function Update Magnitude: 0.67480

Collected Steps per Second: 23,143.76922
Overall Steps per Second: 10,770.60256

Timestep Collection Time: 2.16050
Timestep Consumption Time: 2.48196
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.64245

Cumulative Model Updates: 113,782
Cumulative Timesteps: 948,897,328

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 948897328...
Checkpoint 948897328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 973.54094
Policy Entropy: 3.06803
Value Function Loss: 0.00544

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10129
Policy Update Magnitude: 0.59344
Value Function Update Magnitude: 0.65374

Collected Steps per Second: 22,604.42296
Overall Steps per Second: 10,597.10315

Timestep Collection Time: 2.21231
Timestep Consumption Time: 2.50672
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.71903

Cumulative Model Updates: 113,788
Cumulative Timesteps: 948,947,336

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.95039
Policy Entropy: 3.07742
Value Function Loss: 0.00527

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.59114
Value Function Update Magnitude: 0.63604

Collected Steps per Second: 22,779.65227
Overall Steps per Second: 10,650.86391

Timestep Collection Time: 2.19564
Timestep Consumption Time: 2.50031
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.69596

Cumulative Model Updates: 113,794
Cumulative Timesteps: 948,997,352

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 948997352...
Checkpoint 948997352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620.64693
Policy Entropy: 3.08195
Value Function Loss: 0.00541

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11384
Policy Update Magnitude: 0.59294
Value Function Update Magnitude: 0.65236

Collected Steps per Second: 22,798.32584
Overall Steps per Second: 10,788.77517

Timestep Collection Time: 2.19385
Timestep Consumption Time: 2.44208
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.63593

Cumulative Model Updates: 113,800
Cumulative Timesteps: 949,047,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.62453
Policy Entropy: 3.08814
Value Function Loss: 0.00504

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11728
Policy Update Magnitude: 0.59058
Value Function Update Magnitude: 0.66708

Collected Steps per Second: 23,051.06767
Overall Steps per Second: 10,776.88388

Timestep Collection Time: 2.16988
Timestep Consumption Time: 2.47135
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.64123

Cumulative Model Updates: 113,806
Cumulative Timesteps: 949,097,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 949097386...
Checkpoint 949097386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.68329
Policy Entropy: 3.07970
Value Function Loss: 0.00510

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.57813
Value Function Update Magnitude: 0.64111

Collected Steps per Second: 22,578.48665
Overall Steps per Second: 10,604.68616

Timestep Collection Time: 2.21494
Timestep Consumption Time: 2.50090
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.71584

Cumulative Model Updates: 113,812
Cumulative Timesteps: 949,147,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,581.60760
Policy Entropy: 3.07122
Value Function Loss: 0.00513

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.57136
Value Function Update Magnitude: 0.59745

Collected Steps per Second: 23,011.03909
Overall Steps per Second: 10,723.56080

Timestep Collection Time: 2.17374
Timestep Consumption Time: 2.49076
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.66450

Cumulative Model Updates: 113,818
Cumulative Timesteps: 949,197,416

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 949197416...
Checkpoint 949197416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.09085
Policy Entropy: 3.07805
Value Function Loss: 0.00522

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10068
Policy Update Magnitude: 0.57429
Value Function Update Magnitude: 0.58158

Collected Steps per Second: 22,348.15343
Overall Steps per Second: 10,685.34920

Timestep Collection Time: 2.23750
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.67968

Cumulative Model Updates: 113,824
Cumulative Timesteps: 949,247,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.88009
Policy Entropy: 3.06712
Value Function Loss: 0.00536

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10703
Policy Update Magnitude: 0.58372
Value Function Update Magnitude: 0.58956

Collected Steps per Second: 22,704.44646
Overall Steps per Second: 10,729.70879

Timestep Collection Time: 2.20300
Timestep Consumption Time: 2.45863
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.66164

Cumulative Model Updates: 113,830
Cumulative Timesteps: 949,297,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 949297438...
Checkpoint 949297438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,131.54854
Policy Entropy: 3.08393
Value Function Loss: 0.00499

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.57810
Value Function Update Magnitude: 0.59002

Collected Steps per Second: 22,537.51892
Overall Steps per Second: 10,731.48745

Timestep Collection Time: 2.21870
Timestep Consumption Time: 2.44086
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.65956

Cumulative Model Updates: 113,836
Cumulative Timesteps: 949,347,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.48200
Policy Entropy: 3.08966
Value Function Loss: 0.00486

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09994
Policy Update Magnitude: 0.56922
Value Function Update Magnitude: 0.57407

Collected Steps per Second: 22,623.40694
Overall Steps per Second: 10,514.45618

Timestep Collection Time: 2.21081
Timestep Consumption Time: 2.54607
PPO Batch Consumption Time: 0.29627
Total Iteration Time: 4.75688

Cumulative Model Updates: 113,842
Cumulative Timesteps: 949,397,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 949397458...
Checkpoint 949397458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,935.93170
Policy Entropy: 3.09672
Value Function Loss: 0.00497

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.56844
Value Function Update Magnitude: 0.58386

Collected Steps per Second: 22,700.51917
Overall Steps per Second: 10,610.13744

Timestep Collection Time: 2.20268
Timestep Consumption Time: 2.50998
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.71266

Cumulative Model Updates: 113,848
Cumulative Timesteps: 949,447,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.93204
Policy Entropy: 3.08571
Value Function Loss: 0.00515

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10313
Policy Update Magnitude: 0.57635
Value Function Update Magnitude: 0.60063

Collected Steps per Second: 23,065.57857
Overall Steps per Second: 10,886.79801

Timestep Collection Time: 2.16947
Timestep Consumption Time: 2.42693
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.59639

Cumulative Model Updates: 113,854
Cumulative Timesteps: 949,497,500

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 949497500...
Checkpoint 949497500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911.98158
Policy Entropy: 3.08375
Value Function Loss: 0.00493

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.11935
Policy Update Magnitude: 0.57673
Value Function Update Magnitude: 0.61912

Collected Steps per Second: 22,435.30467
Overall Steps per Second: 10,629.62728

Timestep Collection Time: 2.22881
Timestep Consumption Time: 2.47540
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.70421

Cumulative Model Updates: 113,860
Cumulative Timesteps: 949,547,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.93187
Policy Entropy: 3.07989
Value Function Loss: 0.00499

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.11904
Policy Update Magnitude: 0.56815
Value Function Update Magnitude: 0.60470

Collected Steps per Second: 22,613.61197
Overall Steps per Second: 10,568.86846

Timestep Collection Time: 2.21177
Timestep Consumption Time: 2.52062
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.73239

Cumulative Model Updates: 113,866
Cumulative Timesteps: 949,597,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 949597520...
Checkpoint 949597520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,295.20816
Policy Entropy: 3.09270
Value Function Loss: 0.00493

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.56146
Value Function Update Magnitude: 0.59496

Collected Steps per Second: 22,606.55086
Overall Steps per Second: 10,635.35150

Timestep Collection Time: 2.21316
Timestep Consumption Time: 2.49115
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.70431

Cumulative Model Updates: 113,872
Cumulative Timesteps: 949,647,552

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,026.58543
Policy Entropy: 3.09277
Value Function Loss: 0.00534

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.56810
Value Function Update Magnitude: 0.60037

Collected Steps per Second: 23,198.09151
Overall Steps per Second: 10,849.52313

Timestep Collection Time: 2.15647
Timestep Consumption Time: 2.45442
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.61089

Cumulative Model Updates: 113,878
Cumulative Timesteps: 949,697,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 949697578...
Checkpoint 949697578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,695.64916
Policy Entropy: 3.08618
Value Function Loss: 0.00527

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12560
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.61721

Collected Steps per Second: 22,426.49350
Overall Steps per Second: 10,649.81413

Timestep Collection Time: 2.23004
Timestep Consumption Time: 2.46600
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.69604

Cumulative Model Updates: 113,884
Cumulative Timesteps: 949,747,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256.21572
Policy Entropy: 3.09069
Value Function Loss: 0.00516

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.61739

Collected Steps per Second: 23,099.16436
Overall Steps per Second: 10,915.20550

Timestep Collection Time: 2.16545
Timestep Consumption Time: 2.41715
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.58260

Cumulative Model Updates: 113,890
Cumulative Timesteps: 949,797,610

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 949797610...
Checkpoint 949797610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,469.11012
Policy Entropy: 3.06878
Value Function Loss: 0.00522

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11401
Policy Update Magnitude: 0.56736
Value Function Update Magnitude: 0.60717

Collected Steps per Second: 22,349.62537
Overall Steps per Second: 10,628.66638

Timestep Collection Time: 2.23762
Timestep Consumption Time: 2.46758
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.70520

Cumulative Model Updates: 113,896
Cumulative Timesteps: 949,847,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.84698
Policy Entropy: 3.07946
Value Function Loss: 0.00515

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.56882
Value Function Update Magnitude: 0.59146

Collected Steps per Second: 22,822.55962
Overall Steps per Second: 10,826.06049

Timestep Collection Time: 2.19152
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.61996

Cumulative Model Updates: 113,902
Cumulative Timesteps: 949,897,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 949897636...
Checkpoint 949897636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.17863
Policy Entropy: 3.06734
Value Function Loss: 0.00517

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.57669
Value Function Update Magnitude: 0.59268

Collected Steps per Second: 22,520.89206
Overall Steps per Second: 10,730.68560

Timestep Collection Time: 2.22123
Timestep Consumption Time: 2.44054
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.66177

Cumulative Model Updates: 113,908
Cumulative Timesteps: 949,947,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,730.58580
Policy Entropy: 3.06871
Value Function Loss: 0.00487

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11183
Policy Update Magnitude: 0.57335
Value Function Update Magnitude: 0.59112

Collected Steps per Second: 22,954.12378
Overall Steps per Second: 10,839.57003

Timestep Collection Time: 2.17930
Timestep Consumption Time: 2.43564
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.61494

Cumulative Model Updates: 113,914
Cumulative Timesteps: 949,997,684

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 949997684...
Checkpoint 949997684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.27084
Policy Entropy: 3.05639
Value Function Loss: 0.00468

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10849
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.58626

Collected Steps per Second: 22,976.69522
Overall Steps per Second: 10,689.26093

Timestep Collection Time: 2.17690
Timestep Consumption Time: 2.50237
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.67928

Cumulative Model Updates: 113,920
Cumulative Timesteps: 950,047,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,442.40595
Policy Entropy: 3.05744
Value Function Loss: 0.00472

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10789
Policy Update Magnitude: 0.56426
Value Function Update Magnitude: 0.56304

Collected Steps per Second: 22,746.52128
Overall Steps per Second: 10,843.89121

Timestep Collection Time: 2.19946
Timestep Consumption Time: 2.41420
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.61366

Cumulative Model Updates: 113,926
Cumulative Timesteps: 950,097,732

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 950097732...
Checkpoint 950097732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.35914
Policy Entropy: 3.08327
Value Function Loss: 0.00471

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10248
Policy Update Magnitude: 0.56262
Value Function Update Magnitude: 0.55434

Collected Steps per Second: 22,461.14720
Overall Steps per Second: 10,782.31726

Timestep Collection Time: 2.22696
Timestep Consumption Time: 2.41212
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.63908

Cumulative Model Updates: 113,932
Cumulative Timesteps: 950,147,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,194.82906
Policy Entropy: 3.09204
Value Function Loss: 0.00480

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.55845
Value Function Update Magnitude: 0.56762

Collected Steps per Second: 22,731.27668
Overall Steps per Second: 10,799.73082

Timestep Collection Time: 2.20067
Timestep Consumption Time: 2.43130
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.63197

Cumulative Model Updates: 113,938
Cumulative Timesteps: 950,197,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 950197776...
Checkpoint 950197776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.23355
Policy Entropy: 3.08761
Value Function Loss: 0.00470

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10559
Policy Update Magnitude: 0.56676
Value Function Update Magnitude: 0.57285

Collected Steps per Second: 22,614.84380
Overall Steps per Second: 10,683.34092

Timestep Collection Time: 2.21111
Timestep Consumption Time: 2.46944
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.68056

Cumulative Model Updates: 113,944
Cumulative Timesteps: 950,247,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.96513
Policy Entropy: 3.08476
Value Function Loss: 0.00453

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.56120
Value Function Update Magnitude: 0.59882

Collected Steps per Second: 23,089.26754
Overall Steps per Second: 10,887.11885

Timestep Collection Time: 2.16603
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.59369

Cumulative Model Updates: 113,950
Cumulative Timesteps: 950,297,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 950297792...
Checkpoint 950297792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 804.19416
Policy Entropy: 3.08580
Value Function Loss: 0.00453

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.55774
Value Function Update Magnitude: 0.60414

Collected Steps per Second: 22,392.72518
Overall Steps per Second: 10,647.19783

Timestep Collection Time: 2.23394
Timestep Consumption Time: 2.46439
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.69833

Cumulative Model Updates: 113,956
Cumulative Timesteps: 950,347,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.28700
Policy Entropy: 3.08116
Value Function Loss: 0.00463

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09596
Policy Update Magnitude: 0.56215
Value Function Update Magnitude: 0.60163

Collected Steps per Second: 23,025.27302
Overall Steps per Second: 10,845.36258

Timestep Collection Time: 2.17222
Timestep Consumption Time: 2.43952
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.61174

Cumulative Model Updates: 113,962
Cumulative Timesteps: 950,397,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 950397832...
Checkpoint 950397832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.85603
Policy Entropy: 3.08250
Value Function Loss: 0.00492

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09627
Policy Update Magnitude: 0.56847
Value Function Update Magnitude: 0.60565

Collected Steps per Second: 22,597.37534
Overall Steps per Second: 10,739.21727

Timestep Collection Time: 2.21344
Timestep Consumption Time: 2.44407
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.65751

Cumulative Model Updates: 113,968
Cumulative Timesteps: 950,447,850

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,269.36135
Policy Entropy: 3.08531
Value Function Loss: 0.00504

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.57759
Value Function Update Magnitude: 0.61714

Collected Steps per Second: 22,776.96756
Overall Steps per Second: 10,802.30342

Timestep Collection Time: 2.19590
Timestep Consumption Time: 2.43422
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.63012

Cumulative Model Updates: 113,974
Cumulative Timesteps: 950,497,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 950497866...
Checkpoint 950497866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.66644
Policy Entropy: 3.08610
Value Function Loss: 0.00489

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.62604

Collected Steps per Second: 22,684.00009
Overall Steps per Second: 10,768.07822

Timestep Collection Time: 2.20552
Timestep Consumption Time: 2.44062
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.64614

Cumulative Model Updates: 113,980
Cumulative Timesteps: 950,547,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.11891
Policy Entropy: 3.10051
Value Function Loss: 0.00486

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09734
Policy Update Magnitude: 0.56593
Value Function Update Magnitude: 0.61142

Collected Steps per Second: 23,065.23191
Overall Steps per Second: 10,857.56556

Timestep Collection Time: 2.16863
Timestep Consumption Time: 2.43829
PPO Batch Consumption Time: 0.28255
Total Iteration Time: 4.60693

Cumulative Model Updates: 113,986
Cumulative Timesteps: 950,597,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 950597916...
Checkpoint 950597916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.83674
Policy Entropy: 3.08448
Value Function Loss: 0.00516

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10811
Policy Update Magnitude: 0.56882
Value Function Update Magnitude: 0.60305

Collected Steps per Second: 22,911.16181
Overall Steps per Second: 10,639.34366

Timestep Collection Time: 2.18243
Timestep Consumption Time: 2.51730
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.69973

Cumulative Model Updates: 113,992
Cumulative Timesteps: 950,647,918

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.95547
Policy Entropy: 3.09634
Value Function Loss: 0.00498

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.08682
Policy Update Magnitude: 0.56824
Value Function Update Magnitude: 0.60289

Collected Steps per Second: 22,810.92841
Overall Steps per Second: 10,839.53546

Timestep Collection Time: 2.19281
Timestep Consumption Time: 2.42178
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.61459

Cumulative Model Updates: 113,998
Cumulative Timesteps: 950,697,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 950697938...
Checkpoint 950697938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.78740
Policy Entropy: 3.09034
Value Function Loss: 0.00488

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09456
Policy Update Magnitude: 0.56366
Value Function Update Magnitude: 0.60182

Collected Steps per Second: 22,153.27533
Overall Steps per Second: 10,685.15194

Timestep Collection Time: 2.25791
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.68126

Cumulative Model Updates: 114,004
Cumulative Timesteps: 950,747,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.56528
Policy Entropy: 3.07865
Value Function Loss: 0.00497

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.10004
Policy Update Magnitude: 0.57319
Value Function Update Magnitude: 0.60884

Collected Steps per Second: 22,783.31365
Overall Steps per Second: 10,632.85607

Timestep Collection Time: 2.19503
Timestep Consumption Time: 2.50832
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.70335

Cumulative Model Updates: 114,010
Cumulative Timesteps: 950,797,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 950797968...
Checkpoint 950797968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.55386
Policy Entropy: 3.07981
Value Function Loss: 0.00496

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.09704
Policy Update Magnitude: 0.58319
Value Function Update Magnitude: 0.62350

Collected Steps per Second: 22,537.38915
Overall Steps per Second: 10,648.80818

Timestep Collection Time: 2.21898
Timestep Consumption Time: 2.47732
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.69630

Cumulative Model Updates: 114,016
Cumulative Timesteps: 950,847,978

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695.71195
Policy Entropy: 3.07382
Value Function Loss: 0.00489

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10066
Policy Update Magnitude: 0.58272
Value Function Update Magnitude: 0.63229

Collected Steps per Second: 23,259.06377
Overall Steps per Second: 10,767.56882

Timestep Collection Time: 2.15039
Timestep Consumption Time: 2.49467
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.64506

Cumulative Model Updates: 114,022
Cumulative Timesteps: 950,897,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 950897994...
Checkpoint 950897994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.60878
Policy Entropy: 3.07752
Value Function Loss: 0.00457

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10893
Policy Update Magnitude: 0.56805
Value Function Update Magnitude: 0.61959

Collected Steps per Second: 22,468.68208
Overall Steps per Second: 10,639.20911

Timestep Collection Time: 2.22559
Timestep Consumption Time: 2.47457
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.70016

Cumulative Model Updates: 114,028
Cumulative Timesteps: 950,948,000

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,755.24270
Policy Entropy: 3.07041
Value Function Loss: 0.00470

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.12052
Policy Update Magnitude: 0.56591
Value Function Update Magnitude: 0.59846

Collected Steps per Second: 23,018.22997
Overall Steps per Second: 10,868.64065

Timestep Collection Time: 2.17323
Timestep Consumption Time: 2.42937
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.60260

Cumulative Model Updates: 114,034
Cumulative Timesteps: 950,998,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 950998024...
Checkpoint 950998024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 636.81304
Policy Entropy: 3.06737
Value Function Loss: 0.00500

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12258
Policy Update Magnitude: 0.57532
Value Function Update Magnitude: 0.58888

Collected Steps per Second: 22,629.23005
Overall Steps per Second: 10,695.61165

Timestep Collection Time: 2.21024
Timestep Consumption Time: 2.46607
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.67631

Cumulative Model Updates: 114,040
Cumulative Timesteps: 951,048,040

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660.50679
Policy Entropy: 3.06882
Value Function Loss: 0.00530

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.11933
Policy Update Magnitude: 0.58581
Value Function Update Magnitude: 0.60776

Collected Steps per Second: 23,160.74502
Overall Steps per Second: 10,878.15636

Timestep Collection Time: 2.15883
Timestep Consumption Time: 2.43754
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.59637

Cumulative Model Updates: 114,046
Cumulative Timesteps: 951,098,040

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 951098040...
Checkpoint 951098040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,335.07188
Policy Entropy: 3.05612
Value Function Loss: 0.00536

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.58571
Value Function Update Magnitude: 0.62500

Collected Steps per Second: 22,518.31216
Overall Steps per Second: 10,665.41773

Timestep Collection Time: 2.22157
Timestep Consumption Time: 2.46892
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.69049

Cumulative Model Updates: 114,052
Cumulative Timesteps: 951,148,066

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.60330
Policy Entropy: 3.05940
Value Function Loss: 0.00532

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.58127
Value Function Update Magnitude: 0.64177

Collected Steps per Second: 23,198.97043
Overall Steps per Second: 10,867.45567

Timestep Collection Time: 2.15639
Timestep Consumption Time: 2.44690
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.60329

Cumulative Model Updates: 114,058
Cumulative Timesteps: 951,198,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 951198092...
Checkpoint 951198092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347.76251
Policy Entropy: 3.05711
Value Function Loss: 0.00512

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.58342
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 22,799.70324
Overall Steps per Second: 10,656.87235

Timestep Collection Time: 2.19301
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.69181

Cumulative Model Updates: 114,064
Cumulative Timesteps: 951,248,092

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.52065
Policy Entropy: 3.05090
Value Function Loss: 0.00500

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10501
Policy Update Magnitude: 0.57456
Value Function Update Magnitude: 0.61963

Collected Steps per Second: 22,947.75465
Overall Steps per Second: 10,856.42211

Timestep Collection Time: 2.17965
Timestep Consumption Time: 2.42758
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.60723

Cumulative Model Updates: 114,070
Cumulative Timesteps: 951,298,110

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 951298110...
Checkpoint 951298110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.52754
Policy Entropy: 3.04993
Value Function Loss: 0.00504

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11969
Policy Update Magnitude: 0.57488
Value Function Update Magnitude: 0.60330

Collected Steps per Second: 22,577.13769
Overall Steps per Second: 10,756.05272

Timestep Collection Time: 2.21472
Timestep Consumption Time: 2.43401
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.64873

Cumulative Model Updates: 114,076
Cumulative Timesteps: 951,348,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.67798
Policy Entropy: 3.04952
Value Function Loss: 0.00505

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.58525
Value Function Update Magnitude: 0.62178

Collected Steps per Second: 23,142.56492
Overall Steps per Second: 10,923.31940

Timestep Collection Time: 2.16173
Timestep Consumption Time: 2.41820
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.57993

Cumulative Model Updates: 114,082
Cumulative Timesteps: 951,398,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 951398140...
Checkpoint 951398140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,542.99490
Policy Entropy: 3.05371
Value Function Loss: 0.00517

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.59025
Value Function Update Magnitude: 0.63140

Collected Steps per Second: 22,473.42915
Overall Steps per Second: 10,566.17894

Timestep Collection Time: 2.22494
Timestep Consumption Time: 2.50733
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.73227

Cumulative Model Updates: 114,088
Cumulative Timesteps: 951,448,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 831.12586
Policy Entropy: 3.04636
Value Function Loss: 0.00521

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.59075
Value Function Update Magnitude: 0.64085

Collected Steps per Second: 22,947.29965
Overall Steps per Second: 10,863.70446

Timestep Collection Time: 2.18013
Timestep Consumption Time: 2.42493
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.60506

Cumulative Model Updates: 114,094
Cumulative Timesteps: 951,498,170

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 951498170...
Checkpoint 951498170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 769.60453
Policy Entropy: 3.04003
Value Function Loss: 0.00538

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.58891
Value Function Update Magnitude: 0.65178

Collected Steps per Second: 22,396.92807
Overall Steps per Second: 10,731.20017

Timestep Collection Time: 2.23307
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.66062

Cumulative Model Updates: 114,100
Cumulative Timesteps: 951,548,184

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.82643
Policy Entropy: 3.03341
Value Function Loss: 0.00553

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.59496
Value Function Update Magnitude: 0.64107

Collected Steps per Second: 22,972.55006
Overall Steps per Second: 10,850.68757

Timestep Collection Time: 2.17729
Timestep Consumption Time: 2.43237
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.60966

Cumulative Model Updates: 114,106
Cumulative Timesteps: 951,598,202

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 951598202...
Checkpoint 951598202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.81989
Policy Entropy: 3.02958
Value Function Loss: 0.00536

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.59382
Value Function Update Magnitude: 0.63341

Collected Steps per Second: 22,643.51797
Overall Steps per Second: 10,699.22394

Timestep Collection Time: 2.20831
Timestep Consumption Time: 2.46530
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.67361

Cumulative Model Updates: 114,112
Cumulative Timesteps: 951,648,206

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.28654
Policy Entropy: 3.04108
Value Function Loss: 0.00524

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11808
Policy Update Magnitude: 0.58704
Value Function Update Magnitude: 0.60967

Collected Steps per Second: 23,117.81935
Overall Steps per Second: 10,881.24819

Timestep Collection Time: 2.16379
Timestep Consumption Time: 2.43330
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.59708

Cumulative Model Updates: 114,118
Cumulative Timesteps: 951,698,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 951698228...
Checkpoint 951698228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,309.29187
Policy Entropy: 3.04356
Value Function Loss: 0.00520

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11483
Policy Update Magnitude: 0.58734
Value Function Update Magnitude: 0.60616

Collected Steps per Second: 22,517.42224
Overall Steps per Second: 10,653.62478

Timestep Collection Time: 2.22166
Timestep Consumption Time: 2.47402
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.69568

Cumulative Model Updates: 114,124
Cumulative Timesteps: 951,748,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,453.21906
Policy Entropy: 3.04447
Value Function Loss: 0.00512

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11380
Policy Update Magnitude: 0.58170
Value Function Update Magnitude: 0.61993

Collected Steps per Second: 21,239.03036
Overall Steps per Second: 10,382.81588

Timestep Collection Time: 2.35453
Timestep Consumption Time: 2.46189
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.81642

Cumulative Model Updates: 114,130
Cumulative Timesteps: 951,798,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 951798262...
Checkpoint 951798262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 888.10779
Policy Entropy: 3.04525
Value Function Loss: 0.00506

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09996
Policy Update Magnitude: 0.58151
Value Function Update Magnitude: 0.61658

Collected Steps per Second: 21,936.72981
Overall Steps per Second: 10,488.23693

Timestep Collection Time: 2.27992
Timestep Consumption Time: 2.48866
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.76858

Cumulative Model Updates: 114,136
Cumulative Timesteps: 951,848,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.26882
Policy Entropy: 3.03665
Value Function Loss: 0.00502

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.58757
Value Function Update Magnitude: 0.61564

Collected Steps per Second: 23,089.51888
Overall Steps per Second: 10,687.94033

Timestep Collection Time: 2.16635
Timestep Consumption Time: 2.51369
PPO Batch Consumption Time: 0.29632
Total Iteration Time: 4.68004

Cumulative Model Updates: 114,142
Cumulative Timesteps: 951,898,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 951898296...
Checkpoint 951898296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.21782
Policy Entropy: 3.02053
Value Function Loss: 0.00517

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.58839
Value Function Update Magnitude: 0.61369

Collected Steps per Second: 22,721.95913
Overall Steps per Second: 10,652.72001

Timestep Collection Time: 2.20104
Timestep Consumption Time: 2.49372
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.69476

Cumulative Model Updates: 114,148
Cumulative Timesteps: 951,948,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 787.24662
Policy Entropy: 3.04093
Value Function Loss: 0.00551

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10804
Policy Update Magnitude: 0.59555
Value Function Update Magnitude: 0.61101

Collected Steps per Second: 22,780.25616
Overall Steps per Second: 10,834.80324

Timestep Collection Time: 2.19550
Timestep Consumption Time: 2.42055
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.61605

Cumulative Model Updates: 114,154
Cumulative Timesteps: 951,998,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 951998322...
Checkpoint 951998322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 733.06116
Policy Entropy: 3.04977
Value Function Loss: 0.00567

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.59955
Value Function Update Magnitude: 0.61414

Collected Steps per Second: 22,494.10712
Overall Steps per Second: 10,683.22769

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.45753
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.68042

Cumulative Model Updates: 114,160
Cumulative Timesteps: 952,048,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.65967
Policy Entropy: 3.07290
Value Function Loss: 0.00556

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10169
Policy Update Magnitude: 0.59781
Value Function Update Magnitude: 0.62334

Collected Steps per Second: 23,074.31418
Overall Steps per Second: 10,868.51217

Timestep Collection Time: 2.16743
Timestep Consumption Time: 2.43412
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.60155

Cumulative Model Updates: 114,166
Cumulative Timesteps: 952,098,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 952098336...
Checkpoint 952098336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,559.82789
Policy Entropy: 3.05690
Value Function Loss: 0.00521

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.58911
Value Function Update Magnitude: 0.62228

Collected Steps per Second: 22,107.35797
Overall Steps per Second: 10,650.06187

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.69500

Cumulative Model Updates: 114,172
Cumulative Timesteps: 952,148,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,417.93609
Policy Entropy: 3.06808
Value Function Loss: 0.00532

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.58382
Value Function Update Magnitude: 0.62290

Collected Steps per Second: 23,244.20344
Overall Steps per Second: 10,899.84844

Timestep Collection Time: 2.15142
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.58795

Cumulative Model Updates: 114,178
Cumulative Timesteps: 952,198,346

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 952198346...
Checkpoint 952198346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.17615
Policy Entropy: 3.06071
Value Function Loss: 0.00512

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11285
Policy Update Magnitude: 0.58055
Value Function Update Magnitude: 0.62493

Collected Steps per Second: 22,655.38265
Overall Steps per Second: 10,732.55597

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.45194
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.65910

Cumulative Model Updates: 114,184
Cumulative Timesteps: 952,248,350

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,854.89739
Policy Entropy: 3.06612
Value Function Loss: 0.00506

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.09481
Policy Update Magnitude: 0.57491
Value Function Update Magnitude: 0.62207

Collected Steps per Second: 23,046.19364
Overall Steps per Second: 10,848.79540

Timestep Collection Time: 2.17086
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.61157

Cumulative Model Updates: 114,190
Cumulative Timesteps: 952,298,380

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 952298380...
Checkpoint 952298380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.08350
Policy Entropy: 3.07272
Value Function Loss: 0.00495

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09409
Policy Update Magnitude: 0.57468
Value Function Update Magnitude: 0.60531

Collected Steps per Second: 22,618.06038
Overall Steps per Second: 10,796.71695

Timestep Collection Time: 2.21168
Timestep Consumption Time: 2.42158
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.63326

Cumulative Model Updates: 114,196
Cumulative Timesteps: 952,348,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 828.12094
Policy Entropy: 3.07424
Value Function Loss: 0.00501

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10059
Policy Update Magnitude: 0.57786
Value Function Update Magnitude: 0.60055

Collected Steps per Second: 22,310.35253
Overall Steps per Second: 10,780.87828

Timestep Collection Time: 2.24201
Timestep Consumption Time: 2.39769
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.63970

Cumulative Model Updates: 114,202
Cumulative Timesteps: 952,398,424

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 952398424...
Checkpoint 952398424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.41945
Policy Entropy: 3.07756
Value Function Loss: 0.00511

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.57325
Value Function Update Magnitude: 0.60461

Collected Steps per Second: 22,362.23485
Overall Steps per Second: 10,658.28984

Timestep Collection Time: 2.23645
Timestep Consumption Time: 2.45586
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.69231

Cumulative Model Updates: 114,208
Cumulative Timesteps: 952,448,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 893.57244
Policy Entropy: 3.08413
Value Function Loss: 0.00494

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.10302
Policy Update Magnitude: 0.57498
Value Function Update Magnitude: 0.59395

Collected Steps per Second: 22,973.52518
Overall Steps per Second: 10,834.05944

Timestep Collection Time: 2.17677
Timestep Consumption Time: 2.43905
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.61581

Cumulative Model Updates: 114,214
Cumulative Timesteps: 952,498,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 952498444...
Checkpoint 952498444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 818.30987
Policy Entropy: 3.09852
Value Function Loss: 0.00497

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.57053
Value Function Update Magnitude: 0.57747

Collected Steps per Second: 22,749.01176
Overall Steps per Second: 10,804.90330

Timestep Collection Time: 2.19860
Timestep Consumption Time: 2.43041
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.62901

Cumulative Model Updates: 114,220
Cumulative Timesteps: 952,548,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.56539
Policy Entropy: 3.10343
Value Function Loss: 0.00481

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.56450
Value Function Update Magnitude: 0.57214

Collected Steps per Second: 22,364.79362
Overall Steps per Second: 10,794.68922

Timestep Collection Time: 2.23610
Timestep Consumption Time: 2.39673
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.63283

Cumulative Model Updates: 114,226
Cumulative Timesteps: 952,598,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 952598470...
Checkpoint 952598470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 873.41284
Policy Entropy: 3.09450
Value Function Loss: 0.00495

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.10890
Policy Update Magnitude: 0.55993
Value Function Update Magnitude: 0.56536

Collected Steps per Second: 22,293.79565
Overall Steps per Second: 10,661.88022

Timestep Collection Time: 2.24314
Timestep Consumption Time: 2.44722
PPO Batch Consumption Time: 0.29671
Total Iteration Time: 4.69035

Cumulative Model Updates: 114,232
Cumulative Timesteps: 952,648,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,321.84029
Policy Entropy: 3.08487
Value Function Loss: 0.00490

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.55781
Value Function Update Magnitude: 0.56161

Collected Steps per Second: 21,853.81259
Overall Steps per Second: 10,610.02306

Timestep Collection Time: 2.28793
Timestep Consumption Time: 2.42459
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.71253

Cumulative Model Updates: 114,238
Cumulative Timesteps: 952,698,478

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 952698478...
Checkpoint 952698478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.28443
Policy Entropy: 3.07443
Value Function Loss: 0.00501

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.56086
Value Function Update Magnitude: 0.56955

Collected Steps per Second: 21,984.61402
Overall Steps per Second: 10,621.78355

Timestep Collection Time: 2.27514
Timestep Consumption Time: 2.43387
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.70900

Cumulative Model Updates: 114,244
Cumulative Timesteps: 952,748,496

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.35689
Policy Entropy: 3.07229
Value Function Loss: 0.00515

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.12399
Policy Update Magnitude: 0.57001
Value Function Update Magnitude: 0.59184

Collected Steps per Second: 22,120.80156
Overall Steps per Second: 10,791.47073

Timestep Collection Time: 2.26158
Timestep Consumption Time: 2.37430
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.63588

Cumulative Model Updates: 114,250
Cumulative Timesteps: 952,798,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 952798524...
Checkpoint 952798524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.55166
Policy Entropy: 3.07028
Value Function Loss: 0.00516

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.14014
Policy Update Magnitude: 0.57371
Value Function Update Magnitude: 0.60212

Collected Steps per Second: 21,941.76651
Overall Steps per Second: 10,578.02451

Timestep Collection Time: 2.28004
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.29600
Total Iteration Time: 4.72943

Cumulative Model Updates: 114,256
Cumulative Timesteps: 952,848,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.01250
Policy Entropy: 3.05707
Value Function Loss: 0.00518

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11686
Policy Update Magnitude: 0.57781
Value Function Update Magnitude: 0.61915

Collected Steps per Second: 22,199.75975
Overall Steps per Second: 10,695.12632

Timestep Collection Time: 2.25255
Timestep Consumption Time: 2.42304
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.67559

Cumulative Model Updates: 114,262
Cumulative Timesteps: 952,898,558

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 952898558...
Checkpoint 952898558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.78732
Policy Entropy: 3.07221
Value Function Loss: 0.00517

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11591
Policy Update Magnitude: 0.57999
Value Function Update Magnitude: 0.63417

Collected Steps per Second: 22,011.51677
Overall Steps per Second: 10,773.87635

Timestep Collection Time: 2.27236
Timestep Consumption Time: 2.37017
PPO Batch Consumption Time: 0.28098
Total Iteration Time: 4.64253

Cumulative Model Updates: 114,268
Cumulative Timesteps: 952,948,576

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,393.21308
Policy Entropy: 3.07521
Value Function Loss: 0.00515

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 0.57966
Value Function Update Magnitude: 0.63339

Collected Steps per Second: 22,087.80705
Overall Steps per Second: 10,540.04105

Timestep Collection Time: 2.26396
Timestep Consumption Time: 2.48042
PPO Batch Consumption Time: 0.29715
Total Iteration Time: 4.74438

Cumulative Model Updates: 114,274
Cumulative Timesteps: 952,998,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 952998582...
Checkpoint 952998582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 897.59163
Policy Entropy: 3.06783
Value Function Loss: 0.00550

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.58579
Value Function Update Magnitude: 0.64224

Collected Steps per Second: 21,978.80240
Overall Steps per Second: 10,642.53440

Timestep Collection Time: 2.27547
Timestep Consumption Time: 2.42379
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.69926

Cumulative Model Updates: 114,280
Cumulative Timesteps: 953,048,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 904.27581
Policy Entropy: 3.07317
Value Function Loss: 0.00532

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.59155
Value Function Update Magnitude: 0.65285

Collected Steps per Second: 22,757.06125
Overall Steps per Second: 10,639.91291

Timestep Collection Time: 2.19738
Timestep Consumption Time: 2.50247
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.69985

Cumulative Model Updates: 114,286
Cumulative Timesteps: 953,098,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 953098600...
Checkpoint 953098600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679.16502
Policy Entropy: 3.05920
Value Function Loss: 0.00530

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.10891
Policy Update Magnitude: 0.58968
Value Function Update Magnitude: 0.63418

Collected Steps per Second: 23,123.64993
Overall Steps per Second: 10,830.54324

Timestep Collection Time: 2.16229
Timestep Consumption Time: 2.45429
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.61657

Cumulative Model Updates: 114,292
Cumulative Timesteps: 953,148,600

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.99517
Policy Entropy: 3.06522
Value Function Loss: 0.00543

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11897
Policy Update Magnitude: 0.59101
Value Function Update Magnitude: 0.61453

Collected Steps per Second: 22,878.02248
Overall Steps per Second: 10,650.66941

Timestep Collection Time: 2.18647
Timestep Consumption Time: 2.51014
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.69661

Cumulative Model Updates: 114,298
Cumulative Timesteps: 953,198,622

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 953198622...
Checkpoint 953198622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,643.38193
Policy Entropy: 3.06485
Value Function Loss: 0.00531

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11944
Policy Update Magnitude: 0.58933
Value Function Update Magnitude: 0.62132

Collected Steps per Second: 22,948.39420
Overall Steps per Second: 10,704.92047

Timestep Collection Time: 2.17932
Timestep Consumption Time: 2.49255
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.67187

Cumulative Model Updates: 114,304
Cumulative Timesteps: 953,248,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.55911
Policy Entropy: 3.04906
Value Function Loss: 0.00515

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.58480
Value Function Update Magnitude: 0.61912

Collected Steps per Second: 22,376.79198
Overall Steps per Second: 10,740.38507

Timestep Collection Time: 2.23535
Timestep Consumption Time: 2.42184
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.65719

Cumulative Model Updates: 114,310
Cumulative Timesteps: 953,298,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 953298654...
Checkpoint 953298654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.35303
Policy Entropy: 3.05774
Value Function Loss: 0.00504

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10372
Policy Update Magnitude: 0.58479
Value Function Update Magnitude: 0.60160

Collected Steps per Second: 21,942.74073
Overall Steps per Second: 10,611.47039

Timestep Collection Time: 2.27920
Timestep Consumption Time: 2.43381
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.71301

Cumulative Model Updates: 114,316
Cumulative Timesteps: 953,348,666

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,461.10256
Policy Entropy: 3.04377
Value Function Loss: 0.00534

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.58573
Value Function Update Magnitude: 0.59194

Collected Steps per Second: 23,257.22886
Overall Steps per Second: 10,845.70396

Timestep Collection Time: 2.14987
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.61012

Cumulative Model Updates: 114,322
Cumulative Timesteps: 953,398,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 953398666...
Checkpoint 953398666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.94889
Policy Entropy: 3.06555
Value Function Loss: 0.00522

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.57989
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 21,797.70191
Overall Steps per Second: 10,734.86538

Timestep Collection Time: 2.29419
Timestep Consumption Time: 2.36428
PPO Batch Consumption Time: 0.28195
Total Iteration Time: 4.65847

Cumulative Model Updates: 114,328
Cumulative Timesteps: 953,448,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.14866
Policy Entropy: 3.05267
Value Function Loss: 0.00544

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10774
Policy Update Magnitude: 0.57642
Value Function Update Magnitude: 0.59419

Collected Steps per Second: 22,202.07760
Overall Steps per Second: 10,785.57705

Timestep Collection Time: 2.25348
Timestep Consumption Time: 2.38530
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.63879

Cumulative Model Updates: 114,334
Cumulative Timesteps: 953,498,706

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 953498706...
Checkpoint 953498706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 999.05328
Policy Entropy: 3.04622
Value Function Loss: 0.00541

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10473
Policy Update Magnitude: 0.58029
Value Function Update Magnitude: 0.61115

Collected Steps per Second: 22,426.11803
Overall Steps per Second: 10,714.09476

Timestep Collection Time: 2.23026
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.66824

Cumulative Model Updates: 114,340
Cumulative Timesteps: 953,548,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,103.99052
Policy Entropy: 3.03579
Value Function Loss: 0.00553

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.58791
Value Function Update Magnitude: 0.64031

Collected Steps per Second: 22,738.52011
Overall Steps per Second: 10,642.18155

Timestep Collection Time: 2.19970
Timestep Consumption Time: 2.50027
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.69998

Cumulative Model Updates: 114,346
Cumulative Timesteps: 953,598,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 953598740...
Checkpoint 953598740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.17752
Policy Entropy: 3.02726
Value Function Loss: 0.00515

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10861
Policy Update Magnitude: 0.58519
Value Function Update Magnitude: 0.63641

Collected Steps per Second: 23,035.84556
Overall Steps per Second: 10,869.96581

Timestep Collection Time: 2.17149
Timestep Consumption Time: 2.43037
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.60185

Cumulative Model Updates: 114,352
Cumulative Timesteps: 953,648,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,399.39316
Policy Entropy: 3.02479
Value Function Loss: 0.00515

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11546
Policy Update Magnitude: 0.58268
Value Function Update Magnitude: 0.62503

Collected Steps per Second: 22,659.20844
Overall Steps per Second: 10,550.03457

Timestep Collection Time: 2.20714
Timestep Consumption Time: 2.53332
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.74046

Cumulative Model Updates: 114,358
Cumulative Timesteps: 953,698,774

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 953698774...
Checkpoint 953698774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.81702
Policy Entropy: 3.02800
Value Function Loss: 0.00521

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.11097
Policy Update Magnitude: 0.58950
Value Function Update Magnitude: 0.63577

Collected Steps per Second: 22,678.47855
Overall Steps per Second: 10,584.18968

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.52060
PPO Batch Consumption Time: 0.29544
Total Iteration Time: 4.72648

Cumulative Model Updates: 114,364
Cumulative Timesteps: 953,748,800

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.14043
Policy Entropy: 3.03893
Value Function Loss: 0.00540

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.59629
Value Function Update Magnitude: 0.66192

Collected Steps per Second: 23,015.13342
Overall Steps per Second: 10,741.92734

Timestep Collection Time: 2.17301
Timestep Consumption Time: 2.48277
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.65578

Cumulative Model Updates: 114,370
Cumulative Timesteps: 953,798,812

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 953798812...
Checkpoint 953798812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,531.84158
Policy Entropy: 3.05115
Value Function Loss: 0.00519

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.60139
Value Function Update Magnitude: 0.67217

Collected Steps per Second: 22,864.95866
Overall Steps per Second: 10,815.76474

Timestep Collection Time: 2.18780
Timestep Consumption Time: 2.43730
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.62510

Cumulative Model Updates: 114,376
Cumulative Timesteps: 953,848,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 792.89919
Policy Entropy: 3.05789
Value Function Loss: 0.00591

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11176
Policy Update Magnitude: 0.61335
Value Function Update Magnitude: 0.66327

Collected Steps per Second: 22,533.28673
Overall Steps per Second: 10,603.64876

Timestep Collection Time: 2.21894
Timestep Consumption Time: 2.49642
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.71536

Cumulative Model Updates: 114,382
Cumulative Timesteps: 953,898,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 953898836...
Checkpoint 953898836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 694.84889
Policy Entropy: 3.06167
Value Function Loss: 0.00570

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.61254
Value Function Update Magnitude: 0.67974

Collected Steps per Second: 22,378.89677
Overall Steps per Second: 10,842.44478

Timestep Collection Time: 2.23532
Timestep Consumption Time: 2.37840
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.61372

Cumulative Model Updates: 114,388
Cumulative Timesteps: 953,948,860

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,780.46972
Policy Entropy: 3.05465
Value Function Loss: 0.00576

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.60080
Value Function Update Magnitude: 0.65430

Collected Steps per Second: 22,482.05846
Overall Steps per Second: 10,737.00308

Timestep Collection Time: 2.22408
Timestep Consumption Time: 2.43289
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.65698

Cumulative Model Updates: 114,394
Cumulative Timesteps: 953,998,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 953998862...
Checkpoint 953998862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.89289
Policy Entropy: 3.04290
Value Function Loss: 0.00536

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.59217
Value Function Update Magnitude: 0.61700

Collected Steps per Second: 23,016.85329
Overall Steps per Second: 10,859.51191

Timestep Collection Time: 2.17319
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.60610

Cumulative Model Updates: 114,400
Cumulative Timesteps: 954,048,882

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.31299
Policy Entropy: 3.02714
Value Function Loss: 0.00527

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10364
Policy Update Magnitude: 0.59065
Value Function Update Magnitude: 0.60861

Collected Steps per Second: 22,052.34922
Overall Steps per Second: 10,624.65764

Timestep Collection Time: 2.26779
Timestep Consumption Time: 2.43919
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.70698

Cumulative Model Updates: 114,406
Cumulative Timesteps: 954,098,892

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 954098892...
Checkpoint 954098892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.79946
Policy Entropy: 3.02857
Value Function Loss: 0.00530

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.59346
Value Function Update Magnitude: 0.60809

Collected Steps per Second: 21,895.11334
Overall Steps per Second: 10,595.03438

Timestep Collection Time: 2.28407
Timestep Consumption Time: 2.43606
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.72014

Cumulative Model Updates: 114,412
Cumulative Timesteps: 954,148,902

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,212.46921
Policy Entropy: 3.02297
Value Function Loss: 0.00501

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.58662
Value Function Update Magnitude: 0.60665

Collected Steps per Second: 22,229.62696
Overall Steps per Second: 10,791.13181

Timestep Collection Time: 2.25051
Timestep Consumption Time: 2.38552
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.63603

Cumulative Model Updates: 114,418
Cumulative Timesteps: 954,198,930

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 954198930...
Checkpoint 954198930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800.05342
Policy Entropy: 3.05588
Value Function Loss: 0.00508

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12088
Policy Update Magnitude: 0.57204
Value Function Update Magnitude: 0.61036

Collected Steps per Second: 22,954.80504
Overall Steps per Second: 10,660.92672

Timestep Collection Time: 2.17854
Timestep Consumption Time: 2.51223
PPO Batch Consumption Time: 0.29535
Total Iteration Time: 4.69077

Cumulative Model Updates: 114,424
Cumulative Timesteps: 954,248,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 629.94656
Policy Entropy: 3.05256
Value Function Loss: 0.00516

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11293
Policy Update Magnitude: 0.56928
Value Function Update Magnitude: 0.61515

Collected Steps per Second: 22,618.16624
Overall Steps per Second: 10,562.37019

Timestep Collection Time: 2.21150
Timestep Consumption Time: 2.52418
PPO Batch Consumption Time: 0.29462
Total Iteration Time: 4.73568

Cumulative Model Updates: 114,430
Cumulative Timesteps: 954,298,958

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 954298958...
Checkpoint 954298958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.97250
Policy Entropy: 3.07497
Value Function Loss: 0.00506

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.57663
Value Function Update Magnitude: 0.63059

Collected Steps per Second: 22,966.11587
Overall Steps per Second: 10,697.62156

Timestep Collection Time: 2.17843
Timestep Consumption Time: 2.49831
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.67674

Cumulative Model Updates: 114,436
Cumulative Timesteps: 954,348,988

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,563.48791
Policy Entropy: 3.05602
Value Function Loss: 0.00517

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.10954
Policy Update Magnitude: 0.58064
Value Function Update Magnitude: 0.62295

Collected Steps per Second: 22,789.40785
Overall Steps per Second: 10,794.78318

Timestep Collection Time: 2.19470
Timestep Consumption Time: 2.43865
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.63335

Cumulative Model Updates: 114,442
Cumulative Timesteps: 954,399,004

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 954399004...
Checkpoint 954399004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,474.00434
Policy Entropy: 3.05737
Value Function Loss: 0.00526

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 0.59300
Value Function Update Magnitude: 0.62420

Collected Steps per Second: 23,011.08208
Overall Steps per Second: 10,652.36055

Timestep Collection Time: 2.17469
Timestep Consumption Time: 2.52305
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.69774

Cumulative Model Updates: 114,448
Cumulative Timesteps: 954,449,046

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755.35202
Policy Entropy: 3.05372
Value Function Loss: 0.00509

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10400
Policy Update Magnitude: 0.58784
Value Function Update Magnitude: 0.61647

Collected Steps per Second: 22,851.19476
Overall Steps per Second: 10,780.76430

Timestep Collection Time: 2.18807
Timestep Consumption Time: 2.44982
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.63789

Cumulative Model Updates: 114,454
Cumulative Timesteps: 954,499,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 954499046...
Checkpoint 954499046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.20291
Policy Entropy: 3.05415
Value Function Loss: 0.00501

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11138
Policy Update Magnitude: 0.57214
Value Function Update Magnitude: 0.59758

Collected Steps per Second: 22,875.92759
Overall Steps per Second: 10,731.47488

Timestep Collection Time: 2.18658
Timestep Consumption Time: 2.47448
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.66106

Cumulative Model Updates: 114,460
Cumulative Timesteps: 954,549,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,049.80129
Policy Entropy: 3.06316
Value Function Loss: 0.00502

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09285
Policy Update Magnitude: 0.57452
Value Function Update Magnitude: 0.58611

Collected Steps per Second: 23,130.34670
Overall Steps per Second: 10,811.13524

Timestep Collection Time: 2.16184
Timestep Consumption Time: 2.46340
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.62523

Cumulative Model Updates: 114,466
Cumulative Timesteps: 954,599,070

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 954599070...
Checkpoint 954599070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.22125
Policy Entropy: 3.05442
Value Function Loss: 0.00508

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10354
Policy Update Magnitude: 0.57506
Value Function Update Magnitude: 0.59391

Collected Steps per Second: 22,807.43793
Overall Steps per Second: 10,735.65163

Timestep Collection Time: 2.19306
Timestep Consumption Time: 2.46600
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.65906

Cumulative Model Updates: 114,472
Cumulative Timesteps: 954,649,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,587.76046
Policy Entropy: 3.06015
Value Function Loss: 0.00510

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10351
Policy Update Magnitude: 0.57145
Value Function Update Magnitude: 0.59729

Collected Steps per Second: 22,963.50500
Overall Steps per Second: 10,789.51363

Timestep Collection Time: 2.17833
Timestep Consumption Time: 2.45784
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.63617

Cumulative Model Updates: 114,478
Cumulative Timesteps: 954,699,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 954699110...
Checkpoint 954699110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,376.66349
Policy Entropy: 3.05393
Value Function Loss: 0.00513

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.56910
Value Function Update Magnitude: 0.58149

Collected Steps per Second: 22,222.01293
Overall Steps per Second: 10,678.20111

Timestep Collection Time: 2.25101
Timestep Consumption Time: 2.43349
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.68450

Cumulative Model Updates: 114,484
Cumulative Timesteps: 954,749,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,186.52349
Policy Entropy: 3.05737
Value Function Loss: 0.00517

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.56859
Value Function Update Magnitude: 0.58055

Collected Steps per Second: 23,143.75779
Overall Steps per Second: 10,843.43191

Timestep Collection Time: 2.16067
Timestep Consumption Time: 2.45097
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.61164

Cumulative Model Updates: 114,490
Cumulative Timesteps: 954,799,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 954799138...
Checkpoint 954799138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.84821
Policy Entropy: 3.05442
Value Function Loss: 0.00518

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09967
Policy Update Magnitude: 0.57391
Value Function Update Magnitude: 0.58688

Collected Steps per Second: 22,483.42188
Overall Steps per Second: 10,724.65247

Timestep Collection Time: 2.22537
Timestep Consumption Time: 2.43995
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.66533

Cumulative Model Updates: 114,496
Cumulative Timesteps: 954,849,172

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,197.80114
Policy Entropy: 3.06670
Value Function Loss: 0.00502

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.57519
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 22,875.27229
Overall Steps per Second: 10,651.12179

Timestep Collection Time: 2.18682
Timestep Consumption Time: 2.50978
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69659

Cumulative Model Updates: 114,502
Cumulative Timesteps: 954,899,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 954899196...
Checkpoint 954899196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,203.54089
Policy Entropy: 3.06649
Value Function Loss: 0.00497

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09253
Policy Update Magnitude: 0.56912
Value Function Update Magnitude: 0.59982

Collected Steps per Second: 22,898.79796
Overall Steps per Second: 10,801.17782

Timestep Collection Time: 2.18474
Timestep Consumption Time: 2.44697
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.63172

Cumulative Model Updates: 114,508
Cumulative Timesteps: 954,949,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,284.48887
Policy Entropy: 3.06842
Value Function Loss: 0.00505

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09529
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.58485

Collected Steps per Second: 22,919.81150
Overall Steps per Second: 10,661.30646

Timestep Collection Time: 2.18222
Timestep Consumption Time: 2.50914
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.69136

Cumulative Model Updates: 114,514
Cumulative Timesteps: 954,999,240

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 954999240...
Checkpoint 954999240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,407.64686
Policy Entropy: 3.05967
Value Function Loss: 0.00492

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10378
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.59561

Collected Steps per Second: 22,710.19360
Overall Steps per Second: 10,583.29886

Timestep Collection Time: 2.20218
Timestep Consumption Time: 2.52338
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.72556

Cumulative Model Updates: 114,520
Cumulative Timesteps: 955,049,252

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.89062
Policy Entropy: 3.05247
Value Function Loss: 0.00476

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.08759
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.60653

Collected Steps per Second: 23,180.52443
Overall Steps per Second: 10,841.42692

Timestep Collection Time: 2.15750
Timestep Consumption Time: 2.45555
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.61305

Cumulative Model Updates: 114,526
Cumulative Timesteps: 955,099,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 955099264...
Checkpoint 955099264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,042.75497
Policy Entropy: 3.03919
Value Function Loss: 0.00481

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09038
Policy Update Magnitude: 0.56445
Value Function Update Magnitude: 0.61014

Collected Steps per Second: 22,846.37056
Overall Steps per Second: 10,681.21842

Timestep Collection Time: 2.18932
Timestep Consumption Time: 2.49348
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.68280

Cumulative Model Updates: 114,532
Cumulative Timesteps: 955,149,282

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.44710
Policy Entropy: 3.05241
Value Function Loss: 0.00515

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09324
Policy Update Magnitude: 0.57040
Value Function Update Magnitude: 0.60348

Collected Steps per Second: 23,231.32868
Overall Steps per Second: 10,873.04709

Timestep Collection Time: 2.15364
Timestep Consumption Time: 2.44783
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.60147

Cumulative Model Updates: 114,538
Cumulative Timesteps: 955,199,314

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 955199314...
Checkpoint 955199314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.85049
Policy Entropy: 3.05898
Value Function Loss: 0.00521

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09915
Policy Update Magnitude: 0.57137
Value Function Update Magnitude: 0.60211

Collected Steps per Second: 22,222.37133
Overall Steps per Second: 10,700.70236

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.42309
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.67353

Cumulative Model Updates: 114,544
Cumulative Timesteps: 955,249,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,356.85186
Policy Entropy: 3.06675
Value Function Loss: 0.00545

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09488
Policy Update Magnitude: 0.57618
Value Function Update Magnitude: 0.61220

Collected Steps per Second: 23,153.21451
Overall Steps per Second: 10,844.59716

Timestep Collection Time: 2.16022
Timestep Consumption Time: 2.45185
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.61207

Cumulative Model Updates: 114,550
Cumulative Timesteps: 955,299,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 955299340...
Checkpoint 955299340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.84516
Policy Entropy: 3.05111
Value Function Loss: 0.00562

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.58615
Value Function Update Magnitude: 0.63486

Collected Steps per Second: 22,046.97896
Overall Steps per Second: 10,683.34040

Timestep Collection Time: 2.26897
Timestep Consumption Time: 2.41346
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.68243

Cumulative Model Updates: 114,556
Cumulative Timesteps: 955,349,364

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.45028
Policy Entropy: 3.04826
Value Function Loss: 0.00534

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10724
Policy Update Magnitude: 0.58404
Value Function Update Magnitude: 0.64510

Collected Steps per Second: 22,179.58744
Overall Steps per Second: 10,810.72015

Timestep Collection Time: 2.25523
Timestep Consumption Time: 2.37166
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.62689

Cumulative Model Updates: 114,562
Cumulative Timesteps: 955,399,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 955399384...
Checkpoint 955399384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.69763
Policy Entropy: 3.04192
Value Function Loss: 0.00510

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.57098
Value Function Update Magnitude: 0.62182

Collected Steps per Second: 22,923.47967
Overall Steps per Second: 10,747.05388

Timestep Collection Time: 2.18204
Timestep Consumption Time: 2.47226
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.65430

Cumulative Model Updates: 114,568
Cumulative Timesteps: 955,449,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.18962
Policy Entropy: 3.05465
Value Function Loss: 0.00495

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09710
Policy Update Magnitude: 0.57248
Value Function Update Magnitude: 0.59578

Collected Steps per Second: 22,522.92124
Overall Steps per Second: 10,515.49745

Timestep Collection Time: 2.21996
Timestep Consumption Time: 2.53493
PPO Batch Consumption Time: 0.29577
Total Iteration Time: 4.75489

Cumulative Model Updates: 114,574
Cumulative Timesteps: 955,499,404

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 955499404...
Checkpoint 955499404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.98373
Policy Entropy: 3.06073
Value Function Loss: 0.00502

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.57423
Value Function Update Magnitude: 0.57798

Collected Steps per Second: 22,396.23802
Overall Steps per Second: 10,725.63153

Timestep Collection Time: 2.23270
Timestep Consumption Time: 2.42941
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.66210

Cumulative Model Updates: 114,580
Cumulative Timesteps: 955,549,408

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,400.35109
Policy Entropy: 3.06111
Value Function Loss: 0.00518

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.56850
Value Function Update Magnitude: 0.55869

Collected Steps per Second: 22,974.45650
Overall Steps per Second: 10,787.15744

Timestep Collection Time: 2.17642
Timestep Consumption Time: 2.45891
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.63533

Cumulative Model Updates: 114,586
Cumulative Timesteps: 955,599,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 955599410...
Checkpoint 955599410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708.14454
Policy Entropy: 3.06991
Value Function Loss: 0.00527

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09126
Policy Update Magnitude: 0.57114
Value Function Update Magnitude: 0.56449

Collected Steps per Second: 22,027.71211
Overall Steps per Second: 10,621.30854

Timestep Collection Time: 2.27078
Timestep Consumption Time: 2.43862
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.70940

Cumulative Model Updates: 114,592
Cumulative Timesteps: 955,649,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 953.82132
Policy Entropy: 3.07092
Value Function Loss: 0.00513

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.09404
Policy Update Magnitude: 0.57093
Value Function Update Magnitude: 0.57603

Collected Steps per Second: 22,038.73596
Overall Steps per Second: 10,689.32354

Timestep Collection Time: 2.26973
Timestep Consumption Time: 2.40989
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.67962

Cumulative Model Updates: 114,598
Cumulative Timesteps: 955,699,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 955699452...
Checkpoint 955699452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,204.68372
Policy Entropy: 3.08606
Value Function Loss: 0.00513

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10181
Policy Update Magnitude: 0.56962
Value Function Update Magnitude: 0.57384

Collected Steps per Second: 22,747.77992
Overall Steps per Second: 10,759.38454

Timestep Collection Time: 2.19890
Timestep Consumption Time: 2.45007
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.64896

Cumulative Model Updates: 114,604
Cumulative Timesteps: 955,749,472

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,167.96491
Policy Entropy: 3.09035
Value Function Loss: 0.00474

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10356
Policy Update Magnitude: 0.56708
Value Function Update Magnitude: 0.59370

Collected Steps per Second: 22,874.52227
Overall Steps per Second: 10,584.04473

Timestep Collection Time: 2.18584
Timestep Consumption Time: 2.53825
PPO Batch Consumption Time: 0.29536
Total Iteration Time: 4.72409

Cumulative Model Updates: 114,610
Cumulative Timesteps: 955,799,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 955799472...
Checkpoint 955799472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878.32986
Policy Entropy: 3.10952
Value Function Loss: 0.00505

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10277
Policy Update Magnitude: 0.56856
Value Function Update Magnitude: 0.60940

Collected Steps per Second: 22,811.14118
Overall Steps per Second: 10,590.01032

Timestep Collection Time: 2.19296
Timestep Consumption Time: 2.53073
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.72370

Cumulative Model Updates: 114,616
Cumulative Timesteps: 955,849,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 936.45013
Policy Entropy: 3.11674
Value Function Loss: 0.00520

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11126
Policy Update Magnitude: 0.57594
Value Function Update Magnitude: 0.61691

Collected Steps per Second: 22,911.85652
Overall Steps per Second: 10,666.95858

Timestep Collection Time: 2.18263
Timestep Consumption Time: 2.50550
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.68812

Cumulative Model Updates: 114,622
Cumulative Timesteps: 955,899,504

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 955899504...
Checkpoint 955899504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 750.96028
Policy Entropy: 3.11680
Value Function Loss: 0.00521

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.57485
Value Function Update Magnitude: 0.62211

Collected Steps per Second: 22,841.76630
Overall Steps per Second: 10,694.27472

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.48782
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.67802

Cumulative Model Updates: 114,628
Cumulative Timesteps: 955,949,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.80562
Policy Entropy: 3.10394
Value Function Loss: 0.00499

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10280
Policy Update Magnitude: 0.56766
Value Function Update Magnitude: 0.62100

Collected Steps per Second: 23,091.40034
Overall Steps per Second: 10,669.52109

Timestep Collection Time: 2.16626
Timestep Consumption Time: 2.52205
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.68831

Cumulative Model Updates: 114,634
Cumulative Timesteps: 955,999,554

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 955999554...
Checkpoint 955999554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.31357
Policy Entropy: 3.11289
Value Function Loss: 0.00483

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.57227
Value Function Update Magnitude: 0.62180

Collected Steps per Second: 22,942.25526
Overall Steps per Second: 10,641.91688

Timestep Collection Time: 2.18043
Timestep Consumption Time: 2.52023
PPO Batch Consumption Time: 0.29670
Total Iteration Time: 4.70066

Cumulative Model Updates: 114,640
Cumulative Timesteps: 956,049,578

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,498.28236
Policy Entropy: 3.09992
Value Function Loss: 0.00500

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09308
Policy Update Magnitude: 0.57811
Value Function Update Magnitude: 0.61967

Collected Steps per Second: 22,507.24194
Overall Steps per Second: 10,499.02401

Timestep Collection Time: 2.22195
Timestep Consumption Time: 2.54135
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.76330

Cumulative Model Updates: 114,646
Cumulative Timesteps: 956,099,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 956099588...
Checkpoint 956099588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.87123
Policy Entropy: 3.09726
Value Function Loss: 0.00528

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10538
Policy Update Magnitude: 0.58908
Value Function Update Magnitude: 0.63800

Collected Steps per Second: 23,019.39406
Overall Steps per Second: 10,638.13792

Timestep Collection Time: 2.17312
Timestep Consumption Time: 2.52920
PPO Batch Consumption Time: 0.29613
Total Iteration Time: 4.70233

Cumulative Model Updates: 114,652
Cumulative Timesteps: 956,149,612

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,239.54385
Policy Entropy: 3.09397
Value Function Loss: 0.00524

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.09328
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.65327

Collected Steps per Second: 22,925.65993
Overall Steps per Second: 10,819.41300

Timestep Collection Time: 2.18096
Timestep Consumption Time: 2.44036
PPO Batch Consumption Time: 0.28042
Total Iteration Time: 4.62132

Cumulative Model Updates: 114,658
Cumulative Timesteps: 956,199,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 956199612...
Checkpoint 956199612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.26784
Policy Entropy: 3.09559
Value Function Loss: 0.00524

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09393
Policy Update Magnitude: 0.58042
Value Function Update Magnitude: 0.66476

Collected Steps per Second: 22,702.60477
Overall Steps per Second: 10,695.41675

Timestep Collection Time: 2.20345
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.67714

Cumulative Model Updates: 114,664
Cumulative Timesteps: 956,249,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.12581
Policy Entropy: 3.10001
Value Function Loss: 0.00507

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.66116

Collected Steps per Second: 22,735.77834
Overall Steps per Second: 10,632.91214

Timestep Collection Time: 2.19962
Timestep Consumption Time: 2.50370
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.70332

Cumulative Model Updates: 114,670
Cumulative Timesteps: 956,299,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 956299646...
Checkpoint 956299646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,608.43923
Policy Entropy: 3.09283
Value Function Loss: 0.00519

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.57337
Value Function Update Magnitude: 0.66505

Collected Steps per Second: 22,947.88276
Overall Steps per Second: 10,792.78350

Timestep Collection Time: 2.17894
Timestep Consumption Time: 2.45397
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.63291

Cumulative Model Updates: 114,676
Cumulative Timesteps: 956,349,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 945.45382
Policy Entropy: 3.09125
Value Function Loss: 0.00504

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.56963
Value Function Update Magnitude: 0.64427

Collected Steps per Second: 23,231.75630
Overall Steps per Second: 10,760.42133

Timestep Collection Time: 2.15248
Timestep Consumption Time: 2.49473
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.64722

Cumulative Model Updates: 114,682
Cumulative Timesteps: 956,399,654

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 956399654...
Checkpoint 956399654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 614.89977
Policy Entropy: 3.09185
Value Function Loss: 0.00524

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.57359
Value Function Update Magnitude: 0.62970

Collected Steps per Second: 22,823.77367
Overall Steps per Second: 10,797.80666

Timestep Collection Time: 2.19131
Timestep Consumption Time: 2.44056
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.63187

Cumulative Model Updates: 114,688
Cumulative Timesteps: 956,449,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,575.87421
Policy Entropy: 3.09110
Value Function Loss: 0.00538

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10855
Policy Update Magnitude: 0.57995
Value Function Update Magnitude: 0.64832

Collected Steps per Second: 22,700.39203
Overall Steps per Second: 10,516.57659

Timestep Collection Time: 2.20401
Timestep Consumption Time: 2.55343
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.75744

Cumulative Model Updates: 114,694
Cumulative Timesteps: 956,499,700

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 956499700...
Checkpoint 956499700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 909.19538
Policy Entropy: 3.08839
Value Function Loss: 0.00557

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10465
Policy Update Magnitude: 0.58832
Value Function Update Magnitude: 0.64445

Collected Steps per Second: 22,841.73910
Overall Steps per Second: 10,661.50452

Timestep Collection Time: 2.18915
Timestep Consumption Time: 2.50099
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.69014

Cumulative Model Updates: 114,700
Cumulative Timesteps: 956,549,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,262.86567
Policy Entropy: 3.09063
Value Function Loss: 0.00525

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11666
Policy Update Magnitude: 0.58018
Value Function Update Magnitude: 0.64404

Collected Steps per Second: 22,768.75512
Overall Steps per Second: 10,655.52648

Timestep Collection Time: 2.19617
Timestep Consumption Time: 2.49661
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.69278

Cumulative Model Updates: 114,706
Cumulative Timesteps: 956,599,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 956599708...
Checkpoint 956599708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.99042
Policy Entropy: 3.07938
Value Function Loss: 0.00534

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11839
Policy Update Magnitude: 0.57752
Value Function Update Magnitude: 0.62871

Collected Steps per Second: 22,871.79644
Overall Steps per Second: 10,797.35736

Timestep Collection Time: 2.18689
Timestep Consumption Time: 2.44554
PPO Batch Consumption Time: 0.28275
Total Iteration Time: 4.63243

Cumulative Model Updates: 114,712
Cumulative Timesteps: 956,649,726

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 975.68898
Policy Entropy: 3.07521
Value Function Loss: 0.00515

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.57566
Value Function Update Magnitude: 0.60854

Collected Steps per Second: 22,572.25797
Overall Steps per Second: 10,558.44594

Timestep Collection Time: 2.21555
Timestep Consumption Time: 2.52094
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.73649

Cumulative Model Updates: 114,718
Cumulative Timesteps: 956,699,736

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 956699736...
Checkpoint 956699736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,111.50677
Policy Entropy: 3.06561
Value Function Loss: 0.00524

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11246
Policy Update Magnitude: 0.57246
Value Function Update Magnitude: 0.60317

Collected Steps per Second: 22,680.98290
Overall Steps per Second: 10,625.11730

Timestep Collection Time: 2.20449
Timestep Consumption Time: 2.50134
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.70583

Cumulative Model Updates: 114,724
Cumulative Timesteps: 956,749,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.51900
Policy Entropy: 3.08080
Value Function Loss: 0.00496

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.56905
Value Function Update Magnitude: 0.59175

Collected Steps per Second: 22,758.64790
Overall Steps per Second: 10,842.91479

Timestep Collection Time: 2.19767
Timestep Consumption Time: 2.41511
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.61278

Cumulative Model Updates: 114,730
Cumulative Timesteps: 956,799,752

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 956799752...
Checkpoint 956799752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.01498
Policy Entropy: 3.07713
Value Function Loss: 0.00482

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11347
Policy Update Magnitude: 0.56279
Value Function Update Magnitude: 0.57720

Collected Steps per Second: 22,738.75499
Overall Steps per Second: 10,752.14210

Timestep Collection Time: 2.19924
Timestep Consumption Time: 2.45174
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.65098

Cumulative Model Updates: 114,736
Cumulative Timesteps: 956,849,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.78317
Policy Entropy: 3.07511
Value Function Loss: 0.00499

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.12001
Policy Update Magnitude: 0.56002
Value Function Update Magnitude: 0.56843

Collected Steps per Second: 23,062.52629
Overall Steps per Second: 10,912.02647

Timestep Collection Time: 2.16923
Timestep Consumption Time: 2.41543
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.58467

Cumulative Model Updates: 114,742
Cumulative Timesteps: 956,899,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 956899788...
Checkpoint 956899788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 839.60492
Policy Entropy: 3.06066
Value Function Loss: 0.00514

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.57064
Value Function Update Magnitude: 0.56747

Collected Steps per Second: 22,549.14560
Overall Steps per Second: 10,571.82191

Timestep Collection Time: 2.21764
Timestep Consumption Time: 2.51248
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.73012

Cumulative Model Updates: 114,748
Cumulative Timesteps: 956,949,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 526.07313
Policy Entropy: 3.05755
Value Function Loss: 0.00529

Mean KL Divergence: 0.01228
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.57123
Value Function Update Magnitude: 0.59353

Collected Steps per Second: 22,697.28148
Overall Steps per Second: 10,827.51817

Timestep Collection Time: 2.20405
Timestep Consumption Time: 2.41621
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.62026

Cumulative Model Updates: 114,754
Cumulative Timesteps: 956,999,820

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 956999820...
Checkpoint 956999820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.13429
Policy Entropy: 3.06369
Value Function Loss: 0.00515

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10423
Policy Update Magnitude: 0.57106
Value Function Update Magnitude: 0.61298

Collected Steps per Second: 22,529.74003
Overall Steps per Second: 10,802.18407

Timestep Collection Time: 2.22027
Timestep Consumption Time: 2.41046
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.63073

Cumulative Model Updates: 114,760
Cumulative Timesteps: 957,049,842

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,210.79221
Policy Entropy: 3.06564
Value Function Loss: 0.00511

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.57508
Value Function Update Magnitude: 0.62268

Collected Steps per Second: 22,880.02432
Overall Steps per Second: 10,813.90965

Timestep Collection Time: 2.18557
Timestep Consumption Time: 2.43865
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.62423

Cumulative Model Updates: 114,766
Cumulative Timesteps: 957,099,848

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 957099848...
Checkpoint 957099848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 916.35929
Policy Entropy: 3.07272
Value Function Loss: 0.00497

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 0.57724
Value Function Update Magnitude: 0.62991

Collected Steps per Second: 22,806.03124
Overall Steps per Second: 10,687.20968

Timestep Collection Time: 2.19249
Timestep Consumption Time: 2.48619
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.67868

Cumulative Model Updates: 114,772
Cumulative Timesteps: 957,149,850

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.51328
Policy Entropy: 3.07261
Value Function Loss: 0.00514

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.55999
Value Function Update Magnitude: 0.63159

Collected Steps per Second: 22,903.21514
Overall Steps per Second: 10,845.81459

Timestep Collection Time: 2.18380
Timestep Consumption Time: 2.42775
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.61155

Cumulative Model Updates: 114,778
Cumulative Timesteps: 957,199,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 957199866...
Checkpoint 957199866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,217.71889
Policy Entropy: 3.06216
Value Function Loss: 0.00522

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.56208
Value Function Update Magnitude: 0.63099

Collected Steps per Second: 22,742.26846
Overall Steps per Second: 10,664.87240

Timestep Collection Time: 2.19987
Timestep Consumption Time: 2.49123
PPO Batch Consumption Time: 0.29407
Total Iteration Time: 4.69110

Cumulative Model Updates: 114,784
Cumulative Timesteps: 957,249,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.71719
Policy Entropy: 3.05984
Value Function Loss: 0.00529

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.56968
Value Function Update Magnitude: 0.63526

Collected Steps per Second: 22,494.02958
Overall Steps per Second: 10,598.19192

Timestep Collection Time: 2.22388
Timestep Consumption Time: 2.49617
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.72005

Cumulative Model Updates: 114,790
Cumulative Timesteps: 957,299,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 957299920...
Checkpoint 957299920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,012.17063
Policy Entropy: 3.03468
Value Function Loss: 0.00517

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10002
Policy Update Magnitude: 0.57506
Value Function Update Magnitude: 0.63303

Collected Steps per Second: 22,989.65516
Overall Steps per Second: 10,844.68959

Timestep Collection Time: 2.17602
Timestep Consumption Time: 2.43693
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.61295

Cumulative Model Updates: 114,796
Cumulative Timesteps: 957,349,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.91371
Policy Entropy: 3.04634
Value Function Loss: 0.00514

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.57389
Value Function Update Magnitude: 0.62435

Collected Steps per Second: 22,551.31391
Overall Steps per Second: 10,597.10721

Timestep Collection Time: 2.21725
Timestep Consumption Time: 2.50120
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.71846

Cumulative Model Updates: 114,802
Cumulative Timesteps: 957,399,948

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 957399948...
Checkpoint 957399948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.13491
Policy Entropy: 3.04924
Value Function Loss: 0.00497

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09421
Policy Update Magnitude: 0.56456
Value Function Update Magnitude: 0.61469

Collected Steps per Second: 22,980.44791
Overall Steps per Second: 10,701.31447

Timestep Collection Time: 2.17594
Timestep Consumption Time: 2.49676
PPO Batch Consumption Time: 0.29607
Total Iteration Time: 4.67270

Cumulative Model Updates: 114,808
Cumulative Timesteps: 957,449,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,619.98005
Policy Entropy: 3.07066
Value Function Loss: 0.00479

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09563
Policy Update Magnitude: 0.55290
Value Function Update Magnitude: 0.60290

Collected Steps per Second: 22,818.58518
Overall Steps per Second: 10,799.57880

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.43978
PPO Batch Consumption Time: 0.28316
Total Iteration Time: 4.63203

Cumulative Model Updates: 114,814
Cumulative Timesteps: 957,499,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 957499976...
Checkpoint 957499976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,460.19665
Policy Entropy: 3.06062
Value Function Loss: 0.00481

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09828
Policy Update Magnitude: 0.55041
Value Function Update Magnitude: 0.60612

Collected Steps per Second: 22,708.96337
Overall Steps per Second: 10,642.61774

Timestep Collection Time: 2.20230
Timestep Consumption Time: 2.49692
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.69922

Cumulative Model Updates: 114,820
Cumulative Timesteps: 957,549,988

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.48913
Policy Entropy: 3.06355
Value Function Loss: 0.00486

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09960
Policy Update Magnitude: 0.55630
Value Function Update Magnitude: 0.61253

Collected Steps per Second: 22,883.73269
Overall Steps per Second: 10,725.62180

Timestep Collection Time: 2.18636
Timestep Consumption Time: 2.47836
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.66472

Cumulative Model Updates: 114,826
Cumulative Timesteps: 957,600,020

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 957600020...
Checkpoint 957600020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.60385
Policy Entropy: 3.05053
Value Function Loss: 0.00478

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.55903
Value Function Update Magnitude: 0.61714

Collected Steps per Second: 22,803.57799
Overall Steps per Second: 10,843.32807

Timestep Collection Time: 2.19316
Timestep Consumption Time: 2.41907
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.61224

Cumulative Model Updates: 114,832
Cumulative Timesteps: 957,650,032

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.08000
Policy Entropy: 3.04538
Value Function Loss: 0.00512

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.09775
Policy Update Magnitude: 0.56744
Value Function Update Magnitude: 0.60250

Collected Steps per Second: 22,983.31648
Overall Steps per Second: 10,853.47229

Timestep Collection Time: 2.17558
Timestep Consumption Time: 2.43143
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.60700

Cumulative Model Updates: 114,838
Cumulative Timesteps: 957,700,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 957700034...
Checkpoint 957700034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 952.40748
Policy Entropy: 3.03885
Value Function Loss: 0.00539

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10353
Policy Update Magnitude: 0.58884
Value Function Update Magnitude: 0.61028

Collected Steps per Second: 22,380.53931
Overall Steps per Second: 10,754.82482

Timestep Collection Time: 2.23551
Timestep Consumption Time: 2.41654
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.65205

Cumulative Model Updates: 114,844
Cumulative Timesteps: 957,750,066

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 734.77037
Policy Entropy: 3.03903
Value Function Loss: 0.00546

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.12482
Policy Update Magnitude: 0.58717
Value Function Update Magnitude: 0.62907

Collected Steps per Second: 22,899.24073
Overall Steps per Second: 10,810.83534

Timestep Collection Time: 2.18435
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.62684

Cumulative Model Updates: 114,850
Cumulative Timesteps: 957,800,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 957800086...
Checkpoint 957800086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.76621
Policy Entropy: 3.05501
Value Function Loss: 0.00512

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.12247
Policy Update Magnitude: 0.57452
Value Function Update Magnitude: 0.63452

Collected Steps per Second: 22,910.81649
Overall Steps per Second: 10,701.73457

Timestep Collection Time: 2.18238
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.67214

Cumulative Model Updates: 114,856
Cumulative Timesteps: 957,850,086

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.69737
Policy Entropy: 3.06207
Value Function Loss: 0.00516

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.56473
Value Function Update Magnitude: 0.61350

Collected Steps per Second: 22,653.37969
Overall Steps per Second: 10,760.71767

Timestep Collection Time: 2.20771
Timestep Consumption Time: 2.43994
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.64765

Cumulative Model Updates: 114,862
Cumulative Timesteps: 957,900,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 957900098...
Checkpoint 957900098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,455.39718
Policy Entropy: 3.07436
Value Function Loss: 0.00512

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10698
Policy Update Magnitude: 0.56326
Value Function Update Magnitude: 0.61679

Collected Steps per Second: 22,748.68465
Overall Steps per Second: 10,754.44336

Timestep Collection Time: 2.19907
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.65166

Cumulative Model Updates: 114,868
Cumulative Timesteps: 957,950,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862.17069
Policy Entropy: 3.05701
Value Function Loss: 0.00521

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.56482
Value Function Update Magnitude: 0.61026

Collected Steps per Second: 22,906.27079
Overall Steps per Second: 10,842.84292

Timestep Collection Time: 2.18290
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.28204
Total Iteration Time: 4.61152

Cumulative Model Updates: 114,874
Cumulative Timesteps: 958,000,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 958000126...
Checkpoint 958000126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 800.57211
Policy Entropy: 3.04549
Value Function Loss: 0.00529

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.11074
Policy Update Magnitude: 0.57187
Value Function Update Magnitude: 0.60762

Collected Steps per Second: 22,304.38360
Overall Steps per Second: 10,704.15574

Timestep Collection Time: 2.24315
Timestep Consumption Time: 2.43093
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.67407

Cumulative Model Updates: 114,880
Cumulative Timesteps: 958,050,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,425.16109
Policy Entropy: 3.05036
Value Function Loss: 0.00524

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11924
Policy Update Magnitude: 0.57555
Value Function Update Magnitude: 0.61103

Collected Steps per Second: 22,802.54774
Overall Steps per Second: 10,835.10299

Timestep Collection Time: 2.19335
Timestep Consumption Time: 2.42257
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.61592

Cumulative Model Updates: 114,886
Cumulative Timesteps: 958,100,172

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 958100172...
Checkpoint 958100172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.50236
Policy Entropy: 3.05897
Value Function Loss: 0.00539

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10149
Policy Update Magnitude: 0.57853
Value Function Update Magnitude: 0.62844

Collected Steps per Second: 22,485.38962
Overall Steps per Second: 10,764.57732

Timestep Collection Time: 2.22393
Timestep Consumption Time: 2.42149
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.64542

Cumulative Model Updates: 114,892
Cumulative Timesteps: 958,150,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,789.63487
Policy Entropy: 3.06417
Value Function Loss: 0.00520

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.57849
Value Function Update Magnitude: 0.64825

Collected Steps per Second: 23,242.05203
Overall Steps per Second: 10,840.84831

Timestep Collection Time: 2.15188
Timestep Consumption Time: 2.46160
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.61348

Cumulative Model Updates: 114,898
Cumulative Timesteps: 958,200,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 958200192...
Checkpoint 958200192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,584.32635
Policy Entropy: 3.06157
Value Function Loss: 0.00508

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09508
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.62874

Collected Steps per Second: 22,455.75005
Overall Steps per Second: 10,664.62861

Timestep Collection Time: 2.22660
Timestep Consumption Time: 2.46179
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.68840

Cumulative Model Updates: 114,904
Cumulative Timesteps: 958,250,192

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 885.94626
Policy Entropy: 3.06050
Value Function Loss: 0.00515

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09844
Policy Update Magnitude: 0.57591
Value Function Update Magnitude: 0.63869

Collected Steps per Second: 22,891.08238
Overall Steps per Second: 10,825.29031

Timestep Collection Time: 2.18513
Timestep Consumption Time: 2.43553
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.62066

Cumulative Model Updates: 114,910
Cumulative Timesteps: 958,300,212

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 958300212...
Checkpoint 958300212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,470.85532
Policy Entropy: 3.05476
Value Function Loss: 0.00511

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10179
Policy Update Magnitude: 0.57130
Value Function Update Magnitude: 0.64641

Collected Steps per Second: 22,499.25371
Overall Steps per Second: 10,749.22771

Timestep Collection Time: 2.22265
Timestep Consumption Time: 2.42959
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.65224

Cumulative Model Updates: 114,916
Cumulative Timesteps: 958,350,220

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.59052
Policy Entropy: 3.05385
Value Function Loss: 0.00523

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10719
Policy Update Magnitude: 0.57071
Value Function Update Magnitude: 0.64149

Collected Steps per Second: 22,869.10271
Overall Steps per Second: 10,810.85450

Timestep Collection Time: 2.18732
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.62702

Cumulative Model Updates: 114,922
Cumulative Timesteps: 958,400,242

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 958400242...
Checkpoint 958400242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,609.41045
Policy Entropy: 3.08097
Value Function Loss: 0.00518

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10262
Policy Update Magnitude: 0.57068
Value Function Update Magnitude: 0.63957

Collected Steps per Second: 22,524.95648
Overall Steps per Second: 10,739.99313

Timestep Collection Time: 2.22083
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.65773

Cumulative Model Updates: 114,928
Cumulative Timesteps: 958,450,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894.74080
Policy Entropy: 3.07380
Value Function Loss: 0.00505

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 0.64299

Collected Steps per Second: 22,631.33899
Overall Steps per Second: 10,776.92225

Timestep Collection Time: 2.21047
Timestep Consumption Time: 2.43148
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.64196

Cumulative Model Updates: 114,934
Cumulative Timesteps: 958,500,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 958500292...
Checkpoint 958500292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,007.68011
Policy Entropy: 3.07000
Value Function Loss: 0.00523

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.57192
Value Function Update Magnitude: 0.63294

Collected Steps per Second: 22,506.28135
Overall Steps per Second: 10,702.99149

Timestep Collection Time: 2.22214
Timestep Consumption Time: 2.45058
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.67271

Cumulative Model Updates: 114,940
Cumulative Timesteps: 958,550,304

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 852.85038
Policy Entropy: 3.04162
Value Function Loss: 0.00559

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.58492
Value Function Update Magnitude: 0.65474

Collected Steps per Second: 22,939.47930
Overall Steps per Second: 10,761.06540

Timestep Collection Time: 2.17982
Timestep Consumption Time: 2.46693
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.64675

Cumulative Model Updates: 114,946
Cumulative Timesteps: 958,600,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 958600308...
Checkpoint 958600308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 898.31768
Policy Entropy: 3.03299
Value Function Loss: 0.00575

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.58956
Value Function Update Magnitude: 0.67136

Collected Steps per Second: 22,740.28841
Overall Steps per Second: 10,794.02045

Timestep Collection Time: 2.19944
Timestep Consumption Time: 2.43423
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.63368

Cumulative Model Updates: 114,952
Cumulative Timesteps: 958,650,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,202.65652
Policy Entropy: 3.01985
Value Function Loss: 0.00577

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.12468
Policy Update Magnitude: 0.59400
Value Function Update Magnitude: 0.67373

Collected Steps per Second: 22,769.57288
Overall Steps per Second: 10,710.66883

Timestep Collection Time: 2.19723
Timestep Consumption Time: 2.47381
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.67104

Cumulative Model Updates: 114,958
Cumulative Timesteps: 958,700,354

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 958700354...
Checkpoint 958700354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 995.28964
Policy Entropy: 3.01748
Value Function Loss: 0.00558

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11268
Policy Update Magnitude: 0.58745
Value Function Update Magnitude: 0.67274

Collected Steps per Second: 22,919.37879
Overall Steps per Second: 10,839.96340

Timestep Collection Time: 2.18156
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.61256

Cumulative Model Updates: 114,964
Cumulative Timesteps: 958,750,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.99474
Policy Entropy: 3.01878
Value Function Loss: 0.00544

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.12699
Policy Update Magnitude: 0.57856
Value Function Update Magnitude: 0.66673

Collected Steps per Second: 23,022.47924
Overall Steps per Second: 10,862.12653

Timestep Collection Time: 2.17309
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.60591

Cumulative Model Updates: 114,970
Cumulative Timesteps: 958,800,384

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 958800384...
Checkpoint 958800384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 854.58433
Policy Entropy: 3.02928
Value Function Loss: 0.00519

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11037
Policy Update Magnitude: 0.57965
Value Function Update Magnitude: 0.66210

Collected Steps per Second: 22,450.37776
Overall Steps per Second: 10,738.91559

Timestep Collection Time: 2.22785
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.65745

Cumulative Model Updates: 114,976
Cumulative Timesteps: 958,850,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.79717
Policy Entropy: 3.05746
Value Function Loss: 0.00510

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.57659
Value Function Update Magnitude: 0.65121

Collected Steps per Second: 22,265.71398
Overall Steps per Second: 10,786.52174

Timestep Collection Time: 2.24686
Timestep Consumption Time: 2.39115
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.63801

Cumulative Model Updates: 114,982
Cumulative Timesteps: 958,900,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 958900428...
Checkpoint 958900428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.96622
Policy Entropy: 3.07750
Value Function Loss: 0.00490

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.11956
Policy Update Magnitude: 0.56856
Value Function Update Magnitude: 0.64560

Collected Steps per Second: 22,180.65253
Overall Steps per Second: 10,736.27711

Timestep Collection Time: 2.25485
Timestep Consumption Time: 2.40356
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.65841

Cumulative Model Updates: 114,988
Cumulative Timesteps: 958,950,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.59322
Policy Entropy: 3.07955
Value Function Loss: 0.00501

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.56193
Value Function Update Magnitude: 0.62960

Collected Steps per Second: 22,226.94501
Overall Steps per Second: 10,825.60162

Timestep Collection Time: 2.24961
Timestep Consumption Time: 2.36925
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.61887

Cumulative Model Updates: 114,994
Cumulative Timesteps: 959,000,444

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 959000444...
Checkpoint 959000444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.83579
Policy Entropy: 3.05245
Value Function Loss: 0.00524

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.11646
Policy Update Magnitude: 0.56880
Value Function Update Magnitude: 0.62221

Collected Steps per Second: 21,780.56844
Overall Steps per Second: 10,710.27363

Timestep Collection Time: 2.29636
Timestep Consumption Time: 2.37355
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.66991

Cumulative Model Updates: 115,000
Cumulative Timesteps: 959,050,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.25941
Policy Entropy: 3.05211
Value Function Loss: 0.00535

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11070
Policy Update Magnitude: 0.58086
Value Function Update Magnitude: 0.62653

Collected Steps per Second: 22,214.20993
Overall Steps per Second: 10,701.04857

Timestep Collection Time: 2.25126
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.67337

Cumulative Model Updates: 115,006
Cumulative Timesteps: 959,100,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 959100470...
Checkpoint 959100470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.91762
Policy Entropy: 3.03549
Value Function Loss: 0.00538

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.11990
Policy Update Magnitude: 0.57754
Value Function Update Magnitude: 0.61351

Collected Steps per Second: 22,245.17147
Overall Steps per Second: 10,800.55682

Timestep Collection Time: 2.24786
Timestep Consumption Time: 2.38190
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.62976

Cumulative Model Updates: 115,012
Cumulative Timesteps: 959,150,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 898.81015
Policy Entropy: 3.02676
Value Function Loss: 0.00571

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11500
Policy Update Magnitude: 0.58288
Value Function Update Magnitude: 0.60218

Collected Steps per Second: 22,152.82786
Overall Steps per Second: 10,647.99358

Timestep Collection Time: 2.25849
Timestep Consumption Time: 2.44023
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.69873

Cumulative Model Updates: 115,018
Cumulative Timesteps: 959,200,506

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 959200506...
Checkpoint 959200506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 826.56490
Policy Entropy: 3.03145
Value Function Loss: 0.00556

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.59032
Value Function Update Magnitude: 0.61495

Collected Steps per Second: 22,166.94074
Overall Steps per Second: 10,669.06934

Timestep Collection Time: 2.25705
Timestep Consumption Time: 2.43239
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.68944

Cumulative Model Updates: 115,024
Cumulative Timesteps: 959,250,538

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 892.52971
Policy Entropy: 3.04373
Value Function Loss: 0.00528

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.57929
Value Function Update Magnitude: 0.61436

Collected Steps per Second: 21,987.74721
Overall Steps per Second: 10,760.96767

Timestep Collection Time: 2.27481
Timestep Consumption Time: 2.37328
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.64810

Cumulative Model Updates: 115,030
Cumulative Timesteps: 959,300,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 959300556...
Checkpoint 959300556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,069.87783
Policy Entropy: 3.06330
Value Function Loss: 0.00496

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.56739
Value Function Update Magnitude: 0.60320

Collected Steps per Second: 22,771.62431
Overall Steps per Second: 10,624.86674

Timestep Collection Time: 2.19624
Timestep Consumption Time: 2.51083
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.70707

Cumulative Model Updates: 115,036
Cumulative Timesteps: 959,350,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.90984
Policy Entropy: 3.05928
Value Function Loss: 0.00530

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.11034
Policy Update Magnitude: 0.57487
Value Function Update Magnitude: 0.61163

Collected Steps per Second: 23,220.54621
Overall Steps per Second: 10,868.07346

Timestep Collection Time: 2.15395
Timestep Consumption Time: 2.44815
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.60210

Cumulative Model Updates: 115,042
Cumulative Timesteps: 959,400,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 959400584...
Checkpoint 959400584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.44286
Policy Entropy: 3.06190
Value Function Loss: 0.00523

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11484
Policy Update Magnitude: 0.58074
Value Function Update Magnitude: 0.62645

Collected Steps per Second: 22,914.86986
Overall Steps per Second: 10,676.41980

Timestep Collection Time: 2.18269
Timestep Consumption Time: 2.50203
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.68472

Cumulative Model Updates: 115,048
Cumulative Timesteps: 959,450,600

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 993.29247
Policy Entropy: 3.07886
Value Function Loss: 0.00524

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.57884
Value Function Update Magnitude: 0.62593

Collected Steps per Second: 23,145.10967
Overall Steps per Second: 10,831.35664

Timestep Collection Time: 2.16132
Timestep Consumption Time: 2.45712
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.61844

Cumulative Model Updates: 115,054
Cumulative Timesteps: 959,500,624

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 959500624...
Checkpoint 959500624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.01883
Policy Entropy: 3.08641
Value Function Loss: 0.00489

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11928
Policy Update Magnitude: 0.57079
Value Function Update Magnitude: 0.62773

Collected Steps per Second: 22,418.08948
Overall Steps per Second: 10,674.11513

Timestep Collection Time: 2.23159
Timestep Consumption Time: 2.45526
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.68685

Cumulative Model Updates: 115,060
Cumulative Timesteps: 959,550,652

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,308.26884
Policy Entropy: 3.08596
Value Function Loss: 0.00491

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.56762
Value Function Update Magnitude: 0.62793

Collected Steps per Second: 23,183.58163
Overall Steps per Second: 10,850.17065

Timestep Collection Time: 2.15773
Timestep Consumption Time: 2.45270
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.61043

Cumulative Model Updates: 115,066
Cumulative Timesteps: 959,600,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 959600676...
Checkpoint 959600676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.49949
Policy Entropy: 3.06806
Value Function Loss: 0.00517

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10298
Policy Update Magnitude: 0.57221
Value Function Update Magnitude: 0.61568

Collected Steps per Second: 22,490.20831
Overall Steps per Second: 10,722.72863

Timestep Collection Time: 2.22408
Timestep Consumption Time: 2.44078
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.66486

Cumulative Model Updates: 115,072
Cumulative Timesteps: 959,650,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,082.09440
Policy Entropy: 3.06634
Value Function Loss: 0.00552

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.58420
Value Function Update Magnitude: 0.61598

Collected Steps per Second: 23,228.30232
Overall Steps per Second: 10,862.54890

Timestep Collection Time: 2.15427
Timestep Consumption Time: 2.45239
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.60665

Cumulative Model Updates: 115,078
Cumulative Timesteps: 959,700,736

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 959700736...
Checkpoint 959700736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,450.64078
Policy Entropy: 3.07529
Value Function Loss: 0.00575

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10657
Policy Update Magnitude: 0.59071
Value Function Update Magnitude: 0.63411

Collected Steps per Second: 22,694.40562
Overall Steps per Second: 10,735.86355

Timestep Collection Time: 2.20433
Timestep Consumption Time: 2.45538
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.65971

Cumulative Model Updates: 115,084
Cumulative Timesteps: 959,750,762

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.29770
Policy Entropy: 3.07047
Value Function Loss: 0.00554

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10151
Policy Update Magnitude: 0.58968
Value Function Update Magnitude: 0.63316

Collected Steps per Second: 23,199.64024
Overall Steps per Second: 10,832.74308

Timestep Collection Time: 2.15590
Timestep Consumption Time: 2.46122
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.61711

Cumulative Model Updates: 115,090
Cumulative Timesteps: 959,800,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 959800778...
Checkpoint 959800778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,126.14204
Policy Entropy: 3.06020
Value Function Loss: 0.00539

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.58787
Value Function Update Magnitude: 0.60388

Collected Steps per Second: 22,628.87781
Overall Steps per Second: 10,740.01374

Timestep Collection Time: 2.21080
Timestep Consumption Time: 2.44729
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.65809

Cumulative Model Updates: 115,096
Cumulative Timesteps: 959,850,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 733.63563
Policy Entropy: 3.07477
Value Function Loss: 0.00519

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.11454
Policy Update Magnitude: 0.57479
Value Function Update Magnitude: 0.59731

Collected Steps per Second: 23,047.55869
Overall Steps per Second: 10,850.89001

Timestep Collection Time: 2.16969
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.60847

Cumulative Model Updates: 115,102
Cumulative Timesteps: 959,900,812

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 959900812...
Checkpoint 959900812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 871.19238
Policy Entropy: 3.08942
Value Function Loss: 0.00506

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.56547
Value Function Update Magnitude: 0.59607

Collected Steps per Second: 22,869.43261
Overall Steps per Second: 10,624.28958

Timestep Collection Time: 2.18737
Timestep Consumption Time: 2.52108
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.70846

Cumulative Model Updates: 115,108
Cumulative Timesteps: 959,950,836

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,994.05765
Policy Entropy: 3.10924
Value Function Loss: 0.00500

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.58446

Collected Steps per Second: 23,046.59825
Overall Steps per Second: 10,859.88895

Timestep Collection Time: 2.16986
Timestep Consumption Time: 2.43497
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.60484

Cumulative Model Updates: 115,114
Cumulative Timesteps: 960,000,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 960000844...
Checkpoint 960000844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,257.69544
Policy Entropy: 3.09692
Value Function Loss: 0.00520

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10617
Policy Update Magnitude: 0.56220
Value Function Update Magnitude: 0.57189

Collected Steps per Second: 22,528.07675
Overall Steps per Second: 10,691.13143

Timestep Collection Time: 2.21972
Timestep Consumption Time: 2.45762
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.67733

Cumulative Model Updates: 115,120
Cumulative Timesteps: 960,050,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.65438
Policy Entropy: 3.08067
Value Function Loss: 0.00552

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.57188
Value Function Update Magnitude: 0.58176

Collected Steps per Second: 23,297.39462
Overall Steps per Second: 10,867.52821

Timestep Collection Time: 2.14685
Timestep Consumption Time: 2.45548
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.60233

Cumulative Model Updates: 115,126
Cumulative Timesteps: 960,100,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 960100866...
Checkpoint 960100866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.71287
Policy Entropy: 3.07196
Value Function Loss: 0.00567

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.10210
Policy Update Magnitude: 0.58449
Value Function Update Magnitude: 0.59059

Collected Steps per Second: 22,695.83619
Overall Steps per Second: 10,749.40845

Timestep Collection Time: 2.20437
Timestep Consumption Time: 2.44984
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.65421

Cumulative Model Updates: 115,132
Cumulative Timesteps: 960,150,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.17517
Policy Entropy: 3.07902
Value Function Loss: 0.00561

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.11432
Policy Update Magnitude: 0.58603
Value Function Update Magnitude: 0.59344

Collected Steps per Second: 23,013.55040
Overall Steps per Second: 10,799.43543

Timestep Collection Time: 2.17359
Timestep Consumption Time: 2.45832
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.63191

Cumulative Model Updates: 115,138
Cumulative Timesteps: 960,200,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 960200918...
Checkpoint 960200918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.78988
Policy Entropy: 3.09402
Value Function Loss: 0.00568

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.58720
Value Function Update Magnitude: 0.60074

Collected Steps per Second: 22,511.02050
Overall Steps per Second: 10,682.98041

Timestep Collection Time: 2.22229
Timestep Consumption Time: 2.46049
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.68278

Cumulative Model Updates: 115,144
Cumulative Timesteps: 960,250,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 986.33384
Policy Entropy: 3.10669
Value Function Loss: 0.00526

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11422
Policy Update Magnitude: 0.58832
Value Function Update Magnitude: 0.61090

Collected Steps per Second: 23,032.52385
Overall Steps per Second: 10,790.03680

Timestep Collection Time: 2.17162
Timestep Consumption Time: 2.46395
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.63557

Cumulative Model Updates: 115,150
Cumulative Timesteps: 960,300,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 960300962...
Checkpoint 960300962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.90761
Policy Entropy: 3.10006
Value Function Loss: 0.00539

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.57587
Value Function Update Magnitude: 0.59756

Collected Steps per Second: 22,622.42091
Overall Steps per Second: 10,751.55673

Timestep Collection Time: 2.21135
Timestep Consumption Time: 2.44156
PPO Batch Consumption Time: 0.28235
Total Iteration Time: 4.65291

Cumulative Model Updates: 115,156
Cumulative Timesteps: 960,350,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 966.52435
Policy Entropy: 3.10073
Value Function Loss: 0.00549

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.57196
Value Function Update Magnitude: 0.59181

Collected Steps per Second: 23,061.93764
Overall Steps per Second: 10,728.94796

Timestep Collection Time: 2.16903
Timestep Consumption Time: 2.49331
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.66234

Cumulative Model Updates: 115,162
Cumulative Timesteps: 960,401,010

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 960401010...
Checkpoint 960401010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 986.03098
Policy Entropy: 3.07995
Value Function Loss: 0.00567

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10903
Policy Update Magnitude: 0.57711
Value Function Update Magnitude: 0.61282

Collected Steps per Second: 22,972.54056
Overall Steps per Second: 10,800.16113

Timestep Collection Time: 2.17730
Timestep Consumption Time: 2.45393
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.63123

Cumulative Model Updates: 115,168
Cumulative Timesteps: 960,451,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946.58696
Policy Entropy: 3.08521
Value Function Loss: 0.00523

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11538
Policy Update Magnitude: 0.57694
Value Function Update Magnitude: 0.61587

Collected Steps per Second: 22,862.17623
Overall Steps per Second: 10,638.61629

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.51334
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.70080

Cumulative Model Updates: 115,174
Cumulative Timesteps: 960,501,038

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 960501038...
Checkpoint 960501038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.50833
Policy Entropy: 3.08717
Value Function Loss: 0.00482

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.12016
Policy Update Magnitude: 0.56825
Value Function Update Magnitude: 0.60311

Collected Steps per Second: 22,630.64197
Overall Steps per Second: 10,574.85484

Timestep Collection Time: 2.20975
Timestep Consumption Time: 2.51921
PPO Batch Consumption Time: 0.29564
Total Iteration Time: 4.72895

Cumulative Model Updates: 115,180
Cumulative Timesteps: 960,551,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,181.86968
Policy Entropy: 3.09060
Value Function Loss: 0.00495

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.56642
Value Function Update Magnitude: 0.60866

Collected Steps per Second: 23,073.69208
Overall Steps per Second: 10,836.26208

Timestep Collection Time: 2.16723
Timestep Consumption Time: 2.44746
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.61469

Cumulative Model Updates: 115,186
Cumulative Timesteps: 960,601,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 960601052...
Checkpoint 960601052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 566.03838
Policy Entropy: 3.08149
Value Function Loss: 0.00526

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.11485
Policy Update Magnitude: 0.57822
Value Function Update Magnitude: 0.60779

Collected Steps per Second: 22,552.77991
Overall Steps per Second: 10,660.41983

Timestep Collection Time: 2.21791
Timestep Consumption Time: 2.47421
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.69212

Cumulative Model Updates: 115,192
Cumulative Timesteps: 960,651,072

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.34890
Policy Entropy: 3.08602
Value Function Loss: 0.00527

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10730
Policy Update Magnitude: 0.58864
Value Function Update Magnitude: 0.62933

Collected Steps per Second: 22,959.39356
Overall Steps per Second: 10,799.53138

Timestep Collection Time: 2.17802
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.63039

Cumulative Model Updates: 115,198
Cumulative Timesteps: 960,701,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 960701078...
Checkpoint 960701078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,590.42894
Policy Entropy: 3.07498
Value Function Loss: 0.00542

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10644
Policy Update Magnitude: 0.59611
Value Function Update Magnitude: 0.62863

Collected Steps per Second: 22,673.28454
Overall Steps per Second: 10,768.85535

Timestep Collection Time: 2.20524
Timestep Consumption Time: 2.43778
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.64302

Cumulative Model Updates: 115,204
Cumulative Timesteps: 960,751,078

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,247.86553
Policy Entropy: 3.08186
Value Function Loss: 0.00560

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10316
Policy Update Magnitude: 0.59399
Value Function Update Magnitude: 0.62443

Collected Steps per Second: 23,342.15566
Overall Steps per Second: 10,901.96679

Timestep Collection Time: 2.14316
Timestep Consumption Time: 2.44555
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.58871

Cumulative Model Updates: 115,210
Cumulative Timesteps: 960,801,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 960801104...
Checkpoint 960801104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,656.42586
Policy Entropy: 3.06567
Value Function Loss: 0.00565

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.59326
Value Function Update Magnitude: 0.61619

Collected Steps per Second: 22,356.53847
Overall Steps per Second: 10,631.75416

Timestep Collection Time: 2.23711
Timestep Consumption Time: 2.46710
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.70421

Cumulative Model Updates: 115,216
Cumulative Timesteps: 960,851,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 842.53500
Policy Entropy: 3.07954
Value Function Loss: 0.00542

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.58456
Value Function Update Magnitude: 0.60959

Collected Steps per Second: 23,138.08563
Overall Steps per Second: 10,839.10252

Timestep Collection Time: 2.16172
Timestep Consumption Time: 2.45287
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.61459

Cumulative Model Updates: 115,222
Cumulative Timesteps: 960,901,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 960901136...
Checkpoint 960901136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,198.71940
Policy Entropy: 3.08715
Value Function Loss: 0.00515

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09512
Policy Update Magnitude: 0.58096
Value Function Update Magnitude: 0.59684

Collected Steps per Second: 22,661.74395
Overall Steps per Second: 10,683.71116

Timestep Collection Time: 2.20680
Timestep Consumption Time: 2.47415
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.68096

Cumulative Model Updates: 115,228
Cumulative Timesteps: 960,951,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.01719
Policy Entropy: 3.08669
Value Function Loss: 0.00527

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09252
Policy Update Magnitude: 0.58054
Value Function Update Magnitude: 0.59949

Collected Steps per Second: 23,216.60407
Overall Steps per Second: 10,842.06260

Timestep Collection Time: 2.15501
Timestep Consumption Time: 2.45961
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.61462

Cumulative Model Updates: 115,234
Cumulative Timesteps: 961,001,178

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 961001178...
Checkpoint 961001178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,022.12291
Policy Entropy: 3.11124
Value Function Loss: 0.00537

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09373
Policy Update Magnitude: 0.58731
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 22,557.17559
Overall Steps per Second: 10,721.71963

Timestep Collection Time: 2.21748
Timestep Consumption Time: 2.44782
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.66530

Cumulative Model Updates: 115,240
Cumulative Timesteps: 961,051,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 785.80497
Policy Entropy: 3.10850
Value Function Loss: 0.00570

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.60170
Value Function Update Magnitude: 0.62069

Collected Steps per Second: 22,889.84185
Overall Steps per Second: 10,649.06437

Timestep Collection Time: 2.18638
Timestep Consumption Time: 2.51318
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.69957

Cumulative Model Updates: 115,246
Cumulative Timesteps: 961,101,244

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 961101244...
Checkpoint 961101244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,521.44586
Policy Entropy: 3.10658
Value Function Loss: 0.00577

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10726
Policy Update Magnitude: 0.61165
Value Function Update Magnitude: 0.63700

Collected Steps per Second: 23,040.82067
Overall Steps per Second: 10,805.96331

Timestep Collection Time: 2.17032
Timestep Consumption Time: 2.45731
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.62763

Cumulative Model Updates: 115,252
Cumulative Timesteps: 961,151,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,601.92293
Policy Entropy: 3.10279
Value Function Loss: 0.00584

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.60475
Value Function Update Magnitude: 0.64991

Collected Steps per Second: 22,985.99483
Overall Steps per Second: 10,711.51682

Timestep Collection Time: 2.17532
Timestep Consumption Time: 2.49274
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.66806

Cumulative Model Updates: 115,258
Cumulative Timesteps: 961,201,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 961201252...
Checkpoint 961201252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.60971
Policy Entropy: 3.10355
Value Function Loss: 0.00577

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.59810
Value Function Update Magnitude: 0.64065

Collected Steps per Second: 22,536.76104
Overall Steps per Second: 10,607.88677

Timestep Collection Time: 2.21895
Timestep Consumption Time: 2.49528
PPO Batch Consumption Time: 0.29478
Total Iteration Time: 4.71423

Cumulative Model Updates: 115,264
Cumulative Timesteps: 961,251,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.10457
Policy Entropy: 3.11011
Value Function Loss: 0.00565

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.59870
Value Function Update Magnitude: 0.63838

Collected Steps per Second: 23,198.24305
Overall Steps per Second: 10,773.02762

Timestep Collection Time: 2.15637
Timestep Consumption Time: 2.48708
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.64345

Cumulative Model Updates: 115,270
Cumulative Timesteps: 961,301,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 961301284...
Checkpoint 961301284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 747.38530
Policy Entropy: 3.09184
Value Function Loss: 0.00550

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11130
Policy Update Magnitude: 0.59286
Value Function Update Magnitude: 0.63086

Collected Steps per Second: 22,632.69772
Overall Steps per Second: 10,625.14332

Timestep Collection Time: 2.21061
Timestep Consumption Time: 2.49822
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.70883

Cumulative Model Updates: 115,276
Cumulative Timesteps: 961,351,316

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.33466
Policy Entropy: 3.09084
Value Function Loss: 0.00529

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10456
Policy Update Magnitude: 0.58750
Value Function Update Magnitude: 0.62409

Collected Steps per Second: 23,222.63241
Overall Steps per Second: 10,843.65623

Timestep Collection Time: 2.15376
Timestep Consumption Time: 2.45871
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.61247

Cumulative Model Updates: 115,282
Cumulative Timesteps: 961,401,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 961401332...
Checkpoint 961401332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 935.23302
Policy Entropy: 3.08086
Value Function Loss: 0.00547

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10709
Policy Update Magnitude: 0.58159
Value Function Update Magnitude: 0.61968

Collected Steps per Second: 22,553.72442
Overall Steps per Second: 10,714.24210

Timestep Collection Time: 2.21711
Timestep Consumption Time: 2.44995
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.66706

Cumulative Model Updates: 115,288
Cumulative Timesteps: 961,451,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 646.87869
Policy Entropy: 3.07759
Value Function Loss: 0.00561

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09787
Policy Update Magnitude: 0.58323
Value Function Update Magnitude: 0.60627

Collected Steps per Second: 23,060.60220
Overall Steps per Second: 10,808.73600

Timestep Collection Time: 2.16820
Timestep Consumption Time: 2.45769
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.62589

Cumulative Model Updates: 115,294
Cumulative Timesteps: 961,501,336

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 961501336...
Checkpoint 961501336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.03394
Policy Entropy: 3.08008
Value Function Loss: 0.00579

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.09970
Policy Update Magnitude: 0.59714
Value Function Update Magnitude: 0.61183

Collected Steps per Second: 22,590.77205
Overall Steps per Second: 10,761.43629

Timestep Collection Time: 2.21356
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.64678

Cumulative Model Updates: 115,300
Cumulative Timesteps: 961,551,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 638.11684
Policy Entropy: 3.08801
Value Function Loss: 0.00558

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10137
Policy Update Magnitude: 0.59701
Value Function Update Magnitude: 0.62877

Collected Steps per Second: 23,130.45903
Overall Steps per Second: 10,920.54399

Timestep Collection Time: 2.16208
Timestep Consumption Time: 2.41736
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.57944

Cumulative Model Updates: 115,306
Cumulative Timesteps: 961,601,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 961601352...
Checkpoint 961601352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,429.69352
Policy Entropy: 3.08687
Value Function Loss: 0.00531

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09042
Policy Update Magnitude: 0.59121
Value Function Update Magnitude: 0.62882

Collected Steps per Second: 22,745.73059
Overall Steps per Second: 10,612.87845

Timestep Collection Time: 2.19874
Timestep Consumption Time: 2.51365
PPO Batch Consumption Time: 0.29628
Total Iteration Time: 4.71239

Cumulative Model Updates: 115,312
Cumulative Timesteps: 961,651,364

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,414.00467
Policy Entropy: 3.07707
Value Function Loss: 0.00525

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.58035
Value Function Update Magnitude: 0.61783

Collected Steps per Second: 22,783.06381
Overall Steps per Second: 10,829.46184

Timestep Collection Time: 2.19602
Timestep Consumption Time: 2.42397
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.61999

Cumulative Model Updates: 115,318
Cumulative Timesteps: 961,701,396

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 961701396...
Checkpoint 961701396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,099.00159
Policy Entropy: 3.07479
Value Function Loss: 0.00516

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11537
Policy Update Magnitude: 0.58445
Value Function Update Magnitude: 0.59815

Collected Steps per Second: 22,755.49057
Overall Steps per Second: 10,721.35806

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.46632
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.66359

Cumulative Model Updates: 115,324
Cumulative Timesteps: 961,751,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,921.20543
Policy Entropy: 3.06721
Value Function Loss: 0.00524

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11320
Policy Update Magnitude: 0.58043
Value Function Update Magnitude: 0.58712

Collected Steps per Second: 22,835.90195
Overall Steps per Second: 10,846.21350

Timestep Collection Time: 2.19006
Timestep Consumption Time: 2.42095
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.61101

Cumulative Model Updates: 115,330
Cumulative Timesteps: 961,801,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 961801408...
Checkpoint 961801408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 814.09209
Policy Entropy: 3.08083
Value Function Loss: 0.00528

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10816
Policy Update Magnitude: 0.58395
Value Function Update Magnitude: 0.59797

Collected Steps per Second: 22,286.57736
Overall Steps per Second: 10,706.42504

Timestep Collection Time: 2.24494
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.67308

Cumulative Model Updates: 115,336
Cumulative Timesteps: 961,851,440

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,290.89590
Policy Entropy: 3.08352
Value Function Loss: 0.00535

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11588
Policy Update Magnitude: 0.59585
Value Function Update Magnitude: 0.61608

Collected Steps per Second: 22,987.99219
Overall Steps per Second: 10,871.27781

Timestep Collection Time: 2.17548
Timestep Consumption Time: 2.42471
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.60020

Cumulative Model Updates: 115,342
Cumulative Timesteps: 961,901,450

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 961901450...
Checkpoint 961901450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 977.53242
Policy Entropy: 3.08210
Value Function Loss: 0.00547

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10809
Policy Update Magnitude: 0.58938
Value Function Update Magnitude: 0.61677

Collected Steps per Second: 22,766.93314
Overall Steps per Second: 10,663.47745

Timestep Collection Time: 2.19643
Timestep Consumption Time: 2.49303
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.68946

Cumulative Model Updates: 115,348
Cumulative Timesteps: 961,951,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.10050
Policy Entropy: 3.05430
Value Function Loss: 0.00539

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10450
Policy Update Magnitude: 0.58491
Value Function Update Magnitude: 0.61473

Collected Steps per Second: 23,087.44527
Overall Steps per Second: 10,825.02260

Timestep Collection Time: 2.16568
Timestep Consumption Time: 2.45325
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.61893

Cumulative Model Updates: 115,354
Cumulative Timesteps: 962,001,456

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 962001456...
Checkpoint 962001456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 492.36640
Policy Entropy: 3.05472
Value Function Loss: 0.00511

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.58296
Value Function Update Magnitude: 0.62225

Collected Steps per Second: 22,360.03165
Overall Steps per Second: 10,733.47340

Timestep Collection Time: 2.23694
Timestep Consumption Time: 2.42306
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.66000

Cumulative Model Updates: 115,360
Cumulative Timesteps: 962,051,474

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.51661
Policy Entropy: 3.06408
Value Function Loss: 0.00490

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.57437
Value Function Update Magnitude: 0.62042

Collected Steps per Second: 23,039.75765
Overall Steps per Second: 10,863.83823

Timestep Collection Time: 2.17129
Timestep Consumption Time: 2.43353
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.60482

Cumulative Model Updates: 115,366
Cumulative Timesteps: 962,101,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 962101500...
Checkpoint 962101500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.16311
Policy Entropy: 3.06038
Value Function Loss: 0.00502

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09536
Policy Update Magnitude: 0.57792
Value Function Update Magnitude: 0.61634

Collected Steps per Second: 22,685.99989
Overall Steps per Second: 10,700.91187

Timestep Collection Time: 2.20506
Timestep Consumption Time: 2.46968
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.67474

Cumulative Model Updates: 115,372
Cumulative Timesteps: 962,151,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,392.19937
Policy Entropy: 3.06755
Value Function Loss: 0.00523

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.57968
Value Function Update Magnitude: 0.62160

Collected Steps per Second: 22,905.83156
Overall Steps per Second: 10,807.89793

Timestep Collection Time: 2.18320
Timestep Consumption Time: 2.44379
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.62699

Cumulative Model Updates: 115,378
Cumulative Timesteps: 962,201,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 962201532...
Checkpoint 962201532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 829.46623
Policy Entropy: 3.06714
Value Function Loss: 0.00520

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.57757
Value Function Update Magnitude: 0.60454

Collected Steps per Second: 22,600.56125
Overall Steps per Second: 10,710.34044

Timestep Collection Time: 2.21287
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.66951

Cumulative Model Updates: 115,384
Cumulative Timesteps: 962,251,544

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 855.86985
Policy Entropy: 3.08356
Value Function Loss: 0.00508

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09320
Policy Update Magnitude: 0.57587
Value Function Update Magnitude: 0.59225

Collected Steps per Second: 23,032.49696
Overall Steps per Second: 10,856.05001

Timestep Collection Time: 2.17128
Timestep Consumption Time: 2.43537
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.60665

Cumulative Model Updates: 115,390
Cumulative Timesteps: 962,301,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 962301554...
Checkpoint 962301554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.18309
Policy Entropy: 3.07466
Value Function Loss: 0.00486

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.56759
Value Function Update Magnitude: 0.57806

Collected Steps per Second: 22,779.57535
Overall Steps per Second: 10,695.71649

Timestep Collection Time: 2.19627
Timestep Consumption Time: 2.48131
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.67757

Cumulative Model Updates: 115,396
Cumulative Timesteps: 962,351,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.75739
Policy Entropy: 3.06876
Value Function Loss: 0.00514

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.09045
Policy Update Magnitude: 0.56667
Value Function Update Magnitude: 0.57177

Collected Steps per Second: 22,925.64561
Overall Steps per Second: 10,845.64069

Timestep Collection Time: 2.18105
Timestep Consumption Time: 2.42928
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.61033

Cumulative Model Updates: 115,402
Cumulative Timesteps: 962,401,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 962401586...
Checkpoint 962401586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,214.55603
Policy Entropy: 3.06773
Value Function Loss: 0.00521

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.59786

Collected Steps per Second: 22,282.57457
Overall Steps per Second: 10,679.45445

Timestep Collection Time: 2.24426
Timestep Consumption Time: 2.43837
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.68264

Cumulative Model Updates: 115,408
Cumulative Timesteps: 962,451,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.24031
Policy Entropy: 3.07574
Value Function Loss: 0.00512

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.56837
Value Function Update Magnitude: 0.60642

Collected Steps per Second: 23,027.69412
Overall Steps per Second: 10,893.32095

Timestep Collection Time: 2.17130
Timestep Consumption Time: 2.41867
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.58997

Cumulative Model Updates: 115,414
Cumulative Timesteps: 962,501,594

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 962501594...
Checkpoint 962501594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.93339
Policy Entropy: 3.05997
Value Function Loss: 0.00509

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10799
Policy Update Magnitude: 0.56885
Value Function Update Magnitude: 0.58639

Collected Steps per Second: 22,281.24246
Overall Steps per Second: 10,662.51093

Timestep Collection Time: 2.24458
Timestep Consumption Time: 2.44587
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.69045

Cumulative Model Updates: 115,420
Cumulative Timesteps: 962,551,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,152.92523
Policy Entropy: 3.05389
Value Function Loss: 0.00515

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.57312
Value Function Update Magnitude: 0.58823

Collected Steps per Second: 23,036.65799
Overall Steps per Second: 10,839.83519

Timestep Collection Time: 2.17132
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.61446

Cumulative Model Updates: 115,426
Cumulative Timesteps: 962,601,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 962601626...
Checkpoint 962601626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.08523
Policy Entropy: 3.05187
Value Function Loss: 0.00516

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10000
Policy Update Magnitude: 0.57725
Value Function Update Magnitude: 0.59383

Collected Steps per Second: 22,333.16199
Overall Steps per Second: 10,710.44396

Timestep Collection Time: 2.23891
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.66853

Cumulative Model Updates: 115,432
Cumulative Timesteps: 962,651,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 935.28572
Policy Entropy: 3.07276
Value Function Loss: 0.00507

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.57085
Value Function Update Magnitude: 0.57845

Collected Steps per Second: 23,233.49509
Overall Steps per Second: 10,952.12134

Timestep Collection Time: 2.15336
Timestep Consumption Time: 2.41471
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.56806

Cumulative Model Updates: 115,438
Cumulative Timesteps: 962,701,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 962701658...
Checkpoint 962701658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,282.83144
Policy Entropy: 3.08106
Value Function Loss: 0.00505

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.56130
Value Function Update Magnitude: 0.56081

Collected Steps per Second: 22,470.71951
Overall Steps per Second: 10,608.40285

Timestep Collection Time: 2.22530
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.71362

Cumulative Model Updates: 115,444
Cumulative Timesteps: 962,751,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 869.33879
Policy Entropy: 3.09706
Value Function Loss: 0.00521

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.56276
Value Function Update Magnitude: 0.55669

Collected Steps per Second: 22,960.82464
Overall Steps per Second: 10,820.53066

Timestep Collection Time: 2.17875
Timestep Consumption Time: 2.44449
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.62325

Cumulative Model Updates: 115,450
Cumulative Timesteps: 962,801,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 962801688...
Checkpoint 962801688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,452.73481
Policy Entropy: 3.10398
Value Function Loss: 0.00503

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.56148
Value Function Update Magnitude: 0.55492

Collected Steps per Second: 22,500.64148
Overall Steps per Second: 10,663.81468

Timestep Collection Time: 2.22260
Timestep Consumption Time: 2.46709
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.68969

Cumulative Model Updates: 115,456
Cumulative Timesteps: 962,851,698

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.94377
Policy Entropy: 3.10363
Value Function Loss: 0.00511

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10828
Policy Update Magnitude: 0.55468
Value Function Update Magnitude: 0.54152

Collected Steps per Second: 23,069.68765
Overall Steps per Second: 10,869.06880

Timestep Collection Time: 2.16743
Timestep Consumption Time: 2.43296
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.60039

Cumulative Model Updates: 115,462
Cumulative Timesteps: 962,901,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 962901700...
Checkpoint 962901700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,236.54747
Policy Entropy: 3.08599
Value Function Loss: 0.00485

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11987
Policy Update Magnitude: 0.54941
Value Function Update Magnitude: 0.53436

Collected Steps per Second: 22,765.28645
Overall Steps per Second: 10,722.05778

Timestep Collection Time: 2.19729
Timestep Consumption Time: 2.46804
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.66534

Cumulative Model Updates: 115,468
Cumulative Timesteps: 962,951,722

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,763.73114
Policy Entropy: 3.07354
Value Function Loss: 0.00502

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11350
Policy Update Magnitude: 0.55385
Value Function Update Magnitude: 0.54100

Collected Steps per Second: 23,129.01807
Overall Steps per Second: 10,879.06802

Timestep Collection Time: 2.16282
Timestep Consumption Time: 2.43536
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.59819

Cumulative Model Updates: 115,474
Cumulative Timesteps: 963,001,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 963001746...
Checkpoint 963001746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,129.29430
Policy Entropy: 3.07914
Value Function Loss: 0.00490

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09455
Policy Update Magnitude: 0.56759
Value Function Update Magnitude: 0.56033

Collected Steps per Second: 22,551.12244
Overall Steps per Second: 10,670.33383

Timestep Collection Time: 2.21816
Timestep Consumption Time: 2.46979
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.68795

Cumulative Model Updates: 115,480
Cumulative Timesteps: 963,051,768

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,412.70687
Policy Entropy: 3.08149
Value Function Loss: 0.00512

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10051
Policy Update Magnitude: 0.57161
Value Function Update Magnitude: 0.58203

Collected Steps per Second: 22,610.81272
Overall Steps per Second: 10,698.84370

Timestep Collection Time: 2.21151
Timestep Consumption Time: 2.46227
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.67378

Cumulative Model Updates: 115,486
Cumulative Timesteps: 963,101,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 963101772...
Checkpoint 963101772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 961.70282
Policy Entropy: 3.10174
Value Function Loss: 0.00527

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.11069
Policy Update Magnitude: 0.57853
Value Function Update Magnitude: 0.60443

Collected Steps per Second: 22,945.73171
Overall Steps per Second: 10,875.44128

Timestep Collection Time: 2.17975
Timestep Consumption Time: 2.41923
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.59899

Cumulative Model Updates: 115,492
Cumulative Timesteps: 963,151,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,490.57704
Policy Entropy: 3.09709
Value Function Loss: 0.00522

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.57563
Value Function Update Magnitude: 0.61898

Collected Steps per Second: 23,073.40951
Overall Steps per Second: 10,874.28088

Timestep Collection Time: 2.16786
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.59984

Cumulative Model Updates: 115,498
Cumulative Timesteps: 963,201,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 963201808...
Checkpoint 963201808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.95622
Policy Entropy: 3.08103
Value Function Loss: 0.00507

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.57043
Value Function Update Magnitude: 0.60737

Collected Steps per Second: 22,296.09472
Overall Steps per Second: 10,632.29612

Timestep Collection Time: 2.24299
Timestep Consumption Time: 2.46060
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.70359

Cumulative Model Updates: 115,504
Cumulative Timesteps: 963,251,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.21093
Policy Entropy: 3.06993
Value Function Loss: 0.00479

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.09143
Policy Update Magnitude: 0.56873
Value Function Update Magnitude: 0.59244

Collected Steps per Second: 23,066.92087
Overall Steps per Second: 10,872.41654

Timestep Collection Time: 2.16821
Timestep Consumption Time: 2.43187
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.60008

Cumulative Model Updates: 115,510
Cumulative Timesteps: 963,301,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 963301832...
Checkpoint 963301832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.76311
Policy Entropy: 3.09066
Value Function Loss: 0.00464

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.56123
Value Function Update Magnitude: 0.59049

Collected Steps per Second: 22,511.39402
Overall Steps per Second: 10,736.36908

Timestep Collection Time: 2.22119
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.65725

Cumulative Model Updates: 115,516
Cumulative Timesteps: 963,351,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,983.15478
Policy Entropy: 3.10879
Value Function Loss: 0.00460

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11404
Policy Update Magnitude: 0.55378
Value Function Update Magnitude: 0.59555

Collected Steps per Second: 23,138.63919
Overall Steps per Second: 10,852.20993

Timestep Collection Time: 2.16097
Timestep Consumption Time: 2.44657
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.60754

Cumulative Model Updates: 115,522
Cumulative Timesteps: 963,401,836

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 963401836...
Checkpoint 963401836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,148.63351
Policy Entropy: 3.10948
Value Function Loss: 0.00482

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11597
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.58354

Collected Steps per Second: 22,572.57485
Overall Steps per Second: 10,645.75400

Timestep Collection Time: 2.21561
Timestep Consumption Time: 2.48223
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.69784

Cumulative Model Updates: 115,528
Cumulative Timesteps: 963,451,848

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.69697
Policy Entropy: 3.09432
Value Function Loss: 0.00508

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10706
Policy Update Magnitude: 0.56955
Value Function Update Magnitude: 0.56812

Collected Steps per Second: 23,010.69522
Overall Steps per Second: 10,874.85753

Timestep Collection Time: 2.17386
Timestep Consumption Time: 2.42593
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.59978

Cumulative Model Updates: 115,534
Cumulative Timesteps: 963,501,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 963501870...
Checkpoint 963501870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,647.18597
Policy Entropy: 3.09070
Value Function Loss: 0.00528

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09852
Policy Update Magnitude: 0.57277
Value Function Update Magnitude: 0.58294

Collected Steps per Second: 22,896.49390
Overall Steps per Second: 10,678.82521

Timestep Collection Time: 2.18488
Timestep Consumption Time: 2.49972
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.68460

Cumulative Model Updates: 115,540
Cumulative Timesteps: 963,551,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.71087
Policy Entropy: 3.07731
Value Function Loss: 0.00515

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10190
Policy Update Magnitude: 0.57598
Value Function Update Magnitude: 0.59880

Collected Steps per Second: 23,024.93673
Overall Steps per Second: 10,867.10449

Timestep Collection Time: 2.17277
Timestep Consumption Time: 2.43084
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.60362

Cumulative Model Updates: 115,546
Cumulative Timesteps: 963,601,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 963601924...
Checkpoint 963601924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.67838
Policy Entropy: 3.07905
Value Function Loss: 0.00490

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.56495
Value Function Update Magnitude: 0.59592

Collected Steps per Second: 22,585.83931
Overall Steps per Second: 10,678.70761

Timestep Collection Time: 2.21484
Timestep Consumption Time: 2.46962
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.68446

Cumulative Model Updates: 115,552
Cumulative Timesteps: 963,651,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.24747
Policy Entropy: 3.09012
Value Function Loss: 0.00480

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.55607
Value Function Update Magnitude: 0.58764

Collected Steps per Second: 22,940.38436
Overall Steps per Second: 10,848.07619

Timestep Collection Time: 2.17974
Timestep Consumption Time: 2.42974
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.60948

Cumulative Model Updates: 115,558
Cumulative Timesteps: 963,701,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 963701952...
Checkpoint 963701952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,649.68541
Policy Entropy: 3.09668
Value Function Loss: 0.00497

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.08963
Policy Update Magnitude: 0.55678
Value Function Update Magnitude: 0.58761

Collected Steps per Second: 22,588.74560
Overall Steps per Second: 10,708.30552

Timestep Collection Time: 2.21358
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.66946

Cumulative Model Updates: 115,564
Cumulative Timesteps: 963,751,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.96441
Policy Entropy: 3.09579
Value Function Loss: 0.00476

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.56949
Value Function Update Magnitude: 0.60238

Collected Steps per Second: 22,974.48501
Overall Steps per Second: 10,844.55914

Timestep Collection Time: 2.17641
Timestep Consumption Time: 2.43438
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.61079

Cumulative Model Updates: 115,570
Cumulative Timesteps: 963,801,956

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 963801956...
Checkpoint 963801956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,004.41512
Policy Entropy: 3.10402
Value Function Loss: 0.00501

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09433
Policy Update Magnitude: 0.56833
Value Function Update Magnitude: 0.63691

Collected Steps per Second: 22,363.43101
Overall Steps per Second: 10,732.90928

Timestep Collection Time: 2.23696
Timestep Consumption Time: 2.42404
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.66099

Cumulative Model Updates: 115,576
Cumulative Timesteps: 963,851,982

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235.71610
Policy Entropy: 3.11370
Value Function Loss: 0.00507

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.09181
Policy Update Magnitude: 0.57369
Value Function Update Magnitude: 0.64657

Collected Steps per Second: 23,136.42221
Overall Steps per Second: 10,897.43260

Timestep Collection Time: 2.16144
Timestep Consumption Time: 2.42753
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.58897

Cumulative Model Updates: 115,582
Cumulative Timesteps: 963,901,990

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 963901990...
Checkpoint 963901990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,662.66935
Policy Entropy: 3.11803
Value Function Loss: 0.00512

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09838
Policy Update Magnitude: 0.57685
Value Function Update Magnitude: 0.64723

Collected Steps per Second: 22,423.11960
Overall Steps per Second: 10,643.82616

Timestep Collection Time: 2.23100
Timestep Consumption Time: 2.46900
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.70000

Cumulative Model Updates: 115,588
Cumulative Timesteps: 963,952,016

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,413.90746
Policy Entropy: 3.12212
Value Function Loss: 0.00520

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09820
Policy Update Magnitude: 0.57943
Value Function Update Magnitude: 0.65325

Collected Steps per Second: 23,212.79275
Overall Steps per Second: 10,910.94761

Timestep Collection Time: 2.15416
Timestep Consumption Time: 2.42876
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.58292

Cumulative Model Updates: 115,594
Cumulative Timesteps: 964,002,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 964002020...
Checkpoint 964002020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737.27496
Policy Entropy: 3.09745
Value Function Loss: 0.00499

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09695
Policy Update Magnitude: 0.57443
Value Function Update Magnitude: 0.65090

Collected Steps per Second: 22,520.72644
Overall Steps per Second: 10,582.40958

Timestep Collection Time: 2.22080
Timestep Consumption Time: 2.50535
PPO Batch Consumption Time: 0.29501
Total Iteration Time: 4.72614

Cumulative Model Updates: 115,600
Cumulative Timesteps: 964,052,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 877.43287
Policy Entropy: 3.09121
Value Function Loss: 0.00502

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.09028
Policy Update Magnitude: 0.57614
Value Function Update Magnitude: 0.63441

Collected Steps per Second: 23,184.94302
Overall Steps per Second: 10,888.72941

Timestep Collection Time: 2.15761
Timestep Consumption Time: 2.43650
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.59411

Cumulative Model Updates: 115,606
Cumulative Timesteps: 964,102,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 964102058...
Checkpoint 964102058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,435.66469
Policy Entropy: 3.08162
Value Function Loss: 0.00512

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09332
Policy Update Magnitude: 0.58007
Value Function Update Magnitude: 0.62582

Collected Steps per Second: 22,771.58165
Overall Steps per Second: 10,680.08297

Timestep Collection Time: 2.19589
Timestep Consumption Time: 2.48609
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.68199

Cumulative Model Updates: 115,612
Cumulative Timesteps: 964,152,062

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,038.57878
Policy Entropy: 3.08475
Value Function Loss: 0.00523

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.08893
Policy Update Magnitude: 0.58300
Value Function Update Magnitude: 0.63968

Collected Steps per Second: 22,939.07994
Overall Steps per Second: 10,836.80611

Timestep Collection Time: 2.18021
Timestep Consumption Time: 2.43480
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.61501

Cumulative Model Updates: 115,618
Cumulative Timesteps: 964,202,074

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 964202074...
Checkpoint 964202074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.69137
Policy Entropy: 3.07972
Value Function Loss: 0.00555

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.58352
Value Function Update Magnitude: 0.65601

Collected Steps per Second: 22,707.90057
Overall Steps per Second: 10,698.16487

Timestep Collection Time: 2.20267
Timestep Consumption Time: 2.47271
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.67538

Cumulative Model Updates: 115,624
Cumulative Timesteps: 964,252,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867.56847
Policy Entropy: 3.08351
Value Function Loss: 0.00558

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.10512
Policy Update Magnitude: 0.58471
Value Function Update Magnitude: 0.66265

Collected Steps per Second: 22,459.89050
Overall Steps per Second: 10,624.51455

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.48110
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.70836

Cumulative Model Updates: 115,630
Cumulative Timesteps: 964,302,116

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 964302116...
Checkpoint 964302116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 900.73847
Policy Entropy: 3.07945
Value Function Loss: 0.00545

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.58330
Value Function Update Magnitude: 0.65671

Collected Steps per Second: 22,961.32076
Overall Steps per Second: 10,855.34214

Timestep Collection Time: 2.17801
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.60695

Cumulative Model Updates: 115,636
Cumulative Timesteps: 964,352,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983.86014
Policy Entropy: 3.09108
Value Function Loss: 0.00527

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.57625
Value Function Update Magnitude: 0.63556

Collected Steps per Second: 22,524.40057
Overall Steps per Second: 10,610.04558

Timestep Collection Time: 2.21981
Timestep Consumption Time: 2.49270
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.71252

Cumulative Model Updates: 115,642
Cumulative Timesteps: 964,402,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 964402126...
Checkpoint 964402126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.53068
Policy Entropy: 3.08273
Value Function Loss: 0.00540

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.57793
Value Function Update Magnitude: 0.61996

Collected Steps per Second: 22,347.15835
Overall Steps per Second: 10,571.51011

Timestep Collection Time: 2.23849
Timestep Consumption Time: 2.49347
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.73196

Cumulative Model Updates: 115,648
Cumulative Timesteps: 964,452,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 928.09430
Policy Entropy: 3.08372
Value Function Loss: 0.00543

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09458
Policy Update Magnitude: 0.58189
Value Function Update Magnitude: 0.62208

Collected Steps per Second: 23,255.80855
Overall Steps per Second: 10,906.99636

Timestep Collection Time: 2.15138
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.58715

Cumulative Model Updates: 115,654
Cumulative Timesteps: 964,502,182

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 964502182...
Checkpoint 964502182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,134.11932
Policy Entropy: 3.06897
Value Function Loss: 0.00559

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10265
Policy Update Magnitude: 0.58478
Value Function Update Magnitude: 0.62145

Collected Steps per Second: 22,749.17549
Overall Steps per Second: 10,794.09213

Timestep Collection Time: 2.19815
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.63272

Cumulative Model Updates: 115,660
Cumulative Timesteps: 964,552,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,666.67641
Policy Entropy: 3.07863
Value Function Loss: 0.00543

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11175
Policy Update Magnitude: 0.58548
Value Function Update Magnitude: 0.60931

Collected Steps per Second: 22,635.08176
Overall Steps per Second: 10,782.38286

Timestep Collection Time: 2.20967
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.63868

Cumulative Model Updates: 115,666
Cumulative Timesteps: 964,602,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 964602204...
Checkpoint 964602204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.76564
Policy Entropy: 3.07888
Value Function Loss: 0.00519

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.11257
Policy Update Magnitude: 0.57759
Value Function Update Magnitude: 0.61271

Collected Steps per Second: 22,546.38245
Overall Steps per Second: 10,616.52634

Timestep Collection Time: 2.21818
Timestep Consumption Time: 2.49259
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.71077

Cumulative Model Updates: 115,672
Cumulative Timesteps: 964,652,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.51072
Policy Entropy: 3.10243
Value Function Loss: 0.00504

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.57882
Value Function Update Magnitude: 0.61305

Collected Steps per Second: 22,981.68190
Overall Steps per Second: 10,914.44673

Timestep Collection Time: 2.17695
Timestep Consumption Time: 2.40688
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.58383

Cumulative Model Updates: 115,678
Cumulative Timesteps: 964,702,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 964702246...
Checkpoint 964702246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.78498
Policy Entropy: 3.10001
Value Function Loss: 0.00489

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09609
Policy Update Magnitude: 0.58249
Value Function Update Magnitude: 0.61455

Collected Steps per Second: 22,230.54433
Overall Steps per Second: 10,647.28633

Timestep Collection Time: 2.24970
Timestep Consumption Time: 2.44746
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.69716

Cumulative Model Updates: 115,684
Cumulative Timesteps: 964,752,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,706.42882
Policy Entropy: 3.09143
Value Function Loss: 0.00496

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.58450
Value Function Update Magnitude: 0.60656

Collected Steps per Second: 22,901.33910
Overall Steps per Second: 10,821.45465

Timestep Collection Time: 2.18372
Timestep Consumption Time: 2.43766
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.62137

Cumulative Model Updates: 115,690
Cumulative Timesteps: 964,802,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 964802268...
Checkpoint 964802268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,708.96558
Policy Entropy: 3.08013
Value Function Loss: 0.00490

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.57059
Value Function Update Magnitude: 0.60167

Collected Steps per Second: 22,591.27580
Overall Steps per Second: 10,705.10693

Timestep Collection Time: 2.21369
Timestep Consumption Time: 2.45792
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.67160

Cumulative Model Updates: 115,696
Cumulative Timesteps: 964,852,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,067.37611
Policy Entropy: 3.09709
Value Function Loss: 0.00493

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10841
Policy Update Magnitude: 0.56861
Value Function Update Magnitude: 0.59963

Collected Steps per Second: 22,959.94374
Overall Steps per Second: 10,869.63607

Timestep Collection Time: 2.17893
Timestep Consumption Time: 2.42362
PPO Batch Consumption Time: 0.28120
Total Iteration Time: 4.60255

Cumulative Model Updates: 115,702
Cumulative Timesteps: 964,902,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 964902306...
Checkpoint 964902306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.47275
Policy Entropy: 3.10214
Value Function Loss: 0.00495

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10588
Policy Update Magnitude: 0.57029
Value Function Update Magnitude: 0.60233

Collected Steps per Second: 22,353.10688
Overall Steps per Second: 10,752.23587

Timestep Collection Time: 2.23790
Timestep Consumption Time: 2.41453
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.65243

Cumulative Model Updates: 115,708
Cumulative Timesteps: 964,952,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,640.79934
Policy Entropy: 3.09462
Value Function Loss: 0.00496

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.10634
Policy Update Magnitude: 0.57408
Value Function Update Magnitude: 0.61348

Collected Steps per Second: 23,062.35041
Overall Steps per Second: 10,901.74404

Timestep Collection Time: 2.16908
Timestep Consumption Time: 2.41955
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.58862

Cumulative Model Updates: 115,714
Cumulative Timesteps: 965,002,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 965002354...
Checkpoint 965002354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.90189
Policy Entropy: 3.07208
Value Function Loss: 0.00534

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.57977
Value Function Update Magnitude: 0.62232

Collected Steps per Second: 22,112.64442
Overall Steps per Second: 10,610.00890

Timestep Collection Time: 2.26187
Timestep Consumption Time: 2.45217
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.71404

Cumulative Model Updates: 115,720
Cumulative Timesteps: 965,052,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.89807
Policy Entropy: 3.07294
Value Function Loss: 0.00551

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.58756
Value Function Update Magnitude: 0.64332

Collected Steps per Second: 23,221.33034
Overall Steps per Second: 10,928.31422

Timestep Collection Time: 2.15336
Timestep Consumption Time: 2.42227
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.57564

Cumulative Model Updates: 115,726
Cumulative Timesteps: 965,102,374

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 965102374...
Checkpoint 965102374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,146.98529
Policy Entropy: 3.08044
Value Function Loss: 0.00542

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.57947
Value Function Update Magnitude: 0.64557

Collected Steps per Second: 22,276.37323
Overall Steps per Second: 10,653.35473

Timestep Collection Time: 2.24615
Timestep Consumption Time: 2.45059
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.69674

Cumulative Model Updates: 115,732
Cumulative Timesteps: 965,152,410

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.87461
Policy Entropy: 3.08213
Value Function Loss: 0.00537

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.58441
Value Function Update Magnitude: 0.64659

Collected Steps per Second: 23,015.45954
Overall Steps per Second: 10,820.87881

Timestep Collection Time: 2.17341
Timestep Consumption Time: 2.44932
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.62273

Cumulative Model Updates: 115,738
Cumulative Timesteps: 965,202,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 965202432...
Checkpoint 965202432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,536.81570
Policy Entropy: 3.08260
Value Function Loss: 0.00538

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.58083
Value Function Update Magnitude: 0.63917

Collected Steps per Second: 22,394.69255
Overall Steps per Second: 10,716.36695

Timestep Collection Time: 2.23312
Timestep Consumption Time: 2.43358
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.66669

Cumulative Model Updates: 115,744
Cumulative Timesteps: 965,252,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,572.16176
Policy Entropy: 3.09036
Value Function Loss: 0.00525

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.57800
Value Function Update Magnitude: 0.61882

Collected Steps per Second: 23,115.97630
Overall Steps per Second: 10,906.06460

Timestep Collection Time: 2.16387
Timestep Consumption Time: 2.42257
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.58644

Cumulative Model Updates: 115,750
Cumulative Timesteps: 965,302,462

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 965302462...
Checkpoint 965302462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 736.84043
Policy Entropy: 3.09320
Value Function Loss: 0.00532

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.57200
Value Function Update Magnitude: 0.60242

Collected Steps per Second: 22,822.93981
Overall Steps per Second: 10,662.50645

Timestep Collection Time: 2.19122
Timestep Consumption Time: 2.49905
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.69027

Cumulative Model Updates: 115,756
Cumulative Timesteps: 965,352,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.39754
Policy Entropy: 3.10519
Value Function Loss: 0.00523

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.57952
Value Function Update Magnitude: 0.61230

Collected Steps per Second: 22,980.19062
Overall Steps per Second: 10,826.88939

Timestep Collection Time: 2.17579
Timestep Consumption Time: 2.44234
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.61813

Cumulative Model Updates: 115,762
Cumulative Timesteps: 965,402,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 965402472...
Checkpoint 965402472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 773.27796
Policy Entropy: 3.10127
Value Function Loss: 0.00536

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.12813
Policy Update Magnitude: 0.58244
Value Function Update Magnitude: 0.62053

Collected Steps per Second: 22,658.05983
Overall Steps per Second: 10,677.23883

Timestep Collection Time: 2.20778
Timestep Consumption Time: 2.47733
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.68511

Cumulative Model Updates: 115,768
Cumulative Timesteps: 965,452,496

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,164.73531
Policy Entropy: 3.11334
Value Function Loss: 0.00506

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11416
Policy Update Magnitude: 0.58606
Value Function Update Magnitude: 0.63050

Collected Steps per Second: 22,909.15712
Overall Steps per Second: 10,855.46030

Timestep Collection Time: 2.18419
Timestep Consumption Time: 2.42529
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.60948

Cumulative Model Updates: 115,774
Cumulative Timesteps: 965,502,534

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 965502534...
Checkpoint 965502534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.44170
Policy Entropy: 3.12152
Value Function Loss: 0.00492

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11572
Policy Update Magnitude: 0.57177
Value Function Update Magnitude: 0.59899

Collected Steps per Second: 22,723.41465
Overall Steps per Second: 10,719.36246

Timestep Collection Time: 2.20081
Timestep Consumption Time: 2.46458
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.66539

Cumulative Model Updates: 115,780
Cumulative Timesteps: 965,552,544

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,478.82403
Policy Entropy: 3.13923
Value Function Loss: 0.00470

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09470
Policy Update Magnitude: 0.56500
Value Function Update Magnitude: 0.58992

Collected Steps per Second: 22,950.73512
Overall Steps per Second: 10,862.82652

Timestep Collection Time: 2.17928
Timestep Consumption Time: 2.42505
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.60433

Cumulative Model Updates: 115,786
Cumulative Timesteps: 965,602,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 965602560...
Checkpoint 965602560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.62708
Policy Entropy: 3.11610
Value Function Loss: 0.00462

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10263
Policy Update Magnitude: 0.56009
Value Function Update Magnitude: 0.56629

Collected Steps per Second: 22,394.77278
Overall Steps per Second: 10,650.99109

Timestep Collection Time: 2.23311
Timestep Consumption Time: 2.46223
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.69534

Cumulative Model Updates: 115,792
Cumulative Timesteps: 965,652,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555.09243
Policy Entropy: 3.10442
Value Function Loss: 0.00493

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09231
Policy Update Magnitude: 0.57042
Value Function Update Magnitude: 0.55697

Collected Steps per Second: 22,625.11381
Overall Steps per Second: 10,679.03311

Timestep Collection Time: 2.21108
Timestep Consumption Time: 2.47342
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.68451

Cumulative Model Updates: 115,798
Cumulative Timesteps: 965,702,596

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 965702596...
Checkpoint 965702596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.23000
Policy Entropy: 3.08779
Value Function Loss: 0.00524

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10459
Policy Update Magnitude: 0.58061
Value Function Update Magnitude: 0.57146

Collected Steps per Second: 22,626.53607
Overall Steps per Second: 10,784.67093

Timestep Collection Time: 2.21112
Timestep Consumption Time: 2.42787
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.63899

Cumulative Model Updates: 115,804
Cumulative Timesteps: 965,752,626

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,053.08903
Policy Entropy: 3.10044
Value Function Loss: 0.00510

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.57381
Value Function Update Magnitude: 0.58570

Collected Steps per Second: 22,585.42068
Overall Steps per Second: 10,574.17057

Timestep Collection Time: 2.21479
Timestep Consumption Time: 2.51579
PPO Batch Consumption Time: 0.29571
Total Iteration Time: 4.73058

Cumulative Model Updates: 115,810
Cumulative Timesteps: 965,802,648

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 965802648...
Checkpoint 965802648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.93747
Policy Entropy: 3.09929
Value Function Loss: 0.00506

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.56296
Value Function Update Magnitude: 0.58533

Collected Steps per Second: 22,738.92961
Overall Steps per Second: 10,661.13252

Timestep Collection Time: 2.20081
Timestep Consumption Time: 2.49325
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.69406

Cumulative Model Updates: 115,816
Cumulative Timesteps: 965,852,692

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603.16063
Policy Entropy: 3.08891
Value Function Loss: 0.00509

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.56812
Value Function Update Magnitude: 0.57758

Collected Steps per Second: 23,042.75537
Overall Steps per Second: 10,870.79812

Timestep Collection Time: 2.17153
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.60297

Cumulative Model Updates: 115,822
Cumulative Timesteps: 965,902,730

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 965902730...
Checkpoint 965902730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.22650
Policy Entropy: 3.06304
Value Function Loss: 0.00548

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.57709
Value Function Update Magnitude: 0.59593

Collected Steps per Second: 22,626.26979
Overall Steps per Second: 10,654.17867

Timestep Collection Time: 2.21017
Timestep Consumption Time: 2.48357
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.69375

Cumulative Model Updates: 115,828
Cumulative Timesteps: 965,952,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,739.66641
Policy Entropy: 3.06229
Value Function Loss: 0.00548

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09716
Policy Update Magnitude: 0.58035
Value Function Update Magnitude: 0.62551

Collected Steps per Second: 23,002.29015
Overall Steps per Second: 10,823.93563

Timestep Collection Time: 2.17387
Timestep Consumption Time: 2.44589
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.61976

Cumulative Model Updates: 115,834
Cumulative Timesteps: 966,002,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 966002742...
Checkpoint 966002742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.76494
Policy Entropy: 3.08578
Value Function Loss: 0.00506

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.09714
Policy Update Magnitude: 0.57944
Value Function Update Magnitude: 0.62909

Collected Steps per Second: 22,578.20002
Overall Steps per Second: 10,744.27269

Timestep Collection Time: 2.21506
Timestep Consumption Time: 2.43970
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.65476

Cumulative Model Updates: 115,840
Cumulative Timesteps: 966,052,754

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,150.90015
Policy Entropy: 3.09549
Value Function Loss: 0.00496

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09724
Policy Update Magnitude: 0.57638
Value Function Update Magnitude: 0.61738

Collected Steps per Second: 23,106.62216
Overall Steps per Second: 10,857.28020

Timestep Collection Time: 2.16492
Timestep Consumption Time: 2.44249
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.60742

Cumulative Model Updates: 115,846
Cumulative Timesteps: 966,102,778

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 966102778...
Checkpoint 966102778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,044.38084
Policy Entropy: 3.10783
Value Function Loss: 0.00492

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.09493
Policy Update Magnitude: 0.56864
Value Function Update Magnitude: 0.60946

Collected Steps per Second: 23,000.92836
Overall Steps per Second: 10,688.70649

Timestep Collection Time: 2.17383
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.67783

Cumulative Model Updates: 115,852
Cumulative Timesteps: 966,152,778

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.04169
Policy Entropy: 3.10766
Value Function Loss: 0.00497

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09987
Policy Update Magnitude: 0.56730
Value Function Update Magnitude: 0.61084

Collected Steps per Second: 23,016.77747
Overall Steps per Second: 10,859.33217

Timestep Collection Time: 2.17268
Timestep Consumption Time: 2.43240
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.60507

Cumulative Model Updates: 115,858
Cumulative Timesteps: 966,202,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 966202786...
Checkpoint 966202786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.29110
Policy Entropy: 3.11477
Value Function Loss: 0.00527

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10755
Policy Update Magnitude: 0.57330
Value Function Update Magnitude: 0.62064

Collected Steps per Second: 22,597.83255
Overall Steps per Second: 10,629.69000

Timestep Collection Time: 2.21304
Timestep Consumption Time: 2.49170
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.70475

Cumulative Model Updates: 115,864
Cumulative Timesteps: 966,252,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 886.18180
Policy Entropy: 3.10962
Value Function Loss: 0.00511

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09969
Policy Update Magnitude: 0.57939
Value Function Update Magnitude: 0.62629

Collected Steps per Second: 22,930.06408
Overall Steps per Second: 10,869.11360

Timestep Collection Time: 2.18133
Timestep Consumption Time: 2.42052
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.60185

Cumulative Model Updates: 115,870
Cumulative Timesteps: 966,302,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 966302814...
Checkpoint 966302814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.11028
Policy Entropy: 3.12324
Value Function Loss: 0.00508

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.57641
Value Function Update Magnitude: 0.61507

Collected Steps per Second: 22,741.65786
Overall Steps per Second: 10,727.46295

Timestep Collection Time: 2.19861
Timestep Consumption Time: 2.46233
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.66093

Cumulative Model Updates: 115,876
Cumulative Timesteps: 966,352,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 899.64239
Policy Entropy: 3.10481
Value Function Loss: 0.00492

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.09188
Policy Update Magnitude: 0.57257
Value Function Update Magnitude: 0.60777

Collected Steps per Second: 23,091.17131
Overall Steps per Second: 10,850.33256

Timestep Collection Time: 2.16637
Timestep Consumption Time: 2.44400
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.61037

Cumulative Model Updates: 115,882
Cumulative Timesteps: 966,402,838

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 966402838...
Checkpoint 966402838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,193.10213
Policy Entropy: 3.10582
Value Function Loss: 0.00538

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.57264
Value Function Update Magnitude: 0.61807

Collected Steps per Second: 22,514.80598
Overall Steps per Second: 10,705.28508

Timestep Collection Time: 2.22174
Timestep Consumption Time: 2.45091
PPO Batch Consumption Time: 0.28640
Total Iteration Time: 4.67265

Cumulative Model Updates: 115,888
Cumulative Timesteps: 966,452,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,499.99517
Policy Entropy: 3.08695
Value Function Loss: 0.00530

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.57241
Value Function Update Magnitude: 0.62050

Collected Steps per Second: 22,776.52352
Overall Steps per Second: 10,801.55023

Timestep Collection Time: 2.19586
Timestep Consumption Time: 2.43440
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.63026

Cumulative Model Updates: 115,894
Cumulative Timesteps: 966,502,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 966502874...
Checkpoint 966502874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.71191
Policy Entropy: 3.10673
Value Function Loss: 0.00557

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11367
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.60545

Collected Steps per Second: 22,557.34890
Overall Steps per Second: 10,760.53290

Timestep Collection Time: 2.21737
Timestep Consumption Time: 2.43091
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.64828

Cumulative Model Updates: 115,900
Cumulative Timesteps: 966,552,892

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,618.62521
Policy Entropy: 3.10467
Value Function Loss: 0.00513

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11509
Policy Update Magnitude: 0.56517
Value Function Update Magnitude: 0.61327

Collected Steps per Second: 22,457.26325
Overall Steps per Second: 10,615.16571

Timestep Collection Time: 2.22681
Timestep Consumption Time: 2.48419
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.71100

Cumulative Model Updates: 115,906
Cumulative Timesteps: 966,602,900

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 966602900...
Checkpoint 966602900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.49461
Policy Entropy: 3.10635
Value Function Loss: 0.00550

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.57212
Value Function Update Magnitude: 0.61994

Collected Steps per Second: 22,777.51109
Overall Steps per Second: 10,812.04077

Timestep Collection Time: 2.19585
Timestep Consumption Time: 2.43010
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.62595

Cumulative Model Updates: 115,912
Cumulative Timesteps: 966,652,916

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 740.99149
Policy Entropy: 3.09307
Value Function Loss: 0.00572

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.58599
Value Function Update Magnitude: 0.61943

Collected Steps per Second: 22,781.88218
Overall Steps per Second: 10,940.28817

Timestep Collection Time: 2.19534
Timestep Consumption Time: 2.37620
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.57154

Cumulative Model Updates: 115,918
Cumulative Timesteps: 966,702,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 966702930...
Checkpoint 966702930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,408.78513
Policy Entropy: 3.08559
Value Function Loss: 0.00595

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.11397
Policy Update Magnitude: 0.59024
Value Function Update Magnitude: 0.63020

Collected Steps per Second: 22,295.10506
Overall Steps per Second: 10,698.28178

Timestep Collection Time: 2.24363
Timestep Consumption Time: 2.43207
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.67570

Cumulative Model Updates: 115,924
Cumulative Timesteps: 966,752,952

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.99965
Policy Entropy: 3.07542
Value Function Loss: 0.00570

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10625
Policy Update Magnitude: 0.58290
Value Function Update Magnitude: 0.61417

Collected Steps per Second: 22,360.06057
Overall Steps per Second: 10,823.38630

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.38350
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.61963

Cumulative Model Updates: 115,930
Cumulative Timesteps: 966,802,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 966802952...
Checkpoint 966802952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730.67948
Policy Entropy: 3.07909
Value Function Loss: 0.00547

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.58123
Value Function Update Magnitude: 0.59073

Collected Steps per Second: 22,076.25208
Overall Steps per Second: 10,675.90842

Timestep Collection Time: 2.26488
Timestep Consumption Time: 2.41857
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.68344

Cumulative Model Updates: 115,936
Cumulative Timesteps: 966,852,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,418.12306
Policy Entropy: 3.07679
Value Function Loss: 0.00513

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.57500
Value Function Update Magnitude: 0.59600

Collected Steps per Second: 22,418.56986
Overall Steps per Second: 10,889.69984

Timestep Collection Time: 2.23092
Timestep Consumption Time: 2.36186
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.59278

Cumulative Model Updates: 115,942
Cumulative Timesteps: 966,902,966

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 966902966...
Checkpoint 966902966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 839.24436
Policy Entropy: 3.08737
Value Function Loss: 0.00495

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.57179
Value Function Update Magnitude: 0.58464

Collected Steps per Second: 22,114.39488
Overall Steps per Second: 10,684.48482

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.41958
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.68137

Cumulative Model Updates: 115,948
Cumulative Timesteps: 966,952,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.20410
Policy Entropy: 3.07699
Value Function Loss: 0.00491

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.56360
Value Function Update Magnitude: 0.56343

Collected Steps per Second: 22,613.55123
Overall Steps per Second: 10,864.36048

Timestep Collection Time: 2.21106
Timestep Consumption Time: 2.39114
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.60220

Cumulative Model Updates: 115,954
Cumulative Timesteps: 967,002,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 967002984...
Checkpoint 967002984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 685.32214
Policy Entropy: 3.07451
Value Function Loss: 0.00548

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.57156
Value Function Update Magnitude: 0.56817

Collected Steps per Second: 22,134.74919
Overall Steps per Second: 10,692.86868

Timestep Collection Time: 2.25898
Timestep Consumption Time: 2.41722
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.67620

Cumulative Model Updates: 115,960
Cumulative Timesteps: 967,052,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 858.47414
Policy Entropy: 3.07283
Value Function Loss: 0.00546

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10200
Policy Update Magnitude: 0.58775
Value Function Update Magnitude: 0.60180

Collected Steps per Second: 22,467.95904
Overall Steps per Second: 10,846.30333

Timestep Collection Time: 2.22610
Timestep Consumption Time: 2.38524
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.61134

Cumulative Model Updates: 115,966
Cumulative Timesteps: 967,103,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 967103002...
Checkpoint 967103002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 574.47816
Policy Entropy: 3.09033
Value Function Loss: 0.00579

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.58887
Value Function Update Magnitude: 0.60056

Collected Steps per Second: 22,690.29257
Overall Steps per Second: 10,716.27396

Timestep Collection Time: 2.20376
Timestep Consumption Time: 2.46241
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.66617

Cumulative Model Updates: 115,972
Cumulative Timesteps: 967,153,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679.06520
Policy Entropy: 3.09213
Value Function Loss: 0.00569

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.57674
Value Function Update Magnitude: 0.59350

Collected Steps per Second: 22,894.28695
Overall Steps per Second: 10,774.90714

Timestep Collection Time: 2.18491
Timestep Consumption Time: 2.45754
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.64245

Cumulative Model Updates: 115,978
Cumulative Timesteps: 967,203,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 967203028...
Checkpoint 967203028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.92698
Policy Entropy: 3.08674
Value Function Loss: 0.00527

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.56801
Value Function Update Magnitude: 0.58366

Collected Steps per Second: 22,655.81580
Overall Steps per Second: 10,716.43234

Timestep Collection Time: 2.20791
Timestep Consumption Time: 2.45987
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.66778

Cumulative Model Updates: 115,984
Cumulative Timesteps: 967,253,050

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767.25626
Policy Entropy: 3.07749
Value Function Loss: 0.00524

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09622
Policy Update Magnitude: 0.57116
Value Function Update Magnitude: 0.57915

Collected Steps per Second: 22,643.42416
Overall Steps per Second: 10,603.15157

Timestep Collection Time: 2.20850
Timestep Consumption Time: 2.50783
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.71633

Cumulative Model Updates: 115,990
Cumulative Timesteps: 967,303,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 967303058...
Checkpoint 967303058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 680.88222
Policy Entropy: 3.05944
Value Function Loss: 0.00506

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10928
Policy Update Magnitude: 0.57571
Value Function Update Magnitude: 0.59067

Collected Steps per Second: 23,114.53688
Overall Steps per Second: 10,867.03849

Timestep Collection Time: 2.16383
Timestep Consumption Time: 2.43871
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.60254

Cumulative Model Updates: 115,996
Cumulative Timesteps: 967,353,074

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,215.66276
Policy Entropy: 3.06383
Value Function Loss: 0.00514

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.57406
Value Function Update Magnitude: 0.58266

Collected Steps per Second: 22,720.62231
Overall Steps per Second: 10,573.55801

Timestep Collection Time: 2.20082
Timestep Consumption Time: 2.52834
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.72916

Cumulative Model Updates: 116,002
Cumulative Timesteps: 967,403,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 967403078...
Checkpoint 967403078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.13070
Policy Entropy: 3.06377
Value Function Loss: 0.00509

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.56012
Value Function Update Magnitude: 0.56921

Collected Steps per Second: 22,794.42179
Overall Steps per Second: 10,617.99631

Timestep Collection Time: 2.19369
Timestep Consumption Time: 2.51567
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.70936

Cumulative Model Updates: 116,008
Cumulative Timesteps: 967,453,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,514.77648
Policy Entropy: 3.08545
Value Function Loss: 0.00513

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.54386
Value Function Update Magnitude: 0.55394

Collected Steps per Second: 23,044.84150
Overall Steps per Second: 10,865.72070

Timestep Collection Time: 2.17012
Timestep Consumption Time: 2.43243
PPO Batch Consumption Time: 0.28134
Total Iteration Time: 4.60255

Cumulative Model Updates: 116,014
Cumulative Timesteps: 967,503,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 967503092...
Checkpoint 967503092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 742.51791
Policy Entropy: 3.10695
Value Function Loss: 0.00491

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11407
Policy Update Magnitude: 0.54979
Value Function Update Magnitude: 0.54932

Collected Steps per Second: 22,509.36090
Overall Steps per Second: 10,716.35128

Timestep Collection Time: 2.22254
Timestep Consumption Time: 2.44584
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.66838

Cumulative Model Updates: 116,020
Cumulative Timesteps: 967,553,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,219.90098
Policy Entropy: 3.09512
Value Function Loss: 0.00507

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.11207
Policy Update Magnitude: 0.54910
Value Function Update Magnitude: 0.55633

Collected Steps per Second: 22,894.04439
Overall Steps per Second: 10,788.20387

Timestep Collection Time: 2.18397
Timestep Consumption Time: 2.45072
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.63469

Cumulative Model Updates: 116,026
Cumulative Timesteps: 967,603,120

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 967603120...
Checkpoint 967603120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.92879
Policy Entropy: 3.08184
Value Function Loss: 0.00505

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11146
Policy Update Magnitude: 0.56242
Value Function Update Magnitude: 0.55974

Collected Steps per Second: 22,614.14691
Overall Steps per Second: 10,739.15293

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.44544
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.65698

Cumulative Model Updates: 116,032
Cumulative Timesteps: 967,653,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,155.06295
Policy Entropy: 3.05620
Value Function Loss: 0.00506

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.11361
Policy Update Magnitude: 0.56455
Value Function Update Magnitude: 0.56680

Collected Steps per Second: 22,935.38007
Overall Steps per Second: 10,791.85931

Timestep Collection Time: 2.18030
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.63368

Cumulative Model Updates: 116,038
Cumulative Timesteps: 967,703,138

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 967703138...
Checkpoint 967703138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.71548
Policy Entropy: 3.06425
Value Function Loss: 0.00499

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10910
Policy Update Magnitude: 0.56308
Value Function Update Magnitude: 0.57846

Collected Steps per Second: 22,259.43748
Overall Steps per Second: 10,643.37593

Timestep Collection Time: 2.24723
Timestep Consumption Time: 2.45260
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.69982

Cumulative Model Updates: 116,044
Cumulative Timesteps: 967,753,160

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 752.33704
Policy Entropy: 3.05319
Value Function Loss: 0.00501

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.56690
Value Function Update Magnitude: 0.58499

Collected Steps per Second: 22,819.57430
Overall Steps per Second: 10,589.84120

Timestep Collection Time: 2.19180
Timestep Consumption Time: 2.53121
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.72302

Cumulative Model Updates: 116,050
Cumulative Timesteps: 967,803,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 967803176...
Checkpoint 967803176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,375.71764
Policy Entropy: 3.06396
Value Function Loss: 0.00515

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.57162
Value Function Update Magnitude: 0.60813

Collected Steps per Second: 22,717.46993
Overall Steps per Second: 10,593.32847

Timestep Collection Time: 2.20183
Timestep Consumption Time: 2.52001
PPO Batch Consumption Time: 0.29642
Total Iteration Time: 4.72184

Cumulative Model Updates: 116,056
Cumulative Timesteps: 967,853,196

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,296.39669
Policy Entropy: 3.05881
Value Function Loss: 0.00536

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.56931
Value Function Update Magnitude: 0.60883

Collected Steps per Second: 22,883.43028
Overall Steps per Second: 10,682.06271

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.49606
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.68131

Cumulative Model Updates: 116,062
Cumulative Timesteps: 967,903,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 967903202...
Checkpoint 967903202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.86800
Policy Entropy: 3.06360
Value Function Loss: 0.00541

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11464
Policy Update Magnitude: 0.56634
Value Function Update Magnitude: 0.59206

Collected Steps per Second: 22,912.12935
Overall Steps per Second: 10,784.28119

Timestep Collection Time: 2.18269
Timestep Consumption Time: 2.45462
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.63730

Cumulative Model Updates: 116,068
Cumulative Timesteps: 967,953,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,692.37334
Policy Entropy: 3.06575
Value Function Loss: 0.00530

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.55585
Value Function Update Magnitude: 0.58494

Collected Steps per Second: 22,672.10530
Overall Steps per Second: 10,570.79928

Timestep Collection Time: 2.20597
Timestep Consumption Time: 2.52537
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.73134

Cumulative Model Updates: 116,074
Cumulative Timesteps: 968,003,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 968003226...
Checkpoint 968003226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.40809
Policy Entropy: 3.08550
Value Function Loss: 0.00514

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.55502
Value Function Update Magnitude: 0.57644

Collected Steps per Second: 22,643.12628
Overall Steps per Second: 10,568.09223

Timestep Collection Time: 2.20835
Timestep Consumption Time: 2.52325
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.73160

Cumulative Model Updates: 116,080
Cumulative Timesteps: 968,053,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 619.67917
Policy Entropy: 3.08280
Value Function Loss: 0.00512

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11742
Policy Update Magnitude: 0.55838
Value Function Update Magnitude: 0.56753

Collected Steps per Second: 22,489.96648
Overall Steps per Second: 10,531.28568

Timestep Collection Time: 2.22499
Timestep Consumption Time: 2.52656
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 4.75156

Cumulative Model Updates: 116,086
Cumulative Timesteps: 968,103,270

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 968103270...
Checkpoint 968103270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.93504
Policy Entropy: 3.08119
Value Function Loss: 0.00508

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.11349
Policy Update Magnitude: 0.55717
Value Function Update Magnitude: 0.56733

Collected Steps per Second: 22,761.10153
Overall Steps per Second: 10,663.62168

Timestep Collection Time: 2.19770
Timestep Consumption Time: 2.49320
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.69090

Cumulative Model Updates: 116,092
Cumulative Timesteps: 968,153,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.60668
Policy Entropy: 3.07681
Value Function Loss: 0.00517

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10984
Policy Update Magnitude: 0.55863
Value Function Update Magnitude: 0.57869

Collected Steps per Second: 22,936.96244
Overall Steps per Second: 10,803.70279

Timestep Collection Time: 2.17989
Timestep Consumption Time: 2.44816
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.62804

Cumulative Model Updates: 116,098
Cumulative Timesteps: 968,203,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 968203292...
Checkpoint 968203292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 682.67174
Policy Entropy: 3.07655
Value Function Loss: 0.00499

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.55612
Value Function Update Magnitude: 0.59703

Collected Steps per Second: 22,778.22493
Overall Steps per Second: 10,679.87961

Timestep Collection Time: 2.19622
Timestep Consumption Time: 2.48791
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.68414

Cumulative Model Updates: 116,104
Cumulative Timesteps: 968,253,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 745.73800
Policy Entropy: 3.08424
Value Function Loss: 0.00515

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10506
Policy Update Magnitude: 0.56385
Value Function Update Magnitude: 0.60294

Collected Steps per Second: 23,176.75492
Overall Steps per Second: 10,900.04082

Timestep Collection Time: 2.15785
Timestep Consumption Time: 2.43039
PPO Batch Consumption Time: 0.28207
Total Iteration Time: 4.58824

Cumulative Model Updates: 116,110
Cumulative Timesteps: 968,303,330

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 968303330...
Checkpoint 968303330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 844.03163
Policy Entropy: 3.07263
Value Function Loss: 0.00540

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11160
Policy Update Magnitude: 0.56931
Value Function Update Magnitude: 0.61101

Collected Steps per Second: 22,477.15685
Overall Steps per Second: 10,680.06559

Timestep Collection Time: 2.22546
Timestep Consumption Time: 2.45822
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.68368

Cumulative Model Updates: 116,116
Cumulative Timesteps: 968,353,352

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.00076
Policy Entropy: 3.07441
Value Function Loss: 0.00507

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11470
Policy Update Magnitude: 0.56559
Value Function Update Magnitude: 0.60869

Collected Steps per Second: 22,597.47925
Overall Steps per Second: 10,750.79502

Timestep Collection Time: 2.21308
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.65175

Cumulative Model Updates: 116,122
Cumulative Timesteps: 968,403,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 968403362...
Checkpoint 968403362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.00999
Policy Entropy: 3.06529
Value Function Loss: 0.00498

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11900
Policy Update Magnitude: 0.56205
Value Function Update Magnitude: 0.59877

Collected Steps per Second: 22,772.76987
Overall Steps per Second: 10,762.19254

Timestep Collection Time: 2.19569
Timestep Consumption Time: 2.45039
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.64608

Cumulative Model Updates: 116,128
Cumulative Timesteps: 968,453,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 725.80937
Policy Entropy: 3.07943
Value Function Loss: 0.00504

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.11216
Policy Update Magnitude: 0.56626
Value Function Update Magnitude: 0.59884

Collected Steps per Second: 22,795.94551
Overall Steps per Second: 10,778.99332

Timestep Collection Time: 2.19337
Timestep Consumption Time: 2.44528
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.63865

Cumulative Model Updates: 116,134
Cumulative Timesteps: 968,503,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 968503364...
Checkpoint 968503364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.42182
Policy Entropy: 3.07647
Value Function Loss: 0.00502

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.11486
Policy Update Magnitude: 0.56793
Value Function Update Magnitude: 0.59875

Collected Steps per Second: 22,701.85062
Overall Steps per Second: 10,766.68936

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.44256
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.64600

Cumulative Model Updates: 116,140
Cumulative Timesteps: 968,553,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.25349
Policy Entropy: 3.06763
Value Function Loss: 0.00514

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10862
Policy Update Magnitude: 0.56798
Value Function Update Magnitude: 0.60551

Collected Steps per Second: 22,617.99953
Overall Steps per Second: 10,684.03338

Timestep Collection Time: 2.21151
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.68175

Cumulative Model Updates: 116,146
Cumulative Timesteps: 968,603,406

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 968603406...
Checkpoint 968603406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635.29413
Policy Entropy: 3.07228
Value Function Loss: 0.00517

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.12078
Policy Update Magnitude: 0.57075
Value Function Update Magnitude: 0.59820

Collected Steps per Second: 22,683.61187
Overall Steps per Second: 10,782.48065

Timestep Collection Time: 2.20512
Timestep Consumption Time: 2.43389
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.63901

Cumulative Model Updates: 116,152
Cumulative Timesteps: 968,653,426

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.95584
Policy Entropy: 3.06847
Value Function Loss: 0.00542

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10324
Policy Update Magnitude: 0.57993
Value Function Update Magnitude: 0.59671

Collected Steps per Second: 22,429.76534
Overall Steps per Second: 10,590.87060

Timestep Collection Time: 2.22918
Timestep Consumption Time: 2.49187
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.72105

Cumulative Model Updates: 116,158
Cumulative Timesteps: 968,703,426

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 968703426...
Checkpoint 968703426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.76321
Policy Entropy: 3.05767
Value Function Loss: 0.00563

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.11112
Policy Update Magnitude: 0.58707
Value Function Update Magnitude: 0.59910

Collected Steps per Second: 22,425.90893
Overall Steps per Second: 10,573.48735

Timestep Collection Time: 2.22974
Timestep Consumption Time: 2.49944
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 4.72919

Cumulative Model Updates: 116,164
Cumulative Timesteps: 968,753,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.53183
Policy Entropy: 3.05886
Value Function Loss: 0.00552

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 0.58695
Value Function Update Magnitude: 0.61213

Collected Steps per Second: 22,962.40778
Overall Steps per Second: 10,801.72825

Timestep Collection Time: 2.17747
Timestep Consumption Time: 2.45142
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.62889

Cumulative Model Updates: 116,170
Cumulative Timesteps: 968,803,430

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 968803430...
Checkpoint 968803430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.25477
Policy Entropy: 3.05286
Value Function Loss: 0.00534

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11167
Policy Update Magnitude: 0.58067
Value Function Update Magnitude: 0.61222

Collected Steps per Second: 22,591.57147
Overall Steps per Second: 10,721.88555

Timestep Collection Time: 2.21357
Timestep Consumption Time: 2.45054
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.66410

Cumulative Model Updates: 116,176
Cumulative Timesteps: 968,853,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,377.16898
Policy Entropy: 3.05791
Value Function Loss: 0.00505

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.57214
Value Function Update Magnitude: 0.59768

Collected Steps per Second: 22,207.37173
Overall Steps per Second: 10,692.01369

Timestep Collection Time: 2.25268
Timestep Consumption Time: 2.42614
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.67882

Cumulative Model Updates: 116,182
Cumulative Timesteps: 968,903,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 968903464...
Checkpoint 968903464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.29413
Policy Entropy: 3.05614
Value Function Loss: 0.00508

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11291
Policy Update Magnitude: 0.56558
Value Function Update Magnitude: 0.58819

Collected Steps per Second: 22,342.94917
Overall Steps per Second: 10,876.57003

Timestep Collection Time: 2.23820
Timestep Consumption Time: 2.35957
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.59777

Cumulative Model Updates: 116,188
Cumulative Timesteps: 968,953,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 599.26310
Policy Entropy: 3.06002
Value Function Loss: 0.00526

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.57249
Value Function Update Magnitude: 0.58999

Collected Steps per Second: 22,191.47420
Overall Steps per Second: 10,781.33688

Timestep Collection Time: 2.25330
Timestep Consumption Time: 2.38472
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.63801

Cumulative Model Updates: 116,194
Cumulative Timesteps: 969,003,476

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 969003476...
Checkpoint 969003476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 759.93493
Policy Entropy: 3.08490
Value Function Loss: 0.00526

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.57651
Value Function Update Magnitude: 0.60469

Collected Steps per Second: 22,170.53954
Overall Steps per Second: 10,750.25775

Timestep Collection Time: 2.25552
Timestep Consumption Time: 2.39609
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.65161

Cumulative Model Updates: 116,200
Cumulative Timesteps: 969,053,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.48852
Policy Entropy: 3.09572
Value Function Loss: 0.00532

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.57365
Value Function Update Magnitude: 0.60746

Collected Steps per Second: 23,194.43003
Overall Steps per Second: 10,849.11731

Timestep Collection Time: 2.15612
Timestep Consumption Time: 2.45347
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.60959

Cumulative Model Updates: 116,206
Cumulative Timesteps: 969,103,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 969103492...
Checkpoint 969103492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.95408
Policy Entropy: 3.09171
Value Function Loss: 0.00552

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.11164
Policy Update Magnitude: 0.57990
Value Function Update Magnitude: 0.60161

Collected Steps per Second: 22,183.53187
Overall Steps per Second: 10,704.97435

Timestep Collection Time: 2.25483
Timestep Consumption Time: 2.41777
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.67259

Cumulative Model Updates: 116,212
Cumulative Timesteps: 969,153,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 786.65246
Policy Entropy: 3.08229
Value Function Loss: 0.00556

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.58112
Value Function Update Magnitude: 0.60369

Collected Steps per Second: 22,830.65618
Overall Steps per Second: 10,692.57599

Timestep Collection Time: 2.19013
Timestep Consumption Time: 2.48620
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.67633

Cumulative Model Updates: 116,218
Cumulative Timesteps: 969,203,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 969203514...
Checkpoint 969203514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.31734
Policy Entropy: 3.08858
Value Function Loss: 0.00553

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11456
Policy Update Magnitude: 0.58481
Value Function Update Magnitude: 0.61637

Collected Steps per Second: 22,916.73674
Overall Steps per Second: 10,786.51577

Timestep Collection Time: 2.18216
Timestep Consumption Time: 2.45400
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.63616

Cumulative Model Updates: 116,224
Cumulative Timesteps: 969,253,522

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,157.71934
Policy Entropy: 3.09143
Value Function Loss: 0.00515

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.57254
Value Function Update Magnitude: 0.61187

Collected Steps per Second: 22,599.55528
Overall Steps per Second: 10,587.59344

Timestep Collection Time: 2.21296
Timestep Consumption Time: 2.51068
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.72364

Cumulative Model Updates: 116,230
Cumulative Timesteps: 969,303,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 969303534...
Checkpoint 969303534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.50242
Policy Entropy: 3.08852
Value Function Loss: 0.00553

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.57573
Value Function Update Magnitude: 0.60425

Collected Steps per Second: 23,014.26596
Overall Steps per Second: 10,671.45741

Timestep Collection Time: 2.17291
Timestep Consumption Time: 2.51323
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.68615

Cumulative Model Updates: 116,236
Cumulative Timesteps: 969,353,542

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 822.28204
Policy Entropy: 3.09076
Value Function Loss: 0.00563

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10740
Policy Update Magnitude: 0.59062
Value Function Update Magnitude: 0.60799

Collected Steps per Second: 22,733.62603
Overall Steps per Second: 10,738.74049

Timestep Collection Time: 2.20000
Timestep Consumption Time: 2.45734
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.65734

Cumulative Model Updates: 116,242
Cumulative Timesteps: 969,403,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 969403556...
Checkpoint 969403556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 913.86842
Policy Entropy: 3.07843
Value Function Loss: 0.00572

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11065
Policy Update Magnitude: 0.57861
Value Function Update Magnitude: 0.60001

Collected Steps per Second: 22,882.12062
Overall Steps per Second: 10,713.88034

Timestep Collection Time: 2.18590
Timestep Consumption Time: 2.48262
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.66852

Cumulative Model Updates: 116,248
Cumulative Timesteps: 969,453,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518.44254
Policy Entropy: 3.09352
Value Function Loss: 0.00582

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.57016
Value Function Update Magnitude: 0.61108

Collected Steps per Second: 23,109.31697
Overall Steps per Second: 10,838.34003

Timestep Collection Time: 2.16458
Timestep Consumption Time: 2.45070
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.61528

Cumulative Model Updates: 116,254
Cumulative Timesteps: 969,503,596

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 969503596...
Checkpoint 969503596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.53394
Policy Entropy: 3.10036
Value Function Loss: 0.00578

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.13106
Policy Update Magnitude: 0.56771
Value Function Update Magnitude: 0.60067

Collected Steps per Second: 22,564.71009
Overall Steps per Second: 10,757.42674

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.43259
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.64888

Cumulative Model Updates: 116,260
Cumulative Timesteps: 969,553,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.52967
Policy Entropy: 3.13907
Value Function Loss: 0.00541

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.55908
Value Function Update Magnitude: 0.59488

Collected Steps per Second: 22,794.46979
Overall Steps per Second: 10,744.41128

Timestep Collection Time: 2.19351
Timestep Consumption Time: 2.46007
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.65358

Cumulative Model Updates: 116,266
Cumulative Timesteps: 969,603,606

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 969603606...
Checkpoint 969603606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 811.25653
Policy Entropy: 3.13661
Value Function Loss: 0.00558

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.57875

Collected Steps per Second: 22,897.49347
Overall Steps per Second: 10,750.98091

Timestep Collection Time: 2.18417
Timestep Consumption Time: 2.46769
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.65185

Cumulative Model Updates: 116,272
Cumulative Timesteps: 969,653,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.66604
Policy Entropy: 3.13830
Value Function Loss: 0.00602

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.54387
Value Function Update Magnitude: 0.58379

Collected Steps per Second: 23,033.17243
Overall Steps per Second: 10,787.82259

Timestep Collection Time: 2.17087
Timestep Consumption Time: 2.46417
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.63504

Cumulative Model Updates: 116,278
Cumulative Timesteps: 969,703,620

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 969703620...
Checkpoint 969703620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 533.35816
Policy Entropy: 3.13334
Value Function Loss: 0.00582

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.55951
Value Function Update Magnitude: 0.59115

Collected Steps per Second: 22,874.23396
Overall Steps per Second: 10,707.66043

Timestep Collection Time: 2.18700
Timestep Consumption Time: 2.48498
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.67198

Cumulative Model Updates: 116,284
Cumulative Timesteps: 969,753,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.69416
Policy Entropy: 3.14462
Value Function Loss: 0.00578

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.12359
Policy Update Magnitude: 0.56003
Value Function Update Magnitude: 0.60284

Collected Steps per Second: 22,646.71848
Overall Steps per Second: 10,564.18276

Timestep Collection Time: 2.20791
Timestep Consumption Time: 2.52525
PPO Batch Consumption Time: 0.29524
Total Iteration Time: 4.73316

Cumulative Model Updates: 116,290
Cumulative Timesteps: 969,803,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 969803648...
Checkpoint 969803648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.44894
Policy Entropy: 3.13065
Value Function Loss: 0.00521

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.11218
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.59033

Collected Steps per Second: 23,092.04484
Overall Steps per Second: 10,711.73176

Timestep Collection Time: 2.16585
Timestep Consumption Time: 2.50323
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.66909

Cumulative Model Updates: 116,296
Cumulative Timesteps: 969,853,662

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882.25886
Policy Entropy: 3.11792
Value Function Loss: 0.00527

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.55410
Value Function Update Magnitude: 0.57505

Collected Steps per Second: 23,003.11661
Overall Steps per Second: 10,769.13873

Timestep Collection Time: 2.17457
Timestep Consumption Time: 2.47036
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.64494

Cumulative Model Updates: 116,302
Cumulative Timesteps: 969,903,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 969903684...
Checkpoint 969903684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.48385
Policy Entropy: 3.10360
Value Function Loss: 0.00517

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10532
Policy Update Magnitude: 0.55768
Value Function Update Magnitude: 0.57271

Collected Steps per Second: 22,959.94911
Overall Steps per Second: 10,634.90461

Timestep Collection Time: 2.17797
Timestep Consumption Time: 2.52410
PPO Batch Consumption Time: 0.29592
Total Iteration Time: 4.70206

Cumulative Model Updates: 116,308
Cumulative Timesteps: 969,953,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 783.25631
Policy Entropy: 3.10181
Value Function Loss: 0.00563

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.56752
Value Function Update Magnitude: 0.57729

Collected Steps per Second: 22,815.58785
Overall Steps per Second: 10,778.03707

Timestep Collection Time: 2.19254
Timestep Consumption Time: 2.44875
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.64129

Cumulative Model Updates: 116,314
Cumulative Timesteps: 970,003,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 970003714...
Checkpoint 970003714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 808.89595
Policy Entropy: 3.10839
Value Function Loss: 0.00532

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09549
Policy Update Magnitude: 0.57340
Value Function Update Magnitude: 0.57540

Collected Steps per Second: 22,676.13884
Overall Steps per Second: 10,740.60771

Timestep Collection Time: 2.20620
Timestep Consumption Time: 2.45164
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.65784

Cumulative Model Updates: 116,320
Cumulative Timesteps: 970,053,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 951.33703
Policy Entropy: 3.09895
Value Function Loss: 0.00534

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.56722
Value Function Update Magnitude: 0.55624

Collected Steps per Second: 23,047.77084
Overall Steps per Second: 10,691.72648

Timestep Collection Time: 2.16941
Timestep Consumption Time: 2.50711
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.67651

Cumulative Model Updates: 116,326
Cumulative Timesteps: 970,103,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 970103742...
Checkpoint 970103742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582.60702
Policy Entropy: 3.09880
Value Function Loss: 0.00520

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09769
Policy Update Magnitude: 0.56022
Value Function Update Magnitude: 0.56799

Collected Steps per Second: 22,905.46499
Overall Steps per Second: 10,812.38529

Timestep Collection Time: 2.18358
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.62581

Cumulative Model Updates: 116,332
Cumulative Timesteps: 970,153,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 688.51661
Policy Entropy: 3.10254
Value Function Loss: 0.00547

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.09762
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.57275

Collected Steps per Second: 22,462.09634
Overall Steps per Second: 10,512.82692

Timestep Collection Time: 2.22686
Timestep Consumption Time: 2.53113
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.75800

Cumulative Model Updates: 116,338
Cumulative Timesteps: 970,203,778

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 970203778...
Checkpoint 970203778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 730.55242
Policy Entropy: 3.09813
Value Function Loss: 0.00543

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.56388
Value Function Update Magnitude: 0.57463

Collected Steps per Second: 22,554.38993
Overall Steps per Second: 10,714.82209

Timestep Collection Time: 2.21802
Timestep Consumption Time: 2.45084
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.66886

Cumulative Model Updates: 116,344
Cumulative Timesteps: 970,253,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.93009
Policy Entropy: 3.11002
Value Function Loss: 0.00535

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09413
Policy Update Magnitude: 0.56256
Value Function Update Magnitude: 0.57086

Collected Steps per Second: 22,808.24447
Overall Steps per Second: 10,815.60156

Timestep Collection Time: 2.19333
Timestep Consumption Time: 2.43203
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.62536

Cumulative Model Updates: 116,350
Cumulative Timesteps: 970,303,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 970303830...
Checkpoint 970303830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714.13513
Policy Entropy: 3.10618
Value Function Loss: 0.00518

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09093
Policy Update Magnitude: 0.55557
Value Function Update Magnitude: 0.57918

Collected Steps per Second: 22,835.21846
Overall Steps per Second: 10,692.11850

Timestep Collection Time: 2.18986
Timestep Consumption Time: 2.48704
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.67690

Cumulative Model Updates: 116,356
Cumulative Timesteps: 970,353,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 736.98090
Policy Entropy: 3.10248
Value Function Loss: 0.00518

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.09213
Policy Update Magnitude: 0.56365
Value Function Update Magnitude: 0.59956

Collected Steps per Second: 22,838.44613
Overall Steps per Second: 10,839.49457

Timestep Collection Time: 2.18929
Timestep Consumption Time: 2.42347
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.61276

Cumulative Model Updates: 116,362
Cumulative Timesteps: 970,403,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 970403836...
Checkpoint 970403836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.85478
Policy Entropy: 3.09404
Value Function Loss: 0.00504

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.56360
Value Function Update Magnitude: 0.61354

Collected Steps per Second: 22,860.72533
Overall Steps per Second: 10,698.64941

Timestep Collection Time: 2.18716
Timestep Consumption Time: 2.48633
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.67349

Cumulative Model Updates: 116,368
Cumulative Timesteps: 970,453,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.63462
Policy Entropy: 3.09498
Value Function Loss: 0.00493

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09935
Policy Update Magnitude: 0.55222
Value Function Update Magnitude: 0.60344

Collected Steps per Second: 23,103.49282
Overall Steps per Second: 10,880.40865

Timestep Collection Time: 2.16452
Timestep Consumption Time: 2.43163
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.59615

Cumulative Model Updates: 116,374
Cumulative Timesteps: 970,503,844

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 970503844...
Checkpoint 970503844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,046.89621
Policy Entropy: 3.08974
Value Function Loss: 0.00504

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.54627
Value Function Update Magnitude: 0.57733

Collected Steps per Second: 22,796.59471
Overall Steps per Second: 10,643.43604

Timestep Collection Time: 2.19375
Timestep Consumption Time: 2.50492
PPO Batch Consumption Time: 0.29660
Total Iteration Time: 4.69867

Cumulative Model Updates: 116,380
Cumulative Timesteps: 970,553,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.49140
Policy Entropy: 3.10317
Value Function Loss: 0.00529

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.10222
Policy Update Magnitude: 0.55089
Value Function Update Magnitude: 0.55384

Collected Steps per Second: 22,934.51472
Overall Steps per Second: 10,853.92106

Timestep Collection Time: 2.18099
Timestep Consumption Time: 2.42748
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.60847

Cumulative Model Updates: 116,386
Cumulative Timesteps: 970,603,874

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 970603874...
Checkpoint 970603874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642.12773
Policy Entropy: 3.09201
Value Function Loss: 0.00543

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.55831
Value Function Update Magnitude: 0.55872

Collected Steps per Second: 22,513.12246
Overall Steps per Second: 10,728.45424

Timestep Collection Time: 2.22253
Timestep Consumption Time: 2.44133
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.66386

Cumulative Model Updates: 116,392
Cumulative Timesteps: 970,653,910

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.53966
Policy Entropy: 3.08657
Value Function Loss: 0.00523

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.56815
Value Function Update Magnitude: 0.57584

Collected Steps per Second: 23,160.05950
Overall Steps per Second: 10,886.22011

Timestep Collection Time: 2.15967
Timestep Consumption Time: 2.43495
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.59462

Cumulative Model Updates: 116,398
Cumulative Timesteps: 970,703,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 970703928...
Checkpoint 970703928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.37717
Policy Entropy: 3.08365
Value Function Loss: 0.00536

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09482
Policy Update Magnitude: 0.58044
Value Function Update Magnitude: 0.57995

Collected Steps per Second: 22,633.47290
Overall Steps per Second: 10,668.63778

Timestep Collection Time: 2.21000
Timestep Consumption Time: 2.47851
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68851

Cumulative Model Updates: 116,404
Cumulative Timesteps: 970,753,948

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.07024
Policy Entropy: 3.07475
Value Function Loss: 0.00546

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.57823
Value Function Update Magnitude: 0.59017

Collected Steps per Second: 22,612.85141
Overall Steps per Second: 10,675.53292

Timestep Collection Time: 2.21166
Timestep Consumption Time: 2.47307
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.68473

Cumulative Model Updates: 116,410
Cumulative Timesteps: 970,803,960

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 970803960...
Checkpoint 970803960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.61488
Policy Entropy: 3.07648
Value Function Loss: 0.00555

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09569
Policy Update Magnitude: 0.57576
Value Function Update Magnitude: 0.59780

Collected Steps per Second: 22,695.09905
Overall Steps per Second: 10,825.02588

Timestep Collection Time: 2.20374
Timestep Consumption Time: 2.41648
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.62022

Cumulative Model Updates: 116,416
Cumulative Timesteps: 970,853,974

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 856.42015
Policy Entropy: 3.07215
Value Function Loss: 0.00538

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10064
Policy Update Magnitude: 0.57616
Value Function Update Magnitude: 0.61282

Collected Steps per Second: 22,654.18472
Overall Steps per Second: 10,608.12748

Timestep Collection Time: 2.20789
Timestep Consumption Time: 2.50717
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.71506

Cumulative Model Updates: 116,422
Cumulative Timesteps: 970,903,992

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 970903992...
Checkpoint 970903992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,017.96877
Policy Entropy: 3.07310
Value Function Loss: 0.00532

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.57551
Value Function Update Magnitude: 0.61748

Collected Steps per Second: 22,789.00240
Overall Steps per Second: 10,693.84510

Timestep Collection Time: 2.19439
Timestep Consumption Time: 2.48194
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.67633

Cumulative Model Updates: 116,428
Cumulative Timesteps: 970,954,000

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 699.21607
Policy Entropy: 3.07748
Value Function Loss: 0.00521

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09824
Policy Update Magnitude: 0.57357
Value Function Update Magnitude: 0.60634

Collected Steps per Second: 22,804.16426
Overall Steps per Second: 10,750.52544

Timestep Collection Time: 2.19267
Timestep Consumption Time: 2.45845
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.65112

Cumulative Model Updates: 116,434
Cumulative Timesteps: 971,004,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 971004002...
Checkpoint 971004002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 672.93146
Policy Entropy: 3.08024
Value Function Loss: 0.00512

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.56657
Value Function Update Magnitude: 0.60116

Collected Steps per Second: 23,127.88477
Overall Steps per Second: 11,015.96612

Timestep Collection Time: 2.16215
Timestep Consumption Time: 2.37726
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.53941

Cumulative Model Updates: 116,440
Cumulative Timesteps: 971,054,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479.27320
Policy Entropy: 3.08266
Value Function Loss: 0.00537

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.11741
Policy Update Magnitude: 0.57101
Value Function Update Magnitude: 0.60230

Collected Steps per Second: 22,007.03683
Overall Steps per Second: 10,630.92926

Timestep Collection Time: 2.27227
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.70382

Cumulative Model Updates: 116,446
Cumulative Timesteps: 971,104,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 971104014...
Checkpoint 971104014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 990.26040
Policy Entropy: 3.07815
Value Function Loss: 0.00513

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11503
Policy Update Magnitude: 0.57166
Value Function Update Magnitude: 0.61082

Collected Steps per Second: 22,246.79557
Overall Steps per Second: 10,704.78872

Timestep Collection Time: 2.24805
Timestep Consumption Time: 2.42387
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.67193

Cumulative Model Updates: 116,452
Cumulative Timesteps: 971,154,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.49437
Policy Entropy: 3.07168
Value Function Loss: 0.00523

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11237
Policy Update Magnitude: 0.57050
Value Function Update Magnitude: 0.61308

Collected Steps per Second: 21,772.91971
Overall Steps per Second: 10,695.61566

Timestep Collection Time: 2.29652
Timestep Consumption Time: 2.37848
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.67500

Cumulative Model Updates: 116,458
Cumulative Timesteps: 971,204,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 971204028...
Checkpoint 971204028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 967.93123
Policy Entropy: 3.07810
Value Function Loss: 0.00527

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.12210
Policy Update Magnitude: 0.57055
Value Function Update Magnitude: 0.62473

Collected Steps per Second: 22,067.72091
Overall Steps per Second: 10,681.54188

Timestep Collection Time: 2.26612
Timestep Consumption Time: 2.41561
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.68172

Cumulative Model Updates: 116,464
Cumulative Timesteps: 971,254,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,135.66969
Policy Entropy: 3.08564
Value Function Loss: 0.00562

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11010
Policy Update Magnitude: 0.57647
Value Function Update Magnitude: 0.63853

Collected Steps per Second: 22,024.79800
Overall Steps per Second: 10,627.36385

Timestep Collection Time: 2.27044
Timestep Consumption Time: 2.43496
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.70540

Cumulative Model Updates: 116,470
Cumulative Timesteps: 971,304,042

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 971304042...
Checkpoint 971304042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886.28499
Policy Entropy: 3.08195
Value Function Loss: 0.00557

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11828
Policy Update Magnitude: 0.58160
Value Function Update Magnitude: 0.65112

Collected Steps per Second: 22,293.52331
Overall Steps per Second: 10,841.85918

Timestep Collection Time: 2.24388
Timestep Consumption Time: 2.37009
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.61397

Cumulative Model Updates: 116,476
Cumulative Timesteps: 971,354,066

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.89598
Policy Entropy: 3.09053
Value Function Loss: 0.00541

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11428
Policy Update Magnitude: 0.58247
Value Function Update Magnitude: 0.63889

Collected Steps per Second: 22,264.42644
Overall Steps per Second: 10,678.23146

Timestep Collection Time: 2.24627
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.68355

Cumulative Model Updates: 116,482
Cumulative Timesteps: 971,404,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 971404078...
Checkpoint 971404078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 950.30806
Policy Entropy: 3.09346
Value Function Loss: 0.00516

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.10765
Policy Update Magnitude: 0.57783
Value Function Update Magnitude: 0.61291

Collected Steps per Second: 22,904.49687
Overall Steps per Second: 10,837.34870

Timestep Collection Time: 2.18324
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.61423

Cumulative Model Updates: 116,488
Cumulative Timesteps: 971,454,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 760.41661
Policy Entropy: 3.09418
Value Function Loss: 0.00539

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.10469
Policy Update Magnitude: 0.58110
Value Function Update Magnitude: 0.62052

Collected Steps per Second: 22,219.86217
Overall Steps per Second: 10,626.50837

Timestep Collection Time: 2.25042
Timestep Consumption Time: 2.45517
PPO Batch Consumption Time: 0.29588
Total Iteration Time: 4.70559

Cumulative Model Updates: 116,494
Cumulative Timesteps: 971,504,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 971504088...
Checkpoint 971504088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.28204
Policy Entropy: 3.09400
Value Function Loss: 0.00538

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10554
Policy Update Magnitude: 0.58238
Value Function Update Magnitude: 0.63220

Collected Steps per Second: 23,154.84215
Overall Steps per Second: 10,759.76362

Timestep Collection Time: 2.15989
Timestep Consumption Time: 2.48816
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.64806

Cumulative Model Updates: 116,500
Cumulative Timesteps: 971,554,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,306.80165
Policy Entropy: 3.09677
Value Function Loss: 0.00556

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10772
Policy Update Magnitude: 0.57830
Value Function Update Magnitude: 0.62469

Collected Steps per Second: 23,093.70189
Overall Steps per Second: 10,723.71459

Timestep Collection Time: 2.16587
Timestep Consumption Time: 2.49837
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.66424

Cumulative Model Updates: 116,506
Cumulative Timesteps: 971,604,118

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 971604118...
Checkpoint 971604118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.01424
Policy Entropy: 3.10737
Value Function Loss: 0.00532

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.12417
Policy Update Magnitude: 0.56638
Value Function Update Magnitude: 0.59359

Collected Steps per Second: 22,928.67011
Overall Steps per Second: 10,615.41106

Timestep Collection Time: 2.18076
Timestep Consumption Time: 2.52956
PPO Batch Consumption Time: 0.29549
Total Iteration Time: 4.71032

Cumulative Model Updates: 116,512
Cumulative Timesteps: 971,654,120

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 934.13949
Policy Entropy: 3.09717
Value Function Loss: 0.00529

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.12104
Policy Update Magnitude: 0.55703
Value Function Update Magnitude: 0.56001

Collected Steps per Second: 22,783.51587
Overall Steps per Second: 10,667.40405

Timestep Collection Time: 2.19510
Timestep Consumption Time: 2.49321
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.68830

Cumulative Model Updates: 116,518
Cumulative Timesteps: 971,704,132

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 971704132...
Checkpoint 971704132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 304.94898
Policy Entropy: 3.08786
Value Function Loss: 0.00552

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.55433
Value Function Update Magnitude: 0.55835

Collected Steps per Second: 23,060.62666
Overall Steps per Second: 10,827.74963

Timestep Collection Time: 2.16820
Timestep Consumption Time: 2.44957
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.61776

Cumulative Model Updates: 116,524
Cumulative Timesteps: 971,754,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229.25190
Policy Entropy: 3.07194
Value Function Loss: 0.00576

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.56545
Value Function Update Magnitude: 0.57611

Collected Steps per Second: 22,801.04574
Overall Steps per Second: 10,639.62084

Timestep Collection Time: 2.19358
Timestep Consumption Time: 2.50734
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.70092

Cumulative Model Updates: 116,530
Cumulative Timesteps: 971,804,148

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 971804148...
Checkpoint 971804148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599.61090
Policy Entropy: 3.07880
Value Function Loss: 0.00553

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.57317
Value Function Update Magnitude: 0.58262

Collected Steps per Second: 22,952.12799
Overall Steps per Second: 10,684.17940

Timestep Collection Time: 2.17949
Timestep Consumption Time: 2.50257
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.68206

Cumulative Model Updates: 116,536
Cumulative Timesteps: 971,854,172

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 643.26295
Policy Entropy: 3.05709
Value Function Loss: 0.00533

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.57509
Value Function Update Magnitude: 0.58195

Collected Steps per Second: 23,182.85696
Overall Steps per Second: 10,724.70085

Timestep Collection Time: 2.15677
Timestep Consumption Time: 2.50537
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.66213

Cumulative Model Updates: 116,542
Cumulative Timesteps: 971,904,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 971904172...
Checkpoint 971904172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 860.44814
Policy Entropy: 3.06820
Value Function Loss: 0.00501

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.11317
Policy Update Magnitude: 0.56166
Value Function Update Magnitude: 0.58203

Collected Steps per Second: 22,780.37827
Overall Steps per Second: 10,656.27269

Timestep Collection Time: 2.19601
Timestep Consumption Time: 2.49850
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.69451

Cumulative Model Updates: 116,548
Cumulative Timesteps: 971,954,198

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 672.05625
Policy Entropy: 3.06416
Value Function Loss: 0.00540

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.55958
Value Function Update Magnitude: 0.57334

Collected Steps per Second: 23,029.42015
Overall Steps per Second: 10,802.23872

Timestep Collection Time: 2.17140
Timestep Consumption Time: 2.45783
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.62923

Cumulative Model Updates: 116,554
Cumulative Timesteps: 972,004,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 972004204...
Checkpoint 972004204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.28846
Policy Entropy: 3.08343
Value Function Loss: 0.00572

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.57444
Value Function Update Magnitude: 0.58219

Collected Steps per Second: 22,631.94396
Overall Steps per Second: 10,793.46303

Timestep Collection Time: 2.21015
Timestep Consumption Time: 2.42414
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.63429

Cumulative Model Updates: 116,560
Cumulative Timesteps: 972,054,224

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,074.01811
Policy Entropy: 3.06892
Value Function Loss: 0.00550

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10563
Policy Update Magnitude: 0.57037
Value Function Update Magnitude: 0.60101

Collected Steps per Second: 22,912.52975
Overall Steps per Second: 10,786.85445

Timestep Collection Time: 2.18309
Timestep Consumption Time: 2.45404
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.63713

Cumulative Model Updates: 116,566
Cumulative Timesteps: 972,104,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 972104244...
Checkpoint 972104244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738.90763
Policy Entropy: 3.08202
Value Function Loss: 0.00533

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09923
Policy Update Magnitude: 0.57212
Value Function Update Magnitude: 0.61106

Collected Steps per Second: 22,625.68730
Overall Steps per Second: 10,664.00081

Timestep Collection Time: 2.21023
Timestep Consumption Time: 2.47919
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.68942

Cumulative Model Updates: 116,572
Cumulative Timesteps: 972,154,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.87984
Policy Entropy: 3.08613
Value Function Loss: 0.00514

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09979
Policy Update Magnitude: 0.56804
Value Function Update Magnitude: 0.62725

Collected Steps per Second: 22,923.45031
Overall Steps per Second: 10,696.74553

Timestep Collection Time: 2.18187
Timestep Consumption Time: 2.49394
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.67581

Cumulative Model Updates: 116,578
Cumulative Timesteps: 972,204,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 972204268...
Checkpoint 972204268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 905.27658
Policy Entropy: 3.08731
Value Function Loss: 0.00543

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.56382
Value Function Update Magnitude: 0.61057

Collected Steps per Second: 22,970.57885
Overall Steps per Second: 10,790.36663

Timestep Collection Time: 2.17678
Timestep Consumption Time: 2.45716
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.63395

Cumulative Model Updates: 116,584
Cumulative Timesteps: 972,254,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.70583
Policy Entropy: 3.09212
Value Function Loss: 0.00559

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.56797
Value Function Update Magnitude: 0.58303

Collected Steps per Second: 22,654.16124
Overall Steps per Second: 10,578.19826

Timestep Collection Time: 2.20728
Timestep Consumption Time: 2.51980
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.72708

Cumulative Model Updates: 116,590
Cumulative Timesteps: 972,304,274

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 972304274...
Checkpoint 972304274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 831.01226
Policy Entropy: 3.11094
Value Function Loss: 0.00570

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.58204

Collected Steps per Second: 22,754.41036
Overall Steps per Second: 10,574.22991

Timestep Collection Time: 2.19755
Timestep Consumption Time: 2.53130
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.72886

Cumulative Model Updates: 116,596
Cumulative Timesteps: 972,354,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 554.57932
Policy Entropy: 3.14314
Value Function Loss: 0.00592

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09075
Policy Update Magnitude: 0.56173
Value Function Update Magnitude: 0.58094

Collected Steps per Second: 23,007.77706
Overall Steps per Second: 10,701.35044

Timestep Collection Time: 2.17440
Timestep Consumption Time: 2.50053
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.67492

Cumulative Model Updates: 116,602
Cumulative Timesteps: 972,404,306

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 972404306...
Checkpoint 972404306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,218.59347
Policy Entropy: 3.14105
Value Function Loss: 0.00599

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.08522
Policy Update Magnitude: 0.56511
Value Function Update Magnitude: 0.58151

Collected Steps per Second: 22,524.58009
Overall Steps per Second: 10,572.38618

Timestep Collection Time: 2.21989
Timestep Consumption Time: 2.50960
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.72949

Cumulative Model Updates: 116,608
Cumulative Timesteps: 972,454,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,244.86618
Policy Entropy: 3.09346
Value Function Loss: 0.00582

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.09164
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.58403

Collected Steps per Second: 23,200.44157
Overall Steps per Second: 10,726.67138

Timestep Collection Time: 2.15522
Timestep Consumption Time: 2.50625
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.66146

Cumulative Model Updates: 116,614
Cumulative Timesteps: 972,504,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 972504310...
Checkpoint 972504310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 872.55568
Policy Entropy: 3.07181
Value Function Loss: 0.00546

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.10022
Policy Update Magnitude: 0.57472
Value Function Update Magnitude: 0.57672

Collected Steps per Second: 22,599.43771
Overall Steps per Second: 10,671.36528

Timestep Collection Time: 2.21351
Timestep Consumption Time: 2.47418
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.68769

Cumulative Model Updates: 116,620
Cumulative Timesteps: 972,554,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.83577
Policy Entropy: 3.07519
Value Function Loss: 0.00543

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.57536
Value Function Update Magnitude: 0.59199

Collected Steps per Second: 22,883.38839
Overall Steps per Second: 10,770.34106

Timestep Collection Time: 2.18534
Timestep Consumption Time: 2.45778
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.64312

Cumulative Model Updates: 116,626
Cumulative Timesteps: 972,604,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 972604342...
Checkpoint 972604342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 589.51735
Policy Entropy: 3.10301
Value Function Loss: 0.00509

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.56477
Value Function Update Magnitude: 0.58280

Collected Steps per Second: 22,686.49271
Overall Steps per Second: 10,794.95998

Timestep Collection Time: 2.20501
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.63401

Cumulative Model Updates: 116,632
Cumulative Timesteps: 972,654,366

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 944.94575
Policy Entropy: 3.10581
Value Function Loss: 0.00519

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09291
Policy Update Magnitude: 0.56190
Value Function Update Magnitude: 0.56229

Collected Steps per Second: 22,668.76930
Overall Steps per Second: 10,794.53575

Timestep Collection Time: 2.20682
Timestep Consumption Time: 2.42756
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.63438

Cumulative Model Updates: 116,638
Cumulative Timesteps: 972,704,392

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 972704392...
Checkpoint 972704392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.23631
Policy Entropy: 3.09889
Value Function Loss: 0.00512

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.56270
Value Function Update Magnitude: 0.55842

Collected Steps per Second: 22,867.79355
Overall Steps per Second: 10,692.47200

Timestep Collection Time: 2.18771
Timestep Consumption Time: 2.49110
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.67881

Cumulative Model Updates: 116,644
Cumulative Timesteps: 972,754,420

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846.37527
Policy Entropy: 3.09348
Value Function Loss: 0.00534

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09172
Policy Update Magnitude: 0.56447
Value Function Update Magnitude: 0.55714

Collected Steps per Second: 22,442.03686
Overall Steps per Second: 10,571.39998

Timestep Collection Time: 2.22814
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.73012

Cumulative Model Updates: 116,650
Cumulative Timesteps: 972,804,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 972804424...
Checkpoint 972804424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573.86071
Policy Entropy: 3.11798
Value Function Loss: 0.00563

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10283
Policy Update Magnitude: 0.57081
Value Function Update Magnitude: 0.57415

Collected Steps per Second: 22,973.05976
Overall Steps per Second: 10,750.22988

Timestep Collection Time: 2.17681
Timestep Consumption Time: 2.47500
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.65181

Cumulative Model Updates: 116,656
Cumulative Timesteps: 972,854,432

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,092.44969
Policy Entropy: 3.15190
Value Function Loss: 0.00561

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.57352
Value Function Update Magnitude: 0.58853

Collected Steps per Second: 22,496.02383
Overall Steps per Second: 10,710.38216

Timestep Collection Time: 2.22262
Timestep Consumption Time: 2.44575
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.66837

Cumulative Model Updates: 116,662
Cumulative Timesteps: 972,904,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 972904432...
Checkpoint 972904432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 534.38610
Policy Entropy: 3.16172
Value Function Loss: 0.00553

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.08466
Policy Update Magnitude: 0.56327
Value Function Update Magnitude: 0.57677

Collected Steps per Second: 21,830.13154
Overall Steps per Second: 10,622.26259

Timestep Collection Time: 2.29087
Timestep Consumption Time: 2.41717
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.70804

Cumulative Model Updates: 116,668
Cumulative Timesteps: 972,954,442

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,350.92009
Policy Entropy: 3.14924
Value Function Loss: 0.00530

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10112
Policy Update Magnitude: 0.55680
Value Function Update Magnitude: 0.57279

Collected Steps per Second: 22,300.35857
Overall Steps per Second: 10,832.75869

Timestep Collection Time: 2.24337
Timestep Consumption Time: 2.37484
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.61821

Cumulative Model Updates: 116,674
Cumulative Timesteps: 973,004,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 973004470...
Checkpoint 973004470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516.83785
Policy Entropy: 3.10920
Value Function Loss: 0.00552

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11520
Policy Update Magnitude: 0.56249
Value Function Update Magnitude: 0.58966

Collected Steps per Second: 22,121.70023
Overall Steps per Second: 10,685.03672

Timestep Collection Time: 2.26022
Timestep Consumption Time: 2.41922
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.67944

Cumulative Model Updates: 116,680
Cumulative Timesteps: 973,054,470

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 729.19883
Policy Entropy: 3.08366
Value Function Loss: 0.00554

Mean KL Divergence: 0.01283
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.57695
Value Function Update Magnitude: 0.60196

Collected Steps per Second: 22,674.30469
Overall Steps per Second: 10,626.99956

Timestep Collection Time: 2.20540
Timestep Consumption Time: 2.50016
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.70556

Cumulative Model Updates: 116,686
Cumulative Timesteps: 973,104,476

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 973104476...
Checkpoint 973104476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 481.91805
Policy Entropy: 3.06759
Value Function Loss: 0.00588

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12056
Policy Update Magnitude: 0.58632
Value Function Update Magnitude: 0.60448

Collected Steps per Second: 22,842.52656
Overall Steps per Second: 10,676.29516

Timestep Collection Time: 2.18934
Timestep Consumption Time: 2.49487
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.68421

Cumulative Model Updates: 116,692
Cumulative Timesteps: 973,154,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.39217
Policy Entropy: 3.07461
Value Function Loss: 0.00581

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.58956
Value Function Update Magnitude: 0.60445

Collected Steps per Second: 23,399.88097
Overall Steps per Second: 10,718.79377

Timestep Collection Time: 2.13736
Timestep Consumption Time: 2.52865
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 4.66601

Cumulative Model Updates: 116,698
Cumulative Timesteps: 973,204,500

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 973204500...
Checkpoint 973204500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 699.52498
Policy Entropy: 3.07348
Value Function Loss: 0.00593

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.58779
Value Function Update Magnitude: 0.61302

Collected Steps per Second: 22,867.49541
Overall Steps per Second: 10,643.76610

Timestep Collection Time: 2.18712
Timestep Consumption Time: 2.51178
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.69890

Cumulative Model Updates: 116,704
Cumulative Timesteps: 973,254,514

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 906.71315
Policy Entropy: 3.06008
Value Function Loss: 0.00572

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11187
Policy Update Magnitude: 0.58865
Value Function Update Magnitude: 0.62330

Collected Steps per Second: 23,020.71243
Overall Steps per Second: 10,808.93172

Timestep Collection Time: 2.17239
Timestep Consumption Time: 2.45434
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.62673

Cumulative Model Updates: 116,710
Cumulative Timesteps: 973,304,524

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 973304524...
Checkpoint 973304524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 386.43702
Policy Entropy: 3.06375
Value Function Loss: 0.00564

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10449
Policy Update Magnitude: 0.58461
Value Function Update Magnitude: 0.62544

Collected Steps per Second: 22,773.29294
Overall Steps per Second: 10,721.24111

Timestep Collection Time: 2.19696
Timestep Consumption Time: 2.46966
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.66662

Cumulative Model Updates: 116,716
Cumulative Timesteps: 973,354,556

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.92568
Policy Entropy: 3.06345
Value Function Loss: 0.00548

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10810
Policy Update Magnitude: 0.57949
Value Function Update Magnitude: 0.62158

Collected Steps per Second: 22,955.34830
Overall Steps per Second: 10,662.14436

Timestep Collection Time: 2.17936
Timestep Consumption Time: 2.51275
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.69211

Cumulative Model Updates: 116,722
Cumulative Timesteps: 973,404,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 973404584...
Checkpoint 973404584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.15228
Policy Entropy: 3.07486
Value Function Loss: 0.00561

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11056
Policy Update Magnitude: 0.58024
Value Function Update Magnitude: 0.62193

Collected Steps per Second: 22,932.16552
Overall Steps per Second: 10,802.63850

Timestep Collection Time: 2.18043
Timestep Consumption Time: 2.44825
PPO Batch Consumption Time: 0.28214
Total Iteration Time: 4.62868

Cumulative Model Updates: 116,728
Cumulative Timesteps: 973,454,586

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 434.04001
Policy Entropy: 3.07558
Value Function Loss: 0.00540

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.58003
Value Function Update Magnitude: 0.61750

Collected Steps per Second: 22,749.41205
Overall Steps per Second: 10,608.28488

Timestep Collection Time: 2.19909
Timestep Consumption Time: 2.51685
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.71594

Cumulative Model Updates: 116,734
Cumulative Timesteps: 973,504,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 973504614...
Checkpoint 973504614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 871.88671
Policy Entropy: 3.06204
Value Function Loss: 0.00563

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11184
Policy Update Magnitude: 0.58246
Value Function Update Magnitude: 0.61393

Collected Steps per Second: 22,569.15950
Overall Steps per Second: 10,589.50966

Timestep Collection Time: 2.21656
Timestep Consumption Time: 2.50754
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.72411

Cumulative Model Updates: 116,740
Cumulative Timesteps: 973,554,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.68631
Policy Entropy: 3.06823
Value Function Loss: 0.00540

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11660
Policy Update Magnitude: 0.58368
Value Function Update Magnitude: 0.62413

Collected Steps per Second: 22,765.23160
Overall Steps per Second: 10,648.08494

Timestep Collection Time: 2.19747
Timestep Consumption Time: 2.50065
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.69812

Cumulative Model Updates: 116,746
Cumulative Timesteps: 973,604,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 973604666...
Checkpoint 973604666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,655.24877
Policy Entropy: 3.05883
Value Function Loss: 0.00525

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.57650
Value Function Update Magnitude: 0.62383

Collected Steps per Second: 22,512.67924
Overall Steps per Second: 10,583.51294

Timestep Collection Time: 2.22221
Timestep Consumption Time: 2.50476
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.72697

Cumulative Model Updates: 116,752
Cumulative Timesteps: 973,654,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.43011
Policy Entropy: 3.06203
Value Function Loss: 0.00543

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.11854
Policy Update Magnitude: 0.57768
Value Function Update Magnitude: 0.61927

Collected Steps per Second: 23,285.27856
Overall Steps per Second: 10,789.77065

Timestep Collection Time: 2.14771
Timestep Consumption Time: 2.48724
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.63495

Cumulative Model Updates: 116,758
Cumulative Timesteps: 973,704,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 973704704...
Checkpoint 973704704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 884.05928
Policy Entropy: 3.07538
Value Function Loss: 0.00576

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.58856
Value Function Update Magnitude: 0.62486

Collected Steps per Second: 22,600.32792
Overall Steps per Second: 10,656.17277

Timestep Collection Time: 2.21360
Timestep Consumption Time: 2.48115
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.69474

Cumulative Model Updates: 116,764
Cumulative Timesteps: 973,754,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506.43807
Policy Entropy: 3.08253
Value Function Loss: 0.00607

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.59409
Value Function Update Magnitude: 0.63517

Collected Steps per Second: 23,076.93195
Overall Steps per Second: 10,813.93539

Timestep Collection Time: 2.16675
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.62385

Cumulative Model Updates: 116,770
Cumulative Timesteps: 973,804,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 973804734...
Checkpoint 973804734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 739.43850
Policy Entropy: 3.09773
Value Function Loss: 0.00585

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.10588
Policy Update Magnitude: 0.58722
Value Function Update Magnitude: 0.63639

Collected Steps per Second: 22,591.95390
Overall Steps per Second: 10,738.25526

Timestep Collection Time: 2.21442
Timestep Consumption Time: 2.44444
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.65886

Cumulative Model Updates: 116,776
Cumulative Timesteps: 973,854,762

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 657.24573
Policy Entropy: 3.09230
Value Function Loss: 0.00544

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.57554
Value Function Update Magnitude: 0.62713

Collected Steps per Second: 23,164.19109
Overall Steps per Second: 10,898.92446

Timestep Collection Time: 2.15971
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.59018

Cumulative Model Updates: 116,782
Cumulative Timesteps: 973,904,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 973904790...
Checkpoint 973904790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 942.23690
Policy Entropy: 3.09483
Value Function Loss: 0.00559

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10574
Policy Update Magnitude: 0.57643
Value Function Update Magnitude: 0.62078

Collected Steps per Second: 22,328.97904
Overall Steps per Second: 10,629.61838

Timestep Collection Time: 2.23969
Timestep Consumption Time: 2.46509
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.70478

Cumulative Model Updates: 116,788
Cumulative Timesteps: 973,954,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 396.05580
Policy Entropy: 3.09223
Value Function Loss: 0.00609

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.09761
Policy Update Magnitude: 0.58414
Value Function Update Magnitude: 0.60793

Collected Steps per Second: 23,095.17352
Overall Steps per Second: 10,874.75945

Timestep Collection Time: 2.16530
Timestep Consumption Time: 2.43324
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.59854

Cumulative Model Updates: 116,794
Cumulative Timesteps: 974,004,808

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 974004808...
Checkpoint 974004808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.13454
Policy Entropy: 3.09039
Value Function Loss: 0.00599

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09519
Policy Update Magnitude: 0.59016
Value Function Update Magnitude: 0.62506

Collected Steps per Second: 22,411.22519
Overall Steps per Second: 10,655.55098

Timestep Collection Time: 2.23138
Timestep Consumption Time: 2.46176
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.69314

Cumulative Model Updates: 116,800
Cumulative Timesteps: 974,054,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 784.84457
Policy Entropy: 3.06843
Value Function Loss: 0.00568

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10020
Policy Update Magnitude: 0.58714
Value Function Update Magnitude: 0.63630

Collected Steps per Second: 22,700.35365
Overall Steps per Second: 10,735.20970

Timestep Collection Time: 2.20349
Timestep Consumption Time: 2.45594
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.65943

Cumulative Model Updates: 116,806
Cumulative Timesteps: 974,104,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 974104836...
Checkpoint 974104836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 966.83508
Policy Entropy: 3.06754
Value Function Loss: 0.00523

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.10546
Policy Update Magnitude: 0.57943
Value Function Update Magnitude: 0.63854

Collected Steps per Second: 22,347.63765
Overall Steps per Second: 10,637.97230

Timestep Collection Time: 2.23827
Timestep Consumption Time: 2.46376
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.70202

Cumulative Model Updates: 116,812
Cumulative Timesteps: 974,154,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 830.64770
Policy Entropy: 3.08138
Value Function Loss: 0.00533

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09590
Policy Update Magnitude: 0.57786
Value Function Update Magnitude: 0.62700

Collected Steps per Second: 23,152.49515
Overall Steps per Second: 10,787.47116

Timestep Collection Time: 2.15985
Timestep Consumption Time: 2.47571
PPO Batch Consumption Time: 0.29423
Total Iteration Time: 4.63556

Cumulative Model Updates: 116,818
Cumulative Timesteps: 974,204,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 974204862...
Checkpoint 974204862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,014.28157
Policy Entropy: 3.08082
Value Function Loss: 0.00550

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09600
Policy Update Magnitude: 0.57706
Value Function Update Magnitude: 0.62219

Collected Steps per Second: 22,960.32736
Overall Steps per Second: 10,824.56608

Timestep Collection Time: 2.17767
Timestep Consumption Time: 2.44145
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.61912

Cumulative Model Updates: 116,824
Cumulative Timesteps: 974,254,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.49839
Policy Entropy: 3.06881
Value Function Loss: 0.00553

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10999
Policy Update Magnitude: 0.58221
Value Function Update Magnitude: 0.63006

Collected Steps per Second: 22,989.53163
Overall Steps per Second: 10,746.63274

Timestep Collection Time: 2.17586
Timestep Consumption Time: 2.47881
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.65467

Cumulative Model Updates: 116,830
Cumulative Timesteps: 974,304,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 974304884...
Checkpoint 974304884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.95447
Policy Entropy: 3.04358
Value Function Loss: 0.00532

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.58389
Value Function Update Magnitude: 0.63372

Collected Steps per Second: 22,678.87500
Overall Steps per Second: 10,824.32578

Timestep Collection Time: 2.20540
Timestep Consumption Time: 2.41530
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.62070

Cumulative Model Updates: 116,836
Cumulative Timesteps: 974,354,900

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.56430
Policy Entropy: 3.05206
Value Function Loss: 0.00539

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.11333
Policy Update Magnitude: 0.57427
Value Function Update Magnitude: 0.62094

Collected Steps per Second: 22,840.89488
Overall Steps per Second: 10,680.90411

Timestep Collection Time: 2.18949
Timestep Consumption Time: 2.49269
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.68219

Cumulative Model Updates: 116,842
Cumulative Timesteps: 974,404,910

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 974404910...
Checkpoint 974404910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,323.40939
Policy Entropy: 3.04776
Value Function Loss: 0.00526

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.56986
Value Function Update Magnitude: 0.61875

Collected Steps per Second: 22,735.59723
Overall Steps per Second: 10,734.65162

Timestep Collection Time: 2.20051
Timestep Consumption Time: 2.46009
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.66061

Cumulative Model Updates: 116,848
Cumulative Timesteps: 974,454,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,792.28582
Policy Entropy: 3.04903
Value Function Loss: 0.00537

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10525
Policy Update Magnitude: 0.58000
Value Function Update Magnitude: 0.62722

Collected Steps per Second: 23,083.95914
Overall Steps per Second: 10,674.62307

Timestep Collection Time: 2.16609
Timestep Consumption Time: 2.51810
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 4.68419

Cumulative Model Updates: 116,854
Cumulative Timesteps: 974,504,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 974504942...
Checkpoint 974504942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 948.63557
Policy Entropy: 3.03616
Value Function Loss: 0.00508

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10328
Policy Update Magnitude: 0.57518
Value Function Update Magnitude: 0.61442

Collected Steps per Second: 22,688.30197
Overall Steps per Second: 10,626.78658

Timestep Collection Time: 2.20387
Timestep Consumption Time: 2.50141
PPO Batch Consumption Time: 0.29624
Total Iteration Time: 4.70528

Cumulative Model Updates: 116,860
Cumulative Timesteps: 974,554,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.61403
Policy Entropy: 3.04824
Value Function Loss: 0.00519

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.10254
Policy Update Magnitude: 0.57259
Value Function Update Magnitude: 0.59532

Collected Steps per Second: 22,559.66115
Overall Steps per Second: 10,649.54788

Timestep Collection Time: 2.21643
Timestep Consumption Time: 2.47879
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.69522

Cumulative Model Updates: 116,866
Cumulative Timesteps: 974,604,946

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 974604946...
Checkpoint 974604946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,013.97309
Policy Entropy: 3.08091
Value Function Loss: 0.00484

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.56258
Value Function Update Magnitude: 0.58503

Collected Steps per Second: 22,927.90955
Overall Steps per Second: 10,852.55446

Timestep Collection Time: 2.18101
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.60776

Cumulative Model Updates: 116,872
Cumulative Timesteps: 974,654,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605.30787
Policy Entropy: 3.09054
Value Function Loss: 0.00517

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.10756
Policy Update Magnitude: 0.55462
Value Function Update Magnitude: 0.57301

Collected Steps per Second: 22,521.39041
Overall Steps per Second: 10,620.23200

Timestep Collection Time: 2.22020
Timestep Consumption Time: 2.48798
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.70818

Cumulative Model Updates: 116,878
Cumulative Timesteps: 974,704,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 974704954...
Checkpoint 974704954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,491.71645
Policy Entropy: 3.08428
Value Function Loss: 0.00528

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.56213
Value Function Update Magnitude: 0.58446

Collected Steps per Second: 22,654.51618
Overall Steps per Second: 10,664.52378

Timestep Collection Time: 2.20733
Timestep Consumption Time: 2.48167
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.68900

Cumulative Model Updates: 116,884
Cumulative Timesteps: 974,754,960

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,318.87464
Policy Entropy: 3.08021
Value Function Loss: 0.00527

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.56901
Value Function Update Magnitude: 0.61091

Collected Steps per Second: 23,177.82286
Overall Steps per Second: 10,783.01558

Timestep Collection Time: 2.15836
Timestep Consumption Time: 2.48098
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.63933

Cumulative Model Updates: 116,890
Cumulative Timesteps: 974,804,986

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 974804986...
Checkpoint 974804986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.91792
Policy Entropy: 3.07884
Value Function Loss: 0.00493

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.12202
Policy Update Magnitude: 0.56154
Value Function Update Magnitude: 0.61181

Collected Steps per Second: 22,701.18401
Overall Steps per Second: 10,587.39062

Timestep Collection Time: 2.20332
Timestep Consumption Time: 2.52098
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 4.72430

Cumulative Model Updates: 116,896
Cumulative Timesteps: 974,855,004

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,265.76725
Policy Entropy: 3.09633
Value Function Loss: 0.00485

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.13239
Policy Update Magnitude: 0.55124
Value Function Update Magnitude: 0.61300

Collected Steps per Second: 23,064.88736
Overall Steps per Second: 10,848.34355

Timestep Collection Time: 2.16797
Timestep Consumption Time: 2.44140
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.60937

Cumulative Model Updates: 116,902
Cumulative Timesteps: 974,905,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 974905008...
Checkpoint 974905008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,567.13830
Policy Entropy: 3.07296
Value Function Loss: 0.00520

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.55868
Value Function Update Magnitude: 0.61320

Collected Steps per Second: 22,517.34091
Overall Steps per Second: 10,653.44223

Timestep Collection Time: 2.22069
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.69369

Cumulative Model Updates: 116,908
Cumulative Timesteps: 974,955,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.55971
Policy Entropy: 3.08304
Value Function Loss: 0.00553

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.63191

Collected Steps per Second: 22,989.40834
Overall Steps per Second: 10,727.32711

Timestep Collection Time: 2.17509
Timestep Consumption Time: 2.48628
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.66137

Cumulative Model Updates: 116,914
Cumulative Timesteps: 975,005,016

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 975005016...
Checkpoint 975005016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.33400
Policy Entropy: 3.06778
Value Function Loss: 0.00546

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10767
Policy Update Magnitude: 0.58812
Value Function Update Magnitude: 0.64812

Collected Steps per Second: 22,672.55727
Overall Steps per Second: 10,825.26415

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.41400
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.61975

Cumulative Model Updates: 116,920
Cumulative Timesteps: 975,055,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965.29869
Policy Entropy: 3.07178
Value Function Loss: 0.00534

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.09864
Policy Update Magnitude: 0.59012
Value Function Update Magnitude: 0.65109

Collected Steps per Second: 22,997.89420
Overall Steps per Second: 10,734.79486

Timestep Collection Time: 2.17533
Timestep Consumption Time: 2.48503
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.66036

Cumulative Model Updates: 116,926
Cumulative Timesteps: 975,105,054

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 975105054...
Checkpoint 975105054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659.32869
Policy Entropy: 3.05663
Value Function Loss: 0.00519

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10420
Policy Update Magnitude: 0.58276
Value Function Update Magnitude: 0.64933

Collected Steps per Second: 22,786.51868
Overall Steps per Second: 10,899.30627

Timestep Collection Time: 2.19551
Timestep Consumption Time: 2.39451
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.59002

Cumulative Model Updates: 116,932
Cumulative Timesteps: 975,155,082

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611.86417
Policy Entropy: 3.06538
Value Function Loss: 0.00525

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10255
Policy Update Magnitude: 0.58259
Value Function Update Magnitude: 0.64616

Collected Steps per Second: 22,293.27109
Overall Steps per Second: 10,531.31612

Timestep Collection Time: 2.24400
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.75021

Cumulative Model Updates: 116,938
Cumulative Timesteps: 975,205,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 975205108...
Checkpoint 975205108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757.27557
Policy Entropy: 3.05877
Value Function Loss: 0.00564

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.10087
Policy Update Magnitude: 0.58948
Value Function Update Magnitude: 0.62977

Collected Steps per Second: 22,861.03421
Overall Steps per Second: 10,946.62313

Timestep Collection Time: 2.18800
Timestep Consumption Time: 2.38144
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.56945

Cumulative Model Updates: 116,944
Cumulative Timesteps: 975,255,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,388.91165
Policy Entropy: 3.04972
Value Function Loss: 0.00581

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10564
Policy Update Magnitude: 0.60363
Value Function Update Magnitude: 0.63828

Collected Steps per Second: 22,290.86748
Overall Steps per Second: 10,711.84676

Timestep Collection Time: 2.24397
Timestep Consumption Time: 2.42563
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.66960

Cumulative Model Updates: 116,950
Cumulative Timesteps: 975,305,148

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 975305148...
Checkpoint 975305148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 734.61404
Policy Entropy: 3.05588
Value Function Loss: 0.00600

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.61011
Value Function Update Magnitude: 0.65076

Collected Steps per Second: 21,925.71670
Overall Steps per Second: 10,631.96738

Timestep Collection Time: 2.28061
Timestep Consumption Time: 2.42257
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.70317

Cumulative Model Updates: 116,956
Cumulative Timesteps: 975,355,152

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 516.56767
Policy Entropy: 3.06119
Value Function Loss: 0.00550

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.59337
Value Function Update Magnitude: 0.65633

Collected Steps per Second: 22,329.22592
Overall Steps per Second: 10,762.05466

Timestep Collection Time: 2.23949
Timestep Consumption Time: 2.40702
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.64651

Cumulative Model Updates: 116,962
Cumulative Timesteps: 975,405,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 975405158...
Checkpoint 975405158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.07667
Policy Entropy: 3.07202
Value Function Loss: 0.00554

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.57925
Value Function Update Magnitude: 0.62331

Collected Steps per Second: 22,174.04497
Overall Steps per Second: 10,645.10892

Timestep Collection Time: 2.25579
Timestep Consumption Time: 2.44308
PPO Batch Consumption Time: 0.29543
Total Iteration Time: 4.69887

Cumulative Model Updates: 116,968
Cumulative Timesteps: 975,455,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.21733
Policy Entropy: 3.06737
Value Function Loss: 0.00512

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.11366
Policy Update Magnitude: 0.56935
Value Function Update Magnitude: 0.60692

Collected Steps per Second: 22,611.50447
Overall Steps per Second: 10,901.16358

Timestep Collection Time: 2.21241
Timestep Consumption Time: 2.37664
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.58905

Cumulative Model Updates: 116,974
Cumulative Timesteps: 975,505,204

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 975505204...
Checkpoint 975505204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 841.44172
Policy Entropy: 3.05847
Value Function Loss: 0.00507

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.57272
Value Function Update Magnitude: 0.58807

Collected Steps per Second: 22,033.22766
Overall Steps per Second: 10,621.12108

Timestep Collection Time: 2.26975
Timestep Consumption Time: 2.43879
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.70854

Cumulative Model Updates: 116,980
Cumulative Timesteps: 975,555,214

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.33346
Policy Entropy: 3.04581
Value Function Loss: 0.00516

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.57773
Value Function Update Magnitude: 0.56994

Collected Steps per Second: 22,623.83764
Overall Steps per Second: 10,920.61153

Timestep Collection Time: 2.21032
Timestep Consumption Time: 2.36872
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.57905

Cumulative Model Updates: 116,986
Cumulative Timesteps: 975,605,220

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 975605220...
Checkpoint 975605220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 892.36299
Policy Entropy: 3.04113
Value Function Loss: 0.00543

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10270
Policy Update Magnitude: 0.58152
Value Function Update Magnitude: 0.57214

Collected Steps per Second: 22,883.34022
Overall Steps per Second: 10,646.98182

Timestep Collection Time: 2.18526
Timestep Consumption Time: 2.51147
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.69673

Cumulative Model Updates: 116,992
Cumulative Timesteps: 975,655,226

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.22582
Policy Entropy: 3.06326
Value Function Loss: 0.00573

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10531
Policy Update Magnitude: 0.57765
Value Function Update Magnitude: 0.58794

Collected Steps per Second: 23,040.86524
Overall Steps per Second: 10,816.20234

Timestep Collection Time: 2.17023
Timestep Consumption Time: 2.45283
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.62306

Cumulative Model Updates: 116,998
Cumulative Timesteps: 975,705,230

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 975705230...
Checkpoint 975705230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 915.97531
Policy Entropy: 3.06251
Value Function Loss: 0.00580

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.57866
Value Function Update Magnitude: 0.60236

Collected Steps per Second: 22,564.60869
Overall Steps per Second: 10,695.14646

Timestep Collection Time: 2.21692
Timestep Consumption Time: 2.46034
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.67726

Cumulative Model Updates: 117,004
Cumulative Timesteps: 975,755,254

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.32932
Policy Entropy: 3.07995
Value Function Loss: 0.00586

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.10934
Policy Update Magnitude: 0.58499
Value Function Update Magnitude: 0.59009

Collected Steps per Second: 22,948.85225
Overall Steps per Second: 10,717.65163

Timestep Collection Time: 2.17893
Timestep Consumption Time: 2.48664
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.66557

Cumulative Model Updates: 117,010
Cumulative Timesteps: 975,805,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 975805258...
Checkpoint 975805258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 605.03613
Policy Entropy: 3.09018
Value Function Loss: 0.00608

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.59118
Value Function Update Magnitude: 0.60062

Collected Steps per Second: 23,318.98418
Overall Steps per Second: 10,850.29021

Timestep Collection Time: 2.14426
Timestep Consumption Time: 2.46409
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.60836

Cumulative Model Updates: 117,016
Cumulative Timesteps: 975,855,260

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 512.26080
Policy Entropy: 3.09417
Value Function Loss: 0.00607

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.58034
Value Function Update Magnitude: 0.61295

Collected Steps per Second: 22,882.47870
Overall Steps per Second: 10,786.59908

Timestep Collection Time: 2.18604
Timestep Consumption Time: 2.45138
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.63742

Cumulative Model Updates: 117,022
Cumulative Timesteps: 975,905,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 975905282...
Checkpoint 975905282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,064.45809
Policy Entropy: 3.08689
Value Function Loss: 0.00589

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.11219
Policy Update Magnitude: 0.58090
Value Function Update Magnitude: 0.62055

Collected Steps per Second: 22,682.90851
Overall Steps per Second: 10,708.17061

Timestep Collection Time: 2.20448
Timestep Consumption Time: 2.46523
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.66971

Cumulative Model Updates: 117,028
Cumulative Timesteps: 975,955,286

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 397.42807
Policy Entropy: 3.06128
Value Function Loss: 0.00567

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.58763
Value Function Update Magnitude: 0.63959

Collected Steps per Second: 22,819.23405
Overall Steps per Second: 10,666.92422

Timestep Collection Time: 2.19148
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.68814

Cumulative Model Updates: 117,034
Cumulative Timesteps: 976,005,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 976005294...
Checkpoint 976005294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 521.64818
Policy Entropy: 3.06331
Value Function Loss: 0.00544

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10615
Policy Update Magnitude: 0.58835
Value Function Update Magnitude: 0.62971

Collected Steps per Second: 22,828.21399
Overall Steps per Second: 10,688.28038

Timestep Collection Time: 2.19115
Timestep Consumption Time: 2.48874
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.67989

Cumulative Model Updates: 117,040
Cumulative Timesteps: 976,055,314

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.36603
Policy Entropy: 3.05882
Value Function Loss: 0.00569

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.58890
Value Function Update Magnitude: 0.61481

Collected Steps per Second: 23,347.13521
Overall Steps per Second: 10,649.08024

Timestep Collection Time: 2.14270
Timestep Consumption Time: 2.55498
PPO Batch Consumption Time: 0.29676
Total Iteration Time: 4.69768

Cumulative Model Updates: 117,046
Cumulative Timesteps: 976,105,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 976105340...
Checkpoint 976105340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.57664
Policy Entropy: 3.05974
Value Function Loss: 0.00577

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09943
Policy Update Magnitude: 0.58544
Value Function Update Magnitude: 0.61355

Collected Steps per Second: 22,408.26931
Overall Steps per Second: 10,666.94535

Timestep Collection Time: 2.23194
Timestep Consumption Time: 2.45675
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.68869

Cumulative Model Updates: 117,052
Cumulative Timesteps: 976,155,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.59048
Policy Entropy: 3.05670
Value Function Loss: 0.00581

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.08992
Policy Update Magnitude: 0.58419
Value Function Update Magnitude: 0.61520

Collected Steps per Second: 23,180.55510
Overall Steps per Second: 10,860.24489

Timestep Collection Time: 2.15810
Timestep Consumption Time: 2.44824
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.60634

Cumulative Model Updates: 117,058
Cumulative Timesteps: 976,205,380

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 976205380...
Checkpoint 976205380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.75709
Policy Entropy: 3.06645
Value Function Loss: 0.00544

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.58362
Value Function Update Magnitude: 0.61658

Collected Steps per Second: 22,763.68193
Overall Steps per Second: 10,738.30091

Timestep Collection Time: 2.19718
Timestep Consumption Time: 2.46054
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.65772

Cumulative Model Updates: 117,064
Cumulative Timesteps: 976,255,396

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,237.38225
Policy Entropy: 3.06747
Value Function Loss: 0.00529

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09359
Policy Update Magnitude: 0.57452
Value Function Update Magnitude: 0.60740

Collected Steps per Second: 23,113.59889
Overall Steps per Second: 10,892.98762

Timestep Collection Time: 2.16418
Timestep Consumption Time: 2.42795
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.59213

Cumulative Model Updates: 117,070
Cumulative Timesteps: 976,305,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 976305418...
Checkpoint 976305418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539.41957
Policy Entropy: 3.07260
Value Function Loss: 0.00534

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.59930

Collected Steps per Second: 22,558.39725
Overall Steps per Second: 10,606.01501

Timestep Collection Time: 2.21674
Timestep Consumption Time: 2.49814
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.71487

Cumulative Model Updates: 117,076
Cumulative Timesteps: 976,355,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.37955
Policy Entropy: 3.04300
Value Function Loss: 0.00542

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.57748
Value Function Update Magnitude: 0.60999

Collected Steps per Second: 23,003.59853
Overall Steps per Second: 10,847.51204

Timestep Collection Time: 2.17383
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.60991

Cumulative Model Updates: 117,082
Cumulative Timesteps: 976,405,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 976405430...
Checkpoint 976405430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,380.72398
Policy Entropy: 3.05609
Value Function Loss: 0.00554

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.58787
Value Function Update Magnitude: 0.62458

Collected Steps per Second: 22,943.05220
Overall Steps per Second: 10,695.29054

Timestep Collection Time: 2.17992
Timestep Consumption Time: 2.49634
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.67626

Cumulative Model Updates: 117,088
Cumulative Timesteps: 976,455,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.25981
Policy Entropy: 3.04891
Value Function Loss: 0.00530

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.59038
Value Function Update Magnitude: 0.64901

Collected Steps per Second: 23,062.91614
Overall Steps per Second: 10,884.01804

Timestep Collection Time: 2.16816
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.59426

Cumulative Model Updates: 117,094
Cumulative Timesteps: 976,505,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 976505448...
Checkpoint 976505448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 976.64753
Policy Entropy: 3.06102
Value Function Loss: 0.00559

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.10544
Policy Update Magnitude: 0.58766
Value Function Update Magnitude: 0.64729

Collected Steps per Second: 22,483.05443
Overall Steps per Second: 10,665.65616

Timestep Collection Time: 2.22434
Timestep Consumption Time: 2.46454
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.68888

Cumulative Model Updates: 117,100
Cumulative Timesteps: 976,555,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.94241
Policy Entropy: 3.04829
Value Function Loss: 0.00559

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.59155
Value Function Update Magnitude: 0.63593

Collected Steps per Second: 23,004.35495
Overall Steps per Second: 10,849.43339

Timestep Collection Time: 2.17350
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.60854

Cumulative Model Updates: 117,106
Cumulative Timesteps: 976,605,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 976605458...
Checkpoint 976605458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 867.80848
Policy Entropy: 3.05437
Value Function Loss: 0.00564

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.59111
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 22,679.38890
Overall Steps per Second: 10,705.53721

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.46820
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.67496

Cumulative Model Updates: 117,112
Cumulative Timesteps: 976,655,506

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.28108
Policy Entropy: 3.07108
Value Function Loss: 0.00529

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.58073
Value Function Update Magnitude: 0.63324

Collected Steps per Second: 22,947.54326
Overall Steps per Second: 10,923.18537

Timestep Collection Time: 2.18002
Timestep Consumption Time: 2.39978
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.57980

Cumulative Model Updates: 117,118
Cumulative Timesteps: 976,705,532

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 976705532...
Checkpoint 976705532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 552.59107
Policy Entropy: 3.06872
Value Function Loss: 0.00520

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.57106
Value Function Update Magnitude: 0.60040

Collected Steps per Second: 21,735.14818
Overall Steps per Second: 10,554.40629

Timestep Collection Time: 2.30042
Timestep Consumption Time: 2.43694
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.73736

Cumulative Model Updates: 117,124
Cumulative Timesteps: 976,755,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 861.78407
Policy Entropy: 3.06066
Value Function Loss: 0.00528

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11262
Policy Update Magnitude: 0.57270
Value Function Update Magnitude: 0.59762

Collected Steps per Second: 22,880.53355
Overall Steps per Second: 10,945.00850

Timestep Collection Time: 2.18588
Timestep Consumption Time: 2.38370
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.56957

Cumulative Model Updates: 117,130
Cumulative Timesteps: 976,805,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 976805546...
Checkpoint 976805546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 562.84216
Policy Entropy: 3.05899
Value Function Loss: 0.00549

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10437
Policy Update Magnitude: 0.57774
Value Function Update Magnitude: 0.60366

Collected Steps per Second: 21,953.55571
Overall Steps per Second: 10,727.59486

Timestep Collection Time: 2.27836
Timestep Consumption Time: 2.38420
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.66255

Cumulative Model Updates: 117,136
Cumulative Timesteps: 976,855,564

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.81469
Policy Entropy: 3.07188
Value Function Loss: 0.00525

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09881
Policy Update Magnitude: 0.57216
Value Function Update Magnitude: 0.58483

Collected Steps per Second: 22,494.00834
Overall Steps per Second: 10,840.18193

Timestep Collection Time: 2.22388
Timestep Consumption Time: 2.39080
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.61468

Cumulative Model Updates: 117,142
Cumulative Timesteps: 976,905,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 976905588...
Checkpoint 976905588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 763.12649
Policy Entropy: 3.06543
Value Function Loss: 0.00534

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09574
Policy Update Magnitude: 0.56945
Value Function Update Magnitude: 0.56350

Collected Steps per Second: 21,871.83199
Overall Steps per Second: 10,692.88834

Timestep Collection Time: 2.28614
Timestep Consumption Time: 2.39006
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.67619

Cumulative Model Updates: 117,148
Cumulative Timesteps: 976,955,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963.18726
Policy Entropy: 3.04925
Value Function Loss: 0.00529

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.10663
Policy Update Magnitude: 0.57041
Value Function Update Magnitude: 0.55765

Collected Steps per Second: 22,246.74708
Overall Steps per Second: 10,779.79947

Timestep Collection Time: 2.24806
Timestep Consumption Time: 2.39136
PPO Batch Consumption Time: 0.28267
Total Iteration Time: 4.63942

Cumulative Model Updates: 117,154
Cumulative Timesteps: 977,005,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 977005602...
Checkpoint 977005602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 943.38787
Policy Entropy: 3.04978
Value Function Loss: 0.00521

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.10573
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.55154

Collected Steps per Second: 21,911.16505
Overall Steps per Second: 10,737.89070

Timestep Collection Time: 2.28212
Timestep Consumption Time: 2.37466
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.65678

Cumulative Model Updates: 117,160
Cumulative Timesteps: 977,055,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 628.05127
Policy Entropy: 3.05268
Value Function Loss: 0.00524

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.55028
Value Function Update Magnitude: 0.53145

Collected Steps per Second: 22,160.38800
Overall Steps per Second: 10,667.81576

Timestep Collection Time: 2.25754
Timestep Consumption Time: 2.43208
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68962

Cumulative Model Updates: 117,166
Cumulative Timesteps: 977,105,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 977105634...
Checkpoint 977105634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,036.01853
Policy Entropy: 3.07302
Value Function Loss: 0.00546

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.08937
Policy Update Magnitude: 0.55489
Value Function Update Magnitude: 0.53612

Collected Steps per Second: 22,138.36220
Overall Steps per Second: 10,779.74703

Timestep Collection Time: 2.25943
Timestep Consumption Time: 2.38076
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.64018

Cumulative Model Updates: 117,172
Cumulative Timesteps: 977,155,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561.74529
Policy Entropy: 3.07298
Value Function Loss: 0.00555

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09296
Policy Update Magnitude: 0.55723
Value Function Update Magnitude: 0.56974

Collected Steps per Second: 22,961.55047
Overall Steps per Second: 10,658.43528

Timestep Collection Time: 2.17755
Timestep Consumption Time: 2.51357
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.69112

Cumulative Model Updates: 117,178
Cumulative Timesteps: 977,205,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 977205654...
Checkpoint 977205654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.93266
Policy Entropy: 3.07462
Value Function Loss: 0.00561

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09346
Policy Update Magnitude: 0.56279
Value Function Update Magnitude: 0.58052

Collected Steps per Second: 22,912.25129
Overall Steps per Second: 10,667.90066

Timestep Collection Time: 2.18337
Timestep Consumption Time: 2.50602
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.68940

Cumulative Model Updates: 117,184
Cumulative Timesteps: 977,255,680

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.18017
Policy Entropy: 3.08243
Value Function Loss: 0.00555

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09051
Policy Update Magnitude: 0.56874
Value Function Update Magnitude: 0.57395

Collected Steps per Second: 23,189.28344
Overall Steps per Second: 10,777.28166

Timestep Collection Time: 2.15729
Timestep Consumption Time: 2.48451
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.64180

Cumulative Model Updates: 117,190
Cumulative Timesteps: 977,305,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 977305706...
Checkpoint 977305706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881.96802
Policy Entropy: 3.07221
Value Function Loss: 0.00547

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09696
Policy Update Magnitude: 0.56972
Value Function Update Magnitude: 0.56654

Collected Steps per Second: 22,513.52232
Overall Steps per Second: 10,621.42989

Timestep Collection Time: 2.22142
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.70859

Cumulative Model Updates: 117,196
Cumulative Timesteps: 977,355,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.38014
Policy Entropy: 3.06929
Value Function Loss: 0.00514

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.09390
Policy Update Magnitude: 0.56290
Value Function Update Magnitude: 0.57587

Collected Steps per Second: 22,510.60222
Overall Steps per Second: 10,888.14405

Timestep Collection Time: 2.22215
Timestep Consumption Time: 2.37202
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.59417

Cumulative Model Updates: 117,202
Cumulative Timesteps: 977,405,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 977405740...
Checkpoint 977405740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.60707
Policy Entropy: 3.06101
Value Function Loss: 0.00509

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.56333
Value Function Update Magnitude: 0.59383

Collected Steps per Second: 22,876.75124
Overall Steps per Second: 10,700.78024

Timestep Collection Time: 2.18659
Timestep Consumption Time: 2.48803
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.67461

Cumulative Model Updates: 117,208
Cumulative Timesteps: 977,455,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426.33894
Policy Entropy: 3.07508
Value Function Loss: 0.00522

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10695
Policy Update Magnitude: 0.56109
Value Function Update Magnitude: 0.59422

Collected Steps per Second: 23,311.46959
Overall Steps per Second: 10,842.12607

Timestep Collection Time: 2.14521
Timestep Consumption Time: 2.46717
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.61238

Cumulative Model Updates: 117,214
Cumulative Timesteps: 977,505,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 977505770...
Checkpoint 977505770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.04969
Policy Entropy: 3.08108
Value Function Loss: 0.00546

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10825
Policy Update Magnitude: 0.56269
Value Function Update Magnitude: 0.58552

Collected Steps per Second: 22,853.64021
Overall Steps per Second: 10,719.10493

Timestep Collection Time: 2.18871
Timestep Consumption Time: 2.47772
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.66643

Cumulative Model Updates: 117,220
Cumulative Timesteps: 977,555,790

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 633.87771
Policy Entropy: 3.07726
Value Function Loss: 0.00575

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.57231
Value Function Update Magnitude: 0.59433

Collected Steps per Second: 22,650.75397
Overall Steps per Second: 10,617.22409

Timestep Collection Time: 2.20867
Timestep Consumption Time: 2.50330
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.71197

Cumulative Model Updates: 117,226
Cumulative Timesteps: 977,605,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 977605818...
Checkpoint 977605818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576.00689
Policy Entropy: 3.07516
Value Function Loss: 0.00559

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09664
Policy Update Magnitude: 0.57545
Value Function Update Magnitude: 0.59894

Collected Steps per Second: 23,149.72727
Overall Steps per Second: 10,871.35662

Timestep Collection Time: 2.16072
Timestep Consumption Time: 2.44037
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.60108

Cumulative Model Updates: 117,232
Cumulative Timesteps: 977,655,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622.01829
Policy Entropy: 3.06800
Value Function Loss: 0.00557

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.09018
Policy Update Magnitude: 0.57104
Value Function Update Magnitude: 0.59044

Collected Steps per Second: 22,752.23203
Overall Steps per Second: 10,605.78984

Timestep Collection Time: 2.19785
Timestep Consumption Time: 2.51712
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.71497

Cumulative Model Updates: 117,238
Cumulative Timesteps: 977,705,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 977705844...
Checkpoint 977705844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.07376
Policy Entropy: 3.08226
Value Function Loss: 0.00569

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.10104
Policy Update Magnitude: 0.57660
Value Function Update Magnitude: 0.58275

Collected Steps per Second: 22,740.06714
Overall Steps per Second: 10,589.19328

Timestep Collection Time: 2.19911
Timestep Consumption Time: 2.52344
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.72255

Cumulative Model Updates: 117,244
Cumulative Timesteps: 977,755,852

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.19488
Policy Entropy: 3.08107
Value Function Loss: 0.00569

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.11379
Policy Update Magnitude: 0.57246
Value Function Update Magnitude: 0.58225

Collected Steps per Second: 23,056.63557
Overall Steps per Second: 10,827.49576

Timestep Collection Time: 2.16875
Timestep Consumption Time: 2.44950
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.61824

Cumulative Model Updates: 117,250
Cumulative Timesteps: 977,805,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 977805856...
Checkpoint 977805856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,125.20379
Policy Entropy: 3.08257
Value Function Loss: 0.00580

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.56967
Value Function Update Magnitude: 0.57386

Collected Steps per Second: 22,684.55039
Overall Steps per Second: 10,689.14744

Timestep Collection Time: 2.20520
Timestep Consumption Time: 2.47469
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.67989

Cumulative Model Updates: 117,256
Cumulative Timesteps: 977,855,880

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.48522
Policy Entropy: 3.07523
Value Function Loss: 0.00565

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.57302
Value Function Update Magnitude: 0.58072

Collected Steps per Second: 22,834.82592
Overall Steps per Second: 10,635.82983

Timestep Collection Time: 2.19078
Timestep Consumption Time: 2.51276
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.70354

Cumulative Model Updates: 117,262
Cumulative Timesteps: 977,905,906

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 977905906...
Checkpoint 977905906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 745.91106
Policy Entropy: 3.06915
Value Function Loss: 0.00562

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10576
Policy Update Magnitude: 0.56931
Value Function Update Magnitude: 0.58458

Collected Steps per Second: 22,758.54020
Overall Steps per Second: 10,811.67079

Timestep Collection Time: 2.19768
Timestep Consumption Time: 2.42843
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.62611

Cumulative Model Updates: 117,268
Cumulative Timesteps: 977,955,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,043.30337
Policy Entropy: 3.06342
Value Function Loss: 0.00558

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.56018
Value Function Update Magnitude: 0.58895

Collected Steps per Second: 23,089.30444
Overall Steps per Second: 10,790.26598

Timestep Collection Time: 2.16672
Timestep Consumption Time: 2.46968
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.63640

Cumulative Model Updates: 117,274
Cumulative Timesteps: 978,005,950

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 978005950...
Checkpoint 978005950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.13329
Policy Entropy: 3.06614
Value Function Loss: 0.00550

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09510
Policy Update Magnitude: 0.56281
Value Function Update Magnitude: 0.60300

Collected Steps per Second: 23,056.47989
Overall Steps per Second: 10,928.35361

Timestep Collection Time: 2.16867
Timestep Consumption Time: 2.40676
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.57544

Cumulative Model Updates: 117,280
Cumulative Timesteps: 978,055,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,034.08188
Policy Entropy: 3.04834
Value Function Loss: 0.00532

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.56313
Value Function Update Magnitude: 0.60063

Collected Steps per Second: 23,149.76136
Overall Steps per Second: 10,825.79458

Timestep Collection Time: 2.16097
Timestep Consumption Time: 2.46003
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.62100

Cumulative Model Updates: 117,286
Cumulative Timesteps: 978,105,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 978105978...
Checkpoint 978105978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 887.33848
Policy Entropy: 3.06231
Value Function Loss: 0.00506

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10250
Policy Update Magnitude: 0.56131
Value Function Update Magnitude: 0.58280

Collected Steps per Second: 22,789.25791
Overall Steps per Second: 10,649.28103

Timestep Collection Time: 2.19481
Timestep Consumption Time: 2.50204
PPO Batch Consumption Time: 0.29688
Total Iteration Time: 4.69684

Cumulative Model Updates: 117,292
Cumulative Timesteps: 978,155,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,097.06242
Policy Entropy: 3.07352
Value Function Loss: 0.00492

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.08710
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.59440

Collected Steps per Second: 22,957.41748
Overall Steps per Second: 10,843.60446

Timestep Collection Time: 2.17882
Timestep Consumption Time: 2.43404
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.61286

Cumulative Model Updates: 117,298
Cumulative Timesteps: 978,206,016

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 978206016...
Checkpoint 978206016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.52105
Policy Entropy: 3.07806
Value Function Loss: 0.00499

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.56398
Value Function Update Magnitude: 0.61241

Collected Steps per Second: 22,815.85563
Overall Steps per Second: 10,728.22481

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.66135

Cumulative Model Updates: 117,304
Cumulative Timesteps: 978,256,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.13550
Policy Entropy: 3.06992
Value Function Loss: 0.00521

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.56795
Value Function Update Magnitude: 0.61510

Collected Steps per Second: 22,824.23839
Overall Steps per Second: 10,796.20384

Timestep Collection Time: 2.19065
Timestep Consumption Time: 2.44060
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.63126

Cumulative Model Updates: 117,310
Cumulative Timesteps: 978,306,024

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 978306024...
Checkpoint 978306024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.08291
Policy Entropy: 3.08858
Value Function Loss: 0.00543

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.56351
Value Function Update Magnitude: 0.61043

Collected Steps per Second: 22,723.06668
Overall Steps per Second: 10,755.05879

Timestep Collection Time: 2.20138
Timestep Consumption Time: 2.44965
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.65102

Cumulative Model Updates: 117,316
Cumulative Timesteps: 978,356,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 452.19582
Policy Entropy: 3.09022
Value Function Loss: 0.00553

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.55873
Value Function Update Magnitude: 0.62967

Collected Steps per Second: 22,640.38988
Overall Steps per Second: 10,823.69931

Timestep Collection Time: 2.20977
Timestep Consumption Time: 2.41250
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.62226

Cumulative Model Updates: 117,322
Cumulative Timesteps: 978,406,076

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 978406076...
Checkpoint 978406076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.67552
Policy Entropy: 3.08195
Value Function Loss: 0.00532

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.55900
Value Function Update Magnitude: 0.63052

Collected Steps per Second: 22,714.02013
Overall Steps per Second: 10,697.66147

Timestep Collection Time: 2.20128
Timestep Consumption Time: 2.47264
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.67392

Cumulative Model Updates: 117,328
Cumulative Timesteps: 978,456,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.12057
Policy Entropy: 3.07593
Value Function Loss: 0.00539

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.11700
Policy Update Magnitude: 0.55715
Value Function Update Magnitude: 0.62003

Collected Steps per Second: 22,811.11952
Overall Steps per Second: 10,837.32402

Timestep Collection Time: 2.19253
Timestep Consumption Time: 2.42245
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.61498

Cumulative Model Updates: 117,334
Cumulative Timesteps: 978,506,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 978506090...
Checkpoint 978506090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 885.50918
Policy Entropy: 3.07777
Value Function Loss: 0.00511

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.55820
Value Function Update Magnitude: 0.60842

Collected Steps per Second: 22,665.73914
Overall Steps per Second: 10,686.60634

Timestep Collection Time: 2.20615
Timestep Consumption Time: 2.47298
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.67913

Cumulative Model Updates: 117,340
Cumulative Timesteps: 978,556,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,287.95807
Policy Entropy: 3.08160
Value Function Loss: 0.00508

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10483
Policy Update Magnitude: 0.55766
Value Function Update Magnitude: 0.59691

Collected Steps per Second: 22,772.23192
Overall Steps per Second: 10,713.21794

Timestep Collection Time: 2.19618
Timestep Consumption Time: 2.47207
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.66825

Cumulative Model Updates: 117,346
Cumulative Timesteps: 978,606,106

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 978606106...
Checkpoint 978606106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.66706
Policy Entropy: 3.07086
Value Function Loss: 0.00498

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09912
Policy Update Magnitude: 0.55460
Value Function Update Magnitude: 0.58929

Collected Steps per Second: 22,939.32887
Overall Steps per Second: 10,829.24152

Timestep Collection Time: 2.18045
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.28141
Total Iteration Time: 4.61879

Cumulative Model Updates: 117,352
Cumulative Timesteps: 978,656,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894.39982
Policy Entropy: 3.06752
Value Function Loss: 0.00526

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.10099
Policy Update Magnitude: 0.56258
Value Function Update Magnitude: 0.58308

Collected Steps per Second: 23,077.04947
Overall Steps per Second: 10,965.00702

Timestep Collection Time: 2.16665
Timestep Consumption Time: 2.39331
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.55996

Cumulative Model Updates: 117,358
Cumulative Timesteps: 978,706,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 978706124...
Checkpoint 978706124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.46029
Policy Entropy: 3.07472
Value Function Loss: 0.00521

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.56430
Value Function Update Magnitude: 0.58205

Collected Steps per Second: 22,078.16950
Overall Steps per Second: 10,642.27772

Timestep Collection Time: 2.26541
Timestep Consumption Time: 2.43434
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.69975

Cumulative Model Updates: 117,364
Cumulative Timesteps: 978,756,140

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 990.25807
Policy Entropy: 3.06542
Value Function Loss: 0.00535

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.09406
Policy Update Magnitude: 0.56690
Value Function Update Magnitude: 0.58719

Collected Steps per Second: 22,125.02248
Overall Steps per Second: 10,786.46753

Timestep Collection Time: 2.26007
Timestep Consumption Time: 2.37574
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.63581

Cumulative Model Updates: 117,370
Cumulative Timesteps: 978,806,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 978806144...
Checkpoint 978806144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,267.91011
Policy Entropy: 3.05642
Value Function Loss: 0.00537

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09880
Policy Update Magnitude: 0.57102
Value Function Update Magnitude: 0.59162

Collected Steps per Second: 22,171.84322
Overall Steps per Second: 10,755.93126

Timestep Collection Time: 2.25583
Timestep Consumption Time: 2.39425
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.65009

Cumulative Model Updates: 117,376
Cumulative Timesteps: 978,856,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,389.50128
Policy Entropy: 3.03149
Value Function Loss: 0.00574

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.57588
Value Function Update Magnitude: 0.59934

Collected Steps per Second: 21,872.09059
Overall Steps per Second: 10,595.04404

Timestep Collection Time: 2.28730
Timestep Consumption Time: 2.43453
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.72183

Cumulative Model Updates: 117,382
Cumulative Timesteps: 978,906,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 978906188...
Checkpoint 978906188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577.38062
Policy Entropy: 3.03383
Value Function Loss: 0.00581

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10393
Policy Update Magnitude: 0.58211
Value Function Update Magnitude: 0.60252

Collected Steps per Second: 21,975.41981
Overall Steps per Second: 10,616.19426

Timestep Collection Time: 2.27536
Timestep Consumption Time: 2.43461
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.70997

Cumulative Model Updates: 117,388
Cumulative Timesteps: 978,956,190

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,058.31487
Policy Entropy: 3.03950
Value Function Loss: 0.00556

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.58124
Value Function Update Magnitude: 0.60616

Collected Steps per Second: 22,436.75444
Overall Steps per Second: 10,813.50948

Timestep Collection Time: 2.22938
Timestep Consumption Time: 2.39632
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.62570

Cumulative Model Updates: 117,394
Cumulative Timesteps: 979,006,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 979006210...
Checkpoint 979006210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.67164
Policy Entropy: 3.04502
Value Function Loss: 0.00533

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11464
Policy Update Magnitude: 0.57474
Value Function Update Magnitude: 0.60501

Collected Steps per Second: 22,339.39766
Overall Steps per Second: 10,709.40778

Timestep Collection Time: 2.23847
Timestep Consumption Time: 2.43089
PPO Batch Consumption Time: 0.29505
Total Iteration Time: 4.66935

Cumulative Model Updates: 117,400
Cumulative Timesteps: 979,056,216

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,161.86398
Policy Entropy: 3.04392
Value Function Loss: 0.00543

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.11911
Policy Update Magnitude: 0.57858
Value Function Update Magnitude: 0.61830

Collected Steps per Second: 22,757.80704
Overall Steps per Second: 10,749.69193

Timestep Collection Time: 2.19775
Timestep Consumption Time: 2.45503
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.65278

Cumulative Model Updates: 117,406
Cumulative Timesteps: 979,106,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 979106232...
Checkpoint 979106232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 796.39081
Policy Entropy: 3.04978
Value Function Loss: 0.00532

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.12208
Policy Update Magnitude: 0.58181
Value Function Update Magnitude: 0.62999

Collected Steps per Second: 22,808.20415
Overall Steps per Second: 10,682.60354

Timestep Collection Time: 2.19246
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.68107

Cumulative Model Updates: 117,412
Cumulative Timesteps: 979,156,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568.50669
Policy Entropy: 3.05966
Value Function Loss: 0.00554

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.57325
Value Function Update Magnitude: 0.63830

Collected Steps per Second: 23,015.31445
Overall Steps per Second: 10,702.13942

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.50070
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.67421

Cumulative Model Updates: 117,418
Cumulative Timesteps: 979,206,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 979206262...
Checkpoint 979206262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,902.97039
Policy Entropy: 3.07283
Value Function Loss: 0.00555

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.11083
Policy Update Magnitude: 0.56970
Value Function Update Magnitude: 0.63766

Collected Steps per Second: 23,013.28921
Overall Steps per Second: 10,839.90089

Timestep Collection Time: 2.17266
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.61259

Cumulative Model Updates: 117,424
Cumulative Timesteps: 979,256,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,015.55150
Policy Entropy: 3.09261
Value Function Loss: 0.00555

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10700
Policy Update Magnitude: 0.56518
Value Function Update Magnitude: 0.62879

Collected Steps per Second: 22,899.82257
Overall Steps per Second: 10,681.44365

Timestep Collection Time: 2.18430
Timestep Consumption Time: 2.49859
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.68289

Cumulative Model Updates: 117,430
Cumulative Timesteps: 979,306,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 979306282...
Checkpoint 979306282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 795.32239
Policy Entropy: 3.09773
Value Function Loss: 0.00539

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10687
Policy Update Magnitude: 0.55423
Value Function Update Magnitude: 0.60553

Collected Steps per Second: 22,933.11654
Overall Steps per Second: 10,810.66713

Timestep Collection Time: 2.18139
Timestep Consumption Time: 2.44608
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.62747

Cumulative Model Updates: 117,436
Cumulative Timesteps: 979,356,308

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635.30302
Policy Entropy: 3.08612
Value Function Loss: 0.00551

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.10416
Policy Update Magnitude: 0.55944
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 23,003.71644
Overall Steps per Second: 10,690.18130

Timestep Collection Time: 2.17391
Timestep Consumption Time: 2.50403
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.67794

Cumulative Model Updates: 117,442
Cumulative Timesteps: 979,406,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 979406316...
Checkpoint 979406316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228.77680
Policy Entropy: 3.07205
Value Function Loss: 0.00563

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.57032
Value Function Update Magnitude: 0.60280

Collected Steps per Second: 22,964.08806
Overall Steps per Second: 10,856.95401

Timestep Collection Time: 2.17818
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.60719

Cumulative Model Updates: 117,448
Cumulative Timesteps: 979,456,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.79105
Policy Entropy: 3.07181
Value Function Loss: 0.00553

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11961
Policy Update Magnitude: 0.57267
Value Function Update Magnitude: 0.59001

Collected Steps per Second: 22,864.74014
Overall Steps per Second: 10,632.37023

Timestep Collection Time: 2.18695
Timestep Consumption Time: 2.51605
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.70300

Cumulative Model Updates: 117,454
Cumulative Timesteps: 979,506,340

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 979506340...
Checkpoint 979506340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,330.94409
Policy Entropy: 3.07454
Value Function Loss: 0.00519

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10671
Policy Update Magnitude: 0.56508
Value Function Update Magnitude: 0.59639

Collected Steps per Second: 22,851.58244
Overall Steps per Second: 10,656.12985

Timestep Collection Time: 2.18812
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.69232

Cumulative Model Updates: 117,460
Cumulative Timesteps: 979,556,342

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.40868
Policy Entropy: 3.06913
Value Function Loss: 0.00482

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.09837
Policy Update Magnitude: 0.56146
Value Function Update Magnitude: 0.60127

Collected Steps per Second: 22,932.32959
Overall Steps per Second: 10,777.10998

Timestep Collection Time: 2.18042
Timestep Consumption Time: 2.45923
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.63965

Cumulative Model Updates: 117,466
Cumulative Timesteps: 979,606,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 979606344...
Checkpoint 979606344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 998.25676
Policy Entropy: 3.06195
Value Function Loss: 0.00504

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09305
Policy Update Magnitude: 0.55732
Value Function Update Magnitude: 0.61785

Collected Steps per Second: 22,765.88585
Overall Steps per Second: 10,636.74397

Timestep Collection Time: 2.19750
Timestep Consumption Time: 2.50582
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.70332

Cumulative Model Updates: 117,472
Cumulative Timesteps: 979,656,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,114.31856
Policy Entropy: 3.06491
Value Function Loss: 0.00492

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09503
Policy Update Magnitude: 0.55309
Value Function Update Magnitude: 0.61717

Collected Steps per Second: 22,636.41598
Overall Steps per Second: 10,633.29851

Timestep Collection Time: 2.20927
Timestep Consumption Time: 2.49388
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.70315

Cumulative Model Updates: 117,478
Cumulative Timesteps: 979,706,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 979706382...
Checkpoint 979706382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,653.83314
Policy Entropy: 3.06896
Value Function Loss: 0.00523

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10172
Policy Update Magnitude: 0.54661
Value Function Update Magnitude: 0.59592

Collected Steps per Second: 22,877.87740
Overall Steps per Second: 10,796.68274

Timestep Collection Time: 2.18578
Timestep Consumption Time: 2.44583
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.63161

Cumulative Model Updates: 117,484
Cumulative Timesteps: 979,756,388

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 709.55638
Policy Entropy: 3.07347
Value Function Loss: 0.00499

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09261
Policy Update Magnitude: 0.54264
Value Function Update Magnitude: 0.57780

Collected Steps per Second: 22,821.78632
Overall Steps per Second: 10,603.24143

Timestep Collection Time: 2.19194
Timestep Consumption Time: 2.52586
PPO Batch Consumption Time: 0.29579
Total Iteration Time: 4.71780

Cumulative Model Updates: 117,490
Cumulative Timesteps: 979,806,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 979806412...
Checkpoint 979806412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 732.05233
Policy Entropy: 3.08407
Value Function Loss: 0.00519

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.57714

Collected Steps per Second: 22,499.34768
Overall Steps per Second: 10,611.19616

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.49031
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.71313

Cumulative Model Updates: 117,496
Cumulative Timesteps: 979,856,424

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,699.78943
Policy Entropy: 3.09563
Value Function Loss: 0.00491

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.54129
Value Function Update Magnitude: 0.59882

Collected Steps per Second: 22,866.20881
Overall Steps per Second: 10,759.11835

Timestep Collection Time: 2.18690
Timestep Consumption Time: 2.46088
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.64778

Cumulative Model Updates: 117,502
Cumulative Timesteps: 979,906,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 979906430...
Checkpoint 979906430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,144.90982
Policy Entropy: 3.09313
Value Function Loss: 0.00523

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.54909
Value Function Update Magnitude: 0.61465

Collected Steps per Second: 22,830.81053
Overall Steps per Second: 10,775.09668

Timestep Collection Time: 2.19072
Timestep Consumption Time: 2.45109
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.64181

Cumulative Model Updates: 117,508
Cumulative Timesteps: 979,956,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 940.03964
Policy Entropy: 3.10077
Value Function Loss: 0.00505

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09656
Policy Update Magnitude: 0.55361
Value Function Update Magnitude: 0.62927

Collected Steps per Second: 22,737.60077
Overall Steps per Second: 10,624.22099

Timestep Collection Time: 2.19988
Timestep Consumption Time: 2.50823
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.70811

Cumulative Model Updates: 117,514
Cumulative Timesteps: 980,006,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 980006466...
Checkpoint 980006466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,696.32606
Policy Entropy: 3.07536
Value Function Loss: 0.00494

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09763
Policy Update Magnitude: 0.55771
Value Function Update Magnitude: 0.63920

Collected Steps per Second: 22,968.90028
Overall Steps per Second: 10,820.78146

Timestep Collection Time: 2.17755
Timestep Consumption Time: 2.44466
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.62222

Cumulative Model Updates: 117,520
Cumulative Timesteps: 980,056,482

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.37079
Policy Entropy: 3.07846
Value Function Loss: 0.00498

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.55550
Value Function Update Magnitude: 0.62537

Collected Steps per Second: 22,526.51300
Overall Steps per Second: 10,569.92271

Timestep Collection Time: 2.22094
Timestep Consumption Time: 2.51230
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.73324

Cumulative Model Updates: 117,526
Cumulative Timesteps: 980,106,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 980106512...
Checkpoint 980106512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,029.40021
Policy Entropy: 3.06284
Value Function Loss: 0.00508

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.55102
Value Function Update Magnitude: 0.61343

Collected Steps per Second: 22,932.82707
Overall Steps per Second: 10,687.98478

Timestep Collection Time: 2.18037
Timestep Consumption Time: 2.49797
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.67834

Cumulative Model Updates: 117,532
Cumulative Timesteps: 980,156,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,240.08332
Policy Entropy: 3.07237
Value Function Loss: 0.00553

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.09947
Policy Update Magnitude: 0.55454
Value Function Update Magnitude: 0.61618

Collected Steps per Second: 22,957.39938
Overall Steps per Second: 10,892.67732

Timestep Collection Time: 2.17873
Timestep Consumption Time: 2.41316
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.59189

Cumulative Model Updates: 117,538
Cumulative Timesteps: 980,206,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 980206532...
Checkpoint 980206532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 630.02171
Policy Entropy: 3.06769
Value Function Loss: 0.00543

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09962
Policy Update Magnitude: 0.55865
Value Function Update Magnitude: 0.60951

Collected Steps per Second: 23,083.12001
Overall Steps per Second: 10,789.24096

Timestep Collection Time: 2.16608
Timestep Consumption Time: 2.46816
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.63425

Cumulative Model Updates: 117,544
Cumulative Timesteps: 980,256,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,374.37932
Policy Entropy: 3.09140
Value Function Loss: 0.00514

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.55428
Value Function Update Magnitude: 0.61213

Collected Steps per Second: 22,412.41460
Overall Steps per Second: 10,689.53620

Timestep Collection Time: 2.23180
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.67934

Cumulative Model Updates: 117,550
Cumulative Timesteps: 980,306,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 980306552...
Checkpoint 980306552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 981.38941
Policy Entropy: 3.07622
Value Function Loss: 0.00494

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10447
Policy Update Magnitude: 0.55283
Value Function Update Magnitude: 0.60635

Collected Steps per Second: 22,787.04849
Overall Steps per Second: 10,651.61282

Timestep Collection Time: 2.19476
Timestep Consumption Time: 2.50050
PPO Batch Consumption Time: 0.29692
Total Iteration Time: 4.69525

Cumulative Model Updates: 117,556
Cumulative Timesteps: 980,356,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 533.73038
Policy Entropy: 3.08598
Value Function Loss: 0.00508

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.09447
Policy Update Magnitude: 0.55375
Value Function Update Magnitude: 0.60219

Collected Steps per Second: 22,960.45389
Overall Steps per Second: 10,854.75041

Timestep Collection Time: 2.17905
Timestep Consumption Time: 2.43018
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.60923

Cumulative Model Updates: 117,562
Cumulative Timesteps: 980,406,596

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 980406596...
Checkpoint 980406596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 882.86480
Policy Entropy: 3.07812
Value Function Loss: 0.00477

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.58758

Collected Steps per Second: 22,583.37680
Overall Steps per Second: 10,725.69779

Timestep Collection Time: 2.21420
Timestep Consumption Time: 2.44788
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.66207

Cumulative Model Updates: 117,568
Cumulative Timesteps: 980,456,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 978.85042
Policy Entropy: 3.07520
Value Function Loss: 0.00490

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.09416
Policy Update Magnitude: 0.53605
Value Function Update Magnitude: 0.56567

Collected Steps per Second: 22,722.96845
Overall Steps per Second: 10,788.31314

Timestep Collection Time: 2.20077
Timestep Consumption Time: 2.43462
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.63539

Cumulative Model Updates: 117,574
Cumulative Timesteps: 980,506,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 980506608...
Checkpoint 980506608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,828.12320
Policy Entropy: 3.07798
Value Function Loss: 0.00473

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10918
Policy Update Magnitude: 0.54336
Value Function Update Magnitude: 0.56469

Collected Steps per Second: 22,863.83576
Overall Steps per Second: 10,754.77793

Timestep Collection Time: 2.18773
Timestep Consumption Time: 2.46322
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.65096

Cumulative Model Updates: 117,580
Cumulative Timesteps: 980,556,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.93743
Policy Entropy: 3.06685
Value Function Loss: 0.00522

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.11709
Policy Update Magnitude: 0.54932
Value Function Update Magnitude: 0.56566

Collected Steps per Second: 22,791.21552
Overall Steps per Second: 10,823.12798

Timestep Collection Time: 2.19514
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.62251

Cumulative Model Updates: 117,586
Cumulative Timesteps: 980,606,658

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 980606658...
Checkpoint 980606658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016.66553
Policy Entropy: 3.07050
Value Function Loss: 0.00521

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10238
Policy Update Magnitude: 0.55107
Value Function Update Magnitude: 0.57310

Collected Steps per Second: 22,853.21968
Overall Steps per Second: 10,714.27011

Timestep Collection Time: 2.18831
Timestep Consumption Time: 2.47929
PPO Batch Consumption Time: 0.29289
Total Iteration Time: 4.66761

Cumulative Model Updates: 117,592
Cumulative Timesteps: 980,656,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,055.09455
Policy Entropy: 3.06292
Value Function Loss: 0.00554

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10130
Policy Update Magnitude: 0.55285
Value Function Update Magnitude: 0.58426

Collected Steps per Second: 22,700.92749
Overall Steps per Second: 10,679.26350

Timestep Collection Time: 2.20343
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.68384

Cumulative Model Updates: 117,598
Cumulative Timesteps: 980,706,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 980706688...
Checkpoint 980706688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555.73639
Policy Entropy: 3.05276
Value Function Loss: 0.00537

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.10931
Policy Update Magnitude: 0.55902
Value Function Update Magnitude: 0.59888

Collected Steps per Second: 23,086.16773
Overall Steps per Second: 10,909.07854

Timestep Collection Time: 2.16649
Timestep Consumption Time: 2.41831
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.58481

Cumulative Model Updates: 117,604
Cumulative Timesteps: 980,756,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 962.09334
Policy Entropy: 3.06470
Value Function Loss: 0.00515

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.11441
Policy Update Magnitude: 0.56133
Value Function Update Magnitude: 0.59182

Collected Steps per Second: 22,659.68045
Overall Steps per Second: 10,787.97715

Timestep Collection Time: 2.20762
Timestep Consumption Time: 2.42939
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.63701

Cumulative Model Updates: 117,610
Cumulative Timesteps: 980,806,728

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 980806728...
Checkpoint 980806728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,369.63012
Policy Entropy: 3.06104
Value Function Loss: 0.00532

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10665
Policy Update Magnitude: 0.56334
Value Function Update Magnitude: 0.59562

Collected Steps per Second: 22,783.78140
Overall Steps per Second: 10,719.77638

Timestep Collection Time: 2.19516
Timestep Consumption Time: 2.47042
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.66558

Cumulative Model Updates: 117,616
Cumulative Timesteps: 980,856,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,867.36559
Policy Entropy: 3.07472
Value Function Loss: 0.00549

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10425
Policy Update Magnitude: 0.57365
Value Function Update Magnitude: 0.61050

Collected Steps per Second: 22,407.79662
Overall Steps per Second: 10,603.17812

Timestep Collection Time: 2.23137
Timestep Consumption Time: 2.48420
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.71557

Cumulative Model Updates: 117,622
Cumulative Timesteps: 980,906,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 980906742...
Checkpoint 980906742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.23065
Policy Entropy: 3.07743
Value Function Loss: 0.00548

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.57408
Value Function Update Magnitude: 0.62910

Collected Steps per Second: 22,706.23201
Overall Steps per Second: 10,812.72641

Timestep Collection Time: 2.20266
Timestep Consumption Time: 2.42282
PPO Batch Consumption Time: 0.28268
Total Iteration Time: 4.62548

Cumulative Model Updates: 117,628
Cumulative Timesteps: 980,956,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.50997
Policy Entropy: 3.07195
Value Function Loss: 0.00545

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.56544
Value Function Update Magnitude: 0.61019

Collected Steps per Second: 22,845.21733
Overall Steps per Second: 10,704.79244

Timestep Collection Time: 2.18978
Timestep Consumption Time: 2.48345
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.67323

Cumulative Model Updates: 117,634
Cumulative Timesteps: 981,006,782

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 981006782...
Checkpoint 981006782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 709.06640
Policy Entropy: 3.05173
Value Function Loss: 0.00519

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.57393
Value Function Update Magnitude: 0.59170

Collected Steps per Second: 22,930.18466
Overall Steps per Second: 10,867.27850

Timestep Collection Time: 2.18201
Timestep Consumption Time: 2.42208
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.60410

Cumulative Model Updates: 117,640
Cumulative Timesteps: 981,056,816

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,008.49405
Policy Entropy: 3.04872
Value Function Loss: 0.00525

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.57011
Value Function Update Magnitude: 0.59575

Collected Steps per Second: 22,806.67954
Overall Steps per Second: 10,643.11172

Timestep Collection Time: 2.19348
Timestep Consumption Time: 2.50684
PPO Batch Consumption Time: 0.29551
Total Iteration Time: 4.70032

Cumulative Model Updates: 117,646
Cumulative Timesteps: 981,106,842

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 981106842...
Checkpoint 981106842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.34232
Policy Entropy: 3.06254
Value Function Loss: 0.00487

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10758
Policy Update Magnitude: 0.56141
Value Function Update Magnitude: 0.58946

Collected Steps per Second: 22,526.76574
Overall Steps per Second: 10,625.89487

Timestep Collection Time: 2.22029
Timestep Consumption Time: 2.48670
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.70699

Cumulative Model Updates: 117,652
Cumulative Timesteps: 981,156,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 840.89871
Policy Entropy: 3.08257
Value Function Loss: 0.00519

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.55915
Value Function Update Magnitude: 0.57855

Collected Steps per Second: 22,992.20960
Overall Steps per Second: 10,873.47921

Timestep Collection Time: 2.17543
Timestep Consumption Time: 2.42457
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.60000

Cumulative Model Updates: 117,658
Cumulative Timesteps: 981,206,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 981206876...
Checkpoint 981206876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 775.91359
Policy Entropy: 3.08095
Value Function Loss: 0.00516

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.56442
Value Function Update Magnitude: 0.58087

Collected Steps per Second: 22,631.05801
Overall Steps per Second: 10,634.39637

Timestep Collection Time: 2.20997
Timestep Consumption Time: 2.49307
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.70304

Cumulative Model Updates: 117,664
Cumulative Timesteps: 981,256,890

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,360.88018
Policy Entropy: 3.06794
Value Function Loss: 0.00556

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11075
Policy Update Magnitude: 0.57096
Value Function Update Magnitude: 0.59192

Collected Steps per Second: 22,656.43021
Overall Steps per Second: 10,762.02976

Timestep Collection Time: 2.20794
Timestep Consumption Time: 2.44026
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.64819

Cumulative Model Updates: 117,670
Cumulative Timesteps: 981,306,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 981306914...
Checkpoint 981306914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 843.87538
Policy Entropy: 3.06442
Value Function Loss: 0.00560

Mean KL Divergence: 0.01146
SB3 Clip Fraction: 0.11762
Policy Update Magnitude: 0.57206
Value Function Update Magnitude: 0.59630

Collected Steps per Second: 22,947.65043
Overall Steps per Second: 10,759.86647

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.46891
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.64857

Cumulative Model Updates: 117,676
Cumulative Timesteps: 981,356,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.31149
Policy Entropy: 3.05668
Value Function Loss: 0.00548

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09517
Policy Update Magnitude: 0.56650
Value Function Update Magnitude: 0.61485

Collected Steps per Second: 22,867.86959
Overall Steps per Second: 10,829.72243

Timestep Collection Time: 2.18647
Timestep Consumption Time: 2.43045
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.61692

Cumulative Model Updates: 117,682
Cumulative Timesteps: 981,406,932

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 981406932...
Checkpoint 981406932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628.75595
Policy Entropy: 3.07038
Value Function Loss: 0.00518

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09939
Policy Update Magnitude: 0.55517
Value Function Update Magnitude: 0.59466

Collected Steps per Second: 22,876.44002
Overall Steps per Second: 10,714.65135

Timestep Collection Time: 2.18679
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.66893

Cumulative Model Updates: 117,688
Cumulative Timesteps: 981,456,958

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 738.37634
Policy Entropy: 3.04854
Value Function Loss: 0.00518

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10406
Policy Update Magnitude: 0.55152
Value Function Update Magnitude: 0.56212

Collected Steps per Second: 22,341.94996
Overall Steps per Second: 10,580.85214

Timestep Collection Time: 2.23830
Timestep Consumption Time: 2.48797
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.72627

Cumulative Model Updates: 117,694
Cumulative Timesteps: 981,506,966

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 981506966...
Checkpoint 981506966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,021.57532
Policy Entropy: 3.04839
Value Function Loss: 0.00530

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10635
Policy Update Magnitude: 0.55290
Value Function Update Magnitude: 0.57198

Collected Steps per Second: 22,967.80596
Overall Steps per Second: 10,843.00683

Timestep Collection Time: 2.17827
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.61403

Cumulative Model Updates: 117,700
Cumulative Timesteps: 981,556,996

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,391.50410
Policy Entropy: 3.03553
Value Function Loss: 0.00528

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.55442
Value Function Update Magnitude: 0.58512

Collected Steps per Second: 22,981.75922
Overall Steps per Second: 10,741.05000

Timestep Collection Time: 2.17668
Timestep Consumption Time: 2.48059
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.65727

Cumulative Model Updates: 117,706
Cumulative Timesteps: 981,607,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 981607020...
Checkpoint 981607020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,980.10036
Policy Entropy: 3.05272
Value Function Loss: 0.00560

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.55641
Value Function Update Magnitude: 0.57620

Collected Steps per Second: 22,806.70490
Overall Steps per Second: 10,831.22729

Timestep Collection Time: 2.19295
Timestep Consumption Time: 2.42462
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.61757

Cumulative Model Updates: 117,712
Cumulative Timesteps: 981,657,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.79663
Policy Entropy: 3.05403
Value Function Loss: 0.00595

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.56210
Value Function Update Magnitude: 0.57670

Collected Steps per Second: 22,607.22937
Overall Steps per Second: 10,567.07556

Timestep Collection Time: 2.21168
Timestep Consumption Time: 2.52000
PPO Batch Consumption Time: 0.29578
Total Iteration Time: 4.73168

Cumulative Model Updates: 117,718
Cumulative Timesteps: 981,707,034

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 981707034...
Checkpoint 981707034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,550.93802
Policy Entropy: 3.05019
Value Function Loss: 0.00583

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10108
Policy Update Magnitude: 0.56431
Value Function Update Magnitude: 0.59370

Collected Steps per Second: 22,817.31165
Overall Steps per Second: 10,630.06051

Timestep Collection Time: 2.19211
Timestep Consumption Time: 2.51323
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.70534

Cumulative Model Updates: 117,724
Cumulative Timesteps: 981,757,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,286.05393
Policy Entropy: 3.03131
Value Function Loss: 0.00579

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09801
Policy Update Magnitude: 0.56933
Value Function Update Magnitude: 0.61128

Collected Steps per Second: 22,733.30380
Overall Steps per Second: 10,946.03476

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.36864
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.56823

Cumulative Model Updates: 117,730
Cumulative Timesteps: 981,807,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 981807056...
Checkpoint 981807056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 544.66880
Policy Entropy: 3.04668
Value Function Loss: 0.00564

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.57704
Value Function Update Magnitude: 0.59633

Collected Steps per Second: 22,345.21943
Overall Steps per Second: 10,747.17725

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.41516
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.65313

Cumulative Model Updates: 117,736
Cumulative Timesteps: 981,857,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.75505
Policy Entropy: 3.05590
Value Function Loss: 0.00562

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11086
Policy Update Magnitude: 0.57268
Value Function Update Magnitude: 0.59839

Collected Steps per Second: 22,175.21459
Overall Steps per Second: 10,733.60108

Timestep Collection Time: 2.25684
Timestep Consumption Time: 2.40571
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.66255

Cumulative Model Updates: 117,742
Cumulative Timesteps: 981,907,110

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 981907110...
Checkpoint 981907110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 951.33585
Policy Entropy: 3.06445
Value Function Loss: 0.00548

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.10441
Policy Update Magnitude: 0.56444
Value Function Update Magnitude: 0.59400

Collected Steps per Second: 21,995.03634
Overall Steps per Second: 10,671.87652

Timestep Collection Time: 2.27397
Timestep Consumption Time: 2.41274
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.68671

Cumulative Model Updates: 117,748
Cumulative Timesteps: 981,957,126

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 763.33588
Policy Entropy: 3.05400
Value Function Loss: 0.00533

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10219
Policy Update Magnitude: 0.56108
Value Function Update Magnitude: 0.60632

Collected Steps per Second: 22,014.07670
Overall Steps per Second: 10,637.13806

Timestep Collection Time: 2.27146
Timestep Consumption Time: 2.42943
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.70089

Cumulative Model Updates: 117,754
Cumulative Timesteps: 982,007,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 982007130...
Checkpoint 982007130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 869.03925
Policy Entropy: 3.05259
Value Function Loss: 0.00530

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10551
Policy Update Magnitude: 0.56056
Value Function Update Magnitude: 0.60224

Collected Steps per Second: 22,416.21081
Overall Steps per Second: 10,846.37742

Timestep Collection Time: 2.23124
Timestep Consumption Time: 2.38007
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.61131

Cumulative Model Updates: 117,760
Cumulative Timesteps: 982,057,146

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,248.87222
Policy Entropy: 3.06720
Value Function Loss: 0.00529

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.56158
Value Function Update Magnitude: 0.61646

Collected Steps per Second: 22,714.30546
Overall Steps per Second: 10,564.46491

Timestep Collection Time: 2.20205
Timestep Consumption Time: 2.53250
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.73455

Cumulative Model Updates: 117,766
Cumulative Timesteps: 982,107,164

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 982107164...
Checkpoint 982107164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,704.24489
Policy Entropy: 3.08127
Value Function Loss: 0.00538

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09659
Policy Update Magnitude: 0.56466
Value Function Update Magnitude: 0.62314

Collected Steps per Second: 23,006.94114
Overall Steps per Second: 10,668.78415

Timestep Collection Time: 2.17360
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.68732

Cumulative Model Updates: 117,772
Cumulative Timesteps: 982,157,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,242.88249
Policy Entropy: 3.06912
Value Function Loss: 0.00537

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.56288
Value Function Update Magnitude: 0.61766

Collected Steps per Second: 23,132.10261
Overall Steps per Second: 10,856.35008

Timestep Collection Time: 2.16167
Timestep Consumption Time: 2.44430
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.60597

Cumulative Model Updates: 117,778
Cumulative Timesteps: 982,207,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 982207176...
Checkpoint 982207176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 520.44098
Policy Entropy: 3.05771
Value Function Loss: 0.00576

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.57297
Value Function Update Magnitude: 0.62117

Collected Steps per Second: 23,164.83689
Overall Steps per Second: 10,692.25498

Timestep Collection Time: 2.15853
Timestep Consumption Time: 2.51794
PPO Batch Consumption Time: 0.29526
Total Iteration Time: 4.67647

Cumulative Model Updates: 117,784
Cumulative Timesteps: 982,257,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.11568
Policy Entropy: 3.06137
Value Function Loss: 0.00518

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.10472
Policy Update Magnitude: 0.57028
Value Function Update Magnitude: 0.63169

Collected Steps per Second: 22,973.90605
Overall Steps per Second: 10,771.87243

Timestep Collection Time: 2.17734
Timestep Consumption Time: 2.46642
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.64376

Cumulative Model Updates: 117,790
Cumulative Timesteps: 982,307,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 982307200...
Checkpoint 982307200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.73359
Policy Entropy: 3.07492
Value Function Loss: 0.00501

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.55593
Value Function Update Magnitude: 0.60430

Collected Steps per Second: 22,666.65319
Overall Steps per Second: 10,773.63290

Timestep Collection Time: 2.20597
Timestep Consumption Time: 2.43517
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.64115

Cumulative Model Updates: 117,796
Cumulative Timesteps: 982,357,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,337.19788
Policy Entropy: 3.07792
Value Function Loss: 0.00484

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10290
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.58723

Collected Steps per Second: 23,095.01459
Overall Steps per Second: 10,822.04264

Timestep Collection Time: 2.16532
Timestep Consumption Time: 2.45562
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.62094

Cumulative Model Updates: 117,802
Cumulative Timesteps: 982,407,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 982407210...
Checkpoint 982407210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 849.67230
Policy Entropy: 3.07591
Value Function Loss: 0.00503

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.11271
Policy Update Magnitude: 0.54821
Value Function Update Magnitude: 0.58544

Collected Steps per Second: 22,894.76268
Overall Steps per Second: 10,686.10808

Timestep Collection Time: 2.18487
Timestep Consumption Time: 2.49616
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.68103

Cumulative Model Updates: 117,808
Cumulative Timesteps: 982,457,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732.56768
Policy Entropy: 3.08430
Value Function Loss: 0.00519

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.55207
Value Function Update Magnitude: 0.60382

Collected Steps per Second: 22,733.17503
Overall Steps per Second: 10,645.52993

Timestep Collection Time: 2.20022
Timestep Consumption Time: 2.49828
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.69850

Cumulative Model Updates: 117,814
Cumulative Timesteps: 982,507,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 982507250...
Checkpoint 982507250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,072.35372
Policy Entropy: 3.08308
Value Function Loss: 0.00529

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.10939
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.62349

Collected Steps per Second: 22,965.48363
Overall Steps per Second: 10,833.10921

Timestep Collection Time: 2.17762
Timestep Consumption Time: 2.43879
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.61640

Cumulative Model Updates: 117,820
Cumulative Timesteps: 982,557,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 616.54031
Policy Entropy: 3.06832
Value Function Loss: 0.00530

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10321
Policy Update Magnitude: 0.56117
Value Function Update Magnitude: 0.63586

Collected Steps per Second: 23,195.26539
Overall Steps per Second: 10,851.58465

Timestep Collection Time: 2.15587
Timestep Consumption Time: 2.45230
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.60817

Cumulative Model Updates: 117,826
Cumulative Timesteps: 982,607,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 982607266...
Checkpoint 982607266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.70779
Policy Entropy: 3.06015
Value Function Loss: 0.00519

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.56343
Value Function Update Magnitude: 0.64015

Collected Steps per Second: 23,109.33768
Overall Steps per Second: 10,730.14557

Timestep Collection Time: 2.16389
Timestep Consumption Time: 2.49644
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.66033

Cumulative Model Updates: 117,832
Cumulative Timesteps: 982,657,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,047.79079
Policy Entropy: 3.06521
Value Function Loss: 0.00559

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.57241
Value Function Update Magnitude: 0.63787

Collected Steps per Second: 22,810.39685
Overall Steps per Second: 10,664.21130

Timestep Collection Time: 2.19286
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.69045

Cumulative Model Updates: 117,838
Cumulative Timesteps: 982,707,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 982707292...
Checkpoint 982707292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608.86605
Policy Entropy: 3.08011
Value Function Loss: 0.00584

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.11514
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.63564

Collected Steps per Second: 22,755.32426
Overall Steps per Second: 10,753.37712

Timestep Collection Time: 2.19790
Timestep Consumption Time: 2.45310
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.65100

Cumulative Model Updates: 117,844
Cumulative Timesteps: 982,757,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 802.58775
Policy Entropy: 3.06621
Value Function Loss: 0.00593

Mean KL Divergence: 0.01267
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.56903
Value Function Update Magnitude: 0.62870

Collected Steps per Second: 22,899.52169
Overall Steps per Second: 10,644.56954

Timestep Collection Time: 2.18433
Timestep Consumption Time: 2.51478
PPO Batch Consumption Time: 0.29461
Total Iteration Time: 4.69911

Cumulative Model Updates: 117,850
Cumulative Timesteps: 982,807,326

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 982807326...
Checkpoint 982807326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.19000
Policy Entropy: 3.07080
Value Function Loss: 0.00549

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.60635

Collected Steps per Second: 22,730.47489
Overall Steps per Second: 10,584.41384

Timestep Collection Time: 2.20022
Timestep Consumption Time: 2.52484
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.72506

Cumulative Model Updates: 117,856
Cumulative Timesteps: 982,857,338

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,406.42467
Policy Entropy: 3.07834
Value Function Loss: 0.00518

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10867
Policy Update Magnitude: 0.56205
Value Function Update Magnitude: 0.59291

Collected Steps per Second: 22,861.74410
Overall Steps per Second: 10,775.18194

Timestep Collection Time: 2.18723
Timestep Consumption Time: 2.45343
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.64066

Cumulative Model Updates: 117,862
Cumulative Timesteps: 982,907,342

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 982907342...
Checkpoint 982907342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,195.66082
Policy Entropy: 3.07840
Value Function Loss: 0.00521

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.56810
Value Function Update Magnitude: 0.58991

Collected Steps per Second: 22,614.37717
Overall Steps per Second: 10,713.32362

Timestep Collection Time: 2.21178
Timestep Consumption Time: 2.45699
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.66877

Cumulative Model Updates: 117,868
Cumulative Timesteps: 982,957,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 747.17379
Policy Entropy: 3.07478
Value Function Loss: 0.00527

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.56950
Value Function Update Magnitude: 0.61271

Collected Steps per Second: 23,003.21899
Overall Steps per Second: 10,866.28533

Timestep Collection Time: 2.17413
Timestep Consumption Time: 2.42836
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.60249

Cumulative Model Updates: 117,874
Cumulative Timesteps: 983,007,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 983007372...
Checkpoint 983007372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 664.69978
Policy Entropy: 3.04168
Value Function Loss: 0.00548

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.09821
Policy Update Magnitude: 0.57220
Value Function Update Magnitude: 0.63272

Collected Steps per Second: 22,812.34931
Overall Steps per Second: 10,773.52649

Timestep Collection Time: 2.19180
Timestep Consumption Time: 2.44921
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.64101

Cumulative Model Updates: 117,880
Cumulative Timesteps: 983,057,372

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.89016
Policy Entropy: 3.05796
Value Function Loss: 0.00548

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10083
Policy Update Magnitude: 0.57000
Value Function Update Magnitude: 0.63284

Collected Steps per Second: 22,860.91181
Overall Steps per Second: 10,822.14064

Timestep Collection Time: 2.18810
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.62219

Cumulative Model Updates: 117,886
Cumulative Timesteps: 983,107,394

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 983107394...
Checkpoint 983107394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 666.20308
Policy Entropy: 3.05933
Value Function Loss: 0.00564

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.57272
Value Function Update Magnitude: 0.63933

Collected Steps per Second: 22,911.52650
Overall Steps per Second: 10,674.80779

Timestep Collection Time: 2.18309
Timestep Consumption Time: 2.50252
PPO Batch Consumption Time: 0.29728
Total Iteration Time: 4.68561

Cumulative Model Updates: 117,892
Cumulative Timesteps: 983,157,412

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610.72726
Policy Entropy: 3.08036
Value Function Loss: 0.00546

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10224
Policy Update Magnitude: 0.57056
Value Function Update Magnitude: 0.63640

Collected Steps per Second: 23,093.90659
Overall Steps per Second: 10,886.13619

Timestep Collection Time: 2.16577
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.28216
Total Iteration Time: 4.59447

Cumulative Model Updates: 117,898
Cumulative Timesteps: 983,207,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 983207428...
Checkpoint 983207428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,637.33945
Policy Entropy: 3.09849
Value Function Loss: 0.00531

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.11300
Policy Update Magnitude: 0.56285
Value Function Update Magnitude: 0.62052

Collected Steps per Second: 22,844.77971
Overall Steps per Second: 10,678.48011

Timestep Collection Time: 2.18973
Timestep Consumption Time: 2.49483
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.68456

Cumulative Model Updates: 117,904
Cumulative Timesteps: 983,257,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 905.59225
Policy Entropy: 3.09610
Value Function Loss: 0.00497

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.55118
Value Function Update Magnitude: 0.61940

Collected Steps per Second: 22,326.05454
Overall Steps per Second: 10,578.83097

Timestep Collection Time: 2.24133
Timestep Consumption Time: 2.48887
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.73020

Cumulative Model Updates: 117,910
Cumulative Timesteps: 983,307,492

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 983307492...
Checkpoint 983307492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 890.48745
Policy Entropy: 3.08123
Value Function Loss: 0.00516

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.14155
Policy Update Magnitude: 0.55611
Value Function Update Magnitude: 0.61551

Collected Steps per Second: 22,813.18431
Overall Steps per Second: 10,723.01764

Timestep Collection Time: 2.19277
Timestep Consumption Time: 2.47234
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.66510

Cumulative Model Updates: 117,916
Cumulative Timesteps: 983,357,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.87315
Policy Entropy: 3.08012
Value Function Loss: 0.00532

Mean KL Divergence: 0.01822
SB3 Clip Fraction: 0.15549
Policy Update Magnitude: 0.56490
Value Function Update Magnitude: 0.63585

Collected Steps per Second: 22,645.38561
Overall Steps per Second: 10,743.22760

Timestep Collection Time: 2.20875
Timestep Consumption Time: 2.44702
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.65577

Cumulative Model Updates: 117,922
Cumulative Timesteps: 983,407,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 983407534...
Checkpoint 983407534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 912.39525
Policy Entropy: 3.07903
Value Function Loss: 0.00566

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.14551
Policy Update Magnitude: 0.57229
Value Function Update Magnitude: 0.63819

Collected Steps per Second: 23,025.79556
Overall Steps per Second: 10,753.27571

Timestep Collection Time: 2.17261
Timestep Consumption Time: 2.47956
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.65216

Cumulative Model Updates: 117,928
Cumulative Timesteps: 983,457,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.17304
Policy Entropy: 3.09125
Value Function Loss: 0.00550

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.56898
Value Function Update Magnitude: 0.63529

Collected Steps per Second: 22,946.21194
Overall Steps per Second: 10,761.06277

Timestep Collection Time: 2.17944
Timestep Consumption Time: 2.46787
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.64731

Cumulative Model Updates: 117,934
Cumulative Timesteps: 983,507,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 983507570...
Checkpoint 983507570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.94767
Policy Entropy: 3.09218
Value Function Loss: 0.00554

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.10478
Policy Update Magnitude: 0.56522
Value Function Update Magnitude: 0.62655

Collected Steps per Second: 22,836.67158
Overall Steps per Second: 10,677.99867

Timestep Collection Time: 2.18955
Timestep Consumption Time: 2.49316
PPO Batch Consumption Time: 0.29547
Total Iteration Time: 4.68271

Cumulative Model Updates: 117,940
Cumulative Timesteps: 983,557,572

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 528.74512
Policy Entropy: 3.09431
Value Function Loss: 0.00538

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09633
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.62740

Collected Steps per Second: 23,250.09695
Overall Steps per Second: 10,909.54605

Timestep Collection Time: 2.15147
Timestep Consumption Time: 2.43368
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.58516

Cumulative Model Updates: 117,946
Cumulative Timesteps: 983,607,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 983607594...
Checkpoint 983607594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 697.75013
Policy Entropy: 3.09168
Value Function Loss: 0.00540

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10106
Policy Update Magnitude: 0.56707
Value Function Update Magnitude: 0.62403

Collected Steps per Second: 23,034.64206
Overall Steps per Second: 10,737.88855

Timestep Collection Time: 2.17108
Timestep Consumption Time: 2.48626
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.65734

Cumulative Model Updates: 117,952
Cumulative Timesteps: 983,657,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540.85504
Policy Entropy: 3.09725
Value Function Loss: 0.00540

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.56438
Value Function Update Magnitude: 0.60750

Collected Steps per Second: 22,654.29484
Overall Steps per Second: 10,804.89442

Timestep Collection Time: 2.20771
Timestep Consumption Time: 2.42112
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.62883

Cumulative Model Updates: 117,958
Cumulative Timesteps: 983,707,618

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 983707618...
Checkpoint 983707618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,492.68556
Policy Entropy: 3.09198
Value Function Loss: 0.00522

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.10072
Policy Update Magnitude: 0.56332
Value Function Update Magnitude: 0.61123

Collected Steps per Second: 22,712.34843
Overall Steps per Second: 10,642.83285

Timestep Collection Time: 2.20233
Timestep Consumption Time: 2.49755
PPO Batch Consumption Time: 0.29523
Total Iteration Time: 4.69988

Cumulative Model Updates: 117,964
Cumulative Timesteps: 983,757,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 878.68506
Policy Entropy: 3.09478
Value Function Loss: 0.00532

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10194
Policy Update Magnitude: 0.55772
Value Function Update Magnitude: 0.61414

Collected Steps per Second: 22,651.80452
Overall Steps per Second: 10,765.54826

Timestep Collection Time: 2.20812
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.64612

Cumulative Model Updates: 117,970
Cumulative Timesteps: 983,807,656

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 983807656...
Checkpoint 983807656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,547.32202
Policy Entropy: 3.09684
Value Function Loss: 0.00519

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.55275
Value Function Update Magnitude: 0.59637

Collected Steps per Second: 22,825.91591
Overall Steps per Second: 10,729.52307

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.47103
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.66284

Cumulative Model Updates: 117,976
Cumulative Timesteps: 983,857,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.19939
Policy Entropy: 3.10525
Value Function Loss: 0.00528

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.55591
Value Function Update Magnitude: 0.58493

Collected Steps per Second: 22,621.27072
Overall Steps per Second: 10,671.86381

Timestep Collection Time: 2.21119
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.68709

Cumulative Model Updates: 117,982
Cumulative Timesteps: 983,907,706

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 983907706...
Checkpoint 983907706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.93285
Policy Entropy: 3.09400
Value Function Loss: 0.00538

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.10797
Policy Update Magnitude: 0.56015
Value Function Update Magnitude: 0.58679

Collected Steps per Second: 22,384.88849
Overall Steps per Second: 10,571.10248

Timestep Collection Time: 2.23419
Timestep Consumption Time: 2.49683
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.73101

Cumulative Model Updates: 117,988
Cumulative Timesteps: 983,957,718

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 896.90012
Policy Entropy: 3.08901
Value Function Loss: 0.00502

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.56523
Value Function Update Magnitude: 0.58485

Collected Steps per Second: 22,917.93083
Overall Steps per Second: 10,817.57146

Timestep Collection Time: 2.18179
Timestep Consumption Time: 2.44051
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.62229

Cumulative Model Updates: 117,994
Cumulative Timesteps: 984,007,720

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 984007720...
Checkpoint 984007720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 774.91795
Policy Entropy: 3.07676
Value Function Loss: 0.00526

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.10750
Policy Update Magnitude: 0.55279
Value Function Update Magnitude: 0.57823

Collected Steps per Second: 22,652.68996
Overall Steps per Second: 10,615.39875

Timestep Collection Time: 2.20795
Timestep Consumption Time: 2.50370
PPO Batch Consumption Time: 0.29573
Total Iteration Time: 4.71165

Cumulative Model Updates: 118,000
Cumulative Timesteps: 984,057,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765.52455
Policy Entropy: 3.08061
Value Function Loss: 0.00534

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.54939
Value Function Update Magnitude: 0.57371

Collected Steps per Second: 22,787.59565
Overall Steps per Second: 10,796.54941

Timestep Collection Time: 2.19444
Timestep Consumption Time: 2.43723
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.63167

Cumulative Model Updates: 118,006
Cumulative Timesteps: 984,107,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 984107742...
Checkpoint 984107742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403.37149
Policy Entropy: 3.09489
Value Function Loss: 0.00530

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.11369
Policy Update Magnitude: 0.54684
Value Function Update Magnitude: 0.56197

Collected Steps per Second: 22,644.89349
Overall Steps per Second: 10,703.95705

Timestep Collection Time: 2.20836
Timestep Consumption Time: 2.46356
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.67192

Cumulative Model Updates: 118,012
Cumulative Timesteps: 984,157,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 669.78470
Policy Entropy: 3.08606
Value Function Loss: 0.00526

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.54724
Value Function Update Magnitude: 0.55495

Collected Steps per Second: 23,052.12047
Overall Steps per Second: 10,868.54958

Timestep Collection Time: 2.17021
Timestep Consumption Time: 2.43279
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.60301

Cumulative Model Updates: 118,018
Cumulative Timesteps: 984,207,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 984207778...
Checkpoint 984207778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,508.52458
Policy Entropy: 3.09779
Value Function Loss: 0.00507

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.54825
Value Function Update Magnitude: 0.58467

Collected Steps per Second: 22,805.03894
Overall Steps per Second: 10,746.80960

Timestep Collection Time: 2.19364
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.65496

Cumulative Model Updates: 118,024
Cumulative Timesteps: 984,257,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,175.96593
Policy Entropy: 3.09421
Value Function Loss: 0.00513

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.55645
Value Function Update Magnitude: 0.60936

Collected Steps per Second: 22,633.83173
Overall Steps per Second: 10,626.50399

Timestep Collection Time: 2.20988
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.70691

Cumulative Model Updates: 118,030
Cumulative Timesteps: 984,307,822

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 984307822...
Checkpoint 984307822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,664.53456
Policy Entropy: 3.09272
Value Function Loss: 0.00525

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.10366
Policy Update Magnitude: 0.56301
Value Function Update Magnitude: 0.62445

Collected Steps per Second: 22,940.66992
Overall Steps per Second: 10,857.33839

Timestep Collection Time: 2.18049
Timestep Consumption Time: 2.42671
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.60721

Cumulative Model Updates: 118,036
Cumulative Timesteps: 984,357,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583.68177
Policy Entropy: 3.08926
Value Function Loss: 0.00531

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11197
Policy Update Magnitude: 0.56518
Value Function Update Magnitude: 0.61625

Collected Steps per Second: 22,930.55754
Overall Steps per Second: 10,822.93295

Timestep Collection Time: 2.18058
Timestep Consumption Time: 2.43942
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.62000

Cumulative Model Updates: 118,042
Cumulative Timesteps: 984,407,846

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 984407846...
Checkpoint 984407846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706.14304
Policy Entropy: 3.10746
Value Function Loss: 0.00528

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10727
Policy Update Magnitude: 0.56265
Value Function Update Magnitude: 0.59440

Collected Steps per Second: 22,912.90116
Overall Steps per Second: 10,767.67087

Timestep Collection Time: 2.18314
Timestep Consumption Time: 2.46244
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.64557

Cumulative Model Updates: 118,048
Cumulative Timesteps: 984,457,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 650.89322
Policy Entropy: 3.11717
Value Function Loss: 0.00526

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10618
Policy Update Magnitude: 0.54729
Value Function Update Magnitude: 0.57229

Collected Steps per Second: 23,015.80292
Overall Steps per Second: 10,853.98996

Timestep Collection Time: 2.17268
Timestep Consumption Time: 2.43447
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.60715

Cumulative Model Updates: 118,054
Cumulative Timesteps: 984,507,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 984507874...
Checkpoint 984507874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761.42465
Policy Entropy: 3.12321
Value Function Loss: 0.00503

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.54078
Value Function Update Magnitude: 0.57038

Collected Steps per Second: 22,711.45197
Overall Steps per Second: 10,673.55111

Timestep Collection Time: 2.20180
Timestep Consumption Time: 2.48324
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.68504

Cumulative Model Updates: 118,060
Cumulative Timesteps: 984,557,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 762.93115
Policy Entropy: 3.10834
Value Function Loss: 0.00508

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.10138
Policy Update Magnitude: 0.54060
Value Function Update Magnitude: 0.57313

Collected Steps per Second: 23,115.83115
Overall Steps per Second: 10,898.88726

Timestep Collection Time: 2.16311
Timestep Consumption Time: 2.42470
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.58781

Cumulative Model Updates: 118,066
Cumulative Timesteps: 984,607,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 984607882...
Checkpoint 984607882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643.01147
Policy Entropy: 3.10837
Value Function Loss: 0.00504

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.10654
Policy Update Magnitude: 0.54707
Value Function Update Magnitude: 0.57526

Collected Steps per Second: 22,620.46508
Overall Steps per Second: 10,615.24046

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.50112
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.71266

Cumulative Model Updates: 118,072
Cumulative Timesteps: 984,657,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.51960
Policy Entropy: 3.09411
Value Function Loss: 0.00500

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11830
Policy Update Magnitude: 0.55207
Value Function Update Magnitude: 0.57190

Collected Steps per Second: 22,679.63481
Overall Steps per Second: 10,956.35835

Timestep Collection Time: 2.20541
Timestep Consumption Time: 2.35979
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.56520

Cumulative Model Updates: 118,078
Cumulative Timesteps: 984,707,926

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 984707926...
Checkpoint 984707926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 656.18827
Policy Entropy: 3.08295
Value Function Loss: 0.00504

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11431
Policy Update Magnitude: 0.55758
Value Function Update Magnitude: 0.56939

Collected Steps per Second: 21,991.34375
Overall Steps per Second: 10,607.47489

Timestep Collection Time: 2.27389
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.71422

Cumulative Model Updates: 118,084
Cumulative Timesteps: 984,757,932

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 837.37443
Policy Entropy: 3.07267
Value Function Loss: 0.00522

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.55952
Value Function Update Magnitude: 0.57595

Collected Steps per Second: 22,548.82840
Overall Steps per Second: 10,857.64754

Timestep Collection Time: 2.21759
Timestep Consumption Time: 2.38783
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.60542

Cumulative Model Updates: 118,090
Cumulative Timesteps: 984,807,936

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 984807936...
Checkpoint 984807936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 527.40376
Policy Entropy: 3.07077
Value Function Loss: 0.00537

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 0.55866
Value Function Update Magnitude: 0.57812

Collected Steps per Second: 21,738.05225
Overall Steps per Second: 10,694.50834

Timestep Collection Time: 2.30057
Timestep Consumption Time: 2.37566
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.67623

Cumulative Model Updates: 118,096
Cumulative Timesteps: 984,857,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578.68622
Policy Entropy: 3.07432
Value Function Loss: 0.00534

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.55165
Value Function Update Magnitude: 0.57115

Collected Steps per Second: 22,876.31985
Overall Steps per Second: 10,695.31662

Timestep Collection Time: 2.18619
Timestep Consumption Time: 2.48987
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.67607

Cumulative Model Updates: 118,102
Cumulative Timesteps: 984,907,958

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 984907958...
Checkpoint 984907958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 661.46567
Policy Entropy: 3.07126
Value Function Loss: 0.00528

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.56293
Value Function Update Magnitude: 0.58986

Collected Steps per Second: 23,067.12620
Overall Steps per Second: 10,840.97826

Timestep Collection Time: 2.16819
Timestep Consumption Time: 2.44523
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.61342

Cumulative Model Updates: 118,108
Cumulative Timesteps: 984,957,972

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 927.42038
Policy Entropy: 3.07751
Value Function Loss: 0.00500

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.56912
Value Function Update Magnitude: 0.60715

Collected Steps per Second: 23,091.89053
Overall Steps per Second: 10,713.99177

Timestep Collection Time: 2.16526
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.66679

Cumulative Model Updates: 118,114
Cumulative Timesteps: 985,007,972

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 985007972...
Checkpoint 985007972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522.22018
Policy Entropy: 3.07379
Value Function Loss: 0.00528

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.57449
Value Function Update Magnitude: 0.60451

Collected Steps per Second: 23,100.57642
Overall Steps per Second: 10,822.02444

Timestep Collection Time: 2.16505
Timestep Consumption Time: 2.45645
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.62150

Cumulative Model Updates: 118,120
Cumulative Timesteps: 985,057,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.30034
Policy Entropy: 3.07696
Value Function Loss: 0.00520

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09729
Policy Update Magnitude: 0.57852
Value Function Update Magnitude: 0.61072

Collected Steps per Second: 22,865.85923
Overall Steps per Second: 10,681.40750

Timestep Collection Time: 2.18702
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.68178

Cumulative Model Updates: 118,126
Cumulative Timesteps: 985,107,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 985107994...
Checkpoint 985107994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 917.33597
Policy Entropy: 3.07628
Value Function Loss: 0.00529

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.60506

Collected Steps per Second: 22,932.79836
Overall Steps per Second: 10,804.43035

Timestep Collection Time: 2.18168
Timestep Consumption Time: 2.44901
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.63069

Cumulative Model Updates: 118,132
Cumulative Timesteps: 985,158,026

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.45144
Policy Entropy: 3.09787
Value Function Loss: 0.00508

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.56168
Value Function Update Magnitude: 0.59148

Collected Steps per Second: 22,830.32498
Overall Steps per Second: 10,646.30399

Timestep Collection Time: 2.19103
Timestep Consumption Time: 2.50750
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.69853

Cumulative Model Updates: 118,138
Cumulative Timesteps: 985,208,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 985208048...
Checkpoint 985208048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,185.35372
Policy Entropy: 3.10497
Value Function Loss: 0.00509

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.09562
Policy Update Magnitude: 0.54905
Value Function Update Magnitude: 0.58459

Collected Steps per Second: 22,929.39981
Overall Steps per Second: 10,654.75087

Timestep Collection Time: 2.18069
Timestep Consumption Time: 2.51224
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.69293

Cumulative Model Updates: 118,144
Cumulative Timesteps: 985,258,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 621.18782
Policy Entropy: 3.11420
Value Function Loss: 0.00518

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09251
Policy Update Magnitude: 0.54748
Value Function Update Magnitude: 0.58997

Collected Steps per Second: 22,812.46766
Overall Steps per Second: 10,767.03847

Timestep Collection Time: 2.19249
Timestep Consumption Time: 2.45280
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.64529

Cumulative Model Updates: 118,150
Cumulative Timesteps: 985,308,066

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 985308066...
Checkpoint 985308066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 833.22060
Policy Entropy: 3.11623
Value Function Loss: 0.00539

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.11009
Policy Update Magnitude: 0.56124
Value Function Update Magnitude: 0.61457

Collected Steps per Second: 22,597.77776
Overall Steps per Second: 10,663.44690

Timestep Collection Time: 2.21376
Timestep Consumption Time: 2.47760
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.69135

Cumulative Model Updates: 118,156
Cumulative Timesteps: 985,358,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,143.42917
Policy Entropy: 3.11672
Value Function Loss: 0.00533

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.10264
Policy Update Magnitude: 0.56550
Value Function Update Magnitude: 0.61331

Collected Steps per Second: 22,827.97701
Overall Steps per Second: 10,566.49531

Timestep Collection Time: 2.19082
Timestep Consumption Time: 2.54225
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.73307

Cumulative Model Updates: 118,162
Cumulative Timesteps: 985,408,104

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 985408104...
Checkpoint 985408104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 633.95538
Policy Entropy: 3.10326
Value Function Loss: 0.00528

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10579
Policy Update Magnitude: 0.56110
Value Function Update Magnitude: 0.59701

Collected Steps per Second: 22,730.12524
Overall Steps per Second: 10,628.31602

Timestep Collection Time: 2.19981
Timestep Consumption Time: 2.50479
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.70460

Cumulative Model Updates: 118,168
Cumulative Timesteps: 985,458,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.59891
Policy Entropy: 3.10078
Value Function Loss: 0.00481

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09686
Policy Update Magnitude: 0.55578
Value Function Update Magnitude: 0.58662

Collected Steps per Second: 23,273.01237
Overall Steps per Second: 10,767.85169

Timestep Collection Time: 2.14893
Timestep Consumption Time: 2.49564
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.64457

Cumulative Model Updates: 118,174
Cumulative Timesteps: 985,508,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 985508118...
Checkpoint 985508118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 735.07619
Policy Entropy: 3.10205
Value Function Loss: 0.00493

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09407
Policy Update Magnitude: 0.55039
Value Function Update Magnitude: 0.56742

Collected Steps per Second: 22,859.81661
Overall Steps per Second: 10,685.79989

Timestep Collection Time: 2.18847
Timestep Consumption Time: 2.49326
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.68173

Cumulative Model Updates: 118,180
Cumulative Timesteps: 985,558,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,168.00838
Policy Entropy: 3.10336
Value Function Loss: 0.00504

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.08886
Policy Update Magnitude: 0.55085
Value Function Update Magnitude: 0.56919

Collected Steps per Second: 23,018.23832
Overall Steps per Second: 10,850.38110

Timestep Collection Time: 2.17332
Timestep Consumption Time: 2.43721
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.61053

Cumulative Model Updates: 118,186
Cumulative Timesteps: 985,608,172

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 985608172...
Checkpoint 985608172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.35752
Policy Entropy: 3.11404
Value Function Loss: 0.00535

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.08811
Policy Update Magnitude: 0.55454
Value Function Update Magnitude: 0.56125

Collected Steps per Second: 22,566.32773
Overall Steps per Second: 10,687.67567

Timestep Collection Time: 2.21605
Timestep Consumption Time: 2.46299
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.67903

Cumulative Model Updates: 118,192
Cumulative Timesteps: 985,658,180

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.85808
Policy Entropy: 3.12009
Value Function Loss: 0.00526

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.54765
Value Function Update Magnitude: 0.57038

Collected Steps per Second: 22,537.67008
Overall Steps per Second: 10,636.93023

Timestep Collection Time: 2.21886
Timestep Consumption Time: 2.48249
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.70136

Cumulative Model Updates: 118,198
Cumulative Timesteps: 985,708,188

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 985708188...
Checkpoint 985708188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,312.91544
Policy Entropy: 3.11032
Value Function Loss: 0.00506

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10159
Policy Update Magnitude: 0.55047
Value Function Update Magnitude: 0.58566

Collected Steps per Second: 22,816.45628
Overall Steps per Second: 10,816.94426

Timestep Collection Time: 2.19175
Timestep Consumption Time: 2.43137
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.62312

Cumulative Model Updates: 118,204
Cumulative Timesteps: 985,758,196

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,439.74372
Policy Entropy: 3.09121
Value Function Loss: 0.00506

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11284
Policy Update Magnitude: 0.56245
Value Function Update Magnitude: 0.60140

Collected Steps per Second: 22,908.59169
Overall Steps per Second: 10,790.39073

Timestep Collection Time: 2.18398
Timestep Consumption Time: 2.45273
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.63672

Cumulative Model Updates: 118,210
Cumulative Timesteps: 985,808,228

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 985808228...
Checkpoint 985808228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.90338
Policy Entropy: 3.09153
Value Function Loss: 0.00497

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10097
Policy Update Magnitude: 0.56852
Value Function Update Magnitude: 0.58736

Collected Steps per Second: 22,671.27316
Overall Steps per Second: 10,738.92160

Timestep Collection Time: 2.20570
Timestep Consumption Time: 2.45082
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.65652

Cumulative Model Updates: 118,216
Cumulative Timesteps: 985,858,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 805.54630
Policy Entropy: 3.11027
Value Function Loss: 0.00522

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.56711
Value Function Update Magnitude: 0.57337

Collected Steps per Second: 23,017.09342
Overall Steps per Second: 10,775.26156

Timestep Collection Time: 2.17239
Timestep Consumption Time: 2.46806
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.64044

Cumulative Model Updates: 118,222
Cumulative Timesteps: 985,908,236

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 985908236...
Checkpoint 985908236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,434.52589
Policy Entropy: 3.12262
Value Function Loss: 0.00534

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10157
Policy Update Magnitude: 0.56815
Value Function Update Magnitude: 0.59502

Collected Steps per Second: 22,683.23495
Overall Steps per Second: 10,807.35333

Timestep Collection Time: 2.20498
Timestep Consumption Time: 2.42298
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.62796

Cumulative Model Updates: 118,228
Cumulative Timesteps: 985,958,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 843.78582
Policy Entropy: 3.11663
Value Function Loss: 0.00526

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.09491
Policy Update Magnitude: 0.56458
Value Function Update Magnitude: 0.59371

Collected Steps per Second: 23,250.46764
Overall Steps per Second: 10,910.87498

Timestep Collection Time: 2.15058
Timestep Consumption Time: 2.43219
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.58277

Cumulative Model Updates: 118,234
Cumulative Timesteps: 986,008,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 986008254...
Checkpoint 986008254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.69245
Policy Entropy: 3.09888
Value Function Loss: 0.00527

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10234
Policy Update Magnitude: 0.56386
Value Function Update Magnitude: 0.59142

Collected Steps per Second: 22,209.45823
Overall Steps per Second: 10,719.86496

Timestep Collection Time: 2.25147
Timestep Consumption Time: 2.41314
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.66461

Cumulative Model Updates: 118,240
Cumulative Timesteps: 986,058,258

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,132.70951
Policy Entropy: 3.09937
Value Function Loss: 0.00540

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.10922
Policy Update Magnitude: 0.56765
Value Function Update Magnitude: 0.58957

Collected Steps per Second: 22,934.03795
Overall Steps per Second: 10,826.36552

Timestep Collection Time: 2.18051
Timestep Consumption Time: 2.43858
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.61909

Cumulative Model Updates: 118,246
Cumulative Timesteps: 986,108,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 986108266...
Checkpoint 986108266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 419.03366
Policy Entropy: 3.09728
Value Function Loss: 0.00542

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.11028
Policy Update Magnitude: 0.56605
Value Function Update Magnitude: 0.58569

Collected Steps per Second: 22,711.45729
Overall Steps per Second: 10,729.80853

Timestep Collection Time: 2.20153
Timestep Consumption Time: 2.45838
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.65992

Cumulative Model Updates: 118,252
Cumulative Timesteps: 986,158,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,557.94068
Policy Entropy: 3.11414
Value Function Loss: 0.00514

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.55490
Value Function Update Magnitude: 0.57186

Collected Steps per Second: 22,998.18822
Overall Steps per Second: 10,918.93792

Timestep Collection Time: 2.17504
Timestep Consumption Time: 2.40617
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.58121

Cumulative Model Updates: 118,258
Cumulative Timesteps: 986,208,288

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 986208288...
Checkpoint 986208288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 921.43166
Policy Entropy: 3.12897
Value Function Loss: 0.00499

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08955
Policy Update Magnitude: 0.54163
Value Function Update Magnitude: 0.56790

Collected Steps per Second: 22,558.70504
Overall Steps per Second: 10,624.47363

Timestep Collection Time: 2.21724
Timestep Consumption Time: 2.49057
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 4.70781

Cumulative Model Updates: 118,264
Cumulative Timesteps: 986,258,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458.40086
Policy Entropy: 3.14567
Value Function Loss: 0.00486

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.08577
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.55373

Collected Steps per Second: 22,909.43401
Overall Steps per Second: 10,808.94687

Timestep Collection Time: 2.18373
Timestep Consumption Time: 2.44466
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.62839

Cumulative Model Updates: 118,270
Cumulative Timesteps: 986,308,334

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 986308334...
Checkpoint 986308334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.27806
Policy Entropy: 3.13699
Value Function Loss: 0.00501

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.53674
Value Function Update Magnitude: 0.55296

Collected Steps per Second: 23,063.14282
Overall Steps per Second: 10,686.19901

Timestep Collection Time: 2.16865
Timestep Consumption Time: 2.51177
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.68043

Cumulative Model Updates: 118,276
Cumulative Timesteps: 986,358,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,025.58588
Policy Entropy: 3.14358
Value Function Loss: 0.00518

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09212
Policy Update Magnitude: 0.53712
Value Function Update Magnitude: 0.55135

Collected Steps per Second: 23,039.51360
Overall Steps per Second: 10,877.63577

Timestep Collection Time: 2.17131
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.59898

Cumulative Model Updates: 118,282
Cumulative Timesteps: 986,408,376

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 986408376...
Checkpoint 986408376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.10861
Policy Entropy: 3.12755
Value Function Loss: 0.00497

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.09817
Policy Update Magnitude: 0.54179
Value Function Update Magnitude: 0.55402

Collected Steps per Second: 22,413.70656
Overall Steps per Second: 10,754.81419

Timestep Collection Time: 2.23122
Timestep Consumption Time: 2.41879
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.65001

Cumulative Model Updates: 118,288
Cumulative Timesteps: 986,458,386

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 897.68615
Policy Entropy: 3.12962
Value Function Loss: 0.00496

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.54286
Value Function Update Magnitude: 0.56407

Collected Steps per Second: 23,235.35727
Overall Steps per Second: 10,895.91486

Timestep Collection Time: 2.15361
Timestep Consumption Time: 2.43893
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.59255

Cumulative Model Updates: 118,294
Cumulative Timesteps: 986,508,426

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 986508426...
Checkpoint 986508426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 777.90133
Policy Entropy: 3.12180
Value Function Loss: 0.00507

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09401
Policy Update Magnitude: 0.54647
Value Function Update Magnitude: 0.55745

Collected Steps per Second: 22,638.89081
Overall Steps per Second: 10,570.86832

Timestep Collection Time: 2.20885
Timestep Consumption Time: 2.52169
PPO Batch Consumption Time: 0.29530
Total Iteration Time: 4.73055

Cumulative Model Updates: 118,300
Cumulative Timesteps: 986,558,432

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.18434
Policy Entropy: 3.12061
Value Function Loss: 0.00526

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.09451
Policy Update Magnitude: 0.55368
Value Function Update Magnitude: 0.55732

Collected Steps per Second: 23,148.50071
Overall Steps per Second: 10,901.87104

Timestep Collection Time: 2.16014
Timestep Consumption Time: 2.42660
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.58674

Cumulative Model Updates: 118,306
Cumulative Timesteps: 986,608,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 986608436...
Checkpoint 986608436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 407.49910
Policy Entropy: 3.11996
Value Function Loss: 0.00524

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09774
Policy Update Magnitude: 0.55314
Value Function Update Magnitude: 0.55351

Collected Steps per Second: 22,605.28483
Overall Steps per Second: 10,709.35704

Timestep Collection Time: 2.21311
Timestep Consumption Time: 2.45832
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.67143

Cumulative Model Updates: 118,312
Cumulative Timesteps: 986,658,464

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,910.63971
Policy Entropy: 3.11088
Value Function Loss: 0.00516

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09330
Policy Update Magnitude: 0.55066
Value Function Update Magnitude: 0.55252

Collected Steps per Second: 23,127.16887
Overall Steps per Second: 10,848.02432

Timestep Collection Time: 2.16274
Timestep Consumption Time: 2.44806
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.61079

Cumulative Model Updates: 118,318
Cumulative Timesteps: 986,708,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 986708482...
Checkpoint 986708482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 907.24473
Policy Entropy: 3.11122
Value Function Loss: 0.00521

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.09982
Policy Update Magnitude: 0.55036
Value Function Update Magnitude: 0.58006

Collected Steps per Second: 22,782.19495
Overall Steps per Second: 10,717.56410

Timestep Collection Time: 2.19575
Timestep Consumption Time: 2.47173
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.66748

Cumulative Model Updates: 118,324
Cumulative Timesteps: 986,758,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,154.22359
Policy Entropy: 3.10808
Value Function Loss: 0.00517

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10672
Policy Update Magnitude: 0.55131
Value Function Update Magnitude: 0.57330

Collected Steps per Second: 22,685.32489
Overall Steps per Second: 10,788.64266

Timestep Collection Time: 2.20539
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.63728

Cumulative Model Updates: 118,330
Cumulative Timesteps: 986,808,536

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 986808536...
Checkpoint 986808536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,430.91552
Policy Entropy: 3.10517
Value Function Loss: 0.00536

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10509
Policy Update Magnitude: 0.55408
Value Function Update Magnitude: 0.57143

Collected Steps per Second: 22,613.75971
Overall Steps per Second: 10,744.42695

Timestep Collection Time: 2.21122
Timestep Consumption Time: 2.44273
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.65395

Cumulative Model Updates: 118,336
Cumulative Timesteps: 986,858,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.80757
Policy Entropy: 3.09092
Value Function Loss: 0.00532

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.55868
Value Function Update Magnitude: 0.58393

Collected Steps per Second: 23,226.75839
Overall Steps per Second: 10,924.03263

Timestep Collection Time: 2.15329
Timestep Consumption Time: 2.42505
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.57835

Cumulative Model Updates: 118,342
Cumulative Timesteps: 986,908,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 986908554...
Checkpoint 986908554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960.60700
Policy Entropy: 3.08352
Value Function Loss: 0.00556

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.10586
Policy Update Magnitude: 0.57180
Value Function Update Magnitude: 0.60233

Collected Steps per Second: 22,575.22899
Overall Steps per Second: 10,610.60380

Timestep Collection Time: 2.21553
Timestep Consumption Time: 2.49825
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.71378

Cumulative Model Updates: 118,348
Cumulative Timesteps: 986,958,570

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431.59197
Policy Entropy: 3.10206
Value Function Loss: 0.00520

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.58634
Value Function Update Magnitude: 0.61396

Collected Steps per Second: 23,168.66162
Overall Steps per Second: 10,905.60994

Timestep Collection Time: 2.15904
Timestep Consumption Time: 2.42778
PPO Batch Consumption Time: 0.28190
Total Iteration Time: 4.58681

Cumulative Model Updates: 118,354
Cumulative Timesteps: 987,008,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 987008592...
Checkpoint 987008592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,896.20313
Policy Entropy: 3.10339
Value Function Loss: 0.00522

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10852
Policy Update Magnitude: 0.56315
Value Function Update Magnitude: 0.59337

Collected Steps per Second: 22,622.02418
Overall Steps per Second: 10,638.50780

Timestep Collection Time: 2.21156
Timestep Consumption Time: 2.49117
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.70273

Cumulative Model Updates: 118,360
Cumulative Timesteps: 987,058,622

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,250.51193
Policy Entropy: 3.11560
Value Function Loss: 0.00518

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.54903
Value Function Update Magnitude: 0.56437

Collected Steps per Second: 22,750.20829
Overall Steps per Second: 10,703.27368

Timestep Collection Time: 2.19875
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.67352

Cumulative Model Updates: 118,366
Cumulative Timesteps: 987,108,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 987108644...
Checkpoint 987108644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,140.55661
Policy Entropy: 3.10656
Value Function Loss: 0.00529

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.54825
Value Function Update Magnitude: 0.56196

Collected Steps per Second: 22,373.05139
Overall Steps per Second: 10,729.43990

Timestep Collection Time: 2.23483
Timestep Consumption Time: 2.42524
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.66008

Cumulative Model Updates: 118,372
Cumulative Timesteps: 987,158,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 703.71723
Policy Entropy: 3.10266
Value Function Loss: 0.00527

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.56491

Collected Steps per Second: 23,176.27621
Overall Steps per Second: 10,808.20749

Timestep Collection Time: 2.15738
Timestep Consumption Time: 2.46874
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.62611

Cumulative Model Updates: 118,378
Cumulative Timesteps: 987,208,644

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 987208644...
Checkpoint 987208644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 474.32975
Policy Entropy: 3.10927
Value Function Loss: 0.00513

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.11628
Policy Update Magnitude: 0.54761
Value Function Update Magnitude: 0.56835

Collected Steps per Second: 22,558.96599
Overall Steps per Second: 10,776.83566

Timestep Collection Time: 2.21650
Timestep Consumption Time: 2.42326
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.63977

Cumulative Model Updates: 118,384
Cumulative Timesteps: 987,258,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,128.76571
Policy Entropy: 3.11933
Value Function Loss: 0.00509

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.10556
Policy Update Magnitude: 0.53209
Value Function Update Magnitude: 0.56474

Collected Steps per Second: 22,933.24891
Overall Steps per Second: 10,738.58375

Timestep Collection Time: 2.18129
Timestep Consumption Time: 2.47706
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.65834

Cumulative Model Updates: 118,390
Cumulative Timesteps: 987,308,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 987308670...
Checkpoint 987308670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 746.61931
Policy Entropy: 3.13630
Value Function Loss: 0.00526

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.54925
Value Function Update Magnitude: 0.56308

Collected Steps per Second: 22,894.25037
Overall Steps per Second: 10,932.77356

Timestep Collection Time: 2.18448
Timestep Consumption Time: 2.39002
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.57450

Cumulative Model Updates: 118,396
Cumulative Timesteps: 987,358,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 655.68130
Policy Entropy: 3.12985
Value Function Loss: 0.00527

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.55712
Value Function Update Magnitude: 0.56672

Collected Steps per Second: 22,410.04073
Overall Steps per Second: 10,865.82587

Timestep Collection Time: 2.23123
Timestep Consumption Time: 2.37054
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.60177

Cumulative Model Updates: 118,402
Cumulative Timesteps: 987,408,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 987408684...
Checkpoint 987408684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.78215
Policy Entropy: 3.13922
Value Function Loss: 0.00518

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11020
Policy Update Magnitude: 0.54209
Value Function Update Magnitude: 0.57252

Collected Steps per Second: 21,807.63981
Overall Steps per Second: 10,663.13500

Timestep Collection Time: 2.29378
Timestep Consumption Time: 2.39733
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.69112

Cumulative Model Updates: 118,408
Cumulative Timesteps: 987,458,706

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 999.83845
Policy Entropy: 3.12376
Value Function Loss: 0.00513

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.09953
Policy Update Magnitude: 0.54023
Value Function Update Magnitude: 0.58176

Collected Steps per Second: 22,247.88537
Overall Steps per Second: 10,818.08214

Timestep Collection Time: 2.24749
Timestep Consumption Time: 2.37458
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.62208

Cumulative Model Updates: 118,414
Cumulative Timesteps: 987,508,708

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 987508708...
Checkpoint 987508708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 972.91329
Policy Entropy: 3.11480
Value Function Loss: 0.00514

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.09345
Policy Update Magnitude: 0.55360
Value Function Update Magnitude: 0.59860

Collected Steps per Second: 21,960.20753
Overall Steps per Second: 10,699.45918

Timestep Collection Time: 2.27794
Timestep Consumption Time: 2.39744
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.67538

Cumulative Model Updates: 118,420
Cumulative Timesteps: 987,558,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 777.51030
Policy Entropy: 3.09540
Value Function Loss: 0.00518

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.56876
Value Function Update Magnitude: 0.62184

Collected Steps per Second: 21,520.78400
Overall Steps per Second: 10,487.50103

Timestep Collection Time: 2.32380
Timestep Consumption Time: 2.44473
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.76853

Cumulative Model Updates: 118,426
Cumulative Timesteps: 987,608,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 987608742...
Checkpoint 987608742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,220.58349
Policy Entropy: 3.10247
Value Function Loss: 0.00554

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.57333
Value Function Update Magnitude: 0.65506

Collected Steps per Second: 22,733.44490
Overall Steps per Second: 10,633.72090

Timestep Collection Time: 2.19975
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.70278

Cumulative Model Updates: 118,432
Cumulative Timesteps: 987,658,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,039.63662
Policy Entropy: 3.11424
Value Function Loss: 0.00572

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.58000
Value Function Update Magnitude: 0.67031

Collected Steps per Second: 22,788.80730
Overall Steps per Second: 10,701.56092

Timestep Collection Time: 2.19415
Timestep Consumption Time: 2.47826
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.67240

Cumulative Model Updates: 118,438
Cumulative Timesteps: 987,708,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 987708752...
Checkpoint 987708752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 550.10111
Policy Entropy: 3.11170
Value Function Loss: 0.00558

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.57648
Value Function Update Magnitude: 0.65846

Collected Steps per Second: 22,704.93045
Overall Steps per Second: 10,751.89985

Timestep Collection Time: 2.20322
Timestep Consumption Time: 2.44935
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.65257

Cumulative Model Updates: 118,444
Cumulative Timesteps: 987,758,776

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,035.60627
Policy Entropy: 3.11930
Value Function Loss: 0.00548

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.12513
Policy Update Magnitude: 0.57239
Value Function Update Magnitude: 0.62506

Collected Steps per Second: 23,223.59809
Overall Steps per Second: 10,889.68144

Timestep Collection Time: 2.15393
Timestep Consumption Time: 2.43959
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.59352

Cumulative Model Updates: 118,450
Cumulative Timesteps: 987,808,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 987808798...
Checkpoint 987808798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 623.58993
Policy Entropy: 3.11039
Value Function Loss: 0.00540

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.12026
Policy Update Magnitude: 0.56825
Value Function Update Magnitude: 0.60245

Collected Steps per Second: 22,487.43441
Overall Steps per Second: 10,684.26223

Timestep Collection Time: 2.22355
Timestep Consumption Time: 2.45641
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.67997

Cumulative Model Updates: 118,456
Cumulative Timesteps: 987,858,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567.62093
Policy Entropy: 3.11405
Value Function Loss: 0.00537

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.56929
Value Function Update Magnitude: 0.59011

Collected Steps per Second: 23,018.23501
Overall Steps per Second: 10,657.17544

Timestep Collection Time: 2.17341
Timestep Consumption Time: 2.52089
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69430

Cumulative Model Updates: 118,462
Cumulative Timesteps: 987,908,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 987908828...
Checkpoint 987908828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.41281
Policy Entropy: 3.10194
Value Function Loss: 0.00538

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.10749
Policy Update Magnitude: 0.57377
Value Function Update Magnitude: 0.58157

Collected Steps per Second: 22,682.53332
Overall Steps per Second: 10,623.88682

Timestep Collection Time: 2.20540
Timestep Consumption Time: 2.50324
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.70863

Cumulative Model Updates: 118,468
Cumulative Timesteps: 987,958,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659.50818
Policy Entropy: 3.09582
Value Function Loss: 0.00551

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.57572
Value Function Update Magnitude: 0.57859

Collected Steps per Second: 23,176.29764
Overall Steps per Second: 10,808.98656

Timestep Collection Time: 2.15746
Timestep Consumption Time: 2.46850
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.62597

Cumulative Model Updates: 118,474
Cumulative Timesteps: 988,008,854

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 988008854...
Checkpoint 988008854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 667.65515
Policy Entropy: 3.08396
Value Function Loss: 0.00596

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09677
Policy Update Magnitude: 0.58764
Value Function Update Magnitude: 0.59371

Collected Steps per Second: 22,582.23200
Overall Steps per Second: 10,634.54364

Timestep Collection Time: 2.21519
Timestep Consumption Time: 2.48872
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.70392

Cumulative Model Updates: 118,480
Cumulative Timesteps: 988,058,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.44507
Policy Entropy: 3.08596
Value Function Loss: 0.00560

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.57615
Value Function Update Magnitude: 0.61656

Collected Steps per Second: 22,723.27757
Overall Steps per Second: 10,631.14434

Timestep Collection Time: 2.20153
Timestep Consumption Time: 2.50408
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.70561

Cumulative Model Updates: 118,486
Cumulative Timesteps: 988,108,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 988108904...
Checkpoint 988108904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 710.20023
Policy Entropy: 3.08462
Value Function Loss: 0.00538

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10680
Policy Update Magnitude: 0.57176
Value Function Update Magnitude: 0.62303

Collected Steps per Second: 23,143.30081
Overall Steps per Second: 10,859.29179

Timestep Collection Time: 2.16088
Timestep Consumption Time: 2.44439
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.60527

Cumulative Model Updates: 118,492
Cumulative Timesteps: 988,158,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,050.33920
Policy Entropy: 3.09217
Value Function Loss: 0.00539

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.09156
Policy Update Magnitude: 0.57714
Value Function Update Magnitude: 0.61477

Collected Steps per Second: 23,120.00382
Overall Steps per Second: 10,767.46066

Timestep Collection Time: 2.16263
Timestep Consumption Time: 2.48099
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.64362

Cumulative Model Updates: 118,498
Cumulative Timesteps: 988,208,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988208914...
Checkpoint 988208914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 691.19813
Policy Entropy: 3.08920
Value Function Loss: 0.00538

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.08832
Policy Update Magnitude: 0.58288
Value Function Update Magnitude: 0.63091

Collected Steps per Second: 22,502.31139
Overall Steps per Second: 10,597.35910

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.71872

Cumulative Model Updates: 118,504
Cumulative Timesteps: 988,258,920

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576.27145
Policy Entropy: 3.09780
Value Function Loss: 0.00547

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.57280
Value Function Update Magnitude: 0.63063

Collected Steps per Second: 23,015.36441
Overall Steps per Second: 10,727.53291

Timestep Collection Time: 2.17246
Timestep Consumption Time: 2.48844
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.66090

Cumulative Model Updates: 118,510
Cumulative Timesteps: 988,308,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988308920...
Checkpoint 988308920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 994.10877
Policy Entropy: 3.10232
Value Function Loss: 0.00519

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09294
Policy Update Magnitude: 0.56400
Value Function Update Magnitude: 0.61286

Collected Steps per Second: 22,739.17391
Overall Steps per Second: 10,633.58237

Timestep Collection Time: 2.19955
Timestep Consumption Time: 2.50404
PPO Batch Consumption Time: 0.29723
Total Iteration Time: 4.70359

Cumulative Model Updates: 118,516
Cumulative Timesteps: 988,358,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 884.56922
Policy Entropy: 3.09280
Value Function Loss: 0.00523

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09733
Policy Update Magnitude: 0.55730
Value Function Update Magnitude: 0.59429

Collected Steps per Second: 23,096.45572
Overall Steps per Second: 10,851.51565

Timestep Collection Time: 2.16509
Timestep Consumption Time: 2.44311
PPO Batch Consumption Time: 0.28618
Total Iteration Time: 4.60820

Cumulative Model Updates: 118,522
Cumulative Timesteps: 988,408,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 988408942...
Checkpoint 988408942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,275.59254
Policy Entropy: 3.10280
Value Function Loss: 0.00504

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.08708
Policy Update Magnitude: 0.55829
Value Function Update Magnitude: 0.58072

Collected Steps per Second: 22,202.93626
Overall Steps per Second: 10,701.50804

Timestep Collection Time: 2.25195
Timestep Consumption Time: 2.42028
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.67224

Cumulative Model Updates: 118,528
Cumulative Timesteps: 988,458,942

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,827.20956
Policy Entropy: 3.09314
Value Function Loss: 0.00530

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.56302
Value Function Update Magnitude: 0.57948

Collected Steps per Second: 23,125.06200
Overall Steps per Second: 10,855.80548

Timestep Collection Time: 2.16319
Timestep Consumption Time: 2.44485
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.60804

Cumulative Model Updates: 118,534
Cumulative Timesteps: 988,508,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 988508966...
Checkpoint 988508966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.70844
Policy Entropy: 3.08512
Value Function Loss: 0.00544

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09441
Policy Update Magnitude: 0.56607
Value Function Update Magnitude: 0.59822

Collected Steps per Second: 22,540.84943
Overall Steps per Second: 10,685.49364

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.46203
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.68111

Cumulative Model Updates: 118,540
Cumulative Timesteps: 988,558,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.24626
Policy Entropy: 3.07544
Value Function Loss: 0.00549

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10491
Policy Update Magnitude: 0.57114
Value Function Update Magnitude: 0.61500

Collected Steps per Second: 22,918.23056
Overall Steps per Second: 10,815.23593

Timestep Collection Time: 2.18219
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.62422

Cumulative Model Updates: 118,546
Cumulative Timesteps: 988,608,998

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 988608998...
Checkpoint 988608998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.13912
Policy Entropy: 3.08857
Value Function Loss: 0.00541

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.57080
Value Function Update Magnitude: 0.61420

Collected Steps per Second: 22,688.65352
Overall Steps per Second: 10,734.59849

Timestep Collection Time: 2.20463
Timestep Consumption Time: 2.45507
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.65970

Cumulative Model Updates: 118,552
Cumulative Timesteps: 988,659,018

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,086.40813
Policy Entropy: 3.08787
Value Function Loss: 0.00529

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.56945
Value Function Update Magnitude: 0.61109

Collected Steps per Second: 22,981.09893
Overall Steps per Second: 10,823.22069

Timestep Collection Time: 2.17631
Timestep Consumption Time: 2.44468
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.62099

Cumulative Model Updates: 118,558
Cumulative Timesteps: 988,709,032

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 988709032...
Checkpoint 988709032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.40403
Policy Entropy: 3.09010
Value Function Loss: 0.00516

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09913
Policy Update Magnitude: 0.56872
Value Function Update Magnitude: 0.61843

Collected Steps per Second: 22,905.95837
Overall Steps per Second: 10,693.16108

Timestep Collection Time: 2.18310
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.67645

Cumulative Model Updates: 118,564
Cumulative Timesteps: 988,759,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 957.55100
Policy Entropy: 3.07711
Value Function Loss: 0.00547

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.57383
Value Function Update Magnitude: 0.63341

Collected Steps per Second: 23,230.01675
Overall Steps per Second: 10,946.06369

Timestep Collection Time: 2.15239
Timestep Consumption Time: 2.41546
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.56785

Cumulative Model Updates: 118,570
Cumulative Timesteps: 988,809,038

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 988809038...
Checkpoint 988809038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.00916
Policy Entropy: 3.07755
Value Function Loss: 0.00546

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10601
Policy Update Magnitude: 0.58020
Value Function Update Magnitude: 0.64288

Collected Steps per Second: 22,783.19499
Overall Steps per Second: 10,674.16164

Timestep Collection Time: 2.19521
Timestep Consumption Time: 2.49031
PPO Batch Consumption Time: 0.29626
Total Iteration Time: 4.68552

Cumulative Model Updates: 118,576
Cumulative Timesteps: 988,859,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,104.94592
Policy Entropy: 3.08166
Value Function Loss: 0.00519

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.57715
Value Function Update Magnitude: 0.62980

Collected Steps per Second: 22,757.94488
Overall Steps per Second: 10,804.48958

Timestep Collection Time: 2.19721
Timestep Consumption Time: 2.43087
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.62808

Cumulative Model Updates: 118,582
Cumulative Timesteps: 988,909,056

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 988909056...
Checkpoint 988909056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 944.18787
Policy Entropy: 3.09381
Value Function Loss: 0.00520

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.56730
Value Function Update Magnitude: 0.60640

Collected Steps per Second: 22,435.11943
Overall Steps per Second: 10,670.65026

Timestep Collection Time: 2.22999
Timestep Consumption Time: 2.45858
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.68856

Cumulative Model Updates: 118,588
Cumulative Timesteps: 988,959,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.10681
Policy Entropy: 3.09382
Value Function Loss: 0.00513

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.09701
Policy Update Magnitude: 0.55465
Value Function Update Magnitude: 0.59415

Collected Steps per Second: 23,064.46239
Overall Steps per Second: 10,845.56409

Timestep Collection Time: 2.16836
Timestep Consumption Time: 2.44293
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.61129

Cumulative Model Updates: 118,594
Cumulative Timesteps: 989,009,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 989009098...
Checkpoint 989009098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.02004
Policy Entropy: 3.08719
Value Function Loss: 0.00534

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09467
Policy Update Magnitude: 0.55696
Value Function Update Magnitude: 0.58934

Collected Steps per Second: 22,454.16823
Overall Steps per Second: 10,773.18005

Timestep Collection Time: 2.22783
Timestep Consumption Time: 2.41556
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.64338

Cumulative Model Updates: 118,600
Cumulative Timesteps: 989,059,122

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,056.31738
Policy Entropy: 3.07527
Value Function Loss: 0.00538

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09768
Policy Update Magnitude: 0.57013
Value Function Update Magnitude: 0.59265

Collected Steps per Second: 23,084.21974
Overall Steps per Second: 10,891.82607

Timestep Collection Time: 2.16685
Timestep Consumption Time: 2.42559
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.59243

Cumulative Model Updates: 118,606
Cumulative Timesteps: 989,109,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 989109142...
Checkpoint 989109142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,211.28722
Policy Entropy: 3.07041
Value Function Loss: 0.00528

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09812
Policy Update Magnitude: 0.56949
Value Function Update Magnitude: 0.59141

Collected Steps per Second: 22,597.89134
Overall Steps per Second: 10,614.61033

Timestep Collection Time: 2.21437
Timestep Consumption Time: 2.49989
PPO Batch Consumption Time: 0.29542
Total Iteration Time: 4.71426

Cumulative Model Updates: 118,612
Cumulative Timesteps: 989,159,182

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 933.70736
Policy Entropy: 3.06872
Value Function Loss: 0.00526

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.10271
Policy Update Magnitude: 0.56064
Value Function Update Magnitude: 0.57510

Collected Steps per Second: 23,062.26577
Overall Steps per Second: 10,876.93387

Timestep Collection Time: 2.16804
Timestep Consumption Time: 2.42884
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.59688

Cumulative Model Updates: 118,618
Cumulative Timesteps: 989,209,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 989209182...
Checkpoint 989209182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.82037
Policy Entropy: 3.07583
Value Function Loss: 0.00494

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.10769
Policy Update Magnitude: 0.55574
Value Function Update Magnitude: 0.56672

Collected Steps per Second: 22,453.42396
Overall Steps per Second: 10,667.41781

Timestep Collection Time: 2.22772
Timestep Consumption Time: 2.46132
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.68904

Cumulative Model Updates: 118,624
Cumulative Timesteps: 989,259,202

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019.39930
Policy Entropy: 3.08039
Value Function Loss: 0.00518

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.56612
Value Function Update Magnitude: 0.57326

Collected Steps per Second: 23,040.09655
Overall Steps per Second: 10,904.93610

Timestep Collection Time: 2.17022
Timestep Consumption Time: 2.41505
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.58526

Cumulative Model Updates: 118,630
Cumulative Timesteps: 989,309,204

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 989309204...
Checkpoint 989309204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,384.59159
Policy Entropy: 3.08529
Value Function Loss: 0.00504

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.10212
Policy Update Magnitude: 0.56540
Value Function Update Magnitude: 0.56487

Collected Steps per Second: 22,886.10104
Overall Steps per Second: 10,711.41464

Timestep Collection Time: 2.18569
Timestep Consumption Time: 2.48428
PPO Batch Consumption Time: 0.29658
Total Iteration Time: 4.66997

Cumulative Model Updates: 118,636
Cumulative Timesteps: 989,359,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372.68657
Policy Entropy: 3.08405
Value Function Loss: 0.00505

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.10293
Policy Update Magnitude: 0.55757
Value Function Update Magnitude: 0.56404

Collected Steps per Second: 23,274.59258
Overall Steps per Second: 10,851.50698

Timestep Collection Time: 2.14878
Timestep Consumption Time: 2.45998
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.60876

Cumulative Model Updates: 118,642
Cumulative Timesteps: 989,409,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 989409238...
Checkpoint 989409238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.20338
Policy Entropy: 3.05958
Value Function Loss: 0.00525

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10308
Policy Update Magnitude: 0.56368
Value Function Update Magnitude: 0.56290

Collected Steps per Second: 22,699.30152
Overall Steps per Second: 10,626.63105

Timestep Collection Time: 2.20324
Timestep Consumption Time: 2.50305
PPO Batch Consumption Time: 0.29667
Total Iteration Time: 4.70629

Cumulative Model Updates: 118,648
Cumulative Timesteps: 989,459,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 781.34677
Policy Entropy: 3.06023
Value Function Loss: 0.00558

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10975
Policy Update Magnitude: 0.57394
Value Function Update Magnitude: 0.57828

Collected Steps per Second: 23,029.16106
Overall Steps per Second: 10,874.04312

Timestep Collection Time: 2.17212
Timestep Consumption Time: 2.42801
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.60013

Cumulative Model Updates: 118,654
Cumulative Timesteps: 989,509,272

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 989509272...
Checkpoint 989509272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,293.73665
Policy Entropy: 3.06191
Value Function Loss: 0.00554

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.11460
Policy Update Magnitude: 0.57243
Value Function Update Magnitude: 0.60655

Collected Steps per Second: 22,601.64925
Overall Steps per Second: 10,655.85344

Timestep Collection Time: 2.21338
Timestep Consumption Time: 2.48132
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.69470

Cumulative Model Updates: 118,660
Cumulative Timesteps: 989,559,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.72418
Policy Entropy: 3.06265
Value Function Loss: 0.00541

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.11977
Policy Update Magnitude: 0.57606
Value Function Update Magnitude: 0.61183

Collected Steps per Second: 23,197.67810
Overall Steps per Second: 10,954.50432

Timestep Collection Time: 2.15634
Timestep Consumption Time: 2.41000
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.56634

Cumulative Model Updates: 118,666
Cumulative Timesteps: 989,609,320

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 989609320...
Checkpoint 989609320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.81840
Policy Entropy: 3.07460
Value Function Loss: 0.00524

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.11279
Policy Update Magnitude: 0.57703
Value Function Update Magnitude: 0.60617

Collected Steps per Second: 21,798.51945
Overall Steps per Second: 10,618.84270

Timestep Collection Time: 2.29529
Timestep Consumption Time: 2.41652
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.71181

Cumulative Model Updates: 118,672
Cumulative Timesteps: 989,659,354

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702.42618
Policy Entropy: 3.08329
Value Function Loss: 0.00528

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.10123
Policy Update Magnitude: 0.56950
Value Function Update Magnitude: 0.58428

Collected Steps per Second: 22,548.59338
Overall Steps per Second: 10,866.95245

Timestep Collection Time: 2.21805
Timestep Consumption Time: 2.38434
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.60239

Cumulative Model Updates: 118,678
Cumulative Timesteps: 989,709,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 989709368...
Checkpoint 989709368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,110.66278
Policy Entropy: 3.08362
Value Function Loss: 0.00505

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.09802
Policy Update Magnitude: 0.55975
Value Function Update Magnitude: 0.56726

Collected Steps per Second: 21,726.60309
Overall Steps per Second: 10,696.09611

Timestep Collection Time: 2.30261
Timestep Consumption Time: 2.37461
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.67722

Cumulative Model Updates: 118,684
Cumulative Timesteps: 989,759,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,231.50389
Policy Entropy: 3.07938
Value Function Loss: 0.00519

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.55847
Value Function Update Magnitude: 0.56063

Collected Steps per Second: 22,428.43139
Overall Steps per Second: 10,850.63620

Timestep Collection Time: 2.22958
Timestep Consumption Time: 2.37900
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.60858

Cumulative Model Updates: 118,690
Cumulative Timesteps: 989,809,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 989809402...
Checkpoint 989809402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,416.62244
Policy Entropy: 3.06759
Value Function Loss: 0.00516

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09779
Policy Update Magnitude: 0.56068
Value Function Update Magnitude: 0.57237

Collected Steps per Second: 21,509.73761
Overall Steps per Second: 10,655.94318

Timestep Collection Time: 2.32546
Timestep Consumption Time: 2.36864
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.69409

Cumulative Model Updates: 118,696
Cumulative Timesteps: 989,859,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.12414
Policy Entropy: 3.06588
Value Function Loss: 0.00511

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.10133
Policy Update Magnitude: 0.55829
Value Function Update Magnitude: 0.58413

Collected Steps per Second: 22,080.00458
Overall Steps per Second: 10,637.24085

Timestep Collection Time: 2.26576
Timestep Consumption Time: 2.43734
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.70310

Cumulative Model Updates: 118,702
Cumulative Timesteps: 989,909,450

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 989909450...
Checkpoint 989909450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717.22631
Policy Entropy: 3.07158
Value Function Loss: 0.00515

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.09765
Policy Update Magnitude: 0.56035
Value Function Update Magnitude: 0.59161

Collected Steps per Second: 22,188.37063
Overall Steps per Second: 10,562.09038

Timestep Collection Time: 2.25487
Timestep Consumption Time: 2.48207
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.73694

Cumulative Model Updates: 118,708
Cumulative Timesteps: 989,959,482

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 827.44647
Policy Entropy: 3.06111
Value Function Loss: 0.00523

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.56373
Value Function Update Magnitude: 0.60483

Collected Steps per Second: 21,948.72687
Overall Steps per Second: 10,399.56141

Timestep Collection Time: 2.27822
Timestep Consumption Time: 2.53006
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.80828

Cumulative Model Updates: 118,714
Cumulative Timesteps: 990,009,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 990009486...
Checkpoint 990009486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 933.58331
Policy Entropy: 3.06670
Value Function Loss: 0.00519

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10526
Policy Update Magnitude: 0.57109
Value Function Update Magnitude: 0.58745

Collected Steps per Second: 22,818.22925
Overall Steps per Second: 10,610.77786

Timestep Collection Time: 2.19176
Timestep Consumption Time: 2.52156
PPO Batch Consumption Time: 0.29476
Total Iteration Time: 4.71332

Cumulative Model Updates: 118,720
Cumulative Timesteps: 990,059,498

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.68209
Policy Entropy: 3.05835
Value Function Loss: 0.00538

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10923
Policy Update Magnitude: 0.57478
Value Function Update Magnitude: 0.60117

Collected Steps per Second: 22,943.16650
Overall Steps per Second: 10,715.58558

Timestep Collection Time: 2.18034
Timestep Consumption Time: 2.48800
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.66834

Cumulative Model Updates: 118,726
Cumulative Timesteps: 990,109,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 990109522...
Checkpoint 990109522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.25283
Policy Entropy: 3.06965
Value Function Loss: 0.00534

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.11905
Policy Update Magnitude: 0.56991
Value Function Update Magnitude: 0.61148

Collected Steps per Second: 22,466.45384
Overall Steps per Second: 10,596.57856

Timestep Collection Time: 2.22607
Timestep Consumption Time: 2.49356
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.71964

Cumulative Model Updates: 118,732
Cumulative Timesteps: 990,159,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.67997
Policy Entropy: 3.08278
Value Function Loss: 0.00539

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.57156
Value Function Update Magnitude: 0.62040

Collected Steps per Second: 23,237.64180
Overall Steps per Second: 10,714.93310

Timestep Collection Time: 2.15228
Timestep Consumption Time: 2.51541
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.66769

Cumulative Model Updates: 118,738
Cumulative Timesteps: 990,209,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 990209548...
Checkpoint 990209548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 928.26295
Policy Entropy: 3.07860
Value Function Loss: 0.00515

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.11189
Policy Update Magnitude: 0.56748
Value Function Update Magnitude: 0.62862

Collected Steps per Second: 22,607.73638
Overall Steps per Second: 10,632.14005

Timestep Collection Time: 2.21163
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.70272

Cumulative Model Updates: 118,744
Cumulative Timesteps: 990,259,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,382.45670
Policy Entropy: 3.08136
Value Function Loss: 0.00513

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.56001
Value Function Update Magnitude: 0.62679

Collected Steps per Second: 22,774.16085
Overall Steps per Second: 10,613.29389

Timestep Collection Time: 2.19652
Timestep Consumption Time: 2.51681
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.71333

Cumulative Model Updates: 118,750
Cumulative Timesteps: 990,309,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 990309572...
Checkpoint 990309572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.78378
Policy Entropy: 3.07592
Value Function Loss: 0.00503

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.56181
Value Function Update Magnitude: 0.61813

Collected Steps per Second: 23,043.82763
Overall Steps per Second: 10,798.48479

Timestep Collection Time: 2.17099
Timestep Consumption Time: 2.46188
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.63287

Cumulative Model Updates: 118,756
Cumulative Timesteps: 990,359,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.20534
Policy Entropy: 3.09527
Value Function Loss: 0.00519

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.11656
Policy Update Magnitude: 0.56795
Value Function Update Magnitude: 0.60923

Collected Steps per Second: 23,349.52683
Overall Steps per Second: 10,741.86017

Timestep Collection Time: 2.14197
Timestep Consumption Time: 2.51402
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.65599

Cumulative Model Updates: 118,762
Cumulative Timesteps: 990,409,614

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 990409614...
Checkpoint 990409614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,651.29800
Policy Entropy: 3.09181
Value Function Loss: 0.00500

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.56909
Value Function Update Magnitude: 0.59781

Collected Steps per Second: 22,718.56435
Overall Steps per Second: 10,643.84678

Timestep Collection Time: 2.20216
Timestep Consumption Time: 2.49820
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.70037

Cumulative Model Updates: 118,768
Cumulative Timesteps: 990,459,644

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.50149
Policy Entropy: 3.08693
Value Function Loss: 0.00518

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.10050
Policy Update Magnitude: 0.55975
Value Function Update Magnitude: 0.58050

Collected Steps per Second: 22,773.81496
Overall Steps per Second: 10,770.37215

Timestep Collection Time: 2.19586
Timestep Consumption Time: 2.44725
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.64311

Cumulative Model Updates: 118,774
Cumulative Timesteps: 990,509,652

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 990509652...
Checkpoint 990509652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883.36796
Policy Entropy: 3.07921
Value Function Loss: 0.00500

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11053
Policy Update Magnitude: 0.55494
Value Function Update Magnitude: 0.56987

Collected Steps per Second: 22,722.09994
Overall Steps per Second: 10,565.59589

Timestep Collection Time: 2.20121
Timestep Consumption Time: 2.53265
PPO Batch Consumption Time: 0.29540
Total Iteration Time: 4.73386

Cumulative Model Updates: 118,780
Cumulative Timesteps: 990,559,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 742.14528
Policy Entropy: 3.07620
Value Function Loss: 0.00542

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.11571
Policy Update Magnitude: 0.56029
Value Function Update Magnitude: 0.58181

Collected Steps per Second: 22,955.20893
Overall Steps per Second: 10,674.28793

Timestep Collection Time: 2.17894
Timestep Consumption Time: 2.50690
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.68584

Cumulative Model Updates: 118,786
Cumulative Timesteps: 990,609,686

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 990609686...
Checkpoint 990609686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 813.84608
Policy Entropy: 3.07876
Value Function Loss: 0.00547

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.11331
Policy Update Magnitude: 0.56506
Value Function Update Magnitude: 0.59630

Collected Steps per Second: 22,828.72735
Overall Steps per Second: 10,684.16237

Timestep Collection Time: 2.19084
Timestep Consumption Time: 2.49030
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.68113

Cumulative Model Updates: 118,792
Cumulative Timesteps: 990,659,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 534.66993
Policy Entropy: 3.06908
Value Function Loss: 0.00571

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.61453

Collected Steps per Second: 23,250.32471
Overall Steps per Second: 10,713.51518

Timestep Collection Time: 2.15051
Timestep Consumption Time: 2.51649
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.66700

Cumulative Model Updates: 118,798
Cumulative Timesteps: 990,709,700

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 990709700...
Checkpoint 990709700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 596.09943
Policy Entropy: 3.06628
Value Function Loss: 0.00594

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.12894
Policy Update Magnitude: 0.57546
Value Function Update Magnitude: 0.62349

Collected Steps per Second: 22,766.91787
Overall Steps per Second: 10,577.67267

Timestep Collection Time: 2.19705
Timestep Consumption Time: 2.53178
PPO Batch Consumption Time: 0.29610
Total Iteration Time: 4.72883

Cumulative Model Updates: 118,804
Cumulative Timesteps: 990,759,720

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.67623
Policy Entropy: 3.08357
Value Function Loss: 0.00579

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.57635
Value Function Update Magnitude: 0.62567

Collected Steps per Second: 22,828.11282
Overall Steps per Second: 10,616.70584

Timestep Collection Time: 2.19107
Timestep Consumption Time: 2.52018
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.71125

Cumulative Model Updates: 118,810
Cumulative Timesteps: 990,809,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 990809738...
Checkpoint 990809738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,151.77280
Policy Entropy: 3.09763
Value Function Loss: 0.00596

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.58085
Value Function Update Magnitude: 0.60738

Collected Steps per Second: 22,697.81052
Overall Steps per Second: 10,740.83066

Timestep Collection Time: 2.20382
Timestep Consumption Time: 2.45336
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.65718

Cumulative Model Updates: 118,816
Cumulative Timesteps: 990,859,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 847.27504
Policy Entropy: 3.07249
Value Function Loss: 0.00565

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.57895
Value Function Update Magnitude: 0.59849

Collected Steps per Second: 23,408.55526
Overall Steps per Second: 10,810.72878

Timestep Collection Time: 2.13640
Timestep Consumption Time: 2.48956
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.62596

Cumulative Model Updates: 118,822
Cumulative Timesteps: 990,909,770

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 990909770...
Checkpoint 990909770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 525.11810
Policy Entropy: 3.07808
Value Function Loss: 0.00572

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11302
Policy Update Magnitude: 0.57641
Value Function Update Magnitude: 0.61663

Collected Steps per Second: 22,768.41092
Overall Steps per Second: 10,735.28248

Timestep Collection Time: 2.19620
Timestep Consumption Time: 2.46171
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.65791

Cumulative Model Updates: 118,828
Cumulative Timesteps: 990,959,774

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.17803
Policy Entropy: 3.06403
Value Function Loss: 0.00573

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.10913
Policy Update Magnitude: 0.57671
Value Function Update Magnitude: 0.64209

Collected Steps per Second: 23,301.61150
Overall Steps per Second: 10,809.30394

Timestep Collection Time: 2.14595
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.62601

Cumulative Model Updates: 118,834
Cumulative Timesteps: 991,009,778

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 991009778...
Checkpoint 991009778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.70142
Policy Entropy: 3.08760
Value Function Loss: 0.00537

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10160
Policy Update Magnitude: 0.57138
Value Function Update Magnitude: 0.64893

Collected Steps per Second: 22,599.99140
Overall Steps per Second: 10,704.32489

Timestep Collection Time: 2.21283
Timestep Consumption Time: 2.45911
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.67194

Cumulative Model Updates: 118,840
Cumulative Timesteps: 991,059,788

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 819.70179
Policy Entropy: 3.09504
Value Function Loss: 0.00527

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.10057
Policy Update Magnitude: 0.56147
Value Function Update Magnitude: 0.60696

Collected Steps per Second: 23,094.85677
Overall Steps per Second: 10,695.78247

Timestep Collection Time: 2.16498
Timestep Consumption Time: 2.50976
PPO Batch Consumption Time: 0.29727
Total Iteration Time: 4.67474

Cumulative Model Updates: 118,846
Cumulative Timesteps: 991,109,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 991109788...
Checkpoint 991109788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,105.09926
Policy Entropy: 3.08943
Value Function Loss: 0.00531

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.09335
Policy Update Magnitude: 0.55750
Value Function Update Magnitude: 0.59186

Collected Steps per Second: 22,895.43245
Overall Steps per Second: 10,691.22361

Timestep Collection Time: 2.18515
Timestep Consumption Time: 2.49439
PPO Batch Consumption Time: 0.29554
Total Iteration Time: 4.67954

Cumulative Model Updates: 118,852
Cumulative Timesteps: 991,159,818

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,098.76429
Policy Entropy: 3.06943
Value Function Loss: 0.00557

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09940
Policy Update Magnitude: 0.57011
Value Function Update Magnitude: 0.61033

Collected Steps per Second: 22,850.31703
Overall Steps per Second: 10,813.35063

Timestep Collection Time: 2.18833
Timestep Consumption Time: 2.43596
PPO Batch Consumption Time: 0.28222
Total Iteration Time: 4.62428

Cumulative Model Updates: 118,858
Cumulative Timesteps: 991,209,822

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 991209822...
Checkpoint 991209822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 487.02640
Policy Entropy: 3.05406
Value Function Loss: 0.00565

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.57480
Value Function Update Magnitude: 0.61699

Collected Steps per Second: 22,818.96510
Overall Steps per Second: 10,671.72155

Timestep Collection Time: 2.19221
Timestep Consumption Time: 2.49532
PPO Batch Consumption Time: 0.29575
Total Iteration Time: 4.68753

Cumulative Model Updates: 118,864
Cumulative Timesteps: 991,259,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 671.93292
Policy Entropy: 3.05127
Value Function Loss: 0.00587

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.10358
Policy Update Magnitude: 0.57681
Value Function Update Magnitude: 0.62097

Collected Steps per Second: 22,714.42614
Overall Steps per Second: 10,811.85811

Timestep Collection Time: 2.20221
Timestep Consumption Time: 2.42437
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.62659

Cumulative Model Updates: 118,870
Cumulative Timesteps: 991,309,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 991309868...
Checkpoint 991309868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,162.78786
Policy Entropy: 3.06275
Value Function Loss: 0.00558

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.10168
Policy Update Magnitude: 0.57552
Value Function Update Magnitude: 0.60073

Collected Steps per Second: 22,593.99588
Overall Steps per Second: 10,730.90259

Timestep Collection Time: 2.21298
Timestep Consumption Time: 2.44646
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.65944

Cumulative Model Updates: 118,876
Cumulative Timesteps: 991,359,868

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.75919
Policy Entropy: 3.07027
Value Function Loss: 0.00549

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10856
Policy Update Magnitude: 0.57010
Value Function Update Magnitude: 0.58824

Collected Steps per Second: 22,987.42362
Overall Steps per Second: 10,881.63268

Timestep Collection Time: 2.17536
Timestep Consumption Time: 2.42009
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.59545

Cumulative Model Updates: 118,882
Cumulative Timesteps: 991,409,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 991409874...
Checkpoint 991409874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 806.76230
Policy Entropy: 3.08687
Value Function Loss: 0.00529

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.56339
Value Function Update Magnitude: 0.58922

Collected Steps per Second: 22,251.21636
Overall Steps per Second: 10,704.82569

Timestep Collection Time: 2.24743
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.67154

Cumulative Model Updates: 118,888
Cumulative Timesteps: 991,459,882

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 932.29034
Policy Entropy: 3.08649
Value Function Loss: 0.00526

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.11454
Policy Update Magnitude: 0.56327
Value Function Update Magnitude: 0.58736

Collected Steps per Second: 23,078.71945
Overall Steps per Second: 10,844.29562

Timestep Collection Time: 2.16676
Timestep Consumption Time: 2.44451
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.61127

Cumulative Model Updates: 118,894
Cumulative Timesteps: 991,509,888

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 991509888...
Checkpoint 991509888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 690.40573
Policy Entropy: 3.09365
Value Function Loss: 0.00502

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.10668
Policy Update Magnitude: 0.55820
Value Function Update Magnitude: 0.59053

Collected Steps per Second: 22,821.24167
Overall Steps per Second: 10,683.72371

Timestep Collection Time: 2.19173
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.68170

Cumulative Model Updates: 118,900
Cumulative Timesteps: 991,559,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 900.28744
Policy Entropy: 3.09033
Value Function Loss: 0.00503

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.55330
Value Function Update Magnitude: 0.58626

Collected Steps per Second: 22,610.23677
Overall Steps per Second: 10,656.89735

Timestep Collection Time: 2.21263
Timestep Consumption Time: 2.48180
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.69442

Cumulative Model Updates: 118,906
Cumulative Timesteps: 991,609,934

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 991609934...
Checkpoint 991609934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,249.46872
Policy Entropy: 3.09112
Value Function Loss: 0.00508

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10023
Policy Update Magnitude: 0.55880
Value Function Update Magnitude: 0.58153

Collected Steps per Second: 22,795.70271
Overall Steps per Second: 10,852.34133

Timestep Collection Time: 2.19471
Timestep Consumption Time: 2.41535
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.61007

Cumulative Model Updates: 118,912
Cumulative Timesteps: 991,659,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,112.61949
Policy Entropy: 3.07280
Value Function Loss: 0.00575

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.56508
Value Function Update Magnitude: 0.59645

Collected Steps per Second: 22,709.35499
Overall Steps per Second: 10,672.22903

Timestep Collection Time: 2.20262
Timestep Consumption Time: 2.48431
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.68693

Cumulative Model Updates: 118,918
Cumulative Timesteps: 991,709,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 991709984...
Checkpoint 991709984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821.55221
Policy Entropy: 3.05854
Value Function Loss: 0.00558

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10089
Policy Update Magnitude: 0.58118
Value Function Update Magnitude: 0.60237

Collected Steps per Second: 23,126.44026
Overall Steps per Second: 10,939.99541

Timestep Collection Time: 2.16298
Timestep Consumption Time: 2.40942
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.57240

Cumulative Model Updates: 118,924
Cumulative Timesteps: 991,760,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,697.60590
Policy Entropy: 3.05717
Value Function Loss: 0.00574

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11109
Policy Update Magnitude: 0.58501
Value Function Update Magnitude: 0.61509

Collected Steps per Second: 22,895.20956
Overall Steps per Second: 10,821.48460

Timestep Collection Time: 2.18474
Timestep Consumption Time: 2.43755
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.62229

Cumulative Model Updates: 118,930
Cumulative Timesteps: 991,810,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 991810026...
Checkpoint 991810026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.73280
Policy Entropy: 3.07954
Value Function Loss: 0.00542

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.57593
Value Function Update Magnitude: 0.61470

Collected Steps per Second: 22,787.09958
Overall Steps per Second: 10,711.43680

Timestep Collection Time: 2.19554
Timestep Consumption Time: 2.47517
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.67071

Cumulative Model Updates: 118,936
Cumulative Timesteps: 991,860,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 836.49732
Policy Entropy: 3.09393
Value Function Loss: 0.00570

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.11557
Policy Update Magnitude: 0.57028
Value Function Update Magnitude: 0.61871

Collected Steps per Second: 22,942.02354
Overall Steps per Second: 10,828.67785

Timestep Collection Time: 2.18054
Timestep Consumption Time: 2.43923
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.61977

Cumulative Model Updates: 118,942
Cumulative Timesteps: 991,910,082

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 991910082...
Checkpoint 991910082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,075.46508
Policy Entropy: 3.08334
Value Function Loss: 0.00550

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.11537
Policy Update Magnitude: 0.57002
Value Function Update Magnitude: 0.62618

Collected Steps per Second: 22,694.63891
Overall Steps per Second: 10,717.80139

Timestep Collection Time: 2.20484
Timestep Consumption Time: 2.46384
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.66868

Cumulative Model Updates: 118,948
Cumulative Timesteps: 991,960,120

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573.88553
Policy Entropy: 3.07300
Value Function Loss: 0.00567

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.56470
Value Function Update Magnitude: 0.60569

Collected Steps per Second: 22,967.04206
Overall Steps per Second: 10,847.57203

Timestep Collection Time: 2.17764
Timestep Consumption Time: 2.43297
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.61062

Cumulative Model Updates: 118,954
Cumulative Timesteps: 992,010,134

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 992010134...
Checkpoint 992010134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858.44393
Policy Entropy: 3.06874
Value Function Loss: 0.00530

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11629
Policy Update Magnitude: 0.56575
Value Function Update Magnitude: 0.59806

Collected Steps per Second: 22,675.68249
Overall Steps per Second: 10,695.64354

Timestep Collection Time: 2.20633
Timestep Consumption Time: 2.47128
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.67761

Cumulative Model Updates: 118,960
Cumulative Timesteps: 992,060,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,201.31971
Policy Entropy: 3.08051
Value Function Loss: 0.00523

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.10385
Policy Update Magnitude: 0.56963
Value Function Update Magnitude: 0.60596

Collected Steps per Second: 22,973.50921
Overall Steps per Second: 10,852.44049

Timestep Collection Time: 2.17659
Timestep Consumption Time: 2.43103
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.60763

Cumulative Model Updates: 118,966
Cumulative Timesteps: 992,110,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 992110168...
Checkpoint 992110168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.42565
Policy Entropy: 3.08500
Value Function Loss: 0.00519

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.56412
Value Function Update Magnitude: 0.61389

Collected Steps per Second: 22,493.55173
Overall Steps per Second: 10,672.70597

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.46219
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.68522

Cumulative Model Updates: 118,972
Cumulative Timesteps: 992,160,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.81275
Policy Entropy: 3.07748
Value Function Loss: 0.00540

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09564
Policy Update Magnitude: 0.56524
Value Function Update Magnitude: 0.59228

Collected Steps per Second: 22,925.14176
Overall Steps per Second: 10,840.63512

Timestep Collection Time: 2.18188
Timestep Consumption Time: 2.43224
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.61412

Cumulative Model Updates: 118,978
Cumulative Timesteps: 992,210,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 992210192...
Checkpoint 992210192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.28271
Policy Entropy: 3.07618
Value Function Loss: 0.00561

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11537
Policy Update Magnitude: 0.56955
Value Function Update Magnitude: 0.63352

Collected Steps per Second: 22,363.78650
Overall Steps per Second: 10,769.73151

Timestep Collection Time: 2.23620
Timestep Consumption Time: 2.40737
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.64357

Cumulative Model Updates: 118,984
Cumulative Timesteps: 992,260,202

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,357.71315
Policy Entropy: 3.06857
Value Function Loss: 0.00544

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.10866
Policy Update Magnitude: 0.57858
Value Function Update Magnitude: 0.63933

Collected Steps per Second: 22,133.71491
Overall Steps per Second: 10,485.33535

Timestep Collection Time: 2.25900
Timestep Consumption Time: 2.50957
PPO Batch Consumption Time: 0.29518
Total Iteration Time: 4.76856

Cumulative Model Updates: 118,990
Cumulative Timesteps: 992,310,202

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 992310202...
Checkpoint 992310202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.93654
Policy Entropy: 3.07417
Value Function Loss: 0.00530

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10359
Policy Update Magnitude: 0.58178
Value Function Update Magnitude: 0.64862

Collected Steps per Second: 22,744.58131
Overall Steps per Second: 10,946.92450

Timestep Collection Time: 2.19964
Timestep Consumption Time: 2.37059
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.57023

Cumulative Model Updates: 118,996
Cumulative Timesteps: 992,360,232

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 829.16808
Policy Entropy: 3.08211
Value Function Loss: 0.00529

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.57680
Value Function Update Magnitude: 0.63461

Collected Steps per Second: 21,914.26572
Overall Steps per Second: 10,538.00605

Timestep Collection Time: 2.28180
Timestep Consumption Time: 2.46331
PPO Batch Consumption Time: 0.29597
Total Iteration Time: 4.74511

Cumulative Model Updates: 119,002
Cumulative Timesteps: 992,410,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 992410236...
Checkpoint 992410236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610.69349
Policy Entropy: 3.09255
Value Function Loss: 0.00533

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.11435
Policy Update Magnitude: 0.57141
Value Function Update Magnitude: 0.60931

Collected Steps per Second: 22,392.36167
Overall Steps per Second: 10,687.89590

Timestep Collection Time: 2.23362
Timestep Consumption Time: 2.44607
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.67969

Cumulative Model Updates: 119,008
Cumulative Timesteps: 992,460,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,751.29282
Policy Entropy: 3.09327
Value Function Loss: 0.00564

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10174
Policy Update Magnitude: 0.56610
Value Function Update Magnitude: 0.60621

Collected Steps per Second: 22,230.05354
Overall Steps per Second: 10,804.80384

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.37884
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.62850

Cumulative Model Updates: 119,014
Cumulative Timesteps: 992,510,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 992510262...
Checkpoint 992510262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023.10987
Policy Entropy: 3.09015
Value Function Loss: 0.00538

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.56925
Value Function Update Magnitude: 0.61949

Collected Steps per Second: 22,288.20058
Overall Steps per Second: 10,725.38014

Timestep Collection Time: 2.24343
Timestep Consumption Time: 2.41860
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.66203

Cumulative Model Updates: 119,020
Cumulative Timesteps: 992,560,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 475.01405
Policy Entropy: 3.09399
Value Function Loss: 0.00549

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.10643
Policy Update Magnitude: 0.57068
Value Function Update Magnitude: 0.62918

Collected Steps per Second: 22,024.84320
Overall Steps per Second: 10,686.08242

Timestep Collection Time: 2.27125
Timestep Consumption Time: 2.40998
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.68123

Cumulative Model Updates: 119,026
Cumulative Timesteps: 992,610,288

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 992610288...
Checkpoint 992610288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 852.03996
Policy Entropy: 3.08913
Value Function Loss: 0.00533

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.11617
Policy Update Magnitude: 0.56937
Value Function Update Magnitude: 0.62139

Collected Steps per Second: 22,172.17169
Overall Steps per Second: 10,802.04656

Timestep Collection Time: 2.25634
Timestep Consumption Time: 2.37500
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.63134

Cumulative Model Updates: 119,032
Cumulative Timesteps: 992,660,316

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 879.13059
Policy Entropy: 3.08387
Value Function Loss: 0.00545

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10626
Policy Update Magnitude: 0.57148
Value Function Update Magnitude: 0.62192

Collected Steps per Second: 22,284.68268
Overall Steps per Second: 10,719.07699

Timestep Collection Time: 2.24387
Timestep Consumption Time: 2.42108
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.66495

Cumulative Model Updates: 119,038
Cumulative Timesteps: 992,710,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 992710320...
Checkpoint 992710320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 687.51227
Policy Entropy: 3.09076
Value Function Loss: 0.00530

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10857
Policy Update Magnitude: 0.57226
Value Function Update Magnitude: 0.63322

Collected Steps per Second: 22,542.83809
Overall Steps per Second: 10,600.90893

Timestep Collection Time: 2.21871
Timestep Consumption Time: 2.49938
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.71809

Cumulative Model Updates: 119,044
Cumulative Timesteps: 992,760,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.92913
Policy Entropy: 3.08812
Value Function Loss: 0.00530

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.09978
Policy Update Magnitude: 0.56811
Value Function Update Magnitude: 0.62087

Collected Steps per Second: 23,181.12289
Overall Steps per Second: 10,747.21488

Timestep Collection Time: 2.15745
Timestep Consumption Time: 2.49604
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.65348

Cumulative Model Updates: 119,050
Cumulative Timesteps: 992,810,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 992810348...
Checkpoint 992810348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.31052
Policy Entropy: 3.09114
Value Function Loss: 0.00517

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.56067
Value Function Update Magnitude: 0.58760

Collected Steps per Second: 22,929.44049
Overall Steps per Second: 10,646.67571

Timestep Collection Time: 2.18130
Timestep Consumption Time: 2.51650
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.69780

Cumulative Model Updates: 119,056
Cumulative Timesteps: 992,860,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782.11152
Policy Entropy: 3.07099
Value Function Loss: 0.00519

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.56179
Value Function Update Magnitude: 0.57656

Collected Steps per Second: 22,934.73222
Overall Steps per Second: 10,781.32670

Timestep Collection Time: 2.18062
Timestep Consumption Time: 2.45814
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.63876

Cumulative Model Updates: 119,062
Cumulative Timesteps: 992,910,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 992910376...
Checkpoint 992910376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.06690
Policy Entropy: 3.08525
Value Function Loss: 0.00508

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.09588
Policy Update Magnitude: 0.56985
Value Function Update Magnitude: 0.60207

Collected Steps per Second: 22,908.64071
Overall Steps per Second: 10,751.46220

Timestep Collection Time: 2.18328
Timestep Consumption Time: 2.46874
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.65202

Cumulative Model Updates: 119,068
Cumulative Timesteps: 992,960,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883.50233
Policy Entropy: 3.08348
Value Function Loss: 0.00526

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.10757
Policy Update Magnitude: 0.56924
Value Function Update Magnitude: 0.61473

Collected Steps per Second: 22,769.44235
Overall Steps per Second: 10,667.41357

Timestep Collection Time: 2.19654
Timestep Consumption Time: 2.49194
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.68848

Cumulative Model Updates: 119,074
Cumulative Timesteps: 993,010,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 993010406...
Checkpoint 993010406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348.42586
Policy Entropy: 3.09412
Value Function Loss: 0.00537

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.60979

Collected Steps per Second: 22,970.69108
Overall Steps per Second: 10,781.74671

Timestep Collection Time: 2.17695
Timestep Consumption Time: 2.46108
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.63802

Cumulative Model Updates: 119,080
Cumulative Timesteps: 993,060,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 971.01722
Policy Entropy: 3.07916
Value Function Loss: 0.00563

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.57353
Value Function Update Magnitude: 0.62639

Collected Steps per Second: 22,596.18840
Overall Steps per Second: 10,519.23012

Timestep Collection Time: 2.21382
Timestep Consumption Time: 2.54166
PPO Batch Consumption Time: 0.29680
Total Iteration Time: 4.75548

Cumulative Model Updates: 119,086
Cumulative Timesteps: 993,110,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 993110436...
Checkpoint 993110436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 964.92934
Policy Entropy: 3.07469
Value Function Loss: 0.00573

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.11338
Policy Update Magnitude: 0.58540
Value Function Update Magnitude: 0.63190

Collected Steps per Second: 23,118.13696
Overall Steps per Second: 10,647.29893

Timestep Collection Time: 2.16324
Timestep Consumption Time: 2.53373
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.69697

Cumulative Model Updates: 119,092
Cumulative Timesteps: 993,160,446

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 939.11469
Policy Entropy: 3.07204
Value Function Loss: 0.00546

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.11156
Policy Update Magnitude: 0.58161
Value Function Update Magnitude: 0.63055

Collected Steps per Second: 22,571.18844
Overall Steps per Second: 10,557.08318

Timestep Collection Time: 2.21583
Timestep Consumption Time: 2.52165
PPO Batch Consumption Time: 0.29507
Total Iteration Time: 4.73748

Cumulative Model Updates: 119,098
Cumulative Timesteps: 993,210,460

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 993210460...
Checkpoint 993210460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 904.45561
Policy Entropy: 3.08676
Value Function Loss: 0.00536

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09885
Policy Update Magnitude: 0.57131
Value Function Update Magnitude: 0.62522

Collected Steps per Second: 22,860.21552
Overall Steps per Second: 10,662.16340

Timestep Collection Time: 2.18852
Timestep Consumption Time: 2.50378
PPO Batch Consumption Time: 0.29481
Total Iteration Time: 4.69229

Cumulative Model Updates: 119,104
Cumulative Timesteps: 993,260,490

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.99674
Policy Entropy: 3.09138
Value Function Loss: 0.00516

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.08787
Policy Update Magnitude: 0.56175
Value Function Update Magnitude: 0.59546

Collected Steps per Second: 23,187.46178
Overall Steps per Second: 10,772.64054

Timestep Collection Time: 2.15668
Timestep Consumption Time: 2.48545
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.64213

Cumulative Model Updates: 119,110
Cumulative Timesteps: 993,310,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 993310498...
Checkpoint 993310498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.25612
Policy Entropy: 3.09781
Value Function Loss: 0.00544

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09845
Policy Update Magnitude: 0.56492
Value Function Update Magnitude: 0.57655

Collected Steps per Second: 22,769.28881
Overall Steps per Second: 10,667.16753

Timestep Collection Time: 2.19699
Timestep Consumption Time: 2.49254
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.68953

Cumulative Model Updates: 119,116
Cumulative Timesteps: 993,360,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 708.11583
Policy Entropy: 3.07615
Value Function Loss: 0.00563

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.10796
Policy Update Magnitude: 0.57570
Value Function Update Magnitude: 0.59675

Collected Steps per Second: 22,898.45324
Overall Steps per Second: 10,676.85540

Timestep Collection Time: 2.18355
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.68303

Cumulative Model Updates: 119,122
Cumulative Timesteps: 993,410,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 993410522...
Checkpoint 993410522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 753.02886
Policy Entropy: 3.08165
Value Function Loss: 0.00562

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.11408
Policy Update Magnitude: 0.57223
Value Function Update Magnitude: 0.61000

Collected Steps per Second: 22,896.30578
Overall Steps per Second: 10,810.45193

Timestep Collection Time: 2.18463
Timestep Consumption Time: 2.44237
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.62700

Cumulative Model Updates: 119,128
Cumulative Timesteps: 993,460,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.20063
Policy Entropy: 3.07415
Value Function Loss: 0.00546

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.10839
Policy Update Magnitude: 0.56681
Value Function Update Magnitude: 0.61335

Collected Steps per Second: 23,001.77538
Overall Steps per Second: 10,683.15611

Timestep Collection Time: 2.17418
Timestep Consumption Time: 2.50702
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.68120

Cumulative Model Updates: 119,134
Cumulative Timesteps: 993,510,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 993510552...
Checkpoint 993510552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,212.41941
Policy Entropy: 3.07766
Value Function Loss: 0.00529

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.09658
Policy Update Magnitude: 0.56908
Value Function Update Magnitude: 0.60296

Collected Steps per Second: 22,986.33666
Overall Steps per Second: 10,863.85054

Timestep Collection Time: 2.17581
Timestep Consumption Time: 2.42789
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.60371

Cumulative Model Updates: 119,140
Cumulative Timesteps: 993,560,566

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.81307
Policy Entropy: 3.06695
Value Function Loss: 0.00545

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.57207
Value Function Update Magnitude: 0.60860

Collected Steps per Second: 22,707.16279
Overall Steps per Second: 10,547.44100

Timestep Collection Time: 2.20221
Timestep Consumption Time: 2.53884
PPO Batch Consumption Time: 0.29568
Total Iteration Time: 4.74106

Cumulative Model Updates: 119,146
Cumulative Timesteps: 993,610,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 993610572...
Checkpoint 993610572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.63671
Policy Entropy: 3.07900
Value Function Loss: 0.00543

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.09794
Policy Update Magnitude: 0.57441
Value Function Update Magnitude: 0.62489

Collected Steps per Second: 22,985.34731
Overall Steps per Second: 10,631.59929

Timestep Collection Time: 2.17626
Timestep Consumption Time: 2.52877
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.70503

Cumulative Model Updates: 119,152
Cumulative Timesteps: 993,660,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464.68739
Policy Entropy: 3.08781
Value Function Loss: 0.00536

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.09997
Policy Update Magnitude: 0.56495
Value Function Update Magnitude: 0.63195

Collected Steps per Second: 22,726.77387
Overall Steps per Second: 10,756.50886

Timestep Collection Time: 2.20049
Timestep Consumption Time: 2.44879
PPO Batch Consumption Time: 0.28263
Total Iteration Time: 4.64928

Cumulative Model Updates: 119,158
Cumulative Timesteps: 993,710,604

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 993710604...
Checkpoint 993710604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.39968
Policy Entropy: 3.08559
Value Function Loss: 0.00528

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10100
Policy Update Magnitude: 0.56389
Value Function Update Magnitude: 0.63016

Collected Steps per Second: 22,782.56979
Overall Steps per Second: 10,733.10382

Timestep Collection Time: 2.19554
Timestep Consumption Time: 2.46481
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.66035

Cumulative Model Updates: 119,164
Cumulative Timesteps: 993,760,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,246.19484
Policy Entropy: 3.09010
Value Function Loss: 0.00509

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.56257
Value Function Update Magnitude: 0.60392

Collected Steps per Second: 22,877.52640
Overall Steps per Second: 10,856.43940

Timestep Collection Time: 2.18686
Timestep Consumption Time: 2.42146
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.60832

Cumulative Model Updates: 119,170
Cumulative Timesteps: 993,810,654

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 993810654...
Checkpoint 993810654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.22900
Policy Entropy: 3.09377
Value Function Loss: 0.00502

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.10578
Policy Update Magnitude: 0.55340
Value Function Update Magnitude: 0.57228

Collected Steps per Second: 22,718.41977
Overall Steps per Second: 10,717.92820

Timestep Collection Time: 2.20086
Timestep Consumption Time: 2.46422
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.66508

Cumulative Model Updates: 119,176
Cumulative Timesteps: 993,860,654

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 907.63279
Policy Entropy: 3.08508
Value Function Loss: 0.00534

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.55609
Value Function Update Magnitude: 0.54582

Collected Steps per Second: 22,952.86328
Overall Steps per Second: 10,859.91442

Timestep Collection Time: 2.17873
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.60482

Cumulative Model Updates: 119,182
Cumulative Timesteps: 993,910,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 993910662...
Checkpoint 993910662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,612.87892
Policy Entropy: 3.07519
Value Function Loss: 0.00553

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.11639
Policy Update Magnitude: 0.56513
Value Function Update Magnitude: 0.55247

Collected Steps per Second: 22,342.50695
Overall Steps per Second: 10,696.32571

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.43701
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.67525

Cumulative Model Updates: 119,188
Cumulative Timesteps: 993,960,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 874.18549
Policy Entropy: 3.06328
Value Function Loss: 0.00551

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.56608
Value Function Update Magnitude: 0.56429

Collected Steps per Second: 22,750.36823
Overall Steps per Second: 10,797.23624

Timestep Collection Time: 2.19838
Timestep Consumption Time: 2.43373
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.63211

Cumulative Model Updates: 119,194
Cumulative Timesteps: 994,010,684

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 994010684...
Checkpoint 994010684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938.65620
Policy Entropy: 3.08957
Value Function Loss: 0.00548

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11633
Policy Update Magnitude: 0.56603
Value Function Update Magnitude: 0.56621

Collected Steps per Second: 22,666.87924
Overall Steps per Second: 10,769.04164

Timestep Collection Time: 2.20595
Timestep Consumption Time: 2.43717
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.64312

Cumulative Model Updates: 119,200
Cumulative Timesteps: 994,060,686

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 910.66059
Policy Entropy: 3.08629
Value Function Loss: 0.00571

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.11013
Policy Update Magnitude: 0.56943
Value Function Update Magnitude: 0.59803

Collected Steps per Second: 23,127.08752
Overall Steps per Second: 10,842.21878

Timestep Collection Time: 2.16318
Timestep Consumption Time: 2.45101
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.61418

Cumulative Model Updates: 119,206
Cumulative Timesteps: 994,110,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 994110714...
Checkpoint 994110714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 673.56284
Policy Entropy: 3.09990
Value Function Loss: 0.00554

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.57347
Value Function Update Magnitude: 0.59442

Collected Steps per Second: 22,823.60777
Overall Steps per Second: 10,690.02708

Timestep Collection Time: 2.19185
Timestep Consumption Time: 2.48784
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.67969

Cumulative Model Updates: 119,212
Cumulative Timesteps: 994,160,740

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.32943
Policy Entropy: 3.08976
Value Function Loss: 0.00541

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.56900
Value Function Update Magnitude: 0.57193

Collected Steps per Second: 22,602.88085
Overall Steps per Second: 10,794.64638

Timestep Collection Time: 2.21211
Timestep Consumption Time: 2.41982
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.63193

Cumulative Model Updates: 119,218
Cumulative Timesteps: 994,210,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 994210740...
Checkpoint 994210740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.38568
Policy Entropy: 3.07906
Value Function Loss: 0.00501

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.55878
Value Function Update Magnitude: 0.55175

Collected Steps per Second: 22,991.56633
Overall Steps per Second: 10,717.19558

Timestep Collection Time: 2.17523
Timestep Consumption Time: 2.49129
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.66652

Cumulative Model Updates: 119,224
Cumulative Timesteps: 994,260,752

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 941.42320
Policy Entropy: 3.06615
Value Function Loss: 0.00523

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.56394
Value Function Update Magnitude: 0.54739

Collected Steps per Second: 22,778.07747
Overall Steps per Second: 10,709.12335

Timestep Collection Time: 2.19580
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.67041

Cumulative Model Updates: 119,230
Cumulative Timesteps: 994,310,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 994310768...
Checkpoint 994310768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,281.73059
Policy Entropy: 3.05898
Value Function Loss: 0.00528

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.57719
Value Function Update Magnitude: 0.55597

Collected Steps per Second: 23,029.15720
Overall Steps per Second: 10,889.86477

Timestep Collection Time: 2.17125
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.59161

Cumulative Model Updates: 119,236
Cumulative Timesteps: 994,360,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.96005
Policy Entropy: 3.06465
Value Function Loss: 0.00550

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.58380
Value Function Update Magnitude: 0.59011

Collected Steps per Second: 22,446.04247
Overall Steps per Second: 10,672.50887

Timestep Collection Time: 2.22854
Timestep Consumption Time: 2.45845
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.68700

Cumulative Model Updates: 119,242
Cumulative Timesteps: 994,410,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 994410792...
Checkpoint 994410792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692.22188
Policy Entropy: 3.06712
Value Function Loss: 0.00557

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.10419
Policy Update Magnitude: 0.58149
Value Function Update Magnitude: 0.60948

Collected Steps per Second: 23,012.48356
Overall Steps per Second: 10,816.12916

Timestep Collection Time: 2.17308
Timestep Consumption Time: 2.45038
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.62347

Cumulative Model Updates: 119,248
Cumulative Timesteps: 994,460,800

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636.36271
Policy Entropy: 3.08493
Value Function Loss: 0.00573

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.57758
Value Function Update Magnitude: 0.59375

Collected Steps per Second: 22,696.15576
Overall Steps per Second: 10,923.06469

Timestep Collection Time: 2.20407
Timestep Consumption Time: 2.37559
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.57967

Cumulative Model Updates: 119,254
Cumulative Timesteps: 994,510,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 994510824...
Checkpoint 994510824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,147.58317
Policy Entropy: 3.10193
Value Function Loss: 0.00546

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.57088
Value Function Update Magnitude: 0.58761

Collected Steps per Second: 22,270.94238
Overall Steps per Second: 10,655.53551

Timestep Collection Time: 2.24580
Timestep Consumption Time: 2.44810
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.69390

Cumulative Model Updates: 119,260
Cumulative Timesteps: 994,560,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 693.88617
Policy Entropy: 3.10596
Value Function Loss: 0.00535

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.09693
Policy Update Magnitude: 0.56437
Value Function Update Magnitude: 0.59893

Collected Steps per Second: 22,180.86374
Overall Steps per Second: 10,799.80849

Timestep Collection Time: 2.25519
Timestep Consumption Time: 2.37656
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.63175

Cumulative Model Updates: 119,266
Cumulative Timesteps: 994,610,862

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 994610862...
Checkpoint 994610862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,358.04963
Policy Entropy: 3.09584
Value Function Loss: 0.00528

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.56597
Value Function Update Magnitude: 0.60019

Collected Steps per Second: 22,107.32943
Overall Steps per Second: 10,747.50846

Timestep Collection Time: 2.26296
Timestep Consumption Time: 2.39189
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.65485

Cumulative Model Updates: 119,272
Cumulative Timesteps: 994,660,890

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.69602
Policy Entropy: 3.09037
Value Function Loss: 0.00538

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.08956
Policy Update Magnitude: 0.56918
Value Function Update Magnitude: 0.60121

Collected Steps per Second: 22,291.78737
Overall Steps per Second: 10,805.72493

Timestep Collection Time: 2.24388
Timestep Consumption Time: 2.38515
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.62903

Cumulative Model Updates: 119,278
Cumulative Timesteps: 994,710,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 994710910...
Checkpoint 994710910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 836.32796
Policy Entropy: 3.08431
Value Function Loss: 0.00540

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.56801
Value Function Update Magnitude: 0.58925

Collected Steps per Second: 22,063.16185
Overall Steps per Second: 10,689.05133

Timestep Collection Time: 2.26758
Timestep Consumption Time: 2.41291
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.68049

Cumulative Model Updates: 119,284
Cumulative Timesteps: 994,760,940

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,117.24281
Policy Entropy: 3.08905
Value Function Loss: 0.00568

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.09531
Policy Update Magnitude: 0.57828
Value Function Update Magnitude: 0.60371

Collected Steps per Second: 21,803.06776
Overall Steps per Second: 10,506.09746

Timestep Collection Time: 2.29426
Timestep Consumption Time: 2.46697
PPO Batch Consumption Time: 0.29637
Total Iteration Time: 4.76124

Cumulative Model Updates: 119,290
Cumulative Timesteps: 994,810,962

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 994810962...
Checkpoint 994810962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418.35228
Policy Entropy: 3.09391
Value Function Loss: 0.00576

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.10056
Policy Update Magnitude: 0.57887
Value Function Update Magnitude: 0.60968

Collected Steps per Second: 22,140.12341
Overall Steps per Second: 10,647.96922

Timestep Collection Time: 2.25934
Timestep Consumption Time: 2.43846
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.69780

Cumulative Model Updates: 119,296
Cumulative Timesteps: 994,860,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 986.69192
Policy Entropy: 3.10320
Value Function Loss: 0.00559

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.56806
Value Function Update Magnitude: 0.60134

Collected Steps per Second: 22,097.53690
Overall Steps per Second: 10,672.21696

Timestep Collection Time: 2.26360
Timestep Consumption Time: 2.42334
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.68694

Cumulative Model Updates: 119,302
Cumulative Timesteps: 994,911,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 994911004...
Checkpoint 994911004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,234.20522
Policy Entropy: 3.10409
Value Function Loss: 0.00538

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.11584
Policy Update Magnitude: 0.56283
Value Function Update Magnitude: 0.58688

Collected Steps per Second: 22,524.05432
Overall Steps per Second: 10,894.59249

Timestep Collection Time: 2.22020
Timestep Consumption Time: 2.36996
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.59017

Cumulative Model Updates: 119,308
Cumulative Timesteps: 994,961,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 806.98954
Policy Entropy: 3.09112
Value Function Loss: 0.00535

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.10021
Policy Update Magnitude: 0.56327
Value Function Update Magnitude: 0.58786

Collected Steps per Second: 22,629.70752
Overall Steps per Second: 10,628.53446

Timestep Collection Time: 2.21090
Timestep Consumption Time: 2.49643
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.70733

Cumulative Model Updates: 119,314
Cumulative Timesteps: 995,011,044

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 995011044...
Checkpoint 995011044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 740.79612
Policy Entropy: 3.09384
Value Function Loss: 0.00535

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09521
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.58454

Collected Steps per Second: 23,082.07654
Overall Steps per Second: 10,820.64404

Timestep Collection Time: 2.16688
Timestep Consumption Time: 2.45540
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.62228

Cumulative Model Updates: 119,320
Cumulative Timesteps: 995,061,060

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 825.85079
Policy Entropy: 3.09584
Value Function Loss: 0.00574

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.57035
Value Function Update Magnitude: 0.59427

Collected Steps per Second: 22,963.35777
Overall Steps per Second: 10,691.56359

Timestep Collection Time: 2.17773
Timestep Consumption Time: 2.49960
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.67733

Cumulative Model Updates: 119,326
Cumulative Timesteps: 995,111,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 995111068...
Checkpoint 995111068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 866.72512
Policy Entropy: 3.09953
Value Function Loss: 0.00560

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.08969
Policy Update Magnitude: 0.57208
Value Function Update Magnitude: 0.59587

Collected Steps per Second: 23,085.16679
Overall Steps per Second: 10,833.99623

Timestep Collection Time: 2.16771
Timestep Consumption Time: 2.45127
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.61898

Cumulative Model Updates: 119,332
Cumulative Timesteps: 995,161,110

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 873.89250
Policy Entropy: 3.11998
Value Function Loss: 0.00524

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.55931
Value Function Update Magnitude: 0.58477

Collected Steps per Second: 23,087.30614
Overall Steps per Second: 10,711.86096

Timestep Collection Time: 2.16647
Timestep Consumption Time: 2.50293
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.66940

Cumulative Model Updates: 119,338
Cumulative Timesteps: 995,211,128

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 995211128...
Checkpoint 995211128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924.80718
Policy Entropy: 3.11519
Value Function Loss: 0.00526

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09273
Policy Update Magnitude: 0.55130
Value Function Update Magnitude: 0.57184

Collected Steps per Second: 22,843.22459
Overall Steps per Second: 10,720.74972

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.47552
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.66479

Cumulative Model Updates: 119,344
Cumulative Timesteps: 995,261,138

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,206.30134
Policy Entropy: 3.10875
Value Function Loss: 0.00524

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.09076
Policy Update Magnitude: 0.55824
Value Function Update Magnitude: 0.58220

Collected Steps per Second: 23,519.17793
Overall Steps per Second: 10,753.34131

Timestep Collection Time: 2.12720
Timestep Consumption Time: 2.52531
PPO Batch Consumption Time: 0.29574
Total Iteration Time: 4.65251

Cumulative Model Updates: 119,350
Cumulative Timesteps: 995,311,168

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 995311168...
Checkpoint 995311168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.08706
Policy Entropy: 3.09178
Value Function Loss: 0.00547

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.09471
Policy Update Magnitude: 0.56407
Value Function Update Magnitude: 0.60087

Collected Steps per Second: 21,786.90803
Overall Steps per Second: 10,620.20394

Timestep Collection Time: 2.29578
Timestep Consumption Time: 2.41392
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.70970

Cumulative Model Updates: 119,356
Cumulative Timesteps: 995,361,186

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,285.29783
Policy Entropy: 3.08989
Value Function Loss: 0.00515

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.09975
Policy Update Magnitude: 0.56166
Value Function Update Magnitude: 0.60939

Collected Steps per Second: 23,018.93731
Overall Steps per Second: 10,820.91181

Timestep Collection Time: 2.17212
Timestep Consumption Time: 2.44856
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.62068

Cumulative Model Updates: 119,362
Cumulative Timesteps: 995,411,186

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 995411186...
Checkpoint 995411186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,052.81153
Policy Entropy: 3.08829
Value Function Loss: 0.00498

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.55556
Value Function Update Magnitude: 0.58948

Collected Steps per Second: 22,909.82745
Overall Steps per Second: 10,719.46272

Timestep Collection Time: 2.18352
Timestep Consumption Time: 2.48313
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.66665

Cumulative Model Updates: 119,368
Cumulative Timesteps: 995,461,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.26777
Policy Entropy: 3.09826
Value Function Loss: 0.00517

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10754
Policy Update Magnitude: 0.55269
Value Function Update Magnitude: 0.57416

Collected Steps per Second: 23,068.14862
Overall Steps per Second: 10,844.48706

Timestep Collection Time: 2.16844
Timestep Consumption Time: 2.44422
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.61267

Cumulative Model Updates: 119,374
Cumulative Timesteps: 995,511,232

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 995511232...
Checkpoint 995511232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,500.55267
Policy Entropy: 3.08991
Value Function Loss: 0.00528

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.11178
Policy Update Magnitude: 0.55622
Value Function Update Magnitude: 0.59354

Collected Steps per Second: 23,283.17213
Overall Steps per Second: 10,692.02174

Timestep Collection Time: 2.14816
Timestep Consumption Time: 2.52972
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.67788

Cumulative Model Updates: 119,380
Cumulative Timesteps: 995,561,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.41013
Policy Entropy: 3.08549
Value Function Loss: 0.00573

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.10652
Policy Update Magnitude: 0.57368
Value Function Update Magnitude: 0.61797

Collected Steps per Second: 22,858.26582
Overall Steps per Second: 10,832.63187

Timestep Collection Time: 2.18809
Timestep Consumption Time: 2.42907
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.61716

Cumulative Model Updates: 119,386
Cumulative Timesteps: 995,611,264

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 995611264...
Checkpoint 995611264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 948.46086
Policy Entropy: 3.07897
Value Function Loss: 0.00534

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.10258
Policy Update Magnitude: 0.57584
Value Function Update Magnitude: 0.61895

Collected Steps per Second: 22,600.45644
Overall Steps per Second: 10,700.10263

Timestep Collection Time: 2.21376
Timestep Consumption Time: 2.46208
PPO Batch Consumption Time: 0.28178
Total Iteration Time: 4.67584

Cumulative Model Updates: 119,392
Cumulative Timesteps: 995,661,296

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,440.34465
Policy Entropy: 3.08608
Value Function Loss: 0.00524

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.10178
Policy Update Magnitude: 0.56680
Value Function Update Magnitude: 0.57417

Collected Steps per Second: 22,890.72769
Overall Steps per Second: 10,716.07532

Timestep Collection Time: 2.18473
Timestep Consumption Time: 2.48209
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.66682

Cumulative Model Updates: 119,398
Cumulative Timesteps: 995,711,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 995711306...
Checkpoint 995711306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,199.22224
Policy Entropy: 3.08659
Value Function Loss: 0.00501

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.55845
Value Function Update Magnitude: 0.56632

Collected Steps per Second: 21,351.81565
Overall Steps per Second: 10,419.56893

Timestep Collection Time: 2.34331
Timestep Consumption Time: 2.45861
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.80193

Cumulative Model Updates: 119,404
Cumulative Timesteps: 995,761,340

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,939.87152
Policy Entropy: 3.08743
Value Function Loss: 0.00517

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.55726
Value Function Update Magnitude: 0.57784

Collected Steps per Second: 23,015.27639
Overall Steps per Second: 10,837.61874

Timestep Collection Time: 2.17308
Timestep Consumption Time: 2.44177
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.61485

Cumulative Model Updates: 119,410
Cumulative Timesteps: 995,811,354

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 995811354...
Checkpoint 995811354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 939.92987
Policy Entropy: 3.07408
Value Function Loss: 0.00530

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.56224
Value Function Update Magnitude: 0.58049

Collected Steps per Second: 22,772.95363
Overall Steps per Second: 10,682.72736

Timestep Collection Time: 2.19611
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.68158

Cumulative Model Updates: 119,416
Cumulative Timesteps: 995,861,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 614.31806
Policy Entropy: 3.08216
Value Function Loss: 0.00538

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09293
Policy Update Magnitude: 0.56694
Value Function Update Magnitude: 0.57540

Collected Steps per Second: 23,182.06948
Overall Steps per Second: 10,822.63329

Timestep Collection Time: 2.15770
Timestep Consumption Time: 2.46409
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.62180

Cumulative Model Updates: 119,422
Cumulative Timesteps: 995,911,386

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 995911386...
Checkpoint 995911386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 683.04660
Policy Entropy: 3.08679
Value Function Loss: 0.00552

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.09426
Policy Update Magnitude: 0.57185
Value Function Update Magnitude: 0.56523

Collected Steps per Second: 22,821.46088
Overall Steps per Second: 10,764.75177

Timestep Collection Time: 2.19136
Timestep Consumption Time: 2.45436
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.64572

Cumulative Model Updates: 119,428
Cumulative Timesteps: 995,961,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065.53974
Policy Entropy: 3.08310
Value Function Loss: 0.00560

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.10742
Policy Update Magnitude: 0.57183
Value Function Update Magnitude: 0.57329

Collected Steps per Second: 22,570.72378
Overall Steps per Second: 10,605.16555

Timestep Collection Time: 2.21659
Timestep Consumption Time: 2.50092
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.71751

Cumulative Model Updates: 119,434
Cumulative Timesteps: 996,011,426

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 996011426...
Checkpoint 996011426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070.11362
Policy Entropy: 3.09200
Value Function Loss: 0.00524

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.10709
Policy Update Magnitude: 0.55859
Value Function Update Magnitude: 0.58145

Collected Steps per Second: 22,988.27015
Overall Steps per Second: 10,839.89041

Timestep Collection Time: 2.17598
Timestep Consumption Time: 2.43864
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.61462

Cumulative Model Updates: 119,440
Cumulative Timesteps: 996,061,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796.38922
Policy Entropy: 3.11260
Value Function Loss: 0.00516

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.54661
Value Function Update Magnitude: 0.57125

Collected Steps per Second: 22,778.03490
Overall Steps per Second: 10,568.52534

Timestep Collection Time: 2.19571
Timestep Consumption Time: 2.53664
PPO Batch Consumption Time: 0.29598
Total Iteration Time: 4.73235

Cumulative Model Updates: 119,446
Cumulative Timesteps: 996,111,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 996111462...
Checkpoint 996111462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,554.88003
Policy Entropy: 3.11428
Value Function Loss: 0.00536

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09434
Policy Update Magnitude: 0.55109
Value Function Update Magnitude: 0.55931

Collected Steps per Second: 23,112.91645
Overall Steps per Second: 10,700.61359

Timestep Collection Time: 2.16424
Timestep Consumption Time: 2.51044
PPO Batch Consumption Time: 0.29515
Total Iteration Time: 4.67469

Cumulative Model Updates: 119,452
Cumulative Timesteps: 996,161,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 816.59223
Policy Entropy: 3.11155
Value Function Loss: 0.00541

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.55152
Value Function Update Magnitude: 0.55941

Collected Steps per Second: 22,940.73976
Overall Steps per Second: 10,809.40154

Timestep Collection Time: 2.18031
Timestep Consumption Time: 2.44695
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.62727

Cumulative Model Updates: 119,458
Cumulative Timesteps: 996,211,502

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 996211502...
Checkpoint 996211502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 772.00331
Policy Entropy: 3.10145
Value Function Loss: 0.00550

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.10637
Policy Update Magnitude: 0.54476
Value Function Update Magnitude: 0.55607

Collected Steps per Second: 22,595.31078
Overall Steps per Second: 10,654.68714

Timestep Collection Time: 2.21400
Timestep Consumption Time: 2.48121
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.69521

Cumulative Model Updates: 119,464
Cumulative Timesteps: 996,261,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,160.19151
Policy Entropy: 3.10485
Value Function Loss: 0.00534

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10028
Policy Update Magnitude: 0.55169
Value Function Update Magnitude: 0.55160

Collected Steps per Second: 22,753.45244
Overall Steps per Second: 10,674.17102

Timestep Collection Time: 2.19888
Timestep Consumption Time: 2.48833
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.68720

Cumulative Model Updates: 119,470
Cumulative Timesteps: 996,311,560

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 996311560...
Checkpoint 996311560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 894.98696
Policy Entropy: 3.09688
Value Function Loss: 0.00509

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.55600
Value Function Update Magnitude: 0.55881

Collected Steps per Second: 22,772.29499
Overall Steps per Second: 10,639.07389

Timestep Collection Time: 2.19679
Timestep Consumption Time: 2.50531
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.70210

Cumulative Model Updates: 119,476
Cumulative Timesteps: 996,361,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.92532
Policy Entropy: 3.08072
Value Function Loss: 0.00522

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.09136
Policy Update Magnitude: 0.55547
Value Function Update Magnitude: 0.55861

Collected Steps per Second: 23,076.83791
Overall Steps per Second: 10,684.24879

Timestep Collection Time: 2.16763
Timestep Consumption Time: 2.51422
PPO Batch Consumption Time: 0.29630
Total Iteration Time: 4.68185

Cumulative Model Updates: 119,482
Cumulative Timesteps: 996,411,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 996411608...
Checkpoint 996411608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201.85067
Policy Entropy: 3.07480
Value Function Loss: 0.00514

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.10427
Policy Update Magnitude: 0.55862
Value Function Update Magnitude: 0.55792

Collected Steps per Second: 22,862.31588
Overall Steps per Second: 10,669.45361

Timestep Collection Time: 2.18805
Timestep Consumption Time: 2.50047
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.68852

Cumulative Model Updates: 119,488
Cumulative Timesteps: 996,461,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 803.51271
Policy Entropy: 3.07460
Value Function Loss: 0.00547

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.10718
Policy Update Magnitude: 0.56546
Value Function Update Magnitude: 0.56646

Collected Steps per Second: 23,150.12401
Overall Steps per Second: 10,909.73685

Timestep Collection Time: 2.16033
Timestep Consumption Time: 2.42383
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.58416

Cumulative Model Updates: 119,494
Cumulative Timesteps: 996,511,644

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 996511644...
Checkpoint 996511644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,613.75037
Policy Entropy: 3.05030
Value Function Loss: 0.00544

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.09920
Policy Update Magnitude: 0.57243
Value Function Update Magnitude: 0.58613

Collected Steps per Second: 22,787.07309
Overall Steps per Second: 10,673.67962

Timestep Collection Time: 2.19484
Timestep Consumption Time: 2.49089
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.68573

Cumulative Model Updates: 119,500
Cumulative Timesteps: 996,561,658

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 634.36772
Policy Entropy: 3.04849
Value Function Loss: 0.00542

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.58243
Value Function Update Magnitude: 0.59487

Collected Steps per Second: 22,766.78279
Overall Steps per Second: 10,782.71562

Timestep Collection Time: 2.19662
Timestep Consumption Time: 2.44136
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.63798

Cumulative Model Updates: 119,506
Cumulative Timesteps: 996,611,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 996611668...
Checkpoint 996611668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542.98895
Policy Entropy: 3.06063
Value Function Loss: 0.00516

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.10315
Policy Update Magnitude: 0.56376
Value Function Update Magnitude: 0.59409

Collected Steps per Second: 22,654.79470
Overall Steps per Second: 10,687.39105

Timestep Collection Time: 2.20713
Timestep Consumption Time: 2.47147
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.67860

Cumulative Model Updates: 119,512
Cumulative Timesteps: 996,661,670

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,652.85480
Policy Entropy: 3.07950
Value Function Loss: 0.00533

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.55260
Value Function Update Magnitude: 0.58203

Collected Steps per Second: 22,924.08736
Overall Steps per Second: 10,848.21504

Timestep Collection Time: 2.18129
Timestep Consumption Time: 2.42814
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.60942

Cumulative Model Updates: 119,518
Cumulative Timesteps: 996,711,674

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 996711674...
Checkpoint 996711674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 762.48148
Policy Entropy: 3.07812
Value Function Loss: 0.00557

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.55165
Value Function Update Magnitude: 0.57672

Collected Steps per Second: 22,764.71030
Overall Steps per Second: 10,719.67585

Timestep Collection Time: 2.19717
Timestep Consumption Time: 2.46883
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.66600

Cumulative Model Updates: 119,524
Cumulative Timesteps: 996,761,692

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,051.23659
Policy Entropy: 3.07306
Value Function Loss: 0.00568

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.10933
Policy Update Magnitude: 0.55118
Value Function Update Magnitude: 0.56903

Collected Steps per Second: 22,930.58571
Overall Steps per Second: 10,858.34678

Timestep Collection Time: 2.18093
Timestep Consumption Time: 2.42474
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.60567

Cumulative Model Updates: 119,530
Cumulative Timesteps: 996,811,702

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 996811702...
Checkpoint 996811702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 838.03485
Policy Entropy: 3.06819
Value Function Loss: 0.00554

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.09951
Policy Update Magnitude: 0.55309
Value Function Update Magnitude: 0.56047

Collected Steps per Second: 22,612.74323
Overall Steps per Second: 10,686.87561

Timestep Collection Time: 2.21229
Timestep Consumption Time: 2.46878
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.68107

Cumulative Model Updates: 119,536
Cumulative Timesteps: 996,861,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 773.80295
Policy Entropy: 3.05858
Value Function Loss: 0.00544

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.10434
Policy Update Magnitude: 0.54844
Value Function Update Magnitude: 0.55722

Collected Steps per Second: 22,920.64123
Overall Steps per Second: 10,831.71413

Timestep Collection Time: 2.18153
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.61626

Cumulative Model Updates: 119,542
Cumulative Timesteps: 996,911,730

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 996911730...
Checkpoint 996911730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426.60578
Policy Entropy: 3.05283
Value Function Loss: 0.00543

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.55621
Value Function Update Magnitude: 0.56086

Collected Steps per Second: 22,794.54047
Overall Steps per Second: 10,699.57208

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.67402

Cumulative Model Updates: 119,548
Cumulative Timesteps: 996,961,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,525.85244
Policy Entropy: 3.04556
Value Function Loss: 0.00548

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.10976
Policy Update Magnitude: 0.56075
Value Function Update Magnitude: 0.55143

Collected Steps per Second: 23,096.08601
Overall Steps per Second: 10,875.19565

Timestep Collection Time: 2.16608
Timestep Consumption Time: 2.43411
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.60019

Cumulative Model Updates: 119,554
Cumulative Timesteps: 997,011,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 997011768...
Checkpoint 997011768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,184.90094
Policy Entropy: 3.04836
Value Function Loss: 0.00536

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.55529
Value Function Update Magnitude: 0.56283

Collected Steps per Second: 22,460.65602
Overall Steps per Second: 10,693.32807

Timestep Collection Time: 2.22701
Timestep Consumption Time: 2.45068
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.67768

Cumulative Model Updates: 119,560
Cumulative Timesteps: 997,061,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 849.70699
Policy Entropy: 3.05397
Value Function Loss: 0.00543

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.55263
Value Function Update Magnitude: 0.56104

Collected Steps per Second: 23,138.47397
Overall Steps per Second: 10,919.73896

Timestep Collection Time: 2.16211
Timestep Consumption Time: 2.41931
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.58143

Cumulative Model Updates: 119,566
Cumulative Timesteps: 997,111,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 997111816...
Checkpoint 997111816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,577.14492
Policy Entropy: 3.06955
Value Function Loss: 0.00569

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.56234
Value Function Update Magnitude: 0.56709

Collected Steps per Second: 22,648.85176
Overall Steps per Second: 10,639.27433

Timestep Collection Time: 2.20885
Timestep Consumption Time: 2.49335
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.70220

Cumulative Model Updates: 119,572
Cumulative Timesteps: 997,161,844

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,005.27744
Policy Entropy: 3.07139
Value Function Loss: 0.00567

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.56485
Value Function Update Magnitude: 0.58387

Collected Steps per Second: 22,889.42701
Overall Steps per Second: 10,810.89213

Timestep Collection Time: 2.18503
Timestep Consumption Time: 2.44123
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.62626

Cumulative Model Updates: 119,578
Cumulative Timesteps: 997,211,858

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 997211858...
Checkpoint 997211858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660.39296
Policy Entropy: 3.07067
Value Function Loss: 0.00562

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.56422
Value Function Update Magnitude: 0.60947

Collected Steps per Second: 22,559.48256
Overall Steps per Second: 10,732.96823

Timestep Collection Time: 2.21752
Timestep Consumption Time: 2.44345
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.66097

Cumulative Model Updates: 119,584
Cumulative Timesteps: 997,261,884

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,268.85846
Policy Entropy: 3.06415
Value Function Loss: 0.00579

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.11003
Policy Update Magnitude: 0.56558
Value Function Update Magnitude: 0.60315

Collected Steps per Second: 22,805.29060
Overall Steps per Second: 10,815.31989

Timestep Collection Time: 2.19300
Timestep Consumption Time: 2.43118
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.62418

Cumulative Model Updates: 119,590
Cumulative Timesteps: 997,311,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 997311896...
Checkpoint 997311896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,213.85851
Policy Entropy: 3.07247
Value Function Loss: 0.00560

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.09963
Policy Update Magnitude: 0.57030
Value Function Update Magnitude: 0.61845

Collected Steps per Second: 22,920.89728
Overall Steps per Second: 10,725.08231

Timestep Collection Time: 2.18176
Timestep Consumption Time: 2.48095
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.66271

Cumulative Model Updates: 119,596
Cumulative Timesteps: 997,361,904

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,687.58707
Policy Entropy: 3.07815
Value Function Loss: 0.00539

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.56188
Value Function Update Magnitude: 0.63301

Collected Steps per Second: 23,020.52994
Overall Steps per Second: 10,851.35959

Timestep Collection Time: 2.17250
Timestep Consumption Time: 2.43633
PPO Batch Consumption Time: 0.28254
Total Iteration Time: 4.60882

Cumulative Model Updates: 119,602
Cumulative Timesteps: 997,411,916

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 997411916...
Checkpoint 997411916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 968.36798
Policy Entropy: 3.09847
Value Function Loss: 0.00500

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.55105
Value Function Update Magnitude: 0.63190

Collected Steps per Second: 22,930.24334
Overall Steps per Second: 10,698.11329

Timestep Collection Time: 2.18070
Timestep Consumption Time: 2.49339
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.67410

Cumulative Model Updates: 119,608
Cumulative Timesteps: 997,461,920

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565.10996
Policy Entropy: 3.10301
Value Function Loss: 0.00485

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.09524
Policy Update Magnitude: 0.54651
Value Function Update Magnitude: 0.62770

Collected Steps per Second: 22,879.78976
Overall Steps per Second: 10,854.23078

Timestep Collection Time: 2.18621
Timestep Consumption Time: 2.42213
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.60834

Cumulative Model Updates: 119,614
Cumulative Timesteps: 997,511,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 997511940...
Checkpoint 997511940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 862.85518
Policy Entropy: 3.10503
Value Function Loss: 0.00485

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.11001
Policy Update Magnitude: 0.53882
Value Function Update Magnitude: 0.62811

Collected Steps per Second: 22,609.98077
Overall Steps per Second: 10,686.09942

Timestep Collection Time: 2.21194
Timestep Consumption Time: 2.46816
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.68010

Cumulative Model Updates: 119,620
Cumulative Timesteps: 997,561,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 793.36324
Policy Entropy: 3.09733
Value Function Loss: 0.00513

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10079
Policy Update Magnitude: 0.54285
Value Function Update Magnitude: 0.61248

Collected Steps per Second: 23,102.46112
Overall Steps per Second: 10,865.98154

Timestep Collection Time: 2.16540
Timestep Consumption Time: 2.43851
PPO Batch Consumption Time: 0.28239
Total Iteration Time: 4.60391

Cumulative Model Updates: 119,626
Cumulative Timesteps: 997,611,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 997611978...
Checkpoint 997611978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 639.71095
Policy Entropy: 3.08943
Value Function Loss: 0.00536

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09607
Policy Update Magnitude: 0.55339
Value Function Update Magnitude: 0.60875

Collected Steps per Second: 22,716.67884
Overall Steps per Second: 10,698.86498

Timestep Collection Time: 2.20217
Timestep Consumption Time: 2.47365
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.67582

Cumulative Model Updates: 119,632
Cumulative Timesteps: 997,662,004

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.40403
Policy Entropy: 3.10826
Value Function Loss: 0.00548

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.09875
Policy Update Magnitude: 0.55935
Value Function Update Magnitude: 0.60810

Collected Steps per Second: 23,184.56494
Overall Steps per Second: 10,884.99739

Timestep Collection Time: 2.15712
Timestep Consumption Time: 2.43746
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.59458

Cumulative Model Updates: 119,638
Cumulative Timesteps: 997,712,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 997712016...
Checkpoint 997712016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,558.44269
Policy Entropy: 3.10924
Value Function Loss: 0.00535

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09630
Policy Update Magnitude: 0.54772
Value Function Update Magnitude: 0.60165

Collected Steps per Second: 22,282.43896
Overall Steps per Second: 10,687.45711

Timestep Collection Time: 2.24482
Timestep Consumption Time: 2.43544
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.68025

Cumulative Model Updates: 119,644
Cumulative Timesteps: 997,762,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,223.84231
Policy Entropy: 3.11228
Value Function Loss: 0.00530

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.08076
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 0.61874

Collected Steps per Second: 23,056.02292
Overall Steps per Second: 10,863.83095

Timestep Collection Time: 2.16932
Timestep Consumption Time: 2.43458
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.60390

Cumulative Model Updates: 119,650
Cumulative Timesteps: 997,812,052

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 997812052...
Checkpoint 997812052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,632.50484
Policy Entropy: 3.10991
Value Function Loss: 0.00523

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08897
Policy Update Magnitude: 0.55167
Value Function Update Magnitude: 0.63023

Collected Steps per Second: 22,783.55680
Overall Steps per Second: 10,670.55126

Timestep Collection Time: 2.19588
Timestep Consumption Time: 2.49272
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.68861

Cumulative Model Updates: 119,656
Cumulative Timesteps: 997,862,082

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815.41392
Policy Entropy: 3.09464
Value Function Loss: 0.00519

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.08917
Policy Update Magnitude: 0.55151
Value Function Update Magnitude: 0.62126

Collected Steps per Second: 22,849.52200
Overall Steps per Second: 10,823.61643

Timestep Collection Time: 2.18858
Timestep Consumption Time: 2.43169
PPO Batch Consumption Time: 0.28186
Total Iteration Time: 4.62027

Cumulative Model Updates: 119,662
Cumulative Timesteps: 997,912,090

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 997912090...
Checkpoint 997912090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.79497
Policy Entropy: 3.09173
Value Function Loss: 0.00518

Mean KL Divergence: 0.00838
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.55302
Value Function Update Magnitude: 0.60093

Collected Steps per Second: 22,637.80076
Overall Steps per Second: 10,747.55179

Timestep Collection Time: 2.20940
Timestep Consumption Time: 2.44431
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.65371

Cumulative Model Updates: 119,668
Cumulative Timesteps: 997,962,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 586.83586
Policy Entropy: 3.07622
Value Function Loss: 0.00517

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.09673
Policy Update Magnitude: 0.55190
Value Function Update Magnitude: 0.57129

Collected Steps per Second: 22,978.81679
Overall Steps per Second: 10,854.02458

Timestep Collection Time: 2.17809
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.61119

Cumulative Model Updates: 119,674
Cumulative Timesteps: 998,012,156

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 998012156...
Checkpoint 998012156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,172.19981
Policy Entropy: 3.08811
Value Function Loss: 0.00524

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.09615
Policy Update Magnitude: 0.54397
Value Function Update Magnitude: 0.54908

Collected Steps per Second: 22,718.07735
Overall Steps per Second: 10,683.85903

Timestep Collection Time: 2.20195
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.68220

Cumulative Model Updates: 119,680
Cumulative Timesteps: 998,062,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 721.11401
Policy Entropy: 3.08245
Value Function Loss: 0.00538

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.10110
Policy Update Magnitude: 0.54377
Value Function Update Magnitude: 0.55408

Collected Steps per Second: 22,948.35002
Overall Steps per Second: 10,862.19215

Timestep Collection Time: 2.17950
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.60460

Cumulative Model Updates: 119,686
Cumulative Timesteps: 998,112,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 998112196...
Checkpoint 998112196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,221.24856
Policy Entropy: 3.08349
Value Function Loss: 0.00539

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.10297
Policy Update Magnitude: 0.54405
Value Function Update Magnitude: 0.58087

Collected Steps per Second: 22,352.90621
Overall Steps per Second: 10,691.67971

Timestep Collection Time: 2.23720
Timestep Consumption Time: 2.44008
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.67728

Cumulative Model Updates: 119,692
Cumulative Timesteps: 998,162,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846.00946
Policy Entropy: 3.07804
Value Function Loss: 0.00567

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.56006
Value Function Update Magnitude: 0.58416

Collected Steps per Second: 22,875.37239
Overall Steps per Second: 10,833.84784

Timestep Collection Time: 2.18672
Timestep Consumption Time: 2.43048
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.61720

Cumulative Model Updates: 119,698
Cumulative Timesteps: 998,212,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 998212226...
Checkpoint 998212226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 802.24646
Policy Entropy: 3.07429
Value Function Loss: 0.00550

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.11638
Policy Update Magnitude: 0.56629
Value Function Update Magnitude: 0.59013

Collected Steps per Second: 22,464.26947
Overall Steps per Second: 10,736.04300

Timestep Collection Time: 2.22700
Timestep Consumption Time: 2.43281
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.65982

Cumulative Model Updates: 119,704
Cumulative Timesteps: 998,262,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,261.64310
Policy Entropy: 3.07985
Value Function Loss: 0.00518

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.12013
Policy Update Magnitude: 0.56138
Value Function Update Magnitude: 0.58828

Collected Steps per Second: 23,177.98824
Overall Steps per Second: 10,907.55378

Timestep Collection Time: 2.15834
Timestep Consumption Time: 2.42802
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.58636

Cumulative Model Updates: 119,710
Cumulative Timesteps: 998,312,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 998312280...
Checkpoint 998312280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,263.09006
Policy Entropy: 3.07487
Value Function Loss: 0.00542

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.55934
Value Function Update Magnitude: 0.57362

Collected Steps per Second: 22,573.54072
Overall Steps per Second: 10,614.17419

Timestep Collection Time: 2.21543
Timestep Consumption Time: 2.49620
PPO Batch Consumption Time: 0.29434
Total Iteration Time: 4.71162

Cumulative Model Updates: 119,716
Cumulative Timesteps: 998,362,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 588.12926
Policy Entropy: 3.08147
Value Function Loss: 0.00546

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.55696
Value Function Update Magnitude: 0.56940

Collected Steps per Second: 23,052.72550
Overall Steps per Second: 10,848.30021

Timestep Collection Time: 2.17024
Timestep Consumption Time: 2.44154
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.61178

Cumulative Model Updates: 119,722
Cumulative Timesteps: 998,412,320

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 998412320...
Checkpoint 998412320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 855.55466
Policy Entropy: 3.07401
Value Function Loss: 0.00584

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.11248
Policy Update Magnitude: 0.55642
Value Function Update Magnitude: 0.56141

Collected Steps per Second: 22,666.53510
Overall Steps per Second: 10,723.17028

Timestep Collection Time: 2.20625
Timestep Consumption Time: 2.45730
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.66355

Cumulative Model Updates: 119,728
Cumulative Timesteps: 998,462,328

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.24276
Policy Entropy: 3.08558
Value Function Loss: 0.00548

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.55146
Value Function Update Magnitude: 0.56343

Collected Steps per Second: 23,099.91596
Overall Steps per Second: 10,859.88606

Timestep Collection Time: 2.16468
Timestep Consumption Time: 2.43979
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.60447

Cumulative Model Updates: 119,734
Cumulative Timesteps: 998,512,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 998512332...
Checkpoint 998512332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,626.62764
Policy Entropy: 3.07658
Value Function Loss: 0.00547

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.55504
Value Function Update Magnitude: 0.57968

Collected Steps per Second: 22,420.75900
Overall Steps per Second: 10,663.73013

Timestep Collection Time: 2.23141
Timestep Consumption Time: 2.46019
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.69160

Cumulative Model Updates: 119,740
Cumulative Timesteps: 998,562,362

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 943.85751
Policy Entropy: 3.09275
Value Function Loss: 0.00528

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.55916
Value Function Update Magnitude: 0.61701

Collected Steps per Second: 22,887.41279
Overall Steps per Second: 10,825.28436

Timestep Collection Time: 2.18574
Timestep Consumption Time: 2.43548
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.62122

Cumulative Model Updates: 119,746
Cumulative Timesteps: 998,612,388

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 998612388...
Checkpoint 998612388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,428.89235
Policy Entropy: 3.09243
Value Function Loss: 0.00524

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10508
Policy Update Magnitude: 0.56147
Value Function Update Magnitude: 0.61519

Collected Steps per Second: 22,550.37410
Overall Steps per Second: 10,771.73736

Timestep Collection Time: 2.21832
Timestep Consumption Time: 2.42568
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.64400

Cumulative Model Updates: 119,752
Cumulative Timesteps: 998,662,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608.33751
Policy Entropy: 3.11625
Value Function Loss: 0.00546

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09170
Policy Update Magnitude: 0.56228
Value Function Update Magnitude: 0.62276

Collected Steps per Second: 22,853.48241
Overall Steps per Second: 10,837.98233

Timestep Collection Time: 2.18803
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.61377

Cumulative Model Updates: 119,758
Cumulative Timesteps: 998,712,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 998712416...
Checkpoint 998712416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 930.19461
Policy Entropy: 3.12505
Value Function Loss: 0.00558

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.09290
Policy Update Magnitude: 0.56150
Value Function Update Magnitude: 0.63744

Collected Steps per Second: 22,510.26440
Overall Steps per Second: 10,651.24960

Timestep Collection Time: 2.22210
Timestep Consumption Time: 2.47407
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.69616

Cumulative Model Updates: 119,764
Cumulative Timesteps: 998,762,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,166.43675
Policy Entropy: 3.11655
Value Function Loss: 0.00537

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.09961
Policy Update Magnitude: 0.55938
Value Function Update Magnitude: 0.66058

Collected Steps per Second: 22,926.90600
Overall Steps per Second: 10,863.88785

Timestep Collection Time: 2.18119
Timestep Consumption Time: 2.42195
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.60314

Cumulative Model Updates: 119,770
Cumulative Timesteps: 998,812,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 998812444...
Checkpoint 998812444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,298.41479
Policy Entropy: 3.11490
Value Function Loss: 0.00521

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.55282
Value Function Update Magnitude: 0.66211

Collected Steps per Second: 22,788.72151
Overall Steps per Second: 10,672.51317

Timestep Collection Time: 2.19547
Timestep Consumption Time: 2.49246
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.68793

Cumulative Model Updates: 119,776
Cumulative Timesteps: 998,862,476

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 775.80490
Policy Entropy: 3.11465
Value Function Loss: 0.00536

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.56044
Value Function Update Magnitude: 0.64857

Collected Steps per Second: 22,918.12207
Overall Steps per Second: 10,846.57912

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.42933
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.61215

Cumulative Model Updates: 119,782
Cumulative Timesteps: 998,912,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 998912502...
Checkpoint 998912502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 929.86175
Policy Entropy: 3.12843
Value Function Loss: 0.00532

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.55580
Value Function Update Magnitude: 0.65112

Collected Steps per Second: 22,443.04412
Overall Steps per Second: 10,772.98342

Timestep Collection Time: 2.22866
Timestep Consumption Time: 2.41425
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.64291

Cumulative Model Updates: 119,788
Cumulative Timesteps: 998,962,520

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,280.84254
Policy Entropy: 3.13379
Value Function Loss: 0.00520

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.09003
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.64436

Collected Steps per Second: 22,726.50756
Overall Steps per Second: 10,779.17511

Timestep Collection Time: 2.20095
Timestep Consumption Time: 2.43948
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.64043

Cumulative Model Updates: 119,794
Cumulative Timesteps: 999,012,540

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 999012540...
Checkpoint 999012540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 849.27331
Policy Entropy: 3.14174
Value Function Loss: 0.00482

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.08693
Policy Update Magnitude: 0.54009
Value Function Update Magnitude: 0.61191

Collected Steps per Second: 22,630.93405
Overall Steps per Second: 10,768.10889

Timestep Collection Time: 2.21104
Timestep Consumption Time: 2.43583
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.64687

Cumulative Model Updates: 119,800
Cumulative Timesteps: 999,062,578

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911.60192
Policy Entropy: 3.13514
Value Function Loss: 0.00483

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.52847
Value Function Update Magnitude: 0.58814

Collected Steps per Second: 23,006.24788
Overall Steps per Second: 10,835.94451

Timestep Collection Time: 2.17341
Timestep Consumption Time: 2.44105
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.61446

Cumulative Model Updates: 119,806
Cumulative Timesteps: 999,112,580

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 999112580...
Checkpoint 999112580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,936.28774
Policy Entropy: 3.14555
Value Function Loss: 0.00483

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.09250
Policy Update Magnitude: 0.52752
Value Function Update Magnitude: 0.58784

Collected Steps per Second: 22,634.46845
Overall Steps per Second: 10,701.54499

Timestep Collection Time: 2.21035
Timestep Consumption Time: 2.46468
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.67503

Cumulative Model Updates: 119,812
Cumulative Timesteps: 999,162,610

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.52941
Policy Entropy: 3.14905
Value Function Loss: 0.00489

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.52847
Value Function Update Magnitude: 0.59791

Collected Steps per Second: 22,794.71623
Overall Steps per Second: 10,811.54468

Timestep Collection Time: 2.19463
Timestep Consumption Time: 2.43246
PPO Batch Consumption Time: 0.28234
Total Iteration Time: 4.62709

Cumulative Model Updates: 119,818
Cumulative Timesteps: 999,212,636

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 999212636...
Checkpoint 999212636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,686.31286
Policy Entropy: 3.14198
Value Function Loss: 0.00505

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.53910
Value Function Update Magnitude: 0.60949

Collected Steps per Second: 22,537.23274
Overall Steps per Second: 10,695.14417

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.45696
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.67595

Cumulative Model Updates: 119,824
Cumulative Timesteps: 999,262,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 996.20081
Policy Entropy: 3.14295
Value Function Loss: 0.00504

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09735
Policy Update Magnitude: 0.54514
Value Function Update Magnitude: 0.61853

Collected Steps per Second: 22,703.62484
Overall Steps per Second: 10,686.23610

Timestep Collection Time: 2.20229
Timestep Consumption Time: 2.47662
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.67892

Cumulative Model Updates: 119,830
Cumulative Timesteps: 999,312,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 999312646...
Checkpoint 999312646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 626.92596
Policy Entropy: 3.12525
Value Function Loss: 0.00534

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.09882
Policy Update Magnitude: 0.55095
Value Function Update Magnitude: 0.60691

Collected Steps per Second: 22,903.16079
Overall Steps per Second: 10,836.73574

Timestep Collection Time: 2.18459
Timestep Consumption Time: 2.43248
PPO Batch Consumption Time: 0.28240
Total Iteration Time: 4.61707

Cumulative Model Updates: 119,836
Cumulative Timesteps: 999,362,680

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 901.78363
Policy Entropy: 3.12409
Value Function Loss: 0.00525

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.10487
Policy Update Magnitude: 0.55327
Value Function Update Magnitude: 0.62356

Collected Steps per Second: 22,666.22457
Overall Steps per Second: 10,588.15875

Timestep Collection Time: 2.20645
Timestep Consumption Time: 2.51693
PPO Batch Consumption Time: 0.29463
Total Iteration Time: 4.72339

Cumulative Model Updates: 119,842
Cumulative Timesteps: 999,412,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 999412692...
Checkpoint 999412692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510.75222
Policy Entropy: 3.11457
Value Function Loss: 0.00546

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.10846
Policy Update Magnitude: 0.55300
Value Function Update Magnitude: 0.61299

Collected Steps per Second: 22,796.53091
Overall Steps per Second: 10,707.51558

Timestep Collection Time: 2.19446
Timestep Consumption Time: 2.47759
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.67205

Cumulative Model Updates: 119,848
Cumulative Timesteps: 999,462,718

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 871.05539
Policy Entropy: 3.11701
Value Function Loss: 0.00523

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.09899
Policy Update Magnitude: 0.55153
Value Function Update Magnitude: 0.61276

Collected Steps per Second: 23,131.01051
Overall Steps per Second: 10,765.17789

Timestep Collection Time: 2.16264
Timestep Consumption Time: 2.48420
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.64683

Cumulative Model Updates: 119,854
Cumulative Timesteps: 999,512,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 999512742...
Checkpoint 999512742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.28831
Policy Entropy: 3.11421
Value Function Loss: 0.00505

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.54177
Value Function Update Magnitude: 0.61200

Collected Steps per Second: 22,555.73635
Overall Steps per Second: 10,645.34146

Timestep Collection Time: 2.21673
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.69689

Cumulative Model Updates: 119,860
Cumulative Timesteps: 999,562,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 664.39059
Policy Entropy: 3.11091
Value Function Loss: 0.00497

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09363
Policy Update Magnitude: 0.54524
Value Function Update Magnitude: 0.60915

Collected Steps per Second: 23,241.60505
Overall Steps per Second: 10,925.12049

Timestep Collection Time: 2.15243
Timestep Consumption Time: 2.42656
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.57899

Cumulative Model Updates: 119,866
Cumulative Timesteps: 999,612,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 999612768...
Checkpoint 999612768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 738.00856
Policy Entropy: 3.11231
Value Function Loss: 0.00511

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.10444
Policy Update Magnitude: 0.55155
Value Function Update Magnitude: 0.60327

Collected Steps per Second: 22,885.57273
Overall Steps per Second: 10,998.54553

Timestep Collection Time: 2.18531
Timestep Consumption Time: 2.36184
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.54715

Cumulative Model Updates: 119,872
Cumulative Timesteps: 999,662,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.97287
Policy Entropy: 3.11541
Value Function Loss: 0.00555

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.10598
Policy Update Magnitude: 0.56055
Value Function Update Magnitude: 0.62261

Collected Steps per Second: 22,303.29140
Overall Steps per Second: 10,709.17958

Timestep Collection Time: 2.24209
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.66945

Cumulative Model Updates: 119,878
Cumulative Timesteps: 999,712,786

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 999712786...
Checkpoint 999712786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 893.82420
Policy Entropy: 3.13337
Value Function Loss: 0.00555

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.11232
Policy Update Magnitude: 0.56556
Value Function Update Magnitude: 0.63144

Collected Steps per Second: 22,180.60040
Overall Steps per Second: 10,828.45778

Timestep Collection Time: 2.25485
Timestep Consumption Time: 2.36390
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.61876

Cumulative Model Updates: 119,884
Cumulative Timesteps: 999,762,800

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 801.26641
Policy Entropy: 3.13333
Value Function Loss: 0.00530

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.11105
Policy Update Magnitude: 0.55747
Value Function Update Magnitude: 0.62372

Collected Steps per Second: 22,349.07816
Overall Steps per Second: 10,716.79520

Timestep Collection Time: 2.23839
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.66800

Cumulative Model Updates: 119,890
Cumulative Timesteps: 999,812,826

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 999812826...
Checkpoint 999812826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,437.05666
Policy Entropy: 3.13459
Value Function Loss: 0.00502

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.10455
Policy Update Magnitude: 0.55401
Value Function Update Magnitude: 0.60913

Collected Steps per Second: 22,246.04276
Overall Steps per Second: 10,825.90633

Timestep Collection Time: 2.24876
Timestep Consumption Time: 2.37219
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.62095

Cumulative Model Updates: 119,896
Cumulative Timesteps: 999,862,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824.94633
Policy Entropy: 3.13286
Value Function Loss: 0.00485

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.10902
Policy Update Magnitude: 0.55636
Value Function Update Magnitude: 0.59179

Collected Steps per Second: 22,100.81302
Overall Steps per Second: 10,628.38035

Timestep Collection Time: 2.26254
Timestep Consumption Time: 2.44222
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.70476

Cumulative Model Updates: 119,902
Cumulative Timesteps: 999,912,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 999912856...
Checkpoint 999912856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 511.46192
Policy Entropy: 3.13369
Value Function Loss: 0.00480

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.11748
Policy Update Magnitude: 0.54824
Value Function Update Magnitude: 0.58296

Collected Steps per Second: 22,120.15830
Overall Steps per Second: 10,643.86055

Timestep Collection Time: 2.26065
Timestep Consumption Time: 2.43745
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.69811

Cumulative Model Updates: 119,908
Cumulative Timesteps: 999,962,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,087.37595
Policy Entropy: 3.12191
Value Function Loss: 0.00508

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11297
Policy Update Magnitude: 0.54604
Value Function Update Magnitude: 0.59047

Collected Steps per Second: 22,220.58652
Overall Steps per Second: 10,806.99301

Timestep Collection Time: 2.25116
Timestep Consumption Time: 2.37751
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.62867

Cumulative Model Updates: 119,914
Cumulative Timesteps: 1,000,012,884

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1000012884...
Checkpoint 1000012884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,054.93907
Policy Entropy: 3.12606
Value Function Loss: 0.00541

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.55192
Value Function Update Magnitude: 0.60288

Collected Steps per Second: 22,052.98802
Overall Steps per Second: 10,599.00462

Timestep Collection Time: 2.26781
Timestep Consumption Time: 2.45075
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.71856

Cumulative Model Updates: 119,920
Cumulative Timesteps: 1,000,062,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 992.56687
Policy Entropy: 3.11250
Value Function Loss: 0.00558

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.11447
Policy Update Magnitude: 0.55597
Value Function Update Magnitude: 0.59996

Collected Steps per Second: 22,291.14299
Overall Steps per Second: 10,710.94468

Timestep Collection Time: 2.24367
Timestep Consumption Time: 2.42576
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.66943

Cumulative Model Updates: 119,926
Cumulative Timesteps: 1,000,112,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1000112910...
Checkpoint 1000112910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,634.28029
Policy Entropy: 3.11360
Value Function Loss: 0.00542

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.09781
Policy Update Magnitude: 0.55073
Value Function Update Magnitude: 0.59416

Collected Steps per Second: 21,924.29844
Overall Steps per Second: 10,583.53229

Timestep Collection Time: 2.28103
Timestep Consumption Time: 2.44423
PPO Batch Consumption Time: 0.29442
Total Iteration Time: 4.72527

Cumulative Model Updates: 119,932
Cumulative Timesteps: 1,000,162,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 744.38874
Policy Entropy: 3.09734
Value Function Loss: 0.00549

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.10813
Policy Update Magnitude: 0.55224
Value Function Update Magnitude: 0.58629

Collected Steps per Second: 23,397.78365
Overall Steps per Second: 10,745.61789

Timestep Collection Time: 2.13789
Timestep Consumption Time: 2.51721
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.65511

Cumulative Model Updates: 119,938
Cumulative Timesteps: 1,000,212,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1000212942...
Checkpoint 1000212942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425.05748
Policy Entropy: 3.09373
Value Function Loss: 0.00553

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.11155
Policy Update Magnitude: 0.55215
Value Function Update Magnitude: 0.59760

Collected Steps per Second: 22,637.57581
Overall Steps per Second: 10,683.36206

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.68223

Cumulative Model Updates: 119,944
Cumulative Timesteps: 1,000,262,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.59058
Policy Entropy: 3.09528
Value Function Loss: 0.00571

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.55804
Value Function Update Magnitude: 0.59840

Collected Steps per Second: 23,213.83542
Overall Steps per Second: 10,803.41212

Timestep Collection Time: 2.15415
Timestep Consumption Time: 2.47458
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.62872

Cumulative Model Updates: 119,950
Cumulative Timesteps: 1,000,312,970

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1000312970...
Checkpoint 1000312970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 877.17398
Policy Entropy: 3.10690
Value Function Loss: 0.00612

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.11202
Policy Update Magnitude: 0.56372
Value Function Update Magnitude: 0.58916

Collected Steps per Second: 22,734.57142
Overall Steps per Second: 10,737.19907

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.45781
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.65745

Cumulative Model Updates: 119,956
Cumulative Timesteps: 1,000,362,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 889.73697
Policy Entropy: 3.10378
Value Function Loss: 0.00568

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.10855
Policy Update Magnitude: 0.56647
Value Function Update Magnitude: 0.60443

Collected Steps per Second: 22,953.21868
Overall Steps per Second: 10,797.21254

Timestep Collection Time: 2.17904
Timestep Consumption Time: 2.45327
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.63231

Cumulative Model Updates: 119,962
Cumulative Timesteps: 1,000,412,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1000412994...
Checkpoint 1000412994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,326.77289
Policy Entropy: 3.10183
Value Function Loss: 0.00547

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.10660
Policy Update Magnitude: 0.55888
Value Function Update Magnitude: 0.60588

Collected Steps per Second: 22,966.02950
Overall Steps per Second: 10,749.21481

Timestep Collection Time: 2.17722
Timestep Consumption Time: 2.47447
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.65169

Cumulative Model Updates: 119,968
Cumulative Timesteps: 1,000,462,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.12756
Policy Entropy: 3.09278
Value Function Loss: 0.00548

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.10245
Policy Update Magnitude: 0.56283
Value Function Update Magnitude: 0.58964

Collected Steps per Second: 23,073.91649
Overall Steps per Second: 10,832.44789

Timestep Collection Time: 2.16730
Timestep Consumption Time: 2.44920
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.61650

Cumulative Model Updates: 119,974
Cumulative Timesteps: 1,000,513,004

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1000513004...
Checkpoint 1000513004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061.14071
Policy Entropy: 3.10096
Value Function Loss: 0.00532

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.56717
Value Function Update Magnitude: 0.57601

Collected Steps per Second: 22,739.52024
Overall Steps per Second: 10,710.06355

Timestep Collection Time: 2.19952
Timestep Consumption Time: 2.47048
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.67000

Cumulative Model Updates: 119,980
Cumulative Timesteps: 1,000,563,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,317.77839
Policy Entropy: 3.11051
Value Function Loss: 0.00528

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.10443
Policy Update Magnitude: 0.56012
Value Function Update Magnitude: 0.56461

Collected Steps per Second: 22,795.85050
Overall Steps per Second: 10,702.58630

Timestep Collection Time: 2.19452
Timestep Consumption Time: 2.47968
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.67420

Cumulative Model Updates: 119,986
Cumulative Timesteps: 1,000,613,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1000613046...
Checkpoint 1000613046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 790.63930
Policy Entropy: 3.10935
Value Function Loss: 0.00492

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.10092
Policy Update Magnitude: 0.55461
Value Function Update Magnitude: 0.55497

Collected Steps per Second: 23,064.90501
Overall Steps per Second: 10,862.93407

Timestep Collection Time: 2.16840
Timestep Consumption Time: 2.43569
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.60410

Cumulative Model Updates: 119,992
Cumulative Timesteps: 1,000,663,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,714.26386
Policy Entropy: 3.10816
Value Function Loss: 0.00496

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.09968
Policy Update Magnitude: 0.56168
Value Function Update Magnitude: 0.55262

Collected Steps per Second: 22,974.77860
Overall Steps per Second: 10,845.66923

Timestep Collection Time: 2.17691
Timestep Consumption Time: 2.43452
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.61143

Cumulative Model Updates: 119,998
Cumulative Timesteps: 1,000,713,074

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1000713074...
Checkpoint 1000713074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 874.30754
Policy Entropy: 3.11834
Value Function Loss: 0.00496

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.10748
Policy Update Magnitude: 0.55742
Value Function Update Magnitude: 0.57439

Collected Steps per Second: 22,604.45432
Overall Steps per Second: 10,676.13942

Timestep Collection Time: 2.21284
Timestep Consumption Time: 2.47238
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.68521

Cumulative Model Updates: 120,004
Cumulative Timesteps: 1,000,763,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791.17973
Policy Entropy: 3.13042
Value Function Loss: 0.00477

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.54970
Value Function Update Magnitude: 0.58705

Collected Steps per Second: 22,813.21903
Overall Steps per Second: 10,624.83267

Timestep Collection Time: 2.19294
Timestep Consumption Time: 2.51565
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.70859

Cumulative Model Updates: 120,010
Cumulative Timesteps: 1,000,813,122

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1000813122...
Checkpoint 1000813122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,010.15771
Policy Entropy: 3.12366
Value Function Loss: 0.00514

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.55523
Value Function Update Magnitude: 0.58159

Collected Steps per Second: 23,024.87421
Overall Steps per Second: 10,855.96818

Timestep Collection Time: 2.17278
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.60834

Cumulative Model Updates: 120,016
Cumulative Timesteps: 1,000,863,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570.44625
Policy Entropy: 3.11514
Value Function Loss: 0.00517

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.09726
Policy Update Magnitude: 0.55379
Value Function Update Magnitude: 0.57608

Collected Steps per Second: 23,151.99931
Overall Steps per Second: 10,741.59463

Timestep Collection Time: 2.16025
Timestep Consumption Time: 2.49586
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.65611

Cumulative Model Updates: 120,022
Cumulative Timesteps: 1,000,913,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1000913164...
Checkpoint 1000913164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,182.24304
Policy Entropy: 3.12044
Value Function Loss: 0.00519

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.09668
Policy Update Magnitude: 0.54850
Value Function Update Magnitude: 0.56454

Collected Steps per Second: 22,830.78233
Overall Steps per Second: 10,794.06490

Timestep Collection Time: 2.19020
Timestep Consumption Time: 2.44234
PPO Batch Consumption Time: 0.28168
Total Iteration Time: 4.63255

Cumulative Model Updates: 120,028
Cumulative Timesteps: 1,000,963,168

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755.64013
Policy Entropy: 3.13873
Value Function Loss: 0.00505

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09429
Policy Update Magnitude: 0.54841
Value Function Update Magnitude: 0.56375

Collected Steps per Second: 22,912.56882
Overall Steps per Second: 10,631.28731

Timestep Collection Time: 2.18291
Timestep Consumption Time: 2.52170
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.70460

Cumulative Model Updates: 120,034
Cumulative Timesteps: 1,001,013,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1001013184...
Checkpoint 1001013184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 918.19618
Policy Entropy: 3.14497
Value Function Loss: 0.00463

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.54214
Value Function Update Magnitude: 0.56599

Collected Steps per Second: 23,119.72714
Overall Steps per Second: 10,748.10471

Timestep Collection Time: 2.16291
Timestep Consumption Time: 2.48963
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.65254

Cumulative Model Updates: 120,040
Cumulative Timesteps: 1,001,063,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 696.57440
Policy Entropy: 3.12766
Value Function Loss: 0.00503

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.09198
Policy Update Magnitude: 0.53298
Value Function Update Magnitude: 0.53344

Collected Steps per Second: 23,322.89471
Overall Steps per Second: 10,724.74854

Timestep Collection Time: 2.14476
Timestep Consumption Time: 2.51941
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.66417

Cumulative Model Updates: 120,046
Cumulative Timesteps: 1,001,113,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1001113212...
Checkpoint 1001113212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,077.55212
Policy Entropy: 3.12207
Value Function Loss: 0.00522

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.09376
Policy Update Magnitude: 0.53563
Value Function Update Magnitude: 0.53302

Collected Steps per Second: 22,889.56264
Overall Steps per Second: 10,621.55329

Timestep Collection Time: 2.18484
Timestep Consumption Time: 2.52351
PPO Batch Consumption Time: 0.29539
Total Iteration Time: 4.70835

Cumulative Model Updates: 120,052
Cumulative Timesteps: 1,001,163,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,003.86193
Policy Entropy: 3.12222
Value Function Loss: 0.00519

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.54203
Value Function Update Magnitude: 0.54514

Collected Steps per Second: 23,154.30384
Overall Steps per Second: 10,859.51797

Timestep Collection Time: 2.16038
Timestep Consumption Time: 2.44591
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.60628

Cumulative Model Updates: 120,058
Cumulative Timesteps: 1,001,213,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1001213244...
Checkpoint 1001213244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 845.67921
Policy Entropy: 3.14357
Value Function Loss: 0.00509

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.07957
Policy Update Magnitude: 0.54548
Value Function Update Magnitude: 0.54890

Collected Steps per Second: 22,705.98285
Overall Steps per Second: 10,685.75448

Timestep Collection Time: 2.20303
Timestep Consumption Time: 2.47815
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.68119

Cumulative Model Updates: 120,064
Cumulative Timesteps: 1,001,263,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,031.54869
Policy Entropy: 3.13982
Value Function Loss: 0.00497

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.08236
Policy Update Magnitude: 0.54437
Value Function Update Magnitude: 0.54638

Collected Steps per Second: 23,196.40032
Overall Steps per Second: 10,880.82787

Timestep Collection Time: 2.15568
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.59561

Cumulative Model Updates: 120,070
Cumulative Timesteps: 1,001,313,270

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1001313270...
Checkpoint 1001313270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 625.87471
Policy Entropy: 3.13804
Value Function Loss: 0.00513

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09149
Policy Update Magnitude: 0.54253
Value Function Update Magnitude: 0.55964

Collected Steps per Second: 22,431.14671
Overall Steps per Second: 10,688.54741

Timestep Collection Time: 2.23002
Timestep Consumption Time: 2.44994
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.67996

Cumulative Model Updates: 120,076
Cumulative Timesteps: 1,001,363,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,362.30316
Policy Entropy: 3.12907
Value Function Loss: 0.00511

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.55046
Value Function Update Magnitude: 0.56513

Collected Steps per Second: 23,094.07492
Overall Steps per Second: 10,815.13067

Timestep Collection Time: 2.16523
Timestep Consumption Time: 2.45829
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.62352

Cumulative Model Updates: 120,082
Cumulative Timesteps: 1,001,413,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1001413296...
Checkpoint 1001413296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671.17580
Policy Entropy: 3.10520
Value Function Loss: 0.00506

Mean KL Divergence: 0.00824
SB3 Clip Fraction: 0.08804
Policy Update Magnitude: 0.54965
Value Function Update Magnitude: 0.56078

Collected Steps per Second: 22,287.78093
Overall Steps per Second: 10,649.41145

Timestep Collection Time: 2.24464
Timestep Consumption Time: 2.45309
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.69772

Cumulative Model Updates: 120,088
Cumulative Timesteps: 1,001,463,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.51679
Policy Entropy: 3.11017
Value Function Loss: 0.00547

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.09382
Policy Update Magnitude: 0.55102
Value Function Update Magnitude: 0.56535

Collected Steps per Second: 23,132.73353
Overall Steps per Second: 10,732.14539

Timestep Collection Time: 2.16170
Timestep Consumption Time: 2.49776
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.65946

Cumulative Model Updates: 120,094
Cumulative Timesteps: 1,001,513,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1001513330...
Checkpoint 1001513330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,191.68973
Policy Entropy: 3.09809
Value Function Loss: 0.00549

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.10205
Policy Update Magnitude: 0.56402
Value Function Update Magnitude: 0.57827

Collected Steps per Second: 22,458.73098
Overall Steps per Second: 10,557.92800

Timestep Collection Time: 2.22773
Timestep Consumption Time: 2.51108
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.73881

Cumulative Model Updates: 120,100
Cumulative Timesteps: 1,001,563,362

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,068.47038
Policy Entropy: 3.10736
Value Function Loss: 0.00555

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.11144
Policy Update Magnitude: 0.57411
Value Function Update Magnitude: 0.58563

Collected Steps per Second: 22,686.48620
Overall Steps per Second: 10,690.05484

Timestep Collection Time: 2.20466
Timestep Consumption Time: 2.47408
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.67874

Cumulative Model Updates: 120,106
Cumulative Timesteps: 1,001,613,378

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1001613378...
Checkpoint 1001613378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 723.91779
Policy Entropy: 3.09016
Value Function Loss: 0.00565

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.12153
Policy Update Magnitude: 0.57889
Value Function Update Magnitude: 0.58668

Collected Steps per Second: 22,570.87970
Overall Steps per Second: 10,808.18920

Timestep Collection Time: 2.21578
Timestep Consumption Time: 2.41146
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.62723

Cumulative Model Updates: 120,112
Cumulative Timesteps: 1,001,663,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 961.38702
Policy Entropy: 3.10138
Value Function Loss: 0.00563

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.57574
Value Function Update Magnitude: 0.60586

Collected Steps per Second: 23,158.48731
Overall Steps per Second: 10,900.58762

Timestep Collection Time: 2.16007
Timestep Consumption Time: 2.42904
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.58911

Cumulative Model Updates: 120,118
Cumulative Timesteps: 1,001,713,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1001713414...
Checkpoint 1001713414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486.08961
Policy Entropy: 3.11056
Value Function Loss: 0.00540

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.12000
Policy Update Magnitude: 0.56914
Value Function Update Magnitude: 0.61155

Collected Steps per Second: 22,688.38337
Overall Steps per Second: 10,626.73969

Timestep Collection Time: 2.20456
Timestep Consumption Time: 2.50224
PPO Batch Consumption Time: 0.29702
Total Iteration Time: 4.70681

Cumulative Model Updates: 120,124
Cumulative Timesteps: 1,001,763,432

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 902.03023
Policy Entropy: 3.11473
Value Function Loss: 0.00527

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.55747
Value Function Update Magnitude: 0.59865

Collected Steps per Second: 22,948.90491
Overall Steps per Second: 10,851.99230

Timestep Collection Time: 2.17875
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.60745

Cumulative Model Updates: 120,130
Cumulative Timesteps: 1,001,813,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1001813432...
Checkpoint 1001813432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 847.93596
Policy Entropy: 3.11865
Value Function Loss: 0.00495

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.11087
Policy Update Magnitude: 0.55458
Value Function Update Magnitude: 0.59444

Collected Steps per Second: 22,756.50962
Overall Steps per Second: 10,682.12625

Timestep Collection Time: 2.19788
Timestep Consumption Time: 2.48434
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.68221

Cumulative Model Updates: 120,136
Cumulative Timesteps: 1,001,863,448

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,351.74864
Policy Entropy: 3.11430
Value Function Loss: 0.00528

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.09816
Policy Update Magnitude: 0.56529
Value Function Update Magnitude: 0.58838

Collected Steps per Second: 22,939.41151
Overall Steps per Second: 10,874.02953

Timestep Collection Time: 2.18009
Timestep Consumption Time: 2.41894
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.59903

Cumulative Model Updates: 120,142
Cumulative Timesteps: 1,001,913,458

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1001913458...
Checkpoint 1001913458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 777.22367
Policy Entropy: 3.12588
Value Function Loss: 0.00537

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.56605
Value Function Update Magnitude: 0.58610

Collected Steps per Second: 22,551.21335
Overall Steps per Second: 10,643.39561

Timestep Collection Time: 2.21718
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.69775

Cumulative Model Updates: 120,148
Cumulative Timesteps: 1,001,963,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 754.55639
Policy Entropy: 3.13555
Value Function Loss: 0.00559

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.09708
Policy Update Magnitude: 0.56305
Value Function Update Magnitude: 0.58769

Collected Steps per Second: 23,154.81669
Overall Steps per Second: 10,894.62354

Timestep Collection Time: 2.16016
Timestep Consumption Time: 2.43092
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.59107

Cumulative Model Updates: 120,154
Cumulative Timesteps: 1,002,013,476

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1002013476...
Checkpoint 1002013476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 823.19891
Policy Entropy: 3.15323
Value Function Loss: 0.00554

Mean KL Divergence: 0.00843
SB3 Clip Fraction: 0.09048
Policy Update Magnitude: 0.55754
Value Function Update Magnitude: 0.59212

Collected Steps per Second: 22,731.74275
Overall Steps per Second: 10,699.53363

Timestep Collection Time: 2.20001
Timestep Consumption Time: 2.47403
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.67404

Cumulative Model Updates: 120,160
Cumulative Timesteps: 1,002,063,486

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,001.44040
Policy Entropy: 3.15387
Value Function Loss: 0.00533

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.09480
Policy Update Magnitude: 0.55741
Value Function Update Magnitude: 0.59147

Collected Steps per Second: 23,073.66250
Overall Steps per Second: 10,907.99885

Timestep Collection Time: 2.16715
Timestep Consumption Time: 2.41701
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.58416

Cumulative Model Updates: 120,166
Cumulative Timesteps: 1,002,113,490

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1002113490...
Checkpoint 1002113490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 949.26638
Policy Entropy: 3.14974
Value Function Loss: 0.00503

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.09402
Policy Update Magnitude: 0.54546
Value Function Update Magnitude: 0.57258

Collected Steps per Second: 22,595.49449
Overall Steps per Second: 10,655.65008

Timestep Collection Time: 2.21398
Timestep Consumption Time: 2.48081
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.69479

Cumulative Model Updates: 120,172
Cumulative Timesteps: 1,002,163,516

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430.33713
Policy Entropy: 3.14418
Value Function Loss: 0.00528

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.10480
Policy Update Magnitude: 0.54490
Value Function Update Magnitude: 0.55711

Collected Steps per Second: 22,934.99857
Overall Steps per Second: 10,813.29192

Timestep Collection Time: 2.18130
Timestep Consumption Time: 2.44523
PPO Batch Consumption Time: 0.28372
Total Iteration Time: 4.62653

Cumulative Model Updates: 120,178
Cumulative Timesteps: 1,002,213,544

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1002213544...
Checkpoint 1002213544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 875.79147
Policy Entropy: 3.13608
Value Function Loss: 0.00532

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.55371
Value Function Update Magnitude: 0.56622

Collected Steps per Second: 22,627.48978
Overall Steps per Second: 10,693.31756

Timestep Collection Time: 2.21032
Timestep Consumption Time: 2.46681
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.67713

Cumulative Model Updates: 120,184
Cumulative Timesteps: 1,002,263,558

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,078.81613
Policy Entropy: 3.12397
Value Function Loss: 0.00562

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.09977
Policy Update Magnitude: 0.56507
Value Function Update Magnitude: 0.59236

Collected Steps per Second: 22,963.44223
Overall Steps per Second: 10,851.74642

Timestep Collection Time: 2.17755
Timestep Consumption Time: 2.43037
PPO Batch Consumption Time: 0.28225
Total Iteration Time: 4.60792

Cumulative Model Updates: 120,190
Cumulative Timesteps: 1,002,313,562

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1002313562...
Checkpoint 1002313562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,345.43277
Policy Entropy: 3.12021
Value Function Loss: 0.00522

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.09139
Policy Update Magnitude: 0.56920
Value Function Update Magnitude: 0.61374

Collected Steps per Second: 22,517.17243
Overall Steps per Second: 10,756.21536

Timestep Collection Time: 2.22106
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.64959

Cumulative Model Updates: 120,196
Cumulative Timesteps: 1,002,363,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,456.68577
Policy Entropy: 3.13193
Value Function Loss: 0.00520

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.09163
Policy Update Magnitude: 0.56690
Value Function Update Magnitude: 0.60206

Collected Steps per Second: 22,930.62274
Overall Steps per Second: 9,567.65808

Timestep Collection Time: 2.18058
Timestep Consumption Time: 3.04557
PPO Batch Consumption Time: 0.32150
Total Iteration Time: 5.22615

Cumulative Model Updates: 120,202
Cumulative Timesteps: 1,002,413,576

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1002413576...
Checkpoint 1002413576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,447.20966
Policy Entropy: 3.13038
Value Function Loss: 0.00500

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.09485
Policy Update Magnitude: 0.56262
Value Function Update Magnitude: 0.59748

Collected Steps per Second: 10,361.17879
Overall Steps per Second: 6,415.71567

Timestep Collection Time: 4.82609
Timestep Consumption Time: 2.96789
PPO Batch Consumption Time: 0.35297
Total Iteration Time: 7.79399

Cumulative Model Updates: 120,208
Cumulative Timesteps: 1,002,463,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 681.65143
Policy Entropy: 3.12925
Value Function Loss: 0.00529

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.09573
Policy Update Magnitude: 0.56292
Value Function Update Magnitude: 0.60446

Collected Steps per Second: 18,206.21071
Overall Steps per Second: 9,452.84524

Timestep Collection Time: 2.74741
Timestep Consumption Time: 2.54411
PPO Batch Consumption Time: 0.30108
Total Iteration Time: 5.29153

Cumulative Model Updates: 120,214
Cumulative Timesteps: 1,002,513,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1002513600...
Checkpoint 1002513600 saved!
