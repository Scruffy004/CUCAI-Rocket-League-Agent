Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.52688
Policy Entropy: 2.41629
Value Function Loss: 0.01924

Mean KL Divergence: 0.00058
SB3 Clip Fraction: 0.00439
Policy Update Magnitude: 0.17773
Value Function Update Magnitude: 0.20864

Collected Steps per Second: 19,679.43587
Overall Steps per Second: 12,358.38476

Timestep Collection Time: 2.54235
Timestep Consumption Time: 1.50608
PPO Batch Consumption Time: 0.34068
Total Iteration Time: 4.04843

Cumulative Model Updates: 301,030
Cumulative Timesteps: 2,510,491,534

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.85728
Policy Entropy: 2.42972
Value Function Loss: 0.01843

Mean KL Divergence: 0.00666
SB3 Clip Fraction: 0.05930
Policy Update Magnitude: 0.37971
Value Function Update Magnitude: 0.44436

Collected Steps per Second: 22,691.71126
Overall Steps per Second: 11,969.94888

Timestep Collection Time: 2.20451
Timestep Consumption Time: 1.97463
PPO Batch Consumption Time: 0.30319
Total Iteration Time: 4.17913

Cumulative Model Updates: 301,034
Cumulative Timesteps: 2,510,541,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2510541558...
Checkpoint 2510541558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.84526
Policy Entropy: 2.41943
Value Function Loss: 0.01775

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.09839
Policy Update Magnitude: 0.53572
Value Function Update Magnitude: 0.66273

Collected Steps per Second: 22,098.64184
Overall Steps per Second: 10,727.69296

Timestep Collection Time: 2.26294
Timestep Consumption Time: 2.39864
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.66158

Cumulative Model Updates: 301,040
Cumulative Timesteps: 2,510,591,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.75585
Policy Entropy: 2.42509
Value Function Loss: 0.01677

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.09850
Policy Update Magnitude: 0.49645
Value Function Update Magnitude: 0.66467

Collected Steps per Second: 22,931.29349
Overall Steps per Second: 10,985.83234

Timestep Collection Time: 2.18043
Timestep Consumption Time: 2.37089
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.55132

Cumulative Model Updates: 301,046
Cumulative Timesteps: 2,510,641,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2510641566...
Checkpoint 2510641566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.91066
Policy Entropy: 2.44661
Value Function Loss: 0.01604

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.09625
Policy Update Magnitude: 0.47499
Value Function Update Magnitude: 0.62858

Collected Steps per Second: 21,923.35347
Overall Steps per Second: 10,597.23972

Timestep Collection Time: 2.28140
Timestep Consumption Time: 2.43832
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.71972

Cumulative Model Updates: 301,052
Cumulative Timesteps: 2,510,691,582

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.63601
Policy Entropy: 2.46974
Value Function Loss: 0.01605

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.09259
Policy Update Magnitude: 0.45776
Value Function Update Magnitude: 0.58956

Collected Steps per Second: 22,008.85292
Overall Steps per Second: 10,485.88486

Timestep Collection Time: 2.27209
Timestep Consumption Time: 2.49680
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.76889

Cumulative Model Updates: 301,058
Cumulative Timesteps: 2,510,741,588

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2510741588...
Checkpoint 2510741588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.80416
Policy Entropy: 2.47480
Value Function Loss: 0.01588

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.09049
Policy Update Magnitude: 0.45701
Value Function Update Magnitude: 0.59363

Collected Steps per Second: 22,248.24163
Overall Steps per Second: 10,623.90782

Timestep Collection Time: 2.24764
Timestep Consumption Time: 2.45929
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.70693

Cumulative Model Updates: 301,064
Cumulative Timesteps: 2,510,791,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.61453
Policy Entropy: 2.46913
Value Function Loss: 0.01605

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.46284
Value Function Update Magnitude: 0.62077

Collected Steps per Second: 23,688.76813
Overall Steps per Second: 10,910.47575

Timestep Collection Time: 2.11087
Timestep Consumption Time: 2.47224
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.58312

Cumulative Model Updates: 301,070
Cumulative Timesteps: 2,510,841,598

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2510841598...
Checkpoint 2510841598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 347.14306
Policy Entropy: 2.47269
Value Function Loss: 0.01576

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.46755
Value Function Update Magnitude: 0.62008

Collected Steps per Second: 22,841.93561
Overall Steps per Second: 10,628.23557

Timestep Collection Time: 2.18948
Timestep Consumption Time: 2.51610
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.70558

Cumulative Model Updates: 301,076
Cumulative Timesteps: 2,510,891,610

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.88139
Policy Entropy: 2.48708
Value Function Loss: 0.01695

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09755
Policy Update Magnitude: 0.46543
Value Function Update Magnitude: 0.61914

Collected Steps per Second: 22,398.40799
Overall Steps per Second: 10,590.46500

Timestep Collection Time: 2.23355
Timestep Consumption Time: 2.49032
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.72387

Cumulative Model Updates: 301,082
Cumulative Timesteps: 2,510,941,638

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2510941638...
Checkpoint 2510941638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.48749
Policy Entropy: 2.46297
Value Function Loss: 0.01749

Mean KL Divergence: 0.01603
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.46883
Value Function Update Magnitude: 0.62994

Collected Steps per Second: 22,856.12204
Overall Steps per Second: 10,947.73826

Timestep Collection Time: 2.18760
Timestep Consumption Time: 2.37956
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.56715

Cumulative Model Updates: 301,088
Cumulative Timesteps: 2,510,991,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.86121
Policy Entropy: 2.43531
Value Function Loss: 0.01779

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.47957
Value Function Update Magnitude: 0.64104

Collected Steps per Second: 23,255.96747
Overall Steps per Second: 10,917.39340

Timestep Collection Time: 2.15119
Timestep Consumption Time: 2.43122
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.58241

Cumulative Model Updates: 301,094
Cumulative Timesteps: 2,511,041,666

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2511041666...
Checkpoint 2511041666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.45193
Policy Entropy: 2.43557
Value Function Loss: 0.01692

Mean KL Divergence: 0.02247
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.48430
Value Function Update Magnitude: 0.67937

Collected Steps per Second: 22,876.27003
Overall Steps per Second: 10,670.41309

Timestep Collection Time: 2.18567
Timestep Consumption Time: 2.50018
PPO Batch Consumption Time: 0.29443
Total Iteration Time: 4.68585

Cumulative Model Updates: 301,100
Cumulative Timesteps: 2,511,091,666

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.22726
Policy Entropy: 2.46118
Value Function Loss: 0.01624

Mean KL Divergence: 0.01911
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.48229
Value Function Update Magnitude: 0.66197

Collected Steps per Second: 22,863.21122
Overall Steps per Second: 10,888.58785

Timestep Collection Time: 2.18727
Timestep Consumption Time: 2.40543
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.59270

Cumulative Model Updates: 301,106
Cumulative Timesteps: 2,511,141,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2511141674...
Checkpoint 2511141674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.64469
Policy Entropy: 2.45703
Value Function Loss: 0.01753

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.48795
Value Function Update Magnitude: 0.65574

Collected Steps per Second: 22,484.51306
Overall Steps per Second: 10,842.64874

Timestep Collection Time: 2.22402
Timestep Consumption Time: 2.38795
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.61197

Cumulative Model Updates: 301,112
Cumulative Timesteps: 2,511,191,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.49731
Policy Entropy: 2.42222
Value Function Loss: 0.01756

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.10571
Policy Update Magnitude: 0.49557
Value Function Update Magnitude: 0.66006

Collected Steps per Second: 23,167.97602
Overall Steps per Second: 10,717.43846

Timestep Collection Time: 2.15979
Timestep Consumption Time: 2.50905
PPO Batch Consumption Time: 0.29405
Total Iteration Time: 4.66884

Cumulative Model Updates: 301,118
Cumulative Timesteps: 2,511,241,718

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2511241718...
Checkpoint 2511241718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.56659
Policy Entropy: 2.40848
Value Function Loss: 0.01846

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.10699
Policy Update Magnitude: 0.48939
Value Function Update Magnitude: 0.66072

Collected Steps per Second: 22,021.86577
Overall Steps per Second: 10,644.20754

Timestep Collection Time: 2.27165
Timestep Consumption Time: 2.42818
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.69983

Cumulative Model Updates: 301,124
Cumulative Timesteps: 2,511,291,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.52520
Policy Entropy: 2.41977
Value Function Loss: 0.01813

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.10739
Policy Update Magnitude: 0.48965
Value Function Update Magnitude: 0.65950

Collected Steps per Second: 22,580.88009
Overall Steps per Second: 10,822.59256

Timestep Collection Time: 2.21479
Timestep Consumption Time: 2.40628
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.62107

Cumulative Model Updates: 301,130
Cumulative Timesteps: 2,511,341,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2511341756...
Checkpoint 2511341756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.09567
Policy Entropy: 2.44882
Value Function Loss: 0.01724

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.10712
Policy Update Magnitude: 0.47830
Value Function Update Magnitude: 0.66180

Collected Steps per Second: 22,548.71941
Overall Steps per Second: 10,702.37549

Timestep Collection Time: 2.21813
Timestep Consumption Time: 2.45522
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.67336

Cumulative Model Updates: 301,136
Cumulative Timesteps: 2,511,391,772

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.39710
Policy Entropy: 2.43886
Value Function Loss: 0.01746

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.09826
Policy Update Magnitude: 0.47248
Value Function Update Magnitude: 0.63545

Collected Steps per Second: 23,276.84805
Overall Steps per Second: 10,887.19614

Timestep Collection Time: 2.14900
Timestep Consumption Time: 2.44557
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.59457

Cumulative Model Updates: 301,142
Cumulative Timesteps: 2,511,441,794

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2511441794...
Checkpoint 2511441794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256.15266
Policy Entropy: 2.43588
Value Function Loss: 0.01731

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.09683
Policy Update Magnitude: 0.47942
Value Function Update Magnitude: 0.62430

Collected Steps per Second: 22,818.21567
Overall Steps per Second: 10,659.44332

Timestep Collection Time: 2.19228
Timestep Consumption Time: 2.50064
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.69293

Cumulative Model Updates: 301,148
Cumulative Timesteps: 2,511,491,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337.12576
Policy Entropy: 2.41409
Value Function Loss: 0.01785

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.10536
Policy Update Magnitude: 0.47982
Value Function Update Magnitude: 0.63452

Collected Steps per Second: 23,189.94168
Overall Steps per Second: 10,884.68928

Timestep Collection Time: 2.15671
Timestep Consumption Time: 2.43818
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.59489

Cumulative Model Updates: 301,154
Cumulative Timesteps: 2,511,541,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2511541832...
Checkpoint 2511541832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.11551
Policy Entropy: 2.40727
Value Function Loss: 0.01824

Mean KL Divergence: 0.01995
SB3 Clip Fraction: 0.13132
Policy Update Magnitude: 0.47292
Value Function Update Magnitude: 0.65689

Collected Steps per Second: 22,896.97446
Overall Steps per Second: 10,668.05211

Timestep Collection Time: 2.18457
Timestep Consumption Time: 2.50420
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.68877

Cumulative Model Updates: 301,160
Cumulative Timesteps: 2,511,591,852

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.79566
Policy Entropy: 2.42030
Value Function Loss: 0.01755

Mean KL Divergence: 0.02166
SB3 Clip Fraction: 0.14220
Policy Update Magnitude: 0.46971
Value Function Update Magnitude: 0.68084

Collected Steps per Second: 23,127.41709
Overall Steps per Second: 10,861.40724

Timestep Collection Time: 2.16228
Timestep Consumption Time: 2.44191
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.60419

Cumulative Model Updates: 301,166
Cumulative Timesteps: 2,511,641,860

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2511641860...
Checkpoint 2511641860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236.19759
Policy Entropy: 2.42375
Value Function Loss: 0.01825

Mean KL Divergence: 0.01990
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.49103
Value Function Update Magnitude: 0.67226

Collected Steps per Second: 22,304.00267
Overall Steps per Second: 10,521.76141

Timestep Collection Time: 2.24202
Timestep Consumption Time: 2.51061
PPO Batch Consumption Time: 0.29623
Total Iteration Time: 4.75263

Cumulative Model Updates: 301,172
Cumulative Timesteps: 2,511,691,866

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.74029
Policy Entropy: 2.45340
Value Function Loss: 0.01674

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.49182
Value Function Update Magnitude: 0.66137

Collected Steps per Second: 23,189.73728
Overall Steps per Second: 10,731.29559

Timestep Collection Time: 2.15690
Timestep Consumption Time: 2.50404
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.66095

Cumulative Model Updates: 301,178
Cumulative Timesteps: 2,511,741,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2511741884...
Checkpoint 2511741884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.64232
Policy Entropy: 2.45516
Value Function Loss: 0.01764

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11665
Policy Update Magnitude: 0.49249
Value Function Update Magnitude: 0.65772

Collected Steps per Second: 22,195.10878
Overall Steps per Second: 10,553.94937

Timestep Collection Time: 2.25284
Timestep Consumption Time: 2.48491
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.73775

Cumulative Model Updates: 301,184
Cumulative Timesteps: 2,511,791,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.47735
Policy Entropy: 2.47798
Value Function Loss: 0.01609

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.09831
Policy Update Magnitude: 0.48739
Value Function Update Magnitude: 0.64870

Collected Steps per Second: 22,527.12749
Overall Steps per Second: 10,589.21676

Timestep Collection Time: 2.21999
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.72273

Cumulative Model Updates: 301,190
Cumulative Timesteps: 2,511,841,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2511841896...
Checkpoint 2511841896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.40450
Policy Entropy: 2.45029
Value Function Loss: 0.01754

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.48983
Value Function Update Magnitude: 0.65493

Collected Steps per Second: 22,206.07583
Overall Steps per Second: 10,864.36259

Timestep Collection Time: 2.25245
Timestep Consumption Time: 2.35141
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.60386

Cumulative Model Updates: 301,196
Cumulative Timesteps: 2,511,891,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.77683
Policy Entropy: 2.45209
Value Function Loss: 0.01768

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.11151
Policy Update Magnitude: 0.48444
Value Function Update Magnitude: 0.65747

Collected Steps per Second: 22,763.36720
Overall Steps per Second: 10,543.17613

Timestep Collection Time: 2.19739
Timestep Consumption Time: 2.54691
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.74430

Cumulative Model Updates: 301,202
Cumulative Timesteps: 2,511,941,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2511941934...
Checkpoint 2511941934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.54901
Policy Entropy: 2.43287
Value Function Loss: 0.01881

Mean KL Divergence: 0.01754
SB3 Clip Fraction: 0.12006
Policy Update Magnitude: 0.48641
Value Function Update Magnitude: 0.65247

Collected Steps per Second: 21,987.58577
Overall Steps per Second: 10,552.32277

Timestep Collection Time: 2.27437
Timestep Consumption Time: 2.46468
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.73905

Cumulative Model Updates: 301,208
Cumulative Timesteps: 2,511,991,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.46354
Policy Entropy: 2.44051
Value Function Loss: 0.01841

Mean KL Divergence: 0.01634
SB3 Clip Fraction: 0.11653
Policy Update Magnitude: 0.49321
Value Function Update Magnitude: 0.65847

Collected Steps per Second: 22,834.70695
Overall Steps per Second: 10,759.84582

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.45863
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.64951

Cumulative Model Updates: 301,214
Cumulative Timesteps: 2,512,041,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2512041970...
Checkpoint 2512041970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.83906
Policy Entropy: 2.42862
Value Function Loss: 0.01780

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.10575
Policy Update Magnitude: 0.49285
Value Function Update Magnitude: 0.65672

Collected Steps per Second: 22,591.58386
Overall Steps per Second: 10,903.54853

Timestep Collection Time: 2.21392
Timestep Consumption Time: 2.37321
PPO Batch Consumption Time: 0.28336
Total Iteration Time: 4.58713

Cumulative Model Updates: 301,220
Cumulative Timesteps: 2,512,091,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.99740
Policy Entropy: 2.44464
Value Function Loss: 0.01690

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.09371
Policy Update Magnitude: 0.47880
Value Function Update Magnitude: 0.64926

Collected Steps per Second: 23,009.67803
Overall Steps per Second: 10,856.96857

Timestep Collection Time: 2.17439
Timestep Consumption Time: 2.43390
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.60828

Cumulative Model Updates: 301,226
Cumulative Timesteps: 2,512,142,018

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2512142018...
Checkpoint 2512142018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.03206
Policy Entropy: 2.46165
Value Function Loss: 0.01621

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.09132
Policy Update Magnitude: 0.48411
Value Function Update Magnitude: 0.64500

Collected Steps per Second: 22,503.64478
Overall Steps per Second: 10,653.84388

Timestep Collection Time: 2.22222
Timestep Consumption Time: 2.47167
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.69389

Cumulative Model Updates: 301,232
Cumulative Timesteps: 2,512,192,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.00449
Policy Entropy: 2.45315
Value Function Loss: 0.01607

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.09235
Policy Update Magnitude: 0.49121
Value Function Update Magnitude: 0.64040

Collected Steps per Second: 22,536.87161
Overall Steps per Second: 10,661.91902

Timestep Collection Time: 2.21912
Timestep Consumption Time: 2.47159
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.69071

Cumulative Model Updates: 301,238
Cumulative Timesteps: 2,512,242,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2512242038...
Checkpoint 2512242038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.94197
Policy Entropy: 2.45491
Value Function Loss: 0.01730

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.49968
Value Function Update Magnitude: 0.65378

Collected Steps per Second: 22,248.95996
Overall Steps per Second: 10,859.17660

Timestep Collection Time: 2.24793
Timestep Consumption Time: 2.35776
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.60569

Cumulative Model Updates: 301,244
Cumulative Timesteps: 2,512,292,052

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 271.35222
Policy Entropy: 2.43524
Value Function Loss: 0.01774

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.10398
Policy Update Magnitude: 0.48944
Value Function Update Magnitude: 0.66085

Collected Steps per Second: 21,150.91575
Overall Steps per Second: 10,272.38599

Timestep Collection Time: 2.36519
Timestep Consumption Time: 2.50476
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.86995

Cumulative Model Updates: 301,250
Cumulative Timesteps: 2,512,342,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2512342078...
Checkpoint 2512342078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.97467
Policy Entropy: 2.42341
Value Function Loss: 0.01795

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.10342
Policy Update Magnitude: 0.48540
Value Function Update Magnitude: 0.65126

Collected Steps per Second: 21,968.74504
Overall Steps per Second: 10,463.77306

Timestep Collection Time: 2.27623
Timestep Consumption Time: 2.50273
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.77896

Cumulative Model Updates: 301,256
Cumulative Timesteps: 2,512,392,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.55863
Policy Entropy: 2.40336
Value Function Loss: 0.01850

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.10721
Policy Update Magnitude: 0.48775
Value Function Update Magnitude: 0.64488

Collected Steps per Second: 22,776.25721
Overall Steps per Second: 10,838.15084

Timestep Collection Time: 2.19527
Timestep Consumption Time: 2.41806
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.61333

Cumulative Model Updates: 301,262
Cumulative Timesteps: 2,512,442,084

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2512442084...
Checkpoint 2512442084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.92943
Policy Entropy: 2.40179
Value Function Loss: 0.01874

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.50137
Value Function Update Magnitude: 0.65255

Collected Steps per Second: 22,288.80464
Overall Steps per Second: 10,684.27616

Timestep Collection Time: 2.24337
Timestep Consumption Time: 2.43659
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.67996

Cumulative Model Updates: 301,268
Cumulative Timesteps: 2,512,492,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264.17554
Policy Entropy: 2.40843
Value Function Loss: 0.01879

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.10646
Policy Update Magnitude: 0.50582
Value Function Update Magnitude: 0.67966

Collected Steps per Second: 23,023.80962
Overall Steps per Second: 10,788.01501

Timestep Collection Time: 2.17201
Timestep Consumption Time: 2.46350
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.63551

Cumulative Model Updates: 301,274
Cumulative Timesteps: 2,512,542,094

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2512542094...
Checkpoint 2512542094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.25720
Policy Entropy: 2.41993
Value Function Loss: 0.01846

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.10273
Policy Update Magnitude: 0.49859
Value Function Update Magnitude: 0.69724

Collected Steps per Second: 21,971.69972
Overall Steps per Second: 10,331.58657

Timestep Collection Time: 2.27593
Timestep Consumption Time: 2.56418
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.84011

Cumulative Model Updates: 301,280
Cumulative Timesteps: 2,512,592,100

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.26866
Policy Entropy: 2.43632
Value Function Loss: 0.01813

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.10464
Policy Update Magnitude: 0.50557
Value Function Update Magnitude: 0.69083

Collected Steps per Second: 23,044.19141
Overall Steps per Second: 10,845.62996

Timestep Collection Time: 2.17035
Timestep Consumption Time: 2.44109
PPO Batch Consumption Time: 0.28232
Total Iteration Time: 4.61144

Cumulative Model Updates: 301,286
Cumulative Timesteps: 2,512,642,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2512642114...
Checkpoint 2512642114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.83838
Policy Entropy: 2.45004
Value Function Loss: 0.01772

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.09818
Policy Update Magnitude: 0.50587
Value Function Update Magnitude: 0.67260

Collected Steps per Second: 22,064.64909
Overall Steps per Second: 10,671.88031

Timestep Collection Time: 2.26752
Timestep Consumption Time: 2.42069
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.68821

Cumulative Model Updates: 301,292
Cumulative Timesteps: 2,512,692,146

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.01603
Policy Entropy: 2.47813
Value Function Loss: 0.01623

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.49610
Value Function Update Magnitude: 0.67486

Collected Steps per Second: 22,951.52774
Overall Steps per Second: 10,843.95472

Timestep Collection Time: 2.17911
Timestep Consumption Time: 2.43304
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.61216

Cumulative Model Updates: 301,298
Cumulative Timesteps: 2,512,742,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2512742160...
Checkpoint 2512742160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.27745
Policy Entropy: 2.48416
Value Function Loss: 0.01601

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.47865
Value Function Update Magnitude: 0.65309

Collected Steps per Second: 22,736.86603
Overall Steps per Second: 10,729.63744

Timestep Collection Time: 2.19969
Timestep Consumption Time: 2.46161
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.66129

Cumulative Model Updates: 301,304
Cumulative Timesteps: 2,512,792,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.42139
Policy Entropy: 2.45857
Value Function Loss: 0.01702

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.09312
Policy Update Magnitude: 0.47306
Value Function Update Magnitude: 0.63361

Collected Steps per Second: 22,155.22291
Overall Steps per Second: 10,582.07148

Timestep Collection Time: 2.25744
Timestep Consumption Time: 2.46886
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.72630

Cumulative Model Updates: 301,310
Cumulative Timesteps: 2,512,842,188

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2512842188...
Checkpoint 2512842188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.01919
Policy Entropy: 2.42688
Value Function Loss: 0.01777

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.10507
Policy Update Magnitude: 0.46925
Value Function Update Magnitude: 0.63873

Collected Steps per Second: 22,174.05105
Overall Steps per Second: 10,861.56712

Timestep Collection Time: 2.25543
Timestep Consumption Time: 2.34906
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.60449

Cumulative Model Updates: 301,316
Cumulative Timesteps: 2,512,892,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.47081
Policy Entropy: 2.42138
Value Function Loss: 0.01844

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.11243
Policy Update Magnitude: 0.47575
Value Function Update Magnitude: 0.65073

Collected Steps per Second: 22,535.20721
Overall Steps per Second: 10,546.85062

Timestep Collection Time: 2.21964
Timestep Consumption Time: 2.52301
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.74265

Cumulative Model Updates: 301,322
Cumulative Timesteps: 2,512,942,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2512942220...
Checkpoint 2512942220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.94779
Policy Entropy: 2.43423
Value Function Loss: 0.01760

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.11240
Policy Update Magnitude: 0.48985
Value Function Update Magnitude: 0.66282

Collected Steps per Second: 22,430.41991
Overall Steps per Second: 10,504.87681

Timestep Collection Time: 2.22974
Timestep Consumption Time: 2.53129
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.76103

Cumulative Model Updates: 301,328
Cumulative Timesteps: 2,512,992,234

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 379.98934
Policy Entropy: 2.44477
Value Function Loss: 0.01836

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.11352
Policy Update Magnitude: 0.50173
Value Function Update Magnitude: 0.66777

Collected Steps per Second: 22,532.10789
Overall Steps per Second: 10,606.40003

Timestep Collection Time: 2.22021
Timestep Consumption Time: 2.49638
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.71659

Cumulative Model Updates: 301,334
Cumulative Timesteps: 2,513,042,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2513042260...
Checkpoint 2513042260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.90200
Policy Entropy: 2.44169
Value Function Loss: 0.01828

Mean KL Divergence: 0.01858
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.48256
Value Function Update Magnitude: 0.66846

Collected Steps per Second: 23,093.10813
Overall Steps per Second: 10,701.46038

Timestep Collection Time: 2.16610
Timestep Consumption Time: 2.50821
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.67432

Cumulative Model Updates: 301,340
Cumulative Timesteps: 2,513,092,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.00075
Policy Entropy: 2.45041
Value Function Loss: 0.01887

Mean KL Divergence: 0.02586
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.46577
Value Function Update Magnitude: 0.68034

Collected Steps per Second: 22,961.39037
Overall Steps per Second: 10,814.73427

Timestep Collection Time: 2.17809
Timestep Consumption Time: 2.44634
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.62443

Cumulative Model Updates: 301,346
Cumulative Timesteps: 2,513,142,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2513142294...
Checkpoint 2513142294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 411.00816
Policy Entropy: 2.44927
Value Function Loss: 0.01866

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.12921
Policy Update Magnitude: 0.49708
Value Function Update Magnitude: 0.69101

Collected Steps per Second: 22,316.39028
Overall Steps per Second: 10,695.66826

Timestep Collection Time: 2.24176
Timestep Consumption Time: 2.43565
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.67741

Cumulative Model Updates: 301,352
Cumulative Timesteps: 2,513,192,322

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.41736
Policy Entropy: 2.45127
Value Function Loss: 0.01873

Mean KL Divergence: 0.01826
SB3 Clip Fraction: 0.11918
Policy Update Magnitude: 0.51254
Value Function Update Magnitude: 0.69027

Collected Steps per Second: 23,177.93777
Overall Steps per Second: 10,865.42434

Timestep Collection Time: 2.15835
Timestep Consumption Time: 2.44580
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.60415

Cumulative Model Updates: 301,358
Cumulative Timesteps: 2,513,242,348

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2513242348...
Checkpoint 2513242348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.08022
Policy Entropy: 2.45007
Value Function Loss: 0.01743

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.10522
Policy Update Magnitude: 0.50241
Value Function Update Magnitude: 0.68498

Collected Steps per Second: 22,539.07466
Overall Steps per Second: 10,639.17925

Timestep Collection Time: 2.21917
Timestep Consumption Time: 2.48213
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.70130

Cumulative Model Updates: 301,364
Cumulative Timesteps: 2,513,292,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.43718
Policy Entropy: 2.45505
Value Function Loss: 0.01808

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.10186
Policy Update Magnitude: 0.49186
Value Function Update Magnitude: 0.67326

Collected Steps per Second: 22,843.89708
Overall Steps per Second: 10,713.93963

Timestep Collection Time: 2.18912
Timestep Consumption Time: 2.47845
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.66756

Cumulative Model Updates: 301,370
Cumulative Timesteps: 2,513,342,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2513342374...
Checkpoint 2513342374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.94926
Policy Entropy: 2.44305
Value Function Loss: 0.01861

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.10517
Policy Update Magnitude: 0.50295
Value Function Update Magnitude: 0.65401

Collected Steps per Second: 21,856.98290
Overall Steps per Second: 10,462.85382

Timestep Collection Time: 2.28897
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.78168

Cumulative Model Updates: 301,376
Cumulative Timesteps: 2,513,392,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.80598
Policy Entropy: 2.44944
Value Function Loss: 0.01880

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.11440
Policy Update Magnitude: 0.50159
Value Function Update Magnitude: 0.65875

Collected Steps per Second: 23,565.23008
Overall Steps per Second: 10,866.07332

Timestep Collection Time: 2.12228
Timestep Consumption Time: 2.48030
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.60258

Cumulative Model Updates: 301,382
Cumulative Timesteps: 2,513,442,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2513442416...
Checkpoint 2513442416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.92263
Policy Entropy: 2.45147
Value Function Loss: 0.01749

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 0.49314
Value Function Update Magnitude: 0.66933

Collected Steps per Second: 21,940.34264
Overall Steps per Second: 10,577.35725

Timestep Collection Time: 2.27991
Timestep Consumption Time: 2.44925
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.72916

Cumulative Model Updates: 301,388
Cumulative Timesteps: 2,513,492,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.44447
Policy Entropy: 2.46908
Value Function Loss: 0.01735

Mean KL Divergence: 0.01986
SB3 Clip Fraction: 0.12028
Policy Update Magnitude: 0.48746
Value Function Update Magnitude: 0.64972

Collected Steps per Second: 23,379.01281
Overall Steps per Second: 10,865.28146

Timestep Collection Time: 2.13961
Timestep Consumption Time: 2.46423
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.60384

Cumulative Model Updates: 301,394
Cumulative Timesteps: 2,513,542,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2513542460...
Checkpoint 2513542460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 369.21382
Policy Entropy: 2.47017
Value Function Loss: 0.01742

Mean KL Divergence: 0.01998
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.48326
Value Function Update Magnitude: 0.65211

Collected Steps per Second: 22,685.13742
Overall Steps per Second: 10,764.19267

Timestep Collection Time: 2.20426
Timestep Consumption Time: 2.44114
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.64540

Cumulative Model Updates: 301,400
Cumulative Timesteps: 2,513,592,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.01720
Policy Entropy: 2.46914
Value Function Loss: 0.01666

Mean KL Divergence: 0.01815
SB3 Clip Fraction: 0.10878
Policy Update Magnitude: 0.48356
Value Function Update Magnitude: 0.66315

Collected Steps per Second: 22,979.37994
Overall Steps per Second: 10,691.52106

Timestep Collection Time: 2.17647
Timestep Consumption Time: 2.50144
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.67791

Cumulative Model Updates: 301,406
Cumulative Timesteps: 2,513,642,478

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2513642478...
Checkpoint 2513642478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.90717
Policy Entropy: 2.47327
Value Function Loss: 0.01707

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.09853
Policy Update Magnitude: 0.48468
Value Function Update Magnitude: 0.64162

Collected Steps per Second: 22,150.02685
Overall Steps per Second: 10,388.91530

Timestep Collection Time: 2.25742
Timestep Consumption Time: 2.55559
PPO Batch Consumption Time: 0.30038
Total Iteration Time: 4.81301

Cumulative Model Updates: 301,412
Cumulative Timesteps: 2,513,692,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.72962
Policy Entropy: 2.46323
Value Function Loss: 0.01747

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.47642
Value Function Update Magnitude: 0.62483

Collected Steps per Second: 23,145.18273
Overall Steps per Second: 10,876.30221

Timestep Collection Time: 2.16071
Timestep Consumption Time: 2.43736
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.59807

Cumulative Model Updates: 301,418
Cumulative Timesteps: 2,513,742,490

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2513742490...
Checkpoint 2513742490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.50280
Policy Entropy: 2.46578
Value Function Loss: 0.01854

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.48333
Value Function Update Magnitude: 0.62666

Collected Steps per Second: 22,492.97685
Overall Steps per Second: 10,741.45622

Timestep Collection Time: 2.22354
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.65617

Cumulative Model Updates: 301,424
Cumulative Timesteps: 2,513,792,504

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.12349
Policy Entropy: 2.46051
Value Function Loss: 0.01788

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.09235
Policy Update Magnitude: 0.47924
Value Function Update Magnitude: 0.64094

Collected Steps per Second: 23,473.70361
Overall Steps per Second: 10,854.53816

Timestep Collection Time: 2.13090
Timestep Consumption Time: 2.47732
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.60821

Cumulative Model Updates: 301,430
Cumulative Timesteps: 2,513,842,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2513842524...
Checkpoint 2513842524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.17894
Policy Entropy: 2.48171
Value Function Loss: 0.01627

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.09589
Policy Update Magnitude: 0.47748
Value Function Update Magnitude: 0.64256

Collected Steps per Second: 21,884.37774
Overall Steps per Second: 10,563.53093

Timestep Collection Time: 2.28583
Timestep Consumption Time: 2.44971
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.73554

Cumulative Model Updates: 301,436
Cumulative Timesteps: 2,513,892,548

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.36731
Policy Entropy: 2.46554
Value Function Loss: 0.01624

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.09439
Policy Update Magnitude: 0.47629
Value Function Update Magnitude: 0.63217

Collected Steps per Second: 22,681.81631
Overall Steps per Second: 10,689.53966

Timestep Collection Time: 2.20441
Timestep Consumption Time: 2.47306
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.67747

Cumulative Model Updates: 301,442
Cumulative Timesteps: 2,513,942,548

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2513942548...
Checkpoint 2513942548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.54798
Policy Entropy: 2.47224
Value Function Loss: 0.01688

Mean KL Divergence: 0.01290
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.47775
Value Function Update Magnitude: 0.63098

Collected Steps per Second: 22,937.74534
Overall Steps per Second: 10,862.05754

Timestep Collection Time: 2.18095
Timestep Consumption Time: 2.42463
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.60557

Cumulative Model Updates: 301,448
Cumulative Timesteps: 2,513,992,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.15143
Policy Entropy: 2.45561
Value Function Loss: 0.01709

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.10868
Policy Update Magnitude: 0.47703
Value Function Update Magnitude: 0.64814

Collected Steps per Second: 22,911.42081
Overall Steps per Second: 10,657.03940

Timestep Collection Time: 2.18275
Timestep Consumption Time: 2.50992
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.69267

Cumulative Model Updates: 301,454
Cumulative Timesteps: 2,514,042,584

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2514042584...
Checkpoint 2514042584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.32287
Policy Entropy: 2.46088
Value Function Loss: 0.01667

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.10972
Policy Update Magnitude: 0.47236
Value Function Update Magnitude: 0.64910

Collected Steps per Second: 22,422.28064
Overall Steps per Second: 10,536.09621

Timestep Collection Time: 2.23037
Timestep Consumption Time: 2.51617
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.74654

Cumulative Model Updates: 301,460
Cumulative Timesteps: 2,514,092,594

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.59831
Policy Entropy: 2.45062
Value Function Loss: 0.01696

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.11198
Policy Update Magnitude: 0.47995
Value Function Update Magnitude: 0.65872

Collected Steps per Second: 22,999.79552
Overall Steps per Second: 10,827.31438

Timestep Collection Time: 2.17428
Timestep Consumption Time: 2.44441
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.61869

Cumulative Model Updates: 301,466
Cumulative Timesteps: 2,514,142,602

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2514142602...
Checkpoint 2514142602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.83485
Policy Entropy: 2.47009
Value Function Loss: 0.01718

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.11067
Policy Update Magnitude: 0.48838
Value Function Update Magnitude: 0.66684

Collected Steps per Second: 22,459.54518
Overall Steps per Second: 10,660.04826

Timestep Collection Time: 2.22685
Timestep Consumption Time: 2.46488
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.69172

Cumulative Model Updates: 301,472
Cumulative Timesteps: 2,514,192,616

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.13978
Policy Entropy: 2.45841
Value Function Loss: 0.01774

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.11563
Policy Update Magnitude: 0.48942
Value Function Update Magnitude: 0.66329

Collected Steps per Second: 23,372.03405
Overall Steps per Second: 10,931.01458

Timestep Collection Time: 2.14111
Timestep Consumption Time: 2.43688
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.57798

Cumulative Model Updates: 301,478
Cumulative Timesteps: 2,514,242,658

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2514242658...
Checkpoint 2514242658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.77111
Policy Entropy: 2.45170
Value Function Loss: 0.01698

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.10600
Policy Update Magnitude: 0.48823
Value Function Update Magnitude: 0.65352

Collected Steps per Second: 22,491.90854
Overall Steps per Second: 10,617.03201

Timestep Collection Time: 2.22444
Timestep Consumption Time: 2.48798
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.71243

Cumulative Model Updates: 301,484
Cumulative Timesteps: 2,514,292,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.61790
Policy Entropy: 2.45321
Value Function Loss: 0.01744

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.10812
Policy Update Magnitude: 0.48506
Value Function Update Magnitude: 0.65248

Collected Steps per Second: 23,123.55851
Overall Steps per Second: 10,883.10268

Timestep Collection Time: 2.16282
Timestep Consumption Time: 2.43256
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.59538

Cumulative Model Updates: 301,490
Cumulative Timesteps: 2,514,342,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2514342702...
Checkpoint 2514342702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.73655
Policy Entropy: 2.43722
Value Function Loss: 0.01768

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.10147
Policy Update Magnitude: 0.48744
Value Function Update Magnitude: 0.67317

Collected Steps per Second: 22,204.19727
Overall Steps per Second: 10,687.81707

Timestep Collection Time: 2.25219
Timestep Consumption Time: 2.42679
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.67897

Cumulative Model Updates: 301,496
Cumulative Timesteps: 2,514,392,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.73857
Policy Entropy: 2.45386
Value Function Loss: 0.01724

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.09813
Policy Update Magnitude: 0.49017
Value Function Update Magnitude: 0.68714

Collected Steps per Second: 22,723.59755
Overall Steps per Second: 10,621.13304

Timestep Collection Time: 2.20088
Timestep Consumption Time: 2.50784
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.70873

Cumulative Model Updates: 301,502
Cumulative Timesteps: 2,514,442,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2514442722...
Checkpoint 2514442722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.73873
Policy Entropy: 2.45233
Value Function Loss: 0.01550

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.09706
Policy Update Magnitude: 0.47868
Value Function Update Magnitude: 0.65155

Collected Steps per Second: 22,025.20767
Overall Steps per Second: 10,440.82674

Timestep Collection Time: 2.27094
Timestep Consumption Time: 2.51967
PPO Batch Consumption Time: 0.29647
Total Iteration Time: 4.79062

Cumulative Model Updates: 301,508
Cumulative Timesteps: 2,514,492,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.78565
Policy Entropy: 2.48404
Value Function Loss: 0.01553

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.47692
Value Function Update Magnitude: 0.61794

Collected Steps per Second: 22,385.01847
Overall Steps per Second: 10,893.24168

Timestep Collection Time: 2.23373
Timestep Consumption Time: 2.35646
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59019

Cumulative Model Updates: 301,514
Cumulative Timesteps: 2,514,542,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2514542742...
Checkpoint 2514542742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.56208
Policy Entropy: 2.49331
Value Function Loss: 0.01647

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.08653
Policy Update Magnitude: 0.47137
Value Function Update Magnitude: 0.61349

Collected Steps per Second: 21,836.26459
Overall Steps per Second: 10,426.80972

Timestep Collection Time: 2.29096
Timestep Consumption Time: 2.50686
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.79782

Cumulative Model Updates: 301,520
Cumulative Timesteps: 2,514,592,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.14848
Policy Entropy: 2.48403
Value Function Loss: 0.01805

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.09586
Policy Update Magnitude: 0.47536
Value Function Update Magnitude: 0.63008

Collected Steps per Second: 23,001.83993
Overall Steps per Second: 10,702.67677

Timestep Collection Time: 2.17400
Timestep Consumption Time: 2.49829
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.67229

Cumulative Model Updates: 301,526
Cumulative Timesteps: 2,514,642,774

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2514642774...
Checkpoint 2514642774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.40948
Policy Entropy: 2.47759
Value Function Loss: 0.01837

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.08795
Policy Update Magnitude: 0.48506
Value Function Update Magnitude: 0.63472

Collected Steps per Second: 22,223.39642
Overall Steps per Second: 10,644.49243

Timestep Collection Time: 2.25024
Timestep Consumption Time: 2.44778
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.69802

Cumulative Model Updates: 301,532
Cumulative Timesteps: 2,514,692,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245.71983
Policy Entropy: 2.45465
Value Function Loss: 0.01954

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.48801
Value Function Update Magnitude: 0.64061

Collected Steps per Second: 23,351.84309
Overall Steps per Second: 10,920.83437

Timestep Collection Time: 2.14150
Timestep Consumption Time: 2.43764
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.57914

Cumulative Model Updates: 301,538
Cumulative Timesteps: 2,514,742,790

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2514742790...
Checkpoint 2514742790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.10456
Policy Entropy: 2.46069
Value Function Loss: 0.01915

Mean KL Divergence: 0.01291
SB3 Clip Fraction: 0.09501
Policy Update Magnitude: 0.48906
Value Function Update Magnitude: 0.65035

Collected Steps per Second: 21,991.09000
Overall Steps per Second: 10,601.22426

Timestep Collection Time: 2.27365
Timestep Consumption Time: 2.44279
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.71644

Cumulative Model Updates: 301,544
Cumulative Timesteps: 2,514,792,790

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.11407
Policy Entropy: 2.45829
Value Function Loss: 0.01906

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.09618
Policy Update Magnitude: 0.48746
Value Function Update Magnitude: 0.66125

Collected Steps per Second: 22,872.70805
Overall Steps per Second: 10,716.71135

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.48039
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.66710

Cumulative Model Updates: 301,550
Cumulative Timesteps: 2,514,842,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2514842806...
Checkpoint 2514842806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.92639
Policy Entropy: 2.46305
Value Function Loss: 0.01794

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09547
Policy Update Magnitude: 0.49069
Value Function Update Magnitude: 0.64849

Collected Steps per Second: 23,478.47142
Overall Steps per Second: 10,883.63806

Timestep Collection Time: 2.12978
Timestep Consumption Time: 2.46464
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.59442

Cumulative Model Updates: 301,556
Cumulative Timesteps: 2,514,892,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.68405
Policy Entropy: 2.45799
Value Function Loss: 0.01692

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.10192
Policy Update Magnitude: 0.48226
Value Function Update Magnitude: 0.63943

Collected Steps per Second: 23,165.40744
Overall Steps per Second: 10,878.98020

Timestep Collection Time: 2.15960
Timestep Consumption Time: 2.43899
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.59859

Cumulative Model Updates: 301,562
Cumulative Timesteps: 2,514,942,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2514942838...
Checkpoint 2514942838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.14042
Policy Entropy: 2.45815
Value Function Loss: 0.01675

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.09245
Policy Update Magnitude: 0.47236
Value Function Update Magnitude: 0.62148

Collected Steps per Second: 21,838.88072
Overall Steps per Second: 10,563.91215

Timestep Collection Time: 2.29096
Timestep Consumption Time: 2.44516
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.73612

Cumulative Model Updates: 301,568
Cumulative Timesteps: 2,514,992,870

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.95173
Policy Entropy: 2.46138
Value Function Loss: 0.01754

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.09692
Policy Update Magnitude: 0.47775
Value Function Update Magnitude: 0.61198

Collected Steps per Second: 22,478.42170
Overall Steps per Second: 10,815.12064

Timestep Collection Time: 2.22525
Timestep Consumption Time: 2.39976
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.62501

Cumulative Model Updates: 301,574
Cumulative Timesteps: 2,515,042,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2515042890...
Checkpoint 2515042890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.44929
Policy Entropy: 2.45641
Value Function Loss: 0.01753

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.47747
Value Function Update Magnitude: 0.62689

Collected Steps per Second: 22,332.58851
Overall Steps per Second: 10,574.55468

Timestep Collection Time: 2.23996
Timestep Consumption Time: 2.49065
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.73060

Cumulative Model Updates: 301,580
Cumulative Timesteps: 2,515,092,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.50490
Policy Entropy: 2.46512
Value Function Loss: 0.01793

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.10326
Policy Update Magnitude: 0.48168
Value Function Update Magnitude: 0.63751

Collected Steps per Second: 22,584.86111
Overall Steps per Second: 10,717.09269

Timestep Collection Time: 2.21440
Timestep Consumption Time: 2.45216
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.66656

Cumulative Model Updates: 301,586
Cumulative Timesteps: 2,515,142,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2515142926...
Checkpoint 2515142926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265.79907
Policy Entropy: 2.45032
Value Function Loss: 0.01806

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.10888
Policy Update Magnitude: 0.47872
Value Function Update Magnitude: 0.63294

Collected Steps per Second: 22,272.92392
Overall Steps per Second: 10,723.72746

Timestep Collection Time: 2.24560
Timestep Consumption Time: 2.41845
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.66405

Cumulative Model Updates: 301,592
Cumulative Timesteps: 2,515,192,942

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.48176
Policy Entropy: 2.45090
Value Function Loss: 0.01906

Mean KL Divergence: 0.01560
SB3 Clip Fraction: 0.11157
Policy Update Magnitude: 0.48977
Value Function Update Magnitude: 0.63558

Collected Steps per Second: 23,299.23350
Overall Steps per Second: 10,885.92044

Timestep Collection Time: 2.14720
Timestep Consumption Time: 2.44847
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.59566

Cumulative Model Updates: 301,598
Cumulative Timesteps: 2,515,242,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2515242970...
Checkpoint 2515242970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.73943
Policy Entropy: 2.43764
Value Function Loss: 0.01976

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.11691
Policy Update Magnitude: 0.50972
Value Function Update Magnitude: 0.64257

Collected Steps per Second: 22,799.47682
Overall Steps per Second: 10,611.63416

Timestep Collection Time: 2.19312
Timestep Consumption Time: 2.51888
PPO Batch Consumption Time: 0.29593
Total Iteration Time: 4.71200

Cumulative Model Updates: 301,604
Cumulative Timesteps: 2,515,292,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.11751
Policy Entropy: 2.45392
Value Function Loss: 0.02022

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.10906
Policy Update Magnitude: 0.50489
Value Function Update Magnitude: 0.66195

Collected Steps per Second: 23,231.38914
Overall Steps per Second: 10,882.71766

Timestep Collection Time: 2.15269
Timestep Consumption Time: 2.44267
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.59536

Cumulative Model Updates: 301,610
Cumulative Timesteps: 2,515,342,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2515342982...
Checkpoint 2515342982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.66704
Policy Entropy: 2.44382
Value Function Loss: 0.01909

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.10430
Policy Update Magnitude: 0.49600
Value Function Update Magnitude: 0.67893

Collected Steps per Second: 21,907.02386
Overall Steps per Second: 10,703.61476

Timestep Collection Time: 2.28256
Timestep Consumption Time: 2.38914
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.67169

Cumulative Model Updates: 301,616
Cumulative Timesteps: 2,515,392,986

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.58228
Policy Entropy: 2.44843
Value Function Loss: 0.01831

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.10005
Policy Update Magnitude: 0.49636
Value Function Update Magnitude: 0.68546

Collected Steps per Second: 23,165.16169
Overall Steps per Second: 10,869.77024

Timestep Collection Time: 2.15936
Timestep Consumption Time: 2.44257
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.60194

Cumulative Model Updates: 301,622
Cumulative Timesteps: 2,515,443,008

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2515443008...
Checkpoint 2515443008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.76764
Policy Entropy: 2.42881
Value Function Loss: 0.01774

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.10822
Policy Update Magnitude: 0.49148
Value Function Update Magnitude: 0.65912

Collected Steps per Second: 22,288.74962
Overall Steps per Second: 10,648.96277

Timestep Collection Time: 2.24355
Timestep Consumption Time: 2.45230
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.69586

Cumulative Model Updates: 301,628
Cumulative Timesteps: 2,515,493,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.90425
Policy Entropy: 2.42823
Value Function Loss: 0.01964

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.10693
Policy Update Magnitude: 0.48519
Value Function Update Magnitude: 0.66034

Collected Steps per Second: 22,323.83041
Overall Steps per Second: 10,581.47467

Timestep Collection Time: 2.24065
Timestep Consumption Time: 2.48647
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.72713

Cumulative Model Updates: 301,634
Cumulative Timesteps: 2,515,543,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2515543034...
Checkpoint 2515543034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.70209
Policy Entropy: 2.43671
Value Function Loss: 0.01908

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.11025
Policy Update Magnitude: 0.48909
Value Function Update Magnitude: 0.65332

Collected Steps per Second: 21,804.54167
Overall Steps per Second: 10,606.46455

Timestep Collection Time: 2.29328
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.28193
Total Iteration Time: 4.71448

Cumulative Model Updates: 301,640
Cumulative Timesteps: 2,515,593,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.19472
Policy Entropy: 2.45068
Value Function Loss: 0.01785

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.10141
Policy Update Magnitude: 0.48800
Value Function Update Magnitude: 0.63049

Collected Steps per Second: 22,412.46626
Overall Steps per Second: 10,695.93215

Timestep Collection Time: 2.23215
Timestep Consumption Time: 2.44514
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.67729

Cumulative Model Updates: 301,646
Cumulative Timesteps: 2,515,643,066

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2515643066...
Checkpoint 2515643066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.55967
Policy Entropy: 2.46914
Value Function Loss: 0.01687

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.09730
Policy Update Magnitude: 0.48049
Value Function Update Magnitude: 0.61315

Collected Steps per Second: 21,839.88689
Overall Steps per Second: 10,326.75192

Timestep Collection Time: 2.28994
Timestep Consumption Time: 2.55302
PPO Batch Consumption Time: 0.30003
Total Iteration Time: 4.84296

Cumulative Model Updates: 301,652
Cumulative Timesteps: 2,515,693,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.53117
Policy Entropy: 2.49015
Value Function Loss: 0.01651

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.09411
Policy Update Magnitude: 0.47263
Value Function Update Magnitude: 0.61979

Collected Steps per Second: 22,651.11834
Overall Steps per Second: 10,527.87459

Timestep Collection Time: 2.20801
Timestep Consumption Time: 2.54261
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.75063

Cumulative Model Updates: 301,658
Cumulative Timesteps: 2,515,743,092

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2515743092...
Checkpoint 2515743092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.04480
Policy Entropy: 2.49330
Value Function Loss: 0.01670

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.09080
Policy Update Magnitude: 0.47364
Value Function Update Magnitude: 0.62472

Collected Steps per Second: 22,787.20417
Overall Steps per Second: 10,942.19986

Timestep Collection Time: 2.19448
Timestep Consumption Time: 2.37554
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.57001

Cumulative Model Updates: 301,664
Cumulative Timesteps: 2,515,793,098

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.55829
Policy Entropy: 2.48793
Value Function Loss: 0.01616

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 0.47327
Value Function Update Magnitude: 0.63545

Collected Steps per Second: 23,253.81585
Overall Steps per Second: 10,765.21001

Timestep Collection Time: 2.15087
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.64608

Cumulative Model Updates: 301,670
Cumulative Timesteps: 2,515,843,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2515843114...
Checkpoint 2515843114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.65025
Policy Entropy: 2.46627
Value Function Loss: 0.01622

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09591
Policy Update Magnitude: 0.47254
Value Function Update Magnitude: 0.63511

Collected Steps per Second: 22,674.81161
Overall Steps per Second: 10,767.59462

Timestep Collection Time: 2.20544
Timestep Consumption Time: 2.43886
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.64431

Cumulative Model Updates: 301,676
Cumulative Timesteps: 2,515,893,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.85733
Policy Entropy: 2.44872
Value Function Loss: 0.01640

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.08866
Policy Update Magnitude: 0.46831
Value Function Update Magnitude: 0.62209

Collected Steps per Second: 22,873.92534
Overall Steps per Second: 10,729.74907

Timestep Collection Time: 2.18677
Timestep Consumption Time: 2.47504
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.66181

Cumulative Model Updates: 301,682
Cumulative Timesteps: 2,515,943,142

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2515943142...
Checkpoint 2515943142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.03203
Policy Entropy: 2.45842
Value Function Loss: 0.01744

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.09621
Policy Update Magnitude: 0.46882
Value Function Update Magnitude: 0.58566

Collected Steps per Second: 22,624.33716
Overall Steps per Second: 10,939.54300

Timestep Collection Time: 2.21063
Timestep Consumption Time: 2.36123
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.57185

Cumulative Model Updates: 301,688
Cumulative Timesteps: 2,515,993,156

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.15628
Policy Entropy: 2.44186
Value Function Loss: 0.01805

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.09907
Policy Update Magnitude: 0.47091
Value Function Update Magnitude: 0.59623

Collected Steps per Second: 23,268.63933
Overall Steps per Second: 10,899.37595

Timestep Collection Time: 2.14890
Timestep Consumption Time: 2.43870
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.58760

Cumulative Model Updates: 301,694
Cumulative Timesteps: 2,516,043,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2516043158...
Checkpoint 2516043158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.82179
Policy Entropy: 2.46286
Value Function Loss: 0.01744

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.10091
Policy Update Magnitude: 0.47276
Value Function Update Magnitude: 0.61506

Collected Steps per Second: 21,825.71033
Overall Steps per Second: 10,575.95436

Timestep Collection Time: 2.29170
Timestep Consumption Time: 2.43771
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.72941

Cumulative Model Updates: 301,700
Cumulative Timesteps: 2,516,093,176

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.28822
Policy Entropy: 2.44349
Value Function Loss: 0.01653

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.09770
Policy Update Magnitude: 0.46600
Value Function Update Magnitude: 0.60061

Collected Steps per Second: 22,633.11751
Overall Steps per Second: 10,685.89561

Timestep Collection Time: 2.21030
Timestep Consumption Time: 2.47120
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.68150

Cumulative Model Updates: 301,706
Cumulative Timesteps: 2,516,143,202

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2516143202...
Checkpoint 2516143202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.80512
Policy Entropy: 2.43720
Value Function Loss: 0.01670

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.09405
Policy Update Magnitude: 0.47010
Value Function Update Magnitude: 0.58805

Collected Steps per Second: 22,812.49649
Overall Steps per Second: 10,797.30352

Timestep Collection Time: 2.19257
Timestep Consumption Time: 2.43988
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.63245

Cumulative Model Updates: 301,712
Cumulative Timesteps: 2,516,193,220

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 340.65720
Policy Entropy: 2.43221
Value Function Loss: 0.01628

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.48076
Value Function Update Magnitude: 0.58971

Collected Steps per Second: 22,878.85556
Overall Steps per Second: 10,631.35726

Timestep Collection Time: 2.18595
Timestep Consumption Time: 2.51825
PPO Batch Consumption Time: 0.29487
Total Iteration Time: 4.70420

Cumulative Model Updates: 301,718
Cumulative Timesteps: 2,516,243,232

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2516243232...
Checkpoint 2516243232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.71967
Policy Entropy: 2.43935
Value Function Loss: 0.01803

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.48307
Value Function Update Magnitude: 0.61583

Collected Steps per Second: 22,403.90155
Overall Steps per Second: 10,586.26031

Timestep Collection Time: 2.23247
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.72461

Cumulative Model Updates: 301,724
Cumulative Timesteps: 2,516,293,248

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.44996
Policy Entropy: 2.46466
Value Function Loss: 0.01702

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09748
Policy Update Magnitude: 0.48069
Value Function Update Magnitude: 0.62277

Collected Steps per Second: 22,904.19829
Overall Steps per Second: 10,845.69549

Timestep Collection Time: 2.18301
Timestep Consumption Time: 2.42712
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.61012

Cumulative Model Updates: 301,730
Cumulative Timesteps: 2,516,343,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2516343248...
Checkpoint 2516343248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.68605
Policy Entropy: 2.47358
Value Function Loss: 0.01668

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.08588
Policy Update Magnitude: 0.46565
Value Function Update Magnitude: 0.61284

Collected Steps per Second: 22,615.02762
Overall Steps per Second: 10,722.47283

Timestep Collection Time: 2.21295
Timestep Consumption Time: 2.45444
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.66739

Cumulative Model Updates: 301,736
Cumulative Timesteps: 2,516,393,294

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.75718
Policy Entropy: 2.49434
Value Function Loss: 0.01514

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.08880
Policy Update Magnitude: 0.45033
Value Function Update Magnitude: 0.59299

Collected Steps per Second: 21,960.83306
Overall Steps per Second: 10,430.85093

Timestep Collection Time: 2.27824
Timestep Consumption Time: 2.51830
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.79654

Cumulative Model Updates: 301,742
Cumulative Timesteps: 2,516,443,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2516443326...
Checkpoint 2516443326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243.32189
Policy Entropy: 2.47548
Value Function Loss: 0.01577

Mean KL Divergence: 0.01257
SB3 Clip Fraction: 0.09592
Policy Update Magnitude: 0.46036
Value Function Update Magnitude: 0.57966

Collected Steps per Second: 21,903.36454
Overall Steps per Second: 10,623.53205

Timestep Collection Time: 2.28348
Timestep Consumption Time: 2.42455
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.70804

Cumulative Model Updates: 301,748
Cumulative Timesteps: 2,516,493,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.36563
Policy Entropy: 2.46608
Value Function Loss: 0.01685

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.46518
Value Function Update Magnitude: 0.57335

Collected Steps per Second: 22,358.11826
Overall Steps per Second: 10,868.45442

Timestep Collection Time: 2.23758
Timestep Consumption Time: 2.36547
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.60305

Cumulative Model Updates: 301,754
Cumulative Timesteps: 2,516,543,370

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2516543370...
Checkpoint 2516543370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.42038
Policy Entropy: 2.44951
Value Function Loss: 0.01821

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.47993
Value Function Update Magnitude: 0.58959

Collected Steps per Second: 22,624.09265
Overall Steps per Second: 10,696.19746

Timestep Collection Time: 2.21118
Timestep Consumption Time: 2.46581
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.67699

Cumulative Model Updates: 301,760
Cumulative Timesteps: 2,516,593,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.44106
Policy Entropy: 2.46303
Value Function Loss: 0.01795

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.48536
Value Function Update Magnitude: 0.61744

Collected Steps per Second: 23,199.56743
Overall Steps per Second: 10,826.39873

Timestep Collection Time: 2.15625
Timestep Consumption Time: 2.46431
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.62056

Cumulative Model Updates: 301,766
Cumulative Timesteps: 2,516,643,420

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2516643420...
Checkpoint 2516643420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.59809
Policy Entropy: 2.46618
Value Function Loss: 0.01762

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.08605
Policy Update Magnitude: 0.47717
Value Function Update Magnitude: 0.61823

Collected Steps per Second: 21,794.05779
Overall Steps per Second: 10,621.90012

Timestep Collection Time: 2.29430
Timestep Consumption Time: 2.41315
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.70744

Cumulative Model Updates: 301,772
Cumulative Timesteps: 2,516,693,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.27232
Policy Entropy: 2.46903
Value Function Loss: 0.01752

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.08185
Policy Update Magnitude: 0.48017
Value Function Update Magnitude: 0.61944

Collected Steps per Second: 22,962.58811
Overall Steps per Second: 11,006.41491

Timestep Collection Time: 2.17745
Timestep Consumption Time: 2.36535
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.54281

Cumulative Model Updates: 301,778
Cumulative Timesteps: 2,516,743,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2516743422...
Checkpoint 2516743422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.47427
Policy Entropy: 2.44672
Value Function Loss: 0.01802

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.49226
Value Function Update Magnitude: 0.64237

Collected Steps per Second: 22,669.84533
Overall Steps per Second: 10,659.80310

Timestep Collection Time: 2.20575
Timestep Consumption Time: 2.48514
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.69089

Cumulative Model Updates: 301,784
Cumulative Timesteps: 2,516,793,426

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266.26559
Policy Entropy: 2.44526
Value Function Loss: 0.01778

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.09109
Policy Update Magnitude: 0.49778
Value Function Update Magnitude: 0.66856

Collected Steps per Second: 23,116.35300
Overall Steps per Second: 10,850.54676

Timestep Collection Time: 2.16366
Timestep Consumption Time: 2.44587
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.60954

Cumulative Model Updates: 301,790
Cumulative Timesteps: 2,516,843,442

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2516843442...
Checkpoint 2516843442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.33966
Policy Entropy: 2.44301
Value Function Loss: 0.01753

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.08981
Policy Update Magnitude: 0.49148
Value Function Update Magnitude: 0.68387

Collected Steps per Second: 21,927.71492
Overall Steps per Second: 10,604.59621

Timestep Collection Time: 2.28068
Timestep Consumption Time: 2.43520
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.71588

Cumulative Model Updates: 301,796
Cumulative Timesteps: 2,516,893,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.00876
Policy Entropy: 2.44572
Value Function Loss: 0.01679

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.48622
Value Function Update Magnitude: 0.66481

Collected Steps per Second: 23,387.09496
Overall Steps per Second: 10,919.65629

Timestep Collection Time: 2.13793
Timestep Consumption Time: 2.44097
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.57890

Cumulative Model Updates: 301,802
Cumulative Timesteps: 2,516,943,452

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2516943452...
Checkpoint 2516943452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.38463
Policy Entropy: 2.44732
Value Function Loss: 0.01667

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.09274
Policy Update Magnitude: 0.48164
Value Function Update Magnitude: 0.65737

Collected Steps per Second: 22,309.30284
Overall Steps per Second: 10,576.36449

Timestep Collection Time: 2.24140
Timestep Consumption Time: 2.48650
PPO Batch Consumption Time: 0.28518
Total Iteration Time: 4.72790

Cumulative Model Updates: 301,808
Cumulative Timesteps: 2,516,993,456

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.08105
Policy Entropy: 2.44871
Value Function Loss: 0.01631

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.08961
Policy Update Magnitude: 0.47808
Value Function Update Magnitude: 0.64931

Collected Steps per Second: 22,128.83851
Overall Steps per Second: 10,634.66245

Timestep Collection Time: 2.25995
Timestep Consumption Time: 2.44260
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.70255

Cumulative Model Updates: 301,814
Cumulative Timesteps: 2,517,043,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2517043466...
Checkpoint 2517043466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.88986
Policy Entropy: 2.46518
Value Function Loss: 0.01664

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.10524
Policy Update Magnitude: 0.47633
Value Function Update Magnitude: 0.63362

Collected Steps per Second: 22,298.71534
Overall Steps per Second: 10,712.54459

Timestep Collection Time: 2.24372
Timestep Consumption Time: 2.42670
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.67041

Cumulative Model Updates: 301,820
Cumulative Timesteps: 2,517,093,498

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.30187
Policy Entropy: 2.45238
Value Function Loss: 0.01720

Mean KL Divergence: 0.01906
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.47104
Value Function Update Magnitude: 0.63818

Collected Steps per Second: 23,356.65386
Overall Steps per Second: 10,822.77858

Timestep Collection Time: 2.14072
Timestep Consumption Time: 2.47917
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.61989

Cumulative Model Updates: 301,826
Cumulative Timesteps: 2,517,143,498

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2517143498...
Checkpoint 2517143498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 288.32151
Policy Entropy: 2.46177
Value Function Loss: 0.01678

Mean KL Divergence: 0.01782
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.49231
Value Function Update Magnitude: 0.64353

Collected Steps per Second: 22,467.89986
Overall Steps per Second: 10,593.30853

Timestep Collection Time: 2.22575
Timestep Consumption Time: 2.49496
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.72072

Cumulative Model Updates: 301,832
Cumulative Timesteps: 2,517,193,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377.65492
Policy Entropy: 2.45039
Value Function Loss: 0.01631

Mean KL Divergence: 0.01667
SB3 Clip Fraction: 0.11640
Policy Update Magnitude: 0.48341
Value Function Update Magnitude: 0.62324

Collected Steps per Second: 23,275.76849
Overall Steps per Second: 10,956.84845

Timestep Collection Time: 2.14919
Timestep Consumption Time: 2.41636
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.56555

Cumulative Model Updates: 301,838
Cumulative Timesteps: 2,517,243,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2517243530...
Checkpoint 2517243530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.18820
Policy Entropy: 2.44111
Value Function Loss: 0.01724

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.09784
Policy Update Magnitude: 0.48294
Value Function Update Magnitude: 0.61438

Collected Steps per Second: 22,535.64168
Overall Steps per Second: 10,815.42975

Timestep Collection Time: 2.21995
Timestep Consumption Time: 2.40566
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.62561

Cumulative Model Updates: 301,844
Cumulative Timesteps: 2,517,293,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.74144
Policy Entropy: 2.44007
Value Function Loss: 0.01685

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.09347
Policy Update Magnitude: 0.47906
Value Function Update Magnitude: 0.61657

Collected Steps per Second: 22,681.19472
Overall Steps per Second: 10,717.52272

Timestep Collection Time: 2.20535
Timestep Consumption Time: 2.46177
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.66712

Cumulative Model Updates: 301,850
Cumulative Timesteps: 2,517,343,578

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2517343578...
Checkpoint 2517343578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.61475
Policy Entropy: 2.42328
Value Function Loss: 0.01794

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.09111
Policy Update Magnitude: 0.47980
Value Function Update Magnitude: 0.63038

Collected Steps per Second: 22,678.03198
Overall Steps per Second: 10,688.40446

Timestep Collection Time: 2.20531
Timestep Consumption Time: 2.47378
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.67909

Cumulative Model Updates: 301,856
Cumulative Timesteps: 2,517,393,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243.61340
Policy Entropy: 2.43787
Value Function Loss: 0.01805

Mean KL Divergence: 0.01279
SB3 Clip Fraction: 0.09530
Policy Update Magnitude: 0.49176
Value Function Update Magnitude: 0.65545

Collected Steps per Second: 22,503.19112
Overall Steps per Second: 10,779.47029

Timestep Collection Time: 2.22226
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.63919

Cumulative Model Updates: 301,862
Cumulative Timesteps: 2,517,443,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2517443598...
Checkpoint 2517443598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.60399
Policy Entropy: 2.45411
Value Function Loss: 0.01745

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09134
Policy Update Magnitude: 0.48865
Value Function Update Magnitude: 0.66440

Collected Steps per Second: 22,026.72079
Overall Steps per Second: 10,716.31206

Timestep Collection Time: 2.27070
Timestep Consumption Time: 2.39658
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.66728

Cumulative Model Updates: 301,868
Cumulative Timesteps: 2,517,493,614

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336.70447
Policy Entropy: 2.44707
Value Function Loss: 0.01692

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.08962
Policy Update Magnitude: 0.48290
Value Function Update Magnitude: 0.65439

Collected Steps per Second: 22,319.99278
Overall Steps per Second: 10,514.67264

Timestep Collection Time: 2.24023
Timestep Consumption Time: 2.51522
PPO Batch Consumption Time: 0.29451
Total Iteration Time: 4.75545

Cumulative Model Updates: 301,874
Cumulative Timesteps: 2,517,543,616

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2517543616...
Checkpoint 2517543616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.67688
Policy Entropy: 2.44952
Value Function Loss: 0.01707

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.09985
Policy Update Magnitude: 0.48460
Value Function Update Magnitude: 0.64355

Collected Steps per Second: 22,125.44405
Overall Steps per Second: 10,654.91195

Timestep Collection Time: 2.26056
Timestep Consumption Time: 2.43361
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.69417

Cumulative Model Updates: 301,880
Cumulative Timesteps: 2,517,593,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.40508
Policy Entropy: 2.41670
Value Function Loss: 0.01742

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.10319
Policy Update Magnitude: 0.49166
Value Function Update Magnitude: 0.65588

Collected Steps per Second: 22,934.44542
Overall Steps per Second: 10,674.77560

Timestep Collection Time: 2.18117
Timestep Consumption Time: 2.50501
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.68619

Cumulative Model Updates: 301,886
Cumulative Timesteps: 2,517,643,656

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2517643656...
Checkpoint 2517643656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.56198
Policy Entropy: 2.44234
Value Function Loss: 0.01647

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.10621
Policy Update Magnitude: 0.49041
Value Function Update Magnitude: 0.65700

Collected Steps per Second: 22,056.74129
Overall Steps per Second: 10,615.20811

Timestep Collection Time: 2.26742
Timestep Consumption Time: 2.44393
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.71135

Cumulative Model Updates: 301,892
Cumulative Timesteps: 2,517,693,668

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.86481
Policy Entropy: 2.42921
Value Function Loss: 0.01665

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.09681
Policy Update Magnitude: 0.48268
Value Function Update Magnitude: 0.63748

Collected Steps per Second: 23,428.40502
Overall Steps per Second: 10,782.94349

Timestep Collection Time: 2.13416
Timestep Consumption Time: 2.50279
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.63695

Cumulative Model Updates: 301,898
Cumulative Timesteps: 2,517,743,668

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2517743668...
Checkpoint 2517743668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.12056
Policy Entropy: 2.43487
Value Function Loss: 0.01644

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.08822
Policy Update Magnitude: 0.47332
Value Function Update Magnitude: 0.62900

Collected Steps per Second: 22,366.94625
Overall Steps per Second: 10,519.51830

Timestep Collection Time: 2.23643
Timestep Consumption Time: 2.51874
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.75516

Cumulative Model Updates: 301,904
Cumulative Timesteps: 2,517,793,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.09192
Policy Entropy: 2.42110
Value Function Loss: 0.01783

Mean KL Divergence: 0.01493
SB3 Clip Fraction: 0.10003
Policy Update Magnitude: 0.48103
Value Function Update Magnitude: 0.62974

Collected Steps per Second: 23,143.47394
Overall Steps per Second: 10,886.15609

Timestep Collection Time: 2.16070
Timestep Consumption Time: 2.43285
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.59354

Cumulative Model Updates: 301,910
Cumulative Timesteps: 2,517,843,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2517843696...
Checkpoint 2517843696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.87519
Policy Entropy: 2.41118
Value Function Loss: 0.01808

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.08935
Policy Update Magnitude: 0.49884
Value Function Update Magnitude: 0.65340

Collected Steps per Second: 23,092.54447
Overall Steps per Second: 10,690.98840

Timestep Collection Time: 2.16537
Timestep Consumption Time: 2.51184
PPO Batch Consumption Time: 0.29517
Total Iteration Time: 4.67721

Cumulative Model Updates: 301,916
Cumulative Timesteps: 2,517,893,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.74806
Policy Entropy: 2.40692
Value Function Loss: 0.01808

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.08593
Policy Update Magnitude: 0.49487
Value Function Update Magnitude: 0.66764

Collected Steps per Second: 23,122.81981
Overall Steps per Second: 10,860.06433

Timestep Collection Time: 2.16280
Timestep Consumption Time: 2.44215
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.60495

Cumulative Model Updates: 301,922
Cumulative Timesteps: 2,517,943,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2517943710...
Checkpoint 2517943710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.71324
Policy Entropy: 2.40745
Value Function Loss: 0.01722

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.08996
Policy Update Magnitude: 0.48328
Value Function Update Magnitude: 0.64595

Collected Steps per Second: 21,704.34949
Overall Steps per Second: 10,619.25415

Timestep Collection Time: 2.30442
Timestep Consumption Time: 2.40551
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.70994

Cumulative Model Updates: 301,928
Cumulative Timesteps: 2,517,993,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.36697
Policy Entropy: 2.42140
Value Function Loss: 0.01684

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.08819
Policy Update Magnitude: 0.48377
Value Function Update Magnitude: 0.62162

Collected Steps per Second: 22,726.97838
Overall Steps per Second: 10,889.21293

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.39225
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.59280

Cumulative Model Updates: 301,934
Cumulative Timesteps: 2,518,043,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2518043738...
Checkpoint 2518043738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.64468
Policy Entropy: 2.39930
Value Function Loss: 0.01853

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.49525
Value Function Update Magnitude: 0.62743

Collected Steps per Second: 21,935.80111
Overall Steps per Second: 10,619.08199

Timestep Collection Time: 2.27974
Timestep Consumption Time: 2.42951
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.70926

Cumulative Model Updates: 301,940
Cumulative Timesteps: 2,518,093,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.39076
Policy Entropy: 2.39269
Value Function Loss: 0.02007

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.10633
Policy Update Magnitude: 0.50832
Value Function Update Magnitude: 0.65783

Collected Steps per Second: 22,404.06761
Overall Steps per Second: 10,580.62049

Timestep Collection Time: 2.23290
Timestep Consumption Time: 2.49518
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.72808

Cumulative Model Updates: 301,946
Cumulative Timesteps: 2,518,143,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2518143772...
Checkpoint 2518143772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.63724
Policy Entropy: 2.38425
Value Function Loss: 0.02041

Mean KL Divergence: 0.01763
SB3 Clip Fraction: 0.10930
Policy Update Magnitude: 0.51738
Value Function Update Magnitude: 0.68608

Collected Steps per Second: 22,004.29190
Overall Steps per Second: 10,670.00884

Timestep Collection Time: 2.27419
Timestep Consumption Time: 2.41578
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.68997

Cumulative Model Updates: 301,952
Cumulative Timesteps: 2,518,193,814

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.34874
Policy Entropy: 2.38802
Value Function Loss: 0.01972

Mean KL Divergence: 0.01921
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.49356
Value Function Update Magnitude: 0.68469

Collected Steps per Second: 24,152.51690
Overall Steps per Second: 10,905.32963

Timestep Collection Time: 2.07109
Timestep Consumption Time: 2.51584
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.58693

Cumulative Model Updates: 301,958
Cumulative Timesteps: 2,518,243,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2518243836...
Checkpoint 2518243836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.29527
Policy Entropy: 2.39195
Value Function Loss: 0.01902

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.10476
Policy Update Magnitude: 0.49731
Value Function Update Magnitude: 0.67606

Collected Steps per Second: 22,544.32872
Overall Steps per Second: 10,590.59635

Timestep Collection Time: 2.21794
Timestep Consumption Time: 2.50342
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.72136

Cumulative Model Updates: 301,964
Cumulative Timesteps: 2,518,293,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276.04707
Policy Entropy: 2.40691
Value Function Loss: 0.01906

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.51108
Value Function Update Magnitude: 0.68081

Collected Steps per Second: 22,566.51565
Overall Steps per Second: 10,453.30673

Timestep Collection Time: 2.21620
Timestep Consumption Time: 2.56812
PPO Batch Consumption Time: 0.30016
Total Iteration Time: 4.78432

Cumulative Model Updates: 301,970
Cumulative Timesteps: 2,518,343,850

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2518343850...
Checkpoint 2518343850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.38510
Policy Entropy: 2.40438
Value Function Loss: 0.01768

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.09604
Policy Update Magnitude: 0.50164
Value Function Update Magnitude: 0.68751

Collected Steps per Second: 22,104.07447
Overall Steps per Second: 10,618.85949

Timestep Collection Time: 2.26203
Timestep Consumption Time: 2.44658
PPO Batch Consumption Time: 0.29570
Total Iteration Time: 4.70860

Cumulative Model Updates: 301,976
Cumulative Timesteps: 2,518,393,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.58492
Policy Entropy: 2.41725
Value Function Loss: 0.01750

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.10244
Policy Update Magnitude: 0.49174
Value Function Update Magnitude: 0.65306

Collected Steps per Second: 23,252.89502
Overall Steps per Second: 10,869.76276

Timestep Collection Time: 2.15036
Timestep Consumption Time: 2.44974
PPO Batch Consumption Time: 0.28189
Total Iteration Time: 4.60010

Cumulative Model Updates: 301,982
Cumulative Timesteps: 2,518,443,852

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2518443852...
Checkpoint 2518443852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.41289
Policy Entropy: 2.41894
Value Function Loss: 0.01729

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.09662
Policy Update Magnitude: 0.47349
Value Function Update Magnitude: 0.62833

Collected Steps per Second: 22,013.11591
Overall Steps per Second: 10,663.40657

Timestep Collection Time: 2.27265
Timestep Consumption Time: 2.41891
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.69156

Cumulative Model Updates: 301,988
Cumulative Timesteps: 2,518,493,880

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.66385
Policy Entropy: 2.43794
Value Function Loss: 0.01779

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.09026
Policy Update Magnitude: 0.47758
Value Function Update Magnitude: 0.64459

Collected Steps per Second: 22,753.16272
Overall Steps per Second: 10,725.14528

Timestep Collection Time: 2.19794
Timestep Consumption Time: 2.46494
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.66287

Cumulative Model Updates: 301,994
Cumulative Timesteps: 2,518,543,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2518543890...
Checkpoint 2518543890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.34242
Policy Entropy: 2.42851
Value Function Loss: 0.01817

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.09186
Policy Update Magnitude: 0.48822
Value Function Update Magnitude: 0.64885

Collected Steps per Second: 22,970.77374
Overall Steps per Second: 10,905.37558

Timestep Collection Time: 2.17711
Timestep Consumption Time: 2.40870
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.58581

Cumulative Model Updates: 302,000
Cumulative Timesteps: 2,518,593,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.52906
Policy Entropy: 2.40822
Value Function Loss: 0.01974

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.49588
Value Function Update Magnitude: 0.67202

Collected Steps per Second: 23,044.74036
Overall Steps per Second: 10,821.75679

Timestep Collection Time: 2.17030
Timestep Consumption Time: 2.45132
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.62162

Cumulative Model Updates: 302,006
Cumulative Timesteps: 2,518,643,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2518643914...
Checkpoint 2518643914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.16361
Policy Entropy: 2.40012
Value Function Loss: 0.02066

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.10678
Policy Update Magnitude: 0.50582
Value Function Update Magnitude: 0.70533

Collected Steps per Second: 21,937.66864
Overall Steps per Second: 10,599.40188

Timestep Collection Time: 2.28019
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.28010
Total Iteration Time: 4.71932

Cumulative Model Updates: 302,012
Cumulative Timesteps: 2,518,693,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291.58801
Policy Entropy: 2.41527
Value Function Loss: 0.01959

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.50443
Value Function Update Magnitude: 0.69488

Collected Steps per Second: 23,121.26754
Overall Steps per Second: 11,000.98200

Timestep Collection Time: 2.16268
Timestep Consumption Time: 2.38273
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.54541

Cumulative Model Updates: 302,018
Cumulative Timesteps: 2,518,743,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2518743940...
Checkpoint 2518743940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.48115
Policy Entropy: 2.41593
Value Function Loss: 0.01984

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.10422
Policy Update Magnitude: 0.50278
Value Function Update Magnitude: 0.66752

Collected Steps per Second: 22,490.95741
Overall Steps per Second: 10,672.55902

Timestep Collection Time: 2.22356
Timestep Consumption Time: 2.46229
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.68585

Cumulative Model Updates: 302,024
Cumulative Timesteps: 2,518,793,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.92759
Policy Entropy: 2.40144
Value Function Loss: 0.01894

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.09767
Policy Update Magnitude: 0.49925
Value Function Update Magnitude: 0.66893

Collected Steps per Second: 23,279.75775
Overall Steps per Second: 10,889.85071

Timestep Collection Time: 2.14873
Timestep Consumption Time: 2.44472
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.59345

Cumulative Model Updates: 302,030
Cumulative Timesteps: 2,518,843,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2518843972...
Checkpoint 2518843972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339.67086
Policy Entropy: 2.40206
Value Function Loss: 0.01845

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.10381
Policy Update Magnitude: 0.49949
Value Function Update Magnitude: 0.66088

Collected Steps per Second: 22,034.78743
Overall Steps per Second: 10,634.94781

Timestep Collection Time: 2.26941
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.70204

Cumulative Model Updates: 302,036
Cumulative Timesteps: 2,518,893,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.26307
Policy Entropy: 2.41644
Value Function Loss: 0.01708

Mean KL Divergence: 0.01499
SB3 Clip Fraction: 0.10453
Policy Update Magnitude: 0.48266
Value Function Update Magnitude: 0.63604

Collected Steps per Second: 22,929.13695
Overall Steps per Second: 10,943.88503

Timestep Collection Time: 2.18107
Timestep Consumption Time: 2.38861
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.56968

Cumulative Model Updates: 302,042
Cumulative Timesteps: 2,518,943,988

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2518943988...
Checkpoint 2518943988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.17419
Policy Entropy: 2.45093
Value Function Loss: 0.01631

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.10117
Policy Update Magnitude: 0.47813
Value Function Update Magnitude: 0.63148

Collected Steps per Second: 22,467.39330
Overall Steps per Second: 10,563.22521

Timestep Collection Time: 2.22589
Timestep Consumption Time: 2.50846
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.73435

Cumulative Model Updates: 302,048
Cumulative Timesteps: 2,518,993,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.69725
Policy Entropy: 2.43438
Value Function Loss: 0.01636

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.09389
Policy Update Magnitude: 0.47598
Value Function Update Magnitude: 0.63333

Collected Steps per Second: 22,059.04601
Overall Steps per Second: 10,510.86366

Timestep Collection Time: 2.26719
Timestep Consumption Time: 2.49094
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.75812

Cumulative Model Updates: 302,054
Cumulative Timesteps: 2,519,044,010

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2519044010...
Checkpoint 2519044010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.90784
Policy Entropy: 2.43997
Value Function Loss: 0.01615

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.09721
Policy Update Magnitude: 0.47782
Value Function Update Magnitude: 0.64683

Collected Steps per Second: 21,662.39150
Overall Steps per Second: 10,627.86051

Timestep Collection Time: 2.30907
Timestep Consumption Time: 2.39743
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.70650

Cumulative Model Updates: 302,060
Cumulative Timesteps: 2,519,094,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.68602
Policy Entropy: 2.42948
Value Function Loss: 0.01626

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.10111
Policy Update Magnitude: 0.47229
Value Function Update Magnitude: 0.64097

Collected Steps per Second: 22,740.93279
Overall Steps per Second: 10,908.31178

Timestep Collection Time: 2.19868
Timestep Consumption Time: 2.38498
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.58366

Cumulative Model Updates: 302,066
Cumulative Timesteps: 2,519,144,030

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2519144030...
Checkpoint 2519144030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.19768
Policy Entropy: 2.44664
Value Function Loss: 0.01594

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.46768
Value Function Update Magnitude: 0.64992

Collected Steps per Second: 22,180.78524
Overall Steps per Second: 10,691.46097

Timestep Collection Time: 2.25429
Timestep Consumption Time: 2.42252
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.67682

Cumulative Model Updates: 302,072
Cumulative Timesteps: 2,519,194,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308.05040
Policy Entropy: 2.43321
Value Function Loss: 0.01639

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.09833
Policy Update Magnitude: 0.47501
Value Function Update Magnitude: 0.66204

Collected Steps per Second: 23,042.66391
Overall Steps per Second: 10,783.59806

Timestep Collection Time: 2.16997
Timestep Consumption Time: 2.46688
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.63686

Cumulative Model Updates: 302,078
Cumulative Timesteps: 2,519,244,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2519244034...
Checkpoint 2519244034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245.67276
Policy Entropy: 2.42613
Value Function Loss: 0.01655

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.08978
Policy Update Magnitude: 0.47663
Value Function Update Magnitude: 0.69382

Collected Steps per Second: 22,295.78459
Overall Steps per Second: 10,662.48258

Timestep Collection Time: 2.24302
Timestep Consumption Time: 2.44725
PPO Batch Consumption Time: 0.28587
Total Iteration Time: 4.69028

Cumulative Model Updates: 302,084
Cumulative Timesteps: 2,519,294,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.57753
Policy Entropy: 2.44469
Value Function Loss: 0.01723

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.47470
Value Function Update Magnitude: 0.68116

Collected Steps per Second: 23,151.68450
Overall Steps per Second: 10,959.17596

Timestep Collection Time: 2.16010
Timestep Consumption Time: 2.40320
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.56330

Cumulative Model Updates: 302,090
Cumulative Timesteps: 2,519,344,054

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2519344054...
Checkpoint 2519344054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.91629
Policy Entropy: 2.45208
Value Function Loss: 0.01735

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.08511
Policy Update Magnitude: 0.46578
Value Function Update Magnitude: 0.67450

Collected Steps per Second: 22,655.49830
Overall Steps per Second: 10,670.94967

Timestep Collection Time: 2.20812
Timestep Consumption Time: 2.47994
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.68806

Cumulative Model Updates: 302,096
Cumulative Timesteps: 2,519,394,080

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.62691
Policy Entropy: 2.45143
Value Function Loss: 0.01767

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.09594
Policy Update Magnitude: 0.47226
Value Function Update Magnitude: 0.67412

Collected Steps per Second: 23,310.10914
Overall Steps per Second: 10,929.52422

Timestep Collection Time: 2.14551
Timestep Consumption Time: 2.43036
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.57586

Cumulative Model Updates: 302,102
Cumulative Timesteps: 2,519,444,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2519444092...
Checkpoint 2519444092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.03509
Policy Entropy: 2.42530
Value Function Loss: 0.01779

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.09326
Policy Update Magnitude: 0.47599
Value Function Update Magnitude: 0.66577

Collected Steps per Second: 22,149.73233
Overall Steps per Second: 10,662.75113

Timestep Collection Time: 2.25772
Timestep Consumption Time: 2.43225
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.68997

Cumulative Model Updates: 302,108
Cumulative Timesteps: 2,519,494,100

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.36661
Policy Entropy: 2.43699
Value Function Loss: 0.01818

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.09310
Policy Update Magnitude: 0.47308
Value Function Update Magnitude: 0.65260

Collected Steps per Second: 22,829.85515
Overall Steps per Second: 10,809.48281

Timestep Collection Time: 2.19125
Timestep Consumption Time: 2.43672
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.62797

Cumulative Model Updates: 302,114
Cumulative Timesteps: 2,519,544,126

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2519544126...
Checkpoint 2519544126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.90071
Policy Entropy: 2.42411
Value Function Loss: 0.01741

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.09175
Policy Update Magnitude: 0.46757
Value Function Update Magnitude: 0.62819

Collected Steps per Second: 21,775.62062
Overall Steps per Second: 10,456.83753

Timestep Collection Time: 2.29633
Timestep Consumption Time: 2.48561
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.78194

Cumulative Model Updates: 302,120
Cumulative Timesteps: 2,519,594,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 378.74078
Policy Entropy: 2.43083
Value Function Loss: 0.01766

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.09494
Policy Update Magnitude: 0.47514
Value Function Update Magnitude: 0.63283

Collected Steps per Second: 22,926.44952
Overall Steps per Second: 10,568.44262

Timestep Collection Time: 2.18141
Timestep Consumption Time: 2.55079
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 4.73220

Cumulative Model Updates: 302,126
Cumulative Timesteps: 2,519,644,142

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2519644142...
Checkpoint 2519644142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.34795
Policy Entropy: 2.41266
Value Function Loss: 0.01717

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.47560
Value Function Update Magnitude: 0.65248

Collected Steps per Second: 22,086.65095
Overall Steps per Second: 10,670.60786

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.42205
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.68596

Cumulative Model Updates: 302,132
Cumulative Timesteps: 2,519,694,144

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.12550
Policy Entropy: 2.40499
Value Function Loss: 0.01757

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.09723
Policy Update Magnitude: 0.48417
Value Function Update Magnitude: 0.66082

Collected Steps per Second: 22,760.99075
Overall Steps per Second: 10,534.50754

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.54967
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.74650

Cumulative Model Updates: 302,138
Cumulative Timesteps: 2,519,744,146

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2519744146...
Checkpoint 2519744146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.73536
Policy Entropy: 2.39742
Value Function Loss: 0.01779

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.09428
Policy Update Magnitude: 0.49889
Value Function Update Magnitude: 0.67828

Collected Steps per Second: 22,500.90020
Overall Steps per Second: 10,601.57269

Timestep Collection Time: 2.22284
Timestep Consumption Time: 2.49495
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.71779

Cumulative Model Updates: 302,144
Cumulative Timesteps: 2,519,794,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.09404
Policy Entropy: 2.38239
Value Function Loss: 0.01802

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.09546
Policy Update Magnitude: 0.50026
Value Function Update Magnitude: 0.70205

Collected Steps per Second: 23,034.95531
Overall Steps per Second: 10,878.05989

Timestep Collection Time: 2.17114
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.59751

Cumulative Model Updates: 302,150
Cumulative Timesteps: 2,519,844,174

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2519844174...
Checkpoint 2519844174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.64026
Policy Entropy: 2.37750
Value Function Loss: 0.01829

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.09437
Policy Update Magnitude: 0.49813
Value Function Update Magnitude: 0.69898

Collected Steps per Second: 22,225.90502
Overall Steps per Second: 10,655.05499

Timestep Collection Time: 2.25071
Timestep Consumption Time: 2.44415
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.69486

Cumulative Model Updates: 302,156
Cumulative Timesteps: 2,519,894,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.76994
Policy Entropy: 2.37090
Value Function Loss: 0.01821

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.09355
Policy Update Magnitude: 0.49884
Value Function Update Magnitude: 0.69485

Collected Steps per Second: 21,780.63960
Overall Steps per Second: 10,427.85576

Timestep Collection Time: 2.29562
Timestep Consumption Time: 2.49923
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.79485

Cumulative Model Updates: 302,162
Cumulative Timesteps: 2,519,944,198

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2519944198...
Checkpoint 2519944198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.72816
Policy Entropy: 2.38237
Value Function Loss: 0.01731

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.10679
Policy Update Magnitude: 0.49737
Value Function Update Magnitude: 0.68463

Collected Steps per Second: 21,309.02691
Overall Steps per Second: 10,267.08653

Timestep Collection Time: 2.34671
Timestep Consumption Time: 2.52381
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.87052

Cumulative Model Updates: 302,168
Cumulative Timesteps: 2,519,994,204

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.61219
Policy Entropy: 2.39675
Value Function Loss: 0.01875

Mean KL Divergence: 0.01759
SB3 Clip Fraction: 0.10300
Policy Update Magnitude: 0.49686
Value Function Update Magnitude: 0.70072

Collected Steps per Second: 22,923.22192
Overall Steps per Second: 10,909.49035

Timestep Collection Time: 2.18146
Timestep Consumption Time: 2.40226
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.58372

Cumulative Model Updates: 302,174
Cumulative Timesteps: 2,520,044,210

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2520044210...
Checkpoint 2520044210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.88253
Policy Entropy: 2.41508
Value Function Loss: 0.01807

Mean KL Divergence: 0.01811
SB3 Clip Fraction: 0.10961
Policy Update Magnitude: 0.49044
Value Function Update Magnitude: 0.70401

Collected Steps per Second: 22,399.19601
Overall Steps per Second: 10,668.38867

Timestep Collection Time: 2.23365
Timestep Consumption Time: 2.45609
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.68974

Cumulative Model Updates: 302,180
Cumulative Timesteps: 2,520,094,242

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.81364
Policy Entropy: 2.41148
Value Function Loss: 0.01819

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.09991
Policy Update Magnitude: 0.49169
Value Function Update Magnitude: 0.67687

Collected Steps per Second: 22,564.36681
Overall Steps per Second: 10,606.64987

Timestep Collection Time: 2.21704
Timestep Consumption Time: 2.49944
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.71648

Cumulative Model Updates: 302,186
Cumulative Timesteps: 2,520,144,268

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2520144268...
Checkpoint 2520144268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.55215
Policy Entropy: 2.43046
Value Function Loss: 0.01674

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.48339
Value Function Update Magnitude: 0.65544

Collected Steps per Second: 21,862.71064
Overall Steps per Second: 10,474.63726

Timestep Collection Time: 2.28801
Timestep Consumption Time: 2.48753
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.77554

Cumulative Model Updates: 302,192
Cumulative Timesteps: 2,520,194,290

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.58479
Policy Entropy: 2.42653
Value Function Loss: 0.01664

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.47748
Value Function Update Magnitude: 0.66171

Collected Steps per Second: 22,398.15504
Overall Steps per Second: 10,849.25384

Timestep Collection Time: 2.23259
Timestep Consumption Time: 2.37657
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.60916

Cumulative Model Updates: 302,198
Cumulative Timesteps: 2,520,244,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2520244296...
Checkpoint 2520244296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302.21353
Policy Entropy: 2.43878
Value Function Loss: 0.01617

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.08523
Policy Update Magnitude: 0.46974
Value Function Update Magnitude: 0.66775

Collected Steps per Second: 21,972.65443
Overall Steps per Second: 10,621.46012

Timestep Collection Time: 2.27619
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.70877

Cumulative Model Updates: 302,204
Cumulative Timesteps: 2,520,294,310

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.50009
Policy Entropy: 2.41150
Value Function Loss: 0.01683

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.09636
Policy Update Magnitude: 0.47579
Value Function Update Magnitude: 0.65671

Collected Steps per Second: 22,392.04758
Overall Steps per Second: 10,417.54024

Timestep Collection Time: 2.23401
Timestep Consumption Time: 2.56789
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 4.80190

Cumulative Model Updates: 302,210
Cumulative Timesteps: 2,520,344,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2520344334...
Checkpoint 2520344334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261.19304
Policy Entropy: 2.39897
Value Function Loss: 0.01729

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.09568
Policy Update Magnitude: 0.47801
Value Function Update Magnitude: 0.65249

Collected Steps per Second: 22,572.70009
Overall Steps per Second: 10,782.50599

Timestep Collection Time: 2.21533
Timestep Consumption Time: 2.42237
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.63770

Cumulative Model Updates: 302,216
Cumulative Timesteps: 2,520,394,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.10232
Policy Entropy: 2.38319
Value Function Loss: 0.01808

Mean KL Divergence: 0.01643
SB3 Clip Fraction: 0.11303
Policy Update Magnitude: 0.48057
Value Function Update Magnitude: 0.64663

Collected Steps per Second: 23,239.84405
Overall Steps per Second: 10,889.97971

Timestep Collection Time: 2.15260
Timestep Consumption Time: 2.44117
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.59376

Cumulative Model Updates: 302,222
Cumulative Timesteps: 2,520,444,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2520444366...
Checkpoint 2520444366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344.75445
Policy Entropy: 2.40619
Value Function Loss: 0.01833

Mean KL Divergence: 0.02062
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.46699
Value Function Update Magnitude: 0.63264

Collected Steps per Second: 22,560.49839
Overall Steps per Second: 10,636.19597

Timestep Collection Time: 2.21697
Timestep Consumption Time: 2.48546
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.70243

Cumulative Model Updates: 302,228
Cumulative Timesteps: 2,520,494,382

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.81652
Policy Entropy: 2.41802
Value Function Loss: 0.01903

Mean KL Divergence: 0.02563
SB3 Clip Fraction: 0.14407
Policy Update Magnitude: 0.48253
Value Function Update Magnitude: 0.65123

Collected Steps per Second: 22,964.07580
Overall Steps per Second: 10,888.47661

Timestep Collection Time: 2.17775
Timestep Consumption Time: 2.41518
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.59293

Cumulative Model Updates: 302,234
Cumulative Timesteps: 2,520,544,392

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2520544392...
Checkpoint 2520544392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353.98778
Policy Entropy: 2.44072
Value Function Loss: 0.01761

Mean KL Divergence: 0.02213
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.48437
Value Function Update Magnitude: 0.66950

Collected Steps per Second: 22,596.18072
Overall Steps per Second: 10,820.14557

Timestep Collection Time: 2.21338
Timestep Consumption Time: 2.40892
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.62230

Cumulative Model Updates: 302,240
Cumulative Timesteps: 2,520,594,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.37222
Policy Entropy: 2.43244
Value Function Loss: 0.01706

Mean KL Divergence: 0.01820
SB3 Clip Fraction: 0.11791
Policy Update Magnitude: 0.48441
Value Function Update Magnitude: 0.66783

Collected Steps per Second: 23,235.68884
Overall Steps per Second: 10,787.92326

Timestep Collection Time: 2.15246
Timestep Consumption Time: 2.48365
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.63611

Cumulative Model Updates: 302,246
Cumulative Timesteps: 2,520,644,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2520644420...
Checkpoint 2520644420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.57726
Policy Entropy: 2.42272
Value Function Loss: 0.01751

Mean KL Divergence: 0.01742
SB3 Clip Fraction: 0.11346
Policy Update Magnitude: 0.49589
Value Function Update Magnitude: 0.66351

Collected Steps per Second: 21,822.81262
Overall Steps per Second: 10,575.42821

Timestep Collection Time: 2.29201
Timestep Consumption Time: 2.43764
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.72964

Cumulative Model Updates: 302,252
Cumulative Timesteps: 2,520,694,438

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.60380
Policy Entropy: 2.38784
Value Function Loss: 0.01871

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.09800
Policy Update Magnitude: 0.49555
Value Function Update Magnitude: 0.65507

Collected Steps per Second: 22,408.81597
Overall Steps per Second: 10,857.37151

Timestep Collection Time: 2.23162
Timestep Consumption Time: 2.37428
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.60590

Cumulative Model Updates: 302,258
Cumulative Timesteps: 2,520,744,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2520744446...
Checkpoint 2520744446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338.78673
Policy Entropy: 2.38525
Value Function Loss: 0.01913

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.09866
Policy Update Magnitude: 0.49566
Value Function Update Magnitude: 0.64030

Collected Steps per Second: 22,181.87819
Overall Steps per Second: 10,642.81632

Timestep Collection Time: 2.25499
Timestep Consumption Time: 2.44489
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.69988

Cumulative Model Updates: 302,264
Cumulative Timesteps: 2,520,794,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.57614
Policy Entropy: 2.37646
Value Function Loss: 0.01839

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.10528
Policy Update Magnitude: 0.48787
Value Function Update Magnitude: 0.63966

Collected Steps per Second: 22,488.63666
Overall Steps per Second: 10,543.11434

Timestep Collection Time: 2.22441
Timestep Consumption Time: 2.52030
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.74471

Cumulative Model Updates: 302,270
Cumulative Timesteps: 2,520,844,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2520844490...
Checkpoint 2520844490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 378.54714
Policy Entropy: 2.39243
Value Function Loss: 0.01749

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.10627
Policy Update Magnitude: 0.49099
Value Function Update Magnitude: 0.63789

Collected Steps per Second: 22,170.66001
Overall Steps per Second: 10,634.27934

Timestep Collection Time: 2.25604
Timestep Consumption Time: 2.44742
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.70347

Cumulative Model Updates: 302,276
Cumulative Timesteps: 2,520,894,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.02533
Policy Entropy: 2.41742
Value Function Loss: 0.01698

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.48762
Value Function Update Magnitude: 0.65236

Collected Steps per Second: 22,923.56063
Overall Steps per Second: 10,909.84023

Timestep Collection Time: 2.18186
Timestep Consumption Time: 2.40263
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.58449

Cumulative Model Updates: 302,282
Cumulative Timesteps: 2,520,944,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2520944524...
Checkpoint 2520944524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.64074
Policy Entropy: 2.44336
Value Function Loss: 0.01625

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.10457
Policy Update Magnitude: 0.47578
Value Function Update Magnitude: 0.67095

Collected Steps per Second: 22,209.45585
Overall Steps per Second: 10,631.82264

Timestep Collection Time: 2.25192
Timestep Consumption Time: 2.45226
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.70418

Cumulative Model Updates: 302,288
Cumulative Timesteps: 2,520,994,538

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344.94154
Policy Entropy: 2.46038
Value Function Loss: 0.01690

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.10182
Policy Update Magnitude: 0.47721
Value Function Update Magnitude: 0.67557

Collected Steps per Second: 22,509.45248
Overall Steps per Second: 10,569.79719

Timestep Collection Time: 2.22209
Timestep Consumption Time: 2.51007
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.73216

Cumulative Model Updates: 302,294
Cumulative Timesteps: 2,521,044,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2521044556...
Checkpoint 2521044556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 311.73318
Policy Entropy: 2.47052
Value Function Loss: 0.01788

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.10158
Policy Update Magnitude: 0.48111
Value Function Update Magnitude: 0.68349

Collected Steps per Second: 22,205.27897
Overall Steps per Second: 10,523.44459

Timestep Collection Time: 2.25262
Timestep Consumption Time: 2.50058
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.75320

Cumulative Model Updates: 302,300
Cumulative Timesteps: 2,521,094,576

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.14413
Policy Entropy: 2.44107
Value Function Loss: 0.01794

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09917
Policy Update Magnitude: 0.48354
Value Function Update Magnitude: 0.66601

Collected Steps per Second: 22,853.42004
Overall Steps per Second: 10,873.80698

Timestep Collection Time: 2.18821
Timestep Consumption Time: 2.41073
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.59894

Cumulative Model Updates: 302,306
Cumulative Timesteps: 2,521,144,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2521144584...
Checkpoint 2521144584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.14080
Policy Entropy: 2.42225
Value Function Loss: 0.01836

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.10830
Policy Update Magnitude: 0.49055
Value Function Update Magnitude: 0.64250

Collected Steps per Second: 22,679.88606
Overall Steps per Second: 10,684.16214

Timestep Collection Time: 2.20521
Timestep Consumption Time: 2.47592
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.68113

Cumulative Model Updates: 302,312
Cumulative Timesteps: 2,521,194,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.15829
Policy Entropy: 2.41547
Value Function Loss: 0.01811

Mean KL Divergence: 0.02472
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.46433
Value Function Update Magnitude: 0.64955

Collected Steps per Second: 22,121.28923
Overall Steps per Second: 10,571.12210

Timestep Collection Time: 2.26117
Timestep Consumption Time: 2.47059
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.73176

Cumulative Model Updates: 302,318
Cumulative Timesteps: 2,521,244,618

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2521244618...
Checkpoint 2521244618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.26071
Policy Entropy: 2.42777
Value Function Loss: 0.01819

Mean KL Divergence: 0.02350
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.45173
Value Function Update Magnitude: 0.65585

Collected Steps per Second: 21,838.30245
Overall Steps per Second: 10,609.94614

Timestep Collection Time: 2.29084
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.71520

Cumulative Model Updates: 302,324
Cumulative Timesteps: 2,521,294,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.31206
Policy Entropy: 2.43682
Value Function Loss: 0.01702

Mean KL Divergence: 0.02107
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.45943
Value Function Update Magnitude: 0.63352

Collected Steps per Second: 22,914.27804
Overall Steps per Second: 10,856.14826

Timestep Collection Time: 2.18213
Timestep Consumption Time: 2.42374
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.60587

Cumulative Model Updates: 302,330
Cumulative Timesteps: 2,521,344,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2521344648...
Checkpoint 2521344648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.49992
Policy Entropy: 2.43683
Value Function Loss: 0.01600

Mean KL Divergence: 0.02248
SB3 Clip Fraction: 0.14138
Policy Update Magnitude: 0.44674
Value Function Update Magnitude: 0.61625

Collected Steps per Second: 22,535.10564
Overall Steps per Second: 10,580.15676

Timestep Collection Time: 2.21876
Timestep Consumption Time: 2.50707
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.72583

Cumulative Model Updates: 302,336
Cumulative Timesteps: 2,521,394,648

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343.30260
Policy Entropy: 2.44723
Value Function Loss: 0.01597

Mean KL Divergence: 0.02200
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.46222
Value Function Update Magnitude: 0.59425

Collected Steps per Second: 23,053.97429
Overall Steps per Second: 10,902.79458

Timestep Collection Time: 2.17038
Timestep Consumption Time: 2.41890
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.58928

Cumulative Model Updates: 302,342
Cumulative Timesteps: 2,521,444,684

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2521444684...
Checkpoint 2521444684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.85356
Policy Entropy: 2.42886
Value Function Loss: 0.01666

Mean KL Divergence: 0.02082
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.47821
Value Function Update Magnitude: 0.60639

Collected Steps per Second: 22,650.28231
Overall Steps per Second: 10,832.02610

Timestep Collection Time: 2.20792
Timestep Consumption Time: 2.40895
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.61686

Cumulative Model Updates: 302,348
Cumulative Timesteps: 2,521,494,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 288.55460
Policy Entropy: 2.42557
Value Function Loss: 0.01752

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.11701
Policy Update Magnitude: 0.49014
Value Function Update Magnitude: 0.63454

Collected Steps per Second: 23,176.43749
Overall Steps per Second: 10,736.35489

Timestep Collection Time: 2.15874
Timestep Consumption Time: 2.50131
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.66005

Cumulative Model Updates: 302,354
Cumulative Timesteps: 2,521,544,726

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2521544726...
Checkpoint 2521544726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.44119
Policy Entropy: 2.42179
Value Function Loss: 0.01661

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.49106
Value Function Update Magnitude: 0.64168

Collected Steps per Second: 22,108.52327
Overall Steps per Second: 10,619.53201

Timestep Collection Time: 2.26211
Timestep Consumption Time: 2.44732
PPO Batch Consumption Time: 0.28176
Total Iteration Time: 4.70944

Cumulative Model Updates: 302,360
Cumulative Timesteps: 2,521,594,738

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.48739
Policy Entropy: 2.43173
Value Function Loss: 0.01689

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.11094
Policy Update Magnitude: 0.48073
Value Function Update Magnitude: 0.63576

Collected Steps per Second: 22,621.54615
Overall Steps per Second: 10,735.86933

Timestep Collection Time: 2.21134
Timestep Consumption Time: 2.44818
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.65952

Cumulative Model Updates: 302,366
Cumulative Timesteps: 2,521,644,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2521644762...
Checkpoint 2521644762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.71317
Policy Entropy: 2.41708
Value Function Loss: 0.01741

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.11106
Policy Update Magnitude: 0.48509
Value Function Update Magnitude: 0.64769

Collected Steps per Second: 22,449.96149
Overall Steps per Second: 10,664.40283

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.46142
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.68868

Cumulative Model Updates: 302,372
Cumulative Timesteps: 2,521,694,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.11484
Policy Entropy: 2.42187
Value Function Loss: 0.01797

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.11491
Policy Update Magnitude: 0.49781
Value Function Update Magnitude: 0.66375

Collected Steps per Second: 22,283.75073
Overall Steps per Second: 10,636.22959

Timestep Collection Time: 2.24442
Timestep Consumption Time: 2.45781
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.70223

Cumulative Model Updates: 302,378
Cumulative Timesteps: 2,521,744,778

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2521744778...
Checkpoint 2521744778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255.09991
Policy Entropy: 2.41370
Value Function Loss: 0.01937

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.11490
Policy Update Magnitude: 0.49801
Value Function Update Magnitude: 0.68484

Collected Steps per Second: 21,745.22660
Overall Steps per Second: 10,605.69512

Timestep Collection Time: 2.30009
Timestep Consumption Time: 2.41587
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.71596

Cumulative Model Updates: 302,384
Cumulative Timesteps: 2,521,794,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327.00690
Policy Entropy: 2.44126
Value Function Loss: 0.01809

Mean KL Divergence: 0.01688
SB3 Clip Fraction: 0.11319
Policy Update Magnitude: 0.50122
Value Function Update Magnitude: 0.68597

Collected Steps per Second: 22,438.30543
Overall Steps per Second: 10,872.39240

Timestep Collection Time: 2.22842
Timestep Consumption Time: 2.37057
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.59899

Cumulative Model Updates: 302,390
Cumulative Timesteps: 2,521,844,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2521844796...
Checkpoint 2521844796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.98980
Policy Entropy: 2.44679
Value Function Loss: 0.01803

Mean KL Divergence: 0.01945
SB3 Clip Fraction: 0.11808
Policy Update Magnitude: 0.48833
Value Function Update Magnitude: 0.66891

Collected Steps per Second: 22,057.44441
Overall Steps per Second: 10,612.55719

Timestep Collection Time: 2.26808
Timestep Consumption Time: 2.44596
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.71404

Cumulative Model Updates: 302,396
Cumulative Timesteps: 2,521,894,824

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.28558
Policy Entropy: 2.46331
Value Function Loss: 0.01769

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.10882
Policy Update Magnitude: 0.48908
Value Function Update Magnitude: 0.65737

Collected Steps per Second: 22,566.70243
Overall Steps per Second: 10,559.36728

Timestep Collection Time: 2.21565
Timestep Consumption Time: 2.51948
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.73513

Cumulative Model Updates: 302,402
Cumulative Timesteps: 2,521,944,824

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2521944824...
Checkpoint 2521944824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.62121
Policy Entropy: 2.46414
Value Function Loss: 0.01790

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.10052
Policy Update Magnitude: 0.48223
Value Function Update Magnitude: 0.66995

Collected Steps per Second: 22,364.31196
Overall Steps per Second: 10,667.33841

Timestep Collection Time: 2.23660
Timestep Consumption Time: 2.45248
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.68908

Cumulative Model Updates: 302,408
Cumulative Timesteps: 2,521,994,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.07200
Policy Entropy: 2.46688
Value Function Loss: 0.01741

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.09232
Policy Update Magnitude: 0.48807
Value Function Update Magnitude: 0.68476

Collected Steps per Second: 22,888.56427
Overall Steps per Second: 10,914.23084

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.39716
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.58209

Cumulative Model Updates: 302,414
Cumulative Timesteps: 2,522,044,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2522044854...
Checkpoint 2522044854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312.41579
Policy Entropy: 2.43328
Value Function Loss: 0.01802

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.48902
Value Function Update Magnitude: 0.67292

Collected Steps per Second: 22,850.97588
Overall Steps per Second: 10,639.42108

Timestep Collection Time: 2.18862
Timestep Consumption Time: 2.51202
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.70063

Cumulative Model Updates: 302,420
Cumulative Timesteps: 2,522,094,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239.50324
Policy Entropy: 2.42088
Value Function Loss: 0.01856

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09125
Policy Update Magnitude: 0.49125
Value Function Update Magnitude: 0.65320

Collected Steps per Second: 23,081.70806
Overall Steps per Second: 10,918.91333

Timestep Collection Time: 2.16639
Timestep Consumption Time: 2.41319
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.57958

Cumulative Model Updates: 302,426
Cumulative Timesteps: 2,522,144,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2522144870...
Checkpoint 2522144870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.33635
Policy Entropy: 2.38487
Value Function Loss: 0.01874

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.09722
Policy Update Magnitude: 0.48985
Value Function Update Magnitude: 0.64040

Collected Steps per Second: 21,526.73471
Overall Steps per Second: 10,709.28977

Timestep Collection Time: 2.32288
Timestep Consumption Time: 2.34634
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.66922

Cumulative Model Updates: 302,432
Cumulative Timesteps: 2,522,194,874

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.55668
Policy Entropy: 2.40036
Value Function Loss: 0.01885

Mean KL Divergence: 0.01661
SB3 Clip Fraction: 0.11156
Policy Update Magnitude: 0.48805
Value Function Update Magnitude: 0.64626

Collected Steps per Second: 22,788.61302
Overall Steps per Second: 10,771.64783

Timestep Collection Time: 2.19513
Timestep Consumption Time: 2.44891
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.64404

Cumulative Model Updates: 302,438
Cumulative Timesteps: 2,522,244,898

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2522244898...
Checkpoint 2522244898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.39571
Policy Entropy: 2.40898
Value Function Loss: 0.01759

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.11678
Policy Update Magnitude: 0.48595
Value Function Update Magnitude: 0.67415

Collected Steps per Second: 21,823.41531
Overall Steps per Second: 10,455.96235

Timestep Collection Time: 2.29112
Timestep Consumption Time: 2.49084
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.78196

Cumulative Model Updates: 302,444
Cumulative Timesteps: 2,522,294,898

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338.93495
Policy Entropy: 2.43023
Value Function Loss: 0.01725

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.10967
Policy Update Magnitude: 0.49085
Value Function Update Magnitude: 0.67220

Collected Steps per Second: 22,415.59994
Overall Steps per Second: 10,594.64051

Timestep Collection Time: 2.23166
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.72163

Cumulative Model Updates: 302,450
Cumulative Timesteps: 2,522,344,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2522344922...
Checkpoint 2522344922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.45879
Policy Entropy: 2.45362
Value Function Loss: 0.01638

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.10738
Policy Update Magnitude: 0.49488
Value Function Update Magnitude: 0.65394

Collected Steps per Second: 23,495.93087
Overall Steps per Second: 10,770.79332

Timestep Collection Time: 2.12862
Timestep Consumption Time: 2.51486
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.64348

Cumulative Model Updates: 302,456
Cumulative Timesteps: 2,522,394,936

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.88135
Policy Entropy: 2.46574
Value Function Loss: 0.01661

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.11245
Policy Update Magnitude: 0.48360
Value Function Update Magnitude: 0.64945

Collected Steps per Second: 23,189.74626
Overall Steps per Second: 10,844.10981

Timestep Collection Time: 2.15716
Timestep Consumption Time: 2.45585
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.61301

Cumulative Model Updates: 302,462
Cumulative Timesteps: 2,522,444,960

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2522444960...
Checkpoint 2522444960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.98961
Policy Entropy: 2.46700
Value Function Loss: 0.01662

Mean KL Divergence: 0.01593
SB3 Clip Fraction: 0.10994
Policy Update Magnitude: 0.47385
Value Function Update Magnitude: 0.64248

Collected Steps per Second: 22,730.09885
Overall Steps per Second: 10,658.00001

Timestep Collection Time: 2.20025
Timestep Consumption Time: 2.49218
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.69244

Cumulative Model Updates: 302,468
Cumulative Timesteps: 2,522,494,972

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295.27582
Policy Entropy: 2.45115
Value Function Loss: 0.01773

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09964
Policy Update Magnitude: 0.47953
Value Function Update Magnitude: 0.63323

Collected Steps per Second: 23,039.08830
Overall Steps per Second: 10,976.67843

Timestep Collection Time: 2.17153
Timestep Consumption Time: 2.38632
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.55785

Cumulative Model Updates: 302,474
Cumulative Timesteps: 2,522,545,002

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2522545002...
Checkpoint 2522545002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 252.15111
Policy Entropy: 2.43493
Value Function Loss: 0.01809

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.49125
Value Function Update Magnitude: 0.65386

Collected Steps per Second: 22,973.80275
Overall Steps per Second: 10,682.09222

Timestep Collection Time: 2.17674
Timestep Consumption Time: 2.50474
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.68148

Cumulative Model Updates: 302,480
Cumulative Timesteps: 2,522,595,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.01220
Policy Entropy: 2.44402
Value Function Loss: 0.01798

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.09611
Policy Update Magnitude: 0.50223
Value Function Update Magnitude: 0.67732

Collected Steps per Second: 22,970.28336
Overall Steps per Second: 10,824.97599

Timestep Collection Time: 2.17794
Timestep Consumption Time: 2.44359
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.62153

Cumulative Model Updates: 302,486
Cumulative Timesteps: 2,522,645,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2522645038...
Checkpoint 2522645038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.23862
Policy Entropy: 2.43716
Value Function Loss: 0.01797

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.10710
Policy Update Magnitude: 0.48562
Value Function Update Magnitude: 0.68121

Collected Steps per Second: 21,921.07064
Overall Steps per Second: 10,685.87637

Timestep Collection Time: 2.28118
Timestep Consumption Time: 2.39845
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.67963

Cumulative Model Updates: 302,492
Cumulative Timesteps: 2,522,695,044

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283.82405
Policy Entropy: 2.44169
Value Function Loss: 0.01748

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.10318
Policy Update Magnitude: 0.49326
Value Function Update Magnitude: 0.66391

Collected Steps per Second: 22,735.55260
Overall Steps per Second: 10,895.77382

Timestep Collection Time: 2.19920
Timestep Consumption Time: 2.38974
PPO Batch Consumption Time: 0.28509
Total Iteration Time: 4.58894

Cumulative Model Updates: 302,498
Cumulative Timesteps: 2,522,745,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2522745044...
Checkpoint 2522745044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.54050
Policy Entropy: 2.43138
Value Function Loss: 0.01779

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.11035
Policy Update Magnitude: 0.49990
Value Function Update Magnitude: 0.65353

Collected Steps per Second: 22,583.38984
Overall Steps per Second: 10,629.40739

Timestep Collection Time: 2.21402
Timestep Consumption Time: 2.48991
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.70393

Cumulative Model Updates: 302,504
Cumulative Timesteps: 2,522,795,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.84505
Policy Entropy: 2.43424
Value Function Loss: 0.01779

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.50417
Value Function Update Magnitude: 0.65539

Collected Steps per Second: 22,595.72095
Overall Steps per Second: 10,637.12028

Timestep Collection Time: 2.21316
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.70127

Cumulative Model Updates: 302,510
Cumulative Timesteps: 2,522,845,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2522845052...
Checkpoint 2522845052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.40310
Policy Entropy: 2.45468
Value Function Loss: 0.01759

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.10829
Policy Update Magnitude: 0.49167
Value Function Update Magnitude: 0.65747

Collected Steps per Second: 22,891.31084
Overall Steps per Second: 10,796.33305

Timestep Collection Time: 2.18537
Timestep Consumption Time: 2.44824
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.63361

Cumulative Model Updates: 302,516
Cumulative Timesteps: 2,522,895,078

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300.22924
Policy Entropy: 2.45054
Value Function Loss: 0.01798

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.10333
Policy Update Magnitude: 0.48341
Value Function Update Magnitude: 0.65632

Collected Steps per Second: 23,033.65134
Overall Steps per Second: 11,002.94223

Timestep Collection Time: 2.17152
Timestep Consumption Time: 2.37436
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.54588

Cumulative Model Updates: 302,522
Cumulative Timesteps: 2,522,945,096

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2522945096...
Checkpoint 2522945096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.14374
Policy Entropy: 2.46747
Value Function Loss: 0.01803

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.10329
Policy Update Magnitude: 0.49013
Value Function Update Magnitude: 0.66787

Collected Steps per Second: 22,211.40700
Overall Steps per Second: 10,659.80425

Timestep Collection Time: 2.25218
Timestep Consumption Time: 2.44059
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.69277

Cumulative Model Updates: 302,528
Cumulative Timesteps: 2,522,995,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.13416
Policy Entropy: 2.45720
Value Function Loss: 0.01799

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.50302
Value Function Update Magnitude: 0.67019

Collected Steps per Second: 22,620.29241
Overall Steps per Second: 10,695.67112

Timestep Collection Time: 2.21111
Timestep Consumption Time: 2.46517
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.67628

Cumulative Model Updates: 302,534
Cumulative Timesteps: 2,523,045,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2523045136...
Checkpoint 2523045136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 336.12823
Policy Entropy: 2.46535
Value Function Loss: 0.01779

Mean KL Divergence: 0.01552
SB3 Clip Fraction: 0.10696
Policy Update Magnitude: 0.50289
Value Function Update Magnitude: 0.66414

Collected Steps per Second: 22,700.46986
Overall Steps per Second: 10,838.75186

Timestep Collection Time: 2.20304
Timestep Consumption Time: 2.41096
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.61400

Cumulative Model Updates: 302,540
Cumulative Timesteps: 2,523,095,146

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.45372
Policy Entropy: 2.46320
Value Function Loss: 0.01759

Mean KL Divergence: 0.01413
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.49675
Value Function Update Magnitude: 0.65398

Collected Steps per Second: 23,176.05993
Overall Steps per Second: 10,899.58349

Timestep Collection Time: 2.15809
Timestep Consumption Time: 2.43071
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.58880

Cumulative Model Updates: 302,546
Cumulative Timesteps: 2,523,145,162

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2523145162...
Checkpoint 2523145162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.53924
Policy Entropy: 2.47276
Value Function Loss: 0.01831

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.09666
Policy Update Magnitude: 0.49766
Value Function Update Magnitude: 0.64659

Collected Steps per Second: 22,089.69446
Overall Steps per Second: 10,615.00226

Timestep Collection Time: 2.26431
Timestep Consumption Time: 2.44770
PPO Batch Consumption Time: 0.28101
Total Iteration Time: 4.71201

Cumulative Model Updates: 302,552
Cumulative Timesteps: 2,523,195,180

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355.56303
Policy Entropy: 2.46236
Value Function Loss: 0.01804

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.09509
Policy Update Magnitude: 0.50091
Value Function Update Magnitude: 0.65103

Collected Steps per Second: 22,389.59962
Overall Steps per Second: 10,522.37447

Timestep Collection Time: 2.23407
Timestep Consumption Time: 2.51961
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.75368

Cumulative Model Updates: 302,558
Cumulative Timesteps: 2,523,245,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2523245200...
Checkpoint 2523245200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.61095
Policy Entropy: 2.46362
Value Function Loss: 0.01740

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.09793
Policy Update Magnitude: 0.50240
Value Function Update Magnitude: 0.65032

Collected Steps per Second: 21,899.45026
Overall Steps per Second: 10,603.71764

Timestep Collection Time: 2.28408
Timestep Consumption Time: 2.43314
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.71721

Cumulative Model Updates: 302,564
Cumulative Timesteps: 2,523,295,220

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330.73239
Policy Entropy: 2.43990
Value Function Loss: 0.01785

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.09795
Policy Update Magnitude: 0.51030
Value Function Update Magnitude: 0.64736

Collected Steps per Second: 22,803.27487
Overall Steps per Second: 10,654.30002

Timestep Collection Time: 2.19381
Timestep Consumption Time: 2.50157
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.69538

Cumulative Model Updates: 302,570
Cumulative Timesteps: 2,523,345,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2523345246...
Checkpoint 2523345246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.02003
Policy Entropy: 2.43379
Value Function Loss: 0.01746

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.10124
Policy Update Magnitude: 0.51073
Value Function Update Magnitude: 0.66913

Collected Steps per Second: 22,458.38490
Overall Steps per Second: 10,485.97184

Timestep Collection Time: 2.22705
Timestep Consumption Time: 2.54275
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.76980

Cumulative Model Updates: 302,576
Cumulative Timesteps: 2,523,395,262

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.17545
Policy Entropy: 2.42839
Value Function Loss: 0.01778

Mean KL Divergence: 0.01699
SB3 Clip Fraction: 0.10206
Policy Update Magnitude: 0.50249
Value Function Update Magnitude: 0.67355

Collected Steps per Second: 23,074.25601
Overall Steps per Second: 10,890.71109

Timestep Collection Time: 2.16804
Timestep Consumption Time: 2.42541
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59346

Cumulative Model Updates: 302,582
Cumulative Timesteps: 2,523,445,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2523445288...
Checkpoint 2523445288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.32833
Policy Entropy: 2.44226
Value Function Loss: 0.01831

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.10071
Policy Update Magnitude: 0.49939
Value Function Update Magnitude: 0.66553

Collected Steps per Second: 22,765.99149
Overall Steps per Second: 10,973.47676

Timestep Collection Time: 2.19679
Timestep Consumption Time: 2.36075
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.55753

Cumulative Model Updates: 302,588
Cumulative Timesteps: 2,523,495,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316.35995
Policy Entropy: 2.45214
Value Function Loss: 0.01831

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09712
Policy Update Magnitude: 0.50014
Value Function Update Magnitude: 0.66167

Collected Steps per Second: 23,055.75804
Overall Steps per Second: 10,748.48590

Timestep Collection Time: 2.16987
Timestep Consumption Time: 2.48455
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.65442

Cumulative Model Updates: 302,594
Cumulative Timesteps: 2,523,545,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2523545328...
Checkpoint 2523545328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.86983
Policy Entropy: 2.46112
Value Function Loss: 0.01809

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.09062
Policy Update Magnitude: 0.49555
Value Function Update Magnitude: 0.67005

Collected Steps per Second: 22,581.74304
Overall Steps per Second: 10,676.41769

Timestep Collection Time: 2.21542
Timestep Consumption Time: 2.47042
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.68584

Cumulative Model Updates: 302,600
Cumulative Timesteps: 2,523,595,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.91102
Policy Entropy: 2.45467
Value Function Loss: 0.01840

Mean KL Divergence: 0.01440
SB3 Clip Fraction: 0.10445
Policy Update Magnitude: 0.50097
Value Function Update Magnitude: 0.69894

Collected Steps per Second: 23,067.42181
Overall Steps per Second: 10,564.75662

Timestep Collection Time: 2.16765
Timestep Consumption Time: 2.56526
PPO Batch Consumption Time: 0.30669
Total Iteration Time: 4.73291

Cumulative Model Updates: 302,606
Cumulative Timesteps: 2,523,645,358

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2523645358...
Checkpoint 2523645358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.90243
Policy Entropy: 2.45232
Value Function Loss: 0.01848

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.10831
Policy Update Magnitude: 0.49228
Value Function Update Magnitude: 0.70904

Collected Steps per Second: 22,534.58786
Overall Steps per Second: 10,729.54514

Timestep Collection Time: 2.21952
Timestep Consumption Time: 2.44200
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.66152

Cumulative Model Updates: 302,612
Cumulative Timesteps: 2,523,695,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293.72697
Policy Entropy: 2.44853
Value Function Loss: 0.01747

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.49628
Value Function Update Magnitude: 0.67801

Collected Steps per Second: 22,736.47341
Overall Steps per Second: 10,655.74151

Timestep Collection Time: 2.20043
Timestep Consumption Time: 2.49469
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.69512

Cumulative Model Updates: 302,618
Cumulative Timesteps: 2,523,745,404

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2523745404...
Checkpoint 2523745404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.97377
Policy Entropy: 2.47151
Value Function Loss: 0.01549

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.09400
Policy Update Magnitude: 0.47790
Value Function Update Magnitude: 0.64378

Collected Steps per Second: 22,186.53861
Overall Steps per Second: 10,465.37280

Timestep Collection Time: 2.25407
Timestep Consumption Time: 2.52455
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.77862

Cumulative Model Updates: 302,624
Cumulative Timesteps: 2,523,795,414

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.52318
Policy Entropy: 2.47322
Value Function Loss: 0.01603

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.09356
Policy Update Magnitude: 0.47727
Value Function Update Magnitude: 0.62932

Collected Steps per Second: 22,417.77597
Overall Steps per Second: 10,623.51491

Timestep Collection Time: 2.23037
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.70654

Cumulative Model Updates: 302,630
Cumulative Timesteps: 2,523,845,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2523845414...
Checkpoint 2523845414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.20405
Policy Entropy: 2.47874
Value Function Loss: 0.01510

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.09203
Policy Update Magnitude: 0.47810
Value Function Update Magnitude: 0.60509

Collected Steps per Second: 21,983.61446
Overall Steps per Second: 10,699.92286

Timestep Collection Time: 2.27660
Timestep Consumption Time: 2.40081
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.67742

Cumulative Model Updates: 302,636
Cumulative Timesteps: 2,523,895,462

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.32814
Policy Entropy: 2.45947
Value Function Loss: 0.01618

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.47467
Value Function Update Magnitude: 0.59824

Collected Steps per Second: 23,085.27234
Overall Steps per Second: 10,712.23789

Timestep Collection Time: 2.16675
Timestep Consumption Time: 2.50268
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.66943

Cumulative Model Updates: 302,642
Cumulative Timesteps: 2,523,945,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2523945482...
Checkpoint 2523945482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.95038
Policy Entropy: 2.45834
Value Function Loss: 0.01691

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.48245
Value Function Update Magnitude: 0.60424

Collected Steps per Second: 22,651.71795
Overall Steps per Second: 10,616.78581

Timestep Collection Time: 2.20866
Timestep Consumption Time: 2.50369
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.71235

Cumulative Model Updates: 302,648
Cumulative Timesteps: 2,523,995,512

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.33117
Policy Entropy: 2.46826
Value Function Loss: 0.01634

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.10500
Policy Update Magnitude: 0.47159
Value Function Update Magnitude: 0.62460

Collected Steps per Second: 22,846.86752
Overall Steps per Second: 10,853.28654

Timestep Collection Time: 2.18910
Timestep Consumption Time: 2.41909
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.60819

Cumulative Model Updates: 302,654
Cumulative Timesteps: 2,524,045,526

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2524045526...
Checkpoint 2524045526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.96063
Policy Entropy: 2.47830
Value Function Loss: 0.01610

Mean KL Divergence: 0.01861
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.47575
Value Function Update Magnitude: 0.62135

Collected Steps per Second: 23,099.49456
Overall Steps per Second: 10,679.94755

Timestep Collection Time: 2.16516
Timestep Consumption Time: 2.51783
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.68298

Cumulative Model Updates: 302,660
Cumulative Timesteps: 2,524,095,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.28976
Policy Entropy: 2.50298
Value Function Loss: 0.01513

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.12140
Policy Update Magnitude: 0.47398
Value Function Update Magnitude: 0.60683

Collected Steps per Second: 23,254.53256
Overall Steps per Second: 10,908.70004

Timestep Collection Time: 2.15063
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.58460

Cumulative Model Updates: 302,666
Cumulative Timesteps: 2,524,145,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2524145552...
Checkpoint 2524145552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.34826
Policy Entropy: 2.48558
Value Function Loss: 0.01655

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11547
Policy Update Magnitude: 0.47766
Value Function Update Magnitude: 0.60120

Collected Steps per Second: 22,435.96689
Overall Steps per Second: 10,679.72471

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.45360
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.68252

Cumulative Model Updates: 302,672
Cumulative Timesteps: 2,524,195,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232.11527
Policy Entropy: 2.48876
Value Function Loss: 0.01773

Mean KL Divergence: 0.01409
SB3 Clip Fraction: 0.09759
Policy Update Magnitude: 0.49542
Value Function Update Magnitude: 0.60031

Collected Steps per Second: 22,586.65310
Overall Steps per Second: 10,885.75190

Timestep Collection Time: 2.21476
Timestep Consumption Time: 2.38061
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.59536

Cumulative Model Updates: 302,678
Cumulative Timesteps: 2,524,245,584

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2524245584...
Checkpoint 2524245584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.96790
Policy Entropy: 2.45163
Value Function Loss: 0.01828

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.09237
Policy Update Magnitude: 0.49241
Value Function Update Magnitude: 0.61479

Collected Steps per Second: 22,431.87167
Overall Steps per Second: 10,666.44179

Timestep Collection Time: 2.23067
Timestep Consumption Time: 2.46050
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.69116

Cumulative Model Updates: 302,684
Cumulative Timesteps: 2,524,295,622

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 275.78222
Policy Entropy: 2.47315
Value Function Loss: 0.01710

Mean KL Divergence: 0.01199
SB3 Clip Fraction: 0.08487
Policy Update Magnitude: 0.48655
Value Function Update Magnitude: 0.62149

Collected Steps per Second: 22,300.17496
Overall Steps per Second: 10,403.61834

Timestep Collection Time: 2.24321
Timestep Consumption Time: 2.56512
PPO Batch Consumption Time: 0.30328
Total Iteration Time: 4.80833

Cumulative Model Updates: 302,690
Cumulative Timesteps: 2,524,345,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2524345646...
Checkpoint 2524345646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 346.63077
Policy Entropy: 2.48309
Value Function Loss: 0.01654

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.08047
Policy Update Magnitude: 0.48700
Value Function Update Magnitude: 0.61239

Collected Steps per Second: 21,840.33721
Overall Steps per Second: 10,605.36750

Timestep Collection Time: 2.29053
Timestep Consumption Time: 2.42651
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.71705

Cumulative Model Updates: 302,696
Cumulative Timesteps: 2,524,395,672

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333.81927
Policy Entropy: 2.50913
Value Function Loss: 0.01675

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.08089
Policy Update Magnitude: 0.48578
Value Function Update Magnitude: 0.63971

Collected Steps per Second: 22,638.90739
Overall Steps per Second: 10,867.11216

Timestep Collection Time: 2.20929
Timestep Consumption Time: 2.39322
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.60251

Cumulative Model Updates: 302,702
Cumulative Timesteps: 2,524,445,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2524445688...
Checkpoint 2524445688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 314.74070
Policy Entropy: 2.49613
Value Function Loss: 0.01729

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.09663
Policy Update Magnitude: 0.49283
Value Function Update Magnitude: 0.66516

Collected Steps per Second: 22,879.61245
Overall Steps per Second: 10,727.12992

Timestep Collection Time: 2.18596
Timestep Consumption Time: 2.47642
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.66238

Cumulative Model Updates: 302,708
Cumulative Timesteps: 2,524,495,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.39132
Policy Entropy: 2.47561
Value Function Loss: 0.01765

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.09860
Policy Update Magnitude: 0.49534
Value Function Update Magnitude: 0.65777

Collected Steps per Second: 23,098.13382
Overall Steps per Second: 10,855.63743

Timestep Collection Time: 2.16563
Timestep Consumption Time: 2.44230
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.60793

Cumulative Model Updates: 302,714
Cumulative Timesteps: 2,524,545,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2524545724...
Checkpoint 2524545724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284.60777
Policy Entropy: 2.47615
Value Function Loss: 0.01850

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.09448
Policy Update Magnitude: 0.49321
Value Function Update Magnitude: 0.67588

Collected Steps per Second: 22,688.58662
Overall Steps per Second: 10,797.21379

Timestep Collection Time: 2.20375
Timestep Consumption Time: 2.42707
PPO Batch Consumption Time: 0.29439
Total Iteration Time: 4.63082

Cumulative Model Updates: 302,720
Cumulative Timesteps: 2,524,595,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258.40310
Policy Entropy: 2.46400
Value Function Loss: 0.01822

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.50312
Value Function Update Magnitude: 0.68311

Collected Steps per Second: 23,197.64623
Overall Steps per Second: 10,877.30509

Timestep Collection Time: 2.15599
Timestep Consumption Time: 2.44202
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.59801

Cumulative Model Updates: 302,726
Cumulative Timesteps: 2,524,645,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2524645738...
Checkpoint 2524645738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.02066
Policy Entropy: 2.45997
Value Function Loss: 0.01863

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.10409
Policy Update Magnitude: 0.49717
Value Function Update Magnitude: 0.65693

Collected Steps per Second: 22,270.48994
Overall Steps per Second: 10,624.04302

Timestep Collection Time: 2.24539
Timestep Consumption Time: 2.46148
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.70687

Cumulative Model Updates: 302,732
Cumulative Timesteps: 2,524,695,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.60741
Policy Entropy: 2.46181
Value Function Loss: 0.01801

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.09543
Policy Update Magnitude: 0.48975
Value Function Update Magnitude: 0.62199

Collected Steps per Second: 22,713.53000
Overall Steps per Second: 10,825.97915

Timestep Collection Time: 2.20265
Timestep Consumption Time: 2.41864
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.62129

Cumulative Model Updates: 302,738
Cumulative Timesteps: 2,524,745,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2524745774...
Checkpoint 2524745774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.38663
Policy Entropy: 2.48731
Value Function Loss: 0.01758

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.09309
Policy Update Magnitude: 0.47911
Value Function Update Magnitude: 0.59502

Collected Steps per Second: 22,298.58049
Overall Steps per Second: 10,717.55028

Timestep Collection Time: 2.24230
Timestep Consumption Time: 2.42295
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.66525

Cumulative Model Updates: 302,744
Cumulative Timesteps: 2,524,795,774

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.17187
Policy Entropy: 2.49349
Value Function Loss: 0.01627

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.47075
Value Function Update Magnitude: 0.59605

Collected Steps per Second: 22,147.10654
Overall Steps per Second: 10,439.80562

Timestep Collection Time: 2.25835
Timestep Consumption Time: 2.53254
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.79089

Cumulative Model Updates: 302,750
Cumulative Timesteps: 2,524,845,790

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2524845790...
Checkpoint 2524845790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.81866
Policy Entropy: 2.48626
Value Function Loss: 0.01609

Mean KL Divergence: 0.01828
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.45918
Value Function Update Magnitude: 0.60133

Collected Steps per Second: 22,360.29398
Overall Steps per Second: 10,645.81715

Timestep Collection Time: 2.23700
Timestep Consumption Time: 2.46156
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.69856

Cumulative Model Updates: 302,756
Cumulative Timesteps: 2,524,895,810

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359.08975
Policy Entropy: 2.47056
Value Function Loss: 0.01715

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.12027
Policy Update Magnitude: 0.48059
Value Function Update Magnitude: 0.60223

Collected Steps per Second: 23,055.47496
Overall Steps per Second: 10,996.18798

Timestep Collection Time: 2.16964
Timestep Consumption Time: 2.37939
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.54903

Cumulative Model Updates: 302,762
Cumulative Timesteps: 2,524,945,832

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2524945832...
Checkpoint 2524945832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 329.08381
Policy Entropy: 2.46493
Value Function Loss: 0.01715

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.49725
Value Function Update Magnitude: 0.61606

Collected Steps per Second: 22,253.15162
Overall Steps per Second: 10,599.49927

Timestep Collection Time: 2.24813
Timestep Consumption Time: 2.47171
PPO Batch Consumption Time: 0.28290
Total Iteration Time: 4.71985

Cumulative Model Updates: 302,768
Cumulative Timesteps: 2,524,995,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272.12176
Policy Entropy: 2.46216
Value Function Loss: 0.01773

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.10895
Policy Update Magnitude: 0.50438
Value Function Update Magnitude: 0.62268

Collected Steps per Second: 22,754.46672
Overall Steps per Second: 10,788.78306

Timestep Collection Time: 2.19851
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.63685

Cumulative Model Updates: 302,774
Cumulative Timesteps: 2,525,045,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2525045886...
Checkpoint 2525045886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.66127
Policy Entropy: 2.46502
Value Function Loss: 0.01703

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.49517
Value Function Update Magnitude: 0.61921

Collected Steps per Second: 22,327.15842
Overall Steps per Second: 10,764.54535

Timestep Collection Time: 2.23960
Timestep Consumption Time: 2.40565
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.64525

Cumulative Model Updates: 302,780
Cumulative Timesteps: 2,525,095,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.87570
Policy Entropy: 2.46893
Value Function Loss: 0.01647

Mean KL Divergence: 0.01568
SB3 Clip Fraction: 0.10912
Policy Update Magnitude: 0.48769
Value Function Update Magnitude: 0.60916

Collected Steps per Second: 23,105.63343
Overall Steps per Second: 10,895.65646

Timestep Collection Time: 2.16510
Timestep Consumption Time: 2.42627
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.59137

Cumulative Model Updates: 302,786
Cumulative Timesteps: 2,525,145,916

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2525145916...
Checkpoint 2525145916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.32019
Policy Entropy: 2.48457
Value Function Loss: 0.01568

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.47826
Value Function Update Magnitude: 0.59112

Collected Steps per Second: 22,697.36972
Overall Steps per Second: 10,617.60310

Timestep Collection Time: 2.20387
Timestep Consumption Time: 2.50737
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.71123

Cumulative Model Updates: 302,792
Cumulative Timesteps: 2,525,195,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 307.55940
Policy Entropy: 2.50640
Value Function Loss: 0.01482

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.09368
Policy Update Magnitude: 0.46781
Value Function Update Magnitude: 0.56036

Collected Steps per Second: 22,824.30303
Overall Steps per Second: 10,668.70563

Timestep Collection Time: 2.19100
Timestep Consumption Time: 2.49636
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.68735

Cumulative Model Updates: 302,798
Cumulative Timesteps: 2,525,245,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2525245946...
Checkpoint 2525245946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.61080
Policy Entropy: 2.50633
Value Function Loss: 0.01591

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.09243
Policy Update Magnitude: 0.46305
Value Function Update Magnitude: 0.54164

Collected Steps per Second: 22,070.25173
Overall Steps per Second: 10,574.79454

Timestep Collection Time: 2.26658
Timestep Consumption Time: 2.46391
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.73049

Cumulative Model Updates: 302,804
Cumulative Timesteps: 2,525,295,970

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.84666
Policy Entropy: 2.49393
Value Function Loss: 0.01648

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.46841
Value Function Update Magnitude: 0.56969

Collected Steps per Second: 22,785.92516
Overall Steps per Second: 10,818.46938

Timestep Collection Time: 2.19486
Timestep Consumption Time: 2.42797
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.62284

Cumulative Model Updates: 302,810
Cumulative Timesteps: 2,525,345,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2525345982...
Checkpoint 2525345982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.59325
Policy Entropy: 2.46217
Value Function Loss: 0.01621

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.10162
Policy Update Magnitude: 0.48597
Value Function Update Magnitude: 0.58549

Collected Steps per Second: 22,348.37628
Overall Steps per Second: 10,585.08907

Timestep Collection Time: 2.23846
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.72608

Cumulative Model Updates: 302,816
Cumulative Timesteps: 2,525,396,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.23740
Policy Entropy: 2.45097
Value Function Loss: 0.01682

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.10650
Policy Update Magnitude: 0.48904
Value Function Update Magnitude: 0.58535

Collected Steps per Second: 22,355.71641
Overall Steps per Second: 10,505.62576

Timestep Collection Time: 2.23782
Timestep Consumption Time: 2.52420
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.76202

Cumulative Model Updates: 302,822
Cumulative Timesteps: 2,525,446,036

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2525446036...
Checkpoint 2525446036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381.19373
Policy Entropy: 2.45330
Value Function Loss: 0.01606

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.09614
Policy Update Magnitude: 0.48029
Value Function Update Magnitude: 0.58210

Collected Steps per Second: 22,197.16228
Overall Steps per Second: 10,664.83498

Timestep Collection Time: 2.25344
Timestep Consumption Time: 2.43674
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.69018

Cumulative Model Updates: 302,828
Cumulative Timesteps: 2,525,496,056

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.10127
Policy Entropy: 2.47753
Value Function Loss: 0.01604

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.09610
Policy Update Magnitude: 0.47790
Value Function Update Magnitude: 0.59167

Collected Steps per Second: 23,439.83655
Overall Steps per Second: 10,851.68266

Timestep Collection Time: 2.13389
Timestep Consumption Time: 2.47535
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.60924

Cumulative Model Updates: 302,834
Cumulative Timesteps: 2,525,546,074

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2525546074...
Checkpoint 2525546074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 258.65628
Policy Entropy: 2.48196
Value Function Loss: 0.01606

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09423
Policy Update Magnitude: 0.47281
Value Function Update Magnitude: 0.60274

Collected Steps per Second: 22,707.02527
Overall Steps per Second: 10,615.94102

Timestep Collection Time: 2.20319
Timestep Consumption Time: 2.50934
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.71254

Cumulative Model Updates: 302,840
Cumulative Timesteps: 2,525,596,102

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.66152
Policy Entropy: 2.48962
Value Function Loss: 0.01631

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.09500
Policy Update Magnitude: 0.48578
Value Function Update Magnitude: 0.61441

Collected Steps per Second: 22,820.03761
Overall Steps per Second: 10,510.56096

Timestep Collection Time: 2.19176
Timestep Consumption Time: 2.56688
PPO Batch Consumption Time: 0.30224
Total Iteration Time: 4.75864

Cumulative Model Updates: 302,846
Cumulative Timesteps: 2,525,646,118

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2525646118...
Checkpoint 2525646118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356.06643
Policy Entropy: 2.47711
Value Function Loss: 0.01784

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.09741
Policy Update Magnitude: 0.49518
Value Function Update Magnitude: 0.62613

Collected Steps per Second: 22,401.75051
Overall Steps per Second: 10,587.61272

Timestep Collection Time: 2.23295
Timestep Consumption Time: 2.49163
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.72458

Cumulative Model Updates: 302,852
Cumulative Timesteps: 2,525,696,140

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.58911
Policy Entropy: 2.48261
Value Function Loss: 0.01635

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.08741
Policy Update Magnitude: 0.47866
Value Function Update Magnitude: 0.63941

Collected Steps per Second: 23,689.62752
Overall Steps per Second: 10,965.00120

Timestep Collection Time: 2.11173
Timestep Consumption Time: 2.45061
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.56233

Cumulative Model Updates: 302,858
Cumulative Timesteps: 2,525,746,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2525746166...
Checkpoint 2525746166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.81601
Policy Entropy: 2.47069
Value Function Loss: 0.01651

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.08713
Policy Update Magnitude: 0.47122
Value Function Update Magnitude: 0.63395

Collected Steps per Second: 22,744.49238
Overall Steps per Second: 10,592.08731

Timestep Collection Time: 2.19965
Timestep Consumption Time: 2.52368
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.72334

Cumulative Model Updates: 302,864
Cumulative Timesteps: 2,525,796,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285.84806
Policy Entropy: 2.48146
Value Function Loss: 0.01586

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.08661
Policy Update Magnitude: 0.48103
Value Function Update Magnitude: 0.62162

Collected Steps per Second: 22,213.63698
Overall Steps per Second: 10,533.69692

Timestep Collection Time: 2.25141
Timestep Consumption Time: 2.49640
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.74781

Cumulative Model Updates: 302,870
Cumulative Timesteps: 2,525,846,208

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2525846208...
Checkpoint 2525846208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282.07505
Policy Entropy: 2.47924
Value Function Loss: 0.01628

Mean KL Divergence: 0.01294
SB3 Clip Fraction: 0.09556
Policy Update Magnitude: 0.48485
Value Function Update Magnitude: 0.63655

Collected Steps per Second: 21,925.19557
Overall Steps per Second: 10,606.25686

Timestep Collection Time: 2.28158
Timestep Consumption Time: 2.43489
PPO Batch Consumption Time: 0.29416
Total Iteration Time: 4.71646

Cumulative Model Updates: 302,876
Cumulative Timesteps: 2,525,896,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.65752
Policy Entropy: 2.48595
Value Function Loss: 0.01567

Mean KL Divergence: 0.01389
SB3 Clip Fraction: 0.09743
Policy Update Magnitude: 0.48533
Value Function Update Magnitude: 0.64098

Collected Steps per Second: 22,189.14767
Overall Steps per Second: 10,493.23160

Timestep Collection Time: 2.25444
Timestep Consumption Time: 2.51283
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.76726

Cumulative Model Updates: 302,882
Cumulative Timesteps: 2,525,946,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2525946256...
Checkpoint 2525946256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.50509
Policy Entropy: 2.46467
Value Function Loss: 0.01642

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.09908
Policy Update Magnitude: 0.48515
Value Function Update Magnitude: 0.62229

Collected Steps per Second: 22,437.64884
Overall Steps per Second: 10,566.63903

Timestep Collection Time: 2.23045
Timestep Consumption Time: 2.50578
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.73623

Cumulative Model Updates: 302,888
Cumulative Timesteps: 2,525,996,302

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.56740
Policy Entropy: 2.45735
Value Function Loss: 0.01682

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.48710
Value Function Update Magnitude: 0.62912

Collected Steps per Second: 22,525.18299
Overall Steps per Second: 10,579.01864

Timestep Collection Time: 2.22054
Timestep Consumption Time: 2.50750
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.72804

Cumulative Model Updates: 302,894
Cumulative Timesteps: 2,526,046,320

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2526046320...
Checkpoint 2526046320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.62920
Policy Entropy: 2.47682
Value Function Loss: 0.01821

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.09555
Policy Update Magnitude: 0.49217
Value Function Update Magnitude: 0.63333

Collected Steps per Second: 22,933.05796
Overall Steps per Second: 10,967.63261

Timestep Collection Time: 2.18078
Timestep Consumption Time: 2.37918
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.55996

Cumulative Model Updates: 302,900
Cumulative Timesteps: 2,526,096,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332.45087
Policy Entropy: 2.49434
Value Function Loss: 0.01794

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.09835
Policy Update Magnitude: 0.49349
Value Function Update Magnitude: 0.63904

Collected Steps per Second: 23,377.78903
Overall Steps per Second: 10,910.24453

Timestep Collection Time: 2.13938
Timestep Consumption Time: 2.44475
PPO Batch Consumption Time: 0.27970
Total Iteration Time: 4.58413

Cumulative Model Updates: 302,906
Cumulative Timesteps: 2,526,146,346

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2526146346...
Checkpoint 2526146346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.22678
Policy Entropy: 2.50542
Value Function Loss: 0.01783

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.09635
Policy Update Magnitude: 0.48130
Value Function Update Magnitude: 0.64077

Collected Steps per Second: 22,800.88912
Overall Steps per Second: 10,686.48762

Timestep Collection Time: 2.19377
Timestep Consumption Time: 2.48690
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.68068

Cumulative Model Updates: 302,912
Cumulative Timesteps: 2,526,196,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222.14351
Policy Entropy: 2.48027
Value Function Loss: 0.01819

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.09865
Policy Update Magnitude: 0.48373
Value Function Update Magnitude: 0.63744

Collected Steps per Second: 23,392.57410
Overall Steps per Second: 10,967.43736

Timestep Collection Time: 2.13871
Timestep Consumption Time: 2.42297
PPO Batch Consumption Time: 0.29281
Total Iteration Time: 4.56169

Cumulative Model Updates: 302,918
Cumulative Timesteps: 2,526,246,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2526246396...
Checkpoint 2526246396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257.74085
Policy Entropy: 2.46107
Value Function Loss: 0.01911

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.10874
Policy Update Magnitude: 0.49497
Value Function Update Magnitude: 0.66315

Collected Steps per Second: 22,708.37536
Overall Steps per Second: 10,656.73294

Timestep Collection Time: 2.20245
Timestep Consumption Time: 2.49074
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.69318

Cumulative Model Updates: 302,924
Cumulative Timesteps: 2,526,296,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.95177
Policy Entropy: 2.45372
Value Function Loss: 0.01944

Mean KL Divergence: 0.01847
SB3 Clip Fraction: 0.12057
Policy Update Magnitude: 0.49027
Value Function Update Magnitude: 0.69401

Collected Steps per Second: 23,077.36959
Overall Steps per Second: 10,868.13480

Timestep Collection Time: 2.16723
Timestep Consumption Time: 2.43466
PPO Batch Consumption Time: 0.28261
Total Iteration Time: 4.60189

Cumulative Model Updates: 302,930
Cumulative Timesteps: 2,526,346,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2526346424...
Checkpoint 2526346424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309.28389
Policy Entropy: 2.47439
Value Function Loss: 0.01892

Mean KL Divergence: 0.02515
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.46278
Value Function Update Magnitude: 0.70592

Collected Steps per Second: 22,599.55926
Overall Steps per Second: 10,978.47346

Timestep Collection Time: 2.21332
Timestep Consumption Time: 2.34287
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.55619

Cumulative Model Updates: 302,936
Cumulative Timesteps: 2,526,396,444

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 317.99593
Policy Entropy: 2.48984
Value Function Loss: 0.01917

Mean KL Divergence: 0.02024
SB3 Clip Fraction: 0.12467
Policy Update Magnitude: 0.48572
Value Function Update Magnitude: 0.70692

Collected Steps per Second: 22,920.06064
Overall Steps per Second: 10,734.15135

Timestep Collection Time: 2.18193
Timestep Consumption Time: 2.47703
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.65896

Cumulative Model Updates: 302,942
Cumulative Timesteps: 2,526,446,454

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2526446454...
Checkpoint 2526446454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 380.88891
Policy Entropy: 2.48201
Value Function Loss: 0.01926

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.11838
Policy Update Magnitude: 0.50412
Value Function Update Magnitude: 0.69945

Collected Steps per Second: 22,486.40493
Overall Steps per Second: 10,614.74672

Timestep Collection Time: 2.22365
Timestep Consumption Time: 2.48696
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.71062

Cumulative Model Updates: 302,948
Cumulative Timesteps: 2,526,496,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 324.01708
Policy Entropy: 2.46804
Value Function Loss: 0.01806

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.11127
Policy Update Magnitude: 0.49973
Value Function Update Magnitude: 0.69066

Collected Steps per Second: 23,016.86554
Overall Steps per Second: 10,748.55251

Timestep Collection Time: 2.17371
Timestep Consumption Time: 2.48106
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.65477

Cumulative Model Updates: 302,954
Cumulative Timesteps: 2,526,546,488

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2526546488...
Checkpoint 2526546488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.93353
Policy Entropy: 2.46291
Value Function Loss: 0.01729

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.10912
Policy Update Magnitude: 0.48813
Value Function Update Magnitude: 0.66576

Collected Steps per Second: 23,869.63923
Overall Steps per Second: 11,092.74441

Timestep Collection Time: 2.09597
Timestep Consumption Time: 2.41419
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.51016

Cumulative Model Updates: 302,960
Cumulative Timesteps: 2,526,596,518

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.07395
Policy Entropy: 2.46971
Value Function Loss: 0.01745

Mean KL Divergence: 0.01437
SB3 Clip Fraction: 0.10303
Policy Update Magnitude: 0.49243
Value Function Update Magnitude: 0.65524

Collected Steps per Second: 23,274.37549
Overall Steps per Second: 10,939.98464

Timestep Collection Time: 2.14923
Timestep Consumption Time: 2.42317
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.57240

Cumulative Model Updates: 302,966
Cumulative Timesteps: 2,526,646,540

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2526646540...
Checkpoint 2526646540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.51184
Policy Entropy: 2.46182
Value Function Loss: 0.01755

Mean KL Divergence: 0.01514
SB3 Clip Fraction: 0.10479
Policy Update Magnitude: 0.48521
Value Function Update Magnitude: 0.66342

Collected Steps per Second: 22,987.29989
Overall Steps per Second: 10,828.61515

Timestep Collection Time: 2.17520
Timestep Consumption Time: 2.44238
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.61758

Cumulative Model Updates: 302,972
Cumulative Timesteps: 2,526,696,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.89840
Policy Entropy: 2.47848
Value Function Loss: 0.01733

Mean KL Divergence: 0.01423
SB3 Clip Fraction: 0.09902
Policy Update Magnitude: 0.48238
Value Function Update Magnitude: 0.64808

Collected Steps per Second: 23,572.92354
Overall Steps per Second: 11,228.16127

Timestep Collection Time: 2.12227
Timestep Consumption Time: 2.33332
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.45558

Cumulative Model Updates: 302,978
Cumulative Timesteps: 2,526,746,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2526746570...
Checkpoint 2526746570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 374.21084
Policy Entropy: 2.48899
Value Function Loss: 0.01691

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.09357
Policy Update Magnitude: 0.48730
Value Function Update Magnitude: 0.63382

Collected Steps per Second: 22,568.16598
Overall Steps per Second: 10,592.55038

Timestep Collection Time: 2.21675
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.72294

Cumulative Model Updates: 302,984
Cumulative Timesteps: 2,526,796,598

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.09447
Policy Entropy: 2.49403
Value Function Loss: 0.01687

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.09199
Policy Update Magnitude: 0.48580
Value Function Update Magnitude: 0.63864

Collected Steps per Second: 22,686.17046
Overall Steps per Second: 10,668.90198

Timestep Collection Time: 2.20531
Timestep Consumption Time: 2.48402
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.68933

Cumulative Model Updates: 302,990
Cumulative Timesteps: 2,526,846,628

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2526846628...
Checkpoint 2526846628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.88366
Policy Entropy: 2.47815
Value Function Loss: 0.01609

Mean KL Divergence: 0.01300
SB3 Clip Fraction: 0.09071
Policy Update Magnitude: 0.48444
Value Function Update Magnitude: 0.63788

Collected Steps per Second: 22,544.50654
Overall Steps per Second: 10,821.23681

Timestep Collection Time: 2.21854
Timestep Consumption Time: 2.40348
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.62202

Cumulative Model Updates: 302,996
Cumulative Timesteps: 2,526,896,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236.24098
Policy Entropy: 2.48420
Value Function Loss: 0.01567

Mean KL Divergence: 0.01311
SB3 Clip Fraction: 0.09921
Policy Update Magnitude: 0.46824
Value Function Update Magnitude: 0.62758

Collected Steps per Second: 23,237.26453
Overall Steps per Second: 10,990.77444

Timestep Collection Time: 2.15189
Timestep Consumption Time: 2.39775
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.54963

Cumulative Model Updates: 303,002
Cumulative Timesteps: 2,526,946,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2526946648...
Checkpoint 2526946648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.08269
Policy Entropy: 2.49070
Value Function Loss: 0.01669

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.09265
Policy Update Magnitude: 0.47436
Value Function Update Magnitude: 0.61663

Collected Steps per Second: 22,983.95552
Overall Steps per Second: 10,724.72344

Timestep Collection Time: 2.17647
Timestep Consumption Time: 2.48789
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.66436

Cumulative Model Updates: 303,008
Cumulative Timesteps: 2,526,996,672

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302.17859
Policy Entropy: 2.48587
Value Function Loss: 0.01741

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.10049
Policy Update Magnitude: 0.48106
Value Function Update Magnitude: 0.63459

Collected Steps per Second: 23,297.57893
Overall Steps per Second: 10,814.52431

Timestep Collection Time: 2.14718
Timestep Consumption Time: 2.47846
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.62563

Cumulative Model Updates: 303,014
Cumulative Timesteps: 2,527,046,696

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2527046696...
Checkpoint 2527046696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.94955
Policy Entropy: 2.47028
Value Function Loss: 0.01799

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.10165
Policy Update Magnitude: 0.48559
Value Function Update Magnitude: 0.67592

Collected Steps per Second: 23,046.63460
Overall Steps per Second: 10,769.06488

Timestep Collection Time: 2.17021
Timestep Consumption Time: 2.47421
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.64441

Cumulative Model Updates: 303,020
Cumulative Timesteps: 2,527,096,712

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.71551
Policy Entropy: 2.47858
Value Function Loss: 0.01819

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.09782
Policy Update Magnitude: 0.49049
Value Function Update Magnitude: 0.67297

Collected Steps per Second: 24,258.59752
Overall Steps per Second: 11,160.24449

Timestep Collection Time: 2.06236
Timestep Consumption Time: 2.42052
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.48288

Cumulative Model Updates: 303,026
Cumulative Timesteps: 2,527,146,742

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2527146742...
Checkpoint 2527146742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269.74445
Policy Entropy: 2.46774
Value Function Loss: 0.01893

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.09674
Policy Update Magnitude: 0.50043
Value Function Update Magnitude: 0.67244

Collected Steps per Second: 23,285.21657
Overall Steps per Second: 10,765.53307

Timestep Collection Time: 2.14789
Timestep Consumption Time: 2.49787
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.64575

Cumulative Model Updates: 303,032
Cumulative Timesteps: 2,527,196,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.63939
Policy Entropy: 2.45915
Value Function Loss: 0.01911

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.09823
Policy Update Magnitude: 0.51478
Value Function Update Magnitude: 0.68146

Collected Steps per Second: 22,523.75002
Overall Steps per Second: 10,799.20463

Timestep Collection Time: 2.22015
Timestep Consumption Time: 2.41038
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.63053

Cumulative Model Updates: 303,038
Cumulative Timesteps: 2,527,246,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2527246762...
Checkpoint 2527246762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277.95646
Policy Entropy: 2.45456
Value Function Loss: 0.01809

Mean KL Divergence: 0.01426
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.49800
Value Function Update Magnitude: 0.67958

Collected Steps per Second: 22,233.58119
Overall Steps per Second: 10,683.25783

Timestep Collection Time: 2.24903
Timestep Consumption Time: 2.43156
PPO Batch Consumption Time: 0.29421
Total Iteration Time: 4.68059

Cumulative Model Updates: 303,044
Cumulative Timesteps: 2,527,296,766

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284.11237
Policy Entropy: 2.46590
Value Function Loss: 0.01693

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.08868
Policy Update Magnitude: 0.48064
Value Function Update Magnitude: 0.66310

Collected Steps per Second: 23,134.82310
Overall Steps per Second: 10,897.45334

Timestep Collection Time: 2.16228
Timestep Consumption Time: 2.42815
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.59043

Cumulative Model Updates: 303,050
Cumulative Timesteps: 2,527,346,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2527346790...
Checkpoint 2527346790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296.72678
Policy Entropy: 2.48616
Value Function Loss: 0.01669

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.08726
Policy Update Magnitude: 0.48377
Value Function Update Magnitude: 0.64017

Collected Steps per Second: 22,950.67597
Overall Steps per Second: 10,680.23823

Timestep Collection Time: 2.17885
Timestep Consumption Time: 2.50326
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.68211

Cumulative Model Updates: 303,056
Cumulative Timesteps: 2,527,396,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.12054
Policy Entropy: 2.48492
Value Function Loss: 0.01726

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.10043
Policy Update Magnitude: 0.48828
Value Function Update Magnitude: 0.62829

Collected Steps per Second: 23,334.08097
Overall Steps per Second: 10,885.49308

Timestep Collection Time: 2.14365
Timestep Consumption Time: 2.45146
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.59511

Cumulative Model Updates: 303,062
Cumulative Timesteps: 2,527,446,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2527446816...
Checkpoint 2527446816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.53593
Policy Entropy: 2.48492
Value Function Loss: 0.01775

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.48565
Value Function Update Magnitude: 0.62157

Collected Steps per Second: 22,844.95624
Overall Steps per Second: 11,007.57426

Timestep Collection Time: 2.18919
Timestep Consumption Time: 2.35422
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.54342

Cumulative Model Updates: 303,068
Cumulative Timesteps: 2,527,496,828

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 298.57058
Policy Entropy: 2.47476
Value Function Loss: 0.01751

Mean KL Divergence: 0.01598
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.48649
Value Function Update Magnitude: 0.60605

Collected Steps per Second: 23,481.03311
Overall Steps per Second: 10,964.76202

Timestep Collection Time: 2.12972
Timestep Consumption Time: 2.43107
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.56079

Cumulative Model Updates: 303,074
Cumulative Timesteps: 2,527,546,836

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2527546836...
Checkpoint 2527546836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.71423
Policy Entropy: 2.48428
Value Function Loss: 0.01764

Mean KL Divergence: 0.01962
SB3 Clip Fraction: 0.12131
Policy Update Magnitude: 0.47278
Value Function Update Magnitude: 0.59346

Collected Steps per Second: 22,939.49796
Overall Steps per Second: 10,710.25737

Timestep Collection Time: 2.18061
Timestep Consumption Time: 2.48987
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.67048

Cumulative Model Updates: 303,080
Cumulative Timesteps: 2,527,596,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.21327
Policy Entropy: 2.49714
Value Function Loss: 0.01714

Mean KL Divergence: 0.02357
SB3 Clip Fraction: 0.13985
Policy Update Magnitude: 0.44368
Value Function Update Magnitude: 0.59915

Collected Steps per Second: 22,922.63295
Overall Steps per Second: 10,915.17341

Timestep Collection Time: 2.18247
Timestep Consumption Time: 2.40087
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.58334

Cumulative Model Updates: 303,086
Cumulative Timesteps: 2,527,646,886

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2527646886...
Checkpoint 2527646886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.22415
Policy Entropy: 2.51215
Value Function Loss: 0.01684

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.45928
Value Function Update Magnitude: 0.60447

Collected Steps per Second: 22,648.30886
Overall Steps per Second: 10,978.59558

Timestep Collection Time: 2.20829
Timestep Consumption Time: 2.34730
PPO Batch Consumption Time: 0.27952
Total Iteration Time: 4.55559

Cumulative Model Updates: 303,092
Cumulative Timesteps: 2,527,696,900

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348.00264
Policy Entropy: 2.51396
Value Function Loss: 0.01708

Mean KL Divergence: 0.01735
SB3 Clip Fraction: 0.11652
Policy Update Magnitude: 0.48434
Value Function Update Magnitude: 0.61960

Collected Steps per Second: 22,611.80596
Overall Steps per Second: 10,631.68079

Timestep Collection Time: 2.21256
Timestep Consumption Time: 2.49319
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.70575

Cumulative Model Updates: 303,098
Cumulative Timesteps: 2,527,746,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2527746930...
Checkpoint 2527746930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.20494
Policy Entropy: 2.50421
Value Function Loss: 0.01662

Mean KL Divergence: 0.01758
SB3 Clip Fraction: 0.11536
Policy Update Magnitude: 0.48605
Value Function Update Magnitude: 0.63279

Collected Steps per Second: 22,448.31080
Overall Steps per Second: 10,568.16822

Timestep Collection Time: 2.22850
Timestep Consumption Time: 2.50515
PPO Batch Consumption Time: 0.29403
Total Iteration Time: 4.73365

Cumulative Model Updates: 303,104
Cumulative Timesteps: 2,527,796,956

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 360.06267
Policy Entropy: 2.49940
Value Function Loss: 0.01615

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.47849
Value Function Update Magnitude: 0.62029

Collected Steps per Second: 22,803.55246
Overall Steps per Second: 10,866.91494

Timestep Collection Time: 2.19387
Timestep Consumption Time: 2.40983
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.60370

Cumulative Model Updates: 303,110
Cumulative Timesteps: 2,527,846,984

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2527846984...
Checkpoint 2527846984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.79438
Policy Entropy: 2.49663
Value Function Loss: 0.01582

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.10558
Policy Update Magnitude: 0.47236
Value Function Update Magnitude: 0.60435

Collected Steps per Second: 23,100.06472
Overall Steps per Second: 10,853.73504

Timestep Collection Time: 2.16450
Timestep Consumption Time: 2.44221
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.60671

Cumulative Model Updates: 303,116
Cumulative Timesteps: 2,527,896,984

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.18431
Policy Entropy: 2.50219
Value Function Loss: 0.01628

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.10132
Policy Update Magnitude: 0.47413
Value Function Update Magnitude: 0.60296

Collected Steps per Second: 23,005.76027
Overall Steps per Second: 10,704.28772

Timestep Collection Time: 2.17354
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.67140

Cumulative Model Updates: 303,122
Cumulative Timesteps: 2,527,946,988

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2527946988...
Checkpoint 2527946988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348.17970
Policy Entropy: 2.49042
Value Function Loss: 0.01700

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.10225
Policy Update Magnitude: 0.48745
Value Function Update Magnitude: 0.61144

Collected Steps per Second: 22,952.26937
Overall Steps per Second: 10,683.91221

Timestep Collection Time: 2.17931
Timestep Consumption Time: 2.50250
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.68181

Cumulative Model Updates: 303,128
Cumulative Timesteps: 2,527,997,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 347.89812
Policy Entropy: 2.49916
Value Function Loss: 0.01678

Mean KL Divergence: 0.01572
SB3 Clip Fraction: 0.11030
Policy Update Magnitude: 0.48739
Value Function Update Magnitude: 0.61049

Collected Steps per Second: 23,125.94562
Overall Steps per Second: 10,874.15829

Timestep Collection Time: 2.16233
Timestep Consumption Time: 2.43628
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.59861

Cumulative Model Updates: 303,134
Cumulative Timesteps: 2,528,047,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2528047014...
Checkpoint 2528047014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.71371
Policy Entropy: 2.50303
Value Function Loss: 0.01690

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.10951
Policy Update Magnitude: 0.47398
Value Function Update Magnitude: 0.61041

Collected Steps per Second: 23,068.28701
Overall Steps per Second: 10,730.97094

Timestep Collection Time: 2.16756
Timestep Consumption Time: 2.49203
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.65960

Cumulative Model Updates: 303,140
Cumulative Timesteps: 2,528,097,016

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.57817
Policy Entropy: 2.52431
Value Function Loss: 0.01782

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.10892
Policy Update Magnitude: 0.48305
Value Function Update Magnitude: 0.61705

Collected Steps per Second: 23,528.00508
Overall Steps per Second: 10,840.97486

Timestep Collection Time: 2.12598
Timestep Consumption Time: 2.48800
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.61398

Cumulative Model Updates: 303,146
Cumulative Timesteps: 2,528,147,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2528147036...
Checkpoint 2528147036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.09622
Policy Entropy: 2.49220
Value Function Loss: 0.01851

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.12317
Policy Update Magnitude: 0.49321
Value Function Update Magnitude: 0.63074

Collected Steps per Second: 22,236.56316
Overall Steps per Second: 10,642.00145

Timestep Collection Time: 2.24873
Timestep Consumption Time: 2.45001
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.69874

Cumulative Model Updates: 303,152
Cumulative Timesteps: 2,528,197,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382.94935
Policy Entropy: 2.47704
Value Function Loss: 0.01882

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.50596
Value Function Update Magnitude: 0.63412

Collected Steps per Second: 23,034.26272
Overall Steps per Second: 10,906.01467

Timestep Collection Time: 2.17094
Timestep Consumption Time: 2.41424
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.58518

Cumulative Model Updates: 303,158
Cumulative Timesteps: 2,528,247,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2528247046...
Checkpoint 2528247046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307.65368
Policy Entropy: 2.47854
Value Function Loss: 0.01751

Mean KL Divergence: 0.01778
SB3 Clip Fraction: 0.12087
Policy Update Magnitude: 0.50385
Value Function Update Magnitude: 0.63813

Collected Steps per Second: 22,774.42829
Overall Steps per Second: 10,640.69689

Timestep Collection Time: 2.19597
Timestep Consumption Time: 2.50410
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.70007

Cumulative Model Updates: 303,164
Cumulative Timesteps: 2,528,297,058

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.37752
Policy Entropy: 2.49897
Value Function Loss: 0.01769

Mean KL Divergence: 0.01521
SB3 Clip Fraction: 0.10527
Policy Update Magnitude: 0.49693
Value Function Update Magnitude: 0.62663

Collected Steps per Second: 22,925.25061
Overall Steps per Second: 10,839.49503

Timestep Collection Time: 2.18179
Timestep Consumption Time: 2.43264
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.61442

Cumulative Model Updates: 303,170
Cumulative Timesteps: 2,528,347,076

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2528347076...
Checkpoint 2528347076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.48636
Policy Entropy: 2.48674
Value Function Loss: 0.01789

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.10320
Policy Update Magnitude: 0.49981
Value Function Update Magnitude: 0.63130

Collected Steps per Second: 22,723.75561
Overall Steps per Second: 10,683.10066

Timestep Collection Time: 2.20157
Timestep Consumption Time: 2.48134
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.68291

Cumulative Model Updates: 303,176
Cumulative Timesteps: 2,528,397,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 311.25568
Policy Entropy: 2.49776
Value Function Loss: 0.01785

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.49654
Value Function Update Magnitude: 0.65830

Collected Steps per Second: 23,221.08310
Overall Steps per Second: 10,892.40662

Timestep Collection Time: 2.15511
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.59439

Cumulative Model Updates: 303,182
Cumulative Timesteps: 2,528,447,148

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2528447148...
Checkpoint 2528447148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.48679
Policy Entropy: 2.48072
Value Function Loss: 0.01741

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.08859
Policy Update Magnitude: 0.50454
Value Function Update Magnitude: 0.67082

Collected Steps per Second: 23,245.98587
Overall Steps per Second: 10,769.92609

Timestep Collection Time: 2.15117
Timestep Consumption Time: 2.49195
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.64311

Cumulative Model Updates: 303,188
Cumulative Timesteps: 2,528,497,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 407.71793
Policy Entropy: 2.47774
Value Function Loss: 0.01745

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.09115
Policy Update Magnitude: 0.50640
Value Function Update Magnitude: 0.66148

Collected Steps per Second: 23,527.55732
Overall Steps per Second: 10,796.32826

Timestep Collection Time: 2.12653
Timestep Consumption Time: 2.50764
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.63417

Cumulative Model Updates: 303,194
Cumulative Timesteps: 2,528,547,186

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2528547186...
Checkpoint 2528547186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.30524
Policy Entropy: 2.44969
Value Function Loss: 0.01811

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.09649
Policy Update Magnitude: 0.50544
Value Function Update Magnitude: 0.65062

Collected Steps per Second: 22,781.20732
Overall Steps per Second: 11,035.84665

Timestep Collection Time: 2.19576
Timestep Consumption Time: 2.33693
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.53268

Cumulative Model Updates: 303,200
Cumulative Timesteps: 2,528,597,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.65058
Policy Entropy: 2.48946
Value Function Loss: 0.01718

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.09752
Policy Update Magnitude: 0.50347
Value Function Update Magnitude: 0.63948

Collected Steps per Second: 23,119.26225
Overall Steps per Second: 10,930.71874

Timestep Collection Time: 2.16304
Timestep Consumption Time: 2.41195
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.57500

Cumulative Model Updates: 303,206
Cumulative Timesteps: 2,528,647,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2528647216...
Checkpoint 2528647216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319.26424
Policy Entropy: 2.48132
Value Function Loss: 0.01850

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.09707
Policy Update Magnitude: 0.50203
Value Function Update Magnitude: 0.64803

Collected Steps per Second: 22,575.00501
Overall Steps per Second: 10,706.00161

Timestep Collection Time: 2.21528
Timestep Consumption Time: 2.45593
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.67121

Cumulative Model Updates: 303,212
Cumulative Timesteps: 2,528,697,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.87116
Policy Entropy: 2.47530
Value Function Loss: 0.01808

Mean KL Divergence: 0.01333
SB3 Clip Fraction: 0.09766
Policy Update Magnitude: 0.50905
Value Function Update Magnitude: 0.64751

Collected Steps per Second: 22,866.34547
Overall Steps per Second: 10,916.66709

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.39363
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.58034

Cumulative Model Updates: 303,218
Cumulative Timesteps: 2,528,747,228

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2528747228...
Checkpoint 2528747228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.20888
Policy Entropy: 2.43628
Value Function Loss: 0.01952

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.09892
Policy Update Magnitude: 0.51223
Value Function Update Magnitude: 0.64609

Collected Steps per Second: 22,500.64631
Overall Steps per Second: 10,852.02872

Timestep Collection Time: 2.22340
Timestep Consumption Time: 2.38661
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.61001

Cumulative Model Updates: 303,224
Cumulative Timesteps: 2,528,797,256

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.44926
Policy Entropy: 2.45430
Value Function Loss: 0.01821

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.09498
Policy Update Magnitude: 0.50372
Value Function Update Magnitude: 0.64075

Collected Steps per Second: 23,092.11597
Overall Steps per Second: 10,713.26001

Timestep Collection Time: 2.16559
Timestep Consumption Time: 2.50227
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.66786

Cumulative Model Updates: 303,230
Cumulative Timesteps: 2,528,847,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2528847264...
Checkpoint 2528847264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.99308
Policy Entropy: 2.48068
Value Function Loss: 0.01794

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.09497
Policy Update Magnitude: 0.48847
Value Function Update Magnitude: 0.60982

Collected Steps per Second: 23,282.35499
Overall Steps per Second: 10,689.14765

Timestep Collection Time: 2.14849
Timestep Consumption Time: 2.53121
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.67970

Cumulative Model Updates: 303,236
Cumulative Timesteps: 2,528,897,286

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.16567
Policy Entropy: 2.50349
Value Function Loss: 0.01752

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.09169
Policy Update Magnitude: 0.48499
Value Function Update Magnitude: 0.59258

Collected Steps per Second: 23,474.75809
Overall Steps per Second: 10,835.08488

Timestep Collection Time: 2.13003
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.61482

Cumulative Model Updates: 303,242
Cumulative Timesteps: 2,528,947,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2528947288...
Checkpoint 2528947288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330.96331
Policy Entropy: 2.51211
Value Function Loss: 0.01811

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.09526
Policy Update Magnitude: 0.49304
Value Function Update Magnitude: 0.61793

Collected Steps per Second: 23,189.88816
Overall Steps per Second: 10,987.28959

Timestep Collection Time: 2.15715
Timestep Consumption Time: 2.39575
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.55290

Cumulative Model Updates: 303,248
Cumulative Timesteps: 2,528,997,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.21786
Policy Entropy: 2.49941
Value Function Loss: 0.01853

Mean KL Divergence: 0.01483
SB3 Clip Fraction: 0.10943
Policy Update Magnitude: 0.49257
Value Function Update Magnitude: 0.64147

Collected Steps per Second: 23,670.33670
Overall Steps per Second: 11,040.51917

Timestep Collection Time: 2.11362
Timestep Consumption Time: 2.41787
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.53149

Cumulative Model Updates: 303,254
Cumulative Timesteps: 2,529,047,342

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2529047342...
Checkpoint 2529047342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383.64687
Policy Entropy: 2.50637
Value Function Loss: 0.01753

Mean KL Divergence: 0.01396
SB3 Clip Fraction: 0.10220
Policy Update Magnitude: 0.48676
Value Function Update Magnitude: 0.63925

Collected Steps per Second: 22,951.95163
Overall Steps per Second: 10,746.45759

Timestep Collection Time: 2.17873
Timestep Consumption Time: 2.47453
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.65325

Cumulative Model Updates: 303,260
Cumulative Timesteps: 2,529,097,348

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306.75641
Policy Entropy: 2.49770
Value Function Loss: 0.01664

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.10764
Policy Update Magnitude: 0.48494
Value Function Update Magnitude: 0.62558

Collected Steps per Second: 23,290.81417
Overall Steps per Second: 10,817.21602

Timestep Collection Time: 2.14763
Timestep Consumption Time: 2.47648
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.62411

Cumulative Model Updates: 303,266
Cumulative Timesteps: 2,529,147,368

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2529147368...
Checkpoint 2529147368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266.74744
Policy Entropy: 2.50632
Value Function Loss: 0.01543

Mean KL Divergence: 0.01537
SB3 Clip Fraction: 0.10929
Policy Update Magnitude: 0.49787
Value Function Update Magnitude: 0.64919

Collected Steps per Second: 22,544.51243
Overall Steps per Second: 10,971.26700

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.34083
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.55991

Cumulative Model Updates: 303,272
Cumulative Timesteps: 2,529,197,396

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.05923
Policy Entropy: 2.50522
Value Function Loss: 0.01533

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.10692
Policy Update Magnitude: 0.47421
Value Function Update Magnitude: 0.66214

Collected Steps per Second: 22,790.06988
Overall Steps per Second: 10,695.23269

Timestep Collection Time: 2.19411
Timestep Consumption Time: 2.48124
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.67535

Cumulative Model Updates: 303,278
Cumulative Timesteps: 2,529,247,400

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2529247400...
Checkpoint 2529247400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.83664
Policy Entropy: 2.49645
Value Function Loss: 0.01548

Mean KL Divergence: 0.01202
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.47409
Value Function Update Magnitude: 0.65317

Collected Steps per Second: 22,700.72056
Overall Steps per Second: 10,701.59100

Timestep Collection Time: 2.20389
Timestep Consumption Time: 2.47111
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.67501

Cumulative Model Updates: 303,284
Cumulative Timesteps: 2,529,297,430

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 349.24046
Policy Entropy: 2.50489
Value Function Loss: 0.01620

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.09226
Policy Update Magnitude: 0.47566
Value Function Update Magnitude: 0.64040

Collected Steps per Second: 23,388.11761
Overall Steps per Second: 10,856.29352

Timestep Collection Time: 2.13835
Timestep Consumption Time: 2.46838
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.60673

Cumulative Model Updates: 303,290
Cumulative Timesteps: 2,529,347,442

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2529347442...
Checkpoint 2529347442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324.65321
Policy Entropy: 2.50348
Value Function Loss: 0.01655

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.10336
Policy Update Magnitude: 0.48376
Value Function Update Magnitude: 0.63850

Collected Steps per Second: 23,125.44735
Overall Steps per Second: 10,968.32975

Timestep Collection Time: 2.16290
Timestep Consumption Time: 2.39732
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.56022

Cumulative Model Updates: 303,296
Cumulative Timesteps: 2,529,397,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.36789
Policy Entropy: 2.51448
Value Function Loss: 0.01662

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.08965
Policy Update Magnitude: 0.48136
Value Function Update Magnitude: 0.64043

Collected Steps per Second: 23,390.31278
Overall Steps per Second: 10,871.63034

Timestep Collection Time: 2.13789
Timestep Consumption Time: 2.46178
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.59968

Cumulative Model Updates: 303,302
Cumulative Timesteps: 2,529,447,466

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2529447466...
Checkpoint 2529447466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.32505
Policy Entropy: 2.48084
Value Function Loss: 0.01712

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.10218
Policy Update Magnitude: 0.48627
Value Function Update Magnitude: 0.63226

Collected Steps per Second: 22,622.57662
Overall Steps per Second: 10,615.48724

Timestep Collection Time: 2.21036
Timestep Consumption Time: 2.50012
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.71048

Cumulative Model Updates: 303,308
Cumulative Timesteps: 2,529,497,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280.54413
Policy Entropy: 2.50286
Value Function Loss: 0.01638

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.09242
Policy Update Magnitude: 0.47864
Value Function Update Magnitude: 0.62165

Collected Steps per Second: 23,293.56414
Overall Steps per Second: 10,926.09057

Timestep Collection Time: 2.14772
Timestep Consumption Time: 2.43105
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.57876

Cumulative Model Updates: 303,314
Cumulative Timesteps: 2,529,547,498

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2529547498...
Checkpoint 2529547498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.82742
Policy Entropy: 2.49534
Value Function Loss: 0.01580

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.09065
Policy Update Magnitude: 0.46775
Value Function Update Magnitude: 0.60825

Collected Steps per Second: 22,949.92626
Overall Steps per Second: 11,049.40303

Timestep Collection Time: 2.17953
Timestep Consumption Time: 2.34741
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.52694

Cumulative Model Updates: 303,320
Cumulative Timesteps: 2,529,597,518

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.09168
Policy Entropy: 2.51463
Value Function Loss: 0.01583

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.08858
Policy Update Magnitude: 0.48231
Value Function Update Magnitude: 0.60925

Collected Steps per Second: 23,177.10597
Overall Steps per Second: 10,909.59751

Timestep Collection Time: 2.15799
Timestep Consumption Time: 2.42660
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.58459

Cumulative Model Updates: 303,326
Cumulative Timesteps: 2,529,647,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2529647534...
Checkpoint 2529647534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305.90924
Policy Entropy: 2.49162
Value Function Loss: 0.01679

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.09055
Policy Update Magnitude: 0.49632
Value Function Update Magnitude: 0.63132

Collected Steps per Second: 22,199.23939
Overall Steps per Second: 10,684.76831

Timestep Collection Time: 2.25260
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.68012

Cumulative Model Updates: 303,332
Cumulative Timesteps: 2,529,697,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270.27102
Policy Entropy: 2.49296
Value Function Loss: 0.01724

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.10014
Policy Update Magnitude: 0.49582
Value Function Update Magnitude: 0.63774

Collected Steps per Second: 22,844.89731
Overall Steps per Second: 10,948.68698

Timestep Collection Time: 2.18911
Timestep Consumption Time: 2.37856
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.56767

Cumulative Model Updates: 303,338
Cumulative Timesteps: 2,529,747,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2529747550...
Checkpoint 2529747550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.04381
Policy Entropy: 2.48648
Value Function Loss: 0.01808

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.10120
Policy Update Magnitude: 0.50371
Value Function Update Magnitude: 0.64780

Collected Steps per Second: 22,081.85754
Overall Steps per Second: 10,628.75527

Timestep Collection Time: 2.26548
Timestep Consumption Time: 2.44119
PPO Batch Consumption Time: 0.28259
Total Iteration Time: 4.70667

Cumulative Model Updates: 303,344
Cumulative Timesteps: 2,529,797,576

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.54146
Policy Entropy: 2.51056
Value Function Loss: 0.01752

Mean KL Divergence: 0.01360
SB3 Clip Fraction: 0.09527
Policy Update Magnitude: 0.50299
Value Function Update Magnitude: 0.66364

Collected Steps per Second: 22,940.59313
Overall Steps per Second: 10,794.83166

Timestep Collection Time: 2.17954
Timestep Consumption Time: 2.45230
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.63185

Cumulative Model Updates: 303,350
Cumulative Timesteps: 2,529,847,576

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2529847576...
Checkpoint 2529847576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376.73976
Policy Entropy: 2.49080
Value Function Loss: 0.01762

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.08748
Policy Update Magnitude: 0.50178
Value Function Update Magnitude: 0.66960

Collected Steps per Second: 21,756.23093
Overall Steps per Second: 10,408.68730

Timestep Collection Time: 2.29856
Timestep Consumption Time: 2.50589
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.80445

Cumulative Model Updates: 303,356
Cumulative Timesteps: 2,529,897,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368.26935
Policy Entropy: 2.49871
Value Function Loss: 0.01696

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.09027
Policy Update Magnitude: 0.48838
Value Function Update Magnitude: 0.65258

Collected Steps per Second: 23,393.40552
Overall Steps per Second: 11,079.76454

Timestep Collection Time: 2.13847
Timestep Consumption Time: 2.37661
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.51508

Cumulative Model Updates: 303,362
Cumulative Timesteps: 2,529,947,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2529947610...
Checkpoint 2529947610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.59185
Policy Entropy: 2.47395
Value Function Loss: 0.01753

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.09339
Policy Update Magnitude: 0.48972
Value Function Update Magnitude: 0.65047

Collected Steps per Second: 22,900.13829
Overall Steps per Second: 10,853.48636

Timestep Collection Time: 2.18357
Timestep Consumption Time: 2.42362
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.60718

Cumulative Model Updates: 303,368
Cumulative Timesteps: 2,529,997,614

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.19507
Policy Entropy: 2.49640
Value Function Loss: 0.01730

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.09599
Policy Update Magnitude: 0.49062
Value Function Update Magnitude: 0.66770

Collected Steps per Second: 23,215.85272
Overall Steps per Second: 10,861.04727

Timestep Collection Time: 2.15482
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.60600

Cumulative Model Updates: 303,374
Cumulative Timesteps: 2,530,047,640

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2530047640...
Checkpoint 2530047640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365.64146
Policy Entropy: 2.48670
Value Function Loss: 0.01773

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.08946
Policy Update Magnitude: 0.48498
Value Function Update Magnitude: 0.65746

Collected Steps per Second: 23,005.14722
Overall Steps per Second: 11,043.94644

Timestep Collection Time: 2.17543
Timestep Consumption Time: 2.35611
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.53153

Cumulative Model Updates: 303,380
Cumulative Timesteps: 2,530,097,686

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.35594
Policy Entropy: 2.49736
Value Function Loss: 0.01755

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.09279
Policy Update Magnitude: 0.48307
Value Function Update Magnitude: 0.64437

Collected Steps per Second: 23,067.76350
Overall Steps per Second: 10,907.82629

Timestep Collection Time: 2.16831
Timestep Consumption Time: 2.41721
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.58551

Cumulative Model Updates: 303,386
Cumulative Timesteps: 2,530,147,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2530147704...
Checkpoint 2530147704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.13507
Policy Entropy: 2.49477
Value Function Loss: 0.01785

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.10163
Policy Update Magnitude: 0.48728
Value Function Update Magnitude: 0.64312

Collected Steps per Second: 22,396.90009
Overall Steps per Second: 10,760.73494

Timestep Collection Time: 2.23263
Timestep Consumption Time: 2.41426
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.64689

Cumulative Model Updates: 303,392
Cumulative Timesteps: 2,530,197,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.36263
Policy Entropy: 2.47004
Value Function Loss: 0.01932

Mean KL Divergence: 0.01418
SB3 Clip Fraction: 0.09553
Policy Update Magnitude: 0.50821
Value Function Update Magnitude: 0.66261

Collected Steps per Second: 22,806.84857
Overall Steps per Second: 10,866.55106

Timestep Collection Time: 2.19276
Timestep Consumption Time: 2.40943
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.60220

Cumulative Model Updates: 303,398
Cumulative Timesteps: 2,530,247,718

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2530247718...
Checkpoint 2530247718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.89461
Policy Entropy: 2.44183
Value Function Loss: 0.01936

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.10173
Policy Update Magnitude: 0.51830
Value Function Update Magnitude: 0.69589

Collected Steps per Second: 22,942.66274
Overall Steps per Second: 10,643.75255

Timestep Collection Time: 2.18030
Timestep Consumption Time: 2.51935
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.69966

Cumulative Model Updates: 303,404
Cumulative Timesteps: 2,530,297,740

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.13897
Policy Entropy: 2.42769
Value Function Loss: 0.01914

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.10548
Policy Update Magnitude: 0.52291
Value Function Update Magnitude: 0.68800

Collected Steps per Second: 22,949.98620
Overall Steps per Second: 10,835.39383

Timestep Collection Time: 2.17970
Timestep Consumption Time: 2.43703
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.61672

Cumulative Model Updates: 303,410
Cumulative Timesteps: 2,530,347,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2530347764...
Checkpoint 2530347764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.57582
Policy Entropy: 2.44252
Value Function Loss: 0.01846

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.10055
Policy Update Magnitude: 0.51785
Value Function Update Magnitude: 0.68281

Collected Steps per Second: 22,892.14892
Overall Steps per Second: 10,704.14188

Timestep Collection Time: 2.18424
Timestep Consumption Time: 2.48703
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.67128

Cumulative Model Updates: 303,416
Cumulative Timesteps: 2,530,397,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.65519
Policy Entropy: 2.46072
Value Function Loss: 0.01777

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.50546
Value Function Update Magnitude: 0.67470

Collected Steps per Second: 23,318.00809
Overall Steps per Second: 10,926.73296

Timestep Collection Time: 2.14452
Timestep Consumption Time: 2.43196
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.57648

Cumulative Model Updates: 303,422
Cumulative Timesteps: 2,530,447,772

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2530447772...
Checkpoint 2530447772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321.89420
Policy Entropy: 2.47284
Value Function Loss: 0.01797

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.09606
Policy Update Magnitude: 0.50073
Value Function Update Magnitude: 0.65489

Collected Steps per Second: 22,928.53995
Overall Steps per Second: 10,711.56527

Timestep Collection Time: 2.18147
Timestep Consumption Time: 2.48806
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.66953

Cumulative Model Updates: 303,428
Cumulative Timesteps: 2,530,497,790

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.32488
Policy Entropy: 2.46479
Value Function Loss: 0.01692

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.10349
Policy Update Magnitude: 0.50026
Value Function Update Magnitude: 0.63880

Collected Steps per Second: 23,334.63701
Overall Steps per Second: 10,851.76246

Timestep Collection Time: 2.14342
Timestep Consumption Time: 2.46560
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.60902

Cumulative Model Updates: 303,434
Cumulative Timesteps: 2,530,547,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2530547806...
Checkpoint 2530547806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.59487
Policy Entropy: 2.45842
Value Function Loss: 0.01668

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.09814
Policy Update Magnitude: 0.49084
Value Function Update Magnitude: 0.62414

Collected Steps per Second: 22,693.87299
Overall Steps per Second: 10,699.56224

Timestep Collection Time: 2.20368
Timestep Consumption Time: 2.47034
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.67402

Cumulative Model Updates: 303,440
Cumulative Timesteps: 2,530,597,816

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.71849
Policy Entropy: 2.46349
Value Function Loss: 0.01670

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.10185
Policy Update Magnitude: 0.49224
Value Function Update Magnitude: 0.62729

Collected Steps per Second: 23,795.18902
Overall Steps per Second: 10,849.16863

Timestep Collection Time: 2.10261
Timestep Consumption Time: 2.50899
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.61160

Cumulative Model Updates: 303,446
Cumulative Timesteps: 2,530,647,848

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2530647848...
Checkpoint 2530647848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.58762
Policy Entropy: 2.45664
Value Function Loss: 0.01787

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.10115
Policy Update Magnitude: 0.49824
Value Function Update Magnitude: 0.63709

Collected Steps per Second: 22,275.21433
Overall Steps per Second: 10,628.87240

Timestep Collection Time: 2.24537
Timestep Consumption Time: 2.46031
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.70567

Cumulative Model Updates: 303,452
Cumulative Timesteps: 2,530,697,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265.00884
Policy Entropy: 2.46031
Value Function Loss: 0.01782

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.10237
Policy Update Magnitude: 0.50021
Value Function Update Magnitude: 0.65520

Collected Steps per Second: 23,002.50483
Overall Steps per Second: 10,881.52730

Timestep Collection Time: 2.17420
Timestep Consumption Time: 2.42185
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.59605

Cumulative Model Updates: 303,458
Cumulative Timesteps: 2,530,747,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2530747876...
Checkpoint 2530747876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.87337
Policy Entropy: 2.45093
Value Function Loss: 0.01738

Mean KL Divergence: 0.01564
SB3 Clip Fraction: 0.09916
Policy Update Magnitude: 0.50017
Value Function Update Magnitude: 0.66214

Collected Steps per Second: 22,778.76834
Overall Steps per Second: 10,810.60774

Timestep Collection Time: 2.19555
Timestep Consumption Time: 2.43064
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.62620

Cumulative Model Updates: 303,464
Cumulative Timesteps: 2,530,797,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350.94269
Policy Entropy: 2.46133
Value Function Loss: 0.01659

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.10847
Policy Update Magnitude: 0.49246
Value Function Update Magnitude: 0.65460

Collected Steps per Second: 23,835.49174
Overall Steps per Second: 10,908.97821

Timestep Collection Time: 2.09847
Timestep Consumption Time: 2.48656
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.58503

Cumulative Model Updates: 303,470
Cumulative Timesteps: 2,530,847,906

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2530847906...
Checkpoint 2530847906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291.26584
Policy Entropy: 2.46829
Value Function Loss: 0.01662

Mean KL Divergence: 0.01567
SB3 Clip Fraction: 0.10649
Policy Update Magnitude: 0.48710
Value Function Update Magnitude: 0.65508

Collected Steps per Second: 23,273.34149
Overall Steps per Second: 10,983.50934

Timestep Collection Time: 2.14838
Timestep Consumption Time: 2.40390
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.55228

Cumulative Model Updates: 303,476
Cumulative Timesteps: 2,530,897,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263.19979
Policy Entropy: 2.47686
Value Function Loss: 0.01630

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.10451
Policy Update Magnitude: 0.49511
Value Function Update Magnitude: 0.65455

Collected Steps per Second: 23,486.67627
Overall Steps per Second: 10,897.95540

Timestep Collection Time: 2.12938
Timestep Consumption Time: 2.45974
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.58912

Cumulative Model Updates: 303,482
Cumulative Timesteps: 2,530,947,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2530947918...
Checkpoint 2530947918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.44895
Policy Entropy: 2.46915
Value Function Loss: 0.01615

Mean KL Divergence: 0.01485
SB3 Clip Fraction: 0.10223
Policy Update Magnitude: 0.51825
Value Function Update Magnitude: 0.64712

Collected Steps per Second: 22,532.85546
Overall Steps per Second: 10,852.26460

Timestep Collection Time: 2.22022
Timestep Consumption Time: 2.38969
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.60991

Cumulative Model Updates: 303,488
Cumulative Timesteps: 2,530,997,946

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282.92304
Policy Entropy: 2.47250
Value Function Loss: 0.01619

Mean KL Divergence: 0.01512
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.50564
Value Function Update Magnitude: 0.62339

Collected Steps per Second: 23,426.32397
Overall Steps per Second: 10,864.33209

Timestep Collection Time: 2.13529
Timestep Consumption Time: 2.46895
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.60424

Cumulative Model Updates: 303,494
Cumulative Timesteps: 2,531,047,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2531047968...
Checkpoint 2531047968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306.88512
Policy Entropy: 2.48248
Value Function Loss: 0.01618

Mean KL Divergence: 0.01540
SB3 Clip Fraction: 0.10659
Policy Update Magnitude: 0.48674
Value Function Update Magnitude: 0.60080

Collected Steps per Second: 22,732.59978
Overall Steps per Second: 10,705.63988

Timestep Collection Time: 2.19975
Timestep Consumption Time: 2.47125
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.67100

Cumulative Model Updates: 303,500
Cumulative Timesteps: 2,531,097,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296.40002
Policy Entropy: 2.48620
Value Function Loss: 0.01687

Mean KL Divergence: 0.01372
SB3 Clip Fraction: 0.09932
Policy Update Magnitude: 0.48178
Value Function Update Magnitude: 0.58925

Collected Steps per Second: 22,788.97253
Overall Steps per Second: 10,924.16343

Timestep Collection Time: 2.19457
Timestep Consumption Time: 2.38354
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.57811

Cumulative Model Updates: 303,506
Cumulative Timesteps: 2,531,147,986

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2531147986...
Checkpoint 2531147986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.00910
Policy Entropy: 2.48640
Value Function Loss: 0.01700

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.10442
Policy Update Magnitude: 0.49264
Value Function Update Magnitude: 0.60060

Collected Steps per Second: 22,274.12054
Overall Steps per Second: 10,736.65134

Timestep Collection Time: 2.24512
Timestep Consumption Time: 2.41257
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.65769

Cumulative Model Updates: 303,512
Cumulative Timesteps: 2,531,197,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341.32793
Policy Entropy: 2.47159
Value Function Loss: 0.01735

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.11499
Policy Update Magnitude: 0.49440
Value Function Update Magnitude: 0.59512

Collected Steps per Second: 22,673.47406
Overall Steps per Second: 10,600.08067

Timestep Collection Time: 2.20654
Timestep Consumption Time: 2.51323
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.71978

Cumulative Model Updates: 303,518
Cumulative Timesteps: 2,531,248,024

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2531248024...
Checkpoint 2531248024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.27684
Policy Entropy: 2.46726
Value Function Loss: 0.01697

Mean KL Divergence: 0.01477
SB3 Clip Fraction: 0.10127
Policy Update Magnitude: 0.48926
Value Function Update Magnitude: 0.59059

Collected Steps per Second: 22,336.34087
Overall Steps per Second: 10,569.33064

Timestep Collection Time: 2.23868
Timestep Consumption Time: 2.49236
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.73105

Cumulative Model Updates: 303,524
Cumulative Timesteps: 2,531,298,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321.77778
Policy Entropy: 2.46106
Value Function Loss: 0.01659

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09896
Policy Update Magnitude: 0.49622
Value Function Update Magnitude: 0.58426

Collected Steps per Second: 23,439.71793
Overall Steps per Second: 10,922.50447

Timestep Collection Time: 2.13424
Timestep Consumption Time: 2.44584
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.58009

Cumulative Model Updates: 303,530
Cumulative Timesteps: 2,531,348,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2531348054...
Checkpoint 2531348054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262.34658
Policy Entropy: 2.45212
Value Function Loss: 0.01679

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.08797
Policy Update Magnitude: 0.49957
Value Function Update Magnitude: 0.59373

Collected Steps per Second: 23,149.51036
Overall Steps per Second: 10,722.37864

Timestep Collection Time: 2.16151
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.29510
Total Iteration Time: 4.66669

Cumulative Model Updates: 303,536
Cumulative Timesteps: 2,531,398,092

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.10948
Policy Entropy: 2.43874
Value Function Loss: 0.01813

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.10269
Policy Update Magnitude: 0.51235
Value Function Update Magnitude: 0.62751

Collected Steps per Second: 23,173.98992
Overall Steps per Second: 10,843.36086

Timestep Collection Time: 2.15897
Timestep Consumption Time: 2.45510
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.61407

Cumulative Model Updates: 303,542
Cumulative Timesteps: 2,531,448,124

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2531448124...
Checkpoint 2531448124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363.34103
Policy Entropy: 2.44761
Value Function Loss: 0.01768

Mean KL Divergence: 0.01411
SB3 Clip Fraction: 0.09732
Policy Update Magnitude: 0.50917
Value Function Update Magnitude: 0.64485

Collected Steps per Second: 23,067.01044
Overall Steps per Second: 11,076.97619

Timestep Collection Time: 2.16864
Timestep Consumption Time: 2.34740
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.51603

Cumulative Model Updates: 303,548
Cumulative Timesteps: 2,531,498,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.97050
Policy Entropy: 2.43578
Value Function Loss: 0.01839

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.11311
Policy Update Magnitude: 0.51452
Value Function Update Magnitude: 0.62609

Collected Steps per Second: 23,571.66825
Overall Steps per Second: 10,956.35897

Timestep Collection Time: 2.12128
Timestep Consumption Time: 2.44247
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.56374

Cumulative Model Updates: 303,554
Cumulative Timesteps: 2,531,548,150

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2531548150...
Checkpoint 2531548150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341.05094
Policy Entropy: 2.44223
Value Function Loss: 0.01818

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.10885
Policy Update Magnitude: 0.51299
Value Function Update Magnitude: 0.60447

Collected Steps per Second: 22,361.34517
Overall Steps per Second: 10,628.08727

Timestep Collection Time: 2.23636
Timestep Consumption Time: 2.46891
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.70527

Cumulative Model Updates: 303,560
Cumulative Timesteps: 2,531,598,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 356.64429
Policy Entropy: 2.44035
Value Function Loss: 0.01776

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.11149
Policy Update Magnitude: 0.49204
Value Function Update Magnitude: 0.59949

Collected Steps per Second: 22,000.98569
Overall Steps per Second: 10,521.56460

Timestep Collection Time: 2.27353
Timestep Consumption Time: 2.48051
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.75405

Cumulative Model Updates: 303,566
Cumulative Timesteps: 2,531,648,178

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 2531648178...
Checkpoint 2531648178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 326.49783
Policy Entropy: 2.44993
Value Function Loss: 0.01702

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.09773
Policy Update Magnitude: 0.48749
Value Function Update Magnitude: 0.61262

Collected Steps per Second: 22,597.06002
Overall Steps per Second: 10,946.83491

Timestep Collection Time: 2.21365
Timestep Consumption Time: 2.35589
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.56954

Cumulative Model Updates: 303,572
Cumulative Timesteps: 2,531,698,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 281.33147
Policy Entropy: 2.46783
Value Function Loss: 0.01643

Mean KL Divergence: 0.01450
SB3 Clip Fraction: 0.10156
Policy Update Magnitude: 0.47676
Value Function Update Magnitude: 0.61852

Collected Steps per Second: 22,939.57281
Overall Steps per Second: 10,748.40158

Timestep Collection Time: 2.17990
Timestep Consumption Time: 2.47251
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.65241

Cumulative Model Updates: 303,578
Cumulative Timesteps: 2,531,748,206

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2531748206...
Checkpoint 2531748206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279.59839
Policy Entropy: 2.45516
Value Function Loss: 0.01691

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.09848
Policy Update Magnitude: 0.48180
Value Function Update Magnitude: 0.61128

Collected Steps per Second: 22,854.82797
Overall Steps per Second: 10,788.67320

Timestep Collection Time: 2.18807
Timestep Consumption Time: 2.44716
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.63523

Cumulative Model Updates: 303,584
Cumulative Timesteps: 2,531,798,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246.09003
Policy Entropy: 2.44068
Value Function Loss: 0.01676

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.09425
Policy Update Magnitude: 0.49581
Value Function Update Magnitude: 0.60976

Collected Steps per Second: 22,314.44264
Overall Steps per Second: 10,558.18757

Timestep Collection Time: 2.24079
Timestep Consumption Time: 2.49506
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.73585

Cumulative Model Updates: 303,590
Cumulative Timesteps: 2,531,848,216

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2531848216...
Checkpoint 2531848216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289.96100
Policy Entropy: 2.43154
Value Function Loss: 0.01720

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.09830
Policy Update Magnitude: 0.49263
Value Function Update Magnitude: 0.61827

Collected Steps per Second: 22,260.61815
Overall Steps per Second: 10,745.67939

Timestep Collection Time: 2.24729
Timestep Consumption Time: 2.40817
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.65545

Cumulative Model Updates: 303,596
Cumulative Timesteps: 2,531,898,242

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.64468
Policy Entropy: 2.44208
Value Function Loss: 0.01772

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.09934
Policy Update Magnitude: 0.49424
Value Function Update Magnitude: 0.63114

Collected Steps per Second: 23,166.40739
Overall Steps per Second: 10,788.17192

Timestep Collection Time: 2.15847
Timestep Consumption Time: 2.47661
PPO Batch Consumption Time: 0.28542
Total Iteration Time: 4.63508

Cumulative Model Updates: 303,602
Cumulative Timesteps: 2,531,948,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2531948246...
Checkpoint 2531948246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292.10618
Policy Entropy: 2.45449
Value Function Loss: 0.01796

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.09464
Policy Update Magnitude: 0.49907
Value Function Update Magnitude: 0.63146

Collected Steps per Second: 23,051.46232
Overall Steps per Second: 10,748.30930

Timestep Collection Time: 2.17019
Timestep Consumption Time: 2.48413
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.65431

Cumulative Model Updates: 303,608
Cumulative Timesteps: 2,531,998,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.00129
Policy Entropy: 2.42669
Value Function Loss: 0.01803

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.09422
Policy Update Magnitude: 0.49383
Value Function Update Magnitude: 0.62966

Collected Steps per Second: 23,336.86891
Overall Steps per Second: 11,093.46771

Timestep Collection Time: 2.14279
Timestep Consumption Time: 2.36491
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.50770

Cumulative Model Updates: 303,614
Cumulative Timesteps: 2,532,048,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2532048278...
Checkpoint 2532048278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.89175
Policy Entropy: 2.40273
Value Function Loss: 0.01874

Mean KL Divergence: 0.01666
SB3 Clip Fraction: 0.10952
Policy Update Magnitude: 0.49417
Value Function Update Magnitude: 0.63697

Collected Steps per Second: 23,165.88150
Overall Steps per Second: 10,768.89209

Timestep Collection Time: 2.15852
Timestep Consumption Time: 2.48486
PPO Batch Consumption Time: 0.28809
Total Iteration Time: 4.64337

Cumulative Model Updates: 303,620
Cumulative Timesteps: 2,532,098,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.81120
Policy Entropy: 2.41479
Value Function Loss: 0.01910

Mean KL Divergence: 0.03451
SB3 Clip Fraction: 0.17061
Policy Update Magnitude: 0.45394
Value Function Update Magnitude: 0.65237

Collected Steps per Second: 23,513.76682
Overall Steps per Second: 10,921.43039

Timestep Collection Time: 2.12675
Timestep Consumption Time: 2.45213
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.57889

Cumulative Model Updates: 303,626
Cumulative Timesteps: 2,532,148,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2532148290...
Checkpoint 2532148290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275.35682
Policy Entropy: 2.42564
Value Function Loss: 0.01919

Mean KL Divergence: 0.03352
SB3 Clip Fraction: 0.16125
Policy Update Magnitude: 0.43287
Value Function Update Magnitude: 0.64733

Collected Steps per Second: 23,172.27242
Overall Steps per Second: 11,074.30425

Timestep Collection Time: 2.15896
Timestep Consumption Time: 2.35853
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.51748

Cumulative Model Updates: 303,632
Cumulative Timesteps: 2,532,198,318

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.67160
Policy Entropy: 2.43176
Value Function Loss: 0.01959

Mean KL Divergence: 0.04821
SB3 Clip Fraction: 0.19388
Policy Update Magnitude: 0.44187
Value Function Update Magnitude: 0.63217

Collected Steps per Second: 23,180.25197
Overall Steps per Second: 10,913.99909

Timestep Collection Time: 2.15778
Timestep Consumption Time: 2.42514
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.58292

Cumulative Model Updates: 303,638
Cumulative Timesteps: 2,532,248,336

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2532248336...
Checkpoint 2532248336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263.04565
Policy Entropy: 2.43846
Value Function Loss: 0.01885

Mean KL Divergence: 0.03466
SB3 Clip Fraction: 0.15928
Policy Update Magnitude: 0.48880
Value Function Update Magnitude: 0.62703

Collected Steps per Second: 22,028.56622
Overall Steps per Second: 10,670.65140

Timestep Collection Time: 2.27023
Timestep Consumption Time: 2.41645
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.68669

Cumulative Model Updates: 303,644
Cumulative Timesteps: 2,532,298,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.85360
Policy Entropy: 2.42835
Value Function Loss: 0.01837

Mean KL Divergence: 0.02308
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.50717
Value Function Update Magnitude: 0.62800

Collected Steps per Second: 22,882.54354
Overall Steps per Second: 10,922.49581

Timestep Collection Time: 2.18586
Timestep Consumption Time: 2.39350
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.57936

Cumulative Model Updates: 303,650
Cumulative Timesteps: 2,532,348,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2532348364...
Checkpoint 2532348364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.95682
Policy Entropy: 2.45371
Value Function Loss: 0.01727

Mean KL Divergence: 0.01866
SB3 Clip Fraction: 0.12288
Policy Update Magnitude: 0.51055
Value Function Update Magnitude: 0.63840

Collected Steps per Second: 22,721.81292
Overall Steps per Second: 11,000.09122

Timestep Collection Time: 2.20079
Timestep Consumption Time: 2.34517
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.54596

Cumulative Model Updates: 303,656
Cumulative Timesteps: 2,532,398,370

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257.59527
Policy Entropy: 2.41990
Value Function Loss: 0.01804

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.10638
Policy Update Magnitude: 0.51480
Value Function Update Magnitude: 0.63855

Collected Steps per Second: 22,808.68345
Overall Steps per Second: 10,661.47150

Timestep Collection Time: 2.19259
Timestep Consumption Time: 2.49814
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.69072

Cumulative Model Updates: 303,662
Cumulative Timesteps: 2,532,448,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2532448380...
Checkpoint 2532448380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.38893
Policy Entropy: 2.45484
Value Function Loss: 0.01799

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.11012
Policy Update Magnitude: 0.51974
Value Function Update Magnitude: 0.65215

Collected Steps per Second: 22,765.23804
Overall Steps per Second: 10,597.05891

Timestep Collection Time: 2.19668
Timestep Consumption Time: 2.52236
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.71905

Cumulative Model Updates: 303,668
Cumulative Timesteps: 2,532,498,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.83823
Policy Entropy: 2.43643
Value Function Loss: 0.01819

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.50618
Value Function Update Magnitude: 0.64578

Collected Steps per Second: 23,313.97881
Overall Steps per Second: 10,808.78884

Timestep Collection Time: 2.14567
Timestep Consumption Time: 2.48242
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.62809

Cumulative Model Updates: 303,674
Cumulative Timesteps: 2,532,548,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2532548412...
Checkpoint 2532548412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351.67602
Policy Entropy: 2.44405
Value Function Loss: 0.01750

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.10707
Policy Update Magnitude: 0.50457
Value Function Update Magnitude: 0.62349

Collected Steps per Second: 22,784.06120
Overall Steps per Second: 11,010.47314

Timestep Collection Time: 2.19487
Timestep Consumption Time: 2.34699
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.54186

Cumulative Model Updates: 303,680
Cumulative Timesteps: 2,532,598,420

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.24745
Policy Entropy: 2.43896
Value Function Loss: 0.01720

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.10025
Policy Update Magnitude: 0.49773
Value Function Update Magnitude: 0.62578

Collected Steps per Second: 23,176.88396
Overall Steps per Second: 10,876.05151

Timestep Collection Time: 2.15767
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.59799

Cumulative Model Updates: 303,686
Cumulative Timesteps: 2,532,648,428

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2532648428...
Checkpoint 2532648428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.35851
Policy Entropy: 2.43986
Value Function Loss: 0.01679

Mean KL Divergence: 0.01398
SB3 Clip Fraction: 0.10295
Policy Update Magnitude: 0.48926
Value Function Update Magnitude: 0.64037

Collected Steps per Second: 22,754.80764
Overall Steps per Second: 10,757.76395

Timestep Collection Time: 2.19795
Timestep Consumption Time: 2.45115
PPO Batch Consumption Time: 0.28350
Total Iteration Time: 4.64911

Cumulative Model Updates: 303,692
Cumulative Timesteps: 2,532,698,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.05291
Policy Entropy: 2.44883
Value Function Loss: 0.01819

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.48644
Value Function Update Magnitude: 0.64523

Collected Steps per Second: 23,244.60154
Overall Steps per Second: 10,901.63805

Timestep Collection Time: 2.15293
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.59050

Cumulative Model Updates: 303,698
Cumulative Timesteps: 2,532,748,486

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 2532748486...
Checkpoint 2532748486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270.73648
Policy Entropy: 2.44174
Value Function Loss: 0.01834

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.09851
Policy Update Magnitude: 0.49806
Value Function Update Magnitude: 0.62719

Collected Steps per Second: 22,017.26790
Overall Steps per Second: 10,673.39872

Timestep Collection Time: 2.27167
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.68604

Cumulative Model Updates: 303,704
Cumulative Timesteps: 2,532,798,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418.24204
Policy Entropy: 2.46076
Value Function Loss: 0.01856

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.09385
Policy Update Magnitude: 0.49527
Value Function Update Magnitude: 0.63497

Collected Steps per Second: 22,842.44877
Overall Steps per Second: 10,818.91657

Timestep Collection Time: 2.18926
Timestep Consumption Time: 2.43302
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.62227

Cumulative Model Updates: 303,710
Cumulative Timesteps: 2,532,848,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2532848510...
Checkpoint 2532848510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268.54476
Policy Entropy: 2.46265
Value Function Loss: 0.01730

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.09166
Policy Update Magnitude: 0.49821
Value Function Update Magnitude: 0.63815

Collected Steps per Second: 22,535.69263
Overall Steps per Second: 10,703.65418

Timestep Collection Time: 2.21906
Timestep Consumption Time: 2.45299
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.67205

Cumulative Model Updates: 303,716
Cumulative Timesteps: 2,532,898,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286.62401
Policy Entropy: 2.47482
Value Function Loss: 0.01705

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.09224
Policy Update Magnitude: 0.49390
Value Function Update Magnitude: 0.60243

Collected Steps per Second: 22,896.17737
Overall Steps per Second: 10,912.34529

Timestep Collection Time: 2.18438
Timestep Consumption Time: 2.39887
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.58325

Cumulative Model Updates: 303,722
Cumulative Timesteps: 2,532,948,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2532948532...
Checkpoint 2532948532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.58742
Policy Entropy: 2.47015
Value Function Loss: 0.01693

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.09863
Policy Update Magnitude: 0.49086
Value Function Update Magnitude: 0.59557

Collected Steps per Second: 22,924.92570
Overall Steps per Second: 10,653.69121

Timestep Collection Time: 2.18304
Timestep Consumption Time: 2.51449
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.69753

Cumulative Model Updates: 303,728
Cumulative Timesteps: 2,532,998,578

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320.03747
Policy Entropy: 2.47354
Value Function Loss: 0.01748

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 0.50012
Value Function Update Magnitude: 0.60354

Collected Steps per Second: 23,217.92684
Overall Steps per Second: 10,864.96115

Timestep Collection Time: 2.15377
Timestep Consumption Time: 2.44873
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.60250

Cumulative Model Updates: 303,734
Cumulative Timesteps: 2,533,048,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2533048584...
Checkpoint 2533048584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.12392
Policy Entropy: 2.47006
Value Function Loss: 0.01778

Mean KL Divergence: 0.02243
SB3 Clip Fraction: 0.13381
Policy Update Magnitude: 0.47303
Value Function Update Magnitude: 0.61466

Collected Steps per Second: 22,742.00114
Overall Steps per Second: 10,658.38078

Timestep Collection Time: 2.19937
Timestep Consumption Time: 2.49347
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.69283

Cumulative Model Updates: 303,740
Cumulative Timesteps: 2,533,098,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318.84162
Policy Entropy: 2.46677
Value Function Loss: 0.01912

Mean KL Divergence: 0.02748
SB3 Clip Fraction: 0.15129
Policy Update Magnitude: 0.47235
Value Function Update Magnitude: 0.63116

Collected Steps per Second: 24,112.55289
Overall Steps per Second: 10,933.68387

Timestep Collection Time: 2.07394
Timestep Consumption Time: 2.49982
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.57376

Cumulative Model Updates: 303,746
Cumulative Timesteps: 2,533,148,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2533148610...
Checkpoint 2533148610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.80332
Policy Entropy: 2.44830
Value Function Loss: 0.01879

Mean KL Divergence: 0.02482
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.48351
Value Function Update Magnitude: 0.63323

Collected Steps per Second: 23,087.66813
Overall Steps per Second: 10,751.23803

Timestep Collection Time: 2.16600
Timestep Consumption Time: 2.48537
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.65137

Cumulative Model Updates: 303,752
Cumulative Timesteps: 2,533,198,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301.26527
Policy Entropy: 2.44508
Value Function Loss: 0.01859

Mean KL Divergence: 0.03247
SB3 Clip Fraction: 0.16082
Policy Update Magnitude: 0.46273
Value Function Update Magnitude: 0.61037

Collected Steps per Second: 23,000.85916
Overall Steps per Second: 10,802.82632

Timestep Collection Time: 2.17409
Timestep Consumption Time: 2.45488
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.62897

Cumulative Model Updates: 303,758
Cumulative Timesteps: 2,533,248,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2533248624...
Checkpoint 2533248624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274.52241
Policy Entropy: 2.43695
Value Function Loss: 0.01825

Mean KL Divergence: 0.03095
SB3 Clip Fraction: 0.15861
Policy Update Magnitude: 0.48264
Value Function Update Magnitude: 0.60955

Collected Steps per Second: 22,081.42139
Overall Steps per Second: 10,695.47507

Timestep Collection Time: 2.26534
Timestep Consumption Time: 2.41159
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.67693

Cumulative Model Updates: 303,764
Cumulative Timesteps: 2,533,298,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 326.92294
Policy Entropy: 2.45156
Value Function Loss: 0.01927

Mean KL Divergence: 0.02646
SB3 Clip Fraction: 0.15670
Policy Update Magnitude: 0.50591
Value Function Update Magnitude: 0.64622

Collected Steps per Second: 23,424.97785
Overall Steps per Second: 10,871.73558

Timestep Collection Time: 2.13584
Timestep Consumption Time: 2.46619
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.60203

Cumulative Model Updates: 303,770
Cumulative Timesteps: 2,533,348,678

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2533348678...
Checkpoint 2533348678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.24121
Policy Entropy: 2.45612
Value Function Loss: 0.01914

Mean KL Divergence: 0.02586
SB3 Clip Fraction: 0.15289
Policy Update Magnitude: 0.49924
Value Function Update Magnitude: 0.66552

Collected Steps per Second: 22,670.38624
Overall Steps per Second: 10,627.86605

Timestep Collection Time: 2.20667
Timestep Consumption Time: 2.50039
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.70706

Cumulative Model Updates: 303,776
Cumulative Timesteps: 2,533,398,704

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290.89595
Policy Entropy: 2.46552
Value Function Loss: 0.01902

Mean KL Divergence: 0.02033
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.50233
Value Function Update Magnitude: 0.68171

Collected Steps per Second: 23,065.49046
Overall Steps per Second: 10,963.57296

Timestep Collection Time: 2.16869
Timestep Consumption Time: 2.39387
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.56256

Cumulative Model Updates: 303,782
Cumulative Timesteps: 2,533,448,726

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2533448726...
Checkpoint 2533448726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301.14994
Policy Entropy: 2.47109
Value Function Loss: 0.01888

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.11834
Policy Update Magnitude: 0.50783
Value Function Update Magnitude: 0.70439

Collected Steps per Second: 23,328.05611
Overall Steps per Second: 11,093.50456

Timestep Collection Time: 2.14437
Timestep Consumption Time: 2.36493
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.50931

Cumulative Model Updates: 303,788
Cumulative Timesteps: 2,533,498,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 313.57177
Policy Entropy: 2.48077
Value Function Loss: 0.01791

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.10858
Policy Update Magnitude: 0.50103
Value Function Update Magnitude: 0.70683

Collected Steps per Second: 23,683.77983
Overall Steps per Second: 10,882.56762

Timestep Collection Time: 2.11225
Timestep Consumption Time: 2.48465
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.59689

Cumulative Model Updates: 303,794
Cumulative Timesteps: 2,533,548,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2533548776...
Checkpoint 2533548776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.14333
Policy Entropy: 2.47695
Value Function Loss: 0.01646

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.10502
Policy Update Magnitude: 0.48861
Value Function Update Magnitude: 0.68118

Collected Steps per Second: 22,992.79039
Overall Steps per Second: 10,699.98052

Timestep Collection Time: 2.17564
Timestep Consumption Time: 2.49951
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.67515

Cumulative Model Updates: 303,800
Cumulative Timesteps: 2,533,598,800

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 287.16992
Policy Entropy: 2.50315
Value Function Loss: 0.01551

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.48440
Value Function Update Magnitude: 0.65206

Collected Steps per Second: 23,237.30359
Overall Steps per Second: 10,837.30944

Timestep Collection Time: 2.15266
Timestep Consumption Time: 2.46306
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.61572

Cumulative Model Updates: 303,806
Cumulative Timesteps: 2,533,648,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2533648822...
Checkpoint 2533648822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331.06342
Policy Entropy: 2.48793
Value Function Loss: 0.01722

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.09559
Policy Update Magnitude: 0.48880
Value Function Update Magnitude: 0.63788

Collected Steps per Second: 22,997.96112
Overall Steps per Second: 11,062.14268

Timestep Collection Time: 2.17428
Timestep Consumption Time: 2.34600
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.52028

Cumulative Model Updates: 303,812
Cumulative Timesteps: 2,533,698,826

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.15294
Policy Entropy: 2.48599
Value Function Loss: 0.01750

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.10279
Policy Update Magnitude: 0.49212
Value Function Update Magnitude: 0.63977

Collected Steps per Second: 23,307.20921
Overall Steps per Second: 10,925.80600

Timestep Collection Time: 2.14620
Timestep Consumption Time: 2.43213
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.57834

Cumulative Model Updates: 303,818
Cumulative Timesteps: 2,533,748,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2533748848...
Checkpoint 2533748848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.45986
Policy Entropy: 2.45448
Value Function Loss: 0.01770

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.11957
Policy Update Magnitude: 0.48199
Value Function Update Magnitude: 0.63261

Collected Steps per Second: 22,572.44300
Overall Steps per Second: 10,648.14486

Timestep Collection Time: 2.21704
Timestep Consumption Time: 2.48275
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.69979

Cumulative Model Updates: 303,824
Cumulative Timesteps: 2,533,798,892

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.39874
Policy Entropy: 2.45830
Value Function Loss: 0.01700

Mean KL Divergence: 0.01637
SB3 Clip Fraction: 0.11452
Policy Update Magnitude: 0.48397
Value Function Update Magnitude: 0.61616

Collected Steps per Second: 22,466.50373
Overall Steps per Second: 10,937.24941

Timestep Collection Time: 2.22625
Timestep Consumption Time: 2.34675
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.57300

Cumulative Model Updates: 303,830
Cumulative Timesteps: 2,533,848,908

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2533848908...
Checkpoint 2533848908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.83246
Policy Entropy: 2.42719
Value Function Loss: 0.01952

Mean KL Divergence: 0.01608
SB3 Clip Fraction: 0.11516
Policy Update Magnitude: 0.51210
Value Function Update Magnitude: 0.63077

Collected Steps per Second: 22,088.21208
Overall Steps per Second: 10,667.90526

Timestep Collection Time: 2.26474
Timestep Consumption Time: 2.42447
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.68921

Cumulative Model Updates: 303,836
Cumulative Timesteps: 2,533,898,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.73283
Policy Entropy: 2.43361
Value Function Loss: 0.01907

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.10958
Policy Update Magnitude: 0.52228
Value Function Update Magnitude: 0.64239

Collected Steps per Second: 23,043.66283
Overall Steps per Second: 10,853.64540

Timestep Collection Time: 2.17023
Timestep Consumption Time: 2.43744
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.60767

Cumulative Model Updates: 303,842
Cumulative Timesteps: 2,533,948,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2533948942...
Checkpoint 2533948942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315.04151
Policy Entropy: 2.42004
Value Function Loss: 0.01936

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.10818
Policy Update Magnitude: 0.51087
Value Function Update Magnitude: 0.63185

Collected Steps per Second: 22,955.32879
Overall Steps per Second: 10,857.00026

Timestep Collection Time: 2.17919
Timestep Consumption Time: 2.42835
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.60753

Cumulative Model Updates: 303,848
Cumulative Timesteps: 2,533,998,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289.07847
Policy Entropy: 2.44294
Value Function Loss: 0.01837

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.10377
Policy Update Magnitude: 0.51045
Value Function Update Magnitude: 0.64049

Collected Steps per Second: 23,426.47551
Overall Steps per Second: 10,830.00419

Timestep Collection Time: 2.13459
Timestep Consumption Time: 2.48276
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.61736

Cumulative Model Updates: 303,854
Cumulative Timesteps: 2,534,048,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2534048972...
Checkpoint 2534048972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.91943
Policy Entropy: 2.43658
Value Function Loss: 0.01915

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.11224
Policy Update Magnitude: 0.49958
Value Function Update Magnitude: 0.66118

Collected Steps per Second: 23,118.40603
Overall Steps per Second: 10,927.05004

Timestep Collection Time: 2.16304
Timestep Consumption Time: 2.41331
PPO Batch Consumption Time: 0.27934
Total Iteration Time: 4.57635

Cumulative Model Updates: 303,860
Cumulative Timesteps: 2,534,098,978

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.32290
Policy Entropy: 2.41965
Value Function Loss: 0.01851

Mean KL Divergence: 0.01738
SB3 Clip Fraction: 0.11210
Policy Update Magnitude: 0.50183
Value Function Update Magnitude: 0.66470

Collected Steps per Second: 23,448.53930
Overall Steps per Second: 11,013.85708

Timestep Collection Time: 2.13463
Timestep Consumption Time: 2.41001
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.54464

Cumulative Model Updates: 303,866
Cumulative Timesteps: 2,534,149,032

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 2534149032...
Checkpoint 2534149032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 360.81629
Policy Entropy: 2.41205
Value Function Loss: 0.01883

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.10802
Policy Update Magnitude: 0.50433
Value Function Update Magnitude: 0.65635

Collected Steps per Second: 23,115.52727
Overall Steps per Second: 11,112.92701

Timestep Collection Time: 2.16417
Timestep Consumption Time: 2.33743
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.50160

Cumulative Model Updates: 303,872
Cumulative Timesteps: 2,534,199,058

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.85756
Policy Entropy: 2.41689
Value Function Loss: 0.01834

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.49186
Value Function Update Magnitude: 0.65355

Collected Steps per Second: 22,806.65771
Overall Steps per Second: 10,819.10504

Timestep Collection Time: 2.19348
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.62386

Cumulative Model Updates: 303,878
Cumulative Timesteps: 2,534,249,084

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2534249084...
Checkpoint 2534249084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394.37042
Policy Entropy: 2.46687
Value Function Loss: 0.01688

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.09976
Policy Update Magnitude: 0.48710
Value Function Update Magnitude: 0.65008

Collected Steps per Second: 22,294.38590
Overall Steps per Second: 10,746.07460

Timestep Collection Time: 2.24397
Timestep Consumption Time: 2.41149
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.65547

Cumulative Model Updates: 303,884
Cumulative Timesteps: 2,534,299,112

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.49129
Policy Entropy: 2.46515
Value Function Loss: 0.01700

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.10246
Policy Update Magnitude: 0.49385
Value Function Update Magnitude: 0.63954

Collected Steps per Second: 22,364.95565
Overall Steps per Second: 10,749.29924

Timestep Collection Time: 2.23609
Timestep Consumption Time: 2.41631
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.65240

Cumulative Model Updates: 303,890
Cumulative Timesteps: 2,534,349,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2534349122...
Checkpoint 2534349122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332.83905
Policy Entropy: 2.47797
Value Function Loss: 0.01721

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.10346
Policy Update Magnitude: 0.49386
Value Function Update Magnitude: 0.64665

Collected Steps per Second: 22,953.30155
Overall Steps per Second: 10,748.89684

Timestep Collection Time: 2.17895
Timestep Consumption Time: 2.47400
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.65294

Cumulative Model Updates: 303,896
Cumulative Timesteps: 2,534,399,136

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 310.36981
Policy Entropy: 2.44189
Value Function Loss: 0.01802

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.10253
Policy Update Magnitude: 0.48363
Value Function Update Magnitude: 0.65510

Collected Steps per Second: 23,204.94507
Overall Steps per Second: 10,870.79043

Timestep Collection Time: 2.15575
Timestep Consumption Time: 2.44594
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.60169

Cumulative Model Updates: 303,902
Cumulative Timesteps: 2,534,449,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2534449160...
Checkpoint 2534449160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.32017
Policy Entropy: 2.44456
Value Function Loss: 0.01872

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.09861
Policy Update Magnitude: 0.48737
Value Function Update Magnitude: 0.64851

Collected Steps per Second: 22,962.46983
Overall Steps per Second: 10,686.68191

Timestep Collection Time: 2.17851
Timestep Consumption Time: 2.50246
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.68097

Cumulative Model Updates: 303,908
Cumulative Timesteps: 2,534,499,184

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 312.74552
Policy Entropy: 2.45058
Value Function Loss: 0.01905

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.08699
Policy Update Magnitude: 0.48845
Value Function Update Magnitude: 0.64157

Collected Steps per Second: 23,218.15280
Overall Steps per Second: 10,879.34710

Timestep Collection Time: 2.15366
Timestep Consumption Time: 2.44257
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.59623

Cumulative Model Updates: 303,914
Cumulative Timesteps: 2,534,549,188

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2534549188...
Checkpoint 2534549188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.92115
Policy Entropy: 2.45339
Value Function Loss: 0.01836

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.10107
Policy Update Magnitude: 0.48341
Value Function Update Magnitude: 0.63741

Collected Steps per Second: 23,119.75921
Overall Steps per Second: 11,053.67940

Timestep Collection Time: 2.16291
Timestep Consumption Time: 2.36101
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.52392

Cumulative Model Updates: 303,920
Cumulative Timesteps: 2,534,599,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.82837
Policy Entropy: 2.44599
Value Function Loss: 0.01720

Mean KL Divergence: 0.01679
SB3 Clip Fraction: 0.11716
Policy Update Magnitude: 0.46656
Value Function Update Magnitude: 0.63013

Collected Steps per Second: 23,209.04302
Overall Steps per Second: 10,926.48816

Timestep Collection Time: 2.15494
Timestep Consumption Time: 2.42238
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.57732

Cumulative Model Updates: 303,926
Cumulative Timesteps: 2,534,649,208

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2534649208...
Checkpoint 2534649208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.13874
Policy Entropy: 2.43430
Value Function Loss: 0.01751

Mean KL Divergence: 0.01583
SB3 Clip Fraction: 0.10589
Policy Update Magnitude: 0.47748
Value Function Update Magnitude: 0.63146

Collected Steps per Second: 22,246.07074
Overall Steps per Second: 10,693.51078

Timestep Collection Time: 2.24948
Timestep Consumption Time: 2.43018
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.67966

Cumulative Model Updates: 303,932
Cumulative Timesteps: 2,534,699,250

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 259.33847
Policy Entropy: 2.43853
Value Function Loss: 0.01765

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.10213
Policy Update Magnitude: 0.50755
Value Function Update Magnitude: 0.64042

Collected Steps per Second: 23,078.76991
Overall Steps per Second: 10,961.00017

Timestep Collection Time: 2.16753
Timestep Consumption Time: 2.39628
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.56382

Cumulative Model Updates: 303,938
Cumulative Timesteps: 2,534,749,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2534749274...
Checkpoint 2534749274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297.03830
Policy Entropy: 2.45835
Value Function Loss: 0.01732

Mean KL Divergence: 0.01467
SB3 Clip Fraction: 0.10008
Policy Update Magnitude: 0.50186
Value Function Update Magnitude: 0.64330

Collected Steps per Second: 23,085.42350
Overall Steps per Second: 10,775.63844

Timestep Collection Time: 2.16596
Timestep Consumption Time: 2.47433
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.64028

Cumulative Model Updates: 303,944
Cumulative Timesteps: 2,534,799,276

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.88170
Policy Entropy: 2.45777
Value Function Loss: 0.01765

Mean KL Divergence: 0.01615
SB3 Clip Fraction: 0.11193
Policy Update Magnitude: 0.50040
Value Function Update Magnitude: 0.64782

Collected Steps per Second: 23,058.09680
Overall Steps per Second: 10,706.39238

Timestep Collection Time: 2.16870
Timestep Consumption Time: 2.50197
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.67067

Cumulative Model Updates: 303,950
Cumulative Timesteps: 2,534,849,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2534849282...
Checkpoint 2534849282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.87125
Policy Entropy: 2.45379
Value Function Loss: 0.01747

Mean KL Divergence: 0.01849
SB3 Clip Fraction: 0.12266
Policy Update Magnitude: 0.48916
Value Function Update Magnitude: 0.64547

Collected Steps per Second: 23,198.95656
Overall Steps per Second: 10,720.70237

Timestep Collection Time: 2.15648
Timestep Consumption Time: 2.51001
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.66649

Cumulative Model Updates: 303,956
Cumulative Timesteps: 2,534,899,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305.62435
Policy Entropy: 2.42942
Value Function Loss: 0.01817

Mean KL Divergence: 0.02205
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.48658
Value Function Update Magnitude: 0.66221

Collected Steps per Second: 23,355.12778
Overall Steps per Second: 10,981.77176

Timestep Collection Time: 2.14266
Timestep Consumption Time: 2.41417
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.55682

Cumulative Model Updates: 303,962
Cumulative Timesteps: 2,534,949,352

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 2534949352...
Checkpoint 2534949352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.66921
Policy Entropy: 2.45298
Value Function Loss: 0.01724

Mean KL Divergence: 0.02571
SB3 Clip Fraction: 0.14751
Policy Update Magnitude: 0.48599
Value Function Update Magnitude: 0.65647

Collected Steps per Second: 23,393.11011
Overall Steps per Second: 10,941.98343

Timestep Collection Time: 2.13858
Timestep Consumption Time: 2.43354
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.57211

Cumulative Model Updates: 303,968
Cumulative Timesteps: 2,534,999,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250.41843
Policy Entropy: 2.47168
Value Function Loss: 0.01780

Mean KL Divergence: 0.02593
SB3 Clip Fraction: 0.14343
Policy Update Magnitude: 0.51014
Value Function Update Magnitude: 0.66393

Collected Steps per Second: 23,137.69603
Overall Steps per Second: 10,901.52124

Timestep Collection Time: 2.16175
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.58817

Cumulative Model Updates: 303,974
Cumulative Timesteps: 2,535,049,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2535049398...
Checkpoint 2535049398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.30309
Policy Entropy: 2.48437
Value Function Loss: 0.01682

Mean KL Divergence: 0.01946
SB3 Clip Fraction: 0.12152
Policy Update Magnitude: 0.51565
Value Function Update Magnitude: 0.66713

Collected Steps per Second: 22,675.32688
Overall Steps per Second: 10,672.10201

Timestep Collection Time: 2.20627
Timestep Consumption Time: 2.48146
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.68774

Cumulative Model Updates: 303,980
Cumulative Timesteps: 2,535,099,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315.48411
Policy Entropy: 2.48130
Value Function Loss: 0.01748

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.11091
Policy Update Magnitude: 0.50333
Value Function Update Magnitude: 0.67755

Collected Steps per Second: 24,243.56415
Overall Steps per Second: 10,982.11081

Timestep Collection Time: 2.06290
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.55395

Cumulative Model Updates: 303,986
Cumulative Timesteps: 2,535,149,438

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2535149438...
Checkpoint 2535149438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343.17162
Policy Entropy: 2.46524
Value Function Loss: 0.01669

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.10161
Policy Update Magnitude: 0.49726
Value Function Update Magnitude: 0.67698

Collected Steps per Second: 22,609.37073
Overall Steps per Second: 10,636.41538

Timestep Collection Time: 2.21218
Timestep Consumption Time: 2.49016
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.70234

Cumulative Model Updates: 303,992
Cumulative Timesteps: 2,535,199,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335.45972
Policy Entropy: 2.45722
Value Function Loss: 0.01740

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.09221
Policy Update Magnitude: 0.49757
Value Function Update Magnitude: 0.65199

Collected Steps per Second: 23,237.91205
Overall Steps per Second: 10,883.52892

Timestep Collection Time: 2.15295
Timestep Consumption Time: 2.44391
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.59685

Cumulative Model Updates: 303,998
Cumulative Timesteps: 2,535,249,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2535249484...
Checkpoint 2535249484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308.41943
Policy Entropy: 2.45352
Value Function Loss: 0.01841

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.50023
Value Function Update Magnitude: 0.65619

Collected Steps per Second: 22,246.67008
Overall Steps per Second: 10,741.32691

Timestep Collection Time: 2.24960
Timestep Consumption Time: 2.40961
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.65920

Cumulative Model Updates: 304,004
Cumulative Timesteps: 2,535,299,530

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 294.59781
Policy Entropy: 2.43702
Value Function Loss: 0.01904

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.10388
Policy Update Magnitude: 0.50030
Value Function Update Magnitude: 0.66099

Collected Steps per Second: 23,214.27767
Overall Steps per Second: 10,793.25945

Timestep Collection Time: 2.15385
Timestep Consumption Time: 2.47867
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.63252

Cumulative Model Updates: 304,010
Cumulative Timesteps: 2,535,349,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2535349530...
Checkpoint 2535349530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.66760
Policy Entropy: 2.44008
Value Function Loss: 0.01942

Mean KL Divergence: 0.01462
SB3 Clip Fraction: 0.10199
Policy Update Magnitude: 0.50565
Value Function Update Magnitude: 0.67071

Collected Steps per Second: 23,248.97365
Overall Steps per Second: 10,666.46012

Timestep Collection Time: 2.15141
Timestep Consumption Time: 2.53787
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.68928

Cumulative Model Updates: 304,016
Cumulative Timesteps: 2,535,399,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 331.58530
Policy Entropy: 2.44235
Value Function Loss: 0.01843

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.10674
Policy Update Magnitude: 0.49760
Value Function Update Magnitude: 0.65906

Collected Steps per Second: 23,436.73730
Overall Steps per Second: 10,986.08079

Timestep Collection Time: 2.13468
Timestep Consumption Time: 2.41926
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.55394

Cumulative Model Updates: 304,022
Cumulative Timesteps: 2,535,449,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2535449578...
Checkpoint 2535449578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327.69742
Policy Entropy: 2.45657
Value Function Loss: 0.01831

Mean KL Divergence: 0.01713
SB3 Clip Fraction: 0.11679
Policy Update Magnitude: 0.50689
Value Function Update Magnitude: 0.65534

Collected Steps per Second: 23,143.55308
Overall Steps per Second: 10,943.43558

Timestep Collection Time: 2.16164
Timestep Consumption Time: 2.40987
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.57151

Cumulative Model Updates: 304,028
Cumulative Timesteps: 2,535,499,606

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345.59566
Policy Entropy: 2.47153
Value Function Loss: 0.01734

Mean KL Divergence: 0.01627
SB3 Clip Fraction: 0.11228
Policy Update Magnitude: 0.51087
Value Function Update Magnitude: 0.65237

Collected Steps per Second: 23,401.57616
Overall Steps per Second: 10,940.25927

Timestep Collection Time: 2.13738
Timestep Consumption Time: 2.43454
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.57192

Cumulative Model Updates: 304,034
Cumulative Timesteps: 2,535,549,624

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2535549624...
Checkpoint 2535549624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 313.63753
Policy Entropy: 2.44616
Value Function Loss: 0.01789

Mean KL Divergence: 0.01682
SB3 Clip Fraction: 0.11334
Policy Update Magnitude: 0.50576
Value Function Update Magnitude: 0.63897

Collected Steps per Second: 22,965.53462
Overall Steps per Second: 10,801.89097

Timestep Collection Time: 2.17805
Timestep Consumption Time: 2.45262
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.63067

Cumulative Model Updates: 304,040
Cumulative Timesteps: 2,535,599,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334.78187
Policy Entropy: 2.45436
Value Function Loss: 0.01747

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.10786
Policy Update Magnitude: 0.49660
Value Function Update Magnitude: 0.62622

Collected Steps per Second: 23,082.12410
Overall Steps per Second: 10,949.99518

Timestep Collection Time: 2.16644
Timestep Consumption Time: 2.40032
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.56676

Cumulative Model Updates: 304,046
Cumulative Timesteps: 2,535,649,650

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2535649650...
Checkpoint 2535649650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 298.85018
Policy Entropy: 2.44225
Value Function Loss: 0.01756

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.49390
Value Function Update Magnitude: 0.62675

Collected Steps per Second: 22,239.82644
Overall Steps per Second: 10,514.29781

Timestep Collection Time: 2.24921
Timestep Consumption Time: 2.50831
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.75752

Cumulative Model Updates: 304,052
Cumulative Timesteps: 2,535,699,672

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269.15293
Policy Entropy: 2.42630
Value Function Loss: 0.01845

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.09634
Policy Update Magnitude: 0.50976
Value Function Update Magnitude: 0.62704

Collected Steps per Second: 22,887.12871
Overall Steps per Second: 10,833.86996

Timestep Collection Time: 2.18594
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61793

Cumulative Model Updates: 304,058
Cumulative Timesteps: 2,535,749,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2535749702...
Checkpoint 2535749702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 325.42314
Policy Entropy: 2.41484
Value Function Loss: 0.01783

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.09626
Policy Update Magnitude: 0.51807
Value Function Update Magnitude: 0.62229

Collected Steps per Second: 22,612.52675
Overall Steps per Second: 10,641.94092

Timestep Collection Time: 2.21178
Timestep Consumption Time: 2.48792
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.69971

Cumulative Model Updates: 304,064
Cumulative Timesteps: 2,535,799,716

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292.70409
Policy Entropy: 2.41140
Value Function Loss: 0.01818

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.09597
Policy Update Magnitude: 0.51327
Value Function Update Magnitude: 0.62928

Collected Steps per Second: 22,606.50111
Overall Steps per Second: 10,969.22570

Timestep Collection Time: 2.21308
Timestep Consumption Time: 2.34786
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.56094

Cumulative Model Updates: 304,070
Cumulative Timesteps: 2,535,849,746

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2535849746...
Checkpoint 2535849746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328.56338
Policy Entropy: 2.42170
Value Function Loss: 0.01768

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.09690
Policy Update Magnitude: 0.50091
Value Function Update Magnitude: 0.63426

Collected Steps per Second: 23,216.58577
Overall Steps per Second: 10,715.85282

Timestep Collection Time: 2.15406
Timestep Consumption Time: 2.51285
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.66692

Cumulative Model Updates: 304,076
Cumulative Timesteps: 2,535,899,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.11620
Policy Entropy: 2.40816
Value Function Loss: 0.01850

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.09476
Policy Update Magnitude: 0.49805
Value Function Update Magnitude: 0.63382

Collected Steps per Second: 23,537.16133
Overall Steps per Second: 10,786.09417

Timestep Collection Time: 2.12566
Timestep Consumption Time: 2.51291
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.63857

Cumulative Model Updates: 304,082
Cumulative Timesteps: 2,535,949,788

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 2535949788...
Checkpoint 2535949788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.66895
Policy Entropy: 2.40797
Value Function Loss: 0.01830

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.10018
Policy Update Magnitude: 0.49740
Value Function Update Magnitude: 0.62765

Collected Steps per Second: 23,102.83557
Overall Steps per Second: 11,077.03299

Timestep Collection Time: 2.16424
Timestep Consumption Time: 2.34961
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.51384

Cumulative Model Updates: 304,088
Cumulative Timesteps: 2,535,999,788

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.15922
Policy Entropy: 2.43480
Value Function Loss: 0.01765

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.10373
Policy Update Magnitude: 0.50346
Value Function Update Magnitude: 0.61935

Collected Steps per Second: 23,322.87972
Overall Steps per Second: 10,964.37313

Timestep Collection Time: 2.14545
Timestep Consumption Time: 2.41824
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.56369

Cumulative Model Updates: 304,094
Cumulative Timesteps: 2,536,049,826

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2536049826...
Checkpoint 2536049826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287.73737
Policy Entropy: 2.44242
Value Function Loss: 0.01773

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.09679
Policy Update Magnitude: 0.50353
Value Function Update Magnitude: 0.64955

Collected Steps per Second: 22,794.05331
Overall Steps per Second: 10,647.37351

Timestep Collection Time: 2.19443
Timestep Consumption Time: 2.50344
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.69787

Cumulative Model Updates: 304,100
Cumulative Timesteps: 2,536,099,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 267.90897
Policy Entropy: 2.44649
Value Function Loss: 0.01733

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.09819
Policy Update Magnitude: 0.50323
Value Function Update Magnitude: 0.64356

Collected Steps per Second: 23,475.46539
Overall Steps per Second: 10,875.68771

Timestep Collection Time: 2.13039
Timestep Consumption Time: 2.46812
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.59851

Cumulative Model Updates: 304,106
Cumulative Timesteps: 2,536,149,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 2536149858...
Checkpoint 2536149858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.89130
Policy Entropy: 2.43312
Value Function Loss: 0.01785

Mean KL Divergence: 0.02098
SB3 Clip Fraction: 0.10588
Policy Update Magnitude: 0.49704
Value Function Update Magnitude: 0.61746

Collected Steps per Second: 22,431.45454
Overall Steps per Second: 10,782.01643

Timestep Collection Time: 2.23044
Timestep Consumption Time: 2.40988
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.64032

Cumulative Model Updates: 304,112
Cumulative Timesteps: 2,536,199,890

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.84427
Policy Entropy: 2.44675
Value Function Loss: 0.01689

Mean KL Divergence: 0.01646
SB3 Clip Fraction: 0.09241
Policy Update Magnitude: 0.50043
Value Function Update Magnitude: 0.59873

Collected Steps per Second: 22,795.69579
Overall Steps per Second: 10,779.31652

Timestep Collection Time: 2.19357
Timestep Consumption Time: 2.44531
PPO Batch Consumption Time: 0.28300
Total Iteration Time: 4.63888

Cumulative Model Updates: 304,118
Cumulative Timesteps: 2,536,249,894

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 2536249894...
Checkpoint 2536249894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 357.12421
Policy Entropy: 2.45099
Value Function Loss: 0.01621

Mean KL Divergence: 0.01395
SB3 Clip Fraction: 0.09005
Policy Update Magnitude: 0.49401
Value Function Update Magnitude: 0.58894

Collected Steps per Second: 22,337.92706
Overall Steps per Second: 10,614.95133

Timestep Collection Time: 2.23844
Timestep Consumption Time: 2.47209
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.71053

Cumulative Model Updates: 304,124
Cumulative Timesteps: 2,536,299,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 220.63631
Policy Entropy: 2.42831
Value Function Loss: 0.01680

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.09295
Policy Update Magnitude: 0.49860
Value Function Update Magnitude: 0.58845

Collected Steps per Second: 23,043.95530
Overall Steps per Second: 10,902.07037

Timestep Collection Time: 2.17072
Timestep Consumption Time: 2.41758
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.58830

Cumulative Model Updates: 304,130
Cumulative Timesteps: 2,536,349,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 2536349918...
Checkpoint 2536349918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345.17714
Policy Entropy: 2.42831
Value Function Loss: 0.01726

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.10229
Policy Update Magnitude: 0.49757
Value Function Update Magnitude: 0.60915

Collected Steps per Second: 23,317.12252
Overall Steps per Second: 10,709.43507

Timestep Collection Time: 2.14443
Timestep Consumption Time: 2.52453
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.66897

Cumulative Model Updates: 304,136
Cumulative Timesteps: 2,536,399,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 358.16372
Policy Entropy: 2.42639
Value Function Loss: 0.01751

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.50388
Value Function Update Magnitude: 0.60257

Collected Steps per Second: 23,323.66463
Overall Steps per Second: 10,822.02580

Timestep Collection Time: 2.14520
Timestep Consumption Time: 2.47815
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.62335

Cumulative Model Updates: 304,142
Cumulative Timesteps: 2,536,449,954

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2536449954...
Checkpoint 2536449954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 320.56109
Policy Entropy: 2.44792
Value Function Loss: 0.01708

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.10074
Policy Update Magnitude: 0.50815
Value Function Update Magnitude: 0.60822

Collected Steps per Second: 18,666.49961
Overall Steps per Second: 9,414.40428

Timestep Collection Time: 2.67860
Timestep Consumption Time: 2.63242
PPO Batch Consumption Time: 0.30980
Total Iteration Time: 5.31101

Cumulative Model Updates: 304,148
Cumulative Timesteps: 2,536,499,954

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253.65692
Policy Entropy: 2.45030
Value Function Loss: 0.01758

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.10504
Policy Update Magnitude: 0.50860
Value Function Update Magnitude: 0.63256

Collected Steps per Second: 11,411.13836
Overall Steps per Second: 7,148.71913

Timestep Collection Time: 4.38326
Timestep Consumption Time: 2.61352
PPO Batch Consumption Time: 0.30405
Total Iteration Time: 6.99678

Cumulative Model Updates: 304,154
Cumulative Timesteps: 2,536,549,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2536549972...
Checkpoint 2536549972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 271.13233
Policy Entropy: 2.45658
Value Function Loss: 0.01667

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.10001
Policy Update Magnitude: 0.50359
Value Function Update Magnitude: 0.66515

Collected Steps per Second: 21,725.86331
Overall Steps per Second: 10,289.21098

Timestep Collection Time: 2.30186
Timestep Consumption Time: 2.55857
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.86043

Cumulative Model Updates: 304,160
Cumulative Timesteps: 2,536,599,982

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364.19239
Policy Entropy: 2.45067
Value Function Loss: 0.01664

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.09890
Policy Update Magnitude: 0.49718
Value Function Update Magnitude: 0.64914

Collected Steps per Second: 22,730.99469
Overall Steps per Second: 10,526.16030

Timestep Collection Time: 2.20070
Timestep Consumption Time: 2.55165
PPO Batch Consumption Time: 0.29682
Total Iteration Time: 4.75235

Cumulative Model Updates: 304,166
Cumulative Timesteps: 2,536,650,006

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2536650006...
Checkpoint 2536650006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300.25302
Policy Entropy: 2.46518
Value Function Loss: 0.01628

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.10402
Policy Update Magnitude: 0.49447
Value Function Update Magnitude: 0.62031

Collected Steps per Second: 22,627.03760
Overall Steps per Second: 10,586.39235

Timestep Collection Time: 2.21098
Timestep Consumption Time: 2.51471
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.72569

Cumulative Model Updates: 304,172
Cumulative Timesteps: 2,536,700,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.38088
Policy Entropy: 2.45074
Value Function Loss: 0.01682

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.10228
Policy Update Magnitude: 0.49040
Value Function Update Magnitude: 0.61459

Collected Steps per Second: 23,178.15533
Overall Steps per Second: 10,829.90045

Timestep Collection Time: 2.15789
Timestep Consumption Time: 2.46043
PPO Batch Consumption Time: 0.29745
Total Iteration Time: 4.61832

Cumulative Model Updates: 304,178
Cumulative Timesteps: 2,536,750,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 2536750050...
Checkpoint 2536750050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283.01795
Policy Entropy: 2.46244
Value Function Loss: 0.01708

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.09478
Policy Update Magnitude: 0.48775
Value Function Update Magnitude: 0.60342

Collected Steps per Second: 21,719.37577
Overall Steps per Second: 10,520.94447

Timestep Collection Time: 2.30347
Timestep Consumption Time: 2.45180
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.75528

Cumulative Model Updates: 304,184
Cumulative Timesteps: 2,536,800,080

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277.34359
Policy Entropy: 2.43377
Value Function Loss: 0.01672

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.09887
Policy Update Magnitude: 0.49075
Value Function Update Magnitude: 0.59531

Collected Steps per Second: 21,330.87384
Overall Steps per Second: 10,284.92970

Timestep Collection Time: 2.34411
Timestep Consumption Time: 2.51756
PPO Batch Consumption Time: 0.29779
Total Iteration Time: 4.86168

Cumulative Model Updates: 304,190
Cumulative Timesteps: 2,536,850,082

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2536850082...
Checkpoint 2536850082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.09413
Policy Entropy: 2.42626
Value Function Loss: 0.01726

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.10095
Policy Update Magnitude: 0.48887
Value Function Update Magnitude: 0.60912

Collected Steps per Second: 19,780.91775
Overall Steps per Second: 10,091.78654

Timestep Collection Time: 2.52789
Timestep Consumption Time: 2.42703
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.95492

Cumulative Model Updates: 304,196
Cumulative Timesteps: 2,536,900,086

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.25853
Policy Entropy: 2.41982
Value Function Loss: 0.01711

Mean KL Divergence: 0.01566
SB3 Clip Fraction: 0.10101
Policy Update Magnitude: 0.50278
Value Function Update Magnitude: 0.63831

Collected Steps per Second: 21,265.96690
Overall Steps per Second: 10,440.86417

Timestep Collection Time: 2.35249
Timestep Consumption Time: 2.43907
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.79156

Cumulative Model Updates: 304,202
Cumulative Timesteps: 2,536,950,114

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 2536950114...
Checkpoint 2536950114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293.26709
Policy Entropy: 2.41837
Value Function Loss: 0.01787

Mean KL Divergence: 0.02011
SB3 Clip Fraction: 0.10864
Policy Update Magnitude: 0.50014
Value Function Update Magnitude: 0.65265

Collected Steps per Second: 22,425.21110
Overall Steps per Second: 10,719.26592

Timestep Collection Time: 2.22972
Timestep Consumption Time: 2.43496
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.66469

Cumulative Model Updates: 304,208
Cumulative Timesteps: 2,537,000,116

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 304.17051
Policy Entropy: 2.42713
Value Function Loss: 0.01780

Mean KL Divergence: 0.02154
SB3 Clip Fraction: 0.12278
Policy Update Magnitude: 0.49857
Value Function Update Magnitude: 0.65231

Collected Steps per Second: 22,719.74384
Overall Steps per Second: 10,787.30272

Timestep Collection Time: 2.20152
Timestep Consumption Time: 2.43523
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.63675

Cumulative Model Updates: 304,214
Cumulative Timesteps: 2,537,050,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2537050134...
Checkpoint 2537050134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286.98600
Policy Entropy: 2.43791
Value Function Loss: 0.01735

Mean KL Divergence: 0.01729
SB3 Clip Fraction: 0.11652
Policy Update Magnitude: 0.50838
Value Function Update Magnitude: 0.63410

Collected Steps per Second: 22,896.34613
Overall Steps per Second: 10,685.27559

Timestep Collection Time: 2.18472
Timestep Consumption Time: 2.49668
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.68140

Cumulative Model Updates: 304,220
Cumulative Timesteps: 2,537,100,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 268.52812
Policy Entropy: 2.44008
Value Function Loss: 0.01750

Mean KL Divergence: 0.02217
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.47943
Value Function Update Magnitude: 0.62435

Collected Steps per Second: 21,559.65781
Overall Steps per Second: 10,334.82327

Timestep Collection Time: 2.31961
Timestep Consumption Time: 2.51937
PPO Batch Consumption Time: 0.30073
Total Iteration Time: 4.83898

Cumulative Model Updates: 304,226
Cumulative Timesteps: 2,537,150,166

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2537150166...
Checkpoint 2537150166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.39181
Policy Entropy: 2.42069
Value Function Loss: 0.01721

Mean KL Divergence: 0.01965
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.46750
Value Function Update Magnitude: 0.60783

Collected Steps per Second: 20,488.16677
Overall Steps per Second: 10,040.87073

Timestep Collection Time: 2.44053
Timestep Consumption Time: 2.53932
PPO Batch Consumption Time: 0.29899
Total Iteration Time: 4.97985

Cumulative Model Updates: 304,232
Cumulative Timesteps: 2,537,200,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274.39201
Policy Entropy: 2.41791
Value Function Loss: 0.01707

Mean KL Divergence: 0.02320
SB3 Clip Fraction: 0.14628
Policy Update Magnitude: 0.46153
Value Function Update Magnitude: 0.60235

Collected Steps per Second: 21,079.11284
Overall Steps per Second: 10,026.11754

Timestep Collection Time: 2.37268
Timestep Consumption Time: 2.61569
PPO Batch Consumption Time: 0.31724
Total Iteration Time: 4.98837

Cumulative Model Updates: 304,238
Cumulative Timesteps: 2,537,250,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 2537250182...
Checkpoint 2537250182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 281.88990
Policy Entropy: 2.42924
Value Function Loss: 0.01764

Mean KL Divergence: 0.02513
SB3 Clip Fraction: 0.14739
Policy Update Magnitude: 0.46850
Value Function Update Magnitude: 0.61943

Collected Steps per Second: 22,021.57455
Overall Steps per Second: 10,416.31990

Timestep Collection Time: 2.27059
Timestep Consumption Time: 2.52976
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.80035

Cumulative Model Updates: 304,244
Cumulative Timesteps: 2,537,300,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 260.54225
Policy Entropy: 2.45096
Value Function Loss: 0.01830

Mean KL Divergence: 0.03197
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.48121
Value Function Update Magnitude: 0.63558

Collected Steps per Second: 21,247.47844
Overall Steps per Second: 10,174.81614

Timestep Collection Time: 2.35350
Timestep Consumption Time: 2.56118
PPO Batch Consumption Time: 0.30232
Total Iteration Time: 4.91468

Cumulative Model Updates: 304,250
Cumulative Timesteps: 2,537,350,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 2537350190...
Checkpoint 2537350190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280.97384
Policy Entropy: 2.46061
Value Function Loss: 0.01812

Mean KL Divergence: 0.02407
SB3 Clip Fraction: 0.13999
Policy Update Magnitude: 0.50958
Value Function Update Magnitude: 0.64013

Collected Steps per Second: 20,970.08550
Overall Steps per Second: 10,010.90088

Timestep Collection Time: 2.38540
Timestep Consumption Time: 2.61136
PPO Batch Consumption Time: 0.31411
Total Iteration Time: 4.99675

Cumulative Model Updates: 304,256
Cumulative Timesteps: 2,537,400,212

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346.91097
Policy Entropy: 2.46807
Value Function Loss: 0.01829

Mean KL Divergence: 0.02210
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.51103
Value Function Update Magnitude: 0.64510

Collected Steps per Second: 21,926.55057
Overall Steps per Second: 10,450.52349

Timestep Collection Time: 2.28207
Timestep Consumption Time: 2.50601
PPO Batch Consumption Time: 0.30848
Total Iteration Time: 4.78809

Cumulative Model Updates: 304,262
Cumulative Timesteps: 2,537,450,250

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 2537450250...
Checkpoint 2537450250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290.90706
Policy Entropy: 2.46418
Value Function Loss: 0.01669

Mean KL Divergence: 0.02014
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.50188
Value Function Update Magnitude: 0.64460

Collected Steps per Second: 20,914.00453
Overall Steps per Second: 9,991.30494

Timestep Collection Time: 2.39227
Timestep Consumption Time: 2.61528
PPO Batch Consumption Time: 0.30812
Total Iteration Time: 5.00755

Cumulative Model Updates: 304,268
Cumulative Timesteps: 2,537,500,282

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 354.92179
Policy Entropy: 2.45764
Value Function Loss: 0.01695

Mean KL Divergence: 0.01733
SB3 Clip Fraction: 0.11022
Policy Update Magnitude: 0.49759
Value Function Update Magnitude: 0.63017

Collected Steps per Second: 20,551.85610
Overall Steps per Second: 10,116.00633

Timestep Collection Time: 2.43297
Timestep Consumption Time: 2.50989
PPO Batch Consumption Time: 0.29433
Total Iteration Time: 4.94286

Cumulative Model Updates: 304,274
Cumulative Timesteps: 2,537,550,284

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2537550284...
Checkpoint 2537550284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310.52167
Policy Entropy: 2.44089
Value Function Loss: 0.01740

Mean KL Divergence: 0.01657
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.50736
Value Function Update Magnitude: 0.62144

Collected Steps per Second: 20,160.04402
Overall Steps per Second: 10,157.25328

Timestep Collection Time: 2.48154
Timestep Consumption Time: 2.44381
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.92535

Cumulative Model Updates: 304,280
Cumulative Timesteps: 2,537,600,312

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323.46630
Policy Entropy: 2.44764
Value Function Loss: 0.01733

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.10785
Policy Update Magnitude: 0.50108
Value Function Update Magnitude: 0.61701

Collected Steps per Second: 22,146.18546
Overall Steps per Second: 10,455.48469

Timestep Collection Time: 2.25818
Timestep Consumption Time: 2.52496
PPO Batch Consumption Time: 0.29499
Total Iteration Time: 4.78314

Cumulative Model Updates: 304,286
Cumulative Timesteps: 2,537,650,322

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2537650322...
Checkpoint 2537650322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295.33145
Policy Entropy: 2.45196
Value Function Loss: 0.01763

Mean KL Divergence: 0.01486
SB3 Clip Fraction: 0.10143
Policy Update Magnitude: 0.50201
Value Function Update Magnitude: 0.62779

Collected Steps per Second: 22,095.51082
Overall Steps per Second: 10,613.93998

Timestep Collection Time: 2.26345
Timestep Consumption Time: 2.44847
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.71192

Cumulative Model Updates: 304,292
Cumulative Timesteps: 2,537,700,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.37630
Policy Entropy: 2.47126
Value Function Loss: 0.01711

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.09893
Policy Update Magnitude: 0.49955
Value Function Update Magnitude: 0.63331

Collected Steps per Second: 22,099.96289
Overall Steps per Second: 10,478.85516

Timestep Collection Time: 2.26408
Timestep Consumption Time: 2.51087
PPO Batch Consumption Time: 0.29413
Total Iteration Time: 4.77495

Cumulative Model Updates: 304,298
Cumulative Timesteps: 2,537,750,370

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 2537750370...
Checkpoint 2537750370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322.39005
Policy Entropy: 2.46547
Value Function Loss: 0.01754

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.10094
Policy Update Magnitude: 0.49258
Value Function Update Magnitude: 0.62374

Collected Steps per Second: 22,225.09818
Overall Steps per Second: 10,665.72869

Timestep Collection Time: 2.25007
Timestep Consumption Time: 2.43859
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.68866

Cumulative Model Updates: 304,304
Cumulative Timesteps: 2,537,800,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 405.36734
Policy Entropy: 2.46458
Value Function Loss: 0.01853

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.09809
Policy Update Magnitude: 0.49390
Value Function Update Magnitude: 0.60999

Collected Steps per Second: 23,287.84937
Overall Steps per Second: 10,950.50708

Timestep Collection Time: 2.14704
Timestep Consumption Time: 2.41896
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.56600

Cumulative Model Updates: 304,310
Cumulative Timesteps: 2,537,850,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2537850378...
Checkpoint 2537850378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 362.81380
Policy Entropy: 2.43879
Value Function Loss: 0.01871

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.10405
Policy Update Magnitude: 0.50185
Value Function Update Magnitude: 0.61403

Collected Steps per Second: 22,142.50441
Overall Steps per Second: 10,614.29179

Timestep Collection Time: 2.25927
Timestep Consumption Time: 2.45380
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.71308

Cumulative Model Updates: 304,316
Cumulative Timesteps: 2,537,900,404

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.33746
Policy Entropy: 2.45047
Value Function Loss: 0.01752

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.09377
Policy Update Magnitude: 0.50338
Value Function Update Magnitude: 0.60636

Collected Steps per Second: 21,848.50417
Overall Steps per Second: 9,951.94357

Timestep Collection Time: 2.28968
Timestep Consumption Time: 2.73708
PPO Batch Consumption Time: 0.32226
Total Iteration Time: 5.02676

Cumulative Model Updates: 304,322
Cumulative Timesteps: 2,537,950,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2537950430...
Checkpoint 2537950430 saved!
