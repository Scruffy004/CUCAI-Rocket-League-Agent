{"Overall Steps per Second":12329.384651284401,"PPO Batch Consumption Time":0.3438248634338379,"z_vel":4.095765239916684,"Value Function Loss":0.017594801262021065,"Cumulative Model Updates":226018,"Mean KL Divergence":0.005169036612876807,"_step":120588,"Timestep Consumption Time":1.4056815,"Timesteps Collected":50010,"SB3 Clip Fraction":0.04315999895334244,"Policy Reward":392.43005898417755,"_timestamp":1.7394371410907378e+09,"x_vel":33.19883675005432,"_wandb":{"runtime":290840},"_runtime":290840.6481119,"Collected Steps per Second":18868.266224784787,"y_vel":276.87742289312985,"Cumulative Timesteps":1884942008,"Timestep Collection Time":2.6504819999999985,"Value Function Update Magnitude":0.19055117666721344,"Total Iteration Time":4.0561634999999985,"Policy Entropy":2.1451499462127686,"Policy Update Magnitude":0.20148886740207672}