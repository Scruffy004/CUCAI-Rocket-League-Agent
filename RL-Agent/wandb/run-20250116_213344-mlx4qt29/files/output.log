Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,871.22968
Policy Entropy: 0.50547
Value Function Loss: 0.11247

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.00859
Value Function Update Magnitude: 0.01932

Collected Steps per Second: 17,024.69186
Overall Steps per Second: 13,846.49132

Timestep Collection Time: 2.93950
Timestep Consumption Time: 0.67471
PPO Batch Consumption Time: 0.13398
Total Iteration Time: 3.61420

Cumulative Model Updates: 14,980
Cumulative Timesteps: 250,133,532

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,253.30934
Policy Entropy: 0.53420
Value Function Loss: 0.08948

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01960
Policy Update Magnitude: 0.01605
Value Function Update Magnitude: 0.04356

Collected Steps per Second: 18,270.04673
Overall Steps per Second: 14,117.65569

Timestep Collection Time: 2.73803
Timestep Consumption Time: 0.80533
PPO Batch Consumption Time: 0.10968
Total Iteration Time: 3.54336

Cumulative Model Updates: 14,982
Cumulative Timesteps: 250,183,556

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 250183556...
Checkpoint 250183556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,299.66695
Policy Entropy: 0.53847
Value Function Loss: 0.08757

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.03937
Policy Update Magnitude: 0.02212
Value Function Update Magnitude: 0.05114

Collected Steps per Second: 17,774.82605
Overall Steps per Second: 14,025.17150

Timestep Collection Time: 2.81387
Timestep Consumption Time: 0.75229
PPO Batch Consumption Time: 0.03360
Total Iteration Time: 3.56616

Cumulative Model Updates: 14,985
Cumulative Timesteps: 250,233,572

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,729.07549
Policy Entropy: 0.55061
Value Function Loss: 0.07315

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.04643
Policy Update Magnitude: 0.02026
Value Function Update Magnitude: 0.05228

Collected Steps per Second: 17,710.21888
Overall Steps per Second: 13,126.39794

Timestep Collection Time: 2.82323
Timestep Consumption Time: 0.98589
PPO Batch Consumption Time: 0.05445
Total Iteration Time: 3.80912

Cumulative Model Updates: 14,988
Cumulative Timesteps: 250,283,572

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 250283572...
Checkpoint 250283572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,492.05394
Policy Entropy: 0.54584
Value Function Loss: 0.08333

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03257
Policy Update Magnitude: 0.02045
Value Function Update Magnitude: 0.04693

Collected Steps per Second: 13,852.54349
Overall Steps per Second: 11,103.95728

Timestep Collection Time: 3.60973
Timestep Consumption Time: 0.89353
PPO Batch Consumption Time: 0.03587
Total Iteration Time: 4.50326

Cumulative Model Updates: 14,991
Cumulative Timesteps: 250,333,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,662.18870
Policy Entropy: 0.54629
Value Function Loss: 0.08999

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03031
Policy Update Magnitude: 0.02118
Value Function Update Magnitude: 0.03782

Collected Steps per Second: 14,133.11349
Overall Steps per Second: 10,578.75189

Timestep Collection Time: 3.54048
Timestep Consumption Time: 1.18957
PPO Batch Consumption Time: 0.14708
Total Iteration Time: 4.73005

Cumulative Model Updates: 14,994
Cumulative Timesteps: 250,383,614

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 250383614...
Checkpoint 250383614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,694.68123
Policy Entropy: 0.55295
Value Function Loss: 0.08397

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.02247
Value Function Update Magnitude: 0.04734

Collected Steps per Second: 13,243.72223
Overall Steps per Second: 10,302.16854

Timestep Collection Time: 3.77885
Timestep Consumption Time: 1.07897
PPO Batch Consumption Time: 0.06861
Total Iteration Time: 4.85781

Cumulative Model Updates: 14,997
Cumulative Timesteps: 250,433,660

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,108.14337
Policy Entropy: 0.55174
Value Function Loss: 0.08725

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03729
Policy Update Magnitude: 0.02083
Value Function Update Magnitude: 0.05649

Collected Steps per Second: 15,713.89760
Overall Steps per Second: 11,761.06899

Timestep Collection Time: 3.18279
Timestep Consumption Time: 1.06972
PPO Batch Consumption Time: 0.12842
Total Iteration Time: 4.25250

Cumulative Model Updates: 15,000
Cumulative Timesteps: 250,483,674

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 250483674...
Checkpoint 250483674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,538.42046
Policy Entropy: 0.54476
Value Function Loss: 0.08986

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.04002
Policy Update Magnitude: 0.02302
Value Function Update Magnitude: 0.04801

Collected Steps per Second: 18,129.17881
Overall Steps per Second: 13,198.46798

Timestep Collection Time: 2.75843
Timestep Consumption Time: 1.03050
PPO Batch Consumption Time: 0.11510
Total Iteration Time: 3.78892

Cumulative Model Updates: 15,003
Cumulative Timesteps: 250,533,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,388.90164
Policy Entropy: 0.53645
Value Function Loss: 0.09466

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.05018
Policy Update Magnitude: 0.02291
Value Function Update Magnitude: 0.05644

Collected Steps per Second: 14,685.24871
Overall Steps per Second: 12,143.01509

Timestep Collection Time: 3.40478
Timestep Consumption Time: 0.71282
PPO Batch Consumption Time: 0.02905
Total Iteration Time: 4.11759

Cumulative Model Updates: 15,006
Cumulative Timesteps: 250,583,682

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 250583682...
Checkpoint 250583682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,873.82239
Policy Entropy: 0.53482
Value Function Loss: 0.09410

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.04214
Policy Update Magnitude: 0.02211
Value Function Update Magnitude: 0.06369

Collected Steps per Second: 16,661.10930
Overall Steps per Second: 12,339.99301

Timestep Collection Time: 3.00172
Timestep Consumption Time: 1.05112
PPO Batch Consumption Time: 0.11195
Total Iteration Time: 4.05284

Cumulative Model Updates: 15,009
Cumulative Timesteps: 250,633,694

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,742.92973
Policy Entropy: 0.53358
Value Function Loss: 0.09936

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03073
Policy Update Magnitude: 0.02344
Value Function Update Magnitude: 0.06642

Collected Steps per Second: 18,867.39065
Overall Steps per Second: 13,879.95353

Timestep Collection Time: 2.65060
Timestep Consumption Time: 0.95243
PPO Batch Consumption Time: 0.08362
Total Iteration Time: 3.60304

Cumulative Model Updates: 15,012
Cumulative Timesteps: 250,683,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 250683704...
Checkpoint 250683704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,726.66016
Policy Entropy: 0.52897
Value Function Loss: 0.10436

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03118
Policy Update Magnitude: 0.02581
Value Function Update Magnitude: 0.07452

Collected Steps per Second: 19,428.21541
Overall Steps per Second: 13,865.30376

Timestep Collection Time: 2.57389
Timestep Consumption Time: 1.03267
PPO Batch Consumption Time: 0.07810
Total Iteration Time: 3.60656

Cumulative Model Updates: 15,015
Cumulative Timesteps: 250,733,710

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,934.99407
Policy Entropy: 0.53593
Value Function Loss: 0.09633

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02971
Policy Update Magnitude: 0.02571
Value Function Update Magnitude: 0.07849

Collected Steps per Second: 15,351.51129
Overall Steps per Second: 11,507.19226

Timestep Collection Time: 3.25714
Timestep Consumption Time: 1.08814
PPO Batch Consumption Time: 0.11005
Total Iteration Time: 4.34528

Cumulative Model Updates: 15,018
Cumulative Timesteps: 250,783,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 250783712...
Checkpoint 250783712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,355.61471
Policy Entropy: 0.53759
Value Function Loss: 0.08608

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02015
Policy Update Magnitude: 0.02305
Value Function Update Magnitude: 0.07584

Collected Steps per Second: 16,334.44734
Overall Steps per Second: 12,426.95555

Timestep Collection Time: 3.06187
Timestep Consumption Time: 0.96277
PPO Batch Consumption Time: 0.03902
Total Iteration Time: 4.02464

Cumulative Model Updates: 15,021
Cumulative Timesteps: 250,833,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,777.23192
Policy Entropy: 0.54132
Value Function Loss: 0.08078

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02991
Policy Update Magnitude: 0.02120
Value Function Update Magnitude: 0.07092

Collected Steps per Second: 14,589.86076
Overall Steps per Second: 11,818.02119

Timestep Collection Time: 3.42855
Timestep Consumption Time: 0.80414
PPO Batch Consumption Time: 0.04403
Total Iteration Time: 4.23269

Cumulative Model Updates: 15,024
Cumulative Timesteps: 250,883,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 250883748...
Checkpoint 250883748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,229.51202
Policy Entropy: 0.54326
Value Function Loss: 0.07865

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03035
Policy Update Magnitude: 0.02193
Value Function Update Magnitude: 0.06810

Collected Steps per Second: 19,400.40006
Overall Steps per Second: 14,293.15165

Timestep Collection Time: 2.57881
Timestep Consumption Time: 0.92146
PPO Batch Consumption Time: 0.03536
Total Iteration Time: 3.50028

Cumulative Model Updates: 15,027
Cumulative Timesteps: 250,933,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,814.55045
Policy Entropy: 0.54609
Value Function Loss: 0.08110

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04355
Policy Update Magnitude: 0.02526
Value Function Update Magnitude: 0.07177

Collected Steps per Second: 17,283.39676
Overall Steps per Second: 12,925.30258

Timestep Collection Time: 2.89330
Timestep Consumption Time: 0.97555
PPO Batch Consumption Time: 0.08027
Total Iteration Time: 3.86885

Cumulative Model Updates: 15,030
Cumulative Timesteps: 250,983,784

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 250983784...
Checkpoint 250983784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,184.58104
Policy Entropy: 0.54458
Value Function Loss: 0.08419

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04674
Policy Update Magnitude: 0.03116
Value Function Update Magnitude: 0.06305

Collected Steps per Second: 17,725.29787
Overall Steps per Second: 13,513.48064

Timestep Collection Time: 2.82094
Timestep Consumption Time: 0.87922
PPO Batch Consumption Time: 0.06808
Total Iteration Time: 3.70016

Cumulative Model Updates: 15,033
Cumulative Timesteps: 251,033,786

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,589.42179
Policy Entropy: 0.53806
Value Function Loss: 0.09560

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.07161
Policy Update Magnitude: 0.03215
Value Function Update Magnitude: 0.06149

Collected Steps per Second: 16,390.43258
Overall Steps per Second: 12,472.55513

Timestep Collection Time: 3.05154
Timestep Consumption Time: 0.95855
PPO Batch Consumption Time: 0.04250
Total Iteration Time: 4.01008

Cumulative Model Updates: 15,036
Cumulative Timesteps: 251,083,802

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 251083802...
Checkpoint 251083802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,220.50171
Policy Entropy: 0.53395
Value Function Loss: 0.09604

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.07301
Policy Update Magnitude: 0.02404
Value Function Update Magnitude: 0.04875

Collected Steps per Second: 17,219.44334
Overall Steps per Second: 13,716.20861

Timestep Collection Time: 2.90532
Timestep Consumption Time: 0.74204
PPO Batch Consumption Time: 0.02855
Total Iteration Time: 3.64736

Cumulative Model Updates: 15,039
Cumulative Timesteps: 251,133,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,456.54650
Policy Entropy: 0.53367
Value Function Loss: 0.09853

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.05000
Policy Update Magnitude: 0.02422
Value Function Update Magnitude: 0.04004

Collected Steps per Second: 19,827.38438
Overall Steps per Second: 14,757.83993

Timestep Collection Time: 2.52176
Timestep Consumption Time: 0.86626
PPO Batch Consumption Time: 0.03590
Total Iteration Time: 3.38803

Cumulative Model Updates: 15,042
Cumulative Timesteps: 251,183,830

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 251183830...
Checkpoint 251183830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,432.61359
Policy Entropy: 0.54007
Value Function Loss: 0.10053

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06623
Policy Update Magnitude: 0.02306
Value Function Update Magnitude: 0.03525

Collected Steps per Second: 18,551.36783
Overall Steps per Second: 13,470.84613

Timestep Collection Time: 2.69705
Timestep Consumption Time: 1.01719
PPO Batch Consumption Time: 0.05718
Total Iteration Time: 3.71424

Cumulative Model Updates: 15,045
Cumulative Timesteps: 251,233,864

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,293.34089
Policy Entropy: 0.53868
Value Function Loss: 0.09652

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.04626
Policy Update Magnitude: 0.02430
Value Function Update Magnitude: 0.03202

Collected Steps per Second: 21,308.70956
Overall Steps per Second: 14,846.78570

Timestep Collection Time: 2.34730
Timestep Consumption Time: 1.02164
PPO Batch Consumption Time: 0.12577
Total Iteration Time: 3.36894

Cumulative Model Updates: 15,048
Cumulative Timesteps: 251,283,882

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 251283882...
Checkpoint 251283882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,111.89395
Policy Entropy: 0.53547
Value Function Loss: 0.10011

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.05211
Policy Update Magnitude: 0.02531
Value Function Update Magnitude: 0.02915

Collected Steps per Second: 20,043.42354
Overall Steps per Second: 14,387.98558

Timestep Collection Time: 2.49588
Timestep Consumption Time: 0.98105
PPO Batch Consumption Time: 0.10113
Total Iteration Time: 3.47693

Cumulative Model Updates: 15,051
Cumulative Timesteps: 251,333,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,761.31331
Policy Entropy: 0.53386
Value Function Loss: 0.09930

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.06693
Policy Update Magnitude: 0.02398
Value Function Update Magnitude: 0.03202

Collected Steps per Second: 19,577.97517
Overall Steps per Second: 14,139.68120

Timestep Collection Time: 2.55563
Timestep Consumption Time: 0.98293
PPO Batch Consumption Time: 0.10987
Total Iteration Time: 3.53855

Cumulative Model Updates: 15,054
Cumulative Timesteps: 251,383,942

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 251383942...
Checkpoint 251383942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,499.02001
Policy Entropy: 0.52957
Value Function Loss: 0.10546

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04711
Policy Update Magnitude: 0.02345
Value Function Update Magnitude: 0.03019

Collected Steps per Second: 19,374.84295
Overall Steps per Second: 13,972.03888

Timestep Collection Time: 2.58190
Timestep Consumption Time: 0.99839
PPO Batch Consumption Time: 0.10846
Total Iteration Time: 3.58029

Cumulative Model Updates: 15,057
Cumulative Timesteps: 251,433,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,635.27797
Policy Entropy: 0.52717
Value Function Loss: 0.10377

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04820
Policy Update Magnitude: 0.02241
Value Function Update Magnitude: 0.03389

Collected Steps per Second: 19,774.18879
Overall Steps per Second: 14,662.94620

Timestep Collection Time: 2.52895
Timestep Consumption Time: 0.88155
PPO Batch Consumption Time: 0.08836
Total Iteration Time: 3.41050

Cumulative Model Updates: 15,060
Cumulative Timesteps: 251,483,974

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 251483974...
Checkpoint 251483974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,639.52206
Policy Entropy: 0.52918
Value Function Loss: 0.11118

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03855
Policy Update Magnitude: 0.02330
Value Function Update Magnitude: 0.03061

Collected Steps per Second: 18,982.69063
Overall Steps per Second: 13,845.24737

Timestep Collection Time: 2.63566
Timestep Consumption Time: 0.97799
PPO Batch Consumption Time: 0.11151
Total Iteration Time: 3.61366

Cumulative Model Updates: 15,063
Cumulative Timesteps: 251,534,006

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,021.78792
Policy Entropy: 0.53297
Value Function Loss: 0.10484

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03543
Policy Update Magnitude: 0.02250
Value Function Update Magnitude: 0.03755

Collected Steps per Second: 20,202.97654
Overall Steps per Second: 14,462.08618

Timestep Collection Time: 2.47577
Timestep Consumption Time: 0.98279
PPO Batch Consumption Time: 0.10936
Total Iteration Time: 3.45856

Cumulative Model Updates: 15,066
Cumulative Timesteps: 251,584,024

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 251584024...
Checkpoint 251584024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,024.40364
Policy Entropy: 0.52752
Value Function Loss: 0.10388

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04601
Policy Update Magnitude: 0.02122
Value Function Update Magnitude: 0.03142

Collected Steps per Second: 21,172.08317
Overall Steps per Second: 15,580.39785

Timestep Collection Time: 2.36264
Timestep Consumption Time: 0.84793
PPO Batch Consumption Time: 0.07218
Total Iteration Time: 3.21057

Cumulative Model Updates: 15,069
Cumulative Timesteps: 251,634,046

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,026.38055
Policy Entropy: 0.52665
Value Function Loss: 0.09947

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.05059
Policy Update Magnitude: 0.02082
Value Function Update Magnitude: 0.03006

Collected Steps per Second: 21,612.03617
Overall Steps per Second: 15,445.66877

Timestep Collection Time: 2.31454
Timestep Consumption Time: 0.92403
PPO Batch Consumption Time: 0.09091
Total Iteration Time: 3.23858

Cumulative Model Updates: 15,072
Cumulative Timesteps: 251,684,068

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 251684068...
Checkpoint 251684068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,832.59273
Policy Entropy: 0.53006
Value Function Loss: 0.09722

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04895
Policy Update Magnitude: 0.02269
Value Function Update Magnitude: 0.02665

Collected Steps per Second: 21,458.25717
Overall Steps per Second: 15,615.41061

Timestep Collection Time: 2.33104
Timestep Consumption Time: 0.87221
PPO Batch Consumption Time: 0.09144
Total Iteration Time: 3.20325

Cumulative Model Updates: 15,075
Cumulative Timesteps: 251,734,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,749.45341
Policy Entropy: 0.52757
Value Function Loss: 0.09921

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03967
Policy Update Magnitude: 0.02510
Value Function Update Magnitude: 0.03097

Collected Steps per Second: 18,247.30029
Overall Steps per Second: 13,123.68261

Timestep Collection Time: 2.74068
Timestep Consumption Time: 1.06999
PPO Batch Consumption Time: 0.11172
Total Iteration Time: 3.81067

Cumulative Model Updates: 15,078
Cumulative Timesteps: 251,784,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 251784098...
Checkpoint 251784098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,042.06433
Policy Entropy: 0.53094
Value Function Loss: 0.10067

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05606
Policy Update Magnitude: 0.02638
Value Function Update Magnitude: 0.03312

Collected Steps per Second: 15,642.92859
Overall Steps per Second: 11,919.37018

Timestep Collection Time: 3.19889
Timestep Consumption Time: 0.99932
PPO Batch Consumption Time: 0.11150
Total Iteration Time: 4.19821

Cumulative Model Updates: 15,081
Cumulative Timesteps: 251,834,138

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,142.68958
Policy Entropy: 0.52590
Value Function Loss: 0.10559

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05802
Policy Update Magnitude: 0.02474
Value Function Update Magnitude: 0.03140

Collected Steps per Second: 17,603.50341
Overall Steps per Second: 13,665.35070

Timestep Collection Time: 2.84034
Timestep Consumption Time: 0.81855
PPO Batch Consumption Time: 0.04631
Total Iteration Time: 3.65889

Cumulative Model Updates: 15,084
Cumulative Timesteps: 251,884,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 251884138...
Checkpoint 251884138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,541.86498
Policy Entropy: 0.53116
Value Function Loss: 0.10164

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.07141
Policy Update Magnitude: 0.02571
Value Function Update Magnitude: 0.03090

Collected Steps per Second: 20,698.72607
Overall Steps per Second: 15,901.14424

Timestep Collection Time: 2.41561
Timestep Consumption Time: 0.72882
PPO Batch Consumption Time: 0.02891
Total Iteration Time: 3.14443

Cumulative Model Updates: 15,087
Cumulative Timesteps: 251,934,138

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,468.16372
Policy Entropy: 0.52942
Value Function Loss: 0.10118

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05491
Policy Update Magnitude: 0.02189
Value Function Update Magnitude: 0.03498

Collected Steps per Second: 15,825.28491
Overall Steps per Second: 12,269.09837

Timestep Collection Time: 3.16190
Timestep Consumption Time: 0.91647
PPO Batch Consumption Time: 0.05476
Total Iteration Time: 4.07838

Cumulative Model Updates: 15,090
Cumulative Timesteps: 251,984,176

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 251984176...
Checkpoint 251984176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,366.43802
Policy Entropy: 0.53075
Value Function Loss: 0.09869

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05554
Policy Update Magnitude: 0.02192
Value Function Update Magnitude: 0.03472

Collected Steps per Second: 17,949.91050
Overall Steps per Second: 13,918.34419

Timestep Collection Time: 2.78653
Timestep Consumption Time: 0.80714
PPO Batch Consumption Time: 0.05680
Total Iteration Time: 3.59367

Cumulative Model Updates: 15,093
Cumulative Timesteps: 252,034,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,209.15802
Policy Entropy: 0.53279
Value Function Loss: 0.10150

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02674
Policy Update Magnitude: 0.02304
Value Function Update Magnitude: 0.03394

Collected Steps per Second: 17,055.85966
Overall Steps per Second: 13,035.60391

Timestep Collection Time: 2.93283
Timestep Consumption Time: 0.90450
PPO Batch Consumption Time: 0.05930
Total Iteration Time: 3.83734

Cumulative Model Updates: 15,096
Cumulative Timesteps: 252,084,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 252084216...
Checkpoint 252084216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,174.48600
Policy Entropy: 0.53389
Value Function Loss: 0.10332

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03481
Policy Update Magnitude: 0.02320
Value Function Update Magnitude: 0.02965

Collected Steps per Second: 18,996.69223
Overall Steps per Second: 14,421.09238

Timestep Collection Time: 2.63298
Timestep Consumption Time: 0.83541
PPO Batch Consumption Time: 0.06947
Total Iteration Time: 3.46839

Cumulative Model Updates: 15,099
Cumulative Timesteps: 252,134,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,507.50804
Policy Entropy: 0.52952
Value Function Loss: 0.10484

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02533
Policy Update Magnitude: 0.02245
Value Function Update Magnitude: 0.02749

Collected Steps per Second: 18,762.69383
Overall Steps per Second: 14,304.43525

Timestep Collection Time: 2.66572
Timestep Consumption Time: 0.83082
PPO Batch Consumption Time: 0.06139
Total Iteration Time: 3.49654

Cumulative Model Updates: 15,102
Cumulative Timesteps: 252,184,250

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 252184250...
Checkpoint 252184250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,600.47367
Policy Entropy: 0.52383
Value Function Loss: 0.09867

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03080
Policy Update Magnitude: 0.02244
Value Function Update Magnitude: 0.03493

Collected Steps per Second: 16,865.35568
Overall Steps per Second: 12,957.30248

Timestep Collection Time: 2.96561
Timestep Consumption Time: 0.89446
PPO Batch Consumption Time: 0.07530
Total Iteration Time: 3.86006

Cumulative Model Updates: 15,105
Cumulative Timesteps: 252,234,266

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,651.75529
Policy Entropy: 0.52603
Value Function Loss: 0.10062

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03700
Policy Update Magnitude: 0.02421
Value Function Update Magnitude: 0.02958

Collected Steps per Second: 18,992.07423
Overall Steps per Second: 14,411.92463

Timestep Collection Time: 2.63331
Timestep Consumption Time: 0.83687
PPO Batch Consumption Time: 0.05894
Total Iteration Time: 3.47018

Cumulative Model Updates: 15,108
Cumulative Timesteps: 252,284,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 252284278...
Checkpoint 252284278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,746.88943
Policy Entropy: 0.53317
Value Function Loss: 0.09780

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02541
Policy Update Magnitude: 0.02461
Value Function Update Magnitude: 0.03425

Collected Steps per Second: 17,908.89640
Overall Steps per Second: 13,933.24757

Timestep Collection Time: 2.79236
Timestep Consumption Time: 0.79676
PPO Batch Consumption Time: 0.03685
Total Iteration Time: 3.58911

Cumulative Model Updates: 15,111
Cumulative Timesteps: 252,334,286

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,606.50065
Policy Entropy: 0.52861
Value Function Loss: 0.10835

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02203
Policy Update Magnitude: 0.02581
Value Function Update Magnitude: 0.03627

Collected Steps per Second: 17,284.23266
Overall Steps per Second: 13,176.72294

Timestep Collection Time: 2.89339
Timestep Consumption Time: 0.90194
PPO Batch Consumption Time: 0.08056
Total Iteration Time: 3.79533

Cumulative Model Updates: 15,114
Cumulative Timesteps: 252,384,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 252384296...
Checkpoint 252384296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,367.98240
Policy Entropy: 0.52810
Value Function Loss: 0.09628

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.02566
Value Function Update Magnitude: 0.05004

Collected Steps per Second: 17,873.01604
Overall Steps per Second: 13,947.24639

Timestep Collection Time: 2.79863
Timestep Consumption Time: 0.78774
PPO Batch Consumption Time: 0.03467
Total Iteration Time: 3.58637

Cumulative Model Updates: 15,117
Cumulative Timesteps: 252,434,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,008.81325
Policy Entropy: 0.52947
Value Function Loss: 0.10145

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03653
Policy Update Magnitude: 0.02867
Value Function Update Magnitude: 0.06696

Collected Steps per Second: 14,689.43011
Overall Steps per Second: 11,346.87388

Timestep Collection Time: 3.40558
Timestep Consumption Time: 1.00321
PPO Batch Consumption Time: 0.11268
Total Iteration Time: 4.40879

Cumulative Model Updates: 15,120
Cumulative Timesteps: 252,484,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 252484342...
Checkpoint 252484342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,159.05852
Policy Entropy: 0.53529
Value Function Loss: 0.10286

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03825
Policy Update Magnitude: 0.02653
Value Function Update Magnitude: 0.06530

Collected Steps per Second: 19,244.09523
Overall Steps per Second: 14,319.76533

Timestep Collection Time: 2.59830
Timestep Consumption Time: 0.89351
PPO Batch Consumption Time: 0.06737
Total Iteration Time: 3.49182

Cumulative Model Updates: 15,123
Cumulative Timesteps: 252,534,344

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,731.98252
Policy Entropy: 0.53971
Value Function Loss: 0.09436

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.04339
Policy Update Magnitude: 0.02466
Value Function Update Magnitude: 0.06396

Collected Steps per Second: 16,863.66460
Overall Steps per Second: 12,970.03976

Timestep Collection Time: 2.96519
Timestep Consumption Time: 0.89015
PPO Batch Consumption Time: 0.02880
Total Iteration Time: 3.85535

Cumulative Model Updates: 15,126
Cumulative Timesteps: 252,584,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 252584348...
Checkpoint 252584348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,583.84716
Policy Entropy: 0.54110
Value Function Loss: 0.08020

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03344
Policy Update Magnitude: 0.02383
Value Function Update Magnitude: 0.06345

Collected Steps per Second: 16,329.07418
Overall Steps per Second: 13,016.61022

Timestep Collection Time: 3.06239
Timestep Consumption Time: 0.77932
PPO Batch Consumption Time: 0.04257
Total Iteration Time: 3.84171

Cumulative Model Updates: 15,129
Cumulative Timesteps: 252,634,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,335.49809
Policy Entropy: 0.54395
Value Function Loss: 0.07562

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03039
Policy Update Magnitude: 0.02500
Value Function Update Magnitude: 0.06134

Collected Steps per Second: 17,245.12595
Overall Steps per Second: 13,278.29676

Timestep Collection Time: 2.90099
Timestep Consumption Time: 0.86666
PPO Batch Consumption Time: 0.05311
Total Iteration Time: 3.76765

Cumulative Model Updates: 15,132
Cumulative Timesteps: 252,684,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 252684382...
Checkpoint 252684382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,448.57614
Policy Entropy: 0.54192
Value Function Loss: 0.07501

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02902
Policy Update Magnitude: 0.02445
Value Function Update Magnitude: 0.05944

Collected Steps per Second: 16,240.99633
Overall Steps per Second: 12,948.17835

Timestep Collection Time: 3.08011
Timestep Consumption Time: 0.78329
PPO Batch Consumption Time: 0.03989
Total Iteration Time: 3.86340

Cumulative Model Updates: 15,135
Cumulative Timesteps: 252,734,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,415.01912
Policy Entropy: 0.53649
Value Function Loss: 0.08032

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03343
Policy Update Magnitude: 0.02398
Value Function Update Magnitude: 0.05761

Collected Steps per Second: 16,571.76711
Overall Steps per Second: 12,985.76083

Timestep Collection Time: 3.01851
Timestep Consumption Time: 0.83356
PPO Batch Consumption Time: 0.05719
Total Iteration Time: 3.85207

Cumulative Model Updates: 15,138
Cumulative Timesteps: 252,784,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 252784428...
Checkpoint 252784428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,162.90224
Policy Entropy: 0.52947
Value Function Loss: 0.08549

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02773
Policy Update Magnitude: 0.02212
Value Function Update Magnitude: 0.06310

Collected Steps per Second: 17,031.01298
Overall Steps per Second: 13,464.56579

Timestep Collection Time: 2.93735
Timestep Consumption Time: 0.77803
PPO Batch Consumption Time: 0.03740
Total Iteration Time: 3.71538

Cumulative Model Updates: 15,141
Cumulative Timesteps: 252,834,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,299.45884
Policy Entropy: 0.52019
Value Function Loss: 0.09797

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03809
Policy Update Magnitude: 0.02355
Value Function Update Magnitude: 0.06006

Collected Steps per Second: 17,270.70273
Overall Steps per Second: 13,497.41479

Timestep Collection Time: 2.89600
Timestep Consumption Time: 0.80960
PPO Batch Consumption Time: 0.05339
Total Iteration Time: 3.70560

Cumulative Model Updates: 15,144
Cumulative Timesteps: 252,884,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 252884470...
Checkpoint 252884470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,290.15338
Policy Entropy: 0.52964
Value Function Loss: 0.10536

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03901
Policy Update Magnitude: 0.02532
Value Function Update Magnitude: 0.05584

Collected Steps per Second: 16,868.34494
Overall Steps per Second: 12,428.35300

Timestep Collection Time: 2.96461
Timestep Consumption Time: 1.05910
PPO Batch Consumption Time: 0.11660
Total Iteration Time: 4.02370

Cumulative Model Updates: 15,147
Cumulative Timesteps: 252,934,478

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,723.81785
Policy Entropy: 0.53617
Value Function Loss: 0.09855

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03690
Policy Update Magnitude: 0.02266
Value Function Update Magnitude: 0.04282

Collected Steps per Second: 7,847.28340
Overall Steps per Second: 6,688.24573

Timestep Collection Time: 6.37342
Timestep Consumption Time: 1.10448
PPO Batch Consumption Time: 0.09464
Total Iteration Time: 7.47790

Cumulative Model Updates: 15,150
Cumulative Timesteps: 252,984,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 252984492...
Checkpoint 252984492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,585.87110
Policy Entropy: 0.53784
Value Function Loss: 0.10056

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03263
Policy Update Magnitude: 0.02342
Value Function Update Magnitude: 0.04425

Collected Steps per Second: 5,875.95299
Overall Steps per Second: 5,315.77444

Timestep Collection Time: 8.50926
Timestep Consumption Time: 0.89671
PPO Batch Consumption Time: 0.03142
Total Iteration Time: 9.40597

Cumulative Model Updates: 15,153
Cumulative Timesteps: 253,034,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,438.95171
Policy Entropy: 0.53331
Value Function Loss: 0.10896

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.04048
Policy Update Magnitude: 0.02552
Value Function Update Magnitude: 0.04128

Collected Steps per Second: 6,977.13354
Overall Steps per Second: 6,206.36787

Timestep Collection Time: 7.17171
Timestep Consumption Time: 0.89065
PPO Batch Consumption Time: 0.04660
Total Iteration Time: 8.06236

Cumulative Model Updates: 15,156
Cumulative Timesteps: 253,084,530

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 253084530...
Checkpoint 253084530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,279.78066
Policy Entropy: 0.53848
Value Function Loss: 0.10701

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03913
Policy Update Magnitude: 0.02503
Value Function Update Magnitude: 0.03779

Collected Steps per Second: 17,083.50730
Overall Steps per Second: 12,643.04744

Timestep Collection Time: 2.92832
Timestep Consumption Time: 1.02848
PPO Batch Consumption Time: 0.09962
Total Iteration Time: 3.95680

Cumulative Model Updates: 15,159
Cumulative Timesteps: 253,134,556

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,325.86300
Policy Entropy: 0.54349
Value Function Loss: 0.09922

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03051
Policy Update Magnitude: 0.02755
Value Function Update Magnitude: 0.03458

Collected Steps per Second: 14,681.42401
Overall Steps per Second: 11,198.64680

Timestep Collection Time: 3.40880
Timestep Consumption Time: 1.06014
PPO Batch Consumption Time: 0.09843
Total Iteration Time: 4.46893

Cumulative Model Updates: 15,162
Cumulative Timesteps: 253,184,602

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 253184602...
Checkpoint 253184602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,361.57241
Policy Entropy: 0.54527
Value Function Loss: 0.08870

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01651
Policy Update Magnitude: 0.02336
Value Function Update Magnitude: 0.03095

Collected Steps per Second: 14,840.05444
Overall Steps per Second: 11,327.47667

Timestep Collection Time: 3.37007
Timestep Consumption Time: 1.04504
PPO Batch Consumption Time: 0.11743
Total Iteration Time: 4.41511

Cumulative Model Updates: 15,165
Cumulative Timesteps: 253,234,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,520.77262
Policy Entropy: 0.54819
Value Function Loss: 0.08171

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.02007
Policy Update Magnitude: 0.02220
Value Function Update Magnitude: 0.02826

Collected Steps per Second: 19,203.41861
Overall Steps per Second: 13,842.72334

Timestep Collection Time: 2.60485
Timestep Consumption Time: 1.00875
PPO Batch Consumption Time: 0.11378
Total Iteration Time: 3.61360

Cumulative Model Updates: 15,168
Cumulative Timesteps: 253,284,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 253284636...
Checkpoint 253284636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,377.96466
Policy Entropy: 0.54314
Value Function Loss: 0.08811

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01977
Policy Update Magnitude: 0.02229
Value Function Update Magnitude: 0.02475

Collected Steps per Second: 19,411.35049
Overall Steps per Second: 13,863.41224

Timestep Collection Time: 2.57664
Timestep Consumption Time: 1.03113
PPO Batch Consumption Time: 0.12308
Total Iteration Time: 3.60777

Cumulative Model Updates: 15,171
Cumulative Timesteps: 253,334,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,502.83726
Policy Entropy: 0.53880
Value Function Loss: 0.09268

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.02402
Value Function Update Magnitude: 0.02644

Collected Steps per Second: 19,498.14507
Overall Steps per Second: 13,915.95147

Timestep Collection Time: 2.56630
Timestep Consumption Time: 1.02943
PPO Batch Consumption Time: 0.12483
Total Iteration Time: 3.59573

Cumulative Model Updates: 15,174
Cumulative Timesteps: 253,384,690

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 253384690...
Checkpoint 253384690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,614.61231
Policy Entropy: 0.53564
Value Function Loss: 0.09439

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 0.02597
Value Function Update Magnitude: 0.02590

Collected Steps per Second: 18,429.18963
Overall Steps per Second: 13,182.52761

Timestep Collection Time: 2.71363
Timestep Consumption Time: 1.08003
PPO Batch Consumption Time: 0.13516
Total Iteration Time: 3.79366

Cumulative Model Updates: 15,177
Cumulative Timesteps: 253,434,700

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,785.72220
Policy Entropy: 0.53324
Value Function Loss: 0.08785

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.02502
Value Function Update Magnitude: 0.03037

Collected Steps per Second: 18,216.76759
Overall Steps per Second: 13,329.22930

Timestep Collection Time: 2.74516
Timestep Consumption Time: 1.00659
PPO Batch Consumption Time: 0.10805
Total Iteration Time: 3.75175

Cumulative Model Updates: 15,180
Cumulative Timesteps: 253,484,708

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 253484708...
Checkpoint 253484708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,639.06335
Policy Entropy: 0.53083
Value Function Loss: 0.09019

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03701
Policy Update Magnitude: 0.02344
Value Function Update Magnitude: 0.02708

Collected Steps per Second: 17,738.22646
Overall Steps per Second: 13,016.35260

Timestep Collection Time: 2.81967
Timestep Consumption Time: 1.02288
PPO Batch Consumption Time: 0.09816
Total Iteration Time: 3.84255

Cumulative Model Updates: 15,183
Cumulative Timesteps: 253,534,724

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,278.16054
Policy Entropy: 0.53350
Value Function Loss: 0.09241

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03399
Policy Update Magnitude: 0.02335
Value Function Update Magnitude: 0.02985

Collected Steps per Second: 15,380.16354
Overall Steps per Second: 10,959.91502

Timestep Collection Time: 3.25224
Timestep Consumption Time: 1.31166
PPO Batch Consumption Time: 0.16483
Total Iteration Time: 4.56390

Cumulative Model Updates: 15,186
Cumulative Timesteps: 253,584,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 253584744...
Checkpoint 253584744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,052.38501
Policy Entropy: 0.53207
Value Function Loss: 0.08868

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03779
Policy Update Magnitude: 0.02432
Value Function Update Magnitude: 0.03045

Collected Steps per Second: 13,096.55513
Overall Steps per Second: 10,720.14356

Timestep Collection Time: 3.82100
Timestep Consumption Time: 0.84703
PPO Batch Consumption Time: 0.02947
Total Iteration Time: 4.66803

Cumulative Model Updates: 15,189
Cumulative Timesteps: 253,634,786

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,267.15431
Policy Entropy: 0.53395
Value Function Loss: 0.09525

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.04076
Policy Update Magnitude: 0.02333
Value Function Update Magnitude: 0.03087

Collected Steps per Second: 14,353.24399
Overall Steps per Second: 11,305.91704

Timestep Collection Time: 3.48534
Timestep Consumption Time: 0.93942
PPO Batch Consumption Time: 0.06847
Total Iteration Time: 4.42476

Cumulative Model Updates: 15,192
Cumulative Timesteps: 253,684,812

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 253684812...
Checkpoint 253684812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,016.80570
Policy Entropy: 0.53209
Value Function Loss: 0.09317

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03541
Policy Update Magnitude: 0.02260
Value Function Update Magnitude: 0.02671

Collected Steps per Second: 15,474.94005
Overall Steps per Second: 11,959.47941

Timestep Collection Time: 3.23232
Timestep Consumption Time: 0.95013
PPO Batch Consumption Time: 0.06351
Total Iteration Time: 4.18246

Cumulative Model Updates: 15,195
Cumulative Timesteps: 253,734,832

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,463.16927
Policy Entropy: 0.52019
Value Function Loss: 0.10755

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04796
Policy Update Magnitude: 0.02539
Value Function Update Magnitude: 0.02700

Collected Steps per Second: 7,374.05451
Overall Steps per Second: 6,305.35195

Timestep Collection Time: 6.78568
Timestep Consumption Time: 1.15011
PPO Batch Consumption Time: 0.09219
Total Iteration Time: 7.93580

Cumulative Model Updates: 15,198
Cumulative Timesteps: 253,784,870

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 253784870...
Checkpoint 253784870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,767.37254
Policy Entropy: 0.51697
Value Function Loss: 0.10141

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.02862
Value Function Update Magnitude: 0.02577

Collected Steps per Second: 5,747.90070
Overall Steps per Second: 5,081.55708

Timestep Collection Time: 8.70161
Timestep Consumption Time: 1.14104
PPO Batch Consumption Time: 0.09932
Total Iteration Time: 9.84265

Cumulative Model Updates: 15,201
Cumulative Timesteps: 253,834,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,215.86016
Policy Entropy: 0.51579
Value Function Loss: 0.10621

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.02860
Value Function Update Magnitude: 0.03056

Collected Steps per Second: 7,905.17131
Overall Steps per Second: 7,011.00401

Timestep Collection Time: 6.32927
Timestep Consumption Time: 0.80722
PPO Batch Consumption Time: 0.04531
Total Iteration Time: 7.13650

Cumulative Model Updates: 15,204
Cumulative Timesteps: 253,884,920

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 253884920...
Checkpoint 253884920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,594.15045
Policy Entropy: 0.52721
Value Function Loss: 0.09798

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02101
Policy Update Magnitude: 0.02747
Value Function Update Magnitude: 0.02906

Collected Steps per Second: 17,922.17248
Overall Steps per Second: 12,879.52729

Timestep Collection Time: 2.79252
Timestep Consumption Time: 1.09334
PPO Batch Consumption Time: 0.12375
Total Iteration Time: 3.88586

Cumulative Model Updates: 15,207
Cumulative Timesteps: 253,934,968

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,166.81804
Policy Entropy: 0.52936
Value Function Loss: 0.10634

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.02040
Policy Update Magnitude: 0.02854
Value Function Update Magnitude: 0.03054

Collected Steps per Second: 13,111.68732
Overall Steps per Second: 10,261.30203

Timestep Collection Time: 3.81583
Timestep Consumption Time: 1.05996
PPO Batch Consumption Time: 0.10234
Total Iteration Time: 4.87579

Cumulative Model Updates: 15,210
Cumulative Timesteps: 253,985,000

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 253985000...
Checkpoint 253985000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,540.67539
Policy Entropy: 0.53149
Value Function Loss: 0.11372

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02364
Policy Update Magnitude: 0.02845
Value Function Update Magnitude: 0.03238

Collected Steps per Second: 5,492.21260
Overall Steps per Second: 4,883.79705

Timestep Collection Time: 9.10671
Timestep Consumption Time: 1.13450
PPO Batch Consumption Time: 0.11351
Total Iteration Time: 10.24121

Cumulative Model Updates: 15,213
Cumulative Timesteps: 254,035,016

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,329.07015
Policy Entropy: 0.51944
Value Function Loss: 0.11577

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03314
Policy Update Magnitude: 0.03042
Value Function Update Magnitude: 0.03138

Collected Steps per Second: 5,422.93851
Overall Steps per Second: 4,838.98993

Timestep Collection Time: 9.22157
Timestep Consumption Time: 1.11282
PPO Batch Consumption Time: 0.10363
Total Iteration Time: 10.33439

Cumulative Model Updates: 15,216
Cumulative Timesteps: 254,085,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 254085024...
Checkpoint 254085024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,239.27365
Policy Entropy: 0.52490
Value Function Loss: 0.10460

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03007
Policy Update Magnitude: 0.02730
Value Function Update Magnitude: 0.03205

Collected Steps per Second: 5,332.28664
Overall Steps per Second: 4,772.86301

Timestep Collection Time: 9.38172
Timestep Consumption Time: 1.09962
PPO Batch Consumption Time: 0.09655
Total Iteration Time: 10.48134

Cumulative Model Updates: 15,219
Cumulative Timesteps: 254,135,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,509.06546
Policy Entropy: 0.52444
Value Function Loss: 0.09480

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04841
Policy Update Magnitude: 0.02575
Value Function Update Magnitude: 0.02775

Collected Steps per Second: 6,351.90985
Overall Steps per Second: 5,771.41338

Timestep Collection Time: 7.87480
Timestep Consumption Time: 0.79206
PPO Batch Consumption Time: 0.03678
Total Iteration Time: 8.66685

Cumulative Model Updates: 15,222
Cumulative Timesteps: 254,185,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 254185070...
Checkpoint 254185070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,878.35336
Policy Entropy: 0.53171
Value Function Loss: 0.09859

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.05191
Policy Update Magnitude: 0.02314
Value Function Update Magnitude: 0.02745

Collected Steps per Second: 17,423.50495
Overall Steps per Second: 13,387.22271

Timestep Collection Time: 2.87038
Timestep Consumption Time: 0.86543
PPO Batch Consumption Time: 0.06795
Total Iteration Time: 3.73580

Cumulative Model Updates: 15,225
Cumulative Timesteps: 254,235,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,004.87951
Policy Entropy: 0.52508
Value Function Loss: 0.10444

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.02223
Value Function Update Magnitude: 0.02849

Collected Steps per Second: 17,194.88794
Overall Steps per Second: 13,159.47822

Timestep Collection Time: 2.90877
Timestep Consumption Time: 0.89199
PPO Batch Consumption Time: 0.06220
Total Iteration Time: 3.80076

Cumulative Model Updates: 15,228
Cumulative Timesteps: 254,285,098

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 254285098...
Checkpoint 254285098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,124.13044
Policy Entropy: 0.52895
Value Function Loss: 0.09728

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 0.02265
Value Function Update Magnitude: 0.02775

Collected Steps per Second: 17,107.62831
Overall Steps per Second: 13,138.20640

Timestep Collection Time: 2.92431
Timestep Consumption Time: 0.88352
PPO Batch Consumption Time: 0.06210
Total Iteration Time: 3.80783

Cumulative Model Updates: 15,231
Cumulative Timesteps: 254,335,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,238.55867
Policy Entropy: 0.52833
Value Function Loss: 0.09400

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.02274
Value Function Update Magnitude: 0.02680

Collected Steps per Second: 16,513.66112
Overall Steps per Second: 12,763.57807

Timestep Collection Time: 3.02804
Timestep Consumption Time: 0.88967
PPO Batch Consumption Time: 0.06941
Total Iteration Time: 3.91771

Cumulative Model Updates: 15,234
Cumulative Timesteps: 254,385,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 254385130...
Checkpoint 254385130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,317.12703
Policy Entropy: 0.53667
Value Function Loss: 0.08612

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03923
Policy Update Magnitude: 0.02409
Value Function Update Magnitude: 0.02762

Collected Steps per Second: 16,830.42973
Overall Steps per Second: 13,012.01533

Timestep Collection Time: 2.97093
Timestep Consumption Time: 0.87183
PPO Batch Consumption Time: 0.06668
Total Iteration Time: 3.84276

Cumulative Model Updates: 15,237
Cumulative Timesteps: 254,435,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,050.17024
Policy Entropy: 0.53012
Value Function Loss: 0.09033

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.02384
Value Function Update Magnitude: 0.02861

Collected Steps per Second: 17,365.24686
Overall Steps per Second: 13,019.46057

Timestep Collection Time: 2.88012
Timestep Consumption Time: 0.96136
PPO Batch Consumption Time: 0.09082
Total Iteration Time: 3.84148

Cumulative Model Updates: 15,240
Cumulative Timesteps: 254,485,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 254485146...
Checkpoint 254485146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,041.23129
Policy Entropy: 0.53661
Value Function Loss: 0.08393

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04105
Policy Update Magnitude: 0.02312
Value Function Update Magnitude: 0.02751

Collected Steps per Second: 8,925.05744
Overall Steps per Second: 7,452.33501

Timestep Collection Time: 5.60489
Timestep Consumption Time: 1.10763
PPO Batch Consumption Time: 0.10244
Total Iteration Time: 6.71253

Cumulative Model Updates: 15,243
Cumulative Timesteps: 254,535,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,331.90060
Policy Entropy: 0.53292
Value Function Loss: 0.08410

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03536
Policy Update Magnitude: 0.02236
Value Function Update Magnitude: 0.02448

Collected Steps per Second: 5,724.49690
Overall Steps per Second: 5,077.89515

Timestep Collection Time: 8.73754
Timestep Consumption Time: 1.11261
PPO Batch Consumption Time: 0.10245
Total Iteration Time: 9.85014

Cumulative Model Updates: 15,246
Cumulative Timesteps: 254,585,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 254585188...
Checkpoint 254585188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,905.11622
Policy Entropy: 0.53913
Value Function Loss: 0.08487

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03837
Policy Update Magnitude: 0.02176
Value Function Update Magnitude: 0.02540

Collected Steps per Second: 6,039.43042
Overall Steps per Second: 5,462.71397

Timestep Collection Time: 8.28522
Timestep Consumption Time: 0.87470
PPO Batch Consumption Time: 0.04798
Total Iteration Time: 9.15992

Cumulative Model Updates: 15,249
Cumulative Timesteps: 254,635,226

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,490.21311
Policy Entropy: 0.53899
Value Function Loss: 0.08608

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.02272
Value Function Update Magnitude: 0.02558

Collected Steps per Second: 18,327.75644
Overall Steps per Second: 12,708.60702

Timestep Collection Time: 2.72810
Timestep Consumption Time: 1.20624
PPO Batch Consumption Time: 0.08327
Total Iteration Time: 3.93434

Cumulative Model Updates: 15,252
Cumulative Timesteps: 254,685,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 254685226...
Checkpoint 254685226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,679.33093
Policy Entropy: 0.53624
Value Function Loss: 0.08953

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03043
Policy Update Magnitude: 0.02384
Value Function Update Magnitude: 0.02710

Collected Steps per Second: 17,553.98986
Overall Steps per Second: 13,133.26315

Timestep Collection Time: 2.84870
Timestep Consumption Time: 0.95889
PPO Batch Consumption Time: 0.10025
Total Iteration Time: 3.80758

Cumulative Model Updates: 15,255
Cumulative Timesteps: 254,735,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,947.58841
Policy Entropy: 0.53124
Value Function Loss: 0.08845

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.02416
Value Function Update Magnitude: 0.02771

Collected Steps per Second: 15,759.91275
Overall Steps per Second: 12,252.89533

Timestep Collection Time: 3.17273
Timestep Consumption Time: 0.90810
PPO Batch Consumption Time: 0.09134
Total Iteration Time: 4.08083

Cumulative Model Updates: 15,258
Cumulative Timesteps: 254,785,234

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 254785234...
Checkpoint 254785234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,601.64783
Policy Entropy: 0.53598
Value Function Loss: 0.08694

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03733
Policy Update Magnitude: 0.02333
Value Function Update Magnitude: 0.02859

Collected Steps per Second: 13,122.21984
Overall Steps per Second: 10,299.99147

Timestep Collection Time: 3.81125
Timestep Consumption Time: 1.04429
PPO Batch Consumption Time: 0.07819
Total Iteration Time: 4.85554

Cumulative Model Updates: 15,261
Cumulative Timesteps: 254,835,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,347.18076
Policy Entropy: 0.53706
Value Function Loss: 0.08719

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.02975
Policy Update Magnitude: 0.02356
Value Function Update Magnitude: 0.02745

Collected Steps per Second: 12,875.40382
Overall Steps per Second: 10,045.86667

Timestep Collection Time: 3.88539
Timestep Consumption Time: 1.09437
PPO Batch Consumption Time: 0.14822
Total Iteration Time: 4.97976

Cumulative Model Updates: 15,264
Cumulative Timesteps: 254,885,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 254885272...
Checkpoint 254885272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,846.93353
Policy Entropy: 0.54565
Value Function Loss: 0.08893

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02527
Policy Update Magnitude: 0.02374
Value Function Update Magnitude: 0.03205

Collected Steps per Second: 13,128.59887
Overall Steps per Second: 10,529.18181

Timestep Collection Time: 3.80955
Timestep Consumption Time: 0.94049
PPO Batch Consumption Time: 0.10055
Total Iteration Time: 4.75004

Cumulative Model Updates: 15,267
Cumulative Timesteps: 254,935,286

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,527.89377
Policy Entropy: 0.54254
Value Function Loss: 0.08602

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01827
Policy Update Magnitude: 0.02520
Value Function Update Magnitude: 0.02910

Collected Steps per Second: 5,665.50928
Overall Steps per Second: 4,985.00578

Timestep Collection Time: 8.83239
Timestep Consumption Time: 1.20571
PPO Batch Consumption Time: 0.09182
Total Iteration Time: 10.03810

Cumulative Model Updates: 15,270
Cumulative Timesteps: 254,985,326

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 254985326...
Checkpoint 254985326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,943.93805
Policy Entropy: 0.53964
Value Function Loss: 0.07919

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03693
Policy Update Magnitude: 0.02314
Value Function Update Magnitude: 0.03044

Collected Steps per Second: 5,438.03757
Overall Steps per Second: 4,827.21825

Timestep Collection Time: 9.20001
Timestep Consumption Time: 1.16414
PPO Batch Consumption Time: 0.09180
Total Iteration Time: 10.36415

Cumulative Model Updates: 15,273
Cumulative Timesteps: 255,035,356

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,492.10032
Policy Entropy: 0.53883
Value Function Loss: 0.07253

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.02391
Value Function Update Magnitude: 0.02909

Collected Steps per Second: 5,675.14027
Overall Steps per Second: 5,020.73819

Timestep Collection Time: 8.81740
Timestep Consumption Time: 1.14926
PPO Batch Consumption Time: 0.08663
Total Iteration Time: 9.96666

Cumulative Model Updates: 15,276
Cumulative Timesteps: 255,085,396

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 255085396...
Checkpoint 255085396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,491.39190
Policy Entropy: 0.53934
Value Function Loss: 0.07372

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03081
Policy Update Magnitude: 0.02355
Value Function Update Magnitude: 0.02596

Collected Steps per Second: 5,494.37361
Overall Steps per Second: 4,889.98569

Timestep Collection Time: 9.10277
Timestep Consumption Time: 1.12508
PPO Batch Consumption Time: 0.08320
Total Iteration Time: 10.22784

Cumulative Model Updates: 15,279
Cumulative Timesteps: 255,135,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,255.07802
Policy Entropy: 0.53374
Value Function Loss: 0.09003

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03884
Policy Update Magnitude: 0.02365
Value Function Update Magnitude: 0.02644

Collected Steps per Second: 5,263.63088
Overall Steps per Second: 4,688.43870

Timestep Collection Time: 9.50181
Timestep Consumption Time: 1.16571
PPO Batch Consumption Time: 0.08448
Total Iteration Time: 10.66752

Cumulative Model Updates: 15,282
Cumulative Timesteps: 255,185,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 255185424...
Checkpoint 255185424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,714.70463
Policy Entropy: 0.52894
Value Function Loss: 0.09602

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03447
Policy Update Magnitude: 0.02288
Value Function Update Magnitude: 0.02449

Collected Steps per Second: 5,556.03907
Overall Steps per Second: 4,924.09337

Timestep Collection Time: 9.00462
Timestep Consumption Time: 1.15563
PPO Batch Consumption Time: 0.08531
Total Iteration Time: 10.16025

Cumulative Model Updates: 15,285
Cumulative Timesteps: 255,235,454

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,284.10384
Policy Entropy: 0.52199
Value Function Loss: 0.10477

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03288
Policy Update Magnitude: 0.02343
Value Function Update Magnitude: 0.03186

Collected Steps per Second: 5,523.56307
Overall Steps per Second: 4,901.10146

Timestep Collection Time: 9.05973
Timestep Consumption Time: 1.15063
PPO Batch Consumption Time: 0.09200
Total Iteration Time: 10.21036

Cumulative Model Updates: 15,288
Cumulative Timesteps: 255,285,496

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 255285496...
Checkpoint 255285496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,492.18206
Policy Entropy: 0.52952
Value Function Loss: 0.09766

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03067
Policy Update Magnitude: 0.02434
Value Function Update Magnitude: 0.03047

Collected Steps per Second: 5,617.24294
Overall Steps per Second: 4,941.35717

Timestep Collection Time: 8.90508
Timestep Consumption Time: 1.21805
PPO Batch Consumption Time: 0.09262
Total Iteration Time: 10.12313

Cumulative Model Updates: 15,291
Cumulative Timesteps: 255,335,518

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,714.44882
Policy Entropy: 0.53680
Value Function Loss: 0.09257

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03404
Policy Update Magnitude: 0.02395
Value Function Update Magnitude: 0.02777

Collected Steps per Second: 5,691.65914
Overall Steps per Second: 5,043.88421

Timestep Collection Time: 8.79181
Timestep Consumption Time: 1.12911
PPO Batch Consumption Time: 0.08765
Total Iteration Time: 9.92093

Cumulative Model Updates: 15,294
Cumulative Timesteps: 255,385,558

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 255385558...
Checkpoint 255385558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,899.43147
Policy Entropy: 0.54062
Value Function Loss: 0.08555

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04609
Policy Update Magnitude: 0.02273
Value Function Update Magnitude: 0.02786

Collected Steps per Second: 5,618.04287
Overall Steps per Second: 4,994.05425

Timestep Collection Time: 8.90666
Timestep Consumption Time: 1.11285
PPO Batch Consumption Time: 0.09708
Total Iteration Time: 10.01951

Cumulative Model Updates: 15,297
Cumulative Timesteps: 255,435,596

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,826.31343
Policy Entropy: 0.54138
Value Function Loss: 0.08168

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.04211
Policy Update Magnitude: 0.02447
Value Function Update Magnitude: 0.02429

Collected Steps per Second: 5,558.84120
Overall Steps per Second: 4,928.08776

Timestep Collection Time: 8.99756
Timestep Consumption Time: 1.15161
PPO Batch Consumption Time: 0.08172
Total Iteration Time: 10.14917

Cumulative Model Updates: 15,300
Cumulative Timesteps: 255,485,612

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 255485612...
Checkpoint 255485612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,111.52462
Policy Entropy: 0.53573
Value Function Loss: 0.07831

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02896
Policy Update Magnitude: 0.02423
Value Function Update Magnitude: 0.02463

Collected Steps per Second: 5,663.36435
Overall Steps per Second: 5,013.82674

Timestep Collection Time: 8.83750
Timestep Consumption Time: 1.14489
PPO Batch Consumption Time: 0.09115
Total Iteration Time: 9.98240

Cumulative Model Updates: 15,303
Cumulative Timesteps: 255,535,662

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,672.29957
Policy Entropy: 0.53002
Value Function Loss: 0.08574

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03044
Policy Update Magnitude: 0.02257
Value Function Update Magnitude: 0.02694

Collected Steps per Second: 5,519.18185
Overall Steps per Second: 4,891.90226

Timestep Collection Time: 9.06656
Timestep Consumption Time: 1.16259
PPO Batch Consumption Time: 0.09347
Total Iteration Time: 10.22915

Cumulative Model Updates: 15,306
Cumulative Timesteps: 255,585,702

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 255585702...
Checkpoint 255585702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,822.18275
Policy Entropy: 0.53074
Value Function Loss: 0.08996

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04457
Policy Update Magnitude: 0.02510
Value Function Update Magnitude: 0.02985

Collected Steps per Second: 5,564.97008
Overall Steps per Second: 4,937.94402

Timestep Collection Time: 8.99160
Timestep Consumption Time: 1.14176
PPO Batch Consumption Time: 0.09190
Total Iteration Time: 10.13337

Cumulative Model Updates: 15,309
Cumulative Timesteps: 255,635,740

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,656.50486
Policy Entropy: 0.52851
Value Function Loss: 0.10299

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.05207
Policy Update Magnitude: 0.02364
Value Function Update Magnitude: 0.03052

Collected Steps per Second: 5,662.72964
Overall Steps per Second: 5,055.02598

Timestep Collection Time: 8.82966
Timestep Consumption Time: 1.06148
PPO Batch Consumption Time: 0.08135
Total Iteration Time: 9.89115

Cumulative Model Updates: 15,312
Cumulative Timesteps: 255,685,740

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 255685740...
Checkpoint 255685740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,695.00300
Policy Entropy: 0.53103
Value Function Loss: 0.10967

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.04223
Policy Update Magnitude: 0.02185
Value Function Update Magnitude: 0.03007

Collected Steps per Second: 5,607.72212
Overall Steps per Second: 4,973.24992

Timestep Collection Time: 8.92163
Timestep Consumption Time: 1.13819
PPO Batch Consumption Time: 0.09667
Total Iteration Time: 10.05982

Cumulative Model Updates: 15,315
Cumulative Timesteps: 255,735,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,772.86920
Policy Entropy: 0.52969
Value Function Loss: 0.10104

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03729
Policy Update Magnitude: 0.02324
Value Function Update Magnitude: 0.03393

Collected Steps per Second: 5,578.50578
Overall Steps per Second: 4,963.71167

Timestep Collection Time: 8.96512
Timestep Consumption Time: 1.11040
PPO Batch Consumption Time: 0.08888
Total Iteration Time: 10.07552

Cumulative Model Updates: 15,318
Cumulative Timesteps: 255,785,782

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 255785782...
Checkpoint 255785782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,629.44135
Policy Entropy: 0.53318
Value Function Loss: 0.09823

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04259
Policy Update Magnitude: 0.02436
Value Function Update Magnitude: 0.03424

Collected Steps per Second: 5,434.25007
Overall Steps per Second: 4,801.75827

Timestep Collection Time: 9.20421
Timestep Consumption Time: 1.21239
PPO Batch Consumption Time: 0.08831
Total Iteration Time: 10.41660

Cumulative Model Updates: 15,321
Cumulative Timesteps: 255,835,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,658.44388
Policy Entropy: 0.53585
Value Function Loss: 0.08692

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.02431
Value Function Update Magnitude: 0.04070

Collected Steps per Second: 5,560.36471
Overall Steps per Second: 4,917.09710

Timestep Collection Time: 8.99545
Timestep Consumption Time: 1.17681
PPO Batch Consumption Time: 0.08327
Total Iteration Time: 10.17226

Cumulative Model Updates: 15,324
Cumulative Timesteps: 255,885,818

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 255885818...
Checkpoint 255885818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,860.52614
Policy Entropy: 0.53515
Value Function Loss: 0.09450

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04671
Policy Update Magnitude: 0.02503
Value Function Update Magnitude: 0.03473

Collected Steps per Second: 5,549.75121
Overall Steps per Second: 4,909.57756

Timestep Collection Time: 9.01374
Timestep Consumption Time: 1.17533
PPO Batch Consumption Time: 0.08686
Total Iteration Time: 10.18906

Cumulative Model Updates: 15,327
Cumulative Timesteps: 255,935,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,558.57570
Policy Entropy: 0.53439
Value Function Loss: 0.08759

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06639
Policy Update Magnitude: 0.02324
Value Function Update Magnitude: 0.04282

Collected Steps per Second: 5,389.02041
Overall Steps per Second: 4,794.62655

Timestep Collection Time: 9.27850
Timestep Consumption Time: 1.15026
PPO Batch Consumption Time: 0.09008
Total Iteration Time: 10.42876

Cumulative Model Updates: 15,330
Cumulative Timesteps: 255,985,844

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 255985844...
Checkpoint 255985844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,870.25572
Policy Entropy: 0.53086
Value Function Loss: 0.08520

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05945
Policy Update Magnitude: 0.02202
Value Function Update Magnitude: 0.04118

Collected Steps per Second: 5,501.07231
Overall Steps per Second: 4,906.42145

Timestep Collection Time: 9.09677
Timestep Consumption Time: 1.10252
PPO Batch Consumption Time: 0.08347
Total Iteration Time: 10.19929

Cumulative Model Updates: 15,333
Cumulative Timesteps: 256,035,886

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,124.76932
Policy Entropy: 0.53085
Value Function Loss: 0.08722

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05854
Policy Update Magnitude: 0.02423
Value Function Update Magnitude: 0.03506

Collected Steps per Second: 5,432.52914
Overall Steps per Second: 4,860.93118

Timestep Collection Time: 9.21044
Timestep Consumption Time: 1.08306
PPO Batch Consumption Time: 0.08170
Total Iteration Time: 10.29350

Cumulative Model Updates: 15,336
Cumulative Timesteps: 256,085,922

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 256085922...
Checkpoint 256085922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,785.25240
Policy Entropy: 0.53575
Value Function Loss: 0.09272

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.06053
Policy Update Magnitude: 0.02312
Value Function Update Magnitude: 0.03503

Collected Steps per Second: 5,393.13329
Overall Steps per Second: 4,821.80908

Timestep Collection Time: 9.27513
Timestep Consumption Time: 1.09899
PPO Batch Consumption Time: 0.08558
Total Iteration Time: 10.37411

Cumulative Model Updates: 15,339
Cumulative Timesteps: 256,135,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,404.79853
Policy Entropy: 0.53411
Value Function Loss: 0.09303

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05332
Policy Update Magnitude: 0.02498
Value Function Update Magnitude: 0.03416

Collected Steps per Second: 5,493.91162
Overall Steps per Second: 4,904.94975

Timestep Collection Time: 9.10208
Timestep Consumption Time: 1.09293
PPO Batch Consumption Time: 0.08755
Total Iteration Time: 10.19501

Cumulative Model Updates: 15,342
Cumulative Timesteps: 256,185,950

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 256185950...
Checkpoint 256185950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,422.27647
Policy Entropy: 0.52998
Value Function Loss: 0.08912

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.05075
Policy Update Magnitude: 0.02451
Value Function Update Magnitude: 0.03420

Collected Steps per Second: 5,481.59398
Overall Steps per Second: 4,884.24770

Timestep Collection Time: 9.12764
Timestep Consumption Time: 1.11632
PPO Batch Consumption Time: 0.09312
Total Iteration Time: 10.24395

Cumulative Model Updates: 15,345
Cumulative Timesteps: 256,235,984

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,080.80958
Policy Entropy: 0.52849
Value Function Loss: 0.07680

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.04625
Policy Update Magnitude: 0.02221
Value Function Update Magnitude: 0.03265

Collected Steps per Second: 5,856.75595
Overall Steps per Second: 5,177.42145

Timestep Collection Time: 8.53988
Timestep Consumption Time: 1.12053
PPO Batch Consumption Time: 0.10008
Total Iteration Time: 9.66041

Cumulative Model Updates: 15,348
Cumulative Timesteps: 256,286,000

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 256286000...
Checkpoint 256286000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,146.40421
Policy Entropy: 0.52825
Value Function Loss: 0.07162

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04929
Policy Update Magnitude: 0.02266
Value Function Update Magnitude: 0.03446

Collected Steps per Second: 5,532.27820
Overall Steps per Second: 4,886.43053

Timestep Collection Time: 9.04329
Timestep Consumption Time: 1.19527
PPO Batch Consumption Time: 0.08284
Total Iteration Time: 10.23856

Cumulative Model Updates: 15,351
Cumulative Timesteps: 256,336,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,580.88736
Policy Entropy: 0.53258
Value Function Loss: 0.06909

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04592
Policy Update Magnitude: 0.02363
Value Function Update Magnitude: 0.03195

Collected Steps per Second: 5,645.99921
Overall Steps per Second: 4,962.64274

Timestep Collection Time: 8.86043
Timestep Consumption Time: 1.22008
PPO Batch Consumption Time: 0.08508
Total Iteration Time: 10.08052

Cumulative Model Updates: 15,354
Cumulative Timesteps: 256,386,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 256386056...
Checkpoint 256386056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,624.08642
Policy Entropy: 0.53346
Value Function Loss: 0.07234

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04754
Policy Update Magnitude: 0.02100
Value Function Update Magnitude: 0.03678

Collected Steps per Second: 5,627.54378
Overall Steps per Second: 4,977.96238

Timestep Collection Time: 8.88558
Timestep Consumption Time: 1.15949
PPO Batch Consumption Time: 0.08278
Total Iteration Time: 10.04507

Cumulative Model Updates: 15,357
Cumulative Timesteps: 256,436,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,123.65316
Policy Entropy: 0.53662
Value Function Loss: 0.06621

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03729
Policy Update Magnitude: 0.02102
Value Function Update Magnitude: 0.03466

Collected Steps per Second: 5,590.68027
Overall Steps per Second: 4,961.75742

Timestep Collection Time: 8.95133
Timestep Consumption Time: 1.13462
PPO Batch Consumption Time: 0.09303
Total Iteration Time: 10.08594

Cumulative Model Updates: 15,360
Cumulative Timesteps: 256,486,104

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 256486104...
Checkpoint 256486104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,602.72238
Policy Entropy: 0.53201
Value Function Loss: 0.07226

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04988
Policy Update Magnitude: 0.02502
Value Function Update Magnitude: 0.03558

Collected Steps per Second: 5,533.68686
Overall Steps per Second: 4,899.33386

Timestep Collection Time: 9.03882
Timestep Consumption Time: 1.17032
PPO Batch Consumption Time: 0.09188
Total Iteration Time: 10.20914

Cumulative Model Updates: 15,363
Cumulative Timesteps: 256,536,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,890.88927
Policy Entropy: 0.52459
Value Function Loss: 0.07912

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04545
Policy Update Magnitude: 0.02091
Value Function Update Magnitude: 0.03406

Collected Steps per Second: 5,610.65157
Overall Steps per Second: 4,986.32932

Timestep Collection Time: 8.91305
Timestep Consumption Time: 1.11597
PPO Batch Consumption Time: 0.08288
Total Iteration Time: 10.02902

Cumulative Model Updates: 15,366
Cumulative Timesteps: 256,586,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 256586130...
Checkpoint 256586130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,286.30991
Policy Entropy: 0.51661
Value Function Loss: 0.09846

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04346
Policy Update Magnitude: 0.02206
Value Function Update Magnitude: 0.03724

Collected Steps per Second: 5,491.18273
Overall Steps per Second: 4,882.06309

Timestep Collection Time: 9.10915
Timestep Consumption Time: 1.13652
PPO Batch Consumption Time: 0.08288
Total Iteration Time: 10.24567

Cumulative Model Updates: 15,369
Cumulative Timesteps: 256,636,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,687.44887
Policy Entropy: 0.51746
Value Function Loss: 0.09871

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03853
Policy Update Magnitude: 0.02412
Value Function Update Magnitude: 0.03822

Collected Steps per Second: 5,509.22185
Overall Steps per Second: 4,890.73498

Timestep Collection Time: 9.07605
Timestep Consumption Time: 1.14777
PPO Batch Consumption Time: 0.08811
Total Iteration Time: 10.22382

Cumulative Model Updates: 15,372
Cumulative Timesteps: 256,686,152

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 256686152...
Checkpoint 256686152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,802.19598
Policy Entropy: 0.51654
Value Function Loss: 0.10145

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.04227
Policy Update Magnitude: 0.02588
Value Function Update Magnitude: 0.04301

Collected Steps per Second: 5,478.83904
Overall Steps per Second: 4,833.03154

Timestep Collection Time: 9.12894
Timestep Consumption Time: 1.21984
PPO Batch Consumption Time: 0.08609
Total Iteration Time: 10.34878

Cumulative Model Updates: 15,375
Cumulative Timesteps: 256,736,168

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,835.84246
Policy Entropy: 0.50975
Value Function Loss: 0.10906

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.02661
Value Function Update Magnitude: 0.04300

Collected Steps per Second: 5,620.09522
Overall Steps per Second: 4,986.54724

Timestep Collection Time: 8.90198
Timestep Consumption Time: 1.13101
PPO Batch Consumption Time: 0.08287
Total Iteration Time: 10.03299

Cumulative Model Updates: 15,378
Cumulative Timesteps: 256,786,198

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 256786198...
Checkpoint 256786198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,414.78941
Policy Entropy: 0.51153
Value Function Loss: 0.11563

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06695
Policy Update Magnitude: 0.02791
Value Function Update Magnitude: 0.05256

Collected Steps per Second: 5,537.73734
Overall Steps per Second: 4,913.28506

Timestep Collection Time: 9.03401
Timestep Consumption Time: 1.14818
PPO Batch Consumption Time: 0.08409
Total Iteration Time: 10.18219

Cumulative Model Updates: 15,381
Cumulative Timesteps: 256,836,226

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,004.06425
Policy Entropy: 0.50977
Value Function Loss: 0.10857

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.04877
Policy Update Magnitude: 0.02970
Value Function Update Magnitude: 0.05120

Collected Steps per Second: 5,472.90607
Overall Steps per Second: 4,871.66711

Timestep Collection Time: 9.13738
Timestep Consumption Time: 1.12769
PPO Batch Consumption Time: 0.08449
Total Iteration Time: 10.26507

Cumulative Model Updates: 15,384
Cumulative Timesteps: 256,886,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 256886234...
Checkpoint 256886234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,121.52260
Policy Entropy: 0.51656
Value Function Loss: 0.09212

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04841
Policy Update Magnitude: 0.02757
Value Function Update Magnitude: 0.05228

Collected Steps per Second: 5,294.30980
Overall Steps per Second: 4,782.08368

Timestep Collection Time: 9.44486
Timestep Consumption Time: 1.01167
PPO Batch Consumption Time: 0.08320
Total Iteration Time: 10.45653

Cumulative Model Updates: 15,387
Cumulative Timesteps: 256,936,238

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,146.12588
Policy Entropy: 0.51399
Value Function Loss: 0.08617

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.02469
Value Function Update Magnitude: 0.04586

Collected Steps per Second: 5,410.26721
Overall Steps per Second: 4,880.34774

Timestep Collection Time: 9.24760
Timestep Consumption Time: 1.00413
PPO Batch Consumption Time: 0.09065
Total Iteration Time: 10.25173

Cumulative Model Updates: 15,390
Cumulative Timesteps: 256,986,270

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 256986270...
Checkpoint 256986270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,832.21216
Policy Entropy: 0.51404
Value Function Loss: 0.08617

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03750
Policy Update Magnitude: 0.02278
Value Function Update Magnitude: 0.04484

Collected Steps per Second: 5,273.67707
Overall Steps per Second: 4,760.70656

Timestep Collection Time: 9.48143
Timestep Consumption Time: 1.02163
PPO Batch Consumption Time: 0.08174
Total Iteration Time: 10.50306

Cumulative Model Updates: 15,393
Cumulative Timesteps: 257,036,272

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,243.44299
Policy Entropy: 0.51740
Value Function Loss: 0.08122

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04511
Policy Update Magnitude: 0.02264
Value Function Update Magnitude: 0.03824

Collected Steps per Second: 5,416.67745
Overall Steps per Second: 4,872.01079

Timestep Collection Time: 9.23260
Timestep Consumption Time: 1.03216
PPO Batch Consumption Time: 0.08480
Total Iteration Time: 10.26476

Cumulative Model Updates: 15,396
Cumulative Timesteps: 257,086,282

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 257086282...
Checkpoint 257086282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,111.31609
Policy Entropy: 0.51626
Value Function Loss: 0.07487

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.05005
Policy Update Magnitude: 0.02086
Value Function Update Magnitude: 0.03946

Collected Steps per Second: 5,432.54474
Overall Steps per Second: 4,821.57735

Timestep Collection Time: 9.20931
Timestep Consumption Time: 1.16696
PPO Batch Consumption Time: 0.09111
Total Iteration Time: 10.37627

Cumulative Model Updates: 15,399
Cumulative Timesteps: 257,136,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,237.84029
Policy Entropy: 0.51578
Value Function Loss: 0.08389

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03753
Policy Update Magnitude: 0.02252
Value Function Update Magnitude: 0.04267

Collected Steps per Second: 5,652.73915
Overall Steps per Second: 4,998.12683

Timestep Collection Time: 8.84562
Timestep Consumption Time: 1.15852
PPO Batch Consumption Time: 0.08826
Total Iteration Time: 10.00415

Cumulative Model Updates: 15,402
Cumulative Timesteps: 257,186,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 257186314...
Checkpoint 257186314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,572.58502
Policy Entropy: 0.51317
Value Function Loss: 0.10036

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03059
Policy Update Magnitude: 0.02592
Value Function Update Magnitude: 0.04349

Collected Steps per Second: 5,501.84867
Overall Steps per Second: 4,899.61722

Timestep Collection Time: 9.08894
Timestep Consumption Time: 1.11716
PPO Batch Consumption Time: 0.08109
Total Iteration Time: 10.20610

Cumulative Model Updates: 15,405
Cumulative Timesteps: 257,236,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,379.43989
Policy Entropy: 0.51407
Value Function Loss: 0.09758

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.04603
Policy Update Magnitude: 0.02483
Value Function Update Magnitude: 0.04724

Collected Steps per Second: 5,389.11579
Overall Steps per Second: 4,792.29828

Timestep Collection Time: 9.27870
Timestep Consumption Time: 1.15554
PPO Batch Consumption Time: 0.08570
Total Iteration Time: 10.43424

Cumulative Model Updates: 15,408
Cumulative Timesteps: 257,286,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 257286324...
Checkpoint 257286324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,263.06688
Policy Entropy: 0.51227
Value Function Loss: 0.09355

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.05544
Policy Update Magnitude: 0.02409
Value Function Update Magnitude: 0.04386

Collected Steps per Second: 5,370.93382
Overall Steps per Second: 4,795.34901

Timestep Collection Time: 9.31384
Timestep Consumption Time: 1.11794
PPO Batch Consumption Time: 0.08666
Total Iteration Time: 10.43177

Cumulative Model Updates: 15,411
Cumulative Timesteps: 257,336,348

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,273.58080
Policy Entropy: 0.51985
Value Function Loss: 0.08342

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04897
Policy Update Magnitude: 0.02272
Value Function Update Magnitude: 0.04764

Collected Steps per Second: 5,671.43841
Overall Steps per Second: 4,973.57637

Timestep Collection Time: 8.82563
Timestep Consumption Time: 1.23836
PPO Batch Consumption Time: 0.08363
Total Iteration Time: 10.06399

Cumulative Model Updates: 15,414
Cumulative Timesteps: 257,386,402

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 257386402...
Checkpoint 257386402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,094.11262
Policy Entropy: 0.51907
Value Function Loss: 0.08499

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.02320
Value Function Update Magnitude: 0.05060

Collected Steps per Second: 5,504.57900
Overall Steps per Second: 4,840.29331

Timestep Collection Time: 9.08335
Timestep Consumption Time: 1.24661
PPO Batch Consumption Time: 0.08387
Total Iteration Time: 10.32995

Cumulative Model Updates: 15,417
Cumulative Timesteps: 257,436,402

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,691.35655
Policy Entropy: 0.52240
Value Function Loss: 0.08196

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.06773
Policy Update Magnitude: 0.02427
Value Function Update Magnitude: 0.04718

Collected Steps per Second: 5,486.59702
Overall Steps per Second: 4,867.89200

Timestep Collection Time: 9.11603
Timestep Consumption Time: 1.15864
PPO Batch Consumption Time: 0.08670
Total Iteration Time: 10.27467

Cumulative Model Updates: 15,420
Cumulative Timesteps: 257,486,418

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 257486418...
Checkpoint 257486418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,611.81207
Policy Entropy: 0.51788
Value Function Loss: 0.09260

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.06009
Policy Update Magnitude: 0.02400
Value Function Update Magnitude: 0.04219

Collected Steps per Second: 5,501.23835
Overall Steps per Second: 4,836.45823

Timestep Collection Time: 9.09359
Timestep Consumption Time: 1.24993
PPO Batch Consumption Time: 0.08606
Total Iteration Time: 10.34352

Cumulative Model Updates: 15,423
Cumulative Timesteps: 257,536,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,990.24794
Policy Entropy: 0.51457
Value Function Loss: 0.10759

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.06105
Policy Update Magnitude: 0.02333
Value Function Update Magnitude: 0.04493

Collected Steps per Second: 5,407.34201
Overall Steps per Second: 4,825.34949

Timestep Collection Time: 9.24743
Timestep Consumption Time: 1.11535
PPO Batch Consumption Time: 0.08541
Total Iteration Time: 10.36277

Cumulative Model Updates: 15,426
Cumulative Timesteps: 257,586,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 257586448...
Checkpoint 257586448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,912.63210
Policy Entropy: 0.51514
Value Function Loss: 0.10379

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05661
Policy Update Magnitude: 0.02690
Value Function Update Magnitude: 0.06203

Collected Steps per Second: 5,493.10027
Overall Steps per Second: 4,911.02234

Timestep Collection Time: 9.10378
Timestep Consumption Time: 1.07902
PPO Batch Consumption Time: 0.08411
Total Iteration Time: 10.18281

Cumulative Model Updates: 15,429
Cumulative Timesteps: 257,636,456

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,163.06394
Policy Entropy: 0.51470
Value Function Loss: 0.08963

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.05814
Policy Update Magnitude: 0.02583
Value Function Update Magnitude: 0.07252

Collected Steps per Second: 5,445.17086
Overall Steps per Second: 4,826.86912

Timestep Collection Time: 9.18686
Timestep Consumption Time: 1.17680
PPO Batch Consumption Time: 0.07970
Total Iteration Time: 10.36365

Cumulative Model Updates: 15,432
Cumulative Timesteps: 257,686,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 257686480...
Checkpoint 257686480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,551.13445
Policy Entropy: 0.51482
Value Function Loss: 0.08071

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.05713
Policy Update Magnitude: 0.02232
Value Function Update Magnitude: 0.07357

Collected Steps per Second: 5,427.36885
Overall Steps per Second: 4,809.52262

Timestep Collection Time: 9.21809
Timestep Consumption Time: 1.18419
PPO Batch Consumption Time: 0.08838
Total Iteration Time: 10.40228

Cumulative Model Updates: 15,435
Cumulative Timesteps: 257,736,510

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,791.03378
Policy Entropy: 0.51157
Value Function Loss: 0.08752

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.04960
Policy Update Magnitude: 0.02328
Value Function Update Magnitude: 0.07559

Collected Steps per Second: 5,429.46642
Overall Steps per Second: 4,773.66300

Timestep Collection Time: 9.21048
Timestep Consumption Time: 1.26533
PPO Batch Consumption Time: 0.08920
Total Iteration Time: 10.47581

Cumulative Model Updates: 15,438
Cumulative Timesteps: 257,786,518

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 257786518...
Checkpoint 257786518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,486.53682
Policy Entropy: 0.51063
Value Function Loss: 0.09525

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.04190
Policy Update Magnitude: 0.02295
Value Function Update Magnitude: 0.07139

Collected Steps per Second: 5,409.44207
Overall Steps per Second: 4,809.51669

Timestep Collection Time: 9.24753
Timestep Consumption Time: 1.15351
PPO Batch Consumption Time: 0.08362
Total Iteration Time: 10.40105

Cumulative Model Updates: 15,441
Cumulative Timesteps: 257,836,542

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,654.03037
Policy Entropy: 0.50859
Value Function Loss: 0.10322

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.05127
Policy Update Magnitude: 0.02424
Value Function Update Magnitude: 0.07313

Collected Steps per Second: 5,538.03559
Overall Steps per Second: 4,877.85610

Timestep Collection Time: 9.03100
Timestep Consumption Time: 1.22227
PPO Batch Consumption Time: 0.08316
Total Iteration Time: 10.25328

Cumulative Model Updates: 15,444
Cumulative Timesteps: 257,886,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 257886556...
Checkpoint 257886556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,407.54189
Policy Entropy: 0.50580
Value Function Loss: 0.10609

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03353
Policy Update Magnitude: 0.02285
Value Function Update Magnitude: 0.08273

Collected Steps per Second: 5,430.31909
Overall Steps per Second: 4,817.85846

Timestep Collection Time: 9.21456
Timestep Consumption Time: 1.17138
PPO Batch Consumption Time: 0.08709
Total Iteration Time: 10.38594

Cumulative Model Updates: 15,447
Cumulative Timesteps: 257,936,594

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,901.06901
Policy Entropy: 0.50339
Value Function Loss: 0.10529

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02896
Policy Update Magnitude: 0.02467
Value Function Update Magnitude: 0.07561

Collected Steps per Second: 5,500.05926
Overall Steps per Second: 4,884.74108

Timestep Collection Time: 9.09481
Timestep Consumption Time: 1.14565
PPO Batch Consumption Time: 0.08814
Total Iteration Time: 10.24046

Cumulative Model Updates: 15,450
Cumulative Timesteps: 257,986,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 257986616...
Checkpoint 257986616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,973.18317
Policy Entropy: 0.51275
Value Function Loss: 0.09785

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.02539
Value Function Update Magnitude: 0.08356

Collected Steps per Second: 5,454.77662
Overall Steps per Second: 4,836.84844

Timestep Collection Time: 9.16774
Timestep Consumption Time: 1.17122
PPO Batch Consumption Time: 0.08617
Total Iteration Time: 10.33896

Cumulative Model Updates: 15,453
Cumulative Timesteps: 258,036,624

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,906.35898
Policy Entropy: 0.51062
Value Function Loss: 0.08862

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.01615
Policy Update Magnitude: 0.02671
Value Function Update Magnitude: 0.07464

Collected Steps per Second: 5,517.55380
Overall Steps per Second: 4,924.45659

Timestep Collection Time: 9.06634
Timestep Consumption Time: 1.09194
PPO Batch Consumption Time: 0.08333
Total Iteration Time: 10.15828

Cumulative Model Updates: 15,456
Cumulative Timesteps: 258,086,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 258086648...
Checkpoint 258086648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,354.82634
Policy Entropy: 0.51363
Value Function Loss: 0.08313

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01987
Policy Update Magnitude: 0.02405
Value Function Update Magnitude: 0.05957

Collected Steps per Second: 5,591.81205
Overall Steps per Second: 4,956.02870

Timestep Collection Time: 8.94486
Timestep Consumption Time: 1.14749
PPO Batch Consumption Time: 0.08673
Total Iteration Time: 10.09235

Cumulative Model Updates: 15,459
Cumulative Timesteps: 258,136,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,387.39850
Policy Entropy: 0.50999
Value Function Loss: 0.08946

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.02305
Value Function Update Magnitude: 0.05395

Collected Steps per Second: 5,586.17256
Overall Steps per Second: 4,971.90377

Timestep Collection Time: 8.95604
Timestep Consumption Time: 1.10650
PPO Batch Consumption Time: 0.08467
Total Iteration Time: 10.06254

Cumulative Model Updates: 15,462
Cumulative Timesteps: 258,186,696

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 258186696...
Checkpoint 258186696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,909.16291
Policy Entropy: 0.51379
Value Function Loss: 0.08807

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.02161
Value Function Update Magnitude: 0.05945

Collected Steps per Second: 5,385.85060
Overall Steps per Second: 4,805.09753

Timestep Collection Time: 9.28730
Timestep Consumption Time: 1.12248
PPO Batch Consumption Time: 0.08789
Total Iteration Time: 10.40978

Cumulative Model Updates: 15,465
Cumulative Timesteps: 258,236,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,804.38462
Policy Entropy: 0.50794
Value Function Loss: 0.09740

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02201
Policy Update Magnitude: 0.02270
Value Function Update Magnitude: 0.06743

Collected Steps per Second: 5,501.48705
Overall Steps per Second: 4,897.39502

Timestep Collection Time: 9.09209
Timestep Consumption Time: 1.12151
PPO Batch Consumption Time: 0.08791
Total Iteration Time: 10.21359

Cumulative Model Updates: 15,468
Cumulative Timesteps: 258,286,736

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 258286736...
Checkpoint 258286736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,253.42313
Policy Entropy: 0.51484
Value Function Loss: 0.09250

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.02423
Value Function Update Magnitude: 0.06694

Collected Steps per Second: 5,662.69941
Overall Steps per Second: 5,001.96196

Timestep Collection Time: 8.83042
Timestep Consumption Time: 1.16646
PPO Batch Consumption Time: 0.08739
Total Iteration Time: 9.99688

Cumulative Model Updates: 15,471
Cumulative Timesteps: 258,336,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,269.63069
Policy Entropy: 0.51517
Value Function Loss: 0.09743

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02868
Policy Update Magnitude: 0.02247
Value Function Update Magnitude: 0.06376

Collected Steps per Second: 5,700.74405
Overall Steps per Second: 5,037.65198

Timestep Collection Time: 8.77499
Timestep Consumption Time: 1.15503
PPO Batch Consumption Time: 0.09403
Total Iteration Time: 9.93002

Cumulative Model Updates: 15,474
Cumulative Timesteps: 258,386,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 258386764...
Checkpoint 258386764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,813.67139
Policy Entropy: 0.52247
Value Function Loss: 0.08872

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02020
Policy Update Magnitude: 0.02178
Value Function Update Magnitude: 0.06411

Collected Steps per Second: 5,663.74740
Overall Steps per Second: 5,006.52614

Timestep Collection Time: 8.83373
Timestep Consumption Time: 1.15963
PPO Batch Consumption Time: 0.08631
Total Iteration Time: 9.99336

Cumulative Model Updates: 15,477
Cumulative Timesteps: 258,436,796

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,106.27525
Policy Entropy: 0.52416
Value Function Loss: 0.09312

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01902
Policy Update Magnitude: 0.02300
Value Function Update Magnitude: 0.07131

Collected Steps per Second: 5,580.12172
Overall Steps per Second: 4,904.82493

Timestep Collection Time: 8.96468
Timestep Consumption Time: 1.23426
PPO Batch Consumption Time: 0.08462
Total Iteration Time: 10.19894

Cumulative Model Updates: 15,480
Cumulative Timesteps: 258,486,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 258486820...
Checkpoint 258486820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,883.54193
Policy Entropy: 0.52363
Value Function Loss: 0.09460

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.02343
Value Function Update Magnitude: 0.06908

Collected Steps per Second: 5,528.35376
Overall Steps per Second: 4,885.31458

Timestep Collection Time: 9.04609
Timestep Consumption Time: 1.19071
PPO Batch Consumption Time: 0.08787
Total Iteration Time: 10.23680

Cumulative Model Updates: 15,483
Cumulative Timesteps: 258,536,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,323.65556
Policy Entropy: 0.51801
Value Function Loss: 0.09768

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01737
Policy Update Magnitude: 0.02672
Value Function Update Magnitude: 0.07592

Collected Steps per Second: 5,669.22638
Overall Steps per Second: 5,034.82383

Timestep Collection Time: 8.82519
Timestep Consumption Time: 1.11200
PPO Batch Consumption Time: 0.08687
Total Iteration Time: 9.93719

Cumulative Model Updates: 15,486
Cumulative Timesteps: 258,586,862

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 258586862...
Checkpoint 258586862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,457.18298
Policy Entropy: 0.52364
Value Function Loss: 0.08786

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02042
Policy Update Magnitude: 0.02505
Value Function Update Magnitude: 0.07308

Collected Steps per Second: 5,546.20943
Overall Steps per Second: 4,942.50872

Timestep Collection Time: 9.02382
Timestep Consumption Time: 1.10221
PPO Batch Consumption Time: 0.08711
Total Iteration Time: 10.12603

Cumulative Model Updates: 15,489
Cumulative Timesteps: 258,636,910

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,884.09680
Policy Entropy: 0.52775
Value Function Loss: 0.08300

Mean KL Divergence: 0.00106
SB3 Clip Fraction: 0.00920
Policy Update Magnitude: 0.02228
Value Function Update Magnitude: 0.07168

Collected Steps per Second: 5,398.44333
Overall Steps per Second: 4,828.09081

Timestep Collection Time: 9.26378
Timestep Consumption Time: 1.09435
PPO Batch Consumption Time: 0.08750
Total Iteration Time: 10.35813

Cumulative Model Updates: 15,492
Cumulative Timesteps: 258,686,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 258686920...
Checkpoint 258686920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,248.11855
Policy Entropy: 0.53021
Value Function Loss: 0.08517

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.01027
Policy Update Magnitude: 0.02252
Value Function Update Magnitude: 0.06765

Collected Steps per Second: 5,473.42375
Overall Steps per Second: 4,945.14373

Timestep Collection Time: 9.14126
Timestep Consumption Time: 0.97654
PPO Batch Consumption Time: 0.08951
Total Iteration Time: 10.11781

Cumulative Model Updates: 15,495
Cumulative Timesteps: 258,736,954

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,621.40856
Policy Entropy: 0.52798
Value Function Loss: 0.08585

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01669
Policy Update Magnitude: 0.02434
Value Function Update Magnitude: 0.06830

Collected Steps per Second: 5,400.03624
Overall Steps per Second: 4,893.25703

Timestep Collection Time: 9.26512
Timestep Consumption Time: 0.95956
PPO Batch Consumption Time: 0.08399
Total Iteration Time: 10.22468

Cumulative Model Updates: 15,498
Cumulative Timesteps: 258,786,986

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 258786986...
Checkpoint 258786986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,413.98757
Policy Entropy: 0.52349
Value Function Loss: 0.08111

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02843
Policy Update Magnitude: 0.02534
Value Function Update Magnitude: 0.06058

Collected Steps per Second: 5,437.06083
Overall Steps per Second: 4,904.73246

Timestep Collection Time: 9.20056
Timestep Consumption Time: 0.99857
PPO Batch Consumption Time: 0.08950
Total Iteration Time: 10.19913

Cumulative Model Updates: 15,501
Cumulative Timesteps: 258,837,010

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,184.83405
Policy Entropy: 0.52322
Value Function Loss: 0.08023

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.04117
Policy Update Magnitude: 0.02278
Value Function Update Magnitude: 0.05290

Collected Steps per Second: 5,420.78758
Overall Steps per Second: 4,855.55732

Timestep Collection Time: 9.22560
Timestep Consumption Time: 1.07394
PPO Batch Consumption Time: 0.09506
Total Iteration Time: 10.29954

Cumulative Model Updates: 15,504
Cumulative Timesteps: 258,887,020

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 258887020...
Checkpoint 258887020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,968.16264
Policy Entropy: 0.52171
Value Function Loss: 0.08018

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.02494
Value Function Update Magnitude: 0.05694

Collected Steps per Second: 5,451.34539
Overall Steps per Second: 4,896.36191

Timestep Collection Time: 9.17828
Timestep Consumption Time: 1.04032
PPO Batch Consumption Time: 0.08723
Total Iteration Time: 10.21861

Cumulative Model Updates: 15,507
Cumulative Timesteps: 258,937,054

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,314.23727
Policy Entropy: 0.52464
Value Function Loss: 0.08678

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02707
Policy Update Magnitude: 0.02493
Value Function Update Magnitude: 0.06083

Collected Steps per Second: 5,448.88706
Overall Steps per Second: 4,892.15298

Timestep Collection Time: 9.18243
Timestep Consumption Time: 1.04497
PPO Batch Consumption Time: 0.09213
Total Iteration Time: 10.22740

Cumulative Model Updates: 15,510
Cumulative Timesteps: 258,987,088

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 258987088...
Checkpoint 258987088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,264.14127
Policy Entropy: 0.52876
Value Function Loss: 0.08482

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03349
Policy Update Magnitude: 0.02356
Value Function Update Magnitude: 0.05487

Collected Steps per Second: 5,438.02526
Overall Steps per Second: 4,872.22943

Timestep Collection Time: 9.19856
Timestep Consumption Time: 1.06820
PPO Batch Consumption Time: 0.09345
Total Iteration Time: 10.26676

Cumulative Model Updates: 15,513
Cumulative Timesteps: 259,037,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,894.52501
Policy Entropy: 0.52698
Value Function Loss: 0.08508

Mean KL Divergence: 0.00194
SB3 Clip Fraction: 0.02247
Policy Update Magnitude: 0.02175
Value Function Update Magnitude: 0.04938

Collected Steps per Second: 5,376.77639
Overall Steps per Second: 4,798.74441

Timestep Collection Time: 9.30372
Timestep Consumption Time: 1.12068
PPO Batch Consumption Time: 0.08592
Total Iteration Time: 10.42439

Cumulative Model Updates: 15,516
Cumulative Timesteps: 259,087,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 259087134...
Checkpoint 259087134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,391.06694
Policy Entropy: 0.52690
Value Function Loss: 0.08513

Mean KL Divergence: 0.00144
SB3 Clip Fraction: 0.01571
Policy Update Magnitude: 0.02283
Value Function Update Magnitude: 0.04777

Collected Steps per Second: 5,631.18506
Overall Steps per Second: 5,005.35754

Timestep Collection Time: 8.88019
Timestep Consumption Time: 1.11030
PPO Batch Consumption Time: 0.08641
Total Iteration Time: 9.99050

Cumulative Model Updates: 15,519
Cumulative Timesteps: 259,137,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,337.81967
Policy Entropy: 0.51725
Value Function Loss: 0.10804

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03661
Policy Update Magnitude: 0.02267
Value Function Update Magnitude: 0.04268

Collected Steps per Second: 5,465.41426
Overall Steps per Second: 4,854.71594

Timestep Collection Time: 9.15173
Timestep Consumption Time: 1.15124
PPO Batch Consumption Time: 0.08410
Total Iteration Time: 10.30297

Cumulative Model Updates: 15,522
Cumulative Timesteps: 259,187,158

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 259187158...
Checkpoint 259187158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,117.21944
Policy Entropy: 0.52351
Value Function Loss: 0.10569

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02314
Policy Update Magnitude: 0.02520
Value Function Update Magnitude: 0.03842

Collected Steps per Second: 5,427.31128
Overall Steps per Second: 4,821.62289

Timestep Collection Time: 9.22004
Timestep Consumption Time: 1.15821
PPO Batch Consumption Time: 0.08824
Total Iteration Time: 10.37825

Cumulative Model Updates: 15,525
Cumulative Timesteps: 259,237,198

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,712.92375
Policy Entropy: 0.52465
Value Function Loss: 0.10738

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.02774
Value Function Update Magnitude: 0.04330

Collected Steps per Second: 5,307.64135
Overall Steps per Second: 4,739.20741

Timestep Collection Time: 9.42528
Timestep Consumption Time: 1.13049
PPO Batch Consumption Time: 0.08659
Total Iteration Time: 10.55577

Cumulative Model Updates: 15,528
Cumulative Timesteps: 259,287,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 259287224...
Checkpoint 259287224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,413.38133
Policy Entropy: 0.53485
Value Function Loss: 0.08557

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.04175
Policy Update Magnitude: 0.02853
Value Function Update Magnitude: 0.04730

Collected Steps per Second: 5,422.91800
Overall Steps per Second: 4,831.51698

Timestep Collection Time: 9.22382
Timestep Consumption Time: 1.12904
PPO Batch Consumption Time: 0.08312
Total Iteration Time: 10.35286

Cumulative Model Updates: 15,531
Cumulative Timesteps: 259,337,244

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,689.43415
Policy Entropy: 0.52466
Value Function Loss: 0.09169

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.02913
Policy Update Magnitude: 0.02715
Value Function Update Magnitude: 0.04278

Collected Steps per Second: 5,556.13501
Overall Steps per Second: 4,930.85856

Timestep Collection Time: 9.00662
Timestep Consumption Time: 1.14212
PPO Batch Consumption Time: 0.08971
Total Iteration Time: 10.14874

Cumulative Model Updates: 15,534
Cumulative Timesteps: 259,387,286

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 259387286...
Checkpoint 259387286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,493.63394
Policy Entropy: 0.52373
Value Function Loss: 0.09069

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02413
Policy Update Magnitude: 0.02740
Value Function Update Magnitude: 0.04841

Collected Steps per Second: 5,574.28919
Overall Steps per Second: 4,953.47881

Timestep Collection Time: 8.96975
Timestep Consumption Time: 1.12416
PPO Batch Consumption Time: 0.09048
Total Iteration Time: 10.09392

Cumulative Model Updates: 15,537
Cumulative Timesteps: 259,437,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,373.83912
Policy Entropy: 0.51749
Value Function Loss: 0.10254

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01515
Policy Update Magnitude: 0.02880
Value Function Update Magnitude: 0.05008

Collected Steps per Second: 5,368.46320
Overall Steps per Second: 4,795.82598

Timestep Collection Time: 9.31552
Timestep Consumption Time: 1.11230
PPO Batch Consumption Time: 0.08436
Total Iteration Time: 10.42782

Cumulative Model Updates: 15,540
Cumulative Timesteps: 259,487,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 259487296...
Checkpoint 259487296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,802.56956
Policy Entropy: 0.51835
Value Function Loss: 0.09996

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 0.02746
Value Function Update Magnitude: 0.05945

Collected Steps per Second: 5,469.44717
Overall Steps per Second: 4,850.33457

Timestep Collection Time: 9.14315
Timestep Consumption Time: 1.16706
PPO Batch Consumption Time: 0.08676
Total Iteration Time: 10.31022

Cumulative Model Updates: 15,543
Cumulative Timesteps: 259,537,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,555.57833
Policy Entropy: 0.52260
Value Function Loss: 0.09804

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04461
Policy Update Magnitude: 0.02542
Value Function Update Magnitude: 0.05156

Collected Steps per Second: 5,508.31387
Overall Steps per Second: 4,903.22157

Timestep Collection Time: 9.08009
Timestep Consumption Time: 1.12055
PPO Batch Consumption Time: 0.08503
Total Iteration Time: 10.20064

Cumulative Model Updates: 15,546
Cumulative Timesteps: 259,587,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 259587320...
Checkpoint 259587320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,563.16966
Policy Entropy: 0.52487
Value Function Loss: 0.08760

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03497
Policy Update Magnitude: 0.02311
Value Function Update Magnitude: 0.04953

Collected Steps per Second: 5,612.50710
Overall Steps per Second: 4,991.81547

Timestep Collection Time: 8.90867
Timestep Consumption Time: 1.10772
PPO Batch Consumption Time: 0.08269
Total Iteration Time: 10.01640

Cumulative Model Updates: 15,549
Cumulative Timesteps: 259,637,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,516.86982
Policy Entropy: 0.52610
Value Function Loss: 0.08000

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05607
Policy Update Magnitude: 0.02407
Value Function Update Magnitude: 0.05466

Collected Steps per Second: 5,424.30066
Overall Steps per Second: 4,797.30692

Timestep Collection Time: 9.21999
Timestep Consumption Time: 1.20503
PPO Batch Consumption Time: 0.08856
Total Iteration Time: 10.42502

Cumulative Model Updates: 15,552
Cumulative Timesteps: 259,687,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 259687332...
Checkpoint 259687332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,673.53212
Policy Entropy: 0.52534
Value Function Loss: 0.08078

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03606
Policy Update Magnitude: 0.02343
Value Function Update Magnitude: 0.05137

Collected Steps per Second: 5,671.48364
Overall Steps per Second: 5,015.32528

Timestep Collection Time: 8.81604
Timestep Consumption Time: 1.15341
PPO Batch Consumption Time: 0.08626
Total Iteration Time: 9.96944

Cumulative Model Updates: 15,555
Cumulative Timesteps: 259,737,332

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,810.08904
Policy Entropy: 0.52375
Value Function Loss: 0.09338

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.03893
Policy Update Magnitude: 0.02537
Value Function Update Magnitude: 0.04547

Collected Steps per Second: 5,817.91589
Overall Steps per Second: 5,151.98277

Timestep Collection Time: 8.59827
Timestep Consumption Time: 1.11139
PPO Batch Consumption Time: 0.09056
Total Iteration Time: 9.70966

Cumulative Model Updates: 15,558
Cumulative Timesteps: 259,787,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 259787356...
Checkpoint 259787356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,599.79662
Policy Entropy: 0.52022
Value Function Loss: 0.09220

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04676
Policy Update Magnitude: 0.02471
Value Function Update Magnitude: 0.05946

Collected Steps per Second: 5,585.57595
Overall Steps per Second: 4,961.89453

Timestep Collection Time: 8.95306
Timestep Consumption Time: 1.12535
PPO Batch Consumption Time: 0.09456
Total Iteration Time: 10.07841

Cumulative Model Updates: 15,561
Cumulative Timesteps: 259,837,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,163.44501
Policy Entropy: 0.51413
Value Function Loss: 0.08971

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.04231
Policy Update Magnitude: 0.02485
Value Function Update Magnitude: 0.05465

Collected Steps per Second: 5,537.96450
Overall Steps per Second: 4,899.30483

Timestep Collection Time: 9.03003
Timestep Consumption Time: 1.17713
PPO Batch Consumption Time: 0.09767
Total Iteration Time: 10.20716

Cumulative Model Updates: 15,564
Cumulative Timesteps: 259,887,372

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 259887372...
Checkpoint 259887372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,256.23281
Policy Entropy: 0.52148
Value Function Loss: 0.07947

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 0.02326
Value Function Update Magnitude: 0.04388

Collected Steps per Second: 5,493.03427
Overall Steps per Second: 4,879.11119

Timestep Collection Time: 9.10280
Timestep Consumption Time: 1.14538
PPO Batch Consumption Time: 0.08324
Total Iteration Time: 10.24818

Cumulative Model Updates: 15,567
Cumulative Timesteps: 259,937,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,495.64898
Policy Entropy: 0.52824
Value Function Loss: 0.08178

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04855
Policy Update Magnitude: 0.02252
Value Function Update Magnitude: 0.04594

Collected Steps per Second: 5,417.88233
Overall Steps per Second: 4,810.36878

Timestep Collection Time: 9.23313
Timestep Consumption Time: 1.16607
PPO Batch Consumption Time: 0.08583
Total Iteration Time: 10.39920

Cumulative Model Updates: 15,570
Cumulative Timesteps: 259,987,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 259987398...
Checkpoint 259987398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,664.71759
Policy Entropy: 0.53148
Value Function Loss: 0.08141

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.05347
Policy Update Magnitude: 0.02250
Value Function Update Magnitude: 0.04039

Collected Steps per Second: 5,419.30103
Overall Steps per Second: 4,815.27127

Timestep Collection Time: 9.23293
Timestep Consumption Time: 1.15818
PPO Batch Consumption Time: 0.08978
Total Iteration Time: 10.39111

Cumulative Model Updates: 15,573
Cumulative Timesteps: 260,037,434

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,378.12200
Policy Entropy: 0.52677
Value Function Loss: 0.08963

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03735
Policy Update Magnitude: 0.02350
Value Function Update Magnitude: 0.03966

Collected Steps per Second: 5,713.36466
Overall Steps per Second: 5,057.08685

Timestep Collection Time: 8.75456
Timestep Consumption Time: 1.13611
PPO Batch Consumption Time: 0.08615
Total Iteration Time: 9.89067

Cumulative Model Updates: 15,576
Cumulative Timesteps: 260,087,452

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 260087452...
Checkpoint 260087452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,312.65261
Policy Entropy: 0.52004
Value Function Loss: 0.09072

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.06188
Policy Update Magnitude: 0.02429
Value Function Update Magnitude: 0.03914

Collected Steps per Second: 5,660.82079
Overall Steps per Second: 5,011.93047

Timestep Collection Time: 8.83299
Timestep Consumption Time: 1.14360
PPO Batch Consumption Time: 0.08403
Total Iteration Time: 9.97659

Cumulative Model Updates: 15,579
Cumulative Timesteps: 260,137,454

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,963.71899
Policy Entropy: 0.52306
Value Function Loss: 0.09308

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04440
Policy Update Magnitude: 0.02482
Value Function Update Magnitude: 0.04069

Collected Steps per Second: 5,654.95998
Overall Steps per Second: 4,988.29799

Timestep Collection Time: 8.84250
Timestep Consumption Time: 1.18176
PPO Batch Consumption Time: 0.08848
Total Iteration Time: 10.02426

Cumulative Model Updates: 15,582
Cumulative Timesteps: 260,187,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 260187458...
Checkpoint 260187458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,625.89753
Policy Entropy: 0.52311
Value Function Loss: 0.07779

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.05041
Policy Update Magnitude: 0.02334
Value Function Update Magnitude: 0.03813

Collected Steps per Second: 5,875.52706
Overall Steps per Second: 5,168.38101

Timestep Collection Time: 8.51396
Timestep Consumption Time: 1.16489
PPO Batch Consumption Time: 0.09413
Total Iteration Time: 9.67885

Cumulative Model Updates: 15,585
Cumulative Timesteps: 260,237,482

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,028.74801
Policy Entropy: 0.52536
Value Function Loss: 0.08629

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07923
Policy Update Magnitude: 0.02137
Value Function Update Magnitude: 0.04134

Collected Steps per Second: 5,823.65887
Overall Steps per Second: 5,119.81059

Timestep Collection Time: 8.58670
Timestep Consumption Time: 1.18046
PPO Batch Consumption Time: 0.08719
Total Iteration Time: 9.76716

Cumulative Model Updates: 15,588
Cumulative Timesteps: 260,287,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 260287488...
Checkpoint 260287488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,271.32320
Policy Entropy: 0.52724
Value Function Loss: 0.07830

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.01924
Value Function Update Magnitude: 0.03815

Collected Steps per Second: 5,593.50701
Overall Steps per Second: 4,971.80125

Timestep Collection Time: 8.93965
Timestep Consumption Time: 1.11787
PPO Batch Consumption Time: 0.08338
Total Iteration Time: 10.05752

Cumulative Model Updates: 15,591
Cumulative Timesteps: 260,337,492

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,322.76002
Policy Entropy: 0.52273
Value Function Loss: 0.09180

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.06189
Policy Update Magnitude: 0.02036
Value Function Update Magnitude: 0.04100

Collected Steps per Second: 5,642.38568
Overall Steps per Second: 4,962.22908

Timestep Collection Time: 8.86753
Timestep Consumption Time: 1.21544
PPO Batch Consumption Time: 0.09069
Total Iteration Time: 10.08297

Cumulative Model Updates: 15,594
Cumulative Timesteps: 260,387,526

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 260387526...
Checkpoint 260387526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,927.35482
Policy Entropy: 0.52564
Value Function Loss: 0.07853

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04641
Policy Update Magnitude: 0.02343
Value Function Update Magnitude: 0.03965

Collected Steps per Second: 5,603.34972
Overall Steps per Second: 4,952.16259

Timestep Collection Time: 8.92359
Timestep Consumption Time: 1.17341
PPO Batch Consumption Time: 0.08416
Total Iteration Time: 10.09700

Cumulative Model Updates: 15,597
Cumulative Timesteps: 260,437,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,657.18225
Policy Entropy: 0.53028
Value Function Loss: 0.07524

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04995
Policy Update Magnitude: 0.02306
Value Function Update Magnitude: 0.04379

Collected Steps per Second: 5,565.49482
Overall Steps per Second: 4,948.17602

Timestep Collection Time: 8.98429
Timestep Consumption Time: 1.12085
PPO Batch Consumption Time: 0.08631
Total Iteration Time: 10.10514

Cumulative Model Updates: 15,600
Cumulative Timesteps: 260,487,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 260487530...
Checkpoint 260487530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,970.00205
Policy Entropy: 0.53101
Value Function Loss: 0.06846

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.04000
Policy Update Magnitude: 0.02198
Value Function Update Magnitude: 0.03821

Collected Steps per Second: 5,541.45577
Overall Steps per Second: 4,920.92390

Timestep Collection Time: 9.02795
Timestep Consumption Time: 1.13843
PPO Batch Consumption Time: 0.08646
Total Iteration Time: 10.16638

Cumulative Model Updates: 15,603
Cumulative Timesteps: 260,537,558

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,971.00251
Policy Entropy: 0.53219
Value Function Loss: 0.07905

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.04547
Policy Update Magnitude: 0.02176
Value Function Update Magnitude: 0.04508

Collected Steps per Second: 5,528.24624
Overall Steps per Second: 4,954.20887

Timestep Collection Time: 9.05025
Timestep Consumption Time: 1.04864
PPO Batch Consumption Time: 0.08479
Total Iteration Time: 10.09889

Cumulative Model Updates: 15,606
Cumulative Timesteps: 260,587,590

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 260587590...
Checkpoint 260587590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,473.48231
Policy Entropy: 0.53293
Value Function Loss: 0.07878

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03951
Policy Update Magnitude: 0.02155
Value Function Update Magnitude: 0.05150

Collected Steps per Second: 5,435.64626
Overall Steps per Second: 4,885.00120

Timestep Collection Time: 9.20259
Timestep Consumption Time: 1.03733
PPO Batch Consumption Time: 0.08593
Total Iteration Time: 10.23992

Cumulative Model Updates: 15,609
Cumulative Timesteps: 260,637,612

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,397.66322
Policy Entropy: 0.53928
Value Function Loss: 0.07850

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03921
Policy Update Magnitude: 0.02308
Value Function Update Magnitude: 0.05190

Collected Steps per Second: 5,509.11198
Overall Steps per Second: 4,937.52819

Timestep Collection Time: 9.08023
Timestep Consumption Time: 1.05116
PPO Batch Consumption Time: 0.08459
Total Iteration Time: 10.13139

Cumulative Model Updates: 15,612
Cumulative Timesteps: 260,687,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 260687636...
Checkpoint 260687636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,682.23973
Policy Entropy: 0.53587
Value Function Loss: 0.07858

Mean KL Divergence: 0.00165
SB3 Clip Fraction: 0.01683
Policy Update Magnitude: 0.02350
Value Function Update Magnitude: 0.04882

Collected Steps per Second: 5,406.07795
Overall Steps per Second: 4,780.51183

Timestep Collection Time: 9.25329
Timestep Consumption Time: 1.21086
PPO Batch Consumption Time: 0.09084
Total Iteration Time: 10.46415

Cumulative Model Updates: 15,615
Cumulative Timesteps: 260,737,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,352.97204
Policy Entropy: 0.53301
Value Function Loss: 0.08862

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.02036
Policy Update Magnitude: 0.02780
Value Function Update Magnitude: 0.04277

Collected Steps per Second: 5,552.42544
Overall Steps per Second: 4,938.06414

Timestep Collection Time: 9.01192
Timestep Consumption Time: 1.12120
PPO Batch Consumption Time: 0.08457
Total Iteration Time: 10.13312

Cumulative Model Updates: 15,618
Cumulative Timesteps: 260,787,698

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 260787698...
Checkpoint 260787698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,770.34845
Policy Entropy: 0.52966
Value Function Loss: 0.08567

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02245
Policy Update Magnitude: 0.02753
Value Function Update Magnitude: 0.05462

Collected Steps per Second: 5,444.56109
Overall Steps per Second: 4,814.22782

Timestep Collection Time: 9.18899
Timestep Consumption Time: 1.20313
PPO Batch Consumption Time: 0.08827
Total Iteration Time: 10.39211

Cumulative Model Updates: 15,621
Cumulative Timesteps: 260,837,728

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,773.19053
Policy Entropy: 0.53169
Value Function Loss: 0.08266

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03133
Policy Update Magnitude: 0.02555
Value Function Update Magnitude: 0.04809

Collected Steps per Second: 5,501.09123
Overall Steps per Second: 4,900.56372

Timestep Collection Time: 9.09274
Timestep Consumption Time: 1.11425
PPO Batch Consumption Time: 0.08380
Total Iteration Time: 10.20699

Cumulative Model Updates: 15,624
Cumulative Timesteps: 260,887,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 260887748...
Checkpoint 260887748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,654.84905
Policy Entropy: 0.52250
Value Function Loss: 0.09377

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.04021
Policy Update Magnitude: 0.02565
Value Function Update Magnitude: 0.04132

Collected Steps per Second: 5,515.17202
Overall Steps per Second: 4,863.83768

Timestep Collection Time: 9.07134
Timestep Consumption Time: 1.21478
PPO Batch Consumption Time: 0.08827
Total Iteration Time: 10.28612

Cumulative Model Updates: 15,627
Cumulative Timesteps: 260,937,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,482.08293
Policy Entropy: 0.51635
Value Function Loss: 0.09920

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05224
Policy Update Magnitude: 0.02541
Value Function Update Magnitude: 0.04283

Collected Steps per Second: 7,620.59401
Overall Steps per Second: 6,544.63194

Timestep Collection Time: 6.56274
Timestep Consumption Time: 1.07894
PPO Batch Consumption Time: 0.05574
Total Iteration Time: 7.64168

Cumulative Model Updates: 15,630
Cumulative Timesteps: 260,987,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 260987790...
Checkpoint 260987790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,612.68958
Policy Entropy: 0.50939
Value Function Loss: 0.10810

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04777
Policy Update Magnitude: 0.02316
Value Function Update Magnitude: 0.03997

Collected Steps per Second: 5,398.46433
Overall Steps per Second: 4,729.42459

Timestep Collection Time: 9.26486
Timestep Consumption Time: 1.31064
PPO Batch Consumption Time: 0.08882
Total Iteration Time: 10.57549

Cumulative Model Updates: 15,633
Cumulative Timesteps: 261,037,806

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,536.93469
Policy Entropy: 0.51197
Value Function Loss: 0.10149

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05498
Policy Update Magnitude: 0.02687
Value Function Update Magnitude: 0.04639

Collected Steps per Second: 5,421.79431
Overall Steps per Second: 4,792.04477

Timestep Collection Time: 9.22720
Timestep Consumption Time: 1.21260
PPO Batch Consumption Time: 0.08636
Total Iteration Time: 10.43980

Cumulative Model Updates: 15,636
Cumulative Timesteps: 261,087,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 261087834...
Checkpoint 261087834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,167.32813
Policy Entropy: 0.50755
Value Function Loss: 0.10949

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05667
Policy Update Magnitude: 0.02758
Value Function Update Magnitude: 0.04503

Collected Steps per Second: 5,533.28355
Overall Steps per Second: 4,908.25250

Timestep Collection Time: 9.04382
Timestep Consumption Time: 1.15167
PPO Batch Consumption Time: 0.08468
Total Iteration Time: 10.19548

Cumulative Model Updates: 15,639
Cumulative Timesteps: 261,137,876

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,614.16696
Policy Entropy: 0.50788
Value Function Loss: 0.11072

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05987
Policy Update Magnitude: 0.02611
Value Function Update Magnitude: 0.04913

Collected Steps per Second: 5,641.79756
Overall Steps per Second: 4,999.40044

Timestep Collection Time: 8.86632
Timestep Consumption Time: 1.13928
PPO Batch Consumption Time: 0.08529
Total Iteration Time: 10.00560

Cumulative Model Updates: 15,642
Cumulative Timesteps: 261,187,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 261187898...
Checkpoint 261187898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,839.29145
Policy Entropy: 0.51233
Value Function Loss: 0.10746

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.06200
Policy Update Magnitude: 0.02575
Value Function Update Magnitude: 0.04997

Collected Steps per Second: 5,560.98925
Overall Steps per Second: 4,955.68540

Timestep Collection Time: 8.99480
Timestep Consumption Time: 1.09866
PPO Batch Consumption Time: 0.08390
Total Iteration Time: 10.09346

Cumulative Model Updates: 15,645
Cumulative Timesteps: 261,237,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,188.39438
Policy Entropy: 0.51962
Value Function Loss: 0.09860

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05829
Policy Update Magnitude: 0.02482
Value Function Update Magnitude: 0.05189

Collected Steps per Second: 5,435.20730
Overall Steps per Second: 4,839.31061

Timestep Collection Time: 9.20480
Timestep Consumption Time: 1.13345
PPO Batch Consumption Time: 0.08948
Total Iteration Time: 10.33825

Cumulative Model Updates: 15,648
Cumulative Timesteps: 261,287,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 261287948...
Checkpoint 261287948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,037.98454
Policy Entropy: 0.52244
Value Function Loss: 0.08886

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05733
Policy Update Magnitude: 0.02415
Value Function Update Magnitude: 0.04607

Collected Steps per Second: 5,500.01193
Overall Steps per Second: 4,896.52740

Timestep Collection Time: 9.09416
Timestep Consumption Time: 1.12083
PPO Batch Consumption Time: 0.08627
Total Iteration Time: 10.21499

Cumulative Model Updates: 15,651
Cumulative Timesteps: 261,337,966

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,528.68910
Policy Entropy: 0.51765
Value Function Loss: 0.08729

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.05621
Policy Update Magnitude: 0.02166
Value Function Update Magnitude: 0.04618

Collected Steps per Second: 5,484.56262
Overall Steps per Second: 4,869.59545

Timestep Collection Time: 9.11686
Timestep Consumption Time: 1.15134
PPO Batch Consumption Time: 0.08872
Total Iteration Time: 10.26820

Cumulative Model Updates: 15,654
Cumulative Timesteps: 261,387,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 261387968...
Checkpoint 261387968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,103.53262
Policy Entropy: 0.51603
Value Function Loss: 0.07742

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04121
Policy Update Magnitude: 0.02203
Value Function Update Magnitude: 0.04118

Collected Steps per Second: 5,906.80793
Overall Steps per Second: 5,204.03709

Timestep Collection Time: 8.47124
Timestep Consumption Time: 1.14399
PPO Batch Consumption Time: 0.08699
Total Iteration Time: 9.61523

Cumulative Model Updates: 15,657
Cumulative Timesteps: 261,438,006

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,602.41203
Policy Entropy: 0.51806
Value Function Loss: 0.07478

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04277
Policy Update Magnitude: 0.02384
Value Function Update Magnitude: 0.03885

Collected Steps per Second: 6,035.36521
Overall Steps per Second: 5,367.92539

Timestep Collection Time: 8.28450
Timestep Consumption Time: 1.03008
PPO Batch Consumption Time: 0.08781
Total Iteration Time: 9.31459

Cumulative Model Updates: 15,660
Cumulative Timesteps: 261,488,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 261488006...
Checkpoint 261488006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,873.56472
Policy Entropy: 0.51792
Value Function Loss: 0.07912

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04958
Policy Update Magnitude: 0.02498
Value Function Update Magnitude: 0.03536

Collected Steps per Second: 8,027.46836
Overall Steps per Second: 7,095.52054

Timestep Collection Time: 6.23210
Timestep Consumption Time: 0.81854
PPO Batch Consumption Time: 0.03607
Total Iteration Time: 7.05065

Cumulative Model Updates: 15,663
Cumulative Timesteps: 261,538,034

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,260.20458
Policy Entropy: 0.52161
Value Function Loss: 0.08408

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.05258
Policy Update Magnitude: 0.02394
Value Function Update Magnitude: 0.03728

Collected Steps per Second: 16,945.61018
Overall Steps per Second: 12,750.07392

Timestep Collection Time: 2.95121
Timestep Consumption Time: 0.97112
PPO Batch Consumption Time: 0.05229
Total Iteration Time: 3.92233

Cumulative Model Updates: 15,666
Cumulative Timesteps: 261,588,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 261588044...
Checkpoint 261588044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,875.93418
Policy Entropy: 0.52422
Value Function Loss: 0.08510

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05271
Policy Update Magnitude: 0.02422
Value Function Update Magnitude: 0.03799

Collected Steps per Second: 8,778.37338
Overall Steps per Second: 7,595.29795

Timestep Collection Time: 5.70106
Timestep Consumption Time: 0.88802
PPO Batch Consumption Time: 0.05560
Total Iteration Time: 6.58908

Cumulative Model Updates: 15,669
Cumulative Timesteps: 261,638,090

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,379.31248
Policy Entropy: 0.52725
Value Function Loss: 0.07979

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03783
Policy Update Magnitude: 0.02378
Value Function Update Magnitude: 0.04270

Collected Steps per Second: 16,910.67612
Overall Steps per Second: 12,624.54176

Timestep Collection Time: 2.95730
Timestep Consumption Time: 1.00403
PPO Batch Consumption Time: 0.05448
Total Iteration Time: 3.96133

Cumulative Model Updates: 15,672
Cumulative Timesteps: 261,688,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 261688100...
Checkpoint 261688100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,556.93801
Policy Entropy: 0.50799
Value Function Loss: 0.08334

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02689
Policy Update Magnitude: 0.02396
Value Function Update Magnitude: 0.04000

Collected Steps per Second: 16,956.36561
Overall Steps per Second: 13,276.78266

Timestep Collection Time: 2.94898
Timestep Consumption Time: 0.81729
PPO Batch Consumption Time: 0.04497
Total Iteration Time: 3.76627

Cumulative Model Updates: 15,675
Cumulative Timesteps: 261,738,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,913.56965
Policy Entropy: 0.50724
Value Function Loss: 0.07414

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02692
Policy Update Magnitude: 0.02317
Value Function Update Magnitude: 0.05332

Collected Steps per Second: 20,878.00260
Overall Steps per Second: 14,480.47139

Timestep Collection Time: 2.39506
Timestep Consumption Time: 1.05815
PPO Batch Consumption Time: 0.03699
Total Iteration Time: 3.45320

Cumulative Model Updates: 15,678
Cumulative Timesteps: 261,788,108

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 261788108...
Checkpoint 261788108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,222.00773
Policy Entropy: 0.50343
Value Function Loss: 0.07133

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.02183
Policy Update Magnitude: 0.02219
Value Function Update Magnitude: 0.05419

Collected Steps per Second: 18,635.23184
Overall Steps per Second: 14,373.99535

Timestep Collection Time: 2.68502
Timestep Consumption Time: 0.79599
PPO Batch Consumption Time: 0.04539
Total Iteration Time: 3.48101

Cumulative Model Updates: 15,681
Cumulative Timesteps: 261,838,144

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,069.40389
Policy Entropy: 0.51211
Value Function Loss: 0.06622

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.02154
Value Function Update Magnitude: 0.04573

Collected Steps per Second: 19,932.12491
Overall Steps per Second: 14,107.75861

Timestep Collection Time: 2.50881
Timestep Consumption Time: 1.03576
PPO Batch Consumption Time: 0.11951
Total Iteration Time: 3.54457

Cumulative Model Updates: 15,684
Cumulative Timesteps: 261,888,150

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 261888150...
Checkpoint 261888150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,881.18969
Policy Entropy: 0.51327
Value Function Loss: 0.07129

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02455
Policy Update Magnitude: 0.02219
Value Function Update Magnitude: 0.03897

Collected Steps per Second: 18,535.99771
Overall Steps per Second: 13,288.19666

Timestep Collection Time: 2.69961
Timestep Consumption Time: 1.06614
PPO Batch Consumption Time: 0.12635
Total Iteration Time: 3.76575

Cumulative Model Updates: 15,687
Cumulative Timesteps: 261,938,190

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,897.41505
Policy Entropy: 0.50934
Value Function Loss: 0.08103

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02180
Policy Update Magnitude: 0.02193
Value Function Update Magnitude: 0.03894

Collected Steps per Second: 20,253.27936
Overall Steps per Second: 13,653.78346

Timestep Collection Time: 2.46992
Timestep Consumption Time: 1.19383
PPO Batch Consumption Time: 0.16544
Total Iteration Time: 3.66375

Cumulative Model Updates: 15,690
Cumulative Timesteps: 261,988,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 261988214...
Checkpoint 261988214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,304.42723
Policy Entropy: 0.50923
Value Function Loss: 0.09262

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.02114
Value Function Update Magnitude: 0.03890

Collected Steps per Second: 13,801.97885
Overall Steps per Second: 10,705.87594

Timestep Collection Time: 3.62412
Timestep Consumption Time: 1.04808
PPO Batch Consumption Time: 0.09304
Total Iteration Time: 4.67220

Cumulative Model Updates: 15,693
Cumulative Timesteps: 262,038,234

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,204.41797
Policy Entropy: 0.50669
Value Function Loss: 0.09247

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02503
Policy Update Magnitude: 0.02253
Value Function Update Magnitude: 0.04422

Collected Steps per Second: 12,693.90997
Overall Steps per Second: 9,745.97436

Timestep Collection Time: 3.94173
Timestep Consumption Time: 1.19228
PPO Batch Consumption Time: 0.08088
Total Iteration Time: 5.13402

Cumulative Model Updates: 15,696
Cumulative Timesteps: 262,088,270

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 262088270...
Checkpoint 262088270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,745.47816
Policy Entropy: 0.50729
Value Function Loss: 0.08500

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01921
Policy Update Magnitude: 0.02314
Value Function Update Magnitude: 0.04094

Collected Steps per Second: 12,782.38528
Overall Steps per Second: 10,055.00009

Timestep Collection Time: 3.91476
Timestep Consumption Time: 1.06187
PPO Batch Consumption Time: 0.09449
Total Iteration Time: 4.97663

Cumulative Model Updates: 15,699
Cumulative Timesteps: 262,138,310

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,352.67435
Policy Entropy: 0.50733
Value Function Loss: 0.08055

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.02268
Value Function Update Magnitude: 0.04742

Collected Steps per Second: 12,897.38278
Overall Steps per Second: 9,978.17158

Timestep Collection Time: 3.87846
Timestep Consumption Time: 1.13468
PPO Batch Consumption Time: 0.08294
Total Iteration Time: 5.01314

Cumulative Model Updates: 15,702
Cumulative Timesteps: 262,188,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 262188332...
Checkpoint 262188332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,318.72220
Policy Entropy: 0.51038
Value Function Loss: 0.08785

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.02193
Value Function Update Magnitude: 0.04524

Collected Steps per Second: 6,867.13307
Overall Steps per Second: 5,877.46362

Timestep Collection Time: 7.28688
Timestep Consumption Time: 1.22699
PPO Batch Consumption Time: 0.08796
Total Iteration Time: 8.51388

Cumulative Model Updates: 15,705
Cumulative Timesteps: 262,238,372

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,408.30140
Policy Entropy: 0.51645
Value Function Loss: 0.08612

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02173
Policy Update Magnitude: 0.02460
Value Function Update Magnitude: 0.05209

Collected Steps per Second: 5,614.72718
Overall Steps per Second: 5,042.31256

Timestep Collection Time: 8.90586
Timestep Consumption Time: 1.01101
PPO Batch Consumption Time: 0.08758
Total Iteration Time: 9.91688

Cumulative Model Updates: 15,708
Cumulative Timesteps: 262,288,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 262288376...
Checkpoint 262288376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,422.02814
Policy Entropy: 0.52427
Value Function Loss: 0.08069

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02586
Policy Update Magnitude: 0.02461
Value Function Update Magnitude: 0.05974

Collected Steps per Second: 5,391.71743
Overall Steps per Second: 4,873.38392

Timestep Collection Time: 9.27905
Timestep Consumption Time: 0.98692
PPO Batch Consumption Time: 0.08745
Total Iteration Time: 10.26597

Cumulative Model Updates: 15,711
Cumulative Timesteps: 262,338,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,020.28927
Policy Entropy: 0.52596
Value Function Loss: 0.07307

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02347
Policy Update Magnitude: 0.02418
Value Function Update Magnitude: 0.04914

Collected Steps per Second: 5,597.37982
Overall Steps per Second: 5,002.59719

Timestep Collection Time: 8.93382
Timestep Consumption Time: 1.06218
PPO Batch Consumption Time: 0.08335
Total Iteration Time: 9.99601

Cumulative Model Updates: 15,714
Cumulative Timesteps: 262,388,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 262388412...
Checkpoint 262388412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,462.15701
Policy Entropy: 0.52809
Value Function Loss: 0.07285

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.02254
Value Function Update Magnitude: 0.04571

Collected Steps per Second: 5,449.08265
Overall Steps per Second: 4,879.88781

Timestep Collection Time: 9.17989
Timestep Consumption Time: 1.07075
PPO Batch Consumption Time: 0.08442
Total Iteration Time: 10.25065

Cumulative Model Updates: 15,717
Cumulative Timesteps: 262,438,434

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,663.71496
Policy Entropy: 0.52828
Value Function Loss: 0.07519

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.02176
Value Function Update Magnitude: 0.04340

Collected Steps per Second: 5,337.83710
Overall Steps per Second: 4,773.46983

Timestep Collection Time: 9.36709
Timestep Consumption Time: 1.10747
PPO Batch Consumption Time: 0.08645
Total Iteration Time: 10.47456

Cumulative Model Updates: 15,720
Cumulative Timesteps: 262,488,434

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 262488434...
Checkpoint 262488434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,287.52561
Policy Entropy: 0.53186
Value Function Loss: 0.07246

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02975
Policy Update Magnitude: 0.02127
Value Function Update Magnitude: 0.04442

Collected Steps per Second: 5,476.06407
Overall Steps per Second: 4,889.04865

Timestep Collection Time: 9.13284
Timestep Consumption Time: 1.09656
PPO Batch Consumption Time: 0.08262
Total Iteration Time: 10.22939

Cumulative Model Updates: 15,723
Cumulative Timesteps: 262,538,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,047.47948
Policy Entropy: 0.52882
Value Function Loss: 0.06965

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01733
Policy Update Magnitude: 0.02107
Value Function Update Magnitude: 0.05198

Collected Steps per Second: 5,501.93039
Overall Steps per Second: 4,875.11598

Timestep Collection Time: 9.09281
Timestep Consumption Time: 1.16910
PPO Batch Consumption Time: 0.08965
Total Iteration Time: 10.26191

Cumulative Model Updates: 15,726
Cumulative Timesteps: 262,588,474

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 262588474...
Checkpoint 262588474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,438.31759
Policy Entropy: 0.52291
Value Function Loss: 0.08244

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01875
Policy Update Magnitude: 0.02102
Value Function Update Magnitude: 0.04878

Collected Steps per Second: 5,732.33751
Overall Steps per Second: 5,057.35221

Timestep Collection Time: 8.72698
Timestep Consumption Time: 1.16476
PPO Batch Consumption Time: 0.08763
Total Iteration Time: 9.89174

Cumulative Model Updates: 15,729
Cumulative Timesteps: 262,638,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,241.75448
Policy Entropy: 0.51877
Value Function Loss: 0.08719

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01951
Policy Update Magnitude: 0.02450
Value Function Update Magnitude: 0.04896

Collected Steps per Second: 5,487.80337
Overall Steps per Second: 4,865.54305

Timestep Collection Time: 9.11512
Timestep Consumption Time: 1.16574
PPO Batch Consumption Time: 0.09247
Total Iteration Time: 10.28087

Cumulative Model Updates: 15,732
Cumulative Timesteps: 262,688,522

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 262688522...
Checkpoint 262688522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,813.19830
Policy Entropy: 0.52153
Value Function Loss: 0.09288

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03645
Policy Update Magnitude: 0.02909
Value Function Update Magnitude: 0.04356

Collected Steps per Second: 5,563.44695
Overall Steps per Second: 4,867.63821

Timestep Collection Time: 8.99335
Timestep Consumption Time: 1.28556
PPO Batch Consumption Time: 0.08946
Total Iteration Time: 10.27891

Cumulative Model Updates: 15,735
Cumulative Timesteps: 262,738,556

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,287.68721
Policy Entropy: 0.52513
Value Function Loss: 0.08086

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02592
Policy Update Magnitude: 0.03774
Value Function Update Magnitude: 0.03832

Collected Steps per Second: 5,548.65013
Overall Steps per Second: 4,915.71348

Timestep Collection Time: 9.01336
Timestep Consumption Time: 1.16054
PPO Batch Consumption Time: 0.08697
Total Iteration Time: 10.17390

Cumulative Model Updates: 15,738
Cumulative Timesteps: 262,788,568

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 262788568...
Checkpoint 262788568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,195.60503
Policy Entropy: 0.52294
Value Function Loss: 0.07773

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03358
Policy Update Magnitude: 0.03418
Value Function Update Magnitude: 0.04721

Collected Steps per Second: 5,448.44650
Overall Steps per Second: 4,823.97486

Timestep Collection Time: 9.18280
Timestep Consumption Time: 1.18873
PPO Batch Consumption Time: 0.08664
Total Iteration Time: 10.37153

Cumulative Model Updates: 15,741
Cumulative Timesteps: 262,838,600

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,599.45842
Policy Entropy: 0.52969
Value Function Loss: 0.07812

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03169
Policy Update Magnitude: 0.04022
Value Function Update Magnitude: 0.04560

Collected Steps per Second: 5,517.24010
Overall Steps per Second: 4,893.77598

Timestep Collection Time: 9.06286
Timestep Consumption Time: 1.15460
PPO Batch Consumption Time: 0.09036
Total Iteration Time: 10.21747

Cumulative Model Updates: 15,744
Cumulative Timesteps: 262,888,602

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 262888602...
Checkpoint 262888602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,137.34369
Policy Entropy: 0.52967
Value Function Loss: 0.08066

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02137
Policy Update Magnitude: 0.03297
Value Function Update Magnitude: 0.04573

Collected Steps per Second: 5,533.65801
Overall Steps per Second: 4,904.49802

Timestep Collection Time: 9.03706
Timestep Consumption Time: 1.15929
PPO Batch Consumption Time: 0.08543
Total Iteration Time: 10.19635

Cumulative Model Updates: 15,747
Cumulative Timesteps: 262,938,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,280.74791
Policy Entropy: 0.52418
Value Function Loss: 0.08966

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.03081
Value Function Update Magnitude: 0.04712

Collected Steps per Second: 5,569.20619
Overall Steps per Second: 4,913.64274

Timestep Collection Time: 8.97830
Timestep Consumption Time: 1.19786
PPO Batch Consumption Time: 0.08706
Total Iteration Time: 10.17616

Cumulative Model Updates: 15,750
Cumulative Timesteps: 262,988,612

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 262988612...
Checkpoint 262988612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,319.46378
Policy Entropy: 0.51803
Value Function Loss: 0.09192

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03516
Policy Update Magnitude: 0.02823
Value Function Update Magnitude: 0.04122

Collected Steps per Second: 5,592.61807
Overall Steps per Second: 4,994.54219

Timestep Collection Time: 8.94465
Timestep Consumption Time: 1.07108
PPO Batch Consumption Time: 0.08576
Total Iteration Time: 10.01573

Cumulative Model Updates: 15,753
Cumulative Timesteps: 263,038,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,545.53710
Policy Entropy: 0.51373
Value Function Loss: 0.08633

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03079
Policy Update Magnitude: 0.02772
Value Function Update Magnitude: 0.04734

Collected Steps per Second: 5,473.61289
Overall Steps per Second: 4,890.14937

Timestep Collection Time: 9.13839
Timestep Consumption Time: 1.09034
PPO Batch Consumption Time: 0.08465
Total Iteration Time: 10.22873

Cumulative Model Updates: 15,756
Cumulative Timesteps: 263,088,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 263088656...
Checkpoint 263088656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,019.99895
Policy Entropy: 0.51193
Value Function Loss: 0.08640

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.04342
Policy Update Magnitude: 0.02810
Value Function Update Magnitude: 0.04462

Collected Steps per Second: 5,543.21054
Overall Steps per Second: 4,934.74574

Timestep Collection Time: 9.02618
Timestep Consumption Time: 1.11295
PPO Batch Consumption Time: 0.08370
Total Iteration Time: 10.13912

Cumulative Model Updates: 15,759
Cumulative Timesteps: 263,138,690

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,801.07037
Policy Entropy: 0.51966
Value Function Loss: 0.08494

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.03028
Policy Update Magnitude: 0.02716
Value Function Update Magnitude: 0.05604

Collected Steps per Second: 5,490.45452
Overall Steps per Second: 4,900.97683

Timestep Collection Time: 9.11109
Timestep Consumption Time: 1.09586
PPO Batch Consumption Time: 0.08385
Total Iteration Time: 10.20694

Cumulative Model Updates: 15,762
Cumulative Timesteps: 263,188,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 263188714...
Checkpoint 263188714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,993.75735
Policy Entropy: 0.52646
Value Function Loss: 0.08470

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04633
Policy Update Magnitude: 0.02653
Value Function Update Magnitude: 0.05478

Collected Steps per Second: 5,526.76076
Overall Steps per Second: 4,929.43659

Timestep Collection Time: 9.04689
Timestep Consumption Time: 1.09626
PPO Batch Consumption Time: 0.08510
Total Iteration Time: 10.14315

Cumulative Model Updates: 15,765
Cumulative Timesteps: 263,238,714

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,758.36674
Policy Entropy: 0.52074
Value Function Loss: 0.09639

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03541
Policy Update Magnitude: 0.02754
Value Function Update Magnitude: 0.05556

Collected Steps per Second: 5,859.11589
Overall Steps per Second: 5,207.09055

Timestep Collection Time: 8.53576
Timestep Consumption Time: 1.06884
PPO Batch Consumption Time: 0.08498
Total Iteration Time: 9.60460

Cumulative Model Updates: 15,768
Cumulative Timesteps: 263,288,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 263288726...
Checkpoint 263288726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,211.80641
Policy Entropy: 0.51770
Value Function Loss: 0.09535

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02366
Policy Update Magnitude: 0.02676
Value Function Update Magnitude: 0.04469

Collected Steps per Second: 5,577.22003
Overall Steps per Second: 4,918.47691

Timestep Collection Time: 8.97042
Timestep Consumption Time: 1.20143
PPO Batch Consumption Time: 0.08494
Total Iteration Time: 10.17185

Cumulative Model Updates: 15,771
Cumulative Timesteps: 263,338,756

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,749.79121
Policy Entropy: 0.51622
Value Function Loss: 0.10180

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.02489
Value Function Update Magnitude: 0.03481

Collected Steps per Second: 5,553.50273
Overall Steps per Second: 4,921.41796

Timestep Collection Time: 9.00549
Timestep Consumption Time: 1.15662
PPO Batch Consumption Time: 0.09008
Total Iteration Time: 10.16211

Cumulative Model Updates: 15,774
Cumulative Timesteps: 263,388,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 263388768...
Checkpoint 263388768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,685.35682
Policy Entropy: 0.52609
Value Function Loss: 0.08463

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02133
Policy Update Magnitude: 0.02313
Value Function Update Magnitude: 0.04126

Collected Steps per Second: 5,762.69117
Overall Steps per Second: 5,074.94387

Timestep Collection Time: 8.68205
Timestep Consumption Time: 1.17658
PPO Batch Consumption Time: 0.08330
Total Iteration Time: 9.85863

Cumulative Model Updates: 15,777
Cumulative Timesteps: 263,438,800

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,515.74487
Policy Entropy: 0.52371
Value Function Loss: 0.09015

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01802
Policy Update Magnitude: 0.02201
Value Function Update Magnitude: 0.03966

Collected Steps per Second: 5,485.80091
Overall Steps per Second: 4,874.51559

Timestep Collection Time: 9.11444
Timestep Consumption Time: 1.14299
PPO Batch Consumption Time: 0.08606
Total Iteration Time: 10.25743

Cumulative Model Updates: 15,780
Cumulative Timesteps: 263,488,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 263488800...
Checkpoint 263488800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,818.04605
Policy Entropy: 0.52951
Value Function Loss: 0.09726

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02886
Policy Update Magnitude: 0.02226
Value Function Update Magnitude: 0.04319

Collected Steps per Second: 5,599.04302
Overall Steps per Second: 4,966.17919

Timestep Collection Time: 8.93188
Timestep Consumption Time: 1.13823
PPO Batch Consumption Time: 0.08325
Total Iteration Time: 10.07012

Cumulative Model Updates: 15,783
Cumulative Timesteps: 263,538,810

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,211.63431
Policy Entropy: 0.52825
Value Function Loss: 0.09654

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04391
Policy Update Magnitude: 0.02303
Value Function Update Magnitude: 0.03531

Collected Steps per Second: 5,593.91984
Overall Steps per Second: 4,975.43434

Timestep Collection Time: 8.93828
Timestep Consumption Time: 1.11110
PPO Batch Consumption Time: 0.08529
Total Iteration Time: 10.04937

Cumulative Model Updates: 15,786
Cumulative Timesteps: 263,588,810

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 263588810...
Checkpoint 263588810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,036.01247
Policy Entropy: 0.52598
Value Function Loss: 0.10470

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03597
Policy Update Magnitude: 0.02324
Value Function Update Magnitude: 0.04222

Collected Steps per Second: 5,621.35482
Overall Steps per Second: 4,998.17886

Timestep Collection Time: 8.89999
Timestep Consumption Time: 1.10966
PPO Batch Consumption Time: 0.08619
Total Iteration Time: 10.00965

Cumulative Model Updates: 15,789
Cumulative Timesteps: 263,638,840

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,424.01769
Policy Entropy: 0.52356
Value Function Loss: 0.10089

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03433
Policy Update Magnitude: 0.02345
Value Function Update Magnitude: 0.05140

Collected Steps per Second: 5,680.50141
Overall Steps per Second: 5,035.03380

Timestep Collection Time: 8.80556
Timestep Consumption Time: 1.12883
PPO Batch Consumption Time: 0.08318
Total Iteration Time: 9.93439

Cumulative Model Updates: 15,792
Cumulative Timesteps: 263,688,860

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 263688860...
Checkpoint 263688860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,425.39398
Policy Entropy: 0.51912
Value Function Loss: 0.10993

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.02667
Value Function Update Magnitude: 0.05508

Collected Steps per Second: 5,571.81206
Overall Steps per Second: 4,926.90483

Timestep Collection Time: 8.98092
Timestep Consumption Time: 1.17556
PPO Batch Consumption Time: 0.08505
Total Iteration Time: 10.15648

Cumulative Model Updates: 15,795
Cumulative Timesteps: 263,738,900

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,207.69228
Policy Entropy: 0.52685
Value Function Loss: 0.09615

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.02763
Value Function Update Magnitude: 0.05895

Collected Steps per Second: 5,618.87507
Overall Steps per Second: 4,979.95675

Timestep Collection Time: 8.90071
Timestep Consumption Time: 1.14194
PPO Batch Consumption Time: 0.08391
Total Iteration Time: 10.04266

Cumulative Model Updates: 15,798
Cumulative Timesteps: 263,788,912

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 263788912...
Checkpoint 263788912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,024.20030
Policy Entropy: 0.52926
Value Function Loss: 0.09128

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.03112
Policy Update Magnitude: 0.02575
Value Function Update Magnitude: 0.05081

Collected Steps per Second: 5,631.80181
Overall Steps per Second: 4,998.92268

Timestep Collection Time: 8.88597
Timestep Consumption Time: 1.12499
PPO Batch Consumption Time: 0.08694
Total Iteration Time: 10.01096

Cumulative Model Updates: 15,801
Cumulative Timesteps: 263,838,956

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,035.88138
Policy Entropy: 0.53268
Value Function Loss: 0.07107

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.02387
Value Function Update Magnitude: 0.04512

Collected Steps per Second: 5,574.37539
Overall Steps per Second: 4,968.49347

Timestep Collection Time: 8.97213
Timestep Consumption Time: 1.09410
PPO Batch Consumption Time: 0.08495
Total Iteration Time: 10.06623

Cumulative Model Updates: 15,804
Cumulative Timesteps: 263,888,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 263888970...
Checkpoint 263888970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,302.76093
Policy Entropy: 0.52904
Value Function Loss: 0.06643

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.02239
Value Function Update Magnitude: 0.04635

Collected Steps per Second: 5,608.77148
Overall Steps per Second: 4,988.38555

Timestep Collection Time: 8.91817
Timestep Consumption Time: 1.10912
PPO Batch Consumption Time: 0.09903
Total Iteration Time: 10.02729

Cumulative Model Updates: 15,807
Cumulative Timesteps: 263,938,990

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,761.60301
Policy Entropy: 0.52557
Value Function Loss: 0.06570

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.02133
Value Function Update Magnitude: 0.03944

Collected Steps per Second: 5,773.09281
Overall Steps per Second: 5,121.56537

Timestep Collection Time: 8.66676
Timestep Consumption Time: 1.10252
PPO Batch Consumption Time: 0.08365
Total Iteration Time: 9.76928

Cumulative Model Updates: 15,810
Cumulative Timesteps: 263,989,024

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 263989024...
Checkpoint 263989024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,816.90766
Policy Entropy: 0.52679
Value Function Loss: 0.07353

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02250
Policy Update Magnitude: 0.02097
Value Function Update Magnitude: 0.03728

Collected Steps per Second: 5,530.21974
Overall Steps per Second: 4,898.03877

Timestep Collection Time: 9.04593
Timestep Consumption Time: 1.16754
PPO Batch Consumption Time: 0.09031
Total Iteration Time: 10.21348

Cumulative Model Updates: 15,813
Cumulative Timesteps: 264,039,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,362.59420
Policy Entropy: 0.52589
Value Function Loss: 0.08070

Mean KL Divergence: 0.00184
SB3 Clip Fraction: 0.01972
Policy Update Magnitude: 0.02280
Value Function Update Magnitude: 0.03971

Collected Steps per Second: 5,439.73774
Overall Steps per Second: 4,838.54764

Timestep Collection Time: 9.19566
Timestep Consumption Time: 1.14256
PPO Batch Consumption Time: 0.08458
Total Iteration Time: 10.33823

Cumulative Model Updates: 15,816
Cumulative Timesteps: 264,089,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 264089072...
Checkpoint 264089072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,291.76224
Policy Entropy: 0.52322
Value Function Loss: 0.09493

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.03015
Policy Update Magnitude: 0.02251
Value Function Update Magnitude: 0.03777

Collected Steps per Second: 5,668.41142
Overall Steps per Second: 5,025.47028

Timestep Collection Time: 8.82505
Timestep Consumption Time: 1.12905
PPO Batch Consumption Time: 0.09001
Total Iteration Time: 9.95409

Cumulative Model Updates: 15,819
Cumulative Timesteps: 264,139,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,055.01542
Policy Entropy: 0.52482
Value Function Loss: 0.09489

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.02237
Value Function Update Magnitude: 0.03825

Collected Steps per Second: 5,775.54328
Overall Steps per Second: 5,124.35755

Timestep Collection Time: 8.66689
Timestep Consumption Time: 1.10136
PPO Batch Consumption Time: 0.08217
Total Iteration Time: 9.76825

Cumulative Model Updates: 15,822
Cumulative Timesteps: 264,189,152

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 264189152...
Checkpoint 264189152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,239.71494
Policy Entropy: 0.52219
Value Function Loss: 0.09826

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02361
Policy Update Magnitude: 0.02431
Value Function Update Magnitude: 0.04076

Collected Steps per Second: 5,419.52041
Overall Steps per Second: 4,857.55409

Timestep Collection Time: 9.22997
Timestep Consumption Time: 1.06781
PPO Batch Consumption Time: 0.08628
Total Iteration Time: 10.29778

Cumulative Model Updates: 15,825
Cumulative Timesteps: 264,239,174

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,630.06147
Policy Entropy: 0.52869
Value Function Loss: 0.08509

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04759
Policy Update Magnitude: 0.02617
Value Function Update Magnitude: 0.03991

Collected Steps per Second: 5,648.40788
Overall Steps per Second: 5,017.71029

Timestep Collection Time: 8.85311
Timestep Consumption Time: 1.11279
PPO Batch Consumption Time: 0.08585
Total Iteration Time: 9.96590

Cumulative Model Updates: 15,828
Cumulative Timesteps: 264,289,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 264289180...
Checkpoint 264289180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,516.10999
Policy Entropy: 0.52874
Value Function Loss: 0.08334

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.04260
Policy Update Magnitude: 0.02482
Value Function Update Magnitude: 0.04309

Collected Steps per Second: 5,797.90842
Overall Steps per Second: 5,122.10416

Timestep Collection Time: 8.62552
Timestep Consumption Time: 1.13804
PPO Batch Consumption Time: 0.08814
Total Iteration Time: 9.76357

Cumulative Model Updates: 15,831
Cumulative Timesteps: 264,339,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,725.82636
Policy Entropy: 0.52621
Value Function Loss: 0.08387

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04858
Policy Update Magnitude: 0.02317
Value Function Update Magnitude: 0.04069

Collected Steps per Second: 5,643.64731
Overall Steps per Second: 5,063.71374

Timestep Collection Time: 8.86129
Timestep Consumption Time: 1.01486
PPO Batch Consumption Time: 0.08508
Total Iteration Time: 9.87615

Cumulative Model Updates: 15,834
Cumulative Timesteps: 264,389,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 264389200...
Checkpoint 264389200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,233.44360
Policy Entropy: 0.52332
Value Function Loss: 0.08084

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.04300
Policy Update Magnitude: 0.02267
Value Function Update Magnitude: 0.04481

Collected Steps per Second: 5,544.14111
Overall Steps per Second: 4,986.06208

Timestep Collection Time: 9.02322
Timestep Consumption Time: 1.00995
PPO Batch Consumption Time: 0.08256
Total Iteration Time: 10.03317

Cumulative Model Updates: 15,837
Cumulative Timesteps: 264,439,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,516.29074
Policy Entropy: 0.51794
Value Function Loss: 0.09046

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.02183
Value Function Update Magnitude: 0.04678

Collected Steps per Second: 5,852.97222
Overall Steps per Second: 5,248.09269

Timestep Collection Time: 8.54472
Timestep Consumption Time: 0.98484
PPO Batch Consumption Time: 0.08422
Total Iteration Time: 9.52956

Cumulative Model Updates: 15,840
Cumulative Timesteps: 264,489,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 264489238...
Checkpoint 264489238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,378.91359
Policy Entropy: 0.51348
Value Function Loss: 0.08796

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.04155
Policy Update Magnitude: 0.02301
Value Function Update Magnitude: 0.05758

Collected Steps per Second: 5,494.02829
Overall Steps per Second: 4,955.00930

Timestep Collection Time: 9.10516
Timestep Consumption Time: 0.99048
PPO Batch Consumption Time: 0.09219
Total Iteration Time: 10.09564

Cumulative Model Updates: 15,843
Cumulative Timesteps: 264,539,262

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,504.06838
Policy Entropy: 0.51476
Value Function Loss: 0.08489

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03508
Policy Update Magnitude: 0.02359
Value Function Update Magnitude: 0.06319

Collected Steps per Second: 5,352.76863
Overall Steps per Second: 4,849.45427

Timestep Collection Time: 9.34544
Timestep Consumption Time: 0.96994
PPO Batch Consumption Time: 0.08710
Total Iteration Time: 10.31539

Cumulative Model Updates: 15,846
Cumulative Timesteps: 264,589,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 264589286...
Checkpoint 264589286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,659.19281
Policy Entropy: 0.52021
Value Function Loss: 0.08425

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03965
Policy Update Magnitude: 0.02287
Value Function Update Magnitude: 0.05964

Collected Steps per Second: 5,387.70080
Overall Steps per Second: 4,814.61138

Timestep Collection Time: 9.28337
Timestep Consumption Time: 1.10501
PPO Batch Consumption Time: 0.08386
Total Iteration Time: 10.38838

Cumulative Model Updates: 15,849
Cumulative Timesteps: 264,639,302

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,349.58700
Policy Entropy: 0.52661
Value Function Loss: 0.07796

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05601
Policy Update Magnitude: 0.02259
Value Function Update Magnitude: 0.05151

Collected Steps per Second: 5,721.00640
Overall Steps per Second: 5,106.80606

Timestep Collection Time: 8.74112
Timestep Consumption Time: 1.05130
PPO Batch Consumption Time: 0.08808
Total Iteration Time: 9.79242

Cumulative Model Updates: 15,852
Cumulative Timesteps: 264,689,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 264689310...
Checkpoint 264689310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,878.54050
Policy Entropy: 0.52566
Value Function Loss: 0.07856

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 0.02437
Value Function Update Magnitude: 0.04384

Collected Steps per Second: 5,525.10901
Overall Steps per Second: 4,944.07051

Timestep Collection Time: 9.05430
Timestep Consumption Time: 1.06408
PPO Batch Consumption Time: 0.09700
Total Iteration Time: 10.11838

Cumulative Model Updates: 15,855
Cumulative Timesteps: 264,739,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,732.07353
Policy Entropy: 0.52747
Value Function Loss: 0.08295

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.04099
Policy Update Magnitude: 0.02160
Value Function Update Magnitude: 0.04946

Collected Steps per Second: 5,463.88018
Overall Steps per Second: 4,864.02881

Timestep Collection Time: 9.15247
Timestep Consumption Time: 1.12872
PPO Batch Consumption Time: 0.09395
Total Iteration Time: 10.28119

Cumulative Model Updates: 15,858
Cumulative Timesteps: 264,789,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 264789344...
Checkpoint 264789344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,913.06432
Policy Entropy: 0.52504
Value Function Loss: 0.09114

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.03140
Policy Update Magnitude: 0.02260
Value Function Update Magnitude: 0.05376

Collected Steps per Second: 5,496.12121
Overall Steps per Second: 4,921.54089

Timestep Collection Time: 9.09914
Timestep Consumption Time: 1.06231
PPO Batch Consumption Time: 0.09903
Total Iteration Time: 10.16145

Cumulative Model Updates: 15,861
Cumulative Timesteps: 264,839,354

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,210.68841
Policy Entropy: 0.52722
Value Function Loss: 0.09191

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04904
Policy Update Magnitude: 0.02314
Value Function Update Magnitude: 0.05169

Collected Steps per Second: 5,471.33619
Overall Steps per Second: 4,885.79138

Timestep Collection Time: 9.14036
Timestep Consumption Time: 1.09544
PPO Batch Consumption Time: 0.08730
Total Iteration Time: 10.23580

Cumulative Model Updates: 15,864
Cumulative Timesteps: 264,889,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 264889364...
Checkpoint 264889364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,349.86818
Policy Entropy: 0.53603
Value Function Loss: 0.07735

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03715
Policy Update Magnitude: 0.02298
Value Function Update Magnitude: 0.05753

Collected Steps per Second: 5,457.98605
Overall Steps per Second: 4,884.28841

Timestep Collection Time: 9.16602
Timestep Consumption Time: 1.07662
PPO Batch Consumption Time: 0.08737
Total Iteration Time: 10.24264

Cumulative Model Updates: 15,867
Cumulative Timesteps: 264,939,392

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,134.11277
Policy Entropy: 0.53522
Value Function Loss: 0.08358

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03278
Policy Update Magnitude: 0.02317
Value Function Update Magnitude: 0.05594

Collected Steps per Second: 5,425.56513
Overall Steps per Second: 4,846.86184

Timestep Collection Time: 9.21932
Timestep Consumption Time: 1.10076
PPO Batch Consumption Time: 0.08423
Total Iteration Time: 10.32008

Cumulative Model Updates: 15,870
Cumulative Timesteps: 264,989,412

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 264989412...
Checkpoint 264989412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,403.76952
Policy Entropy: 0.53154
Value Function Loss: 0.08808

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04156
Policy Update Magnitude: 0.02564
Value Function Update Magnitude: 0.04609

Collected Steps per Second: 5,376.88563
Overall Steps per Second: 4,810.08111

Timestep Collection Time: 9.30539
Timestep Consumption Time: 1.09652
PPO Batch Consumption Time: 0.08265
Total Iteration Time: 10.40190

Cumulative Model Updates: 15,873
Cumulative Timesteps: 265,039,446

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,688.77098
Policy Entropy: 0.52505
Value Function Loss: 0.09224

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.02589
Value Function Update Magnitude: 0.05387

Collected Steps per Second: 5,402.72781
Overall Steps per Second: 4,834.60582

Timestep Collection Time: 9.25681
Timestep Consumption Time: 1.08778
PPO Batch Consumption Time: 0.09025
Total Iteration Time: 10.34459

Cumulative Model Updates: 15,876
Cumulative Timesteps: 265,089,458

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 265089458...
Checkpoint 265089458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,088.42068
Policy Entropy: 0.52913
Value Function Loss: 0.09074

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02929
Policy Update Magnitude: 0.02405
Value Function Update Magnitude: 0.04836

Collected Steps per Second: 5,457.63226
Overall Steps per Second: 4,844.02172

Timestep Collection Time: 9.16551
Timestep Consumption Time: 1.16103
PPO Batch Consumption Time: 0.08721
Total Iteration Time: 10.32654

Cumulative Model Updates: 15,879
Cumulative Timesteps: 265,139,480

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,956.84473
Policy Entropy: 0.52464
Value Function Loss: 0.09075

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.02581
Value Function Update Magnitude: 0.05223

Collected Steps per Second: 5,638.12769
Overall Steps per Second: 5,005.32892

Timestep Collection Time: 8.86819
Timestep Consumption Time: 1.12116
PPO Batch Consumption Time: 0.08696
Total Iteration Time: 9.98935

Cumulative Model Updates: 15,882
Cumulative Timesteps: 265,189,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 265189480...
Checkpoint 265189480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,484.29378
Policy Entropy: 0.52414
Value Function Loss: 0.08900

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03756
Policy Update Magnitude: 0.02455
Value Function Update Magnitude: 0.05095

Collected Steps per Second: 5,549.29498
Overall Steps per Second: 4,932.67558

Timestep Collection Time: 9.01123
Timestep Consumption Time: 1.12647
PPO Batch Consumption Time: 0.08683
Total Iteration Time: 10.13770

Cumulative Model Updates: 15,885
Cumulative Timesteps: 265,239,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,853.18156
Policy Entropy: 0.52996
Value Function Loss: 0.07502

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.02310
Value Function Update Magnitude: 0.05322

Collected Steps per Second: 5,702.25945
Overall Steps per Second: 5,036.14811

Timestep Collection Time: 8.77442
Timestep Consumption Time: 1.16056
PPO Batch Consumption Time: 0.08440
Total Iteration Time: 9.93497

Cumulative Model Updates: 15,888
Cumulative Timesteps: 265,289,520

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 265289520...
Checkpoint 265289520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,959.04571
Policy Entropy: 0.53314
Value Function Loss: 0.07764

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03757
Policy Update Magnitude: 0.02111
Value Function Update Magnitude: 0.04641

Collected Steps per Second: 5,545.54240
Overall Steps per Second: 4,897.84920

Timestep Collection Time: 9.01914
Timestep Consumption Time: 1.19269
PPO Batch Consumption Time: 0.08428
Total Iteration Time: 10.21183

Cumulative Model Updates: 15,891
Cumulative Timesteps: 265,339,536

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,237.00652
Policy Entropy: 0.53707
Value Function Loss: 0.08197

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.02085
Value Function Update Magnitude: 0.04631

Collected Steps per Second: 5,531.49515
Overall Steps per Second: 4,888.38086

Timestep Collection Time: 9.04240
Timestep Consumption Time: 1.18962
PPO Batch Consumption Time: 0.08650
Total Iteration Time: 10.23202

Cumulative Model Updates: 15,894
Cumulative Timesteps: 265,389,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 265389554...
Checkpoint 265389554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,888.67606
Policy Entropy: 0.53448
Value Function Loss: 0.08322

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03011
Policy Update Magnitude: 0.02264
Value Function Update Magnitude: 0.04504

Collected Steps per Second: 5,597.94465
Overall Steps per Second: 4,958.33031

Timestep Collection Time: 8.94078
Timestep Consumption Time: 1.15334
PPO Batch Consumption Time: 0.07935
Total Iteration Time: 10.09412

Cumulative Model Updates: 15,897
Cumulative Timesteps: 265,439,604

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,546.52370
Policy Entropy: 0.53007
Value Function Loss: 0.08012

Mean KL Divergence: 0.00156
SB3 Clip Fraction: 0.01560
Policy Update Magnitude: 0.02489
Value Function Update Magnitude: 0.04848

Collected Steps per Second: 5,495.90617
Overall Steps per Second: 4,843.78859

Timestep Collection Time: 9.09804
Timestep Consumption Time: 1.22487
PPO Batch Consumption Time: 0.08435
Total Iteration Time: 10.32291

Cumulative Model Updates: 15,900
Cumulative Timesteps: 265,489,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 265489606...
Checkpoint 265489606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,863.06748
Policy Entropy: 0.53231
Value Function Loss: 0.08327

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.02287
Value Function Update Magnitude: 0.04173

Collected Steps per Second: 5,600.81008
Overall Steps per Second: 4,952.90658

Timestep Collection Time: 8.92871
Timestep Consumption Time: 1.16799
PPO Batch Consumption Time: 0.08816
Total Iteration Time: 10.09670

Cumulative Model Updates: 15,903
Cumulative Timesteps: 265,539,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,583.43614
Policy Entropy: 0.52993
Value Function Loss: 0.09107

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02061
Policy Update Magnitude: 0.02432
Value Function Update Magnitude: 0.04651

Collected Steps per Second: 5,730.72618
Overall Steps per Second: 5,063.56919

Timestep Collection Time: 8.73048
Timestep Consumption Time: 1.15030
PPO Batch Consumption Time: 0.08471
Total Iteration Time: 9.88078

Cumulative Model Updates: 15,906
Cumulative Timesteps: 265,589,646

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 265589646...
Checkpoint 265589646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,403.96728
Policy Entropy: 0.53655
Value Function Loss: 0.09045

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.02564
Value Function Update Magnitude: 0.04559

Collected Steps per Second: 5,615.27372
Overall Steps per Second: 4,977.44464

Timestep Collection Time: 8.90856
Timestep Consumption Time: 1.14158
PPO Batch Consumption Time: 0.08706
Total Iteration Time: 10.05014

Cumulative Model Updates: 15,909
Cumulative Timesteps: 265,639,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,870.84710
Policy Entropy: 0.53215
Value Function Loss: 0.07907

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01460
Policy Update Magnitude: 0.02539
Value Function Update Magnitude: 0.04172

Collected Steps per Second: 5,505.93023
Overall Steps per Second: 4,949.27346

Timestep Collection Time: 9.08584
Timestep Consumption Time: 1.02191
PPO Batch Consumption Time: 0.08524
Total Iteration Time: 10.10775

Cumulative Model Updates: 15,912
Cumulative Timesteps: 265,689,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 265689696...
Checkpoint 265689696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,687.80790
Policy Entropy: 0.52917
Value Function Loss: 0.09144

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02859
Policy Update Magnitude: 0.02590
Value Function Update Magnitude: 0.03882

Collected Steps per Second: 5,431.46985
Overall Steps per Second: 4,905.54963

Timestep Collection Time: 9.20782
Timestep Consumption Time: 0.98716
PPO Batch Consumption Time: 0.08613
Total Iteration Time: 10.19498

Cumulative Model Updates: 15,915
Cumulative Timesteps: 265,739,708

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,891.64314
Policy Entropy: 0.53280
Value Function Loss: 0.08708

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 0.02850
Value Function Update Magnitude: 0.04534

Collected Steps per Second: 5,524.31403
Overall Steps per Second: 4,963.17776

Timestep Collection Time: 9.05705
Timestep Consumption Time: 1.02399
PPO Batch Consumption Time: 0.08466
Total Iteration Time: 10.08104

Cumulative Model Updates: 15,918
Cumulative Timesteps: 265,789,742

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 265789742...
Checkpoint 265789742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,749.58643
Policy Entropy: 0.53525
Value Function Loss: 0.09994

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.05274
Policy Update Magnitude: 0.02648
Value Function Update Magnitude: 0.04369

Collected Steps per Second: 5,623.61939
Overall Steps per Second: 5,021.73968

Timestep Collection Time: 8.89747
Timestep Consumption Time: 1.06641
PPO Batch Consumption Time: 0.08785
Total Iteration Time: 9.96388

Cumulative Model Updates: 15,921
Cumulative Timesteps: 265,839,778

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,198.91272
Policy Entropy: 0.54065
Value Function Loss: 0.09091

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.04167
Policy Update Magnitude: 0.02453
Value Function Update Magnitude: 0.04179

Collected Steps per Second: 5,408.39473
Overall Steps per Second: 4,871.64990

Timestep Collection Time: 9.24859
Timestep Consumption Time: 1.01898
PPO Batch Consumption Time: 0.08480
Total Iteration Time: 10.26757

Cumulative Model Updates: 15,924
Cumulative Timesteps: 265,889,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 265889798...
Checkpoint 265889798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,117.40064
Policy Entropy: 0.53743
Value Function Loss: 0.09393

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.04885
Policy Update Magnitude: 0.02312
Value Function Update Magnitude: 0.03567

Collected Steps per Second: 5,396.64400
Overall Steps per Second: 4,873.52211

Timestep Collection Time: 9.26502
Timestep Consumption Time: 0.99450
PPO Batch Consumption Time: 0.08510
Total Iteration Time: 10.25952

Cumulative Model Updates: 15,927
Cumulative Timesteps: 265,939,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,346.98112
Policy Entropy: 0.54492
Value Function Loss: 0.08580

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.05109
Policy Update Magnitude: 0.02290
Value Function Update Magnitude: 0.04411

Collected Steps per Second: 5,531.54326
Overall Steps per Second: 4,976.50079

Timestep Collection Time: 9.04377
Timestep Consumption Time: 1.00868
PPO Batch Consumption Time: 0.08816
Total Iteration Time: 10.05244

Cumulative Model Updates: 15,930
Cumulative Timesteps: 265,989,824

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 265989824...
Checkpoint 265989824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,142.02772
Policy Entropy: 0.54599
Value Function Loss: 0.08413

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05931
Policy Update Magnitude: 0.02402
Value Function Update Magnitude: 0.04160

Collected Steps per Second: 5,458.56656
Overall Steps per Second: 4,870.01362

Timestep Collection Time: 9.16504
Timestep Consumption Time: 1.10762
PPO Batch Consumption Time: 0.08516
Total Iteration Time: 10.27266

Cumulative Model Updates: 15,933
Cumulative Timesteps: 266,039,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,787.98595
Policy Entropy: 0.53966
Value Function Loss: 0.08486

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05843
Policy Update Magnitude: 0.02154
Value Function Update Magnitude: 0.04109

Collected Steps per Second: 5,525.73936
Overall Steps per Second: 4,906.91642

Timestep Collection Time: 9.04965
Timestep Consumption Time: 1.14127
PPO Batch Consumption Time: 0.08633
Total Iteration Time: 10.19092

Cumulative Model Updates: 15,936
Cumulative Timesteps: 266,089,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 266089858...
Checkpoint 266089858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,324.99232
Policy Entropy: 0.53162
Value Function Loss: 0.08578

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04043
Policy Update Magnitude: 0.02307
Value Function Update Magnitude: 0.03890

Collected Steps per Second: 5,663.51432
Overall Steps per Second: 5,025.21171

Timestep Collection Time: 8.83656
Timestep Consumption Time: 1.12242
PPO Batch Consumption Time: 0.09017
Total Iteration Time: 9.95898

Cumulative Model Updates: 15,939
Cumulative Timesteps: 266,139,904

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,006.55987
Policy Entropy: 0.53066
Value Function Loss: 0.09224

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04505
Policy Update Magnitude: 0.02532
Value Function Update Magnitude: 0.04355

Collected Steps per Second: 5,767.55178
Overall Steps per Second: 5,111.90673

Timestep Collection Time: 8.67370
Timestep Consumption Time: 1.11247
PPO Batch Consumption Time: 0.08371
Total Iteration Time: 9.78617

Cumulative Model Updates: 15,942
Cumulative Timesteps: 266,189,930

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 266189930...
Checkpoint 266189930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,334.09496
Policy Entropy: 0.53183
Value Function Loss: 0.10166

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.04819
Policy Update Magnitude: 0.02411
Value Function Update Magnitude: 0.04211

Collected Steps per Second: 5,473.50124
Overall Steps per Second: 4,869.07336

Timestep Collection Time: 9.14040
Timestep Consumption Time: 1.13465
PPO Batch Consumption Time: 0.08465
Total Iteration Time: 10.27506

Cumulative Model Updates: 15,945
Cumulative Timesteps: 266,239,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,149.78163
Policy Entropy: 0.53162
Value Function Loss: 0.10426

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.04933
Policy Update Magnitude: 0.02425
Value Function Update Magnitude: 0.04931

Collected Steps per Second: 5,717.61921
Overall Steps per Second: 5,054.29978

Timestep Collection Time: 8.75015
Timestep Consumption Time: 1.14836
PPO Batch Consumption Time: 0.08879
Total Iteration Time: 9.89850

Cumulative Model Updates: 15,948
Cumulative Timesteps: 266,289,990

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 266289990...
Checkpoint 266289990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,657.65800
Policy Entropy: 0.53060
Value Function Loss: 0.09701

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02587
Policy Update Magnitude: 0.02486
Value Function Update Magnitude: 0.04742

Collected Steps per Second: 5,577.33536
Overall Steps per Second: 4,920.58007

Timestep Collection Time: 8.97059
Timestep Consumption Time: 1.19731
PPO Batch Consumption Time: 0.09011
Total Iteration Time: 10.16791

Cumulative Model Updates: 15,951
Cumulative Timesteps: 266,340,022

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,049.43818
Policy Entropy: 0.53272
Value Function Loss: 0.09522

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07229
Policy Update Magnitude: 0.02423
Value Function Update Magnitude: 0.05262

Collected Steps per Second: 5,513.15775
Overall Steps per Second: 4,904.23713

Timestep Collection Time: 9.07320
Timestep Consumption Time: 1.12655
PPO Batch Consumption Time: 0.08520
Total Iteration Time: 10.19975

Cumulative Model Updates: 15,954
Cumulative Timesteps: 266,390,044

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 266390044...
Checkpoint 266390044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,242.89891
Policy Entropy: 0.54087
Value Function Loss: 0.08945

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.08052
Policy Update Magnitude: 0.02302
Value Function Update Magnitude: 0.05504

Collected Steps per Second: 5,580.31651
Overall Steps per Second: 4,953.91256

Timestep Collection Time: 8.96831
Timestep Consumption Time: 1.13401
PPO Batch Consumption Time: 0.08491
Total Iteration Time: 10.10232

Cumulative Model Updates: 15,957
Cumulative Timesteps: 266,440,090

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,773.48249
Policy Entropy: 0.54222
Value Function Loss: 0.09163

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.06110
Policy Update Magnitude: 0.02536
Value Function Update Magnitude: 0.05243

Collected Steps per Second: 5,627.06935
Overall Steps per Second: 5,010.49556

Timestep Collection Time: 8.89273
Timestep Consumption Time: 1.09431
PPO Batch Consumption Time: 0.08277
Total Iteration Time: 9.98704

Cumulative Model Updates: 15,960
Cumulative Timesteps: 266,490,130

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 266490130...
Checkpoint 266490130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,776.61865
Policy Entropy: 0.54473
Value Function Loss: 0.08069

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06029
Policy Update Magnitude: 0.02290
Value Function Update Magnitude: 0.04831

Collected Steps per Second: 5,676.69852
Overall Steps per Second: 5,030.44549

Timestep Collection Time: 8.81040
Timestep Consumption Time: 1.13186
PPO Batch Consumption Time: 0.08781
Total Iteration Time: 9.94226

Cumulative Model Updates: 15,963
Cumulative Timesteps: 266,540,144

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,766.29988
Policy Entropy: 0.54522
Value Function Loss: 0.08607

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04199
Policy Update Magnitude: 0.02258
Value Function Update Magnitude: 0.05617

Collected Steps per Second: 5,776.20934
Overall Steps per Second: 5,099.29527

Timestep Collection Time: 8.66000
Timestep Consumption Time: 1.14959
PPO Batch Consumption Time: 0.08376
Total Iteration Time: 9.80959

Cumulative Model Updates: 15,966
Cumulative Timesteps: 266,590,166

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 266590166...
Checkpoint 266590166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,493.32444
Policy Entropy: 0.53930
Value Function Loss: 0.09564

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03829
Policy Update Magnitude: 0.02382
Value Function Update Magnitude: 0.06653

Collected Steps per Second: 5,853.43230
Overall Steps per Second: 5,178.86890

Timestep Collection Time: 8.54712
Timestep Consumption Time: 1.11329
PPO Batch Consumption Time: 0.08723
Total Iteration Time: 9.66041

Cumulative Model Updates: 15,969
Cumulative Timesteps: 266,640,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,030.78234
Policy Entropy: 0.53752
Value Function Loss: 0.10290

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.02429
Value Function Update Magnitude: 0.05868

Collected Steps per Second: 5,736.44102
Overall Steps per Second: 5,090.19523

Timestep Collection Time: 8.72039
Timestep Consumption Time: 1.10713
PPO Batch Consumption Time: 0.08293
Total Iteration Time: 9.82752

Cumulative Model Updates: 15,972
Cumulative Timesteps: 266,690,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 266690220...
Checkpoint 266690220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,880.69934
Policy Entropy: 0.53119
Value Function Loss: 0.09914

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.02757
Value Function Update Magnitude: 0.06316

Collected Steps per Second: 5,774.45866
Overall Steps per Second: 5,086.28849

Timestep Collection Time: 8.66194
Timestep Consumption Time: 1.17195
PPO Batch Consumption Time: 0.08408
Total Iteration Time: 9.83389

Cumulative Model Updates: 15,975
Cumulative Timesteps: 266,740,238

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,355.81930
Policy Entropy: 0.53026
Value Function Loss: 0.08834

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06843
Policy Update Magnitude: 0.02573
Value Function Update Magnitude: 0.07193

Collected Steps per Second: 5,977.11747
Overall Steps per Second: 5,265.52152

Timestep Collection Time: 8.36557
Timestep Consumption Time: 1.13054
PPO Batch Consumption Time: 0.08455
Total Iteration Time: 9.49612

Cumulative Model Updates: 15,978
Cumulative Timesteps: 266,790,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 266790240...
Checkpoint 266790240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,024.12048
Policy Entropy: 0.53108
Value Function Loss: 0.08832

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06946
Policy Update Magnitude: 0.02396
Value Function Update Magnitude: 0.07064

Collected Steps per Second: 5,908.66163
Overall Steps per Second: 5,218.92474

Timestep Collection Time: 8.46486
Timestep Consumption Time: 1.11872
PPO Batch Consumption Time: 0.08294
Total Iteration Time: 9.58358

Cumulative Model Updates: 15,981
Cumulative Timesteps: 266,840,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,946.06737
Policy Entropy: 0.52921
Value Function Loss: 0.07937

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.07985
Policy Update Magnitude: 0.02530
Value Function Update Magnitude: 0.07010

Collected Steps per Second: 5,408.09541
Overall Steps per Second: 4,771.05718

Timestep Collection Time: 9.25427
Timestep Consumption Time: 1.23564
PPO Batch Consumption Time: 0.08566
Total Iteration Time: 10.48992

Cumulative Model Updates: 15,984
Cumulative Timesteps: 266,890,304

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 266890304...
Checkpoint 266890304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,697.09915
Policy Entropy: 0.52879
Value Function Loss: 0.07420

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.07759
Policy Update Magnitude: 0.02101
Value Function Update Magnitude: 0.06594

Collected Steps per Second: 5,469.73125
Overall Steps per Second: 4,863.21448

Timestep Collection Time: 9.14158
Timestep Consumption Time: 1.14009
PPO Batch Consumption Time: 0.08492
Total Iteration Time: 10.28168

Cumulative Model Updates: 15,987
Cumulative Timesteps: 266,940,306

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,407.42255
Policy Entropy: 0.52461
Value Function Loss: 0.08579

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06400
Policy Update Magnitude: 0.02217
Value Function Update Magnitude: 0.06703

Collected Steps per Second: 5,388.97386
Overall Steps per Second: 4,789.83087

Timestep Collection Time: 9.27932
Timestep Consumption Time: 1.16072
PPO Batch Consumption Time: 0.08609
Total Iteration Time: 10.44003

Cumulative Model Updates: 15,990
Cumulative Timesteps: 266,990,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 266990312...
Checkpoint 266990312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,411.02552
Policy Entropy: 0.52796
Value Function Loss: 0.09661

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04881
Policy Update Magnitude: 0.02247
Value Function Update Magnitude: 0.06284

Collected Steps per Second: 5,521.71936
Overall Steps per Second: 4,901.13431

Timestep Collection Time: 9.05877
Timestep Consumption Time: 1.14703
PPO Batch Consumption Time: 0.09563
Total Iteration Time: 10.20580

Cumulative Model Updates: 15,993
Cumulative Timesteps: 267,040,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,937.61426
Policy Entropy: 0.52824
Value Function Loss: 0.10274

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.04133
Policy Update Magnitude: 0.02336
Value Function Update Magnitude: 0.05507

Collected Steps per Second: 5,357.95954
Overall Steps per Second: 4,764.47533

Timestep Collection Time: 9.33826
Timestep Consumption Time: 1.16321
PPO Batch Consumption Time: 0.08525
Total Iteration Time: 10.50147

Cumulative Model Updates: 15,996
Cumulative Timesteps: 267,090,366

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 267090366...
Checkpoint 267090366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,632.35786
Policy Entropy: 0.53162
Value Function Loss: 0.08243

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.06321
Policy Update Magnitude: 0.02348
Value Function Update Magnitude: 0.05792

Collected Steps per Second: 5,643.59578
Overall Steps per Second: 5,019.24499

Timestep Collection Time: 8.86385
Timestep Consumption Time: 1.10259
PPO Batch Consumption Time: 0.08890
Total Iteration Time: 9.96644

Cumulative Model Updates: 15,999
Cumulative Timesteps: 267,140,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,508.91397
Policy Entropy: 0.53303
Value Function Loss: 0.08709

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.03198
Policy Update Magnitude: 0.02159
Value Function Update Magnitude: 0.06236

Collected Steps per Second: 6,012.59177
Overall Steps per Second: 5,286.63549

Timestep Collection Time: 8.31788
Timestep Consumption Time: 1.14220
PPO Batch Consumption Time: 0.08455
Total Iteration Time: 9.46008

Cumulative Model Updates: 16,002
Cumulative Timesteps: 267,190,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 267190402...
Checkpoint 267190402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,223.21008
Policy Entropy: 0.52607
Value Function Loss: 0.08341

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04360
Policy Update Magnitude: 0.02474
Value Function Update Magnitude: 0.06428

Collected Steps per Second: 5,437.55584
Overall Steps per Second: 4,826.50429

Timestep Collection Time: 9.19935
Timestep Consumption Time: 1.16467
PPO Batch Consumption Time: 0.08548
Total Iteration Time: 10.36402

Cumulative Model Updates: 16,005
Cumulative Timesteps: 267,240,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,384.95289
Policy Entropy: 0.52979
Value Function Loss: 0.08437

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03888
Policy Update Magnitude: 0.02562
Value Function Update Magnitude: 0.05453

Collected Steps per Second: 7,995.79275
Overall Steps per Second: 7,028.03281

Timestep Collection Time: 6.25454
Timestep Consumption Time: 0.86125
PPO Batch Consumption Time: 0.05072
Total Iteration Time: 7.11579

Cumulative Model Updates: 16,008
Cumulative Timesteps: 267,290,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 267290434...
Checkpoint 267290434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,236.91946
Policy Entropy: 0.53615
Value Function Loss: 0.07780

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.02306
Value Function Update Magnitude: 0.04814

Collected Steps per Second: 18,009.06176
Overall Steps per Second: 13,144.74337

Timestep Collection Time: 2.77827
Timestep Consumption Time: 1.02812
PPO Batch Consumption Time: 0.11898
Total Iteration Time: 3.80639

Cumulative Model Updates: 16,011
Cumulative Timesteps: 267,340,468

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,570.95567
Policy Entropy: 0.53779
Value Function Loss: 0.08525

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 0.02202
Value Function Update Magnitude: 0.04072

Collected Steps per Second: 11,096.26567
Overall Steps per Second: 8,926.88931

Timestep Collection Time: 4.50890
Timestep Consumption Time: 1.09574
PPO Batch Consumption Time: 0.08715
Total Iteration Time: 5.60464

Cumulative Model Updates: 16,014
Cumulative Timesteps: 267,390,500

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 267390500...
Checkpoint 267390500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,322.94020
Policy Entropy: 0.53037
Value Function Loss: 0.09021

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02937
Policy Update Magnitude: 0.02416
Value Function Update Magnitude: 0.05170

Collected Steps per Second: 13,127.96608
Overall Steps per Second: 10,051.67587

Timestep Collection Time: 3.80866
Timestep Consumption Time: 1.16563
PPO Batch Consumption Time: 0.07903
Total Iteration Time: 4.97429

Cumulative Model Updates: 16,017
Cumulative Timesteps: 267,440,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,373.22804
Policy Entropy: 0.52141
Value Function Loss: 0.09411

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04529
Policy Update Magnitude: 0.02494
Value Function Update Magnitude: 0.05077

Collected Steps per Second: 9,504.97940
Overall Steps per Second: 7,510.18593

Timestep Collection Time: 5.26082
Timestep Consumption Time: 1.39734
PPO Batch Consumption Time: 0.08873
Total Iteration Time: 6.65816

Cumulative Model Updates: 16,020
Cumulative Timesteps: 267,490,504

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 267490504...
Checkpoint 267490504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,563.49702
Policy Entropy: 0.52466
Value Function Loss: 0.07819

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05774
Policy Update Magnitude: 0.02459
Value Function Update Magnitude: 0.04669

Collected Steps per Second: 5,636.83731
Overall Steps per Second: 4,999.46411

Timestep Collection Time: 8.87022
Timestep Consumption Time: 1.13085
PPO Batch Consumption Time: 0.09832
Total Iteration Time: 10.00107

Cumulative Model Updates: 16,023
Cumulative Timesteps: 267,540,504

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,897.20718
Policy Entropy: 0.53501
Value Function Loss: 0.07188

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.04165
Policy Update Magnitude: 0.02188
Value Function Update Magnitude: 0.04021

Collected Steps per Second: 6,567.79951
Overall Steps per Second: 5,896.21384

Timestep Collection Time: 7.62112
Timestep Consumption Time: 0.86805
PPO Batch Consumption Time: 0.04063
Total Iteration Time: 8.48918

Cumulative Model Updates: 16,026
Cumulative Timesteps: 267,590,558

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 267590558...
Checkpoint 267590558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,408.61811
Policy Entropy: 0.54033
Value Function Loss: 0.06945

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04325
Policy Update Magnitude: 0.02351
Value Function Update Magnitude: 0.03183

Collected Steps per Second: 16,893.73842
Overall Steps per Second: 12,860.37862

Timestep Collection Time: 2.96027
Timestep Consumption Time: 0.92842
PPO Batch Consumption Time: 0.06755
Total Iteration Time: 3.88869

Cumulative Model Updates: 16,029
Cumulative Timesteps: 267,640,568

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,920.95671
Policy Entropy: 0.53534
Value Function Loss: 0.07579

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.04625
Policy Update Magnitude: 0.02493
Value Function Update Magnitude: 0.03412

Collected Steps per Second: 10,518.33796
Overall Steps per Second: 8,563.57066

Timestep Collection Time: 4.75607
Timestep Consumption Time: 1.08565
PPO Batch Consumption Time: 0.08682
Total Iteration Time: 5.84172

Cumulative Model Updates: 16,032
Cumulative Timesteps: 267,690,594

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 267690594...
Checkpoint 267690594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,346.52909
Policy Entropy: 0.53153
Value Function Loss: 0.08189

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.04193
Policy Update Magnitude: 0.02314
Value Function Update Magnitude: 0.03921

Collected Steps per Second: 5,676.57430
Overall Steps per Second: 5,057.81007

Timestep Collection Time: 8.81200
Timestep Consumption Time: 1.07805
PPO Batch Consumption Time: 0.08056
Total Iteration Time: 9.89005

Cumulative Model Updates: 16,035
Cumulative Timesteps: 267,740,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,884.53635
Policy Entropy: 0.52292
Value Function Loss: 0.08657

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.04641
Policy Update Magnitude: 0.02649
Value Function Update Magnitude: 0.03813

Collected Steps per Second: 5,739.49788
Overall Steps per Second: 5,096.79505

Timestep Collection Time: 8.71679
Timestep Consumption Time: 1.09918
PPO Batch Consumption Time: 0.08872
Total Iteration Time: 9.81597

Cumulative Model Updates: 16,038
Cumulative Timesteps: 267,790,646

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 267790646...
Checkpoint 267790646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,379.56960
Policy Entropy: 0.52522
Value Function Loss: 0.08691

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.06491
Policy Update Magnitude: 0.02319
Value Function Update Magnitude: 0.03937

Collected Steps per Second: 5,593.57947
Overall Steps per Second: 4,929.41643

Timestep Collection Time: 8.93882
Timestep Consumption Time: 1.20437
PPO Batch Consumption Time: 0.08746
Total Iteration Time: 10.14319

Cumulative Model Updates: 16,041
Cumulative Timesteps: 267,840,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,001.81714
Policy Entropy: 0.52504
Value Function Loss: 0.08625

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04418
Policy Update Magnitude: 0.02211
Value Function Update Magnitude: 0.04082

Collected Steps per Second: 5,395.89022
Overall Steps per Second: 4,783.22598

Timestep Collection Time: 9.26928
Timestep Consumption Time: 1.18726
PPO Batch Consumption Time: 0.08484
Total Iteration Time: 10.45654

Cumulative Model Updates: 16,044
Cumulative Timesteps: 267,890,662

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 267890662...
Checkpoint 267890662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,630.77747
Policy Entropy: 0.53040
Value Function Loss: 0.08403

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05882
Policy Update Magnitude: 0.02132
Value Function Update Magnitude: 0.03668

Collected Steps per Second: 5,935.50302
Overall Steps per Second: 5,228.34360

Timestep Collection Time: 8.42894
Timestep Consumption Time: 1.14006
PPO Batch Consumption Time: 0.08534
Total Iteration Time: 9.56900

Cumulative Model Updates: 16,047
Cumulative Timesteps: 267,940,692

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,224.77392
Policy Entropy: 0.52618
Value Function Loss: 0.08692

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.04021
Policy Update Magnitude: 0.02118
Value Function Update Magnitude: 0.04731

Collected Steps per Second: 5,320.06801
Overall Steps per Second: 4,768.77361

Timestep Collection Time: 9.39950
Timestep Consumption Time: 1.08663
PPO Batch Consumption Time: 0.08464
Total Iteration Time: 10.48613

Cumulative Model Updates: 16,050
Cumulative Timesteps: 267,990,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 267990698...
Checkpoint 267990698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,875.26998
Policy Entropy: 0.52554
Value Function Loss: 0.08389

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05475
Policy Update Magnitude: 0.02300
Value Function Update Magnitude: 0.04589

Collected Steps per Second: 5,265.58745
Overall Steps per Second: 4,757.12375

Timestep Collection Time: 9.50207
Timestep Consumption Time: 1.01563
PPO Batch Consumption Time: 0.08362
Total Iteration Time: 10.51770

Cumulative Model Updates: 16,053
Cumulative Timesteps: 268,040,732

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,111.91532
Policy Entropy: 0.52090
Value Function Loss: 0.08837

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.04242
Policy Update Magnitude: 0.02216
Value Function Update Magnitude: 0.04871

Collected Steps per Second: 5,478.30319
Overall Steps per Second: 4,936.41426

Timestep Collection Time: 9.13202
Timestep Consumption Time: 1.00246
PPO Batch Consumption Time: 0.08337
Total Iteration Time: 10.13448

Cumulative Model Updates: 16,056
Cumulative Timesteps: 268,090,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 268090760...
Checkpoint 268090760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,969.43952
Policy Entropy: 0.51719
Value Function Loss: 0.08715

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.03745
Policy Update Magnitude: 0.02297
Value Function Update Magnitude: 0.04486

Collected Steps per Second: 5,542.38537
Overall Steps per Second: 4,928.33127

Timestep Collection Time: 9.02788
Timestep Consumption Time: 1.12484
PPO Batch Consumption Time: 0.08545
Total Iteration Time: 10.15273

Cumulative Model Updates: 16,059
Cumulative Timesteps: 268,140,796

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,201.51585
Policy Entropy: 0.51694
Value Function Loss: 0.08752

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.02731
Value Function Update Magnitude: 0.05471

Collected Steps per Second: 5,597.44323
Overall Steps per Second: 4,966.67931

Timestep Collection Time: 8.93408
Timestep Consumption Time: 1.13462
PPO Batch Consumption Time: 0.08982
Total Iteration Time: 10.06870

Cumulative Model Updates: 16,062
Cumulative Timesteps: 268,190,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 268190804...
Checkpoint 268190804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,364.61377
Policy Entropy: 0.52003
Value Function Loss: 0.07199

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.05641
Policy Update Magnitude: 0.02476
Value Function Update Magnitude: 0.05093

Collected Steps per Second: 5,704.22527
Overall Steps per Second: 5,009.55586

Timestep Collection Time: 8.76894
Timestep Consumption Time: 1.21598
PPO Batch Consumption Time: 0.08891
Total Iteration Time: 9.98492

Cumulative Model Updates: 16,065
Cumulative Timesteps: 268,240,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,739.40319
Policy Entropy: 0.52650
Value Function Loss: 0.06674

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.05401
Policy Update Magnitude: 0.02071
Value Function Update Magnitude: 0.06338

Collected Steps per Second: 5,617.96485
Overall Steps per Second: 4,977.40375

Timestep Collection Time: 8.90750
Timestep Consumption Time: 1.14634
PPO Batch Consumption Time: 0.08470
Total Iteration Time: 10.05384

Cumulative Model Updates: 16,068
Cumulative Timesteps: 268,290,866

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 268290866...
Checkpoint 268290866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,005.93341
Policy Entropy: 0.52954
Value Function Loss: 0.06865

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04893
Policy Update Magnitude: 0.01910
Value Function Update Magnitude: 0.05947

Collected Steps per Second: 5,576.70333
Overall Steps per Second: 4,964.60188

Timestep Collection Time: 8.96982
Timestep Consumption Time: 1.10592
PPO Batch Consumption Time: 0.09539
Total Iteration Time: 10.07573

Cumulative Model Updates: 16,071
Cumulative Timesteps: 268,340,888

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,244.05403
Policy Entropy: 0.53002
Value Function Loss: 0.07308

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04241
Policy Update Magnitude: 0.02905
Value Function Update Magnitude: 0.06519

Collected Steps per Second: 5,623.15732
Overall Steps per Second: 4,970.82209

Timestep Collection Time: 8.89358
Timestep Consumption Time: 1.16713
PPO Batch Consumption Time: 0.09352
Total Iteration Time: 10.06071

Cumulative Model Updates: 16,074
Cumulative Timesteps: 268,390,898

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 268390898...
Checkpoint 268390898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,269.48828
Policy Entropy: 0.52031
Value Function Loss: 0.08042

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04658
Policy Update Magnitude: 0.02490
Value Function Update Magnitude: 0.07454

Collected Steps per Second: 5,702.33772
Overall Steps per Second: 5,069.84569

Timestep Collection Time: 8.76833
Timestep Consumption Time: 1.09390
PPO Batch Consumption Time: 0.08473
Total Iteration Time: 9.86223

Cumulative Model Updates: 16,077
Cumulative Timesteps: 268,440,898

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,127.06756
Policy Entropy: 0.51655
Value Function Loss: 0.07272

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03639
Policy Update Magnitude: 0.02457
Value Function Update Magnitude: 0.07248

Collected Steps per Second: 5,590.94841
Overall Steps per Second: 4,963.64879

Timestep Collection Time: 8.94589
Timestep Consumption Time: 1.13057
PPO Batch Consumption Time: 0.08683
Total Iteration Time: 10.07646

Cumulative Model Updates: 16,080
Cumulative Timesteps: 268,490,914

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 268490914...
Checkpoint 268490914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,567.49393
Policy Entropy: 0.51177
Value Function Loss: 0.07518

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.03043
Policy Update Magnitude: 0.02395
Value Function Update Magnitude: 0.06774

Collected Steps per Second: 5,677.27398
Overall Steps per Second: 5,034.60204

Timestep Collection Time: 8.81092
Timestep Consumption Time: 1.12472
PPO Batch Consumption Time: 0.08407
Total Iteration Time: 9.93564

Cumulative Model Updates: 16,083
Cumulative Timesteps: 268,540,936

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,418.26028
Policy Entropy: 0.51109
Value Function Loss: 0.07782

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02501
Policy Update Magnitude: 0.02312
Value Function Update Magnitude: 0.06295

Collected Steps per Second: 5,723.68502
Overall Steps per Second: 5,072.48137

Timestep Collection Time: 8.73913
Timestep Consumption Time: 1.12193
PPO Batch Consumption Time: 0.08872
Total Iteration Time: 9.86105

Cumulative Model Updates: 16,086
Cumulative Timesteps: 268,590,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 268590956...
Checkpoint 268590956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,963.75456
Policy Entropy: 0.51233
Value Function Loss: 0.08585

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.02193
Value Function Update Magnitude: 0.07058

Collected Steps per Second: 5,604.42544
Overall Steps per Second: 4,974.89959

Timestep Collection Time: 8.92545
Timestep Consumption Time: 1.12943
PPO Batch Consumption Time: 0.08751
Total Iteration Time: 10.05488

Cumulative Model Updates: 16,089
Cumulative Timesteps: 268,640,978

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,203.51885
Policy Entropy: 0.50770
Value Function Loss: 0.09136

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02745
Policy Update Magnitude: 0.02321
Value Function Update Magnitude: 0.07329

Collected Steps per Second: 5,340.06194
Overall Steps per Second: 4,761.13633

Timestep Collection Time: 9.36618
Timestep Consumption Time: 1.13887
PPO Batch Consumption Time: 0.08754
Total Iteration Time: 10.50506

Cumulative Model Updates: 16,092
Cumulative Timesteps: 268,690,994

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 268690994...
Checkpoint 268690994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,447.86797
Policy Entropy: 0.51107
Value Function Loss: 0.09293

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03531
Policy Update Magnitude: 0.02296
Value Function Update Magnitude: 0.05403

Collected Steps per Second: 5,293.30121
Overall Steps per Second: 4,732.99283

Timestep Collection Time: 9.44741
Timestep Consumption Time: 1.11842
PPO Batch Consumption Time: 0.08920
Total Iteration Time: 10.56583

Cumulative Model Updates: 16,095
Cumulative Timesteps: 268,741,002

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,793.76981
Policy Entropy: 0.50882
Value Function Loss: 0.09666

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.02566
Value Function Update Magnitude: 0.06038

Collected Steps per Second: 5,138.97196
Overall Steps per Second: 4,627.69441

Timestep Collection Time: 9.73074
Timestep Consumption Time: 1.07507
PPO Batch Consumption Time: 0.08808
Total Iteration Time: 10.80581

Cumulative Model Updates: 16,098
Cumulative Timesteps: 268,791,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 268791008...
Checkpoint 268791008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,347.12956
Policy Entropy: 0.50980
Value Function Loss: 0.09009

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.05013
Policy Update Magnitude: 0.02352
Value Function Update Magnitude: 0.05505

Collected Steps per Second: 5,227.70931
Overall Steps per Second: 4,689.70331

Timestep Collection Time: 9.57207
Timestep Consumption Time: 1.09811
PPO Batch Consumption Time: 0.09087
Total Iteration Time: 10.67018

Cumulative Model Updates: 16,101
Cumulative Timesteps: 268,841,048

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,226.45720
Policy Entropy: 0.50833
Value Function Loss: 0.09603

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03795
Policy Update Magnitude: 0.02406
Value Function Update Magnitude: 0.06118

Collected Steps per Second: 5,122.73958
Overall Steps per Second: 4,603.98719

Timestep Collection Time: 9.76392
Timestep Consumption Time: 1.10015
PPO Batch Consumption Time: 0.09474
Total Iteration Time: 10.86406

Cumulative Model Updates: 16,104
Cumulative Timesteps: 268,891,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 268891066...
Checkpoint 268891066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,333.36450
Policy Entropy: 0.51517
Value Function Loss: 0.08857

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.05377
Policy Update Magnitude: 0.02370
Value Function Update Magnitude: 0.04714

Collected Steps per Second: 5,642.86400
Overall Steps per Second: 4,999.68542

Timestep Collection Time: 8.86642
Timestep Consumption Time: 1.14061
PPO Batch Consumption Time: 0.10768
Total Iteration Time: 10.00703

Cumulative Model Updates: 16,107
Cumulative Timesteps: 268,941,098

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,281.44052
Policy Entropy: 0.51268
Value Function Loss: 0.09378

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02987
Policy Update Magnitude: 0.02389
Value Function Update Magnitude: 0.03931

Collected Steps per Second: 5,491.12888
Overall Steps per Second: 4,899.21145

Timestep Collection Time: 9.11033
Timestep Consumption Time: 1.10070
PPO Batch Consumption Time: 0.09124
Total Iteration Time: 10.21103

Cumulative Model Updates: 16,110
Cumulative Timesteps: 268,991,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 268991124...
Checkpoint 268991124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,135.24254
Policy Entropy: 0.51161
Value Function Loss: 0.09804

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.04885
Policy Update Magnitude: 0.02600
Value Function Update Magnitude: 0.03419

Collected Steps per Second: 5,284.91659
Overall Steps per Second: 4,716.63924

Timestep Collection Time: 9.46883
Timestep Consumption Time: 1.14084
PPO Batch Consumption Time: 0.08921
Total Iteration Time: 10.60967

Cumulative Model Updates: 16,113
Cumulative Timesteps: 269,041,166

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,411.75337
Policy Entropy: 0.51326
Value Function Loss: 0.10100

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.06269
Policy Update Magnitude: 0.02529
Value Function Update Magnitude: 0.03171

Collected Steps per Second: 5,392.43839
Overall Steps per Second: 4,834.10656

Timestep Collection Time: 9.27484
Timestep Consumption Time: 1.07123
PPO Batch Consumption Time: 0.08764
Total Iteration Time: 10.34607

Cumulative Model Updates: 16,116
Cumulative Timesteps: 269,091,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 269091180...
Checkpoint 269091180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,033.19082
Policy Entropy: 0.52065
Value Function Loss: 0.09916

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04773
Policy Update Magnitude: 0.02511
Value Function Update Magnitude: 0.03029

Collected Steps per Second: 5,233.21503
Overall Steps per Second: 4,686.32557

Timestep Collection Time: 9.56047
Timestep Consumption Time: 1.11570
PPO Batch Consumption Time: 0.09066
Total Iteration Time: 10.67617

Cumulative Model Updates: 16,119
Cumulative Timesteps: 269,141,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,929.83610
Policy Entropy: 0.52398
Value Function Loss: 0.08915

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04283
Policy Update Magnitude: 0.02311
Value Function Update Magnitude: 0.02692

Collected Steps per Second: 5,472.66264
Overall Steps per Second: 4,889.80058

Timestep Collection Time: 9.13961
Timestep Consumption Time: 1.08944
PPO Batch Consumption Time: 0.08732
Total Iteration Time: 10.22905

Cumulative Model Updates: 16,122
Cumulative Timesteps: 269,191,230

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 269191230...
Checkpoint 269191230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,473.24745
Policy Entropy: 0.53132
Value Function Loss: 0.07929

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03801
Policy Update Magnitude: 0.02425
Value Function Update Magnitude: 0.02989

Collected Steps per Second: 5,264.56209
Overall Steps per Second: 4,714.92174

Timestep Collection Time: 9.49975
Timestep Consumption Time: 1.10743
PPO Batch Consumption Time: 0.09073
Total Iteration Time: 10.60718

Cumulative Model Updates: 16,125
Cumulative Timesteps: 269,241,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,811.17098
Policy Entropy: 0.53291
Value Function Loss: 0.08098

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04397
Policy Update Magnitude: 0.02194
Value Function Update Magnitude: 0.02708

Collected Steps per Second: 5,442.76836
Overall Steps per Second: 4,853.90355

Timestep Collection Time: 9.18797
Timestep Consumption Time: 1.11466
PPO Batch Consumption Time: 0.09004
Total Iteration Time: 10.30264

Cumulative Model Updates: 16,128
Cumulative Timesteps: 269,291,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 269291250...
Checkpoint 269291250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,743.81765
Policy Entropy: 0.53126
Value Function Loss: 0.08058

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.04073
Policy Update Magnitude: 0.02285
Value Function Update Magnitude: 0.02486

Collected Steps per Second: 5,431.86273
Overall Steps per Second: 4,836.79355

Timestep Collection Time: 9.21084
Timestep Consumption Time: 1.13321
PPO Batch Consumption Time: 0.09927
Total Iteration Time: 10.34404

Cumulative Model Updates: 16,131
Cumulative Timesteps: 269,341,282

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,321.82180
Policy Entropy: 0.52698
Value Function Loss: 0.09760

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05675
Policy Update Magnitude: 0.02292
Value Function Update Magnitude: 0.02871

Collected Steps per Second: 5,605.06845
Overall Steps per Second: 4,946.73091

Timestep Collection Time: 8.92300
Timestep Consumption Time: 1.18752
PPO Batch Consumption Time: 0.08292
Total Iteration Time: 10.11052

Cumulative Model Updates: 16,134
Cumulative Timesteps: 269,391,296

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 269391296...
Checkpoint 269391296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,253.15612
Policy Entropy: 0.52422
Value Function Loss: 0.09730

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.05245
Policy Update Magnitude: 0.02376
Value Function Update Magnitude: 0.02873

Collected Steps per Second: 5,504.06113
Overall Steps per Second: 4,955.58603

Timestep Collection Time: 9.08565
Timestep Consumption Time: 1.00558
PPO Batch Consumption Time: 0.08478
Total Iteration Time: 10.09124

Cumulative Model Updates: 16,137
Cumulative Timesteps: 269,441,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,597.32038
Policy Entropy: 0.52402
Value Function Loss: 0.10298

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.05089
Policy Update Magnitude: 0.02635
Value Function Update Magnitude: 0.03259

Collected Steps per Second: 5,483.97265
Overall Steps per Second: 4,939.79710

Timestep Collection Time: 9.11930
Timestep Consumption Time: 1.00460
PPO Batch Consumption Time: 0.09592
Total Iteration Time: 10.12390

Cumulative Model Updates: 16,140
Cumulative Timesteps: 269,491,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 269491314...
Checkpoint 269491314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,697.17484
Policy Entropy: 0.52694
Value Function Loss: 0.08766

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07165
Policy Update Magnitude: 0.02664
Value Function Update Magnitude: 0.03349

Collected Steps per Second: 5,638.51519
Overall Steps per Second: 5,068.72774

Timestep Collection Time: 8.87361
Timestep Consumption Time: 0.99750
PPO Batch Consumption Time: 0.08599
Total Iteration Time: 9.87112

Cumulative Model Updates: 16,143
Cumulative Timesteps: 269,541,348

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,039.55876
Policy Entropy: 0.52847
Value Function Loss: 0.07850

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.06912
Policy Update Magnitude: 0.02160
Value Function Update Magnitude: 0.04322

Collected Steps per Second: 5,587.27752
Overall Steps per Second: 5,030.25337

Timestep Collection Time: 8.95284
Timestep Consumption Time: 0.99139
PPO Batch Consumption Time: 0.08449
Total Iteration Time: 9.94423

Cumulative Model Updates: 16,146
Cumulative Timesteps: 269,591,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 269591370...
Checkpoint 269591370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,510.01151
Policy Entropy: 0.53785
Value Function Loss: 0.07078

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07085
Policy Update Magnitude: 0.02249
Value Function Update Magnitude: 0.04513

Collected Steps per Second: 5,604.89473
Overall Steps per Second: 5,039.55297

Timestep Collection Time: 8.92363
Timestep Consumption Time: 1.00106
PPO Batch Consumption Time: 0.08666
Total Iteration Time: 9.92469

Cumulative Model Updates: 16,149
Cumulative Timesteps: 269,641,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,504.68518
Policy Entropy: 0.53265
Value Function Loss: 0.07777

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05903
Policy Update Magnitude: 0.02201
Value Function Update Magnitude: 0.03870

Collected Steps per Second: 5,616.38034
Overall Steps per Second: 5,040.61425

Timestep Collection Time: 8.90716
Timestep Consumption Time: 1.01742
PPO Batch Consumption Time: 0.08660
Total Iteration Time: 9.92458

Cumulative Model Updates: 16,152
Cumulative Timesteps: 269,691,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 269691412...
Checkpoint 269691412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,302.84303
Policy Entropy: 0.53611
Value Function Loss: 0.08469

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05895
Policy Update Magnitude: 0.02364
Value Function Update Magnitude: 0.04416

Collected Steps per Second: 5,472.66084
Overall Steps per Second: 4,852.46951

Timestep Collection Time: 9.13888
Timestep Consumption Time: 1.16804
PPO Batch Consumption Time: 0.09006
Total Iteration Time: 10.30692

Cumulative Model Updates: 16,155
Cumulative Timesteps: 269,741,426

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,592.80380
Policy Entropy: 0.53465
Value Function Loss: 0.08914

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.06579
Policy Update Magnitude: 0.02462
Value Function Update Magnitude: 0.04642

Collected Steps per Second: 5,445.05021
Overall Steps per Second: 4,812.74945

Timestep Collection Time: 9.18339
Timestep Consumption Time: 1.20652
PPO Batch Consumption Time: 0.09034
Total Iteration Time: 10.38990

Cumulative Model Updates: 16,158
Cumulative Timesteps: 269,791,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 269791430...
Checkpoint 269791430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,138.99043
Policy Entropy: 0.54023
Value Function Loss: 0.08986

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03375
Policy Update Magnitude: 0.02451
Value Function Update Magnitude: 0.04087

Collected Steps per Second: 5,420.32992
Overall Steps per Second: 4,811.67593

Timestep Collection Time: 9.22748
Timestep Consumption Time: 1.16723
PPO Batch Consumption Time: 0.08932
Total Iteration Time: 10.39472

Cumulative Model Updates: 16,161
Cumulative Timesteps: 269,841,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,656.34339
Policy Entropy: 0.53545
Value Function Loss: 0.08358

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03528
Policy Update Magnitude: 0.02420
Value Function Update Magnitude: 0.03788

Collected Steps per Second: 5,446.38523
Overall Steps per Second: 4,818.95758

Timestep Collection Time: 9.18664
Timestep Consumption Time: 1.19610
PPO Batch Consumption Time: 0.08787
Total Iteration Time: 10.38274

Cumulative Model Updates: 16,164
Cumulative Timesteps: 269,891,480

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 269891480...
Checkpoint 269891480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,974.63682
Policy Entropy: 0.53161
Value Function Loss: 0.08912

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03048
Policy Update Magnitude: 0.02447
Value Function Update Magnitude: 0.04218

Collected Steps per Second: 5,400.63972
Overall Steps per Second: 4,800.38916

Timestep Collection Time: 9.26261
Timestep Consumption Time: 1.15822
PPO Batch Consumption Time: 0.09232
Total Iteration Time: 10.42082

Cumulative Model Updates: 16,167
Cumulative Timesteps: 269,941,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,699.17272
Policy Entropy: 0.52916
Value Function Loss: 0.09072

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.02611
Value Function Update Magnitude: 0.04453

Collected Steps per Second: 5,402.34854
Overall Steps per Second: 4,765.08837

Timestep Collection Time: 9.25857
Timestep Consumption Time: 1.23820
PPO Batch Consumption Time: 0.09053
Total Iteration Time: 10.49676

Cumulative Model Updates: 16,170
Cumulative Timesteps: 269,991,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 269991522...
Checkpoint 269991522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,329.24495
Policy Entropy: 0.53382
Value Function Loss: 0.08474

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03579
Policy Update Magnitude: 0.02608
Value Function Update Magnitude: 0.04953

Collected Steps per Second: 5,408.21520
Overall Steps per Second: 4,757.26954

Timestep Collection Time: 9.24852
Timestep Consumption Time: 1.26549
PPO Batch Consumption Time: 0.09213
Total Iteration Time: 10.51401

Cumulative Model Updates: 16,173
Cumulative Timesteps: 270,041,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,919.07214
Policy Entropy: 0.53698
Value Function Loss: 0.08274

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.05281
Policy Update Magnitude: 0.02677
Value Function Update Magnitude: 0.05571

Collected Steps per Second: 5,453.60259
Overall Steps per Second: 4,785.71337

Timestep Collection Time: 9.16862
Timestep Consumption Time: 1.27956
PPO Batch Consumption Time: 0.08923
Total Iteration Time: 10.44818

Cumulative Model Updates: 16,176
Cumulative Timesteps: 270,091,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 270091542...
Checkpoint 270091542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,215.18671
Policy Entropy: 0.53847
Value Function Loss: 0.07155

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04702
Policy Update Magnitude: 0.02446
Value Function Update Magnitude: 0.05024

Collected Steps per Second: 5,319.55530
Overall Steps per Second: 4,708.99800

Timestep Collection Time: 9.40492
Timestep Consumption Time: 1.21942
PPO Batch Consumption Time: 0.08474
Total Iteration Time: 10.62434

Cumulative Model Updates: 16,179
Cumulative Timesteps: 270,141,572

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,208.23203
Policy Entropy: 0.53277
Value Function Loss: 0.07423

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04620
Policy Update Magnitude: 0.02293
Value Function Update Magnitude: 0.04811

Collected Steps per Second: 5,665.70030
Overall Steps per Second: 5,005.19739

Timestep Collection Time: 8.82751
Timestep Consumption Time: 1.16491
PPO Batch Consumption Time: 0.08442
Total Iteration Time: 9.99241

Cumulative Model Updates: 16,182
Cumulative Timesteps: 270,191,586

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 270191586...
Checkpoint 270191586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,895.14029
Policy Entropy: 0.53738
Value Function Loss: 0.07863

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04507
Policy Update Magnitude: 0.02244
Value Function Update Magnitude: 0.04337

Collected Steps per Second: 5,384.44445
Overall Steps per Second: 4,753.46102

Timestep Collection Time: 9.28898
Timestep Consumption Time: 1.23304
PPO Batch Consumption Time: 0.09124
Total Iteration Time: 10.52202

Cumulative Model Updates: 16,185
Cumulative Timesteps: 270,241,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,510.32050
Policy Entropy: 0.53670
Value Function Loss: 0.08696

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02942
Policy Update Magnitude: 0.02172
Value Function Update Magnitude: 0.03782

Collected Steps per Second: 5,409.10734
Overall Steps per Second: 4,781.13020

Timestep Collection Time: 9.24441
Timestep Consumption Time: 1.21421
PPO Batch Consumption Time: 0.08882
Total Iteration Time: 10.45862

Cumulative Model Updates: 16,188
Cumulative Timesteps: 270,291,606

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 270291606...
Checkpoint 270291606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,587.80161
Policy Entropy: 0.53879
Value Function Loss: 0.08503

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.02211
Value Function Update Magnitude: 0.04316

Collected Steps per Second: 5,414.72795
Overall Steps per Second: 4,800.72675

Timestep Collection Time: 9.23961
Timestep Consumption Time: 1.18172
PPO Batch Consumption Time: 0.08516
Total Iteration Time: 10.42134

Cumulative Model Updates: 16,191
Cumulative Timesteps: 270,341,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,966.80052
Policy Entropy: 0.53020
Value Function Loss: 0.09352

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01880
Policy Update Magnitude: 0.02312
Value Function Update Magnitude: 0.04068

Collected Steps per Second: 5,622.86354
Overall Steps per Second: 4,956.74246

Timestep Collection Time: 8.89618
Timestep Consumption Time: 1.19553
PPO Batch Consumption Time: 0.08450
Total Iteration Time: 10.09171

Cumulative Model Updates: 16,194
Cumulative Timesteps: 270,391,658

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 270391658...
Checkpoint 270391658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,383.42022
Policy Entropy: 0.52991
Value Function Loss: 0.09028

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01788
Policy Update Magnitude: 0.02486
Value Function Update Magnitude: 0.03898

Collected Steps per Second: 5,918.80467
Overall Steps per Second: 5,149.62535

Timestep Collection Time: 8.45069
Timestep Consumption Time: 1.26225
PPO Batch Consumption Time: 0.08902
Total Iteration Time: 9.71294

Cumulative Model Updates: 16,197
Cumulative Timesteps: 270,441,676

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,066.49837
Policy Entropy: 0.52972
Value Function Loss: 0.09048

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02259
Policy Update Magnitude: 0.02424
Value Function Update Magnitude: 0.03753

Collected Steps per Second: 7,536.36229
Overall Steps per Second: 6,282.36232

Timestep Collection Time: 6.63954
Timestep Consumption Time: 1.32530
PPO Batch Consumption Time: 0.08461
Total Iteration Time: 7.96484

Cumulative Model Updates: 16,200
Cumulative Timesteps: 270,491,714

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 270491714...
Checkpoint 270491714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,922.28365
Policy Entropy: 0.53728
Value Function Loss: 0.07800

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.02338
Value Function Update Magnitude: 0.03587

Collected Steps per Second: 5,672.68106
Overall Steps per Second: 5,003.51797

Timestep Collection Time: 8.81594
Timestep Consumption Time: 1.17903
PPO Batch Consumption Time: 0.08744
Total Iteration Time: 9.99497

Cumulative Model Updates: 16,203
Cumulative Timesteps: 270,541,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,728.39611
Policy Entropy: 0.53765
Value Function Loss: 0.07549

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02827
Policy Update Magnitude: 0.02283
Value Function Update Magnitude: 0.03833

Collected Steps per Second: 5,669.68985
Overall Steps per Second: 5,095.74060

Timestep Collection Time: 8.81918
Timestep Consumption Time: 0.99333
PPO Batch Consumption Time: 0.08887
Total Iteration Time: 9.81251

Cumulative Model Updates: 16,206
Cumulative Timesteps: 270,591,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 270591726...
Checkpoint 270591726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,232.89262
Policy Entropy: 0.53921
Value Function Loss: 0.07795

Mean KL Divergence: 0.00204
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.02227
Value Function Update Magnitude: 0.03848

Collected Steps per Second: 14,370.05830
Overall Steps per Second: 11,502.34917

Timestep Collection Time: 3.48141
Timestep Consumption Time: 0.86797
PPO Batch Consumption Time: 0.05869
Total Iteration Time: 4.34937

Cumulative Model Updates: 16,209
Cumulative Timesteps: 270,641,754

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,658.15289
Policy Entropy: 0.53067
Value Function Loss: 0.08293

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01501
Policy Update Magnitude: 0.02378
Value Function Update Magnitude: 0.04040

Collected Steps per Second: 18,326.14089
Overall Steps per Second: 13,162.93874

Timestep Collection Time: 2.72900
Timestep Consumption Time: 1.07046
PPO Batch Consumption Time: 0.08044
Total Iteration Time: 3.79946

Cumulative Model Updates: 16,212
Cumulative Timesteps: 270,691,766

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 270691766...
Checkpoint 270691766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,141.62760
Policy Entropy: 0.52845
Value Function Loss: 0.08265

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.02435
Value Function Update Magnitude: 0.03812

Collected Steps per Second: 12,672.31029
Overall Steps per Second: 9,922.54512

Timestep Collection Time: 3.94782
Timestep Consumption Time: 1.09403
PPO Batch Consumption Time: 0.11332
Total Iteration Time: 5.04185

Cumulative Model Updates: 16,215
Cumulative Timesteps: 270,741,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,451.98986
Policy Entropy: 0.52420
Value Function Loss: 0.07793

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02708
Policy Update Magnitude: 0.02123
Value Function Update Magnitude: 0.04096

Collected Steps per Second: 13,735.02708
Overall Steps per Second: 10,793.75938

Timestep Collection Time: 3.64106
Timestep Consumption Time: 0.99218
PPO Batch Consumption Time: 0.09495
Total Iteration Time: 4.63323

Cumulative Model Updates: 16,218
Cumulative Timesteps: 270,791,804

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 270791804...
Checkpoint 270791804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,481.31588
Policy Entropy: 0.53249
Value Function Loss: 0.07170

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01693
Policy Update Magnitude: 0.02111
Value Function Update Magnitude: 0.03610

Collected Steps per Second: 14,384.55840
Overall Steps per Second: 10,654.49997

Timestep Collection Time: 3.47595
Timestep Consumption Time: 1.21690
PPO Batch Consumption Time: 0.16166
Total Iteration Time: 4.69285

Cumulative Model Updates: 16,221
Cumulative Timesteps: 270,841,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,626.32216
Policy Entropy: 0.53932
Value Function Loss: 0.07255

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.02049
Policy Update Magnitude: 0.02079
Value Function Update Magnitude: 0.03695

Collected Steps per Second: 13,575.39624
Overall Steps per Second: 10,683.75042

Timestep Collection Time: 3.68461
Timestep Consumption Time: 0.99727
PPO Batch Consumption Time: 0.09301
Total Iteration Time: 4.68188

Cumulative Model Updates: 16,224
Cumulative Timesteps: 270,891,824

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 270891824...
Checkpoint 270891824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,657.96434
Policy Entropy: 0.53844
Value Function Loss: 0.07706

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01695
Policy Update Magnitude: 0.02126
Value Function Update Magnitude: 0.03613

Collected Steps per Second: 14,240.38026
Overall Steps per Second: 11,021.95509

Timestep Collection Time: 3.51423
Timestep Consumption Time: 1.02616
PPO Batch Consumption Time: 0.09911
Total Iteration Time: 4.54039

Cumulative Model Updates: 16,227
Cumulative Timesteps: 270,941,868

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,762.14862
Policy Entropy: 0.53653
Value Function Loss: 0.07977

Mean KL Divergence: 0.00152
SB3 Clip Fraction: 0.01443
Policy Update Magnitude: 0.02124
Value Function Update Magnitude: 0.03993

Collected Steps per Second: 14,150.73721
Overall Steps per Second: 10,994.29888

Timestep Collection Time: 3.53452
Timestep Consumption Time: 1.01475
PPO Batch Consumption Time: 0.10179
Total Iteration Time: 4.54927

Cumulative Model Updates: 16,230
Cumulative Timesteps: 270,991,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 270991884...
Checkpoint 270991884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,887.98063
Policy Entropy: 0.53307
Value Function Loss: 0.07983

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01649
Policy Update Magnitude: 0.02290
Value Function Update Magnitude: 0.03761

Collected Steps per Second: 13,724.19468
Overall Steps per Second: 10,963.71387

Timestep Collection Time: 3.64364
Timestep Consumption Time: 0.91741
PPO Batch Consumption Time: 0.09976
Total Iteration Time: 4.56105

Cumulative Model Updates: 16,233
Cumulative Timesteps: 271,041,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,763.54186
Policy Entropy: 0.52867
Value Function Loss: 0.07546

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01863
Policy Update Magnitude: 0.02164
Value Function Update Magnitude: 0.03973

Collected Steps per Second: 13,383.50757
Overall Steps per Second: 10,719.30327

Timestep Collection Time: 3.73714
Timestep Consumption Time: 0.92884
PPO Batch Consumption Time: 0.09910
Total Iteration Time: 4.66597

Cumulative Model Updates: 16,236
Cumulative Timesteps: 271,091,906

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 271091906...
Checkpoint 271091906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,906.64333
Policy Entropy: 0.52459
Value Function Loss: 0.07520

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02381
Policy Update Magnitude: 0.02069
Value Function Update Magnitude: 0.03543

Collected Steps per Second: 6,381.35629
Overall Steps per Second: 5,533.65423

Timestep Collection Time: 7.83940
Timestep Consumption Time: 1.20092
PPO Batch Consumption Time: 0.08751
Total Iteration Time: 9.04032

Cumulative Model Updates: 16,239
Cumulative Timesteps: 271,141,932

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,745.29233
Policy Entropy: 0.51981
Value Function Loss: 0.07140

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.02121
Value Function Update Magnitude: 0.04238

Collected Steps per Second: 5,378.53527
Overall Steps per Second: 4,783.80216

Timestep Collection Time: 9.30365
Timestep Consumption Time: 1.15665
PPO Batch Consumption Time: 0.09933
Total Iteration Time: 10.46030

Cumulative Model Updates: 16,242
Cumulative Timesteps: 271,191,972

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 271191972...
Checkpoint 271191972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,190.82543
Policy Entropy: 0.52580
Value Function Loss: 0.07181

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03156
Policy Update Magnitude: 0.02166
Value Function Update Magnitude: 0.03719

Collected Steps per Second: 5,338.77784
Overall Steps per Second: 4,771.68433

Timestep Collection Time: 9.36881
Timestep Consumption Time: 1.11344
PPO Batch Consumption Time: 0.08415
Total Iteration Time: 10.48225

Cumulative Model Updates: 16,245
Cumulative Timesteps: 271,241,990

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,663.21365
Policy Entropy: 0.52698
Value Function Loss: 0.06594

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.02955
Policy Update Magnitude: 0.02165
Value Function Update Magnitude: 0.04143

Collected Steps per Second: 17,366.28433
Overall Steps per Second: 13,864.23552

Timestep Collection Time: 2.88075
Timestep Consumption Time: 0.72767
PPO Batch Consumption Time: 0.03178
Total Iteration Time: 3.60842

Cumulative Model Updates: 16,248
Cumulative Timesteps: 271,292,018

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 271292018...
Checkpoint 271292018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,862.98007
Policy Entropy: 0.53282
Value Function Loss: 0.07009

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02665
Policy Update Magnitude: 0.02123
Value Function Update Magnitude: 0.05147

Collected Steps per Second: 17,546.77672
Overall Steps per Second: 13,205.29898

Timestep Collection Time: 2.84953
Timestep Consumption Time: 0.93683
PPO Batch Consumption Time: 0.09589
Total Iteration Time: 3.78636

Cumulative Model Updates: 16,251
Cumulative Timesteps: 271,342,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,413.18156
Policy Entropy: 0.53406
Value Function Loss: 0.06555

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03141
Policy Update Magnitude: 0.02195
Value Function Update Magnitude: 0.04615

Collected Steps per Second: 19,362.35490
Overall Steps per Second: 13,531.20069

Timestep Collection Time: 2.58264
Timestep Consumption Time: 1.11297
PPO Batch Consumption Time: 0.08789
Total Iteration Time: 3.69561

Cumulative Model Updates: 16,254
Cumulative Timesteps: 271,392,024

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 271392024...
Checkpoint 271392024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,326.77162
Policy Entropy: 0.53611
Value Function Loss: 0.06910

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.03001
Policy Update Magnitude: 0.02165
Value Function Update Magnitude: 0.04690

Collected Steps per Second: 19,469.43418
Overall Steps per Second: 14,908.45817

Timestep Collection Time: 2.56957
Timestep Consumption Time: 0.78611
PPO Batch Consumption Time: 0.03256
Total Iteration Time: 3.35568

Cumulative Model Updates: 16,257
Cumulative Timesteps: 271,442,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,269.80858
Policy Entropy: 0.53870
Value Function Loss: 0.07159

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.02124
Value Function Update Magnitude: 0.04108

Collected Steps per Second: 20,162.04706
Overall Steps per Second: 14,246.68495

Timestep Collection Time: 2.48040
Timestep Consumption Time: 1.02989
PPO Batch Consumption Time: 0.10295
Total Iteration Time: 3.51029

Cumulative Model Updates: 16,260
Cumulative Timesteps: 271,492,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 271492062...
Checkpoint 271492062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,406.73893
Policy Entropy: 0.53876
Value Function Loss: 0.07453

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03395
Policy Update Magnitude: 0.02228
Value Function Update Magnitude: 0.04805

Collected Steps per Second: 17,277.90334
Overall Steps per Second: 12,623.77654

Timestep Collection Time: 2.89399
Timestep Consumption Time: 1.06695
PPO Batch Consumption Time: 0.13043
Total Iteration Time: 3.96094

Cumulative Model Updates: 16,263
Cumulative Timesteps: 271,542,064

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,324.94156
Policy Entropy: 0.53544
Value Function Loss: 0.07763

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.04197
Policy Update Magnitude: 0.02425
Value Function Update Magnitude: 0.04995

Collected Steps per Second: 18,686.61798
Overall Steps per Second: 13,516.62449

Timestep Collection Time: 2.67732
Timestep Consumption Time: 1.02405
PPO Batch Consumption Time: 0.08748
Total Iteration Time: 3.70137

Cumulative Model Updates: 16,266
Cumulative Timesteps: 271,592,094

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 271592094...
Checkpoint 271592094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,362.87227
Policy Entropy: 0.54379
Value Function Loss: 0.07062

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 0.02346
Value Function Update Magnitude: 0.04858

Collected Steps per Second: 16,807.54767
Overall Steps per Second: 13,536.45612

Timestep Collection Time: 2.97640
Timestep Consumption Time: 0.71925
PPO Batch Consumption Time: 0.03093
Total Iteration Time: 3.69565

Cumulative Model Updates: 16,269
Cumulative Timesteps: 271,642,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,397.80046
Policy Entropy: 0.54032
Value Function Loss: 0.08342

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.02883
Value Function Update Magnitude: 0.03896

Collected Steps per Second: 22,141.54092
Overall Steps per Second: 16,463.66429

Timestep Collection Time: 2.25901
Timestep Consumption Time: 0.77907
PPO Batch Consumption Time: 0.03031
Total Iteration Time: 3.03808

Cumulative Model Updates: 16,272
Cumulative Timesteps: 271,692,138

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 271692138...
Checkpoint 271692138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,599.86609
Policy Entropy: 0.54669
Value Function Loss: 0.07639

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.03063
Policy Update Magnitude: 0.02534
Value Function Update Magnitude: 0.03169

Collected Steps per Second: 20,906.40909
Overall Steps per Second: 16,195.13251

Timestep Collection Time: 2.39295
Timestep Consumption Time: 0.69613
PPO Batch Consumption Time: 0.02877
Total Iteration Time: 3.08908

Cumulative Model Updates: 16,275
Cumulative Timesteps: 271,742,166

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,797.87761
Policy Entropy: 0.55483
Value Function Loss: 0.07578

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03737
Policy Update Magnitude: 0.02340
Value Function Update Magnitude: 0.02749

Collected Steps per Second: 20,587.47290
Overall Steps per Second: 15,918.43409

Timestep Collection Time: 2.43041
Timestep Consumption Time: 0.71286
PPO Batch Consumption Time: 0.03230
Total Iteration Time: 3.14327

Cumulative Model Updates: 16,278
Cumulative Timesteps: 271,792,202

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 271792202...
Checkpoint 271792202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,456.56712
Policy Entropy: 0.55622
Value Function Loss: 0.05797

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03909
Policy Update Magnitude: 0.02244
Value Function Update Magnitude: 0.02481

Collected Steps per Second: 22,432.31603
Overall Steps per Second: 15,515.45464

Timestep Collection Time: 2.22919
Timestep Consumption Time: 0.99379
PPO Batch Consumption Time: 0.11467
Total Iteration Time: 3.22298

Cumulative Model Updates: 16,281
Cumulative Timesteps: 271,842,208

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,075.53596
Policy Entropy: 0.55844
Value Function Loss: 0.06605

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.06106
Policy Update Magnitude: 0.02170
Value Function Update Magnitude: 0.02315

Collected Steps per Second: 22,445.28010
Overall Steps per Second: 16,964.92235

Timestep Collection Time: 2.22871
Timestep Consumption Time: 0.71996
PPO Batch Consumption Time: 0.03223
Total Iteration Time: 2.94867

Cumulative Model Updates: 16,284
Cumulative Timesteps: 271,892,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 271892232...
Checkpoint 271892232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,494.99849
Policy Entropy: 0.54920
Value Function Loss: 0.06862

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.05125
Policy Update Magnitude: 0.02283
Value Function Update Magnitude: 0.02526

Collected Steps per Second: 22,237.75810
Overall Steps per Second: 16,387.90380

Timestep Collection Time: 2.24942
Timestep Consumption Time: 0.80296
PPO Batch Consumption Time: 0.05112
Total Iteration Time: 3.05237

Cumulative Model Updates: 16,287
Cumulative Timesteps: 271,942,254

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,900.26676
Policy Entropy: 0.54756
Value Function Loss: 0.07966

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.04119
Policy Update Magnitude: 0.03090
Value Function Update Magnitude: 0.02463

Collected Steps per Second: 22,202.53101
Overall Steps per Second: 16,788.86628

Timestep Collection Time: 2.25380
Timestep Consumption Time: 0.72675
PPO Batch Consumption Time: 0.02996
Total Iteration Time: 2.98055

Cumulative Model Updates: 16,290
Cumulative Timesteps: 271,992,294

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 271992294...
Checkpoint 271992294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,455.05081
Policy Entropy: 0.54744
Value Function Loss: 0.07429

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.03691
Value Function Update Magnitude: 0.02440

Collected Steps per Second: 20,928.19923
Overall Steps per Second: 15,590.51920

Timestep Collection Time: 2.39017
Timestep Consumption Time: 0.81832
PPO Batch Consumption Time: 0.05231
Total Iteration Time: 3.20849

Cumulative Model Updates: 16,293
Cumulative Timesteps: 272,042,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,125.13824
Policy Entropy: 0.55099
Value Function Loss: 0.08463

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.03671
Value Function Update Magnitude: 0.02529

Collected Steps per Second: 19,653.03867
Overall Steps per Second: 14,964.08237

Timestep Collection Time: 2.54454
Timestep Consumption Time: 0.79733
PPO Batch Consumption Time: 0.03128
Total Iteration Time: 3.34187

Cumulative Model Updates: 16,296
Cumulative Timesteps: 272,092,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 272092324...
Checkpoint 272092324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,413.95775
Policy Entropy: 0.54431
Value Function Loss: 0.09014

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.03849
Value Function Update Magnitude: 0.02866

Collected Steps per Second: 15,969.03183
Overall Steps per Second: 12,792.09305

Timestep Collection Time: 3.13106
Timestep Consumption Time: 0.77760
PPO Batch Consumption Time: 0.03151
Total Iteration Time: 3.90866

Cumulative Model Updates: 16,299
Cumulative Timesteps: 272,142,324

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,220.36704
Policy Entropy: 0.55042
Value Function Loss: 0.08556

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.03080
Policy Update Magnitude: 0.03785
Value Function Update Magnitude: 0.02713

Collected Steps per Second: 19,967.06066
Overall Steps per Second: 14,669.11398

Timestep Collection Time: 2.50473
Timestep Consumption Time: 0.90461
PPO Batch Consumption Time: 0.08020
Total Iteration Time: 3.40934

Cumulative Model Updates: 16,302
Cumulative Timesteps: 272,192,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 272192336...
Checkpoint 272192336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,883.64937
Policy Entropy: 0.55628
Value Function Loss: 0.07849

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02751
Policy Update Magnitude: 0.03696
Value Function Update Magnitude: 0.02584

Collected Steps per Second: 19,368.59945
Overall Steps per Second: 14,786.27731

Timestep Collection Time: 2.58398
Timestep Consumption Time: 0.80078
PPO Batch Consumption Time: 0.02985
Total Iteration Time: 3.38476

Cumulative Model Updates: 16,305
Cumulative Timesteps: 272,242,384

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,248.74352
Policy Entropy: 0.56217
Value Function Loss: 0.06947

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.04121
Policy Update Magnitude: 0.03441
Value Function Update Magnitude: 0.02617

Collected Steps per Second: 21,046.34740
Overall Steps per Second: 14,659.45066

Timestep Collection Time: 2.37723
Timestep Consumption Time: 1.03572
PPO Batch Consumption Time: 0.10067
Total Iteration Time: 3.41295

Cumulative Model Updates: 16,308
Cumulative Timesteps: 272,292,416

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 272292416...
Checkpoint 272292416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,783.26251
Policy Entropy: 0.55694
Value Function Loss: 0.06701

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02935
Policy Update Magnitude: 0.03123
Value Function Update Magnitude: 0.02303

Collected Steps per Second: 18,721.77854
Overall Steps per Second: 14,049.81510

Timestep Collection Time: 2.67133
Timestep Consumption Time: 0.88829
PPO Batch Consumption Time: 0.06695
Total Iteration Time: 3.55962

Cumulative Model Updates: 16,311
Cumulative Timesteps: 272,342,428

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,873.75110
Policy Entropy: 0.55743
Value Function Loss: 0.07044

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03449
Policy Update Magnitude: 0.03835
Value Function Update Magnitude: 0.02576

Collected Steps per Second: 18,592.27290
Overall Steps per Second: 13,773.01896

Timestep Collection Time: 2.69069
Timestep Consumption Time: 0.94149
PPO Batch Consumption Time: 0.08177
Total Iteration Time: 3.63217

Cumulative Model Updates: 16,314
Cumulative Timesteps: 272,392,454

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 272392454...
Checkpoint 272392454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,836.24654
Policy Entropy: 0.55141
Value Function Loss: 0.07510

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02959
Policy Update Magnitude: 0.03083
Value Function Update Magnitude: 0.02548

Collected Steps per Second: 16,819.06367
Overall Steps per Second: 12,725.61342

Timestep Collection Time: 2.97567
Timestep Consumption Time: 0.95718
PPO Batch Consumption Time: 0.07827
Total Iteration Time: 3.93286

Cumulative Model Updates: 16,317
Cumulative Timesteps: 272,442,502

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,012.61699
Policy Entropy: 0.55370
Value Function Loss: 0.07833

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02924
Policy Update Magnitude: 0.02905
Value Function Update Magnitude: 0.02663

Collected Steps per Second: 15,738.91221
Overall Steps per Second: 11,742.09924

Timestep Collection Time: 3.17697
Timestep Consumption Time: 1.08139
PPO Batch Consumption Time: 0.10281
Total Iteration Time: 4.25835

Cumulative Model Updates: 16,320
Cumulative Timesteps: 272,492,504

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 272492504...
Checkpoint 272492504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,503.89097
Policy Entropy: 0.55541
Value Function Loss: 0.07142

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.01988
Policy Update Magnitude: 0.02800
Value Function Update Magnitude: 0.02820

Collected Steps per Second: 16,764.53410
Overall Steps per Second: 12,685.57718

Timestep Collection Time: 2.98261
Timestep Consumption Time: 0.95904
PPO Batch Consumption Time: 0.10647
Total Iteration Time: 3.94164

Cumulative Model Updates: 16,323
Cumulative Timesteps: 272,542,506

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,576.71230
Policy Entropy: 0.55873
Value Function Loss: 0.07145

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.03026
Value Function Update Magnitude: 0.02689

Collected Steps per Second: 17,301.54066
Overall Steps per Second: 13,393.63306

Timestep Collection Time: 2.89153
Timestep Consumption Time: 0.84367
PPO Batch Consumption Time: 0.08049
Total Iteration Time: 3.73521

Cumulative Model Updates: 16,326
Cumulative Timesteps: 272,592,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 272592534...
Checkpoint 272592534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,534.40642
Policy Entropy: 0.55178
Value Function Loss: 0.07940

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02228
Policy Update Magnitude: 0.03323
Value Function Update Magnitude: 0.02571

Collected Steps per Second: 16,765.27506
Overall Steps per Second: 12,972.99103

Timestep Collection Time: 2.98414
Timestep Consumption Time: 0.87233
PPO Batch Consumption Time: 0.07992
Total Iteration Time: 3.85647

Cumulative Model Updates: 16,329
Cumulative Timesteps: 272,642,564

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,388.53969
Policy Entropy: 0.55450
Value Function Loss: 0.08597

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01388
Policy Update Magnitude: 0.04000
Value Function Update Magnitude: 0.02465

Collected Steps per Second: 18,842.57207
Overall Steps per Second: 14,652.17434

Timestep Collection Time: 2.65420
Timestep Consumption Time: 0.75908
PPO Batch Consumption Time: 0.06083
Total Iteration Time: 3.41328

Cumulative Model Updates: 16,332
Cumulative Timesteps: 272,692,576

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 272692576...
Checkpoint 272692576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,540.49303
Policy Entropy: 0.55025
Value Function Loss: 0.09712

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03964
Policy Update Magnitude: 0.03481
Value Function Update Magnitude: 0.02890

Collected Steps per Second: 16,297.34967
Overall Steps per Second: 13,449.45105

Timestep Collection Time: 3.06921
Timestep Consumption Time: 0.64990
PPO Batch Consumption Time: 0.02846
Total Iteration Time: 3.71911

Cumulative Model Updates: 16,335
Cumulative Timesteps: 272,742,596

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,640.67096
Policy Entropy: 0.55560
Value Function Loss: 0.08872

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.02968
Value Function Update Magnitude: 0.02981

Collected Steps per Second: 19,180.50684
Overall Steps per Second: 14,639.77662

Timestep Collection Time: 2.60713
Timestep Consumption Time: 0.80864
PPO Batch Consumption Time: 0.08010
Total Iteration Time: 3.41576

Cumulative Model Updates: 16,338
Cumulative Timesteps: 272,792,602

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 272792602...
Checkpoint 272792602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,138.66772
Policy Entropy: 0.55731
Value Function Loss: 0.09580

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01925
Policy Update Magnitude: 0.02930
Value Function Update Magnitude: 0.03237

Collected Steps per Second: 20,739.74637
Overall Steps per Second: 14,891.12835

Timestep Collection Time: 2.41179
Timestep Consumption Time: 0.94725
PPO Batch Consumption Time: 0.11716
Total Iteration Time: 3.35905

Cumulative Model Updates: 16,341
Cumulative Timesteps: 272,842,622

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,264.01270
Policy Entropy: 0.56972
Value Function Loss: 0.08563

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.02777
Value Function Update Magnitude: 0.03552

Collected Steps per Second: 18,520.32427
Overall Steps per Second: 13,944.53555

Timestep Collection Time: 2.70125
Timestep Consumption Time: 0.88639
PPO Batch Consumption Time: 0.09909
Total Iteration Time: 3.58764

Cumulative Model Updates: 16,344
Cumulative Timesteps: 272,892,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 272892650...
Checkpoint 272892650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,409.77098
Policy Entropy: 0.57384
Value Function Loss: 0.08442

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03585
Policy Update Magnitude: 0.02702
Value Function Update Magnitude: 0.02974

Collected Steps per Second: 13,234.15766
Overall Steps per Second: 10,800.94423

Timestep Collection Time: 3.78007
Timestep Consumption Time: 0.85157
PPO Batch Consumption Time: 0.08762
Total Iteration Time: 4.63163

Cumulative Model Updates: 16,347
Cumulative Timesteps: 272,942,676

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,221.66268
Policy Entropy: 0.57672
Value Function Loss: 0.07533

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 0.02556
Value Function Update Magnitude: 0.02727

Collected Steps per Second: 18,178.14311
Overall Steps per Second: 14,111.07002

Timestep Collection Time: 2.75122
Timestep Consumption Time: 0.79295
PPO Batch Consumption Time: 0.06479
Total Iteration Time: 3.54417

Cumulative Model Updates: 16,350
Cumulative Timesteps: 272,992,688

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 272992688...
Checkpoint 272992688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,884.78821
Policy Entropy: 0.56979
Value Function Loss: 0.08156

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02783
Policy Update Magnitude: 0.02443
Value Function Update Magnitude: 0.02641

Collected Steps per Second: 18,060.60293
Overall Steps per Second: 13,105.35600

Timestep Collection Time: 2.76945
Timestep Consumption Time: 1.04715
PPO Batch Consumption Time: 0.11080
Total Iteration Time: 3.81661

Cumulative Model Updates: 16,353
Cumulative Timesteps: 273,042,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,084.81140
Policy Entropy: 0.56604
Value Function Loss: 0.08535

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03589
Policy Update Magnitude: 0.02637
Value Function Update Magnitude: 0.02531

Collected Steps per Second: 17,053.59660
Overall Steps per Second: 13,120.58041

Timestep Collection Time: 2.93475
Timestep Consumption Time: 0.87972
PPO Batch Consumption Time: 0.06617
Total Iteration Time: 3.81447

Cumulative Model Updates: 16,356
Cumulative Timesteps: 273,092,754

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 273092754...
Checkpoint 273092754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,880.25103
Policy Entropy: 0.57131
Value Function Loss: 0.08820

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03623
Policy Update Magnitude: 0.02759
Value Function Update Magnitude: 0.02753

Collected Steps per Second: 19,128.43071
Overall Steps per Second: 13,828.46986

Timestep Collection Time: 2.61485
Timestep Consumption Time: 1.00218
PPO Batch Consumption Time: 0.11747
Total Iteration Time: 3.61703

Cumulative Model Updates: 16,359
Cumulative Timesteps: 273,142,772

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,609.29673
Policy Entropy: 0.57545
Value Function Loss: 0.07893

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03522
Policy Update Magnitude: 0.02450
Value Function Update Magnitude: 0.02690

Collected Steps per Second: 18,049.70707
Overall Steps per Second: 13,376.76288

Timestep Collection Time: 2.77101
Timestep Consumption Time: 0.96801
PPO Batch Consumption Time: 0.11041
Total Iteration Time: 3.73902

Cumulative Model Updates: 16,362
Cumulative Timesteps: 273,192,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 273192788...
Checkpoint 273192788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,177.37088
Policy Entropy: 0.57977
Value Function Loss: 0.07525

Mean KL Divergence: 0.00206
SB3 Clip Fraction: 0.02452
Policy Update Magnitude: 0.02376
Value Function Update Magnitude: 0.02566

Collected Steps per Second: 19,436.96019
Overall Steps per Second: 14,056.40717

Timestep Collection Time: 2.57262
Timestep Consumption Time: 0.98476
PPO Batch Consumption Time: 0.12139
Total Iteration Time: 3.55738

Cumulative Model Updates: 16,365
Cumulative Timesteps: 273,242,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,148.43315
Policy Entropy: 0.58619
Value Function Loss: 0.07429

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02443
Policy Update Magnitude: 0.02347
Value Function Update Magnitude: 0.02877

Collected Steps per Second: 19,581.76452
Overall Steps per Second: 13,915.53344

Timestep Collection Time: 2.55442
Timestep Consumption Time: 1.04013
PPO Batch Consumption Time: 0.12207
Total Iteration Time: 3.59454

Cumulative Model Updates: 16,368
Cumulative Timesteps: 273,292,812

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 273292812...
Checkpoint 273292812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,980.01208
Policy Entropy: 0.58739
Value Function Loss: 0.06837

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.01999
Policy Update Magnitude: 0.02351
Value Function Update Magnitude: 0.02938

Collected Steps per Second: 19,176.94747
Overall Steps per Second: 14,907.40941

Timestep Collection Time: 2.60761
Timestep Consumption Time: 0.74683
PPO Batch Consumption Time: 0.04594
Total Iteration Time: 3.35444

Cumulative Model Updates: 16,371
Cumulative Timesteps: 273,342,818

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,219.11744
Policy Entropy: 0.58996
Value Function Loss: 0.06667

Mean KL Divergence: 0.00136
SB3 Clip Fraction: 0.01463
Policy Update Magnitude: 0.02489
Value Function Update Magnitude: 0.02837

Collected Steps per Second: 19,717.91358
Overall Steps per Second: 13,620.91726

Timestep Collection Time: 2.53627
Timestep Consumption Time: 1.13529
PPO Batch Consumption Time: 0.14284
Total Iteration Time: 3.67156

Cumulative Model Updates: 16,374
Cumulative Timesteps: 273,392,828

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 273392828...
Checkpoint 273392828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,830.91888
Policy Entropy: 0.58514
Value Function Loss: 0.05589

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02342
Policy Update Magnitude: 0.02361
Value Function Update Magnitude: 0.02463

Collected Steps per Second: 19,230.67682
Overall Steps per Second: 13,905.97181

Timestep Collection Time: 2.60116
Timestep Consumption Time: 0.99600
PPO Batch Consumption Time: 0.09870
Total Iteration Time: 3.59716

Cumulative Model Updates: 16,377
Cumulative Timesteps: 273,442,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,468.34703
Policy Entropy: 0.58090
Value Function Loss: 0.07094

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.02519
Value Function Update Magnitude: 0.02395

Collected Steps per Second: 20,298.31294
Overall Steps per Second: 14,889.81980

Timestep Collection Time: 2.46326
Timestep Consumption Time: 0.89474
PPO Batch Consumption Time: 0.07990
Total Iteration Time: 3.35800

Cumulative Model Updates: 16,380
Cumulative Timesteps: 273,492,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 273492850...
Checkpoint 273492850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,552.24346
Policy Entropy: 0.58327
Value Function Loss: 0.07811

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04813
Policy Update Magnitude: 0.02764
Value Function Update Magnitude: 0.02722

Collected Steps per Second: 21,104.58975
Overall Steps per Second: 14,930.90247

Timestep Collection Time: 2.36915
Timestep Consumption Time: 0.97961
PPO Batch Consumption Time: 0.11149
Total Iteration Time: 3.34876

Cumulative Model Updates: 16,383
Cumulative Timesteps: 273,542,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,536.34686
Policy Entropy: 0.58153
Value Function Loss: 0.09125

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.04425
Policy Update Magnitude: 0.02871
Value Function Update Magnitude: 0.03180

Collected Steps per Second: 19,692.21221
Overall Steps per Second: 14,677.52446

Timestep Collection Time: 2.53938
Timestep Consumption Time: 0.86760
PPO Batch Consumption Time: 0.07799
Total Iteration Time: 3.40698

Cumulative Model Updates: 16,386
Cumulative Timesteps: 273,592,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 273592856...
Checkpoint 273592856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,943.26334
Policy Entropy: 0.58091
Value Function Loss: 0.07780

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.04426
Policy Update Magnitude: 0.02862
Value Function Update Magnitude: 0.03002

Collected Steps per Second: 19,444.33944
Overall Steps per Second: 13,763.71721

Timestep Collection Time: 2.57401
Timestep Consumption Time: 1.06236
PPO Batch Consumption Time: 0.11961
Total Iteration Time: 3.63637

Cumulative Model Updates: 16,389
Cumulative Timesteps: 273,642,906

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,820.74641
Policy Entropy: 0.58195
Value Function Loss: 0.06947

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01699
Policy Update Magnitude: 0.02783
Value Function Update Magnitude: 0.02624

Collected Steps per Second: 19,646.69418
Overall Steps per Second: 14,103.88753

Timestep Collection Time: 2.54577
Timestep Consumption Time: 1.00048
PPO Batch Consumption Time: 0.11354
Total Iteration Time: 3.54626

Cumulative Model Updates: 16,392
Cumulative Timesteps: 273,692,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 273692922...
Checkpoint 273692922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,585.39059
Policy Entropy: 0.58638
Value Function Loss: 0.06328

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03799
Policy Update Magnitude: 0.02659
Value Function Update Magnitude: 0.02391

Collected Steps per Second: 19,475.70111
Overall Steps per Second: 13,761.09736

Timestep Collection Time: 2.56823
Timestep Consumption Time: 1.06651
PPO Batch Consumption Time: 0.12220
Total Iteration Time: 3.63474

Cumulative Model Updates: 16,395
Cumulative Timesteps: 273,742,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,987.50606
Policy Entropy: 0.58858
Value Function Loss: 0.06814

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03593
Policy Update Magnitude: 0.02343
Value Function Update Magnitude: 0.02469

Collected Steps per Second: 18,450.10623
Overall Steps per Second: 13,854.40009

Timestep Collection Time: 2.71066
Timestep Consumption Time: 0.89917
PPO Batch Consumption Time: 0.04817
Total Iteration Time: 3.60983

Cumulative Model Updates: 16,398
Cumulative Timesteps: 273,792,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 273792952...
Checkpoint 273792952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,635.38494
Policy Entropy: 0.58697
Value Function Loss: 0.07363

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02904
Policy Update Magnitude: 0.02336
Value Function Update Magnitude: 0.02498

Collected Steps per Second: 15,398.61029
Overall Steps per Second: 11,696.91296

Timestep Collection Time: 3.24822
Timestep Consumption Time: 1.02796
PPO Batch Consumption Time: 0.10873
Total Iteration Time: 4.27617

Cumulative Model Updates: 16,401
Cumulative Timesteps: 273,842,970

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,803.92780
Policy Entropy: 0.58884
Value Function Loss: 0.06689

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03125
Policy Update Magnitude: 0.02671
Value Function Update Magnitude: 0.02465

Collected Steps per Second: 14,512.26618
Overall Steps per Second: 11,309.27681

Timestep Collection Time: 3.44839
Timestep Consumption Time: 0.97665
PPO Batch Consumption Time: 0.03867
Total Iteration Time: 4.42504

Cumulative Model Updates: 16,404
Cumulative Timesteps: 273,893,014

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 273893014...
Checkpoint 273893014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,476.62140
Policy Entropy: 0.58859
Value Function Loss: 0.06822

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01533
Policy Update Magnitude: 0.02884
Value Function Update Magnitude: 0.02777

Collected Steps per Second: 17,449.62125
Overall Steps per Second: 13,405.00000

Timestep Collection Time: 2.86608
Timestep Consumption Time: 0.86477
PPO Batch Consumption Time: 0.06714
Total Iteration Time: 3.73085

Cumulative Model Updates: 16,407
Cumulative Timesteps: 273,943,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,107.53197
Policy Entropy: 0.58430
Value Function Loss: 0.06315

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.04327
Policy Update Magnitude: 0.02887
Value Function Update Magnitude: 0.02497

Collected Steps per Second: 12,395.03991
Overall Steps per Second: 9,746.88552

Timestep Collection Time: 4.03581
Timestep Consumption Time: 1.09650
PPO Batch Consumption Time: 0.10969
Total Iteration Time: 5.13231

Cumulative Model Updates: 16,410
Cumulative Timesteps: 273,993,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 273993050...
Checkpoint 273993050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,185.17713
Policy Entropy: 0.58512
Value Function Loss: 0.06382

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03542
Policy Update Magnitude: 0.02890
Value Function Update Magnitude: 0.02339

Collected Steps per Second: 6,449.26219
Overall Steps per Second: 5,611.34082

Timestep Collection Time: 7.75717
Timestep Consumption Time: 1.15835
PPO Batch Consumption Time: 0.11466
Total Iteration Time: 8.91552

Cumulative Model Updates: 16,413
Cumulative Timesteps: 274,043,078

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,433.62128
Policy Entropy: 0.58941
Value Function Loss: 0.06359

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.03819
Policy Update Magnitude: 0.02581
Value Function Update Magnitude: 0.02311

Collected Steps per Second: 5,285.47301
Overall Steps per Second: 4,781.71299

Timestep Collection Time: 9.46557
Timestep Consumption Time: 0.99721
PPO Batch Consumption Time: 0.10795
Total Iteration Time: 10.46278

Cumulative Model Updates: 16,416
Cumulative Timesteps: 274,093,108

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 274093108...
Checkpoint 274093108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,252.97160
Policy Entropy: 0.58754
Value Function Loss: 0.06333

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03235
Policy Update Magnitude: 0.02400
Value Function Update Magnitude: 0.02181

Collected Steps per Second: 5,253.17143
Overall Steps per Second: 4,755.86017

Timestep Collection Time: 9.52415
Timestep Consumption Time: 0.99592
PPO Batch Consumption Time: 0.10842
Total Iteration Time: 10.52007

Cumulative Model Updates: 16,419
Cumulative Timesteps: 274,143,140

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,028.26171
Policy Entropy: 0.58489
Value Function Loss: 0.06905

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.03775
Policy Update Magnitude: 0.02264
Value Function Update Magnitude: 0.02221

Collected Steps per Second: 5,173.14445
Overall Steps per Second: 4,674.34862

Timestep Collection Time: 9.66723
Timestep Consumption Time: 1.03158
PPO Batch Consumption Time: 0.11467
Total Iteration Time: 10.69882

Cumulative Model Updates: 16,422
Cumulative Timesteps: 274,193,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 274193150...
Checkpoint 274193150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,990.66482
Policy Entropy: 0.59131
Value Function Loss: 0.06409

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03570
Policy Update Magnitude: 0.02201
Value Function Update Magnitude: 0.02082

Collected Steps per Second: 5,214.55340
Overall Steps per Second: 4,714.33581

Timestep Collection Time: 9.59353
Timestep Consumption Time: 1.01793
PPO Batch Consumption Time: 0.11117
Total Iteration Time: 10.61146

Cumulative Model Updates: 16,425
Cumulative Timesteps: 274,243,176

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,921.13947
Policy Entropy: 0.58578
Value Function Loss: 0.06942

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03396
Policy Update Magnitude: 0.02242
Value Function Update Magnitude: 0.02138

Collected Steps per Second: 8,597.22560
Overall Steps per Second: 7,581.31291

Timestep Collection Time: 5.81792
Timestep Consumption Time: 0.77961
PPO Batch Consumption Time: 0.06179
Total Iteration Time: 6.59754

Cumulative Model Updates: 16,428
Cumulative Timesteps: 274,293,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 274293194...
Checkpoint 274293194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,081.74048
Policy Entropy: 0.59085
Value Function Loss: 0.07007

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.02207
Value Function Update Magnitude: 0.02291

Collected Steps per Second: 15,768.96033
Overall Steps per Second: 12,414.33747

Timestep Collection Time: 3.17205
Timestep Consumption Time: 0.85716
PPO Batch Consumption Time: 0.06977
Total Iteration Time: 4.02921

Cumulative Model Updates: 16,431
Cumulative Timesteps: 274,343,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,566.13413
Policy Entropy: 0.58349
Value Function Loss: 0.07766

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01687
Policy Update Magnitude: 0.02171
Value Function Update Magnitude: 0.02342

Collected Steps per Second: 16,895.21156
Overall Steps per Second: 12,925.80938

Timestep Collection Time: 2.96096
Timestep Consumption Time: 0.90928
PPO Batch Consumption Time: 0.09367
Total Iteration Time: 3.87024

Cumulative Model Updates: 16,434
Cumulative Timesteps: 274,393,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 274393240...
Checkpoint 274393240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,919.74967
Policy Entropy: 0.58584
Value Function Loss: 0.07360

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02006
Policy Update Magnitude: 0.02225
Value Function Update Magnitude: 0.02637

Collected Steps per Second: 16,884.31748
Overall Steps per Second: 13,001.54373

Timestep Collection Time: 2.96228
Timestep Consumption Time: 0.88465
PPO Batch Consumption Time: 0.07137
Total Iteration Time: 3.84693

Cumulative Model Updates: 16,437
Cumulative Timesteps: 274,443,256

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,099.39452
Policy Entropy: 0.59102
Value Function Loss: 0.06606

Mean KL Divergence: 0.00139
SB3 Clip Fraction: 0.01407
Policy Update Magnitude: 0.02331
Value Function Update Magnitude: 0.02450

Collected Steps per Second: 16,736.07695
Overall Steps per Second: 13,165.95024

Timestep Collection Time: 2.98935
Timestep Consumption Time: 0.81060
PPO Batch Consumption Time: 0.05859
Total Iteration Time: 3.79995

Cumulative Model Updates: 16,440
Cumulative Timesteps: 274,493,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 274493286...
Checkpoint 274493286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,015.13418
Policy Entropy: 0.59054
Value Function Loss: 0.06697

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.01011
Policy Update Magnitude: 0.02387
Value Function Update Magnitude: 0.02472

Collected Steps per Second: 16,872.06721
Overall Steps per Second: 12,974.48005

Timestep Collection Time: 2.96620
Timestep Consumption Time: 0.89106
PPO Batch Consumption Time: 0.06577
Total Iteration Time: 3.85726

Cumulative Model Updates: 16,443
Cumulative Timesteps: 274,543,332

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,867.05670
Policy Entropy: 0.59273
Value Function Loss: 0.06817

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02000
Policy Update Magnitude: 0.02324
Value Function Update Magnitude: 0.03006

Collected Steps per Second: 10,578.87897
Overall Steps per Second: 8,604.85994

Timestep Collection Time: 4.72905
Timestep Consumption Time: 1.08488
PPO Batch Consumption Time: 0.10988
Total Iteration Time: 5.81392

Cumulative Model Updates: 16,446
Cumulative Timesteps: 274,593,360

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 274593360...
Checkpoint 274593360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,062.54329
Policy Entropy: 0.59221
Value Function Loss: 0.07235

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.01302
Policy Update Magnitude: 0.02363
Value Function Update Magnitude: 0.02945

Collected Steps per Second: 5,242.67055
Overall Steps per Second: 4,688.73649

Timestep Collection Time: 9.54132
Timestep Consumption Time: 1.12723
PPO Batch Consumption Time: 0.11731
Total Iteration Time: 10.66855

Cumulative Model Updates: 16,449
Cumulative Timesteps: 274,643,382

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,467.99418
Policy Entropy: 0.60071
Value Function Loss: 0.07135

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.04058
Policy Update Magnitude: 0.02352
Value Function Update Magnitude: 0.02889

Collected Steps per Second: 5,279.01326
Overall Steps per Second: 4,730.85594

Timestep Collection Time: 9.47904
Timestep Consumption Time: 1.09832
PPO Batch Consumption Time: 0.11723
Total Iteration Time: 10.57737

Cumulative Model Updates: 16,452
Cumulative Timesteps: 274,693,422

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 274693422...
Checkpoint 274693422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,272.22298
Policy Entropy: 0.60283
Value Function Loss: 0.07072

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03319
Policy Update Magnitude: 0.02368
Value Function Update Magnitude: 0.02849

Collected Steps per Second: 12,117.06889
Overall Steps per Second: 10,041.83321

Timestep Collection Time: 4.12707
Timestep Consumption Time: 0.85290
PPO Batch Consumption Time: 0.04641
Total Iteration Time: 4.97997

Cumulative Model Updates: 16,455
Cumulative Timesteps: 274,743,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,363.73852
Policy Entropy: 0.60927
Value Function Loss: 0.06942

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.05038
Policy Update Magnitude: 0.02402
Value Function Update Magnitude: 0.02547

Collected Steps per Second: 13,690.56151
Overall Steps per Second: 10,528.69755

Timestep Collection Time: 3.65376
Timestep Consumption Time: 1.09726
PPO Batch Consumption Time: 0.11133
Total Iteration Time: 4.75102

Cumulative Model Updates: 16,458
Cumulative Timesteps: 274,793,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 274793452...
Checkpoint 274793452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,915.16457
Policy Entropy: 0.60351
Value Function Loss: 0.06447

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03047
Policy Update Magnitude: 0.02225
Value Function Update Magnitude: 0.02456

Collected Steps per Second: 12,653.79289
Overall Steps per Second: 9,794.46329

Timestep Collection Time: 3.95391
Timestep Consumption Time: 1.15428
PPO Batch Consumption Time: 0.11843
Total Iteration Time: 5.10819

Cumulative Model Updates: 16,461
Cumulative Timesteps: 274,843,484

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,219.74312
Policy Entropy: 0.60083
Value Function Loss: 0.07258

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03263
Policy Update Magnitude: 0.02275
Value Function Update Magnitude: 0.02507

Collected Steps per Second: 10,890.89835
Overall Steps per Second: 8,697.58121

Timestep Collection Time: 4.59283
Timestep Consumption Time: 1.15820
PPO Batch Consumption Time: 0.07781
Total Iteration Time: 5.75102

Cumulative Model Updates: 16,464
Cumulative Timesteps: 274,893,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 274893504...
Checkpoint 274893504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,108.02576
Policy Entropy: 0.59998
Value Function Loss: 0.06692

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.05259
Policy Update Magnitude: 0.02078
Value Function Update Magnitude: 0.02772

Collected Steps per Second: 6,862.38155
Overall Steps per Second: 5,817.15550

Timestep Collection Time: 7.28901
Timestep Consumption Time: 1.30969
PPO Batch Consumption Time: 0.09644
Total Iteration Time: 8.59870

Cumulative Model Updates: 16,467
Cumulative Timesteps: 274,943,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,477.88467
Policy Entropy: 0.60094
Value Function Loss: 0.07144

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.02160
Value Function Update Magnitude: 0.02623

Collected Steps per Second: 5,551.86846
Overall Steps per Second: 4,902.58831

Timestep Collection Time: 9.00814
Timestep Consumption Time: 1.19300
PPO Batch Consumption Time: 0.08827
Total Iteration Time: 10.20114

Cumulative Model Updates: 16,470
Cumulative Timesteps: 274,993,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 274993536...
Checkpoint 274993536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,840.49858
Policy Entropy: 0.60747
Value Function Loss: 0.05568

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03366
Policy Update Magnitude: 0.02113
Value Function Update Magnitude: 0.02507

Collected Steps per Second: 5,734.44866
Overall Steps per Second: 5,100.10661

Timestep Collection Time: 8.72551
Timestep Consumption Time: 1.08526
PPO Batch Consumption Time: 0.08635
Total Iteration Time: 9.81078

Cumulative Model Updates: 16,473
Cumulative Timesteps: 275,043,572

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,184.05459
Policy Entropy: 0.61226
Value Function Loss: 0.05440

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03709
Policy Update Magnitude: 0.02063
Value Function Update Magnitude: 0.02492

Collected Steps per Second: 5,615.31028
Overall Steps per Second: 4,965.61206

Timestep Collection Time: 8.90494
Timestep Consumption Time: 1.16512
PPO Batch Consumption Time: 0.08595
Total Iteration Time: 10.07006

Cumulative Model Updates: 16,476
Cumulative Timesteps: 275,093,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 275093576...
Checkpoint 275093576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,027.97203
Policy Entropy: 0.60879
Value Function Loss: 0.04796

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03538
Policy Update Magnitude: 0.02130
Value Function Update Magnitude: 0.02201

Collected Steps per Second: 5,306.99230
Overall Steps per Second: 4,807.44447

Timestep Collection Time: 9.42756
Timestep Consumption Time: 0.97963
PPO Batch Consumption Time: 0.08590
Total Iteration Time: 10.40719

Cumulative Model Updates: 16,479
Cumulative Timesteps: 275,143,608

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,751.67724
Policy Entropy: 0.61369
Value Function Loss: 0.06289

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04436
Policy Update Magnitude: 0.02226
Value Function Update Magnitude: 0.02159

Collected Steps per Second: 5,818.38042
Overall Steps per Second: 5,191.32237

Timestep Collection Time: 8.59380
Timestep Consumption Time: 1.03804
PPO Batch Consumption Time: 0.08366
Total Iteration Time: 9.63184

Cumulative Model Updates: 16,482
Cumulative Timesteps: 275,193,610

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 275193610...
Checkpoint 275193610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,534.71773
Policy Entropy: 0.60110
Value Function Loss: 0.07542

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.04274
Policy Update Magnitude: 0.02291
Value Function Update Magnitude: 0.02856

Collected Steps per Second: 5,627.87875
Overall Steps per Second: 5,047.84808

Timestep Collection Time: 8.88683
Timestep Consumption Time: 1.02115
PPO Batch Consumption Time: 0.08256
Total Iteration Time: 9.90798

Cumulative Model Updates: 16,485
Cumulative Timesteps: 275,243,624

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,236.09317
Policy Entropy: 0.59889
Value Function Loss: 0.07709

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03107
Policy Update Magnitude: 0.02730
Value Function Update Magnitude: 0.02897

Collected Steps per Second: 5,511.02250
Overall Steps per Second: 4,914.43585

Timestep Collection Time: 9.07563
Timestep Consumption Time: 1.10173
PPO Batch Consumption Time: 0.09323
Total Iteration Time: 10.17736

Cumulative Model Updates: 16,488
Cumulative Timesteps: 275,293,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 275293640...
Checkpoint 275293640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,636.22944
Policy Entropy: 0.59995
Value Function Loss: 0.07577

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.02665
Value Function Update Magnitude: 0.02694

Collected Steps per Second: 5,582.23546
Overall Steps per Second: 4,990.56105

Timestep Collection Time: 8.96272
Timestep Consumption Time: 1.06261
PPO Batch Consumption Time: 0.08435
Total Iteration Time: 10.02533

Cumulative Model Updates: 16,491
Cumulative Timesteps: 275,343,672

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,327.48419
Policy Entropy: 0.60643
Value Function Loss: 0.06946

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.02684
Value Function Update Magnitude: 0.02499

Collected Steps per Second: 5,769.69043
Overall Steps per Second: 5,133.56325

Timestep Collection Time: 8.67118
Timestep Consumption Time: 1.07449
PPO Batch Consumption Time: 0.08493
Total Iteration Time: 9.74567

Cumulative Model Updates: 16,494
Cumulative Timesteps: 275,393,702

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 275393702...
Checkpoint 275393702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,221.56464
Policy Entropy: 0.60655
Value Function Loss: 0.07109

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.02686
Value Function Update Magnitude: 0.02576

Collected Steps per Second: 5,626.19287
Overall Steps per Second: 4,964.17003

Timestep Collection Time: 8.89696
Timestep Consumption Time: 1.18650
PPO Batch Consumption Time: 0.09726
Total Iteration Time: 10.08346

Cumulative Model Updates: 16,497
Cumulative Timesteps: 275,443,758

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,004.55194
Policy Entropy: 0.60338
Value Function Loss: 0.08008

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02223
Policy Update Magnitude: 0.02518
Value Function Update Magnitude: 0.02576

Collected Steps per Second: 5,702.13331
Overall Steps per Second: 5,055.60897

Timestep Collection Time: 8.77075
Timestep Consumption Time: 1.12163
PPO Batch Consumption Time: 0.08844
Total Iteration Time: 9.89238

Cumulative Model Updates: 16,500
Cumulative Timesteps: 275,493,770

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 275493770...
Checkpoint 275493770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,003.12370
Policy Entropy: 0.60573
Value Function Loss: 0.08729

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01668
Policy Update Magnitude: 0.02550
Value Function Update Magnitude: 0.02787

Collected Steps per Second: 5,725.41605
Overall Steps per Second: 5,075.23032

Timestep Collection Time: 8.73823
Timestep Consumption Time: 1.11945
PPO Batch Consumption Time: 0.08496
Total Iteration Time: 9.85768

Cumulative Model Updates: 16,503
Cumulative Timesteps: 275,543,800

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,139.18589
Policy Entropy: 0.60551
Value Function Loss: 0.08916

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03717
Policy Update Magnitude: 0.02508
Value Function Update Magnitude: 0.02898

Collected Steps per Second: 5,645.63383
Overall Steps per Second: 5,015.52700

Timestep Collection Time: 8.86136
Timestep Consumption Time: 1.11326
PPO Batch Consumption Time: 0.09041
Total Iteration Time: 9.97462

Cumulative Model Updates: 16,506
Cumulative Timesteps: 275,593,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 275593828...
Checkpoint 275593828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,331.93705
Policy Entropy: 0.61187
Value Function Loss: 0.06841

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03167
Policy Update Magnitude: 0.02343
Value Function Update Magnitude: 0.02901

Collected Steps per Second: 5,649.66571
Overall Steps per Second: 4,971.01340

Timestep Collection Time: 8.85504
Timestep Consumption Time: 1.20891
PPO Batch Consumption Time: 0.08425
Total Iteration Time: 10.06394

Cumulative Model Updates: 16,509
Cumulative Timesteps: 275,643,856

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,326.46212
Policy Entropy: 0.61464
Value Function Loss: 0.06426

Mean KL Divergence: 0.00212
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.02489
Value Function Update Magnitude: 0.03339

Collected Steps per Second: 5,726.07593
Overall Steps per Second: 5,051.85921

Timestep Collection Time: 8.73722
Timestep Consumption Time: 1.16606
PPO Batch Consumption Time: 0.08750
Total Iteration Time: 9.90328

Cumulative Model Updates: 16,512
Cumulative Timesteps: 275,693,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 275693886...
Checkpoint 275693886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,654.73512
Policy Entropy: 0.62202
Value Function Loss: 0.05543

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04063
Policy Update Magnitude: 0.02281
Value Function Update Magnitude: 0.02617

Collected Steps per Second: 5,688.67576
Overall Steps per Second: 5,004.68599

Timestep Collection Time: 8.79642
Timestep Consumption Time: 1.20221
PPO Batch Consumption Time: 0.08575
Total Iteration Time: 9.99863

Cumulative Model Updates: 16,515
Cumulative Timesteps: 275,743,926

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,990.43033
Policy Entropy: 0.61742
Value Function Loss: 0.06482

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02746
Policy Update Magnitude: 0.02224
Value Function Update Magnitude: 0.02574

Collected Steps per Second: 5,676.31342
Overall Steps per Second: 4,998.94783

Timestep Collection Time: 8.81241
Timestep Consumption Time: 1.19410
PPO Batch Consumption Time: 0.08693
Total Iteration Time: 10.00651

Cumulative Model Updates: 16,518
Cumulative Timesteps: 275,793,948

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 275793948...
Checkpoint 275793948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,892.06630
Policy Entropy: 0.61782
Value Function Loss: 0.06542

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03851
Policy Update Magnitude: 0.02385
Value Function Update Magnitude: 0.02505

Collected Steps per Second: 5,541.84480
Overall Steps per Second: 4,911.95640

Timestep Collection Time: 9.02515
Timestep Consumption Time: 1.15735
PPO Batch Consumption Time: 0.08351
Total Iteration Time: 10.18250

Cumulative Model Updates: 16,521
Cumulative Timesteps: 275,843,964

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,630.33708
Policy Entropy: 0.61713
Value Function Loss: 0.06743

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03134
Policy Update Magnitude: 0.02719
Value Function Update Magnitude: 0.02468

Collected Steps per Second: 5,559.10360
Overall Steps per Second: 4,901.38510

Timestep Collection Time: 8.99713
Timestep Consumption Time: 1.20733
PPO Batch Consumption Time: 0.08437
Total Iteration Time: 10.20446

Cumulative Model Updates: 16,524
Cumulative Timesteps: 275,893,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 275893980...
Checkpoint 275893980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,547.77525
Policy Entropy: 0.60537
Value Function Loss: 0.07582

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02631
Policy Update Magnitude: 0.02629
Value Function Update Magnitude: 0.02690

Collected Steps per Second: 5,670.23539
Overall Steps per Second: 5,004.33463

Timestep Collection Time: 8.81833
Timestep Consumption Time: 1.17341
PPO Batch Consumption Time: 0.08308
Total Iteration Time: 9.99174

Cumulative Model Updates: 16,527
Cumulative Timesteps: 275,943,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,017.79014
Policy Entropy: 0.60464
Value Function Loss: 0.08190

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03641
Policy Update Magnitude: 0.02691
Value Function Update Magnitude: 0.02884

Collected Steps per Second: 5,598.64479
Overall Steps per Second: 4,966.18522

Timestep Collection Time: 8.93466
Timestep Consumption Time: 1.13786
PPO Batch Consumption Time: 0.08818
Total Iteration Time: 10.07252

Cumulative Model Updates: 16,530
Cumulative Timesteps: 275,994,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 275994004...
Checkpoint 275994004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,211.67474
Policy Entropy: 0.59365
Value Function Loss: 0.09057

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.02701
Value Function Update Magnitude: 0.03522

Collected Steps per Second: 5,701.43547
Overall Steps per Second: 5,050.84534

Timestep Collection Time: 8.77253
Timestep Consumption Time: 1.12997
PPO Batch Consumption Time: 0.09056
Total Iteration Time: 9.90250

Cumulative Model Updates: 16,533
Cumulative Timesteps: 276,044,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,721.26778
Policy Entropy: 0.60070
Value Function Loss: 0.08851

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02826
Policy Update Magnitude: 0.02787
Value Function Update Magnitude: 0.03221

Collected Steps per Second: 5,961.56907
Overall Steps per Second: 5,253.86015

Timestep Collection Time: 8.39108
Timestep Consumption Time: 1.13030
PPO Batch Consumption Time: 0.08334
Total Iteration Time: 9.52138

Cumulative Model Updates: 16,536
Cumulative Timesteps: 276,094,044

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 276094044...
Checkpoint 276094044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,881.25411
Policy Entropy: 0.60619
Value Function Loss: 0.08157

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03411
Policy Update Magnitude: 0.02659
Value Function Update Magnitude: 0.03175

Collected Steps per Second: 5,550.40721
Overall Steps per Second: 4,968.67783

Timestep Collection Time: 9.01411
Timestep Consumption Time: 1.05537
PPO Batch Consumption Time: 0.08701
Total Iteration Time: 10.06948

Cumulative Model Updates: 16,539
Cumulative Timesteps: 276,144,076

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,676.41919
Policy Entropy: 0.61520
Value Function Loss: 0.07975

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02987
Policy Update Magnitude: 0.02619
Value Function Update Magnitude: 0.03221

Collected Steps per Second: 5,591.81199
Overall Steps per Second: 5,019.16316

Timestep Collection Time: 8.94165
Timestep Consumption Time: 1.02017
PPO Batch Consumption Time: 0.08802
Total Iteration Time: 9.96182

Cumulative Model Updates: 16,542
Cumulative Timesteps: 276,194,076

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 276194076...
Checkpoint 276194076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,433.36315
Policy Entropy: 0.62477
Value Function Loss: 0.07479

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.01919
Policy Update Magnitude: 0.02509
Value Function Update Magnitude: 0.03044

Collected Steps per Second: 5,555.74419
Overall Steps per Second: 4,925.03150

Timestep Collection Time: 9.00041
Timestep Consumption Time: 1.15262
PPO Batch Consumption Time: 0.08310
Total Iteration Time: 10.15303

Cumulative Model Updates: 16,545
Cumulative Timesteps: 276,244,080

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,654.43787
Policy Entropy: 0.62886
Value Function Loss: 0.07449

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01831
Policy Update Magnitude: 0.02534
Value Function Update Magnitude: 0.03191

Collected Steps per Second: 5,637.38840
Overall Steps per Second: 4,986.51101

Timestep Collection Time: 8.87042
Timestep Consumption Time: 1.15783
PPO Batch Consumption Time: 0.08420
Total Iteration Time: 10.02825

Cumulative Model Updates: 16,548
Cumulative Timesteps: 276,294,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 276294086...
Checkpoint 276294086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,519.80889
Policy Entropy: 0.62554
Value Function Loss: 0.06024

Mean KL Divergence: 0.00148
SB3 Clip Fraction: 0.01380
Policy Update Magnitude: 0.02509
Value Function Update Magnitude: 0.02899

Collected Steps per Second: 5,630.89348
Overall Steps per Second: 5,005.34656

Timestep Collection Time: 8.88349
Timestep Consumption Time: 1.11022
PPO Batch Consumption Time: 0.08191
Total Iteration Time: 9.99371

Cumulative Model Updates: 16,551
Cumulative Timesteps: 276,344,108

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,328.19155
Policy Entropy: 0.62270
Value Function Loss: 0.05407

Mean KL Divergence: 0.00197
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.02398
Value Function Update Magnitude: 0.02790

Collected Steps per Second: 5,739.82499
Overall Steps per Second: 5,072.44164

Timestep Collection Time: 8.71281
Timestep Consumption Time: 1.14635
PPO Batch Consumption Time: 0.08276
Total Iteration Time: 9.85916

Cumulative Model Updates: 16,554
Cumulative Timesteps: 276,394,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 276394118...
Checkpoint 276394118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,900.23695
Policy Entropy: 0.61845
Value Function Loss: 0.06119

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04554
Policy Update Magnitude: 0.02055
Value Function Update Magnitude: 0.02639

Collected Steps per Second: 5,576.65305
Overall Steps per Second: 4,936.52664

Timestep Collection Time: 8.97097
Timestep Consumption Time: 1.16328
PPO Batch Consumption Time: 0.08641
Total Iteration Time: 10.13425

Cumulative Model Updates: 16,557
Cumulative Timesteps: 276,444,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,668.32228
Policy Entropy: 0.61762
Value Function Loss: 0.06112

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.02027
Value Function Update Magnitude: 0.02418

Collected Steps per Second: 5,581.34815
Overall Steps per Second: 4,934.42442

Timestep Collection Time: 8.96343
Timestep Consumption Time: 1.17514
PPO Batch Consumption Time: 0.08424
Total Iteration Time: 10.13857

Cumulative Model Updates: 16,560
Cumulative Timesteps: 276,494,174

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 276494174...
Checkpoint 276494174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,905.69966
Policy Entropy: 0.61552
Value Function Loss: 0.07007

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03526
Policy Update Magnitude: 0.02200
Value Function Update Magnitude: 0.02694

Collected Steps per Second: 5,498.37750
Overall Steps per Second: 4,868.84851

Timestep Collection Time: 9.09359
Timestep Consumption Time: 1.17578
PPO Batch Consumption Time: 0.08301
Total Iteration Time: 10.26937

Cumulative Model Updates: 16,563
Cumulative Timesteps: 276,544,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,722.16816
Policy Entropy: 0.60901
Value Function Loss: 0.06875

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 0.02388
Value Function Update Magnitude: 0.02746

Collected Steps per Second: 5,601.80035
Overall Steps per Second: 4,958.71524

Timestep Collection Time: 8.92963
Timestep Consumption Time: 1.15806
PPO Batch Consumption Time: 0.08477
Total Iteration Time: 10.08769

Cumulative Model Updates: 16,566
Cumulative Timesteps: 276,594,196

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 276594196...
Checkpoint 276594196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,864.97221
Policy Entropy: 0.60093
Value Function Loss: 0.07252

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.03269
Policy Update Magnitude: 0.02397
Value Function Update Magnitude: 0.02736

Collected Steps per Second: 5,815.59126
Overall Steps per Second: 5,115.54375

Timestep Collection Time: 8.59792
Timestep Consumption Time: 1.17660
PPO Batch Consumption Time: 0.09030
Total Iteration Time: 9.77452

Cumulative Model Updates: 16,569
Cumulative Timesteps: 276,644,198

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,457.06868
Policy Entropy: 0.59910
Value Function Loss: 0.07092

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.02655
Value Function Update Magnitude: 0.02831

Collected Steps per Second: 5,579.82791
Overall Steps per Second: 4,964.25843

Timestep Collection Time: 8.96264
Timestep Consumption Time: 1.11137
PPO Batch Consumption Time: 0.08444
Total Iteration Time: 10.07401

Cumulative Model Updates: 16,572
Cumulative Timesteps: 276,694,208

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 276694208...
Checkpoint 276694208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,730.76527
Policy Entropy: 0.59739
Value Function Loss: 0.06765

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.02472
Value Function Update Magnitude: 0.03189

Collected Steps per Second: 5,449.43541
Overall Steps per Second: 4,841.68624

Timestep Collection Time: 9.17746
Timestep Consumption Time: 1.15199
PPO Batch Consumption Time: 0.08250
Total Iteration Time: 10.32946

Cumulative Model Updates: 16,575
Cumulative Timesteps: 276,744,220

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,295.35082
Policy Entropy: 0.60615
Value Function Loss: 0.06574

Mean KL Divergence: 0.00142
SB3 Clip Fraction: 0.01220
Policy Update Magnitude: 0.02499
Value Function Update Magnitude: 0.03227

Collected Steps per Second: 5,498.97038
Overall Steps per Second: 4,882.28005

Timestep Collection Time: 9.09625
Timestep Consumption Time: 1.14896
PPO Batch Consumption Time: 0.08304
Total Iteration Time: 10.24521

Cumulative Model Updates: 16,578
Cumulative Timesteps: 276,794,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 276794240...
Checkpoint 276794240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,015.18602
Policy Entropy: 0.61416
Value Function Loss: 0.06910

Mean KL Divergence: 0.00149
SB3 Clip Fraction: 0.01422
Policy Update Magnitude: 0.02630
Value Function Update Magnitude: 0.03063

Collected Steps per Second: 5,669.76192
Overall Steps per Second: 5,034.66601

Timestep Collection Time: 8.81907
Timestep Consumption Time: 1.11248
PPO Batch Consumption Time: 0.09009
Total Iteration Time: 9.93154

Cumulative Model Updates: 16,581
Cumulative Timesteps: 276,844,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,746.62170
Policy Entropy: 0.61883
Value Function Loss: 0.06748

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.01729
Policy Update Magnitude: 0.02603
Value Function Update Magnitude: 0.02814

Collected Steps per Second: 5,467.09733
Overall Steps per Second: 4,925.02632

Timestep Collection Time: 9.14599
Timestep Consumption Time: 1.00665
PPO Batch Consumption Time: 0.09527
Total Iteration Time: 10.15264

Cumulative Model Updates: 16,584
Cumulative Timesteps: 276,894,244

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 276894244...
Checkpoint 276894244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,733.61728
Policy Entropy: 0.61482
Value Function Loss: 0.07318

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01266
Policy Update Magnitude: 0.02820
Value Function Update Magnitude: 0.03009

Collected Steps per Second: 5,491.82787
Overall Steps per Second: 4,940.92427

Timestep Collection Time: 9.10517
Timestep Consumption Time: 1.01521
PPO Batch Consumption Time: 0.09442
Total Iteration Time: 10.12037

Cumulative Model Updates: 16,587
Cumulative Timesteps: 276,944,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,032.79332
Policy Entropy: 0.61747
Value Function Loss: 0.06955

Mean KL Divergence: 0.00173
SB3 Clip Fraction: 0.01816
Policy Update Magnitude: 0.02842
Value Function Update Magnitude: 0.03028

Collected Steps per Second: 5,672.61088
Overall Steps per Second: 5,098.84396

Timestep Collection Time: 8.82063
Timestep Consumption Time: 0.99258
PPO Batch Consumption Time: 0.08267
Total Iteration Time: 9.81320

Cumulative Model Updates: 16,590
Cumulative Timesteps: 276,994,284

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 276994284...
Checkpoint 276994284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,692.40611
Policy Entropy: 0.61673
Value Function Loss: 0.07399

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02926
Policy Update Magnitude: 0.02547
Value Function Update Magnitude: 0.03109

Collected Steps per Second: 5,232.33351
Overall Steps per Second: 4,743.72989

Timestep Collection Time: 9.55902
Timestep Consumption Time: 0.98458
PPO Batch Consumption Time: 0.08310
Total Iteration Time: 10.54360

Cumulative Model Updates: 16,593
Cumulative Timesteps: 277,044,300

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,477.31454
Policy Entropy: 0.61620
Value Function Loss: 0.06693

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.02342
Value Function Update Magnitude: 0.02859

Collected Steps per Second: 5,236.67403
Overall Steps per Second: 4,715.44243

Timestep Collection Time: 9.55607
Timestep Consumption Time: 1.05630
PPO Batch Consumption Time: 0.08795
Total Iteration Time: 10.61237

Cumulative Model Updates: 16,596
Cumulative Timesteps: 277,094,342

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 277094342...
Checkpoint 277094342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,494.76538
Policy Entropy: 0.61243
Value Function Loss: 0.06645

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03831
Policy Update Magnitude: 0.02279
Value Function Update Magnitude: 0.02872

Collected Steps per Second: 5,367.64068
Overall Steps per Second: 4,831.26313

Timestep Collection Time: 9.31843
Timestep Consumption Time: 1.03455
PPO Batch Consumption Time: 0.08472
Total Iteration Time: 10.35299

Cumulative Model Updates: 16,599
Cumulative Timesteps: 277,144,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,421.91540
Policy Entropy: 0.61646
Value Function Loss: 0.06042

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.02565
Value Function Update Magnitude: 0.02804

Collected Steps per Second: 5,620.54356
Overall Steps per Second: 5,028.42638

Timestep Collection Time: 8.90021
Timestep Consumption Time: 1.04803
PPO Batch Consumption Time: 0.08575
Total Iteration Time: 9.94824

Cumulative Model Updates: 16,602
Cumulative Timesteps: 277,194,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 277194384...
Checkpoint 277194384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,416.46993
Policy Entropy: 0.61657
Value Function Loss: 0.06450

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03787
Policy Update Magnitude: 0.02562
Value Function Update Magnitude: 0.02755

Collected Steps per Second: 5,585.03554
Overall Steps per Second: 5,008.05737

Timestep Collection Time: 8.95572
Timestep Consumption Time: 1.03179
PPO Batch Consumption Time: 0.08089
Total Iteration Time: 9.98751

Cumulative Model Updates: 16,605
Cumulative Timesteps: 277,244,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,243.04951
Policy Entropy: 0.61474
Value Function Loss: 0.06921

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03003
Policy Update Magnitude: 0.02915
Value Function Update Magnitude: 0.02626

Collected Steps per Second: 5,710.48166
Overall Steps per Second: 5,081.72617

Timestep Collection Time: 8.75758
Timestep Consumption Time: 1.08356
PPO Batch Consumption Time: 0.08318
Total Iteration Time: 9.84114

Cumulative Model Updates: 16,608
Cumulative Timesteps: 277,294,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 277294412...
Checkpoint 277294412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,873.20380
Policy Entropy: 0.60794
Value Function Loss: 0.06890

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.03041
Value Function Update Magnitude: 0.02783

Collected Steps per Second: 5,630.78896
Overall Steps per Second: 4,969.12822

Timestep Collection Time: 8.88330
Timestep Consumption Time: 1.18285
PPO Batch Consumption Time: 0.08385
Total Iteration Time: 10.06615

Cumulative Model Updates: 16,611
Cumulative Timesteps: 277,344,432

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,400.71074
Policy Entropy: 0.61396
Value Function Loss: 0.06821

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03093
Policy Update Magnitude: 0.03085
Value Function Update Magnitude: 0.03037

Collected Steps per Second: 5,946.00265
Overall Steps per Second: 5,224.65870

Timestep Collection Time: 8.41002
Timestep Consumption Time: 1.16113
PPO Batch Consumption Time: 0.08508
Total Iteration Time: 9.57115

Cumulative Model Updates: 16,614
Cumulative Timesteps: 277,394,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 277394438...
Checkpoint 277394438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,509.23344
Policy Entropy: 0.61131
Value Function Loss: 0.06621

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02303
Policy Update Magnitude: 0.02866
Value Function Update Magnitude: 0.02819

Collected Steps per Second: 5,666.26200
Overall Steps per Second: 5,024.55121

Timestep Collection Time: 8.82487
Timestep Consumption Time: 1.12707
PPO Batch Consumption Time: 0.08413
Total Iteration Time: 9.95193

Cumulative Model Updates: 16,617
Cumulative Timesteps: 277,444,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,942.61569
Policy Entropy: 0.61469
Value Function Loss: 0.06817

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02689
Policy Update Magnitude: 0.02710
Value Function Update Magnitude: 0.02709

Collected Steps per Second: 5,745.77116
Overall Steps per Second: 5,066.96505

Timestep Collection Time: 8.70414
Timestep Consumption Time: 1.16607
PPO Batch Consumption Time: 0.08264
Total Iteration Time: 9.87021

Cumulative Model Updates: 16,620
Cumulative Timesteps: 277,494,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 277494454...
Checkpoint 277494454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,388.36324
Policy Entropy: 0.61303
Value Function Loss: 0.06389

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03697
Policy Update Magnitude: 0.02954
Value Function Update Magnitude: 0.02468

Collected Steps per Second: 7,539.51673
Overall Steps per Second: 6,414.36358

Timestep Collection Time: 6.63252
Timestep Consumption Time: 1.16342
PPO Batch Consumption Time: 0.08409
Total Iteration Time: 7.79594

Cumulative Model Updates: 16,623
Cumulative Timesteps: 277,544,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,148.44629
Policy Entropy: 0.61509
Value Function Loss: 0.06765

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03671
Policy Update Magnitude: 0.02691
Value Function Update Magnitude: 0.02629

Collected Steps per Second: 5,482.86826
Overall Steps per Second: 4,917.66591

Timestep Collection Time: 9.12333
Timestep Consumption Time: 1.04857
PPO Batch Consumption Time: 0.08421
Total Iteration Time: 10.17190

Cumulative Model Updates: 16,626
Cumulative Timesteps: 277,594,482

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 277594482...
Checkpoint 277594482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,945.09297
Policy Entropy: 0.60707
Value Function Loss: 0.07840

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03895
Policy Update Magnitude: 0.02543
Value Function Update Magnitude: 0.02512

Collected Steps per Second: 5,484.74469
Overall Steps per Second: 4,885.08868

Timestep Collection Time: 9.11911
Timestep Consumption Time: 1.11939
PPO Batch Consumption Time: 0.09761
Total Iteration Time: 10.23850

Cumulative Model Updates: 16,629
Cumulative Timesteps: 277,644,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,286.75142
Policy Entropy: 0.61095
Value Function Loss: 0.08138

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.02688
Value Function Update Magnitude: 0.02549

Collected Steps per Second: 5,461.46734
Overall Steps per Second: 4,891.04336

Timestep Collection Time: 9.15542
Timestep Consumption Time: 1.06776
PPO Batch Consumption Time: 0.08552
Total Iteration Time: 10.22318

Cumulative Model Updates: 16,632
Cumulative Timesteps: 277,694,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 277694500...
Checkpoint 277694500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,198.75648
Policy Entropy: 0.62028
Value Function Loss: 0.08018

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01759
Policy Update Magnitude: 0.02755
Value Function Update Magnitude: 0.02691

Collected Steps per Second: 5,258.68813
Overall Steps per Second: 4,726.04159

Timestep Collection Time: 9.51340
Timestep Consumption Time: 1.07220
PPO Batch Consumption Time: 0.08648
Total Iteration Time: 10.58560

Cumulative Model Updates: 16,635
Cumulative Timesteps: 277,744,528

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,958.67941
Policy Entropy: 0.62432
Value Function Loss: 0.06960

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.04973
Policy Update Magnitude: 0.02716
Value Function Update Magnitude: 0.02878

Collected Steps per Second: 5,386.34479
Overall Steps per Second: 4,825.58615

Timestep Collection Time: 9.28682
Timestep Consumption Time: 1.07918
PPO Batch Consumption Time: 0.08701
Total Iteration Time: 10.36599

Cumulative Model Updates: 16,638
Cumulative Timesteps: 277,794,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 277794550...
Checkpoint 277794550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,165.35416
Policy Entropy: 0.62197
Value Function Loss: 0.08001

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03356
Policy Update Magnitude: 0.03347
Value Function Update Magnitude: 0.03060

Collected Steps per Second: 5,494.61573
Overall Steps per Second: 4,898.00799

Timestep Collection Time: 9.10601
Timestep Consumption Time: 1.10917
PPO Batch Consumption Time: 0.09018
Total Iteration Time: 10.21517

Cumulative Model Updates: 16,641
Cumulative Timesteps: 277,844,584

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,484.18423
Policy Entropy: 0.61277
Value Function Loss: 0.07282

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07813
Policy Update Magnitude: 0.02927
Value Function Update Magnitude: 0.03280

Collected Steps per Second: 5,555.51539
Overall Steps per Second: 4,960.92107

Timestep Collection Time: 9.00331
Timestep Consumption Time: 1.07910
PPO Batch Consumption Time: 0.08160
Total Iteration Time: 10.08240

Cumulative Model Updates: 16,644
Cumulative Timesteps: 277,894,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 277894602...
Checkpoint 277894602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,767.51958
Policy Entropy: 0.60961
Value Function Loss: 0.07775

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03689
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.02827

Collected Steps per Second: 5,401.99833
Overall Steps per Second: 4,813.83183

Timestep Collection Time: 9.26102
Timestep Consumption Time: 1.13154
PPO Batch Consumption Time: 0.09746
Total Iteration Time: 10.39255

Cumulative Model Updates: 16,647
Cumulative Timesteps: 277,944,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,386.71100
Policy Entropy: 0.60946
Value Function Loss: 0.07317

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05741
Policy Update Magnitude: 0.03044
Value Function Update Magnitude: 0.03737

Collected Steps per Second: 5,760.22651
Overall Steps per Second: 5,122.88146

Timestep Collection Time: 8.68403
Timestep Consumption Time: 1.08039
PPO Batch Consumption Time: 0.08511
Total Iteration Time: 9.76443

Cumulative Model Updates: 16,650
Cumulative Timesteps: 277,994,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 277994652...
Checkpoint 277994652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,962.20985
Policy Entropy: 0.60697
Value Function Loss: 0.08039

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.03057
Policy Update Magnitude: 0.03140
Value Function Update Magnitude: 0.03396

Collected Steps per Second: 5,579.28907
Overall Steps per Second: 4,986.80950

Timestep Collection Time: 8.96243
Timestep Consumption Time: 1.06482
PPO Batch Consumption Time: 0.08261
Total Iteration Time: 10.02725

Cumulative Model Updates: 16,653
Cumulative Timesteps: 278,044,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,968.71623
Policy Entropy: 0.60090
Value Function Loss: 0.07880

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03319
Policy Update Magnitude: 0.03271
Value Function Update Magnitude: 0.03276

Collected Steps per Second: 5,783.58927
Overall Steps per Second: 5,137.47470

Timestep Collection Time: 8.64757
Timestep Consumption Time: 1.08756
PPO Batch Consumption Time: 0.08972
Total Iteration Time: 9.73513

Cumulative Model Updates: 16,656
Cumulative Timesteps: 278,094,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 278094670...
Checkpoint 278094670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,275.98048
Policy Entropy: 0.59618
Value Function Loss: 0.07888

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.03088
Policy Update Magnitude: 0.03045
Value Function Update Magnitude: 0.03159

Collected Steps per Second: 5,417.58352
Overall Steps per Second: 4,808.81481

Timestep Collection Time: 9.23216
Timestep Consumption Time: 1.16874
PPO Batch Consumption Time: 0.08984
Total Iteration Time: 10.40090

Cumulative Model Updates: 16,659
Cumulative Timesteps: 278,144,686

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,447.03423
Policy Entropy: 0.59264
Value Function Loss: 0.08361

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.02044
Policy Update Magnitude: 0.03607
Value Function Update Magnitude: 0.03106

Collected Steps per Second: 5,510.70019
Overall Steps per Second: 4,882.29872

Timestep Collection Time: 9.07834
Timestep Consumption Time: 1.16847
PPO Batch Consumption Time: 0.09328
Total Iteration Time: 10.24681

Cumulative Model Updates: 16,662
Cumulative Timesteps: 278,194,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 278194714...
Checkpoint 278194714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,263.97752
Policy Entropy: 0.59608
Value Function Loss: 0.08018

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.03961
Value Function Update Magnitude: 0.03024

Collected Steps per Second: 5,522.37793
Overall Steps per Second: 4,911.58118

Timestep Collection Time: 9.06059
Timestep Consumption Time: 1.12676
PPO Batch Consumption Time: 0.08961
Total Iteration Time: 10.18735

Cumulative Model Updates: 16,665
Cumulative Timesteps: 278,244,750

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,801.61659
Policy Entropy: 0.60071
Value Function Loss: 0.07618

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 0.03126
Value Function Update Magnitude: 0.03135

Collected Steps per Second: 5,601.15868
Overall Steps per Second: 4,962.73458

Timestep Collection Time: 8.92708
Timestep Consumption Time: 1.14841
PPO Batch Consumption Time: 0.08500
Total Iteration Time: 10.07549

Cumulative Model Updates: 16,668
Cumulative Timesteps: 278,294,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 278294752...
Checkpoint 278294752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,651.52523
Policy Entropy: 0.60583
Value Function Loss: 0.06712

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.05569
Policy Update Magnitude: 0.03076
Value Function Update Magnitude: 0.02946

Collected Steps per Second: 5,432.67872
Overall Steps per Second: 4,833.56324

Timestep Collection Time: 9.20835
Timestep Consumption Time: 1.14137
PPO Batch Consumption Time: 0.08333
Total Iteration Time: 10.34971

Cumulative Model Updates: 16,671
Cumulative Timesteps: 278,344,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,119.01978
Policy Entropy: 0.60945
Value Function Loss: 0.06593

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.06021
Policy Update Magnitude: 0.02994
Value Function Update Magnitude: 0.03003

Collected Steps per Second: 5,470.17483
Overall Steps per Second: 4,863.36991

Timestep Collection Time: 9.14267
Timestep Consumption Time: 1.14074
PPO Batch Consumption Time: 0.08279
Total Iteration Time: 10.28340

Cumulative Model Updates: 16,674
Cumulative Timesteps: 278,394,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 278394790...
Checkpoint 278394790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,577.84057
Policy Entropy: 0.61300
Value Function Loss: 0.06800

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.07318
Policy Update Magnitude: 0.02724
Value Function Update Magnitude: 0.02810

Collected Steps per Second: 5,586.86808
Overall Steps per Second: 4,956.81488

Timestep Collection Time: 8.94992
Timestep Consumption Time: 1.13761
PPO Batch Consumption Time: 0.08427
Total Iteration Time: 10.08753

Cumulative Model Updates: 16,677
Cumulative Timesteps: 278,444,792

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,587.01549
Policy Entropy: 0.61019
Value Function Loss: 0.06733

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04780
Policy Update Magnitude: 0.02515
Value Function Update Magnitude: 0.02613

Collected Steps per Second: 5,567.01865
Overall Steps per Second: 4,868.33561

Timestep Collection Time: 8.98686
Timestep Consumption Time: 1.28976
PPO Batch Consumption Time: 0.08041
Total Iteration Time: 10.27661

Cumulative Model Updates: 16,680
Cumulative Timesteps: 278,494,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 278494822...
Checkpoint 278494822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,886.35272
Policy Entropy: 0.60657
Value Function Loss: 0.06816

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06664
Policy Update Magnitude: 0.02622
Value Function Update Magnitude: 0.02920

Collected Steps per Second: 5,478.14000
Overall Steps per Second: 4,877.64580

Timestep Collection Time: 9.13011
Timestep Consumption Time: 1.12402
PPO Batch Consumption Time: 0.08366
Total Iteration Time: 10.25413

Cumulative Model Updates: 16,683
Cumulative Timesteps: 278,544,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,530.21273
Policy Entropy: 0.60346
Value Function Loss: 0.06597

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.05263
Policy Update Magnitude: 0.02617
Value Function Update Magnitude: 0.02934

Collected Steps per Second: 5,649.66372
Overall Steps per Second: 5,005.88984

Timestep Collection Time: 8.85398
Timestep Consumption Time: 1.13865
PPO Batch Consumption Time: 0.08572
Total Iteration Time: 9.99263

Cumulative Model Updates: 16,686
Cumulative Timesteps: 278,594,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 278594860...
Checkpoint 278594860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,603.46296
Policy Entropy: 0.60477
Value Function Loss: 0.06836

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06700
Policy Update Magnitude: 0.02535
Value Function Update Magnitude: 0.03233

Collected Steps per Second: 5,912.14654
Overall Steps per Second: 5,197.93797

Timestep Collection Time: 8.45987
Timestep Consumption Time: 1.16241
PPO Batch Consumption Time: 0.08643
Total Iteration Time: 9.62228

Cumulative Model Updates: 16,689
Cumulative Timesteps: 278,644,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,206.86062
Policy Entropy: 0.60726
Value Function Loss: 0.06536

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.05461
Policy Update Magnitude: 0.02546
Value Function Update Magnitude: 0.03035

Collected Steps per Second: 5,864.77305
Overall Steps per Second: 5,175.16804

Timestep Collection Time: 8.52923
Timestep Consumption Time: 1.13654
PPO Batch Consumption Time: 0.08669
Total Iteration Time: 9.66577

Cumulative Model Updates: 16,692
Cumulative Timesteps: 278,694,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 278694898...
Checkpoint 278694898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,976.16131
Policy Entropy: 0.60620
Value Function Loss: 0.06611

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.05983
Policy Update Magnitude: 0.02545
Value Function Update Magnitude: 0.02974

Collected Steps per Second: 5,686.78049
Overall Steps per Second: 5,047.54854

Timestep Collection Time: 8.79619
Timestep Consumption Time: 1.11397
PPO Batch Consumption Time: 0.08062
Total Iteration Time: 9.91016

Cumulative Model Updates: 16,695
Cumulative Timesteps: 278,744,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,128.70909
Policy Entropy: 0.60468
Value Function Loss: 0.06593

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.03637
Policy Update Magnitude: 0.02669
Value Function Update Magnitude: 0.02861

Collected Steps per Second: 5,712.56314
Overall Steps per Second: 5,102.55309

Timestep Collection Time: 8.75369
Timestep Consumption Time: 1.04650
PPO Batch Consumption Time: 0.08354
Total Iteration Time: 9.80019

Cumulative Model Updates: 16,698
Cumulative Timesteps: 278,794,926

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 278794926...
Checkpoint 278794926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,664.11705
Policy Entropy: 0.59916
Value Function Loss: 0.07160

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.05271
Policy Update Magnitude: 0.02534
Value Function Update Magnitude: 0.02923

Collected Steps per Second: 5,570.42134
Overall Steps per Second: 5,002.43970

Timestep Collection Time: 8.97778
Timestep Consumption Time: 1.01935
PPO Batch Consumption Time: 0.08605
Total Iteration Time: 9.99712

Cumulative Model Updates: 16,701
Cumulative Timesteps: 278,844,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,875.65091
Policy Entropy: 0.59488
Value Function Loss: 0.07754

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.02337
Value Function Update Magnitude: 0.02955

Collected Steps per Second: 5,345.20656
Overall Steps per Second: 4,802.57586

Timestep Collection Time: 9.35941
Timestep Consumption Time: 1.05750
PPO Batch Consumption Time: 0.08912
Total Iteration Time: 10.41691

Cumulative Model Updates: 16,704
Cumulative Timesteps: 278,894,964

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 278894964...
Checkpoint 278894964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,949.55023
Policy Entropy: 0.59402
Value Function Loss: 0.08085

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.03090
Policy Update Magnitude: 0.02359
Value Function Update Magnitude: 0.03212

Collected Steps per Second: 5,434.81864
Overall Steps per Second: 4,881.02139

Timestep Collection Time: 9.20068
Timestep Consumption Time: 1.04390
PPO Batch Consumption Time: 0.08726
Total Iteration Time: 10.24458

Cumulative Model Updates: 16,707
Cumulative Timesteps: 278,944,968

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,230.76054
Policy Entropy: 0.59021
Value Function Loss: 0.08394

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.02439
Value Function Update Magnitude: 0.02809

Collected Steps per Second: 5,407.37058
Overall Steps per Second: 4,844.44831

Timestep Collection Time: 9.25108
Timestep Consumption Time: 1.07497
PPO Batch Consumption Time: 0.08202
Total Iteration Time: 10.32605

Cumulative Model Updates: 16,710
Cumulative Timesteps: 278,994,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 278994992...
Checkpoint 278994992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,589.11101
Policy Entropy: 0.58218
Value Function Loss: 0.08126

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.04267
Policy Update Magnitude: 0.02770
Value Function Update Magnitude: 0.02617

Collected Steps per Second: 5,570.98869
Overall Steps per Second: 4,975.89999

Timestep Collection Time: 8.97830
Timestep Consumption Time: 1.07375
PPO Batch Consumption Time: 0.08755
Total Iteration Time: 10.05205

Cumulative Model Updates: 16,713
Cumulative Timesteps: 279,045,010

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,409.70682
Policy Entropy: 0.58719
Value Function Loss: 0.08548

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05407
Policy Update Magnitude: 0.02520
Value Function Update Magnitude: 0.02584

Collected Steps per Second: 5,496.29168
Overall Steps per Second: 4,881.37507

Timestep Collection Time: 9.10068
Timestep Consumption Time: 1.14643
PPO Batch Consumption Time: 0.08769
Total Iteration Time: 10.24711

Cumulative Model Updates: 16,716
Cumulative Timesteps: 279,095,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 279095030...
Checkpoint 279095030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,747.89512
Policy Entropy: 0.59726
Value Function Loss: 0.07474

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03702
Policy Update Magnitude: 0.02700
Value Function Update Magnitude: 0.02581

Collected Steps per Second: 5,445.53615
Overall Steps per Second: 4,879.35561

Timestep Collection Time: 9.18404
Timestep Consumption Time: 1.06568
PPO Batch Consumption Time: 0.08859
Total Iteration Time: 10.24971

Cumulative Model Updates: 16,719
Cumulative Timesteps: 279,145,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,368.07259
Policy Entropy: 0.60611
Value Function Loss: 0.06344

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04437
Policy Update Magnitude: 0.02684
Value Function Update Magnitude: 0.02797

Collected Steps per Second: 5,507.61505
Overall Steps per Second: 4,845.58052

Timestep Collection Time: 9.08233
Timestep Consumption Time: 1.24089
PPO Batch Consumption Time: 0.08446
Total Iteration Time: 10.32322

Cumulative Model Updates: 16,722
Cumulative Timesteps: 279,195,064

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 279195064...
Checkpoint 279195064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,385.58287
Policy Entropy: 0.59941
Value Function Loss: 0.06017

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.03597
Policy Update Magnitude: 0.02355
Value Function Update Magnitude: 0.02732

Collected Steps per Second: 5,406.71499
Overall Steps per Second: 4,779.35657

Timestep Collection Time: 9.25072
Timestep Consumption Time: 1.21429
PPO Batch Consumption Time: 0.08468
Total Iteration Time: 10.46501

Cumulative Model Updates: 16,725
Cumulative Timesteps: 279,245,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,439.25744
Policy Entropy: 0.58630
Value Function Loss: 0.07597

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 0.02407
Value Function Update Magnitude: 0.02809

Collected Steps per Second: 5,624.76947
Overall Steps per Second: 4,944.28404

Timestep Collection Time: 8.89281
Timestep Consumption Time: 1.22392
PPO Batch Consumption Time: 0.08448
Total Iteration Time: 10.11673

Cumulative Model Updates: 16,728
Cumulative Timesteps: 279,295,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 279295100...
Checkpoint 279295100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,892.99361
Policy Entropy: 0.57985
Value Function Loss: 0.08430

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05161
Policy Update Magnitude: 0.02546
Value Function Update Magnitude: 0.03408

Collected Steps per Second: 5,562.94662
Overall Steps per Second: 4,933.38446

Timestep Collection Time: 8.98840
Timestep Consumption Time: 1.14703
PPO Batch Consumption Time: 0.08995
Total Iteration Time: 10.13544

Cumulative Model Updates: 16,731
Cumulative Timesteps: 279,345,102

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,035.98227
Policy Entropy: 0.57686
Value Function Loss: 0.08632

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.06097
Policy Update Magnitude: 0.02673
Value Function Update Magnitude: 0.04111

Collected Steps per Second: 6,388.58346
Overall Steps per Second: 5,580.83780

Timestep Collection Time: 7.82959
Timestep Consumption Time: 1.13322
PPO Batch Consumption Time: 0.08876
Total Iteration Time: 8.96281

Cumulative Model Updates: 16,734
Cumulative Timesteps: 279,395,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 279395122...
Checkpoint 279395122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,078.35271
Policy Entropy: 0.58454
Value Function Loss: 0.07742

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.06343
Policy Update Magnitude: 0.02728
Value Function Update Magnitude: 0.03729

Collected Steps per Second: 5,551.07360
Overall Steps per Second: 4,910.41670

Timestep Collection Time: 9.01231
Timestep Consumption Time: 1.17583
PPO Batch Consumption Time: 0.08555
Total Iteration Time: 10.18814

Cumulative Model Updates: 16,737
Cumulative Timesteps: 279,445,150

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,633.16819
Policy Entropy: 0.58496
Value Function Loss: 0.08279

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04658
Policy Update Magnitude: 0.02608
Value Function Update Magnitude: 0.03543

Collected Steps per Second: 5,479.10322
Overall Steps per Second: 4,848.00901

Timestep Collection Time: 9.13106
Timestep Consumption Time: 1.18864
PPO Batch Consumption Time: 0.08967
Total Iteration Time: 10.31970

Cumulative Model Updates: 16,740
Cumulative Timesteps: 279,495,180

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 279495180...
Checkpoint 279495180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,061.22301
Policy Entropy: 0.58881
Value Function Loss: 0.08889

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.05228
Policy Update Magnitude: 0.02455
Value Function Update Magnitude: 0.03437

Collected Steps per Second: 8,209.41112
Overall Steps per Second: 7,124.02984

Timestep Collection Time: 6.09228
Timestep Consumption Time: 0.92819
PPO Batch Consumption Time: 0.07564
Total Iteration Time: 7.02046

Cumulative Model Updates: 16,743
Cumulative Timesteps: 279,545,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,493.39237
Policy Entropy: 0.59443
Value Function Loss: 0.08613

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03367
Policy Update Magnitude: 0.02643
Value Function Update Magnitude: 0.03036

Collected Steps per Second: 18,319.50795
Overall Steps per Second: 12,773.12493

Timestep Collection Time: 2.73075
Timestep Consumption Time: 1.18575
PPO Batch Consumption Time: 0.07128
Total Iteration Time: 3.91650

Cumulative Model Updates: 16,746
Cumulative Timesteps: 279,595,220

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 279595220...
Checkpoint 279595220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,225.45166
Policy Entropy: 0.59511
Value Function Loss: 0.08033

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.03926
Policy Update Magnitude: 0.02499
Value Function Update Magnitude: 0.03208

Collected Steps per Second: 13,681.00975
Overall Steps per Second: 10,375.98761

Timestep Collection Time: 3.65470
Timestep Consumption Time: 1.16412
PPO Batch Consumption Time: 0.14337
Total Iteration Time: 4.81882

Cumulative Model Updates: 16,749
Cumulative Timesteps: 279,645,220

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,487.52083
Policy Entropy: 0.59133
Value Function Loss: 0.07160

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02940
Policy Update Magnitude: 0.02452
Value Function Update Magnitude: 0.03498

Collected Steps per Second: 12,926.12842
Overall Steps per Second: 9,831.10913

Timestep Collection Time: 3.86968
Timestep Consumption Time: 1.21825
PPO Batch Consumption Time: 0.09581
Total Iteration Time: 5.08793

Cumulative Model Updates: 16,752
Cumulative Timesteps: 279,695,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 279695240...
Checkpoint 279695240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,001.61844
Policy Entropy: 0.58992
Value Function Loss: 0.07212

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03503
Policy Update Magnitude: 0.02474
Value Function Update Magnitude: 0.03372

Collected Steps per Second: 5,219.57627
Overall Steps per Second: 4,616.32427

Timestep Collection Time: 9.58430
Timestep Consumption Time: 1.25246
PPO Batch Consumption Time: 0.08584
Total Iteration Time: 10.83676

Cumulative Model Updates: 16,755
Cumulative Timesteps: 279,745,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,448.42076
Policy Entropy: 0.58841
Value Function Loss: 0.07055

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03221
Policy Update Magnitude: 0.02683
Value Function Update Magnitude: 0.03161

Collected Steps per Second: 5,367.63883
Overall Steps per Second: 4,775.02030

Timestep Collection Time: 9.31844
Timestep Consumption Time: 1.15649
PPO Batch Consumption Time: 0.08349
Total Iteration Time: 10.47493

Cumulative Model Updates: 16,758
Cumulative Timesteps: 279,795,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 279795284...
Checkpoint 279795284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,271.46833
Policy Entropy: 0.59814
Value Function Loss: 0.06274

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03039
Policy Update Magnitude: 0.02648
Value Function Update Magnitude: 0.02983

Collected Steps per Second: 5,723.25017
Overall Steps per Second: 5,039.83610

Timestep Collection Time: 8.74049
Timestep Consumption Time: 1.18523
PPO Batch Consumption Time: 0.08771
Total Iteration Time: 9.92572

Cumulative Model Updates: 16,761
Cumulative Timesteps: 279,845,308

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,037.77744
Policy Entropy: 0.59428
Value Function Loss: 0.06936

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03195
Policy Update Magnitude: 0.02635
Value Function Update Magnitude: 0.02978

Collected Steps per Second: 5,510.79978
Overall Steps per Second: 4,902.31346

Timestep Collection Time: 9.07309
Timestep Consumption Time: 1.12617
PPO Batch Consumption Time: 0.08520
Total Iteration Time: 10.19927

Cumulative Model Updates: 16,764
Cumulative Timesteps: 279,895,308

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 279895308...
Checkpoint 279895308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,613.79215
Policy Entropy: 0.59166
Value Function Loss: 0.07369

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 0.02656
Value Function Update Magnitude: 0.02826

Collected Steps per Second: 5,355.96357
Overall Steps per Second: 4,752.26166

Timestep Collection Time: 9.33614
Timestep Consumption Time: 1.18601
PPO Batch Consumption Time: 0.08609
Total Iteration Time: 10.52215

Cumulative Model Updates: 16,767
Cumulative Timesteps: 279,945,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,119.51406
Policy Entropy: 0.57902
Value Function Loss: 0.08072

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.04030
Policy Update Magnitude: 0.02711
Value Function Update Magnitude: 0.03090

Collected Steps per Second: 5,436.22150
Overall Steps per Second: 4,807.82072

Timestep Collection Time: 9.19830
Timestep Consumption Time: 1.20225
PPO Batch Consumption Time: 0.09514
Total Iteration Time: 10.40055

Cumulative Model Updates: 16,770
Cumulative Timesteps: 279,995,316

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 279995316...
Checkpoint 279995316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,174.59582
Policy Entropy: 0.57405
Value Function Loss: 0.07357

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.02521
Value Function Update Magnitude: 0.03161

Collected Steps per Second: 5,690.88935
Overall Steps per Second: 5,062.93520

Timestep Collection Time: 8.78808
Timestep Consumption Time: 1.08998
PPO Batch Consumption Time: 0.08104
Total Iteration Time: 9.87806

Cumulative Model Updates: 16,773
Cumulative Timesteps: 280,045,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,015.90958
Policy Entropy: 0.57108
Value Function Loss: 0.08304

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.02586
Value Function Update Magnitude: 0.02992

Collected Steps per Second: 5,930.97515
Overall Steps per Second: 5,197.31293

Timestep Collection Time: 8.43065
Timestep Consumption Time: 1.19009
PPO Batch Consumption Time: 0.08957
Total Iteration Time: 9.62074

Cumulative Model Updates: 16,776
Cumulative Timesteps: 280,095,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 280095330...
Checkpoint 280095330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,884.10527
Policy Entropy: 0.57608
Value Function Loss: 0.08663

Mean KL Divergence: 0.00161
SB3 Clip Fraction: 0.01450
Policy Update Magnitude: 0.02814
Value Function Update Magnitude: 0.03551

Collected Steps per Second: 5,752.58355
Overall Steps per Second: 5,112.73972

Timestep Collection Time: 8.69592
Timestep Consumption Time: 1.08827
PPO Batch Consumption Time: 0.09199
Total Iteration Time: 9.78419

Cumulative Model Updates: 16,779
Cumulative Timesteps: 280,145,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,701.57433
Policy Entropy: 0.58724
Value Function Loss: 0.08617

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.02978
Value Function Update Magnitude: 0.03843

Collected Steps per Second: 5,617.87119
Overall Steps per Second: 5,042.26138

Timestep Collection Time: 8.90195
Timestep Consumption Time: 1.01622
PPO Batch Consumption Time: 0.09170
Total Iteration Time: 9.91817

Cumulative Model Updates: 16,782
Cumulative Timesteps: 280,195,364

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 280195364...
Checkpoint 280195364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,820.77517
Policy Entropy: 0.58866
Value Function Loss: 0.07447

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02708
Policy Update Magnitude: 0.03472
Value Function Update Magnitude: 0.03241

Collected Steps per Second: 5,567.27089
Overall Steps per Second: 4,990.51439

Timestep Collection Time: 8.98537
Timestep Consumption Time: 1.03844
PPO Batch Consumption Time: 0.09151
Total Iteration Time: 10.02382

Cumulative Model Updates: 16,785
Cumulative Timesteps: 280,245,388

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,648.66601
Policy Entropy: 0.58542
Value Function Loss: 0.06845

Mean KL Divergence: 0.00169
SB3 Clip Fraction: 0.01702
Policy Update Magnitude: 0.03129
Value Function Update Magnitude: 0.03607

Collected Steps per Second: 5,561.87503
Overall Steps per Second: 5,002.59937

Timestep Collection Time: 8.99301
Timestep Consumption Time: 1.00539
PPO Batch Consumption Time: 0.08569
Total Iteration Time: 9.99840

Cumulative Model Updates: 16,788
Cumulative Timesteps: 280,295,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 280295406...
Checkpoint 280295406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,342.30410
Policy Entropy: 0.58364
Value Function Loss: 0.07138

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.02894
Value Function Update Magnitude: 0.03463

Collected Steps per Second: 5,438.18402
Overall Steps per Second: 4,831.85988

Timestep Collection Time: 9.19425
Timestep Consumption Time: 1.15374
PPO Batch Consumption Time: 0.08760
Total Iteration Time: 10.34798

Cumulative Model Updates: 16,791
Cumulative Timesteps: 280,345,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,271.60098
Policy Entropy: 0.58287
Value Function Loss: 0.07374

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.02759
Value Function Update Magnitude: 0.03311

Collected Steps per Second: 5,420.60894
Overall Steps per Second: 4,816.52777

Timestep Collection Time: 9.22922
Timestep Consumption Time: 1.15751
PPO Batch Consumption Time: 0.09964
Total Iteration Time: 10.38674

Cumulative Model Updates: 16,794
Cumulative Timesteps: 280,395,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 280395434...
Checkpoint 280395434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,440.22757
Policy Entropy: 0.57658
Value Function Loss: 0.08456

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02117
Policy Update Magnitude: 0.02821
Value Function Update Magnitude: 0.03675

Collected Steps per Second: 5,363.69495
Overall Steps per Second: 4,758.54254

Timestep Collection Time: 9.32641
Timestep Consumption Time: 1.18606
PPO Batch Consumption Time: 0.07886
Total Iteration Time: 10.51246

Cumulative Model Updates: 16,797
Cumulative Timesteps: 280,445,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,889.57050
Policy Entropy: 0.57207
Value Function Loss: 0.08204

Mean KL Divergence: 0.00239
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 0.03010
Value Function Update Magnitude: 0.03508

Collected Steps per Second: 5,401.51991
Overall Steps per Second: 4,785.72647

Timestep Collection Time: 9.25702
Timestep Consumption Time: 1.19113
PPO Batch Consumption Time: 0.08537
Total Iteration Time: 10.44815

Cumulative Model Updates: 16,800
Cumulative Timesteps: 280,495,460

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 280495460...
Checkpoint 280495460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,041.02423
Policy Entropy: 0.57305
Value Function Loss: 0.07531

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02200
Policy Update Magnitude: 0.03127
Value Function Update Magnitude: 0.03518

Collected Steps per Second: 5,480.08599
Overall Steps per Second: 4,903.95162

Timestep Collection Time: 9.12759
Timestep Consumption Time: 1.07234
PPO Batch Consumption Time: 0.08661
Total Iteration Time: 10.19994

Cumulative Model Updates: 16,803
Cumulative Timesteps: 280,545,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,900.04931
Policy Entropy: 0.57418
Value Function Loss: 0.07245

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02255
Policy Update Magnitude: 0.02987
Value Function Update Magnitude: 0.03806

Collected Steps per Second: 5,537.98005
Overall Steps per Second: 4,926.23975

Timestep Collection Time: 9.03217
Timestep Consumption Time: 1.12162
PPO Batch Consumption Time: 0.09097
Total Iteration Time: 10.15379

Cumulative Model Updates: 16,806
Cumulative Timesteps: 280,595,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 280595500...
Checkpoint 280595500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,273.71268
Policy Entropy: 0.57909
Value Function Loss: 0.06672

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.02986
Policy Update Magnitude: 0.02800
Value Function Update Magnitude: 0.03624

Collected Steps per Second: 5,672.05370
Overall Steps per Second: 5,080.40934

Timestep Collection Time: 8.81691
Timestep Consumption Time: 1.02678
PPO Batch Consumption Time: 0.03963
Total Iteration Time: 9.84370

Cumulative Model Updates: 16,809
Cumulative Timesteps: 280,645,510

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,050.41883
Policy Entropy: 0.58034
Value Function Loss: 0.07034

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.04161
Policy Update Magnitude: 0.02636
Value Function Update Magnitude: 0.03209

Collected Steps per Second: 13,185.33580
Overall Steps per Second: 10,096.91761

Timestep Collection Time: 3.79315
Timestep Consumption Time: 1.16024
PPO Batch Consumption Time: 0.08973
Total Iteration Time: 4.95339

Cumulative Model Updates: 16,812
Cumulative Timesteps: 280,695,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 280695524...
Checkpoint 280695524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,770.18984
Policy Entropy: 0.58554
Value Function Loss: 0.06952

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04794
Policy Update Magnitude: 0.02412
Value Function Update Magnitude: 0.03229

Collected Steps per Second: 9,343.72151
Overall Steps per Second: 8,023.83560

Timestep Collection Time: 5.35397
Timestep Consumption Time: 0.88070
PPO Batch Consumption Time: 0.04989
Total Iteration Time: 6.23467

Cumulative Model Updates: 16,815
Cumulative Timesteps: 280,745,550

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,492.16114
Policy Entropy: 0.57665
Value Function Loss: 0.07684

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03694
Policy Update Magnitude: 0.02353
Value Function Update Magnitude: 0.03139

Collected Steps per Second: 16,355.65857
Overall Steps per Second: 12,095.46143

Timestep Collection Time: 3.05815
Timestep Consumption Time: 1.07712
PPO Batch Consumption Time: 0.08342
Total Iteration Time: 4.13527

Cumulative Model Updates: 16,818
Cumulative Timesteps: 280,795,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 280795568...
Checkpoint 280795568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,633.00841
Policy Entropy: 0.58042
Value Function Loss: 0.07747

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.05910
Policy Update Magnitude: 0.02434
Value Function Update Magnitude: 0.03500

Collected Steps per Second: 11,541.93121
Overall Steps per Second: 9,521.79217

Timestep Collection Time: 4.33359
Timestep Consumption Time: 0.91941
PPO Batch Consumption Time: 0.04993
Total Iteration Time: 5.25300

Cumulative Model Updates: 16,821
Cumulative Timesteps: 280,845,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,662.00723
Policy Entropy: 0.58411
Value Function Loss: 0.07295

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.04603
Policy Update Magnitude: 0.02431
Value Function Update Magnitude: 0.03307

Collected Steps per Second: 5,820.61959
Overall Steps per Second: 5,209.24378

Timestep Collection Time: 8.59049
Timestep Consumption Time: 1.00821
PPO Batch Consumption Time: 0.09187
Total Iteration Time: 9.59871

Cumulative Model Updates: 16,824
Cumulative Timesteps: 280,895,588

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 280895588...
Checkpoint 280895588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,920.02788
Policy Entropy: 0.58657
Value Function Loss: 0.06916

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03075
Policy Update Magnitude: 0.02360
Value Function Update Magnitude: 0.02967

Collected Steps per Second: 15,057.08182
Overall Steps per Second: 11,492.54412

Timestep Collection Time: 3.32083
Timestep Consumption Time: 1.02999
PPO Batch Consumption Time: 0.09157
Total Iteration Time: 4.35082

Cumulative Model Updates: 16,827
Cumulative Timesteps: 280,945,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,319.70555
Policy Entropy: 0.57867
Value Function Loss: 0.07598

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.02336
Value Function Update Magnitude: 0.02844

Collected Steps per Second: 15,488.05826
Overall Steps per Second: 11,812.41126

Timestep Collection Time: 3.22894
Timestep Consumption Time: 1.00474
PPO Batch Consumption Time: 0.08558
Total Iteration Time: 4.23368

Cumulative Model Updates: 16,830
Cumulative Timesteps: 280,995,600

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 280995600...
Checkpoint 280995600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,333.82157
Policy Entropy: 0.57400
Value Function Loss: 0.08022

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.02409
Value Function Update Magnitude: 0.02943

Collected Steps per Second: 12,990.06488
Overall Steps per Second: 9,857.21228

Timestep Collection Time: 3.85156
Timestep Consumption Time: 1.22412
PPO Batch Consumption Time: 0.13497
Total Iteration Time: 5.07567

Cumulative Model Updates: 16,833
Cumulative Timesteps: 281,045,632

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,766.09244
Policy Entropy: 0.57082
Value Function Loss: 0.08134

Mean KL Divergence: 0.00162
SB3 Clip Fraction: 0.01601
Policy Update Magnitude: 0.02697
Value Function Update Magnitude: 0.02820

Collected Steps per Second: 10,144.22875
Overall Steps per Second: 8,169.81788

Timestep Collection Time: 4.93088
Timestep Consumption Time: 1.19165
PPO Batch Consumption Time: 0.08534
Total Iteration Time: 6.12254

Cumulative Model Updates: 16,836
Cumulative Timesteps: 281,095,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 281095652...
Checkpoint 281095652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,932.29375
Policy Entropy: 0.57581
Value Function Loss: 0.07528

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01677
Policy Update Magnitude: 0.03045
Value Function Update Magnitude: 0.03571

Collected Steps per Second: 5,374.08794
Overall Steps per Second: 4,681.41845

Timestep Collection Time: 9.30837
Timestep Consumption Time: 1.37728
PPO Batch Consumption Time: 0.09421
Total Iteration Time: 10.68565

Cumulative Model Updates: 16,839
Cumulative Timesteps: 281,145,676

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,956.99459
Policy Entropy: 0.57951
Value Function Loss: 0.06618

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.03069
Policy Update Magnitude: 0.02740
Value Function Update Magnitude: 0.03521

Collected Steps per Second: 5,259.45954
Overall Steps per Second: 4,621.61519

Timestep Collection Time: 9.50820
Timestep Consumption Time: 1.31226
PPO Batch Consumption Time: 0.08927
Total Iteration Time: 10.82046

Cumulative Model Updates: 16,842
Cumulative Timesteps: 281,195,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 281195684...
Checkpoint 281195684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,343.77638
Policy Entropy: 0.58161
Value Function Loss: 0.06631

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01953
Policy Update Magnitude: 0.02868
Value Function Update Magnitude: 0.03410

Collected Steps per Second: 5,332.94670
Overall Steps per Second: 4,727.50574

Timestep Collection Time: 9.37868
Timestep Consumption Time: 1.20111
PPO Batch Consumption Time: 0.08503
Total Iteration Time: 10.57979

Cumulative Model Updates: 16,845
Cumulative Timesteps: 281,245,700

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,937.00022
Policy Entropy: 0.57539
Value Function Loss: 0.06465

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02209
Policy Update Magnitude: 0.02661
Value Function Update Magnitude: 0.03400

Collected Steps per Second: 5,376.68353
Overall Steps per Second: 4,750.91527

Timestep Collection Time: 9.30834
Timestep Consumption Time: 1.22605
PPO Batch Consumption Time: 0.08858
Total Iteration Time: 10.53439

Cumulative Model Updates: 16,848
Cumulative Timesteps: 281,295,748

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 281295748...
Checkpoint 281295748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,160.17961
Policy Entropy: 0.57681
Value Function Loss: 0.06712

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.03190
Policy Update Magnitude: 0.02628
Value Function Update Magnitude: 0.03551

Collected Steps per Second: 5,242.44945
Overall Steps per Second: 4,645.64002

Timestep Collection Time: 9.54172
Timestep Consumption Time: 1.22579
PPO Batch Consumption Time: 0.08818
Total Iteration Time: 10.76752

Cumulative Model Updates: 16,851
Cumulative Timesteps: 281,345,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,262.93214
Policy Entropy: 0.58597
Value Function Loss: 0.06393

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.03139
Policy Update Magnitude: 0.02619
Value Function Update Magnitude: 0.03918

Collected Steps per Second: 5,379.48929
Overall Steps per Second: 4,796.88118

Timestep Collection Time: 9.29902
Timestep Consumption Time: 1.12942
PPO Batch Consumption Time: 0.08748
Total Iteration Time: 10.42844

Cumulative Model Updates: 16,854
Cumulative Timesteps: 281,395,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 281395794...
Checkpoint 281395794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,041.31409
Policy Entropy: 0.59609
Value Function Loss: 0.06559

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.02462
Value Function Update Magnitude: 0.03293

Collected Steps per Second: 5,269.33975
Overall Steps per Second: 4,739.84650

Timestep Collection Time: 9.49493
Timestep Consumption Time: 1.06069
PPO Batch Consumption Time: 0.09864
Total Iteration Time: 10.55562

Cumulative Model Updates: 16,857
Cumulative Timesteps: 281,445,826

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,607.44616
Policy Entropy: 0.60072
Value Function Loss: 0.06168

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02981
Policy Update Magnitude: 0.02510
Value Function Update Magnitude: 0.04081

Collected Steps per Second: 5,329.02096
Overall Steps per Second: 4,770.11203

Timestep Collection Time: 9.38446
Timestep Consumption Time: 1.09957
PPO Batch Consumption Time: 0.11335
Total Iteration Time: 10.48403

Cumulative Model Updates: 16,860
Cumulative Timesteps: 281,495,836

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 281495836...
Checkpoint 281495836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,514.97491
Policy Entropy: 0.59882
Value Function Loss: 0.06397

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.03643
Policy Update Magnitude: 0.02423
Value Function Update Magnitude: 0.03706

Collected Steps per Second: 5,325.94642
Overall Steps per Second: 4,778.23850

Timestep Collection Time: 9.39138
Timestep Consumption Time: 1.07649
PPO Batch Consumption Time: 0.11056
Total Iteration Time: 10.46787

Cumulative Model Updates: 16,863
Cumulative Timesteps: 281,545,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,458.82365
Policy Entropy: 0.59667
Value Function Loss: 0.05812

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.02332
Value Function Update Magnitude: 0.03091

Collected Steps per Second: 5,228.46846
Overall Steps per Second: 4,669.27795

Timestep Collection Time: 9.56571
Timestep Consumption Time: 1.14558
PPO Batch Consumption Time: 0.10858
Total Iteration Time: 10.71129

Cumulative Model Updates: 16,866
Cumulative Timesteps: 281,595,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 281595868...
Checkpoint 281595868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,648.34875
Policy Entropy: 0.58606
Value Function Loss: 0.06391

Mean KL Divergence: 0.00171
SB3 Clip Fraction: 0.02043
Policy Update Magnitude: 0.02240
Value Function Update Magnitude: 0.03236

Collected Steps per Second: 6,040.51193
Overall Steps per Second: 5,515.06339

Timestep Collection Time: 8.28109
Timestep Consumption Time: 0.78898
PPO Batch Consumption Time: 0.03840
Total Iteration Time: 9.07007

Cumulative Model Updates: 16,869
Cumulative Timesteps: 281,645,890

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,821.38245
Policy Entropy: 0.58543
Value Function Loss: 0.05935

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01594
Policy Update Magnitude: 0.02452
Value Function Update Magnitude: 0.02864

Collected Steps per Second: 16,867.79777
Overall Steps per Second: 12,302.54266

Timestep Collection Time: 2.96458
Timestep Consumption Time: 1.10010
PPO Batch Consumption Time: 0.12654
Total Iteration Time: 4.06469

Cumulative Model Updates: 16,872
Cumulative Timesteps: 281,695,896

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 281695896...
Checkpoint 281695896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,388.04127
Policy Entropy: 0.58778
Value Function Loss: 0.06392

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01696
Policy Update Magnitude: 0.02414
Value Function Update Magnitude: 0.02687

Collected Steps per Second: 5,388.99573
Overall Steps per Second: 4,783.09764

Timestep Collection Time: 9.28151
Timestep Consumption Time: 1.17573
PPO Batch Consumption Time: 0.09860
Total Iteration Time: 10.45724

Cumulative Model Updates: 16,875
Cumulative Timesteps: 281,745,914

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,347.90336
Policy Entropy: 0.59244
Value Function Loss: 0.07167

Mean KL Divergence: 0.00123
SB3 Clip Fraction: 0.01119
Policy Update Magnitude: 0.02539
Value Function Update Magnitude: 0.02912

Collected Steps per Second: 5,334.74979
Overall Steps per Second: 4,780.64710

Timestep Collection Time: 9.37626
Timestep Consumption Time: 1.08676
PPO Batch Consumption Time: 0.09195
Total Iteration Time: 10.46302

Cumulative Model Updates: 16,878
Cumulative Timesteps: 281,795,934

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 281795934...
Checkpoint 281795934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,464.51608
Policy Entropy: 0.59830
Value Function Loss: 0.06928

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02422
Policy Update Magnitude: 0.02601
Value Function Update Magnitude: 0.03080

Collected Steps per Second: 5,785.43941
Overall Steps per Second: 5,138.52819

Timestep Collection Time: 8.64239
Timestep Consumption Time: 1.08803
PPO Batch Consumption Time: 0.08726
Total Iteration Time: 9.73041

Cumulative Model Updates: 16,881
Cumulative Timesteps: 281,845,934

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,271.03887
Policy Entropy: 0.59852
Value Function Loss: 0.07179

Mean KL Divergence: 0.00242
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.02628
Value Function Update Magnitude: 0.03115

Collected Steps per Second: 5,881.62958
Overall Steps per Second: 5,170.54038

Timestep Collection Time: 8.50445
Timestep Consumption Time: 1.16959
PPO Batch Consumption Time: 0.08057
Total Iteration Time: 9.67404

Cumulative Model Updates: 16,884
Cumulative Timesteps: 281,895,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 281895954...
Checkpoint 281895954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,398.49515
Policy Entropy: 0.60383
Value Function Loss: 0.06578

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.02509
Policy Update Magnitude: 0.02393
Value Function Update Magnitude: 0.03121

Collected Steps per Second: 5,827.53740
Overall Steps per Second: 5,163.88286

Timestep Collection Time: 8.58201
Timestep Consumption Time: 1.10295
PPO Batch Consumption Time: 0.08164
Total Iteration Time: 9.68496

Cumulative Model Updates: 16,887
Cumulative Timesteps: 281,945,966

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,549.06232
Policy Entropy: 0.59968
Value Function Loss: 0.06884

Mean KL Divergence: 0.00180
SB3 Clip Fraction: 0.01849
Policy Update Magnitude: 0.02408
Value Function Update Magnitude: 0.03632

Collected Steps per Second: 5,885.97351
Overall Steps per Second: 5,205.04284

Timestep Collection Time: 8.49817
Timestep Consumption Time: 1.11174
PPO Batch Consumption Time: 0.08375
Total Iteration Time: 9.60991

Cumulative Model Updates: 16,890
Cumulative Timesteps: 281,995,986

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 281995986...
Checkpoint 281995986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,596.31358
Policy Entropy: 0.60119
Value Function Loss: 0.06693

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.02301
Value Function Update Magnitude: 0.03223

Collected Steps per Second: 5,654.17809
Overall Steps per Second: 5,012.54143

Timestep Collection Time: 8.84408
Timestep Consumption Time: 1.13210
PPO Batch Consumption Time: 0.08407
Total Iteration Time: 9.97618

Cumulative Model Updates: 16,893
Cumulative Timesteps: 282,045,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,659.86614
Policy Entropy: 0.60035
Value Function Loss: 0.07146

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.02231
Value Function Update Magnitude: 0.03133

Collected Steps per Second: 5,680.45921
Overall Steps per Second: 5,038.39198

Timestep Collection Time: 8.80598
Timestep Consumption Time: 1.12219
PPO Batch Consumption Time: 0.08338
Total Iteration Time: 9.92817

Cumulative Model Updates: 16,896
Cumulative Timesteps: 282,096,014

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 282096014...
Checkpoint 282096014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,454.84820
Policy Entropy: 0.59964
Value Function Loss: 0.07217

Mean KL Divergence: 0.00181
SB3 Clip Fraction: 0.01897
Policy Update Magnitude: 0.02348
Value Function Update Magnitude: 0.03205

Collected Steps per Second: 5,836.36296
Overall Steps per Second: 5,177.65378

Timestep Collection Time: 8.57006
Timestep Consumption Time: 1.09030
PPO Batch Consumption Time: 0.08869
Total Iteration Time: 9.66036

Cumulative Model Updates: 16,899
Cumulative Timesteps: 282,146,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,897.37789
Policy Entropy: 0.59230
Value Function Loss: 0.07723

Mean KL Divergence: 0.00141
SB3 Clip Fraction: 0.01077
Policy Update Magnitude: 0.02777
Value Function Update Magnitude: 0.03095

Collected Steps per Second: 5,644.11441
Overall Steps per Second: 5,004.11302

Timestep Collection Time: 8.86020
Timestep Consumption Time: 1.13318
PPO Batch Consumption Time: 0.08408
Total Iteration Time: 9.99338

Cumulative Model Updates: 16,902
Cumulative Timesteps: 282,196,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 282196040...
Checkpoint 282196040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,486.87635
Policy Entropy: 0.59709
Value Function Loss: 0.07065

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02033
Policy Update Magnitude: 0.02844
Value Function Update Magnitude: 0.02931

Collected Steps per Second: 5,510.20690
Overall Steps per Second: 4,926.73281

Timestep Collection Time: 9.07443
Timestep Consumption Time: 1.07469
PPO Batch Consumption Time: 0.08344
Total Iteration Time: 10.14912

Cumulative Model Updates: 16,905
Cumulative Timesteps: 282,246,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,128.25705
Policy Entropy: 0.60200
Value Function Loss: 0.07426

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01745
Policy Update Magnitude: 0.02859
Value Function Update Magnitude: 0.02923

Collected Steps per Second: 5,505.12439
Overall Steps per Second: 4,919.39338

Timestep Collection Time: 9.08317
Timestep Consumption Time: 1.08149
PPO Batch Consumption Time: 0.08431
Total Iteration Time: 10.16467

Cumulative Model Updates: 16,908
Cumulative Timesteps: 282,296,046

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 282296046...
Checkpoint 282296046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,488.15791
Policy Entropy: 0.60216
Value Function Loss: 0.07409

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.02884
Value Function Update Magnitude: 0.03519

Collected Steps per Second: 5,734.69757
Overall Steps per Second: 5,071.98244

Timestep Collection Time: 8.71886
Timestep Consumption Time: 1.13922
PPO Batch Consumption Time: 0.08112
Total Iteration Time: 9.85808

Cumulative Model Updates: 16,911
Cumulative Timesteps: 282,346,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,621.91621
Policy Entropy: 0.60011
Value Function Loss: 0.07646

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02723
Policy Update Magnitude: 0.02825
Value Function Update Magnitude: 0.02933

Collected Steps per Second: 5,850.55242
Overall Steps per Second: 5,174.66185

Timestep Collection Time: 8.55099
Timestep Consumption Time: 1.11689
PPO Batch Consumption Time: 0.08585
Total Iteration Time: 9.66788

Cumulative Model Updates: 16,914
Cumulative Timesteps: 282,396,074

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 282396074...
Checkpoint 282396074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,385.43145
Policy Entropy: 0.59892
Value Function Loss: 0.07159

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.02496
Value Function Update Magnitude: 0.03060

Collected Steps per Second: 5,746.42728
Overall Steps per Second: 5,059.12255

Timestep Collection Time: 8.70175
Timestep Consumption Time: 1.18217
PPO Batch Consumption Time: 0.08352
Total Iteration Time: 9.88393

Cumulative Model Updates: 16,917
Cumulative Timesteps: 282,446,078

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,590.96637
Policy Entropy: 0.61090
Value Function Loss: 0.06747

Mean KL Divergence: 0.00153
SB3 Clip Fraction: 0.01489
Policy Update Magnitude: 0.02437
Value Function Update Magnitude: 0.03391

Collected Steps per Second: 5,685.04542
Overall Steps per Second: 5,047.16234

Timestep Collection Time: 8.79993
Timestep Consumption Time: 1.11217
PPO Batch Consumption Time: 0.08448
Total Iteration Time: 9.91210

Cumulative Model Updates: 16,920
Cumulative Timesteps: 282,496,106

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 282496106...
Checkpoint 282496106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,717.13563
Policy Entropy: 0.61424
Value Function Loss: 0.06574

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02267
Policy Update Magnitude: 0.02424
Value Function Update Magnitude: 0.03047

Collected Steps per Second: 5,812.64110
Overall Steps per Second: 5,159.07644

Timestep Collection Time: 8.60538
Timestep Consumption Time: 1.09015
PPO Batch Consumption Time: 0.08679
Total Iteration Time: 9.69553

Cumulative Model Updates: 16,923
Cumulative Timesteps: 282,546,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,225.62667
Policy Entropy: 0.61482
Value Function Loss: 0.06806

Mean KL Divergence: 0.00185
SB3 Clip Fraction: 0.01769
Policy Update Magnitude: 0.02261
Value Function Update Magnitude: 0.02934

Collected Steps per Second: 5,664.72786
Overall Steps per Second: 5,040.91200

Timestep Collection Time: 8.82796
Timestep Consumption Time: 1.09247
PPO Batch Consumption Time: 0.08457
Total Iteration Time: 9.92043

Cumulative Model Updates: 16,926
Cumulative Timesteps: 282,596,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 282596134...
Checkpoint 282596134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,893.80592
Policy Entropy: 0.61199
Value Function Loss: 0.06316

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02849
Policy Update Magnitude: 0.02298
Value Function Update Magnitude: 0.02885

Collected Steps per Second: 5,565.94122
Overall Steps per Second: 4,941.59254

Timestep Collection Time: 8.98680
Timestep Consumption Time: 1.13544
PPO Batch Consumption Time: 0.08386
Total Iteration Time: 10.12224

Cumulative Model Updates: 16,929
Cumulative Timesteps: 282,646,154

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,221.72908
Policy Entropy: 0.61376
Value Function Loss: 0.06469

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04323
Policy Update Magnitude: 0.02401
Value Function Update Magnitude: 0.02878

Collected Steps per Second: 5,467.73451
Overall Steps per Second: 4,892.78270

Timestep Collection Time: 9.14638
Timestep Consumption Time: 1.07479
PPO Batch Consumption Time: 0.08627
Total Iteration Time: 10.22118

Cumulative Model Updates: 16,932
Cumulative Timesteps: 282,696,164

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 282696164...
Checkpoint 282696164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,024.19255
Policy Entropy: 0.61861
Value Function Loss: 0.05529

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02093
Policy Update Magnitude: 0.02453
Value Function Update Magnitude: 0.02940

Collected Steps per Second: 5,642.79150
Overall Steps per Second: 5,046.18681

Timestep Collection Time: 8.86122
Timestep Consumption Time: 1.04765
PPO Batch Consumption Time: 0.08790
Total Iteration Time: 9.90887

Cumulative Model Updates: 16,935
Cumulative Timesteps: 282,746,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,648.91509
Policy Entropy: 0.61973
Value Function Loss: 0.05428

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04341
Policy Update Magnitude: 0.02479
Value Function Update Magnitude: 0.02785

Collected Steps per Second: 5,637.38580
Overall Steps per Second: 5,018.71923

Timestep Collection Time: 8.87042
Timestep Consumption Time: 1.09347
PPO Batch Consumption Time: 0.08646
Total Iteration Time: 9.96390

Cumulative Model Updates: 16,938
Cumulative Timesteps: 282,796,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 282796172...
Checkpoint 282796172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,355.65472
Policy Entropy: 0.62427
Value Function Loss: 0.05405

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02936
Policy Update Magnitude: 0.02335
Value Function Update Magnitude: 0.02497

Collected Steps per Second: 5,705.09340
Overall Steps per Second: 5,088.71310

Timestep Collection Time: 8.76515
Timestep Consumption Time: 1.06170
PPO Batch Consumption Time: 0.08370
Total Iteration Time: 9.82685

Cumulative Model Updates: 16,941
Cumulative Timesteps: 282,846,178

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,748.78079
Policy Entropy: 0.61634
Value Function Loss: 0.05659

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.05023
Policy Update Magnitude: 0.02263
Value Function Update Magnitude: 0.02714

Collected Steps per Second: 5,699.09906
Overall Steps per Second: 5,067.24682

Timestep Collection Time: 8.77402
Timestep Consumption Time: 1.09406
PPO Batch Consumption Time: 0.08314
Total Iteration Time: 9.86808

Cumulative Model Updates: 16,944
Cumulative Timesteps: 282,896,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 282896182...
Checkpoint 282896182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,490.74281
Policy Entropy: 0.61456
Value Function Loss: 0.06342

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04951
Policy Update Magnitude: 0.02072
Value Function Update Magnitude: 0.03172

Collected Steps per Second: 5,939.09563
Overall Steps per Second: 5,223.57096

Timestep Collection Time: 8.42283
Timestep Consumption Time: 1.15376
PPO Batch Consumption Time: 0.08537
Total Iteration Time: 9.57659

Cumulative Model Updates: 16,947
Cumulative Timesteps: 282,946,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,798.45063
Policy Entropy: 0.60420
Value Function Loss: 0.05927

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.03624
Policy Update Magnitude: 0.02145
Value Function Update Magnitude: 0.03037

Collected Steps per Second: 5,785.00454
Overall Steps per Second: 5,080.94035

Timestep Collection Time: 8.64684
Timestep Consumption Time: 1.19819
PPO Batch Consumption Time: 0.08499
Total Iteration Time: 9.84503

Cumulative Model Updates: 16,950
Cumulative Timesteps: 282,996,228

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 282996228...
Checkpoint 282996228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,645.03469
Policy Entropy: 0.60823
Value Function Loss: 0.05878

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.02246
Value Function Update Magnitude: 0.02957

Collected Steps per Second: 5,601.36235
Overall Steps per Second: 4,883.81671

Timestep Collection Time: 8.92997
Timestep Consumption Time: 1.31202
PPO Batch Consumption Time: 0.08805
Total Iteration Time: 10.24199

Cumulative Model Updates: 16,953
Cumulative Timesteps: 283,046,248

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,439.57765
Policy Entropy: 0.60148
Value Function Loss: 0.05880

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.02475
Value Function Update Magnitude: 0.03662

Collected Steps per Second: 6,014.09014
Overall Steps per Second: 5,204.27904

Timestep Collection Time: 8.31414
Timestep Consumption Time: 1.29372
PPO Batch Consumption Time: 0.08423
Total Iteration Time: 9.60786

Cumulative Model Updates: 16,956
Cumulative Timesteps: 283,096,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 283096250...
Checkpoint 283096250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,505.70119
Policy Entropy: 0.60142
Value Function Loss: 0.06113

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.02465
Value Function Update Magnitude: 0.03193

Collected Steps per Second: 5,627.94973
Overall Steps per Second: 4,962.24992

Timestep Collection Time: 8.88565
Timestep Consumption Time: 1.19204
PPO Batch Consumption Time: 0.08375
Total Iteration Time: 10.07769

Cumulative Model Updates: 16,959
Cumulative Timesteps: 283,146,258

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,993.43589
Policy Entropy: 0.59550
Value Function Loss: 0.06542

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02067
Policy Update Magnitude: 0.02296
Value Function Update Magnitude: 0.03098

Collected Steps per Second: 5,444.22679
Overall Steps per Second: 4,822.36400

Timestep Collection Time: 9.19102
Timestep Consumption Time: 1.18522
PPO Batch Consumption Time: 0.08664
Total Iteration Time: 10.37624

Cumulative Model Updates: 16,962
Cumulative Timesteps: 283,196,296

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 283196296...
Checkpoint 283196296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,961.48211
Policy Entropy: 0.59618
Value Function Loss: 0.06749

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.03881
Policy Update Magnitude: 0.02345
Value Function Update Magnitude: 0.02994

Collected Steps per Second: 5,710.88390
Overall Steps per Second: 5,041.85359

Timestep Collection Time: 8.75836
Timestep Consumption Time: 1.16219
PPO Batch Consumption Time: 0.08506
Total Iteration Time: 9.92056

Cumulative Model Updates: 16,965
Cumulative Timesteps: 283,246,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,057.63674
Policy Entropy: 0.59157
Value Function Loss: 0.06977

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.02451
Value Function Update Magnitude: 0.02884

Collected Steps per Second: 5,880.71565
Overall Steps per Second: 5,193.78339

Timestep Collection Time: 8.50509
Timestep Consumption Time: 1.12489
PPO Batch Consumption Time: 0.08620
Total Iteration Time: 9.62997

Cumulative Model Updates: 16,968
Cumulative Timesteps: 283,296,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 283296330...
Checkpoint 283296330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,979.68145
Policy Entropy: 0.59017
Value Function Loss: 0.07110

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02149
Policy Update Magnitude: 0.02663
Value Function Update Magnitude: 0.03164

Collected Steps per Second: 5,986.52072
Overall Steps per Second: 5,249.59188

Timestep Collection Time: 8.35644
Timestep Consumption Time: 1.17306
PPO Batch Consumption Time: 0.08486
Total Iteration Time: 9.52950

Cumulative Model Updates: 16,971
Cumulative Timesteps: 283,346,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,962.96361
Policy Entropy: 0.58962
Value Function Loss: 0.07615

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.03484
Policy Update Magnitude: 0.02744
Value Function Update Magnitude: 0.03257

Collected Steps per Second: 5,914.67811
Overall Steps per Second: 5,217.64232

Timestep Collection Time: 8.45591
Timestep Consumption Time: 1.12964
PPO Batch Consumption Time: 0.08353
Total Iteration Time: 9.58556

Cumulative Model Updates: 16,974
Cumulative Timesteps: 283,396,370

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 283396370...
Checkpoint 283396370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,871.21798
Policy Entropy: 0.60287
Value Function Loss: 0.06862

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.02632
Value Function Update Magnitude: 0.03170

Collected Steps per Second: 5,489.44149
Overall Steps per Second: 4,902.97662

Timestep Collection Time: 9.11095
Timestep Consumption Time: 1.08980
PPO Batch Consumption Time: 0.08167
Total Iteration Time: 10.20074

Cumulative Model Updates: 16,977
Cumulative Timesteps: 283,446,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,096.57871
Policy Entropy: 0.60722
Value Function Loss: 0.06939

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03639
Policy Update Magnitude: 0.02471
Value Function Update Magnitude: 0.03661

Collected Steps per Second: 5,561.22098
Overall Steps per Second: 4,946.62606

Timestep Collection Time: 8.99551
Timestep Consumption Time: 1.11765
PPO Batch Consumption Time: 0.08437
Total Iteration Time: 10.11316

Cumulative Model Updates: 16,980
Cumulative Timesteps: 283,496,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 283496410...
Checkpoint 283496410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,281.75360
Policy Entropy: 0.60937
Value Function Loss: 0.05769

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03101
Policy Update Magnitude: 0.02456
Value Function Update Magnitude: 0.03214

Collected Steps per Second: 5,575.97273
Overall Steps per Second: 4,969.21830

Timestep Collection Time: 8.97278
Timestep Consumption Time: 1.09560
PPO Batch Consumption Time: 0.08426
Total Iteration Time: 10.06838

Cumulative Model Updates: 16,983
Cumulative Timesteps: 283,546,442

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,895.26393
Policy Entropy: 0.60601
Value Function Loss: 0.05996

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03273
Policy Update Magnitude: 0.02283
Value Function Update Magnitude: 0.03118

Collected Steps per Second: 5,530.34106
Overall Steps per Second: 4,911.19659

Timestep Collection Time: 9.04790
Timestep Consumption Time: 1.14065
PPO Batch Consumption Time: 0.08552
Total Iteration Time: 10.18856

Cumulative Model Updates: 16,986
Cumulative Timesteps: 283,596,480

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 283596480...
Checkpoint 283596480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,104.35981
Policy Entropy: 0.60320
Value Function Loss: 0.06565

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.02355
Value Function Update Magnitude: 0.03066

Collected Steps per Second: 5,681.05394
Overall Steps per Second: 5,052.39710

Timestep Collection Time: 8.80259
Timestep Consumption Time: 1.09528
PPO Batch Consumption Time: 0.08251
Total Iteration Time: 9.89788

Cumulative Model Updates: 16,989
Cumulative Timesteps: 283,646,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,789.35373
Policy Entropy: 0.60016
Value Function Loss: 0.07513

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03283
Policy Update Magnitude: 0.02715
Value Function Update Magnitude: 0.03127

Collected Steps per Second: 5,555.52834
Overall Steps per Second: 4,938.25337

Timestep Collection Time: 9.00292
Timestep Consumption Time: 1.12535
PPO Batch Consumption Time: 0.09198
Total Iteration Time: 10.12828

Cumulative Model Updates: 16,992
Cumulative Timesteps: 283,696,504

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 283696504...
Checkpoint 283696504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,656.02582
Policy Entropy: 0.59930
Value Function Loss: 0.07468

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03527
Policy Update Magnitude: 0.03541
Value Function Update Magnitude: 0.03526

Collected Steps per Second: 5,554.02233
Overall Steps per Second: 4,943.16218

Timestep Collection Time: 9.00428
Timestep Consumption Time: 1.11272
PPO Batch Consumption Time: 0.08502
Total Iteration Time: 10.11701

Cumulative Model Updates: 16,995
Cumulative Timesteps: 283,746,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,659.66447
Policy Entropy: 0.60047
Value Function Loss: 0.07213

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.03131
Policy Update Magnitude: 0.03231
Value Function Update Magnitude: 0.03626

Collected Steps per Second: 5,732.83130
Overall Steps per Second: 5,069.61808

Timestep Collection Time: 8.72204
Timestep Consumption Time: 1.14103
PPO Batch Consumption Time: 0.08527
Total Iteration Time: 9.86307

Cumulative Model Updates: 16,998
Cumulative Timesteps: 283,796,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 283796516...
Checkpoint 283796516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,898.24517
Policy Entropy: 0.60126
Value Function Loss: 0.07465

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03080
Policy Update Magnitude: 0.03116
Value Function Update Magnitude: 0.03725

Collected Steps per Second: 5,753.39025
Overall Steps per Second: 5,100.86340

Timestep Collection Time: 8.69435
Timestep Consumption Time: 1.11222
PPO Batch Consumption Time: 0.08253
Total Iteration Time: 9.80658

Cumulative Model Updates: 17,001
Cumulative Timesteps: 283,846,538

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,724.71363
Policy Entropy: 0.60359
Value Function Loss: 0.07139

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04700
Policy Update Magnitude: 0.03052
Value Function Update Magnitude: 0.03568

Collected Steps per Second: 5,728.48632
Overall Steps per Second: 5,071.10423

Timestep Collection Time: 8.73669
Timestep Consumption Time: 1.13256
PPO Batch Consumption Time: 0.08684
Total Iteration Time: 9.86925

Cumulative Model Updates: 17,004
Cumulative Timesteps: 283,896,586

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 283896586...
Checkpoint 283896586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,708.28592
Policy Entropy: 0.59702
Value Function Loss: 0.07243

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.03639
Policy Update Magnitude: 0.02964
Value Function Update Magnitude: 0.03401

Collected Steps per Second: 5,409.96749
Overall Steps per Second: 4,884.86026

Timestep Collection Time: 9.24553
Timestep Consumption Time: 0.99387
PPO Batch Consumption Time: 0.08658
Total Iteration Time: 10.23939

Cumulative Model Updates: 17,007
Cumulative Timesteps: 283,946,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,415.30937
Policy Entropy: 0.60135
Value Function Loss: 0.06907

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04758
Policy Update Magnitude: 0.02725
Value Function Update Magnitude: 0.03583

Collected Steps per Second: 5,568.07406
Overall Steps per Second: 4,977.10275

Timestep Collection Time: 8.98444
Timestep Consumption Time: 1.06679
PPO Batch Consumption Time: 0.09143
Total Iteration Time: 10.05123

Cumulative Model Updates: 17,010
Cumulative Timesteps: 283,996,630

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 283996630...
Checkpoint 283996630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,574.20617
Policy Entropy: 0.60232
Value Function Loss: 0.07786

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04559
Policy Update Magnitude: 0.02706
Value Function Update Magnitude: 0.03755

Collected Steps per Second: 5,465.20404
Overall Steps per Second: 4,916.55011

Timestep Collection Time: 9.14916
Timestep Consumption Time: 1.02098
PPO Batch Consumption Time: 0.08577
Total Iteration Time: 10.17014

Cumulative Model Updates: 17,013
Cumulative Timesteps: 284,046,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,266.02794
Policy Entropy: 0.60452
Value Function Loss: 0.07821

Mean KL Divergence: 0.00190
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.02653
Value Function Update Magnitude: 0.03694

Collected Steps per Second: 7,210.76254
Overall Steps per Second: 6,453.96131

Timestep Collection Time: 6.93408
Timestep Consumption Time: 0.81310
PPO Batch Consumption Time: 0.04180
Total Iteration Time: 7.74718

Cumulative Model Updates: 17,016
Cumulative Timesteps: 284,096,632

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 284096632...
Checkpoint 284096632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,824.39688
Policy Entropy: 0.60281
Value Function Loss: 0.07924

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02352
Policy Update Magnitude: 0.02644
Value Function Update Magnitude: 0.03641

Collected Steps per Second: 10,168.99536
Overall Steps per Second: 8,462.83488

Timestep Collection Time: 4.91907
Timestep Consumption Time: 0.99172
PPO Batch Consumption Time: 0.08864
Total Iteration Time: 5.91079

Cumulative Model Updates: 17,019
Cumulative Timesteps: 284,146,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,892.09604
Policy Entropy: 0.59325
Value Function Loss: 0.08285

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.02673
Value Function Update Magnitude: 0.03541

Collected Steps per Second: 5,511.87988
Overall Steps per Second: 4,957.72539

Timestep Collection Time: 9.07240
Timestep Consumption Time: 1.01408
PPO Batch Consumption Time: 0.08667
Total Iteration Time: 10.08648

Cumulative Model Updates: 17,022
Cumulative Timesteps: 284,196,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 284196660...
Checkpoint 284196660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,701.22637
Policy Entropy: 0.59544
Value Function Loss: 0.07549

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.02867
Value Function Update Magnitude: 0.03607

Collected Steps per Second: 12,598.50710
Overall Steps per Second: 10,364.20995

Timestep Collection Time: 3.96872
Timestep Consumption Time: 0.85557
PPO Batch Consumption Time: 0.04305
Total Iteration Time: 4.82429

Cumulative Model Updates: 17,025
Cumulative Timesteps: 284,246,660

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,368.18586
Policy Entropy: 0.60142
Value Function Loss: 0.07844

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03462
Policy Update Magnitude: 0.03093
Value Function Update Magnitude: 0.03343

Collected Steps per Second: 18,522.40729
Overall Steps per Second: 13,825.64215

Timestep Collection Time: 2.70008
Timestep Consumption Time: 0.91726
PPO Batch Consumption Time: 0.07892
Total Iteration Time: 3.61734

Cumulative Model Updates: 17,028
Cumulative Timesteps: 284,296,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 284296672...
Checkpoint 284296672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,336.14988
Policy Entropy: 0.60274
Value Function Loss: 0.07456

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06810
Policy Update Magnitude: 0.02837
Value Function Update Magnitude: 0.03526

Collected Steps per Second: 18,843.83864
Overall Steps per Second: 13,849.94105

Timestep Collection Time: 2.65402
Timestep Consumption Time: 0.95697
PPO Batch Consumption Time: 0.07726
Total Iteration Time: 3.61099

Cumulative Model Updates: 17,031
Cumulative Timesteps: 284,346,684

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,256.20758
Policy Entropy: 0.60070
Value Function Loss: 0.07396

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03644
Policy Update Magnitude: 0.02681
Value Function Update Magnitude: 0.03610

Collected Steps per Second: 14,656.82366
Overall Steps per Second: 11,645.36128

Timestep Collection Time: 3.41179
Timestep Consumption Time: 0.88228
PPO Batch Consumption Time: 0.04327
Total Iteration Time: 4.29407

Cumulative Model Updates: 17,034
Cumulative Timesteps: 284,396,690

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 284396690...
Checkpoint 284396690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,790.12444
Policy Entropy: 0.60381
Value Function Loss: 0.06068

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06560
Policy Update Magnitude: 0.02944
Value Function Update Magnitude: 0.03220

Collected Steps per Second: 13,955.98380
Overall Steps per Second: 11,176.67929

Timestep Collection Time: 3.58441
Timestep Consumption Time: 0.89134
PPO Batch Consumption Time: 0.04901
Total Iteration Time: 4.47575

Cumulative Model Updates: 17,037
Cumulative Timesteps: 284,446,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,582.44592
Policy Entropy: 0.60786
Value Function Loss: 0.06004

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.05122
Policy Update Magnitude: 0.02582
Value Function Update Magnitude: 0.03206

Collected Steps per Second: 14,657.23826
Overall Steps per Second: 11,456.76404

Timestep Collection Time: 3.41251
Timestep Consumption Time: 0.95329
PPO Batch Consumption Time: 0.05875
Total Iteration Time: 4.36581

Cumulative Model Updates: 17,040
Cumulative Timesteps: 284,496,732

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 284496732...
Checkpoint 284496732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,086.82386
Policy Entropy: 0.60683
Value Function Loss: 0.07042

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07387
Policy Update Magnitude: 0.02458
Value Function Update Magnitude: 0.03142

Collected Steps per Second: 14,171.14992
Overall Steps per Second: 11,099.11702

Timestep Collection Time: 3.52971
Timestep Consumption Time: 0.97696
PPO Batch Consumption Time: 0.06884
Total Iteration Time: 4.50666

Cumulative Model Updates: 17,043
Cumulative Timesteps: 284,546,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,125.79931
Policy Entropy: 0.60454
Value Function Loss: 0.06596

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.09925
Policy Update Magnitude: 0.02105
Value Function Update Magnitude: 0.03033

Collected Steps per Second: 14,422.67183
Overall Steps per Second: 11,309.21047

Timestep Collection Time: 3.46787
Timestep Consumption Time: 0.95472
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 4.42259

Cumulative Model Updates: 17,046
Cumulative Timesteps: 284,596,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 284596768...
Checkpoint 284596768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,084.35298
Policy Entropy: 0.60404
Value Function Loss: 0.06348

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05481
Policy Update Magnitude: 0.02418
Value Function Update Magnitude: 0.02843

Collected Steps per Second: 14,723.24527
Overall Steps per Second: 11,459.75770

Timestep Collection Time: 3.39830
Timestep Consumption Time: 0.96776
PPO Batch Consumption Time: 0.06609
Total Iteration Time: 4.36606

Cumulative Model Updates: 17,049
Cumulative Timesteps: 284,646,802

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,252.84817
Policy Entropy: 0.60077
Value Function Loss: 0.05795

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.07087
Policy Update Magnitude: 0.02411
Value Function Update Magnitude: 0.03258

Collected Steps per Second: 14,773.78516
Overall Steps per Second: 11,681.61656

Timestep Collection Time: 3.38559
Timestep Consumption Time: 0.89618
PPO Batch Consumption Time: 0.05302
Total Iteration Time: 4.28177

Cumulative Model Updates: 17,052
Cumulative Timesteps: 284,696,820

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 284696820...
Checkpoint 284696820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,623.76732
Policy Entropy: 0.59236
Value Function Loss: 0.06800

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05247
Policy Update Magnitude: 0.02874
Value Function Update Magnitude: 0.03652

Collected Steps per Second: 15,392.99561
Overall Steps per Second: 12,058.24942

Timestep Collection Time: 3.24849
Timestep Consumption Time: 0.89838
PPO Batch Consumption Time: 0.05693
Total Iteration Time: 4.14687

Cumulative Model Updates: 17,055
Cumulative Timesteps: 284,746,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,906.31491
Policy Entropy: 0.60058
Value Function Loss: 0.06518

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06866
Policy Update Magnitude: 0.02731
Value Function Update Magnitude: 0.03456

Collected Steps per Second: 6,757.63987
Overall Steps per Second: 5,868.75340

Timestep Collection Time: 7.40318
Timestep Consumption Time: 1.12129
PPO Batch Consumption Time: 0.08449
Total Iteration Time: 8.52447

Cumulative Model Updates: 17,058
Cumulative Timesteps: 284,796,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 284796852...
Checkpoint 284796852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,561.57890
Policy Entropy: 0.60858
Value Function Loss: 0.06432

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.04691
Policy Update Magnitude: 0.02589
Value Function Update Magnitude: 0.03723

Collected Steps per Second: 5,611.84946
Overall Steps per Second: 4,979.46303

Timestep Collection Time: 8.91221
Timestep Consumption Time: 1.13184
PPO Batch Consumption Time: 0.08638
Total Iteration Time: 10.04405

Cumulative Model Updates: 17,061
Cumulative Timesteps: 284,846,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,465.77258
Policy Entropy: 0.61121
Value Function Loss: 0.06281

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05358
Policy Update Magnitude: 0.02602
Value Function Update Magnitude: 0.03623

Collected Steps per Second: 5,546.72811
Overall Steps per Second: 4,965.30554

Timestep Collection Time: 9.01865
Timestep Consumption Time: 1.05606
PPO Batch Consumption Time: 0.08343
Total Iteration Time: 10.07471

Cumulative Model Updates: 17,064
Cumulative Timesteps: 284,896,890

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 284896890...
Checkpoint 284896890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,572.79755
Policy Entropy: 0.61140
Value Function Loss: 0.07093

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02943
Policy Update Magnitude: 0.02874
Value Function Update Magnitude: 0.03664

Collected Steps per Second: 5,742.23917
Overall Steps per Second: 5,088.21721

Timestep Collection Time: 8.71054
Timestep Consumption Time: 1.11962
PPO Batch Consumption Time: 0.09088
Total Iteration Time: 9.83016

Cumulative Model Updates: 17,067
Cumulative Timesteps: 284,946,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,792.94597
Policy Entropy: 0.61541
Value Function Loss: 0.07350

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.04781
Policy Update Magnitude: 0.02786
Value Function Update Magnitude: 0.04014

Collected Steps per Second: 5,445.83005
Overall Steps per Second: 4,858.34396

Timestep Collection Time: 9.18317
Timestep Consumption Time: 1.11046
PPO Batch Consumption Time: 0.08270
Total Iteration Time: 10.29363

Cumulative Model Updates: 17,070
Cumulative Timesteps: 284,996,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 284996918...
Checkpoint 284996918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,540.97407
Policy Entropy: 0.61829
Value Function Loss: 0.07457

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04163
Policy Update Magnitude: 0.02831
Value Function Update Magnitude: 0.03580

Collected Steps per Second: 5,525.49855
Overall Steps per Second: 4,888.50065

Timestep Collection Time: 9.05258
Timestep Consumption Time: 1.17960
PPO Batch Consumption Time: 0.08202
Total Iteration Time: 10.23218

Cumulative Model Updates: 17,073
Cumulative Timesteps: 285,046,938

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,992.37295
Policy Entropy: 0.62362
Value Function Loss: 0.06862

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06973
Policy Update Magnitude: 0.02504
Value Function Update Magnitude: 0.03788

Collected Steps per Second: 5,292.48924
Overall Steps per Second: 4,756.46617

Timestep Collection Time: 9.44924
Timestep Consumption Time: 1.06487
PPO Batch Consumption Time: 0.08335
Total Iteration Time: 10.51411

Cumulative Model Updates: 17,076
Cumulative Timesteps: 285,096,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 285096948...
Checkpoint 285096948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,915.94137
Policy Entropy: 0.61021
Value Function Loss: 0.07315

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05541
Policy Update Magnitude: 0.02613
Value Function Update Magnitude: 0.03425

Collected Steps per Second: 5,376.39932
Overall Steps per Second: 4,830.24944

Timestep Collection Time: 9.30586
Timestep Consumption Time: 1.05220
PPO Batch Consumption Time: 0.08210
Total Iteration Time: 10.35806

Cumulative Model Updates: 17,079
Cumulative Timesteps: 285,146,980

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,019.02342
Policy Entropy: 0.61261
Value Function Loss: 0.07487

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.09397
Policy Update Magnitude: 0.02527
Value Function Update Magnitude: 0.03409

Collected Steps per Second: 5,531.46600
Overall Steps per Second: 4,946.32914

Timestep Collection Time: 9.04064
Timestep Consumption Time: 1.06948
PPO Batch Consumption Time: 0.09082
Total Iteration Time: 10.11012

Cumulative Model Updates: 17,082
Cumulative Timesteps: 285,196,988

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 285196988...
Checkpoint 285196988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,117.61536
Policy Entropy: 0.60067
Value Function Loss: 0.07837

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.09688
Policy Update Magnitude: 0.02450
Value Function Update Magnitude: 0.03558

Collected Steps per Second: 5,554.07555
Overall Steps per Second: 4,975.84596

Timestep Collection Time: 9.00600
Timestep Consumption Time: 1.04656
PPO Batch Consumption Time: 0.08847
Total Iteration Time: 10.05256

Cumulative Model Updates: 17,085
Cumulative Timesteps: 285,247,008

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,895.53652
Policy Entropy: 0.60215
Value Function Loss: 0.07088

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.08529
Policy Update Magnitude: 0.02734
Value Function Update Magnitude: 0.03582

Collected Steps per Second: 5,852.87017
Overall Steps per Second: 5,244.25542

Timestep Collection Time: 8.54794
Timestep Consumption Time: 0.99202
PPO Batch Consumption Time: 0.08295
Total Iteration Time: 9.53996

Cumulative Model Updates: 17,088
Cumulative Timesteps: 285,297,038

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 285297038...
Checkpoint 285297038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,717.17425
Policy Entropy: 0.60235
Value Function Loss: 0.06684

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07700
Policy Update Magnitude: 0.02560
Value Function Update Magnitude: 0.03278

Collected Steps per Second: 5,690.45899
Overall Steps per Second: 5,039.83524

Timestep Collection Time: 8.78804
Timestep Consumption Time: 1.13450
PPO Batch Consumption Time: 0.08352
Total Iteration Time: 9.92255

Cumulative Model Updates: 17,091
Cumulative Timesteps: 285,347,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,121.20396
Policy Entropy: 0.61110
Value Function Loss: 0.06589

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.06306
Policy Update Magnitude: 0.02412
Value Function Update Magnitude: 0.03377

Collected Steps per Second: 5,736.18183
Overall Steps per Second: 5,063.23312

Timestep Collection Time: 8.72009
Timestep Consumption Time: 1.15898
PPO Batch Consumption Time: 0.09339
Total Iteration Time: 9.87906

Cumulative Model Updates: 17,094
Cumulative Timesteps: 285,397,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 285397066...
Checkpoint 285397066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,803.11829
Policy Entropy: 0.60321
Value Function Loss: 0.07143

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.05695
Policy Update Magnitude: 0.02624
Value Function Update Magnitude: 0.03803

Collected Steps per Second: 5,720.36103
Overall Steps per Second: 5,074.24443

Timestep Collection Time: 8.74385
Timestep Consumption Time: 1.11338
PPO Batch Consumption Time: 0.08093
Total Iteration Time: 9.85723

Cumulative Model Updates: 17,097
Cumulative Timesteps: 285,447,084

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,004.12281
Policy Entropy: 0.59986
Value Function Loss: 0.07227

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.02844
Value Function Update Magnitude: 0.03703

Collected Steps per Second: 5,695.23378
Overall Steps per Second: 5,077.46158

Timestep Collection Time: 8.78489
Timestep Consumption Time: 1.06885
PPO Batch Consumption Time: 0.08946
Total Iteration Time: 9.85374

Cumulative Model Updates: 17,100
Cumulative Timesteps: 285,497,116

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 285497116...
Checkpoint 285497116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,761.55356
Policy Entropy: 0.60241
Value Function Loss: 0.06815

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03163
Policy Update Magnitude: 0.02778
Value Function Update Magnitude: 0.03650

Collected Steps per Second: 5,721.19191
Overall Steps per Second: 5,061.23360

Timestep Collection Time: 8.74188
Timestep Consumption Time: 1.13990
PPO Batch Consumption Time: 0.08507
Total Iteration Time: 9.88178

Cumulative Model Updates: 17,103
Cumulative Timesteps: 285,547,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,541.91843
Policy Entropy: 0.61072
Value Function Loss: 0.06681

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03170
Policy Update Magnitude: 0.03140
Value Function Update Magnitude: 0.03359

Collected Steps per Second: 5,446.39869
Overall Steps per Second: 4,845.30787

Timestep Collection Time: 9.18185
Timestep Consumption Time: 1.13907
PPO Batch Consumption Time: 0.09250
Total Iteration Time: 10.32091

Cumulative Model Updates: 17,106
Cumulative Timesteps: 285,597,138

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 285597138...
Checkpoint 285597138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,189.45207
Policy Entropy: 0.61166
Value Function Loss: 0.07384

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05483
Policy Update Magnitude: 0.02759
Value Function Update Magnitude: 0.03571

Collected Steps per Second: 5,622.83046
Overall Steps per Second: 4,987.07352

Timestep Collection Time: 8.89837
Timestep Consumption Time: 1.13437
PPO Batch Consumption Time: 0.08243
Total Iteration Time: 10.03274

Cumulative Model Updates: 17,109
Cumulative Timesteps: 285,647,172

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,377.74136
Policy Entropy: 0.60645
Value Function Loss: 0.07871

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03521
Policy Update Magnitude: 0.02762
Value Function Update Magnitude: 0.03371

Collected Steps per Second: 5,616.29065
Overall Steps per Second: 4,991.57100

Timestep Collection Time: 8.90517
Timestep Consumption Time: 1.11453
PPO Batch Consumption Time: 0.08415
Total Iteration Time: 10.01969

Cumulative Model Updates: 17,112
Cumulative Timesteps: 285,697,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 285697186...
Checkpoint 285697186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,394.78725
Policy Entropy: 0.60927
Value Function Loss: 0.07320

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.02683
Value Function Update Magnitude: 0.03437

Collected Steps per Second: 5,665.36843
Overall Steps per Second: 5,006.36765

Timestep Collection Time: 8.82943
Timestep Consumption Time: 1.16224
PPO Batch Consumption Time: 0.08309
Total Iteration Time: 9.99168

Cumulative Model Updates: 17,115
Cumulative Timesteps: 285,747,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,529.94138
Policy Entropy: 0.61186
Value Function Loss: 0.06382

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03671
Policy Update Magnitude: 0.02548
Value Function Update Magnitude: 0.03806

Collected Steps per Second: 5,793.98436
Overall Steps per Second: 5,106.02927

Timestep Collection Time: 8.63309
Timestep Consumption Time: 1.16317
PPO Batch Consumption Time: 0.08875
Total Iteration Time: 9.79626

Cumulative Model Updates: 17,118
Cumulative Timesteps: 285,797,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 285797228...
Checkpoint 285797228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,751.20767
Policy Entropy: 0.60636
Value Function Loss: 0.06827

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.03566
Policy Update Magnitude: 0.02518
Value Function Update Magnitude: 0.04506

Collected Steps per Second: 5,801.03903
Overall Steps per Second: 5,141.81348

Timestep Collection Time: 8.61915
Timestep Consumption Time: 1.10505
PPO Batch Consumption Time: 0.07898
Total Iteration Time: 9.72420

Cumulative Model Updates: 17,121
Cumulative Timesteps: 285,847,228

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,194.91684
Policy Entropy: 0.59761
Value Function Loss: 0.06711

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04529
Policy Update Magnitude: 0.02444
Value Function Update Magnitude: 0.03597

Collected Steps per Second: 5,676.30826
Overall Steps per Second: 5,017.15542

Timestep Collection Time: 8.81312
Timestep Consumption Time: 1.15787
PPO Batch Consumption Time: 0.08540
Total Iteration Time: 9.97099

Cumulative Model Updates: 17,124
Cumulative Timesteps: 285,897,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 285897254...
Checkpoint 285897254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,908.63865
Policy Entropy: 0.59583
Value Function Loss: 0.07172

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.04297
Policy Update Magnitude: 0.02278
Value Function Update Magnitude: 0.03716

Collected Steps per Second: 6,016.95454
Overall Steps per Second: 5,297.48752

Timestep Collection Time: 8.31085
Timestep Consumption Time: 1.12872
PPO Batch Consumption Time: 0.08490
Total Iteration Time: 9.43957

Cumulative Model Updates: 17,127
Cumulative Timesteps: 285,947,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,968.47740
Policy Entropy: 0.59338
Value Function Loss: 0.06501

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05255
Policy Update Magnitude: 0.02340
Value Function Update Magnitude: 0.03795

Collected Steps per Second: 5,633.25301
Overall Steps per Second: 4,990.82955

Timestep Collection Time: 8.87693
Timestep Consumption Time: 1.14265
PPO Batch Consumption Time: 0.08424
Total Iteration Time: 10.01958

Cumulative Model Updates: 17,130
Cumulative Timesteps: 285,997,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 285997266...
Checkpoint 285997266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,646.09306
Policy Entropy: 0.59909
Value Function Loss: 0.06343

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04831
Policy Update Magnitude: 0.02398
Value Function Update Magnitude: 0.03286

Collected Steps per Second: 5,592.05284
Overall Steps per Second: 4,944.34835

Timestep Collection Time: 8.94269
Timestep Consumption Time: 1.17148
PPO Batch Consumption Time: 0.08526
Total Iteration Time: 10.11417

Cumulative Model Updates: 17,133
Cumulative Timesteps: 286,047,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,673.18646
Policy Entropy: 0.60077
Value Function Loss: 0.05744

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.04382
Policy Update Magnitude: 0.02314
Value Function Update Magnitude: 0.03404

Collected Steps per Second: 5,727.97879
Overall Steps per Second: 5,068.13563

Timestep Collection Time: 8.73292
Timestep Consumption Time: 1.13698
PPO Batch Consumption Time: 0.08424
Total Iteration Time: 9.86990

Cumulative Model Updates: 17,136
Cumulative Timesteps: 286,097,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 286097296...
Checkpoint 286097296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,483.33439
Policy Entropy: 0.60372
Value Function Loss: 0.06665

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05721
Policy Update Magnitude: 0.02228
Value Function Update Magnitude: 0.03300

Collected Steps per Second: 5,709.64497
Overall Steps per Second: 5,044.86057

Timestep Collection Time: 8.76202
Timestep Consumption Time: 1.15461
PPO Batch Consumption Time: 0.08336
Total Iteration Time: 9.91663

Cumulative Model Updates: 17,139
Cumulative Timesteps: 286,147,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,545.08426
Policy Entropy: 0.60751
Value Function Loss: 0.06571

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.04830
Policy Update Magnitude: 0.02259
Value Function Update Magnitude: 0.02945

Collected Steps per Second: 5,777.33229
Overall Steps per Second: 5,117.84182

Timestep Collection Time: 8.65901
Timestep Consumption Time: 1.11581
PPO Batch Consumption Time: 0.08426
Total Iteration Time: 9.77482

Cumulative Model Updates: 17,142
Cumulative Timesteps: 286,197,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 286197350...
Checkpoint 286197350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,439.35667
Policy Entropy: 0.60880
Value Function Loss: 0.06673

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.05019
Policy Update Magnitude: 0.02638
Value Function Update Magnitude: 0.03624

Collected Steps per Second: 5,762.90951
Overall Steps per Second: 5,128.32898

Timestep Collection Time: 8.67756
Timestep Consumption Time: 1.07376
PPO Batch Consumption Time: 0.08659
Total Iteration Time: 9.75132

Cumulative Model Updates: 17,145
Cumulative Timesteps: 286,247,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,080.72884
Policy Entropy: 0.60755
Value Function Loss: 0.05849

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03467
Policy Update Magnitude: 0.02456
Value Function Update Magnitude: 0.03511

Collected Steps per Second: 5,430.71972
Overall Steps per Second: 4,856.00783

Timestep Collection Time: 9.21130
Timestep Consumption Time: 1.09016
PPO Batch Consumption Time: 0.08256
Total Iteration Time: 10.30147

Cumulative Model Updates: 17,148
Cumulative Timesteps: 286,297,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 286297382...
Checkpoint 286297382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,558.80346
Policy Entropy: 0.60430
Value Function Loss: 0.05664

Mean KL Divergence: 0.00191
SB3 Clip Fraction: 0.02176
Policy Update Magnitude: 0.02436
Value Function Update Magnitude: 0.03300

Collected Steps per Second: 5,928.53073
Overall Steps per Second: 5,291.26541

Timestep Collection Time: 8.43615
Timestep Consumption Time: 1.01603
PPO Batch Consumption Time: 0.08215
Total Iteration Time: 9.45218

Cumulative Model Updates: 17,151
Cumulative Timesteps: 286,347,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,098.32570
Policy Entropy: 0.60222
Value Function Loss: 0.05425

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03525
Policy Update Magnitude: 0.02352
Value Function Update Magnitude: 0.03285

Collected Steps per Second: 5,892.57637
Overall Steps per Second: 5,282.88644

Timestep Collection Time: 8.48627
Timestep Consumption Time: 0.97939
PPO Batch Consumption Time: 0.08333
Total Iteration Time: 9.46566

Cumulative Model Updates: 17,154
Cumulative Timesteps: 286,397,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 286397402...
Checkpoint 286397402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,612.15652
Policy Entropy: 0.59839
Value Function Loss: 0.06166

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02405
Policy Update Magnitude: 0.02590
Value Function Update Magnitude: 0.03086

Collected Steps per Second: 5,693.82316
Overall Steps per Second: 5,124.54688

Timestep Collection Time: 8.78636
Timestep Consumption Time: 0.97606
PPO Batch Consumption Time: 0.08317
Total Iteration Time: 9.76242

Cumulative Model Updates: 17,157
Cumulative Timesteps: 286,447,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,667.41805
Policy Entropy: 0.59517
Value Function Loss: 0.06162

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.01743
Policy Update Magnitude: 0.02544
Value Function Update Magnitude: 0.02936

Collected Steps per Second: 5,634.40575
Overall Steps per Second: 5,001.06931

Timestep Collection Time: 8.87583
Timestep Consumption Time: 1.12404
PPO Batch Consumption Time: 0.08426
Total Iteration Time: 9.99986

Cumulative Model Updates: 17,160
Cumulative Timesteps: 286,497,440

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 286497440...
Checkpoint 286497440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,600.15156
Policy Entropy: 0.60319
Value Function Loss: 0.06597

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02388
Policy Update Magnitude: 0.02755
Value Function Update Magnitude: 0.03336

Collected Steps per Second: 5,579.89778
Overall Steps per Second: 4,980.86021

Timestep Collection Time: 8.96396
Timestep Consumption Time: 1.07808
PPO Batch Consumption Time: 0.08553
Total Iteration Time: 10.04204

Cumulative Model Updates: 17,163
Cumulative Timesteps: 286,547,458

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,195.43030
Policy Entropy: 0.61097
Value Function Loss: 0.05846

Mean KL Divergence: 0.00193
SB3 Clip Fraction: 0.02182
Policy Update Magnitude: 0.03014
Value Function Update Magnitude: 0.03341

Collected Steps per Second: 5,540.19712
Overall Steps per Second: 4,967.36717

Timestep Collection Time: 9.03253
Timestep Consumption Time: 1.04162
PPO Batch Consumption Time: 0.08600
Total Iteration Time: 10.07415

Cumulative Model Updates: 17,166
Cumulative Timesteps: 286,597,500

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 286597500...
Checkpoint 286597500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,192.49036
Policy Entropy: 0.61381
Value Function Loss: 0.06209

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02711
Policy Update Magnitude: 0.02770
Value Function Update Magnitude: 0.03470

Collected Steps per Second: 5,407.91813
Overall Steps per Second: 4,848.20330

Timestep Collection Time: 9.25236
Timestep Consumption Time: 1.06817
PPO Batch Consumption Time: 0.08489
Total Iteration Time: 10.32052

Cumulative Model Updates: 17,169
Cumulative Timesteps: 286,647,536

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,485.27913
Policy Entropy: 0.61464
Value Function Loss: 0.06131

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01859
Policy Update Magnitude: 0.02780
Value Function Update Magnitude: 0.03735

Collected Steps per Second: 5,521.63142
Overall Steps per Second: 4,856.98789

Timestep Collection Time: 9.05674
Timestep Consumption Time: 1.23935
PPO Batch Consumption Time: 0.08878
Total Iteration Time: 10.29609

Cumulative Model Updates: 17,172
Cumulative Timesteps: 286,697,544

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 286697544...
Checkpoint 286697544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,615.77549
Policy Entropy: 0.61802
Value Function Loss: 0.06544

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02774
Policy Update Magnitude: 0.03139
Value Function Update Magnitude: 0.03659

Collected Steps per Second: 5,595.97922
Overall Steps per Second: 5,006.30586

Timestep Collection Time: 8.94178
Timestep Consumption Time: 1.05322
PPO Batch Consumption Time: 0.08201
Total Iteration Time: 9.99499

Cumulative Model Updates: 17,175
Cumulative Timesteps: 286,747,582

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,645.16878
Policy Entropy: 0.61584
Value Function Loss: 0.06095

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01785
Policy Update Magnitude: 0.03225
Value Function Update Magnitude: 0.03403

Collected Steps per Second: 5,544.62503
Overall Steps per Second: 4,934.13295

Timestep Collection Time: 9.02279
Timestep Consumption Time: 1.11638
PPO Batch Consumption Time: 0.08379
Total Iteration Time: 10.13917

Cumulative Model Updates: 17,178
Cumulative Timesteps: 286,797,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 286797610...
Checkpoint 286797610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,060.48046
Policy Entropy: 0.61174
Value Function Loss: 0.06169

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.02061
Policy Update Magnitude: 0.02828
Value Function Update Magnitude: 0.03813

Collected Steps per Second: 5,517.08178
Overall Steps per Second: 4,882.38641

Timestep Collection Time: 9.06421
Timestep Consumption Time: 1.17832
PPO Batch Consumption Time: 0.09035
Total Iteration Time: 10.24253

Cumulative Model Updates: 17,181
Cumulative Timesteps: 286,847,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,101.43653
Policy Entropy: 0.60612
Value Function Loss: 0.06281

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.03205
Value Function Update Magnitude: 0.04350

Collected Steps per Second: 5,609.38917
Overall Steps per Second: 4,974.81417

Timestep Collection Time: 8.91826
Timestep Consumption Time: 1.13759
PPO Batch Consumption Time: 0.08517
Total Iteration Time: 10.05585

Cumulative Model Updates: 17,184
Cumulative Timesteps: 286,897,644

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 286897644...
Checkpoint 286897644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,591.92632
Policy Entropy: 0.61031
Value Function Loss: 0.05932

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 0.02938
Value Function Update Magnitude: 0.04195

Collected Steps per Second: 5,562.23290
Overall Steps per Second: 4,962.22849

Timestep Collection Time: 8.99135
Timestep Consumption Time: 1.08718
PPO Batch Consumption Time: 0.08897
Total Iteration Time: 10.07854

Cumulative Model Updates: 17,187
Cumulative Timesteps: 286,947,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,488.36882
Policy Entropy: 0.62244
Value Function Loss: 0.05566

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03525
Policy Update Magnitude: 0.02615
Value Function Update Magnitude: 0.04664

Collected Steps per Second: 5,275.59143
Overall Steps per Second: 4,708.15762

Timestep Collection Time: 9.48140
Timestep Consumption Time: 1.14271
PPO Batch Consumption Time: 0.08443
Total Iteration Time: 10.62411

Cumulative Model Updates: 17,190
Cumulative Timesteps: 286,997,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 286997676...
Checkpoint 286997676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,828.60714
Policy Entropy: 0.62498
Value Function Loss: 0.05129

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.04485
Policy Update Magnitude: 0.02512
Value Function Update Magnitude: 0.04446

Collected Steps per Second: 5,504.21912
Overall Steps per Second: 4,900.26513

Timestep Collection Time: 9.09157
Timestep Consumption Time: 1.12053
PPO Batch Consumption Time: 0.08306
Total Iteration Time: 10.21210

Cumulative Model Updates: 17,193
Cumulative Timesteps: 287,047,718

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,313.09997
Policy Entropy: 0.62966
Value Function Loss: 0.04870

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03646
Policy Update Magnitude: 0.02807
Value Function Update Magnitude: 0.04412

Collected Steps per Second: 5,493.22227
Overall Steps per Second: 4,873.90092

Timestep Collection Time: 9.10649
Timestep Consumption Time: 1.15715
PPO Batch Consumption Time: 0.09179
Total Iteration Time: 10.26365

Cumulative Model Updates: 17,196
Cumulative Timesteps: 287,097,742

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 287097742...
Checkpoint 287097742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,168.51080
Policy Entropy: 0.62125
Value Function Loss: 0.06362

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03918
Policy Update Magnitude: 0.03018
Value Function Update Magnitude: 0.04163

Collected Steps per Second: 5,234.43517
Overall Steps per Second: 4,644.59309

Timestep Collection Time: 9.55213
Timestep Consumption Time: 1.21308
PPO Batch Consumption Time: 0.08294
Total Iteration Time: 10.76521

Cumulative Model Updates: 17,199
Cumulative Timesteps: 287,147,742

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,066.99156
Policy Entropy: 0.62230
Value Function Loss: 0.06516

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.02926
Value Function Update Magnitude: 0.04515

Collected Steps per Second: 5,284.18846
Overall Steps per Second: 4,675.52423

Timestep Collection Time: 9.46863
Timestep Consumption Time: 1.23263
PPO Batch Consumption Time: 0.08713
Total Iteration Time: 10.70126

Cumulative Model Updates: 17,202
Cumulative Timesteps: 287,197,776

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 287197776...
Checkpoint 287197776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,525.04870
Policy Entropy: 0.61880
Value Function Loss: 0.07152

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02926
Policy Update Magnitude: 0.03289
Value Function Update Magnitude: 0.04506

Collected Steps per Second: 5,514.88602
Overall Steps per Second: 4,885.21197

Timestep Collection Time: 9.07290
Timestep Consumption Time: 1.16944
PPO Batch Consumption Time: 0.09159
Total Iteration Time: 10.24234

Cumulative Model Updates: 17,205
Cumulative Timesteps: 287,247,812

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,690.40236
Policy Entropy: 0.61531
Value Function Loss: 0.07468

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.04051
Policy Update Magnitude: 0.03506
Value Function Update Magnitude: 0.04946

Collected Steps per Second: 5,569.65562
Overall Steps per Second: 4,939.95757

Timestep Collection Time: 8.98117
Timestep Consumption Time: 1.14483
PPO Batch Consumption Time: 0.08582
Total Iteration Time: 10.12600

Cumulative Model Updates: 17,208
Cumulative Timesteps: 287,297,834

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 287297834...
Checkpoint 287297834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,627.05253
Policy Entropy: 0.61062
Value Function Loss: 0.08221

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03596
Policy Update Magnitude: 0.03361
Value Function Update Magnitude: 0.04860

Collected Steps per Second: 5,445.30930
Overall Steps per Second: 4,832.20494

Timestep Collection Time: 9.18442
Timestep Consumption Time: 1.16531
PPO Batch Consumption Time: 0.08546
Total Iteration Time: 10.34973

Cumulative Model Updates: 17,211
Cumulative Timesteps: 287,347,846

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,656.46845
Policy Entropy: 0.60136
Value Function Loss: 0.08264

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.05252
Policy Update Magnitude: 0.03046
Value Function Update Magnitude: 0.05864

Collected Steps per Second: 5,355.17268
Overall Steps per Second: 4,785.81576

Timestep Collection Time: 9.34162
Timestep Consumption Time: 1.11135
PPO Batch Consumption Time: 0.09425
Total Iteration Time: 10.45297

Cumulative Model Updates: 17,214
Cumulative Timesteps: 287,397,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 287397872...
Checkpoint 287397872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,610.09075
Policy Entropy: 0.60313
Value Function Loss: 0.08012

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04668
Policy Update Magnitude: 0.02865
Value Function Update Magnitude: 0.06741

Collected Steps per Second: 5,592.87268
Overall Steps per Second: 4,984.87148

Timestep Collection Time: 8.94317
Timestep Consumption Time: 1.09079
PPO Batch Consumption Time: 0.08787
Total Iteration Time: 10.03396

Cumulative Model Updates: 17,217
Cumulative Timesteps: 287,447,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,374.53862
Policy Entropy: 0.60672
Value Function Loss: 0.07637

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.03915
Policy Update Magnitude: 0.02743
Value Function Update Magnitude: 0.06581

Collected Steps per Second: 5,487.42695
Overall Steps per Second: 4,942.45163

Timestep Collection Time: 9.11429
Timestep Consumption Time: 1.00498
PPO Batch Consumption Time: 0.08544
Total Iteration Time: 10.11927

Cumulative Model Updates: 17,220
Cumulative Timesteps: 287,497,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 287497904...
Checkpoint 287497904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,624.41950
Policy Entropy: 0.61005
Value Function Loss: 0.07904

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.04324
Policy Update Magnitude: 0.02742
Value Function Update Magnitude: 0.07306

Collected Steps per Second: 5,614.43999
Overall Steps per Second: 5,033.54894

Timestep Collection Time: 8.90846
Timestep Consumption Time: 1.02807
PPO Batch Consumption Time: 0.07965
Total Iteration Time: 9.93653

Cumulative Model Updates: 17,223
Cumulative Timesteps: 287,547,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,676.87140
Policy Entropy: 0.60971
Value Function Loss: 0.07235

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.03462
Value Function Update Magnitude: 0.06542

Collected Steps per Second: 5,595.29542
Overall Steps per Second: 4,978.44535

Timestep Collection Time: 8.93894
Timestep Consumption Time: 1.10757
PPO Batch Consumption Time: 0.08664
Total Iteration Time: 10.04651

Cumulative Model Updates: 17,226
Cumulative Timesteps: 287,597,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 287597936...
Checkpoint 287597936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,695.66325
Policy Entropy: 0.61539
Value Function Loss: 0.06467

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.04564
Policy Update Magnitude: 0.03183
Value Function Update Magnitude: 0.06390

Collected Steps per Second: 6,068.40903
Overall Steps per Second: 5,571.93843

Timestep Collection Time: 8.24434
Timestep Consumption Time: 0.73459
PPO Batch Consumption Time: 0.03698
Total Iteration Time: 8.97892

Cumulative Model Updates: 17,229
Cumulative Timesteps: 287,647,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,014.80658
Policy Entropy: 0.61059
Value Function Loss: 0.06655

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.02915
Value Function Update Magnitude: 0.05235

Collected Steps per Second: 16,287.89819
Overall Steps per Second: 12,634.85921

Timestep Collection Time: 3.07087
Timestep Consumption Time: 0.88786
PPO Batch Consumption Time: 0.06069
Total Iteration Time: 3.95873

Cumulative Model Updates: 17,232
Cumulative Timesteps: 287,697,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 287697984...
Checkpoint 287697984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,012.77336
Policy Entropy: 0.62200
Value Function Loss: 0.05410

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03493
Policy Update Magnitude: 0.02708
Value Function Update Magnitude: 0.04676

Collected Steps per Second: 16,362.85113
Overall Steps per Second: 12,881.54440

Timestep Collection Time: 3.05619
Timestep Consumption Time: 0.82595
PPO Batch Consumption Time: 0.04983
Total Iteration Time: 3.88214

Cumulative Model Updates: 17,235
Cumulative Timesteps: 287,747,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,527.38642
Policy Entropy: 0.61606
Value Function Loss: 0.05716

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04547
Policy Update Magnitude: 0.02405
Value Function Update Magnitude: 0.05286

Collected Steps per Second: 16,524.75137
Overall Steps per Second: 13,034.93552

Timestep Collection Time: 3.02722
Timestep Consumption Time: 0.81047
PPO Batch Consumption Time: 0.05201
Total Iteration Time: 3.83769

Cumulative Model Updates: 17,238
Cumulative Timesteps: 287,798,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 287798016...
Checkpoint 287798016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,048.60814
Policy Entropy: 0.62167
Value Function Loss: 0.05655

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.03882
Policy Update Magnitude: 0.02309
Value Function Update Magnitude: 0.04879

Collected Steps per Second: 17,067.40872
Overall Steps per Second: 13,085.42350

Timestep Collection Time: 2.93038
Timestep Consumption Time: 0.89174
PPO Batch Consumption Time: 0.06345
Total Iteration Time: 3.82212

Cumulative Model Updates: 17,241
Cumulative Timesteps: 287,848,030

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,668.47519
Policy Entropy: 0.60976
Value Function Loss: 0.06446

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03068
Policy Update Magnitude: 0.02547
Value Function Update Magnitude: 0.04796

Collected Steps per Second: 16,562.11213
Overall Steps per Second: 12,983.54423

Timestep Collection Time: 3.02015
Timestep Consumption Time: 0.83242
PPO Batch Consumption Time: 0.04202
Total Iteration Time: 3.85257

Cumulative Model Updates: 17,244
Cumulative Timesteps: 287,898,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 287898050...
Checkpoint 287898050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,235.60453
Policy Entropy: 0.61158
Value Function Loss: 0.07023

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.05027
Policy Update Magnitude: 0.02681
Value Function Update Magnitude: 0.05583

Collected Steps per Second: 16,769.60352
Overall Steps per Second: 13,023.97876

Timestep Collection Time: 2.98159
Timestep Consumption Time: 0.85749
PPO Batch Consumption Time: 0.04803
Total Iteration Time: 3.83907

Cumulative Model Updates: 17,247
Cumulative Timesteps: 287,948,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,845.72318
Policy Entropy: 0.60705
Value Function Loss: 0.07615

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03400
Policy Update Magnitude: 0.02824
Value Function Update Magnitude: 0.06531

Collected Steps per Second: 16,976.51805
Overall Steps per Second: 13,147.89798

Timestep Collection Time: 2.94630
Timestep Consumption Time: 0.85795
PPO Batch Consumption Time: 0.04753
Total Iteration Time: 3.80426

Cumulative Model Updates: 17,250
Cumulative Timesteps: 287,998,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 287998068...
Checkpoint 287998068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,482.32873
Policy Entropy: 0.60566
Value Function Loss: 0.08407

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03312
Policy Update Magnitude: 0.03450
Value Function Update Magnitude: 0.06744

Collected Steps per Second: 16,751.91126
Overall Steps per Second: 13,088.96413

Timestep Collection Time: 2.98533
Timestep Consumption Time: 0.83545
PPO Batch Consumption Time: 0.05762
Total Iteration Time: 3.82078

Cumulative Model Updates: 17,253
Cumulative Timesteps: 288,048,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,746.22206
Policy Entropy: 0.60753
Value Function Loss: 0.07318

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03741
Policy Update Magnitude: 0.03258
Value Function Update Magnitude: 0.07076

Collected Steps per Second: 16,903.00644
Overall Steps per Second: 12,997.58938

Timestep Collection Time: 2.95936
Timestep Consumption Time: 0.88920
PPO Batch Consumption Time: 0.06366
Total Iteration Time: 3.84856

Cumulative Model Updates: 17,256
Cumulative Timesteps: 288,098,100

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 288098100...
Checkpoint 288098100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,419.07301
Policy Entropy: 0.62065
Value Function Loss: 0.06507

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.03105
Value Function Update Magnitude: 0.06329

Collected Steps per Second: 15,851.35668
Overall Steps per Second: 12,445.28746

Timestep Collection Time: 3.15493
Timestep Consumption Time: 0.86345
PPO Batch Consumption Time: 0.05308
Total Iteration Time: 4.01839

Cumulative Model Updates: 17,259
Cumulative Timesteps: 288,148,110

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,835.56484
Policy Entropy: 0.63516
Value Function Loss: 0.05652

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.04676
Policy Update Magnitude: 0.02686
Value Function Update Magnitude: 0.05790

Collected Steps per Second: 17,354.85220
Overall Steps per Second: 13,219.53829

Timestep Collection Time: 2.88311
Timestep Consumption Time: 0.90189
PPO Batch Consumption Time: 0.06937
Total Iteration Time: 3.78500

Cumulative Model Updates: 17,262
Cumulative Timesteps: 288,198,146

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 288198146...
Checkpoint 288198146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,955.14358
Policy Entropy: 0.63049
Value Function Loss: 0.06138

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 0.02333
Value Function Update Magnitude: 0.04745

Collected Steps per Second: 16,687.14431
Overall Steps per Second: 13,103.00294

Timestep Collection Time: 2.99644
Timestep Consumption Time: 0.81963
PPO Batch Consumption Time: 0.04205
Total Iteration Time: 3.81607

Cumulative Model Updates: 17,265
Cumulative Timesteps: 288,248,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,812.80749
Policy Entropy: 0.61662
Value Function Loss: 0.07489

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.02592
Value Function Update Magnitude: 0.05250

Collected Steps per Second: 16,907.04119
Overall Steps per Second: 12,977.72081

Timestep Collection Time: 2.95806
Timestep Consumption Time: 0.89562
PPO Batch Consumption Time: 0.05854
Total Iteration Time: 3.85368

Cumulative Model Updates: 17,268
Cumulative Timesteps: 288,298,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 288298160...
Checkpoint 288298160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,163.36833
Policy Entropy: 0.60861
Value Function Loss: 0.08249

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.02974
Policy Update Magnitude: 0.02893
Value Function Update Magnitude: 0.05179

Collected Steps per Second: 17,021.22331
Overall Steps per Second: 12,982.81852

Timestep Collection Time: 2.93857
Timestep Consumption Time: 0.91406
PPO Batch Consumption Time: 0.06844
Total Iteration Time: 3.85263

Cumulative Model Updates: 17,271
Cumulative Timesteps: 288,348,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,565.24413
Policy Entropy: 0.61230
Value Function Loss: 0.08228

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03175
Policy Update Magnitude: 0.02898
Value Function Update Magnitude: 0.05193

Collected Steps per Second: 16,452.86408
Overall Steps per Second: 12,655.42736

Timestep Collection Time: 3.04008
Timestep Consumption Time: 0.91222
PPO Batch Consumption Time: 0.06118
Total Iteration Time: 3.95230

Cumulative Model Updates: 17,274
Cumulative Timesteps: 288,398,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 288398196...
Checkpoint 288398196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,871.72940
Policy Entropy: 0.61484
Value Function Loss: 0.07193

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03017
Policy Update Magnitude: 0.02941
Value Function Update Magnitude: 0.05503

Collected Steps per Second: 16,519.61050
Overall Steps per Second: 12,702.25493

Timestep Collection Time: 3.02840
Timestep Consumption Time: 0.91011
PPO Batch Consumption Time: 0.06451
Total Iteration Time: 3.93851

Cumulative Model Updates: 17,277
Cumulative Timesteps: 288,448,224

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,322.50468
Policy Entropy: 0.61523
Value Function Loss: 0.07278

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04864
Policy Update Magnitude: 0.03097
Value Function Update Magnitude: 0.05162

Collected Steps per Second: 16,748.96183
Overall Steps per Second: 13,111.11254

Timestep Collection Time: 2.98693
Timestep Consumption Time: 0.82876
PPO Batch Consumption Time: 0.05082
Total Iteration Time: 3.81569

Cumulative Model Updates: 17,280
Cumulative Timesteps: 288,498,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 288498252...
Checkpoint 288498252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,721.77769
Policy Entropy: 0.60628
Value Function Loss: 0.07851

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.04731
Policy Update Magnitude: 0.03001
Value Function Update Magnitude: 0.06070

Collected Steps per Second: 17,126.07256
Overall Steps per Second: 13,472.45930

Timestep Collection Time: 2.91999
Timestep Consumption Time: 0.79188
PPO Batch Consumption Time: 0.04009
Total Iteration Time: 3.71187

Cumulative Model Updates: 17,283
Cumulative Timesteps: 288,548,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,038.65095
Policy Entropy: 0.60713
Value Function Loss: 0.07443

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.05657
Policy Update Magnitude: 0.02833
Value Function Update Magnitude: 0.05605

Collected Steps per Second: 10,959.85483
Overall Steps per Second: 9,288.57720

Timestep Collection Time: 4.56466
Timestep Consumption Time: 0.82131
PPO Batch Consumption Time: 0.05034
Total Iteration Time: 5.38597

Cumulative Model Updates: 17,286
Cumulative Timesteps: 288,598,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 288598288...
Checkpoint 288598288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,576.75605
Policy Entropy: 0.61062
Value Function Loss: 0.07005

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.04239
Policy Update Magnitude: 0.02589
Value Function Update Magnitude: 0.05606

Collected Steps per Second: 17,237.68450
Overall Steps per Second: 13,309.44944

Timestep Collection Time: 2.90062
Timestep Consumption Time: 0.85611
PPO Batch Consumption Time: 0.04748
Total Iteration Time: 3.75673

Cumulative Model Updates: 17,289
Cumulative Timesteps: 288,648,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,209.88063
Policy Entropy: 0.62494
Value Function Loss: 0.05913

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03783
Policy Update Magnitude: 0.02464
Value Function Update Magnitude: 0.06030

Collected Steps per Second: 16,947.86512
Overall Steps per Second: 13,199.92257

Timestep Collection Time: 2.95164
Timestep Consumption Time: 0.83808
PPO Batch Consumption Time: 0.05091
Total Iteration Time: 3.78972

Cumulative Model Updates: 17,292
Cumulative Timesteps: 288,698,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 288698312...
Checkpoint 288698312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,199.84762
Policy Entropy: 0.61874
Value Function Loss: 0.06452

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.03990
Policy Update Magnitude: 0.02673
Value Function Update Magnitude: 0.06738

Collected Steps per Second: 16,566.77435
Overall Steps per Second: 13,045.13442

Timestep Collection Time: 3.02099
Timestep Consumption Time: 0.81554
PPO Batch Consumption Time: 0.04343
Total Iteration Time: 3.83653

Cumulative Model Updates: 17,295
Cumulative Timesteps: 288,748,360

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,934.56648
Policy Entropy: 0.62215
Value Function Loss: 0.06745

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.02737
Value Function Update Magnitude: 0.07011

Collected Steps per Second: 18,369.44677
Overall Steps per Second: 14,201.42068

Timestep Collection Time: 2.72256
Timestep Consumption Time: 0.79906
PPO Batch Consumption Time: 0.03990
Total Iteration Time: 3.52162

Cumulative Model Updates: 17,298
Cumulative Timesteps: 288,798,372

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 288798372...
Checkpoint 288798372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,893.12026
Policy Entropy: 0.61198
Value Function Loss: 0.06910

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04543
Policy Update Magnitude: 0.02925
Value Function Update Magnitude: 0.07722

Collected Steps per Second: 18,977.50937
Overall Steps per Second: 13,850.35491

Timestep Collection Time: 2.63544
Timestep Consumption Time: 0.97559
PPO Batch Consumption Time: 0.03921
Total Iteration Time: 3.61103

Cumulative Model Updates: 17,301
Cumulative Timesteps: 288,848,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,069.73770
Policy Entropy: 0.62162
Value Function Loss: 0.06385

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.06061
Policy Update Magnitude: 0.02885
Value Function Update Magnitude: 0.07813

Collected Steps per Second: 13,699.03931
Overall Steps per Second: 11,009.37456

Timestep Collection Time: 3.65252
Timestep Consumption Time: 0.89234
PPO Batch Consumption Time: 0.05468
Total Iteration Time: 4.54485

Cumulative Model Updates: 17,304
Cumulative Timesteps: 288,898,422

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 288898422...
Checkpoint 288898422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,868.02500
Policy Entropy: 0.61738
Value Function Loss: 0.05301

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.04084
Policy Update Magnitude: 0.02474
Value Function Update Magnitude: 0.07000

Collected Steps per Second: 15,055.92987
Overall Steps per Second: 11,908.86424

Timestep Collection Time: 3.32254
Timestep Consumption Time: 0.87802
PPO Batch Consumption Time: 0.05196
Total Iteration Time: 4.20057

Cumulative Model Updates: 17,307
Cumulative Timesteps: 288,948,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,932.38044
Policy Entropy: 0.61795
Value Function Loss: 0.05807

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02791
Policy Update Magnitude: 0.02327
Value Function Update Magnitude: 0.05903

Collected Steps per Second: 16,175.35058
Overall Steps per Second: 12,535.31983

Timestep Collection Time: 3.09137
Timestep Consumption Time: 0.89768
PPO Batch Consumption Time: 0.06079
Total Iteration Time: 3.98905

Cumulative Model Updates: 17,310
Cumulative Timesteps: 288,998,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 288998450...
Checkpoint 288998450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,509.53860
Policy Entropy: 0.61619
Value Function Loss: 0.06424

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03075
Policy Update Magnitude: 0.02319
Value Function Update Magnitude: 0.05286

Collected Steps per Second: 8,678.04881
Overall Steps per Second: 7,094.31289

Timestep Collection Time: 5.76604
Timestep Consumption Time: 1.28721
PPO Batch Consumption Time: 0.08459
Total Iteration Time: 7.05326

Cumulative Model Updates: 17,313
Cumulative Timesteps: 289,048,488

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,629.27375
Policy Entropy: 0.62160
Value Function Loss: 0.06888

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03742
Policy Update Magnitude: 0.02506
Value Function Update Magnitude: 0.05465

Collected Steps per Second: 5,562.52094
Overall Steps per Second: 4,856.91242

Timestep Collection Time: 8.99233
Timestep Consumption Time: 1.30640
PPO Batch Consumption Time: 0.09544
Total Iteration Time: 10.29872

Cumulative Model Updates: 17,316
Cumulative Timesteps: 289,098,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 289098508...
Checkpoint 289098508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,921.25276
Policy Entropy: 0.61409
Value Function Loss: 0.06983

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.04215
Policy Update Magnitude: 0.03108
Value Function Update Magnitude: 0.05961

Collected Steps per Second: 5,326.54900
Overall Steps per Second: 4,744.44285

Timestep Collection Time: 9.39332
Timestep Consumption Time: 1.15249
PPO Batch Consumption Time: 0.09495
Total Iteration Time: 10.54581

Cumulative Model Updates: 17,319
Cumulative Timesteps: 289,148,542

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,122.26944
Policy Entropy: 0.60668
Value Function Loss: 0.07104

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.03686
Policy Update Magnitude: 0.02969
Value Function Update Magnitude: 0.05633

Collected Steps per Second: 5,373.74737
Overall Steps per Second: 4,859.01570

Timestep Collection Time: 9.30933
Timestep Consumption Time: 0.98617
PPO Batch Consumption Time: 0.08526
Total Iteration Time: 10.29550

Cumulative Model Updates: 17,322
Cumulative Timesteps: 289,198,568

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 289198568...
Checkpoint 289198568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,472.42563
Policy Entropy: 0.59841
Value Function Loss: 0.07102

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.03059
Policy Update Magnitude: 0.02963
Value Function Update Magnitude: 0.06579

Collected Steps per Second: 5,327.82272
Overall Steps per Second: 4,822.92084

Timestep Collection Time: 9.38920
Timestep Consumption Time: 0.98294
PPO Batch Consumption Time: 0.08841
Total Iteration Time: 10.37214

Cumulative Model Updates: 17,325
Cumulative Timesteps: 289,248,592

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,066.09978
Policy Entropy: 0.60759
Value Function Loss: 0.06506

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.02845
Value Function Update Magnitude: 0.06034

Collected Steps per Second: 5,337.07940
Overall Steps per Second: 4,827.07342

Timestep Collection Time: 9.37217
Timestep Consumption Time: 0.99022
PPO Batch Consumption Time: 0.08863
Total Iteration Time: 10.36239

Cumulative Model Updates: 17,328
Cumulative Timesteps: 289,298,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 289298612...
Checkpoint 289298612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,380.79864
Policy Entropy: 0.60913
Value Function Loss: 0.06242

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.02626
Value Function Update Magnitude: 0.05906

Collected Steps per Second: 5,777.59707
Overall Steps per Second: 5,151.18434

Timestep Collection Time: 8.65827
Timestep Consumption Time: 1.05289
PPO Batch Consumption Time: 0.08381
Total Iteration Time: 9.71116

Cumulative Model Updates: 17,331
Cumulative Timesteps: 289,348,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,219.60158
Policy Entropy: 0.61749
Value Function Loss: 0.05686

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.02584
Value Function Update Magnitude: 0.05955

Collected Steps per Second: 5,463.88355
Overall Steps per Second: 4,860.71317

Timestep Collection Time: 9.15649
Timestep Consumption Time: 1.13624
PPO Batch Consumption Time: 0.08586
Total Iteration Time: 10.29273

Cumulative Model Updates: 17,334
Cumulative Timesteps: 289,398,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 289398666...
Checkpoint 289398666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,740.49708
Policy Entropy: 0.61153
Value Function Loss: 0.06005

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03522
Policy Update Magnitude: 0.02436
Value Function Update Magnitude: 0.05879

Collected Steps per Second: 5,758.72039
Overall Steps per Second: 5,123.77516

Timestep Collection Time: 8.68387
Timestep Consumption Time: 1.07612
PPO Batch Consumption Time: 0.08211
Total Iteration Time: 9.75999

Cumulative Model Updates: 17,337
Cumulative Timesteps: 289,448,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,269.26786
Policy Entropy: 0.61892
Value Function Loss: 0.05629

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03159
Policy Update Magnitude: 0.02433
Value Function Update Magnitude: 0.05042

Collected Steps per Second: 5,634.58519
Overall Steps per Second: 4,972.00420

Timestep Collection Time: 8.87732
Timestep Consumption Time: 1.18301
PPO Batch Consumption Time: 0.08021
Total Iteration Time: 10.06033

Cumulative Model Updates: 17,340
Cumulative Timesteps: 289,498,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 289498694...
Checkpoint 289498694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,262.48852
Policy Entropy: 0.61459
Value Function Loss: 0.06346

Mean KL Divergence: 0.00205
SB3 Clip Fraction: 0.02303
Policy Update Magnitude: 0.02468
Value Function Update Magnitude: 0.04685

Collected Steps per Second: 5,729.08341
Overall Steps per Second: 5,089.34232

Timestep Collection Time: 8.73264
Timestep Consumption Time: 1.09771
PPO Batch Consumption Time: 0.08011
Total Iteration Time: 9.83035

Cumulative Model Updates: 17,343
Cumulative Timesteps: 289,548,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,775.00505
Policy Entropy: 0.61474
Value Function Loss: 0.06084

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.02496
Value Function Update Magnitude: 0.03941

Collected Steps per Second: 5,614.58676
Overall Steps per Second: 4,950.54283

Timestep Collection Time: 8.90787
Timestep Consumption Time: 1.19486
PPO Batch Consumption Time: 0.08385
Total Iteration Time: 10.10273

Cumulative Model Updates: 17,346
Cumulative Timesteps: 289,598,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 289598738...
Checkpoint 289598738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,158.90439
Policy Entropy: 0.61247
Value Function Loss: 0.06206

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.02485
Value Function Update Magnitude: 0.03746

Collected Steps per Second: 5,522.33141
Overall Steps per Second: 4,883.19575

Timestep Collection Time: 9.05777
Timestep Consumption Time: 1.18552
PPO Batch Consumption Time: 0.08734
Total Iteration Time: 10.24329

Cumulative Model Updates: 17,349
Cumulative Timesteps: 289,648,758

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,999.36804
Policy Entropy: 0.60722
Value Function Loss: 0.06542

Mean KL Divergence: 0.00237
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.02387
Value Function Update Magnitude: 0.03295

Collected Steps per Second: 5,656.81529
Overall Steps per Second: 5,023.47744

Timestep Collection Time: 8.83925
Timestep Consumption Time: 1.11441
PPO Batch Consumption Time: 0.08675
Total Iteration Time: 9.95366

Cumulative Model Updates: 17,352
Cumulative Timesteps: 289,698,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 289698760...
Checkpoint 289698760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,504.94730
Policy Entropy: 0.60308
Value Function Loss: 0.07230

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02881
Policy Update Magnitude: 0.02482
Value Function Update Magnitude: 0.03284

Collected Steps per Second: 5,790.41691
Overall Steps per Second: 5,145.89179

Timestep Collection Time: 8.63841
Timestep Consumption Time: 1.08196
PPO Batch Consumption Time: 0.08680
Total Iteration Time: 9.72038

Cumulative Model Updates: 17,355
Cumulative Timesteps: 289,748,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,015.84387
Policy Entropy: 0.60175
Value Function Loss: 0.07200

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03066
Policy Update Magnitude: 0.02602
Value Function Update Magnitude: 0.03204

Collected Steps per Second: 5,614.58963
Overall Steps per Second: 4,968.24061

Timestep Collection Time: 8.90893
Timestep Consumption Time: 1.15902
PPO Batch Consumption Time: 0.08310
Total Iteration Time: 10.06795

Cumulative Model Updates: 17,358
Cumulative Timesteps: 289,798,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 289798800...
Checkpoint 289798800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,635.63149
Policy Entropy: 0.61229
Value Function Loss: 0.06809

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.04376
Policy Update Magnitude: 0.02616
Value Function Update Magnitude: 0.03336

Collected Steps per Second: 5,529.56770
Overall Steps per Second: 4,930.55307

Timestep Collection Time: 9.04664
Timestep Consumption Time: 1.09908
PPO Batch Consumption Time: 0.08254
Total Iteration Time: 10.14572

Cumulative Model Updates: 17,361
Cumulative Timesteps: 289,848,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,935.44902
Policy Entropy: 0.63426
Value Function Loss: 0.05064

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.03361
Policy Update Magnitude: 0.02447
Value Function Update Magnitude: 0.03195

Collected Steps per Second: 5,722.45693
Overall Steps per Second: 5,059.42339

Timestep Collection Time: 8.74100
Timestep Consumption Time: 1.14550
PPO Batch Consumption Time: 0.08610
Total Iteration Time: 9.88650

Cumulative Model Updates: 17,364
Cumulative Timesteps: 289,898,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 289898844...
Checkpoint 289898844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,974.43831
Policy Entropy: 0.62925
Value Function Loss: 0.05800

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.04109
Policy Update Magnitude: 0.02281
Value Function Update Magnitude: 0.03124

Collected Steps per Second: 5,592.39068
Overall Steps per Second: 4,983.32780

Timestep Collection Time: 8.94394
Timestep Consumption Time: 1.09313
PPO Batch Consumption Time: 0.07989
Total Iteration Time: 10.03707

Cumulative Model Updates: 17,367
Cumulative Timesteps: 289,948,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,445.15753
Policy Entropy: 0.62162
Value Function Loss: 0.06469

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.01379
Policy Update Magnitude: 0.02219
Value Function Update Magnitude: 0.03586

Collected Steps per Second: 5,683.39420
Overall Steps per Second: 5,054.70650

Timestep Collection Time: 8.80565
Timestep Consumption Time: 1.09522
PPO Batch Consumption Time: 0.08183
Total Iteration Time: 9.90087

Cumulative Model Updates: 17,370
Cumulative Timesteps: 289,998,908

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 289998908...
Checkpoint 289998908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,884.54485
Policy Entropy: 0.61180
Value Function Loss: 0.06870

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.02251
Value Function Update Magnitude: 0.03732

Collected Steps per Second: 5,556.23944
Overall Steps per Second: 4,941.81200

Timestep Collection Time: 8.99925
Timestep Consumption Time: 1.11890
PPO Batch Consumption Time: 0.08221
Total Iteration Time: 10.11815

Cumulative Model Updates: 17,373
Cumulative Timesteps: 290,048,910

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,382.30457
Policy Entropy: 0.62033
Value Function Loss: 0.06026

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.05137
Policy Update Magnitude: 0.02158
Value Function Update Magnitude: 0.03107

Collected Steps per Second: 5,702.38341
Overall Steps per Second: 5,045.45485

Timestep Collection Time: 8.76896
Timestep Consumption Time: 1.14174
PPO Batch Consumption Time: 0.08339
Total Iteration Time: 9.91070

Cumulative Model Updates: 17,376
Cumulative Timesteps: 290,098,914

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 290098914...
Checkpoint 290098914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,329.99127
Policy Entropy: 0.61973
Value Function Loss: 0.06310

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 0.02212
Value Function Update Magnitude: 0.03409

Collected Steps per Second: 5,720.95117
Overall Steps per Second: 5,042.97436

Timestep Collection Time: 8.74016
Timestep Consumption Time: 1.17503
PPO Batch Consumption Time: 0.08299
Total Iteration Time: 9.91518

Cumulative Model Updates: 17,379
Cumulative Timesteps: 290,148,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,314.52267
Policy Entropy: 0.62025
Value Function Loss: 0.06680

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.03917
Policy Update Magnitude: 0.02261
Value Function Update Magnitude: 0.03202

Collected Steps per Second: 5,733.47083
Overall Steps per Second: 5,061.55814

Timestep Collection Time: 8.72316
Timestep Consumption Time: 1.15798
PPO Batch Consumption Time: 0.09543
Total Iteration Time: 9.88115

Cumulative Model Updates: 17,382
Cumulative Timesteps: 290,198,930

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 290198930...
Checkpoint 290198930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,918.19597
Policy Entropy: 0.61509
Value Function Loss: 0.07136

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.03201
Policy Update Magnitude: 0.02438
Value Function Update Magnitude: 0.03414

Collected Steps per Second: 5,699.81455
Overall Steps per Second: 5,043.70663

Timestep Collection Time: 8.77292
Timestep Consumption Time: 1.14122
PPO Batch Consumption Time: 0.08524
Total Iteration Time: 9.91414

Cumulative Model Updates: 17,385
Cumulative Timesteps: 290,248,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,387.48427
Policy Entropy: 0.62460
Value Function Loss: 0.05974

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.05019
Policy Update Magnitude: 0.02289
Value Function Update Magnitude: 0.03247

Collected Steps per Second: 5,767.04395
Overall Steps per Second: 5,103.34201

Timestep Collection Time: 8.67030
Timestep Consumption Time: 1.12759
PPO Batch Consumption Time: 0.08408
Total Iteration Time: 9.79789

Cumulative Model Updates: 17,388
Cumulative Timesteps: 290,298,936

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 290298936...
Checkpoint 290298936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,748.37146
Policy Entropy: 0.62255
Value Function Loss: 0.05935

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03217
Policy Update Magnitude: 0.02154
Value Function Update Magnitude: 0.03257

Collected Steps per Second: 5,670.98768
Overall Steps per Second: 5,028.89666

Timestep Collection Time: 8.82598
Timestep Consumption Time: 1.12690
PPO Batch Consumption Time: 0.08720
Total Iteration Time: 9.95288

Cumulative Model Updates: 17,391
Cumulative Timesteps: 290,348,988

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,274.05959
Policy Entropy: 0.62083
Value Function Loss: 0.05741

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03556
Policy Update Magnitude: 0.02080
Value Function Update Magnitude: 0.03046

Collected Steps per Second: 5,541.16206
Overall Steps per Second: 4,935.59899

Timestep Collection Time: 9.02410
Timestep Consumption Time: 1.10719
PPO Batch Consumption Time: 0.08358
Total Iteration Time: 10.13129

Cumulative Model Updates: 17,394
Cumulative Timesteps: 290,398,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 290398992...
Checkpoint 290398992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,929.85848
Policy Entropy: 0.61465
Value Function Loss: 0.06060

Mean KL Divergence: 0.00233
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.02245
Value Function Update Magnitude: 0.02799

Collected Steps per Second: 5,821.36379
Overall Steps per Second: 5,155.78243

Timestep Collection Time: 8.59386
Timestep Consumption Time: 1.10942
PPO Batch Consumption Time: 0.08403
Total Iteration Time: 9.70328

Cumulative Model Updates: 17,397
Cumulative Timesteps: 290,449,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,906.29595
Policy Entropy: 0.60839
Value Function Loss: 0.06491

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02771
Policy Update Magnitude: 0.02402
Value Function Update Magnitude: 0.03284

Collected Steps per Second: 5,670.88077
Overall Steps per Second: 5,000.06332

Timestep Collection Time: 8.82085
Timestep Consumption Time: 1.18342
PPO Batch Consumption Time: 0.08518
Total Iteration Time: 10.00427

Cumulative Model Updates: 17,400
Cumulative Timesteps: 290,499,042

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 290499042...
Checkpoint 290499042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,488.35581
Policy Entropy: 0.61345
Value Function Loss: 0.06538

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02009
Policy Update Magnitude: 0.02454
Value Function Update Magnitude: 0.03442

Collected Steps per Second: 5,636.83087
Overall Steps per Second: 5,021.51272

Timestep Collection Time: 8.87272
Timestep Consumption Time: 1.08723
PPO Batch Consumption Time: 0.07943
Total Iteration Time: 9.95995

Cumulative Model Updates: 17,403
Cumulative Timesteps: 290,549,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,583.57140
Policy Entropy: 0.60769
Value Function Loss: 0.07122

Mean KL Divergence: 0.00195
SB3 Clip Fraction: 0.02166
Policy Update Magnitude: 0.02710
Value Function Update Magnitude: 0.03645

Collected Steps per Second: 5,757.33443
Overall Steps per Second: 5,081.24240

Timestep Collection Time: 8.69152
Timestep Consumption Time: 1.15646
PPO Batch Consumption Time: 0.08284
Total Iteration Time: 9.84799

Cumulative Model Updates: 17,406
Cumulative Timesteps: 290,599,096

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 290599096...
Checkpoint 290599096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,518.11636
Policy Entropy: 0.61328
Value Function Loss: 0.07136

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 0.02581
Value Function Update Magnitude: 0.03583

Collected Steps per Second: 5,669.84032
Overall Steps per Second: 5,005.26374

Timestep Collection Time: 8.82177
Timestep Consumption Time: 1.17131
PPO Batch Consumption Time: 0.08011
Total Iteration Time: 9.99308

Cumulative Model Updates: 17,409
Cumulative Timesteps: 290,649,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,167.32790
Policy Entropy: 0.61237
Value Function Loss: 0.07209

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02099
Policy Update Magnitude: 0.02476
Value Function Update Magnitude: 0.03593

Collected Steps per Second: 5,468.32618
Overall Steps per Second: 4,863.70430

Timestep Collection Time: 9.14649
Timestep Consumption Time: 1.13703
PPO Batch Consumption Time: 0.08346
Total Iteration Time: 10.28352

Cumulative Model Updates: 17,412
Cumulative Timesteps: 290,699,130

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 290699130...
Checkpoint 290699130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,796.55756
Policy Entropy: 0.61486
Value Function Loss: 0.06770

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.02479
Value Function Update Magnitude: 0.03223

Collected Steps per Second: 5,445.70101
Overall Steps per Second: 4,848.99847

Timestep Collection Time: 9.18633
Timestep Consumption Time: 1.13044
PPO Batch Consumption Time: 0.08062
Total Iteration Time: 10.31677

Cumulative Model Updates: 17,415
Cumulative Timesteps: 290,749,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,527.35246
Policy Entropy: 0.61226
Value Function Loss: 0.06156

Mean KL Divergence: 0.00151
SB3 Clip Fraction: 0.01445
Policy Update Magnitude: 0.02409
Value Function Update Magnitude: 0.03055

Collected Steps per Second: 5,594.58012
Overall Steps per Second: 4,973.68687

Timestep Collection Time: 8.94008
Timestep Consumption Time: 1.11604
PPO Batch Consumption Time: 0.08085
Total Iteration Time: 10.05612

Cumulative Model Updates: 17,418
Cumulative Timesteps: 290,799,172

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 290799172...
Checkpoint 290799172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,588.85398
Policy Entropy: 0.60655
Value Function Loss: 0.06996

Mean KL Divergence: 0.00199
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.02556
Value Function Update Magnitude: 0.02948

Collected Steps per Second: 5,844.73225
Overall Steps per Second: 5,180.30084

Timestep Collection Time: 8.55779
Timestep Consumption Time: 1.09763
PPO Batch Consumption Time: 0.08558
Total Iteration Time: 9.65542

Cumulative Model Updates: 17,421
Cumulative Timesteps: 290,849,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,774.20198
Policy Entropy: 0.60561
Value Function Loss: 0.06938

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.02838
Value Function Update Magnitude: 0.03401

Collected Steps per Second: 5,731.59520
Overall Steps per Second: 5,082.89071

Timestep Collection Time: 8.72357
Timestep Consumption Time: 1.11335
PPO Batch Consumption Time: 0.08304
Total Iteration Time: 9.83692

Cumulative Model Updates: 17,424
Cumulative Timesteps: 290,899,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 290899190...
Checkpoint 290899190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,487.26219
Policy Entropy: 0.60994
Value Function Loss: 0.06740

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02348
Policy Update Magnitude: 0.03022
Value Function Update Magnitude: 0.03957

Collected Steps per Second: 5,447.37080
Overall Steps per Second: 4,869.49106

Timestep Collection Time: 9.18204
Timestep Consumption Time: 1.08967
PPO Batch Consumption Time: 0.08337
Total Iteration Time: 10.27171

Cumulative Model Updates: 17,427
Cumulative Timesteps: 290,949,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,952.16992
Policy Entropy: 0.62240
Value Function Loss: 0.05674

Mean KL Divergence: 0.00118
SB3 Clip Fraction: 0.01155
Policy Update Magnitude: 0.02836
Value Function Update Magnitude: 0.03602

Collected Steps per Second: 5,634.15648
Overall Steps per Second: 4,991.72241

Timestep Collection Time: 8.87764
Timestep Consumption Time: 1.14255
PPO Batch Consumption Time: 0.08567
Total Iteration Time: 10.02019

Cumulative Model Updates: 17,430
Cumulative Timesteps: 290,999,226

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 290999226...
Checkpoint 290999226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,209.48392
Policy Entropy: 0.62565
Value Function Loss: 0.05582

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02095
Policy Update Magnitude: 0.02937
Value Function Update Magnitude: 0.03155

Collected Steps per Second: 5,477.24081
Overall Steps per Second: 4,936.32391

Timestep Collection Time: 9.13562
Timestep Consumption Time: 1.00107
PPO Batch Consumption Time: 0.08338
Total Iteration Time: 10.13669

Cumulative Model Updates: 17,433
Cumulative Timesteps: 291,049,264

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,774.30277
Policy Entropy: 0.62288
Value Function Loss: 0.06922

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.03559
Policy Update Magnitude: 0.02880
Value Function Update Magnitude: 0.03267

Collected Steps per Second: 5,518.92390
Overall Steps per Second: 4,986.45217

Timestep Collection Time: 9.06191
Timestep Consumption Time: 0.96766
PPO Batch Consumption Time: 0.08412
Total Iteration Time: 10.02958

Cumulative Model Updates: 17,436
Cumulative Timesteps: 291,099,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 291099276...
Checkpoint 291099276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,313.89138
Policy Entropy: 0.62611
Value Function Loss: 0.07496

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03233
Policy Update Magnitude: 0.02908
Value Function Update Magnitude: 0.03328

Collected Steps per Second: 5,344.02009
Overall Steps per Second: 4,838.99570

Timestep Collection Time: 9.36261
Timestep Consumption Time: 0.97713
PPO Batch Consumption Time: 0.08294
Total Iteration Time: 10.33975

Cumulative Model Updates: 17,439
Cumulative Timesteps: 291,149,310

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,868.61063
Policy Entropy: 0.63100
Value Function Loss: 0.07186

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02591
Policy Update Magnitude: 0.02907
Value Function Update Magnitude: 0.03797

Collected Steps per Second: 5,396.61320
Overall Steps per Second: 4,882.19361

Timestep Collection Time: 9.26878
Timestep Consumption Time: 0.97662
PPO Batch Consumption Time: 0.08569
Total Iteration Time: 10.24539

Cumulative Model Updates: 17,442
Cumulative Timesteps: 291,199,330

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 291199330...
Checkpoint 291199330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,523.34543
Policy Entropy: 0.62845
Value Function Loss: 0.06463

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04857
Policy Update Magnitude: 0.02939
Value Function Update Magnitude: 0.03775

Collected Steps per Second: 5,508.49828
Overall Steps per Second: 4,941.58898

Timestep Collection Time: 9.08451
Timestep Consumption Time: 1.04219
PPO Batch Consumption Time: 0.08405
Total Iteration Time: 10.12670

Cumulative Model Updates: 17,445
Cumulative Timesteps: 291,249,372

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,503.55808
Policy Entropy: 0.62238
Value Function Loss: 0.05917

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.02868
Value Function Update Magnitude: 0.03564

Collected Steps per Second: 5,601.77955
Overall Steps per Second: 4,994.29014

Timestep Collection Time: 8.92645
Timestep Consumption Time: 1.08578
PPO Batch Consumption Time: 0.08410
Total Iteration Time: 10.01223

Cumulative Model Updates: 17,448
Cumulative Timesteps: 291,299,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 291299376...
Checkpoint 291299376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,315.45774
Policy Entropy: 0.61635
Value Function Loss: 0.06149

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.03079
Policy Update Magnitude: 0.02716
Value Function Update Magnitude: 0.03757

Collected Steps per Second: 5,402.83585
Overall Steps per Second: 4,825.60696

Timestep Collection Time: 9.25514
Timestep Consumption Time: 1.10708
PPO Batch Consumption Time: 0.08477
Total Iteration Time: 10.36222

Cumulative Model Updates: 17,451
Cumulative Timesteps: 291,349,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,485.23858
Policy Entropy: 0.61714
Value Function Loss: 0.06034

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03509
Policy Update Magnitude: 0.02454
Value Function Update Magnitude: 0.03822

Collected Steps per Second: 5,602.61618
Overall Steps per Second: 4,984.93468

Timestep Collection Time: 8.92833
Timestep Consumption Time: 1.10631
PPO Batch Consumption Time: 0.08780
Total Iteration Time: 10.03463

Cumulative Model Updates: 17,454
Cumulative Timesteps: 291,399,402

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 291399402...
Checkpoint 291399402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,229.94392
Policy Entropy: 0.61309
Value Function Loss: 0.06305

Mean KL Divergence: 0.00143
SB3 Clip Fraction: 0.01359
Policy Update Magnitude: 0.02420
Value Function Update Magnitude: 0.03614

Collected Steps per Second: 5,718.25624
Overall Steps per Second: 5,085.24931

Timestep Collection Time: 8.74602
Timestep Consumption Time: 1.08870
PPO Batch Consumption Time: 0.08283
Total Iteration Time: 9.83472

Cumulative Model Updates: 17,457
Cumulative Timesteps: 291,449,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,857.96151
Policy Entropy: 0.61331
Value Function Loss: 0.06058

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.02524
Value Function Update Magnitude: 0.03858

Collected Steps per Second: 5,710.10713
Overall Steps per Second: 5,060.20716

Timestep Collection Time: 8.75991
Timestep Consumption Time: 1.12507
PPO Batch Consumption Time: 0.08298
Total Iteration Time: 9.88497

Cumulative Model Updates: 17,460
Cumulative Timesteps: 291,499,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 291499434...
Checkpoint 291499434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,702.36863
Policy Entropy: 0.61544
Value Function Loss: 0.06540

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.02948
Value Function Update Magnitude: 0.03456

Collected Steps per Second: 5,416.41668
Overall Steps per Second: 4,813.47806

Timestep Collection Time: 9.23452
Timestep Consumption Time: 1.15672
PPO Batch Consumption Time: 0.08327
Total Iteration Time: 10.39124

Cumulative Model Updates: 17,463
Cumulative Timesteps: 291,549,452

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,726.62661
Policy Entropy: 0.62326
Value Function Loss: 0.06104

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.02852
Value Function Update Magnitude: 0.04122

Collected Steps per Second: 5,628.71323
Overall Steps per Second: 4,991.38481

Timestep Collection Time: 8.88409
Timestep Consumption Time: 1.13437
PPO Batch Consumption Time: 0.08762
Total Iteration Time: 10.01846

Cumulative Model Updates: 17,466
Cumulative Timesteps: 291,599,458

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 291599458...
Checkpoint 291599458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,941.89958
Policy Entropy: 0.62352
Value Function Loss: 0.05886

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01835
Policy Update Magnitude: 0.02738
Value Function Update Magnitude: 0.05816

Collected Steps per Second: 5,663.02061
Overall Steps per Second: 5,006.36639

Timestep Collection Time: 8.83380
Timestep Consumption Time: 1.15868
PPO Batch Consumption Time: 0.08512
Total Iteration Time: 9.99248

Cumulative Model Updates: 17,469
Cumulative Timesteps: 291,649,484

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,208.71235
Policy Entropy: 0.62600
Value Function Loss: 0.05856

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.03132
Value Function Update Magnitude: 0.06112

Collected Steps per Second: 5,554.04754
Overall Steps per Second: 4,849.45916

Timestep Collection Time: 9.01073
Timestep Consumption Time: 1.30919
PPO Batch Consumption Time: 0.08458
Total Iteration Time: 10.31991

Cumulative Model Updates: 17,472
Cumulative Timesteps: 291,699,530

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 291699530...
Checkpoint 291699530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,440.46209
Policy Entropy: 0.62229
Value Function Loss: 0.06231

Mean KL Divergence: 0.00168
SB3 Clip Fraction: 0.01838
Policy Update Magnitude: 0.02980
Value Function Update Magnitude: 0.05801

Collected Steps per Second: 5,629.54576
Overall Steps per Second: 4,965.61957

Timestep Collection Time: 8.88917
Timestep Consumption Time: 1.18852
PPO Batch Consumption Time: 0.08344
Total Iteration Time: 10.07770

Cumulative Model Updates: 17,475
Cumulative Timesteps: 291,749,572

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,933.45258
Policy Entropy: 0.62159
Value Function Loss: 0.05717

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03271
Policy Update Magnitude: 0.02771
Value Function Update Magnitude: 0.06284

Collected Steps per Second: 5,747.42862
Overall Steps per Second: 5,078.70835

Timestep Collection Time: 8.70302
Timestep Consumption Time: 1.14594
PPO Batch Consumption Time: 0.08770
Total Iteration Time: 9.84896

Cumulative Model Updates: 17,478
Cumulative Timesteps: 291,799,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 291799592...
Checkpoint 291799592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,782.33586
Policy Entropy: 0.62261
Value Function Loss: 0.05283

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.02760
Value Function Update Magnitude: 0.05895

Collected Steps per Second: 5,692.00195
Overall Steps per Second: 5,014.43857

Timestep Collection Time: 8.78777
Timestep Consumption Time: 1.18743
PPO Batch Consumption Time: 0.08361
Total Iteration Time: 9.97519

Cumulative Model Updates: 17,481
Cumulative Timesteps: 291,849,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,826.81799
Policy Entropy: 0.62444
Value Function Loss: 0.05042

Mean KL Divergence: 0.00222
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.02457
Value Function Update Magnitude: 0.05419

Collected Steps per Second: 5,541.98000
Overall Steps per Second: 4,947.97537

Timestep Collection Time: 9.02349
Timestep Consumption Time: 1.08327
PPO Batch Consumption Time: 0.08436
Total Iteration Time: 10.10676

Cumulative Model Updates: 17,484
Cumulative Timesteps: 291,899,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 291899620...
Checkpoint 291899620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,240.26872
Policy Entropy: 0.61822
Value Function Loss: 0.05945

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.02325
Value Function Update Magnitude: 0.05376

Collected Steps per Second: 5,872.45294
Overall Steps per Second: 5,160.79390

Timestep Collection Time: 8.51842
Timestep Consumption Time: 1.17467
PPO Batch Consumption Time: 0.10222
Total Iteration Time: 9.69308

Cumulative Model Updates: 17,487
Cumulative Timesteps: 291,949,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,226.69230
Policy Entropy: 0.61233
Value Function Loss: 0.06570

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.04017
Policy Update Magnitude: 0.02295
Value Function Update Magnitude: 0.05325

Collected Steps per Second: 5,759.44109
Overall Steps per Second: 5,096.00473

Timestep Collection Time: 8.68487
Timestep Consumption Time: 1.13066
PPO Batch Consumption Time: 0.08829
Total Iteration Time: 9.81553

Cumulative Model Updates: 17,490
Cumulative Timesteps: 291,999,664

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 291999664...
Checkpoint 291999664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,902.85036
Policy Entropy: 0.60991
Value Function Loss: 0.07461

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.02487
Value Function Update Magnitude: 0.06668

Collected Steps per Second: 5,530.35375
Overall Steps per Second: 4,868.54126

Timestep Collection Time: 9.04391
Timestep Consumption Time: 1.22940
PPO Batch Consumption Time: 0.08398
Total Iteration Time: 10.27330

Cumulative Model Updates: 17,493
Cumulative Timesteps: 292,049,680

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,578.14639
Policy Entropy: 0.60848
Value Function Loss: 0.08239

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03107
Policy Update Magnitude: 0.02719
Value Function Update Magnitude: 0.07248

Collected Steps per Second: 5,501.49008
Overall Steps per Second: 4,899.76736

Timestep Collection Time: 9.09499
Timestep Consumption Time: 1.11692
PPO Batch Consumption Time: 0.08849
Total Iteration Time: 10.21191

Cumulative Model Updates: 17,496
Cumulative Timesteps: 292,099,716

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 292099716...
Checkpoint 292099716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,295.38796
Policy Entropy: 0.60574
Value Function Loss: 0.08048

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.02647
Value Function Update Magnitude: 0.07298

Collected Steps per Second: 5,378.22141
Overall Steps per Second: 4,796.25804

Timestep Collection Time: 9.29973
Timestep Consumption Time: 1.12840
PPO Batch Consumption Time: 0.08487
Total Iteration Time: 10.42813

Cumulative Model Updates: 17,499
Cumulative Timesteps: 292,149,732

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,485.45434
Policy Entropy: 0.61029
Value Function Loss: 0.06987

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02979
Policy Update Magnitude: 0.02730
Value Function Update Magnitude: 0.07573

Collected Steps per Second: 5,601.35529
Overall Steps per Second: 5,002.15000

Timestep Collection Time: 8.92713
Timestep Consumption Time: 1.06938
PPO Batch Consumption Time: 0.08985
Total Iteration Time: 9.99650

Cumulative Model Updates: 17,502
Cumulative Timesteps: 292,199,736

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 292199736...
Checkpoint 292199736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,583.21706
Policy Entropy: 0.61539
Value Function Loss: 0.06656

Mean KL Divergence: 0.00203
SB3 Clip Fraction: 0.02263
Policy Update Magnitude: 0.02749
Value Function Update Magnitude: 0.06520

Collected Steps per Second: 5,426.30308
Overall Steps per Second: 4,825.83797

Timestep Collection Time: 9.21548
Timestep Consumption Time: 1.14666
PPO Batch Consumption Time: 0.08759
Total Iteration Time: 10.36214

Cumulative Model Updates: 17,505
Cumulative Timesteps: 292,249,742

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,526.50662
Policy Entropy: 0.62052
Value Function Loss: 0.06224

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.05608
Policy Update Magnitude: 0.02693
Value Function Update Magnitude: 0.05838

Collected Steps per Second: 5,398.66341
Overall Steps per Second: 4,808.96501

Timestep Collection Time: 9.26600
Timestep Consumption Time: 1.13624
PPO Batch Consumption Time: 0.08217
Total Iteration Time: 10.40224

Cumulative Model Updates: 17,508
Cumulative Timesteps: 292,299,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 292299766...
Checkpoint 292299766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,952.42861
Policy Entropy: 0.61973
Value Function Loss: 0.06126

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.03943
Policy Update Magnitude: 0.02688
Value Function Update Magnitude: 0.05631

Collected Steps per Second: 5,695.23951
Overall Steps per Second: 5,062.68487

Timestep Collection Time: 8.77961
Timestep Consumption Time: 1.09696
PPO Batch Consumption Time: 0.08336
Total Iteration Time: 9.87658

Cumulative Model Updates: 17,511
Cumulative Timesteps: 292,349,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,925.33286
Policy Entropy: 0.62462
Value Function Loss: 0.05697

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.01585
Policy Update Magnitude: 0.02487
Value Function Update Magnitude: 0.05150

Collected Steps per Second: 5,716.53216
Overall Steps per Second: 5,101.24961

Timestep Collection Time: 8.74726
Timestep Consumption Time: 1.05504
PPO Batch Consumption Time: 0.08462
Total Iteration Time: 9.80230

Cumulative Model Updates: 17,514
Cumulative Timesteps: 292,399,772

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 292399772...
Checkpoint 292399772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,736.63139
Policy Entropy: 0.61664
Value Function Loss: 0.06160

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.03271
Policy Update Magnitude: 0.02438
Value Function Update Magnitude: 0.04814

Collected Steps per Second: 6,072.85967
Overall Steps per Second: 5,360.41007

Timestep Collection Time: 8.23401
Timestep Consumption Time: 1.09438
PPO Batch Consumption Time: 0.08758
Total Iteration Time: 9.32839

Cumulative Model Updates: 17,517
Cumulative Timesteps: 292,449,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,564.23503
Policy Entropy: 0.61972
Value Function Loss: 0.06662

Mean KL Divergence: 0.00228
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.02410
Value Function Update Magnitude: 0.05227

Collected Steps per Second: 5,813.24333
Overall Steps per Second: 5,143.42719

Timestep Collection Time: 8.60105
Timestep Consumption Time: 1.12009
PPO Batch Consumption Time: 0.08249
Total Iteration Time: 9.72114

Cumulative Model Updates: 17,520
Cumulative Timesteps: 292,499,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 292499776...
Checkpoint 292499776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,170.93328
Policy Entropy: 0.62142
Value Function Loss: 0.06619

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.05405
Policy Update Magnitude: 0.02512
Value Function Update Magnitude: 0.05841

Collected Steps per Second: 5,662.37116
Overall Steps per Second: 5,003.07624

Timestep Collection Time: 8.83481
Timestep Consumption Time: 1.16423
PPO Batch Consumption Time: 0.08551
Total Iteration Time: 9.99905

Cumulative Model Updates: 17,523
Cumulative Timesteps: 292,549,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,701.16109
Policy Entropy: 0.63085
Value Function Loss: 0.05920

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02977
Policy Update Magnitude: 0.02542
Value Function Update Magnitude: 0.05679

Collected Steps per Second: 5,686.07544
Overall Steps per Second: 5,029.92532

Timestep Collection Time: 8.79447
Timestep Consumption Time: 1.14723
PPO Batch Consumption Time: 0.08345
Total Iteration Time: 9.94170

Cumulative Model Updates: 17,526
Cumulative Timesteps: 292,599,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 292599808...
Checkpoint 292599808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,814.87677
Policy Entropy: 0.63256
Value Function Loss: 0.05118

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.01963
Policy Update Magnitude: 0.02441
Value Function Update Magnitude: 0.05065

Collected Steps per Second: 5,649.96580
Overall Steps per Second: 5,022.40020

Timestep Collection Time: 8.85386
Timestep Consumption Time: 1.10632
PPO Batch Consumption Time: 0.08207
Total Iteration Time: 9.96018

Cumulative Model Updates: 17,529
Cumulative Timesteps: 292,649,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,589.22332
Policy Entropy: 0.63390
Value Function Loss: 0.04324

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.02536
Value Function Update Magnitude: 0.04923

Collected Steps per Second: 5,588.50766
Overall Steps per Second: 4,959.86239

Timestep Collection Time: 8.94944
Timestep Consumption Time: 1.13431
PPO Batch Consumption Time: 0.08237
Total Iteration Time: 10.08375

Cumulative Model Updates: 17,532
Cumulative Timesteps: 292,699,846

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 292699846...
Checkpoint 292699846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,069.02741
Policy Entropy: 0.62341
Value Function Loss: 0.04705

Mean KL Divergence: 0.00208
SB3 Clip Fraction: 0.02195
Policy Update Magnitude: 0.02563
Value Function Update Magnitude: 0.04177

Collected Steps per Second: 5,673.89532
Overall Steps per Second: 5,049.68947

Timestep Collection Time: 8.81476
Timestep Consumption Time: 1.08962
PPO Batch Consumption Time: 0.08528
Total Iteration Time: 9.90437

Cumulative Model Updates: 17,535
Cumulative Timesteps: 292,749,860

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,225.16907
Policy Entropy: 0.61768
Value Function Loss: 0.05020

Mean KL Divergence: 0.00155
SB3 Clip Fraction: 0.01531
Policy Update Magnitude: 0.02731
Value Function Update Magnitude: 0.04248

Collected Steps per Second: 5,618.51366
Overall Steps per Second: 4,993.44878

Timestep Collection Time: 8.90164
Timestep Consumption Time: 1.11428
PPO Batch Consumption Time: 0.08502
Total Iteration Time: 10.01592

Cumulative Model Updates: 17,538
Cumulative Timesteps: 292,799,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 292799874...
Checkpoint 292799874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,383.87880
Policy Entropy: 0.61690
Value Function Loss: 0.05330

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01766
Policy Update Magnitude: 0.02809
Value Function Update Magnitude: 0.04115

Collected Steps per Second: 5,611.07905
Overall Steps per Second: 4,965.44598

Timestep Collection Time: 8.91664
Timestep Consumption Time: 1.15939
PPO Batch Consumption Time: 0.08748
Total Iteration Time: 10.07603

Cumulative Model Updates: 17,541
Cumulative Timesteps: 292,849,906

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,122.26581
Policy Entropy: 0.62269
Value Function Loss: 0.05105

Mean KL Divergence: 0.00150
SB3 Clip Fraction: 0.01387
Policy Update Magnitude: 0.02596
Value Function Update Magnitude: 0.04454

Collected Steps per Second: 5,503.33838
Overall Steps per Second: 4,894.79686

Timestep Collection Time: 9.08648
Timestep Consumption Time: 1.12967
PPO Batch Consumption Time: 0.08296
Total Iteration Time: 10.21615

Cumulative Model Updates: 17,544
Cumulative Timesteps: 292,899,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 292899912...
Checkpoint 292899912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,956.23245
Policy Entropy: 0.62063
Value Function Loss: 0.05404

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.01955
Policy Update Magnitude: 0.02696
Value Function Update Magnitude: 0.04629

Collected Steps per Second: 5,734.92299
Overall Steps per Second: 5,098.39443

Timestep Collection Time: 8.72374
Timestep Consumption Time: 1.08915
PPO Batch Consumption Time: 0.08659
Total Iteration Time: 9.81289

Cumulative Model Updates: 17,547
Cumulative Timesteps: 292,949,942

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,693.06111
Policy Entropy: 0.61148
Value Function Loss: 0.05765

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04501
Policy Update Magnitude: 0.02636
Value Function Update Magnitude: 0.04944

Collected Steps per Second: 5,653.83204
Overall Steps per Second: 5,019.71878

Timestep Collection Time: 8.84780
Timestep Consumption Time: 1.11769
PPO Batch Consumption Time: 0.08529
Total Iteration Time: 9.96550

Cumulative Model Updates: 17,550
Cumulative Timesteps: 292,999,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 292999966...
Checkpoint 292999966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,223.30417
Policy Entropy: 0.60361
Value Function Loss: 0.06372

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.02910
Value Function Update Magnitude: 0.04782

Collected Steps per Second: 5,666.54985
Overall Steps per Second: 5,056.62926

Timestep Collection Time: 8.82442
Timestep Consumption Time: 1.06438
PPO Batch Consumption Time: 0.08719
Total Iteration Time: 9.88880

Cumulative Model Updates: 17,553
Cumulative Timesteps: 293,049,970

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,669.69618
Policy Entropy: 0.60836
Value Function Loss: 0.06368

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.02979
Value Function Update Magnitude: 0.04842

Collected Steps per Second: 5,724.10848
Overall Steps per Second: 5,059.94931

Timestep Collection Time: 8.73778
Timestep Consumption Time: 1.14690
PPO Batch Consumption Time: 0.08433
Total Iteration Time: 9.88468

Cumulative Model Updates: 17,556
Cumulative Timesteps: 293,099,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 293099986...
Checkpoint 293099986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,233.34322
Policy Entropy: 0.60327
Value Function Loss: 0.06503

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04474
Policy Update Magnitude: 0.02555
Value Function Update Magnitude: 0.04645

Collected Steps per Second: 5,778.98816
Overall Steps per Second: 5,182.13056

Timestep Collection Time: 8.65480
Timestep Consumption Time: 0.99683
PPO Batch Consumption Time: 0.08477
Total Iteration Time: 9.65163

Cumulative Model Updates: 17,559
Cumulative Timesteps: 293,150,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,849.39116
Policy Entropy: 0.60780
Value Function Loss: 0.06002

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.04553
Policy Update Magnitude: 0.02758
Value Function Update Magnitude: 0.05011

Collected Steps per Second: 5,589.12767
Overall Steps per Second: 4,992.56123

Timestep Collection Time: 8.94630
Timestep Consumption Time: 1.06900
PPO Batch Consumption Time: 0.08360
Total Iteration Time: 10.01530

Cumulative Model Updates: 17,562
Cumulative Timesteps: 293,200,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 293200004...
Checkpoint 293200004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,997.51705
Policy Entropy: 0.60255
Value Function Loss: 0.05959

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02684
Policy Update Magnitude: 0.02975
Value Function Update Magnitude: 0.05607

Collected Steps per Second: 5,364.70731
Overall Steps per Second: 4,833.15917

Timestep Collection Time: 9.32204
Timestep Consumption Time: 1.02523
PPO Batch Consumption Time: 0.08346
Total Iteration Time: 10.34727

Cumulative Model Updates: 17,565
Cumulative Timesteps: 293,250,014

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,981.14999
Policy Entropy: 0.60574
Value Function Loss: 0.05717

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02865
Policy Update Magnitude: 0.02808
Value Function Update Magnitude: 0.05754

Collected Steps per Second: 5,435.06854
Overall Steps per Second: 4,910.26139

Timestep Collection Time: 9.20320
Timestep Consumption Time: 0.98363
PPO Batch Consumption Time: 0.08816
Total Iteration Time: 10.18683

Cumulative Model Updates: 17,568
Cumulative Timesteps: 293,300,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 293300034...
Checkpoint 293300034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,487.34550
Policy Entropy: 0.60314
Value Function Loss: 0.05453

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05241
Policy Update Magnitude: 0.02708
Value Function Update Magnitude: 0.05437

Collected Steps per Second: 5,486.80062
Overall Steps per Second: 4,919.31599

Timestep Collection Time: 9.11825
Timestep Consumption Time: 1.05187
PPO Batch Consumption Time: 0.08379
Total Iteration Time: 10.17011

Cumulative Model Updates: 17,571
Cumulative Timesteps: 293,350,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,861.86026
Policy Entropy: 0.60355
Value Function Loss: 0.05279

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.03116
Policy Update Magnitude: 0.02658
Value Function Update Magnitude: 0.05843

Collected Steps per Second: 7,907.15123
Overall Steps per Second: 7,034.68664

Timestep Collection Time: 6.32643
Timestep Consumption Time: 0.78462
PPO Batch Consumption Time: 0.04552
Total Iteration Time: 7.11105

Cumulative Model Updates: 17,574
Cumulative Timesteps: 293,400,088

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 293400088...
Checkpoint 293400088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,855.88202
Policy Entropy: 0.60610
Value Function Loss: 0.05327

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.06321
Policy Update Magnitude: 0.02489
Value Function Update Magnitude: 0.05419

Collected Steps per Second: 16,376.89705
Overall Steps per Second: 12,673.59006

Timestep Collection Time: 3.05406
Timestep Consumption Time: 0.89242
PPO Batch Consumption Time: 0.06122
Total Iteration Time: 3.94647

Cumulative Model Updates: 17,577
Cumulative Timesteps: 293,450,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,298.04180
Policy Entropy: 0.60405
Value Function Loss: 0.05945

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04277
Policy Update Magnitude: 0.02511
Value Function Update Magnitude: 0.05214

Collected Steps per Second: 6,782.65099
Overall Steps per Second: 5,877.25805

Timestep Collection Time: 7.37765
Timestep Consumption Time: 1.13653
PPO Batch Consumption Time: 0.11898
Total Iteration Time: 8.51417

Cumulative Model Updates: 17,580
Cumulative Timesteps: 293,500,144

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 293500144...
Checkpoint 293500144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,146.53497
Policy Entropy: 0.60663
Value Function Loss: 0.05829

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.05346
Policy Update Magnitude: 0.02499
Value Function Update Magnitude: 0.04332

Collected Steps per Second: 5,808.21619
Overall Steps per Second: 5,152.21004

Timestep Collection Time: 8.60850
Timestep Consumption Time: 1.09608
PPO Batch Consumption Time: 0.11166
Total Iteration Time: 9.70457

Cumulative Model Updates: 17,583
Cumulative Timesteps: 293,550,144

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,878.10700
Policy Entropy: 0.59955
Value Function Loss: 0.05561

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.04787
Policy Update Magnitude: 0.02355
Value Function Update Magnitude: 0.04285

Collected Steps per Second: 5,400.73045
Overall Steps per Second: 4,848.36190

Timestep Collection Time: 9.26097
Timestep Consumption Time: 1.05509
PPO Batch Consumption Time: 0.08693
Total Iteration Time: 10.31606

Cumulative Model Updates: 17,586
Cumulative Timesteps: 293,600,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 293600160...
Checkpoint 293600160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,014.91832
Policy Entropy: 0.60160
Value Function Loss: 0.05847

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.06020
Policy Update Magnitude: 0.02446
Value Function Update Magnitude: 0.05124

Collected Steps per Second: 6,611.98469
Overall Steps per Second: 5,783.36947

Timestep Collection Time: 7.56324
Timestep Consumption Time: 1.08363
PPO Batch Consumption Time: 0.10533
Total Iteration Time: 8.64686

Cumulative Model Updates: 17,589
Cumulative Timesteps: 293,650,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,149.68814
Policy Entropy: 0.59754
Value Function Loss: 0.06128

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.04791
Policy Update Magnitude: 0.02704
Value Function Update Magnitude: 0.06075

Collected Steps per Second: 5,517.03587
Overall Steps per Second: 4,916.91110

Timestep Collection Time: 9.06356
Timestep Consumption Time: 1.10624
PPO Batch Consumption Time: 0.10838
Total Iteration Time: 10.16980

Cumulative Model Updates: 17,592
Cumulative Timesteps: 293,700,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 293700172...
Checkpoint 293700172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,126.67626
Policy Entropy: 0.60226
Value Function Loss: 0.06431

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.06281
Policy Update Magnitude: 0.02733
Value Function Update Magnitude: 0.07417

Collected Steps per Second: 11,279.38700
Overall Steps per Second: 9,316.16166

Timestep Collection Time: 4.43393
Timestep Consumption Time: 0.93438
PPO Batch Consumption Time: 0.08528
Total Iteration Time: 5.36831

Cumulative Model Updates: 17,595
Cumulative Timesteps: 293,750,184

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,717.59339
Policy Entropy: 0.59527
Value Function Loss: 0.05957

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.05262
Policy Update Magnitude: 0.02716
Value Function Update Magnitude: 0.07864

Collected Steps per Second: 16,694.50418
Overall Steps per Second: 12,711.61740

Timestep Collection Time: 2.99775
Timestep Consumption Time: 0.93928
PPO Batch Consumption Time: 0.08983
Total Iteration Time: 3.93703

Cumulative Model Updates: 17,598
Cumulative Timesteps: 293,800,230

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 293800230...
Checkpoint 293800230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,820.81559
Policy Entropy: 0.60357
Value Function Loss: 0.05223

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05467
Policy Update Magnitude: 0.02565
Value Function Update Magnitude: 0.08379

Collected Steps per Second: 15,838.28970
Overall Steps per Second: 12,376.07958

Timestep Collection Time: 3.15754
Timestep Consumption Time: 0.88332
PPO Batch Consumption Time: 0.07401
Total Iteration Time: 4.04086

Cumulative Model Updates: 17,601
Cumulative Timesteps: 293,850,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,510.53911
Policy Entropy: 0.60302
Value Function Loss: 0.05322

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.07005
Policy Update Magnitude: 0.02533
Value Function Update Magnitude: 0.07900

Collected Steps per Second: 20,058.81353
Overall Steps per Second: 14,007.35666

Timestep Collection Time: 2.49466
Timestep Consumption Time: 1.07774
PPO Batch Consumption Time: 0.13632
Total Iteration Time: 3.57241

Cumulative Model Updates: 17,604
Cumulative Timesteps: 293,900,280

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 293900280...
Checkpoint 293900280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,794.15822
Policy Entropy: 0.60952
Value Function Loss: 0.04920

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.05321
Policy Update Magnitude: 0.02590
Value Function Update Magnitude: 0.06826

Collected Steps per Second: 20,033.14363
Overall Steps per Second: 14,124.67004

Timestep Collection Time: 2.49586
Timestep Consumption Time: 1.04404
PPO Batch Consumption Time: 0.12192
Total Iteration Time: 3.53991

Cumulative Model Updates: 17,607
Cumulative Timesteps: 293,950,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,370.78077
Policy Entropy: 0.59914
Value Function Loss: 0.06111

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06395
Policy Update Magnitude: 0.02734
Value Function Update Magnitude: 0.06487

Collected Steps per Second: 20,780.48055
Overall Steps per Second: 14,640.80252

Timestep Collection Time: 2.40736
Timestep Consumption Time: 1.00953
PPO Batch Consumption Time: 0.11460
Total Iteration Time: 3.41689

Cumulative Model Updates: 17,610
Cumulative Timesteps: 294,000,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 294000306...
Checkpoint 294000306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,385.04860
Policy Entropy: 0.59630
Value Function Loss: 0.06099

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.05603
Policy Update Magnitude: 0.02495
Value Function Update Magnitude: 0.06607

Collected Steps per Second: 17,540.73064
Overall Steps per Second: 13,153.02701

Timestep Collection Time: 2.85108
Timestep Consumption Time: 0.95109
PPO Batch Consumption Time: 0.09193
Total Iteration Time: 3.80217

Cumulative Model Updates: 17,613
Cumulative Timesteps: 294,050,316

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,453.82386
Policy Entropy: 0.58999
Value Function Loss: 0.07204

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03423
Policy Update Magnitude: 0.02555
Value Function Update Magnitude: 0.06707

Collected Steps per Second: 16,657.32548
Overall Steps per Second: 11,418.66520

Timestep Collection Time: 3.00372
Timestep Consumption Time: 1.37805
PPO Batch Consumption Time: 0.07682
Total Iteration Time: 4.38177

Cumulative Model Updates: 17,616
Cumulative Timesteps: 294,100,350

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 294100350...
Checkpoint 294100350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,130.92494
Policy Entropy: 0.58874
Value Function Loss: 0.06298

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05927
Policy Update Magnitude: 0.02379
Value Function Update Magnitude: 0.06087

Collected Steps per Second: 8,365.92375
Overall Steps per Second: 7,074.40836

Timestep Collection Time: 5.97806
Timestep Consumption Time: 1.09136
PPO Batch Consumption Time: 0.11106
Total Iteration Time: 7.06943

Cumulative Model Updates: 17,619
Cumulative Timesteps: 294,150,362

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,266.98192
Policy Entropy: 0.59090
Value Function Loss: 0.06148

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.03605
Policy Update Magnitude: 0.02336
Value Function Update Magnitude: 0.05671

Collected Steps per Second: 5,171.34999
Overall Steps per Second: 4,639.34050

Timestep Collection Time: 9.66866
Timestep Consumption Time: 1.10874
PPO Batch Consumption Time: 0.11024
Total Iteration Time: 10.77739

Cumulative Model Updates: 17,622
Cumulative Timesteps: 294,200,362

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 294200362...
Checkpoint 294200362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,056.04326
Policy Entropy: 0.59982
Value Function Loss: 0.05308

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02961
Policy Update Magnitude: 0.02351
Value Function Update Magnitude: 0.05183

Collected Steps per Second: 5,201.72339
Overall Steps per Second: 4,619.22118

Timestep Collection Time: 9.61297
Timestep Consumption Time: 1.21223
PPO Batch Consumption Time: 0.14534
Total Iteration Time: 10.82520

Cumulative Model Updates: 17,625
Cumulative Timesteps: 294,250,366

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,549.10773
Policy Entropy: 0.60189
Value Function Loss: 0.05238

Mean KL Divergence: 0.00238
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.02367
Value Function Update Magnitude: 0.04901

Collected Steps per Second: 5,072.72390
Overall Steps per Second: 4,564.88478

Timestep Collection Time: 9.85861
Timestep Consumption Time: 1.09676
PPO Batch Consumption Time: 0.11230
Total Iteration Time: 10.95537

Cumulative Model Updates: 17,628
Cumulative Timesteps: 294,300,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 294300376...
Checkpoint 294300376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,753.57717
Policy Entropy: 0.60650
Value Function Loss: 0.04789

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.04889
Policy Update Magnitude: 0.02433
Value Function Update Magnitude: 0.05321

Collected Steps per Second: 5,113.89985
Overall Steps per Second: 4,576.40062

Timestep Collection Time: 9.77727
Timestep Consumption Time: 1.14834
PPO Batch Consumption Time: 0.12914
Total Iteration Time: 10.92562

Cumulative Model Updates: 17,631
Cumulative Timesteps: 294,350,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,735.27103
Policy Entropy: 0.60667
Value Function Loss: 0.04853

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.05275
Policy Update Magnitude: 0.02244
Value Function Update Magnitude: 0.05848

Collected Steps per Second: 5,037.07473
Overall Steps per Second: 4,538.59285

Timestep Collection Time: 9.92640
Timestep Consumption Time: 1.09023
PPO Batch Consumption Time: 0.10566
Total Iteration Time: 11.01663

Cumulative Model Updates: 17,634
Cumulative Timesteps: 294,400,376

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 294400376...
Checkpoint 294400376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,429.06474
Policy Entropy: 0.61516
Value Function Loss: 0.05052

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05859
Policy Update Magnitude: 0.02171
Value Function Update Magnitude: 0.06166

Collected Steps per Second: 5,101.80906
Overall Steps per Second: 4,573.73197

Timestep Collection Time: 9.80084
Timestep Consumption Time: 1.13159
PPO Batch Consumption Time: 0.12875
Total Iteration Time: 10.93243

Cumulative Model Updates: 17,637
Cumulative Timesteps: 294,450,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,975.69602
Policy Entropy: 0.61056
Value Function Loss: 0.05745

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04660
Policy Update Magnitude: 0.02232
Value Function Update Magnitude: 0.06537

Collected Steps per Second: 5,093.64278
Overall Steps per Second: 4,554.31248

Timestep Collection Time: 9.82165
Timestep Consumption Time: 1.16310
PPO Batch Consumption Time: 0.12968
Total Iteration Time: 10.98475

Cumulative Model Updates: 17,640
Cumulative Timesteps: 294,500,406

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 294500406...
Checkpoint 294500406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,086.64797
Policy Entropy: 0.61083
Value Function Loss: 0.06305

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.05205
Policy Update Magnitude: 0.02433
Value Function Update Magnitude: 0.06565

Collected Steps per Second: 5,293.10433
Overall Steps per Second: 4,732.15348

Timestep Collection Time: 9.44701
Timestep Consumption Time: 1.11985
PPO Batch Consumption Time: 0.10209
Total Iteration Time: 10.56686

Cumulative Model Updates: 17,643
Cumulative Timesteps: 294,550,410

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,110.51136
Policy Entropy: 0.60298
Value Function Loss: 0.06454

Mean KL Divergence: 0.00227
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.02619
Value Function Update Magnitude: 0.05537

Collected Steps per Second: 5,817.26367
Overall Steps per Second: 5,162.48065

Timestep Collection Time: 8.59751
Timestep Consumption Time: 1.09047
PPO Batch Consumption Time: 0.10203
Total Iteration Time: 9.68798

Cumulative Model Updates: 17,646
Cumulative Timesteps: 294,600,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 294600424...
Checkpoint 294600424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,609.45223
Policy Entropy: 0.60662
Value Function Loss: 0.06335

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.05911
Policy Update Magnitude: 0.02545
Value Function Update Magnitude: 0.05144

Collected Steps per Second: 5,560.67690
Overall Steps per Second: 4,975.33837

Timestep Collection Time: 8.99243
Timestep Consumption Time: 1.05794
PPO Batch Consumption Time: 0.09460
Total Iteration Time: 10.05037

Cumulative Model Updates: 17,649
Cumulative Timesteps: 294,650,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,912.39117
Policy Entropy: 0.60642
Value Function Loss: 0.06371

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03365
Policy Update Magnitude: 0.02489
Value Function Update Magnitude: 0.05389

Collected Steps per Second: 5,485.79940
Overall Steps per Second: 4,931.06358

Timestep Collection Time: 9.11955
Timestep Consumption Time: 1.02593
PPO Batch Consumption Time: 0.08054
Total Iteration Time: 10.14548

Cumulative Model Updates: 17,652
Cumulative Timesteps: 294,700,456

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 294700456...
Checkpoint 294700456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,151.06101
Policy Entropy: 0.61014
Value Function Loss: 0.06156

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05701
Policy Update Magnitude: 0.02822
Value Function Update Magnitude: 0.05534

Collected Steps per Second: 6,277.17004
Overall Steps per Second: 5,522.87812

Timestep Collection Time: 7.96569
Timestep Consumption Time: 1.08792
PPO Batch Consumption Time: 0.09215
Total Iteration Time: 9.05361

Cumulative Model Updates: 17,655
Cumulative Timesteps: 294,750,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,960.44246
Policy Entropy: 0.60714
Value Function Loss: 0.06093

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 0.02692
Value Function Update Magnitude: 0.05449

Collected Steps per Second: 5,867.62004
Overall Steps per Second: 5,258.53123

Timestep Collection Time: 8.52646
Timestep Consumption Time: 0.98761
PPO Batch Consumption Time: 0.08868
Total Iteration Time: 9.51406

Cumulative Model Updates: 17,658
Cumulative Timesteps: 294,800,488

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 294800488...
Checkpoint 294800488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,907.60039
Policy Entropy: 0.60527
Value Function Loss: 0.05858

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.03903
Policy Update Magnitude: 0.02452
Value Function Update Magnitude: 0.04394

Collected Steps per Second: 6,502.14812
Overall Steps per Second: 5,760.03208

Timestep Collection Time: 7.69253
Timestep Consumption Time: 0.99110
PPO Batch Consumption Time: 0.09505
Total Iteration Time: 8.68363

Cumulative Model Updates: 17,661
Cumulative Timesteps: 294,850,506

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,620.13617
Policy Entropy: 0.59823
Value Function Loss: 0.07040

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.02931
Policy Update Magnitude: 0.02480
Value Function Update Magnitude: 0.04838

Collected Steps per Second: 5,606.96677
Overall Steps per Second: 5,050.13550

Timestep Collection Time: 8.91926
Timestep Consumption Time: 0.98344
PPO Batch Consumption Time: 0.08758
Total Iteration Time: 9.90270

Cumulative Model Updates: 17,664
Cumulative Timesteps: 294,900,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 294900516...
Checkpoint 294900516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,540.84625
Policy Entropy: 0.60687
Value Function Loss: 0.07321

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.03627
Policy Update Magnitude: 0.02687
Value Function Update Magnitude: 0.04599

Collected Steps per Second: 10,297.32984
Overall Steps per Second: 8,563.50740

Timestep Collection Time: 4.86029
Timestep Consumption Time: 0.98405
PPO Batch Consumption Time: 0.08585
Total Iteration Time: 5.84433

Cumulative Model Updates: 17,667
Cumulative Timesteps: 294,950,564

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,150.37950
Policy Entropy: 0.60627
Value Function Loss: 0.06813

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.02674
Value Function Update Magnitude: 0.04131

Collected Steps per Second: 7,744.23664
Overall Steps per Second: 6,523.82411

Timestep Collection Time: 6.45926
Timestep Consumption Time: 1.20833
PPO Batch Consumption Time: 0.11543
Total Iteration Time: 7.66759

Cumulative Model Updates: 17,670
Cumulative Timesteps: 295,000,586

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 295000586...
Checkpoint 295000586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,578.43916
Policy Entropy: 0.61478
Value Function Loss: 0.06387

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.03059
Policy Update Magnitude: 0.02697
Value Function Update Magnitude: 0.03919

Collected Steps per Second: 5,751.09929
Overall Steps per Second: 5,097.43046

Timestep Collection Time: 8.69608
Timestep Consumption Time: 1.11514
PPO Batch Consumption Time: 0.10494
Total Iteration Time: 9.81122

Cumulative Model Updates: 17,673
Cumulative Timesteps: 295,050,598

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,815.49792
Policy Entropy: 0.61032
Value Function Loss: 0.06168

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02651
Policy Update Magnitude: 0.02617
Value Function Update Magnitude: 0.03527

Collected Steps per Second: 5,356.62849
Overall Steps per Second: 4,778.02486

Timestep Collection Time: 9.33871
Timestep Consumption Time: 1.13089
PPO Batch Consumption Time: 0.11068
Total Iteration Time: 10.46960

Cumulative Model Updates: 17,676
Cumulative Timesteps: 295,100,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 295100622...
Checkpoint 295100622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,991.17930
Policy Entropy: 0.61042
Value Function Loss: 0.06371

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.01723
Policy Update Magnitude: 0.02610
Value Function Update Magnitude: 0.03117

Collected Steps per Second: 5,211.30591
Overall Steps per Second: 4,693.90720

Timestep Collection Time: 9.59990
Timestep Consumption Time: 1.05817
PPO Batch Consumption Time: 0.10143
Total Iteration Time: 10.65807

Cumulative Model Updates: 17,679
Cumulative Timesteps: 295,150,650

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,898.76873
Policy Entropy: 0.61180
Value Function Loss: 0.05858

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.02960
Policy Update Magnitude: 0.02439
Value Function Update Magnitude: 0.03018

Collected Steps per Second: 5,170.83923
Overall Steps per Second: 4,642.55687

Timestep Collection Time: 9.67077
Timestep Consumption Time: 1.10045
PPO Batch Consumption Time: 0.10152
Total Iteration Time: 10.77122

Cumulative Model Updates: 17,682
Cumulative Timesteps: 295,200,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 295200656...
Checkpoint 295200656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,995.40909
Policy Entropy: 0.61929
Value Function Loss: 0.05860

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02025
Policy Update Magnitude: 0.02407
Value Function Update Magnitude: 0.03341

Collected Steps per Second: 4,995.50620
Overall Steps per Second: 4,506.15452

Timestep Collection Time: 10.00980
Timestep Consumption Time: 1.08703
PPO Batch Consumption Time: 0.10621
Total Iteration Time: 11.09682

Cumulative Model Updates: 17,685
Cumulative Timesteps: 295,250,660

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,654.95127
Policy Entropy: 0.61692
Value Function Loss: 0.05885

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.02248
Policy Update Magnitude: 0.02416
Value Function Update Magnitude: 0.02893

Collected Steps per Second: 6,391.15779
Overall Steps per Second: 5,625.53893

Timestep Collection Time: 7.82863
Timestep Consumption Time: 1.06545
PPO Batch Consumption Time: 0.08136
Total Iteration Time: 8.89408

Cumulative Model Updates: 17,688
Cumulative Timesteps: 295,300,694

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 295300694...
Checkpoint 295300694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,640.24960
Policy Entropy: 0.61925
Value Function Loss: 0.06137

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01895
Policy Update Magnitude: 0.02798
Value Function Update Magnitude: 0.02938

Collected Steps per Second: 6,884.41109
Overall Steps per Second: 6,140.16415

Timestep Collection Time: 7.26918
Timestep Consumption Time: 0.88109
PPO Batch Consumption Time: 0.04575
Total Iteration Time: 8.15027

Cumulative Model Updates: 17,691
Cumulative Timesteps: 295,350,738

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,787.13162
Policy Entropy: 0.61469
Value Function Loss: 0.06140

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02041
Policy Update Magnitude: 0.02738
Value Function Update Magnitude: 0.03187

Collected Steps per Second: 7,034.74578
Overall Steps per Second: 6,073.58119

Timestep Collection Time: 7.10957
Timestep Consumption Time: 1.12511
PPO Batch Consumption Time: 0.10632
Total Iteration Time: 8.23468

Cumulative Model Updates: 17,694
Cumulative Timesteps: 295,400,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 295400752...
Checkpoint 295400752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,660.45336
Policy Entropy: 0.61447
Value Function Loss: 0.05597

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02263
Policy Update Magnitude: 0.02658
Value Function Update Magnitude: 0.03125

Collected Steps per Second: 6,355.61378
Overall Steps per Second: 5,572.61506

Timestep Collection Time: 7.86706
Timestep Consumption Time: 1.10539
PPO Batch Consumption Time: 0.10205
Total Iteration Time: 8.97245

Cumulative Model Updates: 17,697
Cumulative Timesteps: 295,450,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,215.32468
Policy Entropy: 0.60990
Value Function Loss: 0.05542

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.02857
Policy Update Magnitude: 0.02532
Value Function Update Magnitude: 0.03124

Collected Steps per Second: 5,687.79367
Overall Steps per Second: 5,058.23448

Timestep Collection Time: 8.79216
Timestep Consumption Time: 1.09429
PPO Batch Consumption Time: 0.09577
Total Iteration Time: 9.88645

Cumulative Model Updates: 17,700
Cumulative Timesteps: 295,500,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 295500760...
Checkpoint 295500760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,475.36423
Policy Entropy: 0.60617
Value Function Loss: 0.06049

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.03211
Policy Update Magnitude: 0.02807
Value Function Update Magnitude: 0.03120

Collected Steps per Second: 5,739.90841
Overall Steps per Second: 5,068.57589

Timestep Collection Time: 8.71477
Timestep Consumption Time: 1.15427
PPO Batch Consumption Time: 0.10648
Total Iteration Time: 9.86904

Cumulative Model Updates: 17,703
Cumulative Timesteps: 295,550,782

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,655.06616
Policy Entropy: 0.60598
Value Function Loss: 0.06334

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04816
Policy Update Magnitude: 0.02582
Value Function Update Magnitude: 0.03323

Collected Steps per Second: 8,586.10985
Overall Steps per Second: 7,364.80129

Timestep Collection Time: 5.82476
Timestep Consumption Time: 0.96592
PPO Batch Consumption Time: 0.06598
Total Iteration Time: 6.79068

Cumulative Model Updates: 17,706
Cumulative Timesteps: 295,600,794

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 295600794...
Checkpoint 295600794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,139.26158
Policy Entropy: 0.60964
Value Function Loss: 0.06240

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04583
Policy Update Magnitude: 0.02599
Value Function Update Magnitude: 0.03270

Collected Steps per Second: 5,761.60919
Overall Steps per Second: 5,105.44202

Timestep Collection Time: 8.68334
Timestep Consumption Time: 1.11601
PPO Batch Consumption Time: 0.10039
Total Iteration Time: 9.79935

Cumulative Model Updates: 17,709
Cumulative Timesteps: 295,650,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,543.94643
Policy Entropy: 0.61128
Value Function Loss: 0.05901

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.06071
Policy Update Magnitude: 0.02503
Value Function Update Magnitude: 0.03216

Collected Steps per Second: 10,470.98629
Overall Steps per Second: 8,416.90217

Timestep Collection Time: 4.77682
Timestep Consumption Time: 1.16575
PPO Batch Consumption Time: 0.09959
Total Iteration Time: 5.94257

Cumulative Model Updates: 17,712
Cumulative Timesteps: 295,700,842

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 295700842...
Checkpoint 295700842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,100.25109
Policy Entropy: 0.61202
Value Function Loss: 0.06080

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03983
Policy Update Magnitude: 0.02408
Value Function Update Magnitude: 0.03289

Collected Steps per Second: 5,270.08407
Overall Steps per Second: 4,723.28570

Timestep Collection Time: 9.49435
Timestep Consumption Time: 1.09913
PPO Batch Consumption Time: 0.10189
Total Iteration Time: 10.59347

Cumulative Model Updates: 17,715
Cumulative Timesteps: 295,750,878

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,017.30157
Policy Entropy: 0.61299
Value Function Loss: 0.05825

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.05079
Policy Update Magnitude: 0.02982
Value Function Update Magnitude: 0.03431

Collected Steps per Second: 8,401.81056
Overall Steps per Second: 7,467.67605

Timestep Collection Time: 5.95634
Timestep Consumption Time: 0.74508
PPO Batch Consumption Time: 0.04026
Total Iteration Time: 6.70142

Cumulative Model Updates: 17,718
Cumulative Timesteps: 295,800,922

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 295800922...
Checkpoint 295800922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,350.40742
Policy Entropy: 0.61643
Value Function Loss: 0.06136

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04299
Policy Update Magnitude: 0.02731
Value Function Update Magnitude: 0.03246

Collected Steps per Second: 7,132.38786
Overall Steps per Second: 6,222.78024

Timestep Collection Time: 7.01140
Timestep Consumption Time: 1.02488
PPO Batch Consumption Time: 0.04441
Total Iteration Time: 8.03628

Cumulative Model Updates: 17,721
Cumulative Timesteps: 295,850,930

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,051.26018
Policy Entropy: 0.61797
Value Function Loss: 0.06023

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.04227
Policy Update Magnitude: 0.02715
Value Function Update Magnitude: 0.03533

Collected Steps per Second: 13,220.15386
Overall Steps per Second: 10,887.64119

Timestep Collection Time: 3.78347
Timestep Consumption Time: 0.81055
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 4.59402

Cumulative Model Updates: 17,724
Cumulative Timesteps: 295,900,948

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 295900948...
Checkpoint 295900948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,907.53972
Policy Entropy: 0.61683
Value Function Loss: 0.06038

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.04414
Policy Update Magnitude: 0.02744
Value Function Update Magnitude: 0.03738

Collected Steps per Second: 10,074.27943
Overall Steps per Second: 8,800.73353

Timestep Collection Time: 4.96532
Timestep Consumption Time: 0.71853
PPO Batch Consumption Time: 0.03705
Total Iteration Time: 5.68384

Cumulative Model Updates: 17,727
Cumulative Timesteps: 295,950,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,887.56756
Policy Entropy: 0.61220
Value Function Loss: 0.05776

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.05287
Policy Update Magnitude: 0.02739
Value Function Update Magnitude: 0.03338

Collected Steps per Second: 11,652.35480
Overall Steps per Second: 9,729.79224

Timestep Collection Time: 4.29201
Timestep Consumption Time: 0.84808
PPO Batch Consumption Time: 0.04972
Total Iteration Time: 5.14009

Cumulative Model Updates: 17,730
Cumulative Timesteps: 296,000,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 296000982...
Checkpoint 296000982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,279.73946
Policy Entropy: 0.60463
Value Function Loss: 0.06343

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.03119
Policy Update Magnitude: 0.02660
Value Function Update Magnitude: 0.03420

Collected Steps per Second: 11,861.69128
Overall Steps per Second: 10,167.63895

Timestep Collection Time: 4.21542
Timestep Consumption Time: 0.70234
PPO Batch Consumption Time: 0.03601
Total Iteration Time: 4.91776

Cumulative Model Updates: 17,733
Cumulative Timesteps: 296,050,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,905.15544
Policy Entropy: 0.60443
Value Function Loss: 0.06913

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.02527
Value Function Update Magnitude: 0.03347

Collected Steps per Second: 16,705.02834
Overall Steps per Second: 12,167.21884

Timestep Collection Time: 2.99431
Timestep Consumption Time: 1.11674
PPO Batch Consumption Time: 0.10517
Total Iteration Time: 4.11105

Cumulative Model Updates: 17,736
Cumulative Timesteps: 296,101,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 296101004...
Checkpoint 296101004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,086.02735
Policy Entropy: 0.59971
Value Function Loss: 0.06992

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.02514
Value Function Update Magnitude: 0.03545

Collected Steps per Second: 12,721.49277
Overall Steps per Second: 10,601.78767

Timestep Collection Time: 3.93083
Timestep Consumption Time: 0.78592
PPO Batch Consumption Time: 0.03813
Total Iteration Time: 4.71675

Cumulative Model Updates: 17,739
Cumulative Timesteps: 296,151,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,130.88816
Policy Entropy: 0.60130
Value Function Loss: 0.06866

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03475
Policy Update Magnitude: 0.02687
Value Function Update Magnitude: 0.03530

Collected Steps per Second: 12,832.70117
Overall Steps per Second: 10,553.37479

Timestep Collection Time: 3.89832
Timestep Consumption Time: 0.84196
PPO Batch Consumption Time: 0.05899
Total Iteration Time: 4.74028

Cumulative Model Updates: 17,742
Cumulative Timesteps: 296,201,036

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 296201036...
Checkpoint 296201036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,498.93980
Policy Entropy: 0.59680
Value Function Loss: 0.06150

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06684
Policy Update Magnitude: 0.02742
Value Function Update Magnitude: 0.03969

Collected Steps per Second: 17,458.10678
Overall Steps per Second: 13,698.62488

Timestep Collection Time: 2.86423
Timestep Consumption Time: 0.78607
PPO Batch Consumption Time: 0.03778
Total Iteration Time: 3.65029

Cumulative Model Updates: 17,745
Cumulative Timesteps: 296,251,040

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,649.14102
Policy Entropy: 0.59607
Value Function Loss: 0.06561

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.06707
Policy Update Magnitude: 0.02658
Value Function Update Magnitude: 0.03876

Collected Steps per Second: 16,958.60818
Overall Steps per Second: 12,468.90255

Timestep Collection Time: 2.94883
Timestep Consumption Time: 1.06179
PPO Batch Consumption Time: 0.10957
Total Iteration Time: 4.01062

Cumulative Model Updates: 17,748
Cumulative Timesteps: 296,301,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 296301048...
Checkpoint 296301048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,422.35653
Policy Entropy: 0.59755
Value Function Loss: 0.06221

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08507
Policy Update Magnitude: 0.02702
Value Function Update Magnitude: 0.03812

Collected Steps per Second: 16,079.42781
Overall Steps per Second: 12,721.13658

Timestep Collection Time: 3.11019
Timestep Consumption Time: 0.82107
PPO Batch Consumption Time: 0.03882
Total Iteration Time: 3.93125

Cumulative Model Updates: 17,751
Cumulative Timesteps: 296,351,058

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,287.60022
Policy Entropy: 0.59719
Value Function Loss: 0.06065

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.04929
Policy Update Magnitude: 0.03414
Value Function Update Magnitude: 0.03804

Collected Steps per Second: 17,193.16584
Overall Steps per Second: 13,278.79828

Timestep Collection Time: 2.90976
Timestep Consumption Time: 0.85775
PPO Batch Consumption Time: 0.04913
Total Iteration Time: 3.76751

Cumulative Model Updates: 17,754
Cumulative Timesteps: 296,401,086

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 296401086...
Checkpoint 296401086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,069.79128
Policy Entropy: 0.59409
Value Function Loss: 0.06095

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07475
Policy Update Magnitude: 0.03743
Value Function Update Magnitude: 0.04021

Collected Steps per Second: 16,761.24666
Overall Steps per Second: 13,154.14346

Timestep Collection Time: 2.98534
Timestep Consumption Time: 0.81863
PPO Batch Consumption Time: 0.03897
Total Iteration Time: 3.80397

Cumulative Model Updates: 17,757
Cumulative Timesteps: 296,451,124

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,081.62844
Policy Entropy: 0.59521
Value Function Loss: 0.06315

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05898
Policy Update Magnitude: 0.03992
Value Function Update Magnitude: 0.03532

Collected Steps per Second: 15,893.26115
Overall Steps per Second: 11,726.48091

Timestep Collection Time: 3.14649
Timestep Consumption Time: 1.11805
PPO Batch Consumption Time: 0.11100
Total Iteration Time: 4.26454

Cumulative Model Updates: 17,760
Cumulative Timesteps: 296,501,132

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 296501132...
Checkpoint 296501132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,086.21915
Policy Entropy: 0.59325
Value Function Loss: 0.06544

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.08733
Policy Update Magnitude: 0.03889
Value Function Update Magnitude: 0.03207

Collected Steps per Second: 12,477.73800
Overall Steps per Second: 9,861.33211

Timestep Collection Time: 4.01098
Timestep Consumption Time: 1.06419
PPO Batch Consumption Time: 0.10414
Total Iteration Time: 5.07518

Cumulative Model Updates: 17,763
Cumulative Timesteps: 296,551,180

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,291.48899
Policy Entropy: 0.59417
Value Function Loss: 0.06651

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.08041
Policy Update Magnitude: 0.03290
Value Function Update Magnitude: 0.03257

Collected Steps per Second: 14,683.13432
Overall Steps per Second: 11,868.84898

Timestep Collection Time: 3.40663
Timestep Consumption Time: 0.80776
PPO Batch Consumption Time: 0.04248
Total Iteration Time: 4.21439

Cumulative Model Updates: 17,766
Cumulative Timesteps: 296,601,200

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 296601200...
Checkpoint 296601200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,364.22638
Policy Entropy: 0.59486
Value Function Loss: 0.06959

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.02910
Value Function Update Magnitude: 0.03593

Collected Steps per Second: 16,663.55702
Overall Steps per Second: 13,094.88594

Timestep Collection Time: 3.00248
Timestep Consumption Time: 0.81825
PPO Batch Consumption Time: 0.03770
Total Iteration Time: 3.82073

Cumulative Model Updates: 17,769
Cumulative Timesteps: 296,651,232

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,606.72136
Policy Entropy: 0.58795
Value Function Loss: 0.07194

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09655
Policy Update Magnitude: 0.02619
Value Function Update Magnitude: 0.03715

Collected Steps per Second: 16,237.06729
Overall Steps per Second: 12,491.52713

Timestep Collection Time: 3.07999
Timestep Consumption Time: 0.92352
PPO Batch Consumption Time: 0.06420
Total Iteration Time: 4.00351

Cumulative Model Updates: 17,772
Cumulative Timesteps: 296,701,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 296701242...
Checkpoint 296701242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,267.83198
Policy Entropy: 0.59789
Value Function Loss: 0.06741

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07435
Policy Update Magnitude: 0.02527
Value Function Update Magnitude: 0.03864

Collected Steps per Second: 15,974.16645
Overall Steps per Second: 12,695.86056

Timestep Collection Time: 3.13156
Timestep Consumption Time: 0.80863
PPO Batch Consumption Time: 0.03704
Total Iteration Time: 3.94018

Cumulative Model Updates: 17,775
Cumulative Timesteps: 296,751,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,824.08114
Policy Entropy: 0.59894
Value Function Loss: 0.06075

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.06502
Policy Update Magnitude: 0.02511
Value Function Update Magnitude: 0.03203

Collected Steps per Second: 17,216.46118
Overall Steps per Second: 13,378.96476

Timestep Collection Time: 2.90455
Timestep Consumption Time: 0.83311
PPO Batch Consumption Time: 0.04831
Total Iteration Time: 3.73766

Cumulative Model Updates: 17,778
Cumulative Timesteps: 296,801,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 296801272...
Checkpoint 296801272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,756.88833
Policy Entropy: 0.59764
Value Function Loss: 0.06459

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07234
Policy Update Magnitude: 0.02736
Value Function Update Magnitude: 0.03312

Collected Steps per Second: 17,134.39354
Overall Steps per Second: 13,293.60976

Timestep Collection Time: 2.92068
Timestep Consumption Time: 0.84384
PPO Batch Consumption Time: 0.05450
Total Iteration Time: 3.76452

Cumulative Model Updates: 17,781
Cumulative Timesteps: 296,851,316

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,541.87476
Policy Entropy: 0.59025
Value Function Loss: 0.06998

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.02935
Value Function Update Magnitude: 0.03063

Collected Steps per Second: 17,673.36253
Overall Steps per Second: 13,872.04456

Timestep Collection Time: 2.82980
Timestep Consumption Time: 0.77544
PPO Batch Consumption Time: 0.03863
Total Iteration Time: 3.60524

Cumulative Model Updates: 17,784
Cumulative Timesteps: 296,901,328

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 296901328...
Checkpoint 296901328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,564.52749
Policy Entropy: 0.59175
Value Function Loss: 0.07134

Mean KL Divergence: 0.00764
SB3 Clip Fraction: 0.07989
Policy Update Magnitude: 0.03293
Value Function Update Magnitude: 0.03039

Collected Steps per Second: 16,553.04511
Overall Steps per Second: 13,269.63097

Timestep Collection Time: 3.02180
Timestep Consumption Time: 0.74771
PPO Batch Consumption Time: 0.05431
Total Iteration Time: 3.76951

Cumulative Model Updates: 17,787
Cumulative Timesteps: 296,951,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,728.65849
Policy Entropy: 0.58487
Value Function Loss: 0.06740

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.03152
Value Function Update Magnitude: 0.03149

Collected Steps per Second: 16,915.86611
Overall Steps per Second: 13,518.86744

Timestep Collection Time: 2.95616
Timestep Consumption Time: 0.74282
PPO Batch Consumption Time: 0.04341
Total Iteration Time: 3.69898

Cumulative Model Updates: 17,790
Cumulative Timesteps: 297,001,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 297001354...
Checkpoint 297001354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,735.02769
Policy Entropy: 0.58874
Value Function Loss: 0.06529

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.10467
Policy Update Magnitude: 0.03125
Value Function Update Magnitude: 0.03254

Collected Steps per Second: 16,878.66324
Overall Steps per Second: 13,588.39069

Timestep Collection Time: 2.96232
Timestep Consumption Time: 0.71729
PPO Batch Consumption Time: 0.03752
Total Iteration Time: 3.67961

Cumulative Model Updates: 17,793
Cumulative Timesteps: 297,051,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,694.44620
Policy Entropy: 0.58380
Value Function Loss: 0.05976

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.08473
Policy Update Magnitude: 0.03197
Value Function Update Magnitude: 0.02983

Collected Steps per Second: 17,659.70890
Overall Steps per Second: 13,538.32168

Timestep Collection Time: 2.83142
Timestep Consumption Time: 0.86195
PPO Batch Consumption Time: 0.06560
Total Iteration Time: 3.69337

Cumulative Model Updates: 17,796
Cumulative Timesteps: 297,101,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 297101356...
Checkpoint 297101356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,162.93114
Policy Entropy: 0.58436
Value Function Loss: 0.06706

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06921
Policy Update Magnitude: 0.03457
Value Function Update Magnitude: 0.02942

Collected Steps per Second: 17,824.54949
Overall Steps per Second: 13,802.54021

Timestep Collection Time: 2.80546
Timestep Consumption Time: 0.81750
PPO Batch Consumption Time: 0.05835
Total Iteration Time: 3.62296

Cumulative Model Updates: 17,799
Cumulative Timesteps: 297,151,362

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,288.11209
Policy Entropy: 0.57960
Value Function Loss: 0.06191

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.05305
Policy Update Magnitude: 0.03486
Value Function Update Magnitude: 0.03001

Collected Steps per Second: 17,937.81662
Overall Steps per Second: 14,176.95994

Timestep Collection Time: 2.78875
Timestep Consumption Time: 0.73980
PPO Batch Consumption Time: 0.03758
Total Iteration Time: 3.52854

Cumulative Model Updates: 17,802
Cumulative Timesteps: 297,201,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 297201386...
Checkpoint 297201386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,056.74942
Policy Entropy: 0.58287
Value Function Loss: 0.06850

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.05211
Policy Update Magnitude: 0.03342
Value Function Update Magnitude: 0.03233

Collected Steps per Second: 17,057.59111
Overall Steps per Second: 13,496.31247

Timestep Collection Time: 2.93277
Timestep Consumption Time: 0.77387
PPO Batch Consumption Time: 0.04239
Total Iteration Time: 3.70664

Cumulative Model Updates: 17,805
Cumulative Timesteps: 297,251,412

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,858.38443
Policy Entropy: 0.58493
Value Function Loss: 0.06510

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03539
Policy Update Magnitude: 0.03372
Value Function Update Magnitude: 0.03555

Collected Steps per Second: 17,417.74251
Overall Steps per Second: 13,372.66558

Timestep Collection Time: 2.87075
Timestep Consumption Time: 0.86837
PPO Batch Consumption Time: 0.05846
Total Iteration Time: 3.73912

Cumulative Model Updates: 17,808
Cumulative Timesteps: 297,301,414

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 297301414...
Checkpoint 297301414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,327.64981
Policy Entropy: 0.58699
Value Function Loss: 0.06698

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.04553
Policy Update Magnitude: 0.03324
Value Function Update Magnitude: 0.03754

Collected Steps per Second: 16,583.44981
Overall Steps per Second: 13,002.31621

Timestep Collection Time: 3.01505
Timestep Consumption Time: 0.83041
PPO Batch Consumption Time: 0.04440
Total Iteration Time: 3.84547

Cumulative Model Updates: 17,811
Cumulative Timesteps: 297,351,414

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,102.16127
Policy Entropy: 0.58801
Value Function Loss: 0.06374

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.03703
Policy Update Magnitude: 0.02908
Value Function Update Magnitude: 0.03427

Collected Steps per Second: 14,667.51550
Overall Steps per Second: 11,501.71132

Timestep Collection Time: 3.41080
Timestep Consumption Time: 0.93881
PPO Batch Consumption Time: 0.03719
Total Iteration Time: 4.34961

Cumulative Model Updates: 17,814
Cumulative Timesteps: 297,401,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 297401442...
Checkpoint 297401442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,760.54357
Policy Entropy: 0.59390
Value Function Loss: 0.06113

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.04357
Policy Update Magnitude: 0.02816
Value Function Update Magnitude: 0.03582

Collected Steps per Second: 12,750.95508
Overall Steps per Second: 9,915.41113

Timestep Collection Time: 3.92253
Timestep Consumption Time: 1.12174
PPO Batch Consumption Time: 0.10935
Total Iteration Time: 5.04427

Cumulative Model Updates: 17,817
Cumulative Timesteps: 297,451,458

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,515.77075
Policy Entropy: 0.59180
Value Function Loss: 0.05872

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.05730
Policy Update Magnitude: 0.02817
Value Function Update Magnitude: 0.03358

Collected Steps per Second: 9,762.99199
Overall Steps per Second: 8,474.59091

Timestep Collection Time: 5.12425
Timestep Consumption Time: 0.77905
PPO Batch Consumption Time: 0.03525
Total Iteration Time: 5.90329

Cumulative Model Updates: 17,820
Cumulative Timesteps: 297,501,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 297501486...
Checkpoint 297501486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,210.05355
Policy Entropy: 0.58532
Value Function Loss: 0.05607

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.05437
Policy Update Magnitude: 0.02689
Value Function Update Magnitude: 0.03100

Collected Steps per Second: 15,246.21987
Overall Steps per Second: 12,023.42372

Timestep Collection Time: 3.28239
Timestep Consumption Time: 0.87982
PPO Batch Consumption Time: 0.05983
Total Iteration Time: 4.16221

Cumulative Model Updates: 17,823
Cumulative Timesteps: 297,551,530

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,785.82427
Policy Entropy: 0.58400
Value Function Loss: 0.05348

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03763
Policy Update Magnitude: 0.02590
Value Function Update Magnitude: 0.02924

Collected Steps per Second: 13,684.26643
Overall Steps per Second: 11,254.24073

Timestep Collection Time: 3.65485
Timestep Consumption Time: 0.78916
PPO Batch Consumption Time: 0.03851
Total Iteration Time: 4.44401

Cumulative Model Updates: 17,826
Cumulative Timesteps: 297,601,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 297601544...
Checkpoint 297601544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,644.77145
Policy Entropy: 0.58406
Value Function Loss: 0.05561

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.04270
Policy Update Magnitude: 0.02665
Value Function Update Magnitude: 0.03015

Collected Steps per Second: 9,760.20354
Overall Steps per Second: 8,075.63023

Timestep Collection Time: 5.12305
Timestep Consumption Time: 1.06867
PPO Batch Consumption Time: 0.08539
Total Iteration Time: 6.19171

Cumulative Model Updates: 17,829
Cumulative Timesteps: 297,651,546

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,977.16678
Policy Entropy: 0.58629
Value Function Loss: 0.05857

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04740
Policy Update Magnitude: 0.02554
Value Function Update Magnitude: 0.03409

Collected Steps per Second: 10,958.68194
Overall Steps per Second: 8,905.99754

Timestep Collection Time: 4.56277
Timestep Consumption Time: 1.05164
PPO Batch Consumption Time: 0.08367
Total Iteration Time: 5.61442

Cumulative Model Updates: 17,832
Cumulative Timesteps: 297,701,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 297701548...
Checkpoint 297701548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,324.80968
Policy Entropy: 0.58517
Value Function Loss: 0.06324

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03379
Policy Update Magnitude: 0.02791
Value Function Update Magnitude: 0.03972

Collected Steps per Second: 11,567.59096
Overall Steps per Second: 9,384.90994

Timestep Collection Time: 4.32605
Timestep Consumption Time: 1.00612
PPO Batch Consumption Time: 0.08101
Total Iteration Time: 5.33218

Cumulative Model Updates: 17,835
Cumulative Timesteps: 297,751,590

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,925.79646
Policy Entropy: 0.58273
Value Function Loss: 0.06147

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03410
Policy Update Magnitude: 0.03042
Value Function Update Magnitude: 0.03465

Collected Steps per Second: 8,294.48173
Overall Steps per Second: 7,080.54659

Timestep Collection Time: 6.03027
Timestep Consumption Time: 1.03387
PPO Batch Consumption Time: 0.08380
Total Iteration Time: 7.06414

Cumulative Model Updates: 17,838
Cumulative Timesteps: 297,801,608

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 297801608...
Checkpoint 297801608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,687.38978
Policy Entropy: 0.58310
Value Function Loss: 0.06325

Mean KL Divergence: 0.00186
SB3 Clip Fraction: 0.02138
Policy Update Magnitude: 0.03014
Value Function Update Magnitude: 0.03795

Collected Steps per Second: 5,982.14875
Overall Steps per Second: 5,478.47887

Timestep Collection Time: 8.36154
Timestep Consumption Time: 0.76873
PPO Batch Consumption Time: 0.03600
Total Iteration Time: 9.13027

Cumulative Model Updates: 17,841
Cumulative Timesteps: 297,851,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,360.29908
Policy Entropy: 0.58444
Value Function Loss: 0.06297

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.03116
Value Function Update Magnitude: 0.03495

Collected Steps per Second: 9,479.44718
Overall Steps per Second: 7,933.72892

Timestep Collection Time: 5.27562
Timestep Consumption Time: 1.02784
PPO Batch Consumption Time: 0.10864
Total Iteration Time: 6.30347

Cumulative Model Updates: 17,844
Cumulative Timesteps: 297,901,638

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 297901638...
Checkpoint 297901638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,615.12496
Policy Entropy: 0.58648
Value Function Loss: 0.06514

Mean KL Divergence: 0.00167
SB3 Clip Fraction: 0.01768
Policy Update Magnitude: 0.03238
Value Function Update Magnitude: 0.03715

Collected Steps per Second: 6,309.15328
Overall Steps per Second: 5,593.48357

Timestep Collection Time: 7.92848
Timestep Consumption Time: 1.01443
PPO Batch Consumption Time: 0.09843
Total Iteration Time: 8.94291

Cumulative Model Updates: 17,847
Cumulative Timesteps: 297,951,660

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,560.50753
Policy Entropy: 0.59248
Value Function Loss: 0.06794

Mean KL Divergence: 0.00157
SB3 Clip Fraction: 0.01697
Policy Update Magnitude: 0.03524
Value Function Update Magnitude: 0.03892

Collected Steps per Second: 6,372.62958
Overall Steps per Second: 5,628.97636

Timestep Collection Time: 7.84637
Timestep Consumption Time: 1.03660
PPO Batch Consumption Time: 0.10853
Total Iteration Time: 8.88296

Cumulative Model Updates: 17,850
Cumulative Timesteps: 298,001,662

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 298001662...
Checkpoint 298001662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,989.69570
Policy Entropy: 0.59393
Value Function Loss: 0.06399

Mean KL Divergence: 0.00176
SB3 Clip Fraction: 0.01790
Policy Update Magnitude: 0.03224
Value Function Update Magnitude: 0.03679

Collected Steps per Second: 5,678.00160
Overall Steps per Second: 5,033.05266

Timestep Collection Time: 8.80979
Timestep Consumption Time: 1.12891
PPO Batch Consumption Time: 0.11127
Total Iteration Time: 9.93870

Cumulative Model Updates: 17,853
Cumulative Timesteps: 298,051,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,228.84505
Policy Entropy: 0.59388
Value Function Loss: 0.06092

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.01915
Policy Update Magnitude: 0.02938
Value Function Update Magnitude: 0.03287

Collected Steps per Second: 5,395.09054
Overall Steps per Second: 4,812.95600

Timestep Collection Time: 9.26991
Timestep Consumption Time: 1.12121
PPO Batch Consumption Time: 0.11158
Total Iteration Time: 10.39112

Cumulative Model Updates: 17,856
Cumulative Timesteps: 298,101,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 298101696...
Checkpoint 298101696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,989.09498
Policy Entropy: 0.59049
Value Function Loss: 0.05884

Mean KL Divergence: 0.00189
SB3 Clip Fraction: 0.02221
Policy Update Magnitude: 0.02624
Value Function Update Magnitude: 0.03600

Collected Steps per Second: 5,733.90084
Overall Steps per Second: 5,095.44389

Timestep Collection Time: 8.72076
Timestep Consumption Time: 1.09271
PPO Batch Consumption Time: 0.10656
Total Iteration Time: 9.81347

Cumulative Model Updates: 17,859
Cumulative Timesteps: 298,151,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,253.84797
Policy Entropy: 0.59110
Value Function Loss: 0.06118

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.02514
Value Function Update Magnitude: 0.03851

Collected Steps per Second: 8,227.75838
Overall Steps per Second: 6,965.44455

Timestep Collection Time: 6.07748
Timestep Consumption Time: 1.10139
PPO Batch Consumption Time: 0.10729
Total Iteration Time: 7.17887

Cumulative Model Updates: 17,862
Cumulative Timesteps: 298,201,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 298201704...
Checkpoint 298201704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,295.26085
Policy Entropy: 0.59221
Value Function Loss: 0.06044

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.02890
Value Function Update Magnitude: 0.04078

Collected Steps per Second: 8,454.31037
Overall Steps per Second: 7,176.09540

Timestep Collection Time: 5.91580
Timestep Consumption Time: 1.05373
PPO Batch Consumption Time: 0.10747
Total Iteration Time: 6.96953

Cumulative Model Updates: 17,865
Cumulative Timesteps: 298,251,718

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,145.55540
Policy Entropy: 0.59332
Value Function Loss: 0.05964

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.01894
Policy Update Magnitude: 0.02563
Value Function Update Magnitude: 0.04772

Collected Steps per Second: 5,844.62000
Overall Steps per Second: 5,173.57116

Timestep Collection Time: 8.55590
Timestep Consumption Time: 1.10976
PPO Batch Consumption Time: 0.10714
Total Iteration Time: 9.66566

Cumulative Model Updates: 17,868
Cumulative Timesteps: 298,301,724

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 298301724...
Checkpoint 298301724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,702.66005
Policy Entropy: 0.59161
Value Function Loss: 0.05798

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.03501
Policy Update Magnitude: 0.02241
Value Function Update Magnitude: 0.04099

Collected Steps per Second: 5,651.08064
Overall Steps per Second: 5,015.44856

Timestep Collection Time: 8.85388
Timestep Consumption Time: 1.12210
PPO Batch Consumption Time: 0.10339
Total Iteration Time: 9.97598

Cumulative Model Updates: 17,871
Cumulative Timesteps: 298,351,758

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,680.11163
Policy Entropy: 0.58794
Value Function Loss: 0.05521

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01742
Policy Update Magnitude: 0.02292
Value Function Update Magnitude: 0.04913

Collected Steps per Second: 6,091.10569
Overall Steps per Second: 5,382.63231

Timestep Collection Time: 8.21099
Timestep Consumption Time: 1.08075
PPO Batch Consumption Time: 0.09229
Total Iteration Time: 9.29174

Cumulative Model Updates: 17,874
Cumulative Timesteps: 298,401,772

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 298401772...
Checkpoint 298401772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,847.82753
Policy Entropy: 0.59212
Value Function Loss: 0.04552

Mean KL Divergence: 0.00269
SB3 Clip Fraction: 0.03348
Policy Update Magnitude: 0.02383
Value Function Update Magnitude: 0.05352

Collected Steps per Second: 9,521.83041
Overall Steps per Second: 7,859.77308

Timestep Collection Time: 5.25487
Timestep Consumption Time: 1.11122
PPO Batch Consumption Time: 0.09846
Total Iteration Time: 6.36609

Cumulative Model Updates: 17,877
Cumulative Timesteps: 298,451,808

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,066.00888
Policy Entropy: 0.58934
Value Function Loss: 0.05304

Mean KL Divergence: 0.00219
SB3 Clip Fraction: 0.02636
Policy Update Magnitude: 0.02151
Value Function Update Magnitude: 0.04699

Collected Steps per Second: 7,176.69627
Overall Steps per Second: 6,282.59460

Timestep Collection Time: 6.96867
Timestep Consumption Time: 0.99174
PPO Batch Consumption Time: 0.07493
Total Iteration Time: 7.96041

Cumulative Model Updates: 17,880
Cumulative Timesteps: 298,501,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 298501820...
Checkpoint 298501820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,739.14528
Policy Entropy: 0.58738
Value Function Loss: 0.05746

Mean KL Divergence: 0.00240
SB3 Clip Fraction: 0.02877
Policy Update Magnitude: 0.02328
Value Function Update Magnitude: 0.04888

Collected Steps per Second: 6,607.26837
Overall Steps per Second: 5,749.98367

Timestep Collection Time: 7.56894
Timestep Consumption Time: 1.12848
PPO Batch Consumption Time: 0.10328
Total Iteration Time: 8.69742

Cumulative Model Updates: 17,883
Cumulative Timesteps: 298,551,830

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,425.30941
Policy Entropy: 0.58112
Value Function Loss: 0.06833

Mean KL Divergence: 0.00214
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.02376
Value Function Update Magnitude: 0.05624

Collected Steps per Second: 7,081.08609
Overall Steps per Second: 6,121.35582

Timestep Collection Time: 7.06700
Timestep Consumption Time: 1.10799
PPO Batch Consumption Time: 0.09253
Total Iteration Time: 8.17499

Cumulative Model Updates: 17,886
Cumulative Timesteps: 298,601,872

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 298601872...
Checkpoint 298601872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,962.10879
Policy Entropy: 0.58490
Value Function Loss: 0.06666

Mean KL Divergence: 0.00224
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.02943
Value Function Update Magnitude: 0.05360

Collected Steps per Second: 7,453.00965
Overall Steps per Second: 6,409.80676

Timestep Collection Time: 6.71031
Timestep Consumption Time: 1.09211
PPO Batch Consumption Time: 0.10101
Total Iteration Time: 7.80242

Cumulative Model Updates: 17,889
Cumulative Timesteps: 298,651,884

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,399.95222
Policy Entropy: 0.59030
Value Function Loss: 0.06032

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.04001
Policy Update Magnitude: 0.03234
Value Function Update Magnitude: 0.04605

Collected Steps per Second: 6,119.47609
Overall Steps per Second: 5,426.53915

Timestep Collection Time: 8.17717
Timestep Consumption Time: 1.04418
PPO Batch Consumption Time: 0.09691
Total Iteration Time: 9.22135

Cumulative Model Updates: 17,892
Cumulative Timesteps: 298,701,924

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 298701924...
Checkpoint 298701924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,254.00554
Policy Entropy: 0.59680
Value Function Loss: 0.05545

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.03837
Policy Update Magnitude: 0.02771
Value Function Update Magnitude: 0.03868

Collected Steps per Second: 5,725.27458
Overall Steps per Second: 5,139.92834

Timestep Collection Time: 8.73705
Timestep Consumption Time: 0.99499
PPO Batch Consumption Time: 0.05165
Total Iteration Time: 9.73204

Cumulative Model Updates: 17,895
Cumulative Timesteps: 298,751,946

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,847.73107
Policy Entropy: 0.59016
Value Function Loss: 0.05677

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05720
Policy Update Magnitude: 0.02474
Value Function Update Magnitude: 0.03789

Collected Steps per Second: 6,916.89602
Overall Steps per Second: 6,043.86386

Timestep Collection Time: 7.22954
Timestep Consumption Time: 1.04430
PPO Batch Consumption Time: 0.08054
Total Iteration Time: 8.27385

Cumulative Model Updates: 17,898
Cumulative Timesteps: 298,801,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 298801952...
Checkpoint 298801952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,218.93710
Policy Entropy: 0.58528
Value Function Loss: 0.06977

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.04849
Policy Update Magnitude: 0.02697
Value Function Update Magnitude: 0.04523

Collected Steps per Second: 6,862.28860
Overall Steps per Second: 6,026.44268

Timestep Collection Time: 7.28649
Timestep Consumption Time: 1.01061
PPO Batch Consumption Time: 0.07436
Total Iteration Time: 8.29710

Cumulative Model Updates: 17,901
Cumulative Timesteps: 298,851,954

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,416.78992
Policy Entropy: 0.58130
Value Function Loss: 0.07402

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.05275
Policy Update Magnitude: 0.03064
Value Function Update Magnitude: 0.05083

Collected Steps per Second: 8,096.57756
Overall Steps per Second: 7,114.61275

Timestep Collection Time: 6.17990
Timestep Consumption Time: 0.85295
PPO Batch Consumption Time: 0.05014
Total Iteration Time: 7.03285

Cumulative Model Updates: 17,904
Cumulative Timesteps: 298,901,990

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 298901990...
Checkpoint 298901990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,401.16801
Policy Entropy: 0.58940
Value Function Loss: 0.06575

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.04801
Policy Update Magnitude: 0.03126
Value Function Update Magnitude: 0.05450

Collected Steps per Second: 9,940.91967
Overall Steps per Second: 8,542.72841

Timestep Collection Time: 5.03193
Timestep Consumption Time: 0.82358
PPO Batch Consumption Time: 0.05442
Total Iteration Time: 5.85551

Cumulative Model Updates: 17,907
Cumulative Timesteps: 298,952,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,979.51815
Policy Entropy: 0.58804
Value Function Loss: 0.06588

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06934
Policy Update Magnitude: 0.02893
Value Function Update Magnitude: 0.05762

Collected Steps per Second: 7,812.68256
Overall Steps per Second: 6,850.74182

Timestep Collection Time: 6.40190
Timestep Consumption Time: 0.89892
PPO Batch Consumption Time: 0.07029
Total Iteration Time: 7.30082

Cumulative Model Updates: 17,910
Cumulative Timesteps: 299,002,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 299002028...
Checkpoint 299002028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,253.76028
Policy Entropy: 0.58908
Value Function Loss: 0.06559

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.06216
Policy Update Magnitude: 0.02571
Value Function Update Magnitude: 0.05300

Collected Steps per Second: 10,558.70594
Overall Steps per Second: 8,801.96804

Timestep Collection Time: 4.73562
Timestep Consumption Time: 0.94516
PPO Batch Consumption Time: 0.07912
Total Iteration Time: 5.68077

Cumulative Model Updates: 17,913
Cumulative Timesteps: 299,052,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,095.15115
Policy Entropy: 0.58424
Value Function Loss: 0.06666

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05947
Policy Update Magnitude: 0.02574
Value Function Update Magnitude: 0.05447

Collected Steps per Second: 7,369.75968
Overall Steps per Second: 6,412.49629

Timestep Collection Time: 6.78638
Timestep Consumption Time: 1.01308
PPO Batch Consumption Time: 0.08214
Total Iteration Time: 7.79946

Cumulative Model Updates: 17,916
Cumulative Timesteps: 299,102,044

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 299102044...
Checkpoint 299102044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,718.21602
Policy Entropy: 0.59070
Value Function Loss: 0.06059

Mean KL Divergence: 0.00246
SB3 Clip Fraction: 0.02915
Policy Update Magnitude: 0.02604
Value Function Update Magnitude: 0.04318

Collected Steps per Second: 7,518.09012
Overall Steps per Second: 6,541.25520

Timestep Collection Time: 6.65222
Timestep Consumption Time: 0.99341
PPO Batch Consumption Time: 0.07425
Total Iteration Time: 7.64563

Cumulative Model Updates: 17,919
Cumulative Timesteps: 299,152,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,774.91659
Policy Entropy: 0.58737
Value Function Loss: 0.05613

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.05178
Policy Update Magnitude: 0.02498
Value Function Update Magnitude: 0.03393

Collected Steps per Second: 8,013.29184
Overall Steps per Second: 6,880.49220

Timestep Collection Time: 6.24263
Timestep Consumption Time: 1.02778
PPO Batch Consumption Time: 0.08171
Total Iteration Time: 7.27041

Cumulative Model Updates: 17,922
Cumulative Timesteps: 299,202,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 299202080...
Checkpoint 299202080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,289.61890
Policy Entropy: 0.58685
Value Function Loss: 0.06184

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.05399
Policy Update Magnitude: 0.02617
Value Function Update Magnitude: 0.03150

Collected Steps per Second: 5,614.32675
Overall Steps per Second: 5,022.38858

Timestep Collection Time: 8.90899
Timestep Consumption Time: 1.05001
PPO Batch Consumption Time: 0.07914
Total Iteration Time: 9.95901

Cumulative Model Updates: 17,925
Cumulative Timesteps: 299,252,098

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,572.19372
Policy Entropy: 0.59088
Value Function Loss: 0.05867

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04333
Policy Update Magnitude: 0.02535
Value Function Update Magnitude: 0.03805

Collected Steps per Second: 9,476.67383
Overall Steps per Second: 8,053.32773

Timestep Collection Time: 5.27759
Timestep Consumption Time: 0.93276
PPO Batch Consumption Time: 0.05079
Total Iteration Time: 6.21035

Cumulative Model Updates: 17,928
Cumulative Timesteps: 299,302,112

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 299302112...
Checkpoint 299302112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,508.97017
Policy Entropy: 0.59573
Value Function Loss: 0.05743

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.02481
Value Function Update Magnitude: 0.03772

Collected Steps per Second: 8,021.78382
Overall Steps per Second: 6,971.08754

Timestep Collection Time: 6.23652
Timestep Consumption Time: 0.93998
PPO Batch Consumption Time: 0.05622
Total Iteration Time: 7.17650

Cumulative Model Updates: 17,931
Cumulative Timesteps: 299,352,140

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,000.74458
Policy Entropy: 0.59525
Value Function Loss: 0.05976

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.02789
Policy Update Magnitude: 0.02548
Value Function Update Magnitude: 0.04266

Collected Steps per Second: 8,972.43685
Overall Steps per Second: 7,581.11495

Timestep Collection Time: 5.57663
Timestep Consumption Time: 1.02345
PPO Batch Consumption Time: 0.07829
Total Iteration Time: 6.60008

Cumulative Model Updates: 17,934
Cumulative Timesteps: 299,402,176

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 299402176...
Checkpoint 299402176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,251.00236
Policy Entropy: 0.59399
Value Function Loss: 0.06370

Mean KL Divergence: 0.00207
SB3 Clip Fraction: 0.02407
Policy Update Magnitude: 0.02507
Value Function Update Magnitude: 0.03402

Collected Steps per Second: 7,046.52817
Overall Steps per Second: 6,128.44561

Timestep Collection Time: 7.09654
Timestep Consumption Time: 1.06311
PPO Batch Consumption Time: 0.08025
Total Iteration Time: 8.15965

Cumulative Model Updates: 17,937
Cumulative Timesteps: 299,452,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,988.83766
Policy Entropy: 0.59282
Value Function Loss: 0.06989

Mean KL Divergence: 0.00187
SB3 Clip Fraction: 0.02013
Policy Update Magnitude: 0.02721
Value Function Update Magnitude: 0.04249

Collected Steps per Second: 6,995.00452
Overall Steps per Second: 6,128.56693

Timestep Collection Time: 7.15253
Timestep Consumption Time: 1.01120
PPO Batch Consumption Time: 0.08124
Total Iteration Time: 8.16374

Cumulative Model Updates: 17,940
Cumulative Timesteps: 299,502,214

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 299502214...
Checkpoint 299502214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,868.91528
Policy Entropy: 0.59395
Value Function Loss: 0.06716

Mean KL Divergence: 0.00213
SB3 Clip Fraction: 0.02393
Policy Update Magnitude: 0.02611
Value Function Update Magnitude: 0.03928

Collected Steps per Second: 8,754.50995
Overall Steps per Second: 7,385.44641

Timestep Collection Time: 5.71408
Timestep Consumption Time: 1.05924
PPO Batch Consumption Time: 0.08669
Total Iteration Time: 6.77332

Cumulative Model Updates: 17,943
Cumulative Timesteps: 299,552,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,264.15301
Policy Entropy: 0.59898
Value Function Loss: 0.06137

Mean KL Divergence: 0.00255
SB3 Clip Fraction: 0.03089
Policy Update Magnitude: 0.02642
Value Function Update Magnitude: 0.03694

Collected Steps per Second: 6,121.76345
Overall Steps per Second: 5,424.59049

Timestep Collection Time: 8.16889
Timestep Consumption Time: 1.04987
PPO Batch Consumption Time: 0.08279
Total Iteration Time: 9.21876

Cumulative Model Updates: 17,946
Cumulative Timesteps: 299,602,246

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 299602246...
Checkpoint 299602246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,664.95034
Policy Entropy: 0.59930
Value Function Loss: 0.05909

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03251
Policy Update Magnitude: 0.02811
Value Function Update Magnitude: 0.03583

Collected Steps per Second: 9,941.01886
Overall Steps per Second: 8,471.57246

Timestep Collection Time: 5.03329
Timestep Consumption Time: 0.87305
PPO Batch Consumption Time: 0.04278
Total Iteration Time: 5.90634

Cumulative Model Updates: 17,949
Cumulative Timesteps: 299,652,282

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,804.44874
Policy Entropy: 0.59780
Value Function Loss: 0.06503

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03788
Policy Update Magnitude: 0.02803
Value Function Update Magnitude: 0.03573

Collected Steps per Second: 16,238.69505
Overall Steps per Second: 12,652.09981

Timestep Collection Time: 3.08054
Timestep Consumption Time: 0.87327
PPO Batch Consumption Time: 0.05423
Total Iteration Time: 3.95381

Cumulative Model Updates: 17,952
Cumulative Timesteps: 299,702,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 299702306...
Checkpoint 299702306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,696.49971
Policy Entropy: 0.60000
Value Function Loss: 0.06413

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03417
Policy Update Magnitude: 0.02466
Value Function Update Magnitude: 0.03424

Collected Steps per Second: 16,191.38308
Overall Steps per Second: 12,551.66810

Timestep Collection Time: 3.08905
Timestep Consumption Time: 0.89576
PPO Batch Consumption Time: 0.05371
Total Iteration Time: 3.98481

Cumulative Model Updates: 17,955
Cumulative Timesteps: 299,752,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,650.81909
Policy Entropy: 0.59684
Value Function Loss: 0.06506

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.02157
Policy Update Magnitude: 0.02852
Value Function Update Magnitude: 0.03592

Collected Steps per Second: 9,972.82116
Overall Steps per Second: 8,167.95239

Timestep Collection Time: 5.01383
Timestep Consumption Time: 1.10790
PPO Batch Consumption Time: 0.09095
Total Iteration Time: 6.12173

Cumulative Model Updates: 17,958
Cumulative Timesteps: 299,802,324

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 299802324...
Checkpoint 299802324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,322.18978
Policy Entropy: 0.59657
Value Function Loss: 0.05891

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.03290
Policy Update Magnitude: 0.02761
Value Function Update Magnitude: 0.03633

Collected Steps per Second: 11,502.81970
Overall Steps per Second: 9,345.71229

Timestep Collection Time: 4.34676
Timestep Consumption Time: 1.00329
PPO Batch Consumption Time: 0.06565
Total Iteration Time: 5.35005

Cumulative Model Updates: 17,961
Cumulative Timesteps: 299,852,324

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,037.86691
Policy Entropy: 0.59684
Value Function Loss: 0.06376

Mean KL Divergence: 0.00209
SB3 Clip Fraction: 0.02445
Policy Update Magnitude: 0.02769
Value Function Update Magnitude: 0.03694

Collected Steps per Second: 9,662.99079
Overall Steps per Second: 8,129.44552

Timestep Collection Time: 5.17790
Timestep Consumption Time: 0.97676
PPO Batch Consumption Time: 0.08866
Total Iteration Time: 6.15466

Cumulative Model Updates: 17,964
Cumulative Timesteps: 299,902,358

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 299902358...
Checkpoint 299902358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,562.98227
Policy Entropy: 0.59186
Value Function Loss: 0.06871

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03497
Policy Update Magnitude: 0.02725
Value Function Update Magnitude: 0.03279

Collected Steps per Second: 9,922.77783
Overall Steps per Second: 8,592.72463

Timestep Collection Time: 5.04294
Timestep Consumption Time: 0.78059
PPO Batch Consumption Time: 0.06169
Total Iteration Time: 5.82353

Cumulative Model Updates: 17,967
Cumulative Timesteps: 299,952,398

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,589.48490
Policy Entropy: 0.59336
Value Function Loss: 0.06940

Mean KL Divergence: 0.00170
SB3 Clip Fraction: 0.01791
Policy Update Magnitude: 0.02585
Value Function Update Magnitude: 0.03375

Collected Steps per Second: 14,876.47032
Overall Steps per Second: 12,010.78636

Timestep Collection Time: 3.36128
Timestep Consumption Time: 0.80198
PPO Batch Consumption Time: 0.04212
Total Iteration Time: 4.16326

Cumulative Model Updates: 17,970
Cumulative Timesteps: 300,002,402

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 300002402...
Checkpoint 300002402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,246.99849
Policy Entropy: 0.59057
Value Function Loss: 0.07441

Mean KL Divergence: 0.00201
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.02353
Value Function Update Magnitude: 0.03452

Collected Steps per Second: 16,880.61161
Overall Steps per Second: 13,534.74921

Timestep Collection Time: 2.96304
Timestep Consumption Time: 0.73248
PPO Batch Consumption Time: 0.03917
Total Iteration Time: 3.69552

Cumulative Model Updates: 17,973
Cumulative Timesteps: 300,052,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,669.27626
Policy Entropy: 0.59218
Value Function Loss: 0.07539

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.01861
Policy Update Magnitude: 0.02392
Value Function Update Magnitude: 0.03356

Collected Steps per Second: 7,520.03689
Overall Steps per Second: 6,662.77217

Timestep Collection Time: 6.65289
Timestep Consumption Time: 0.85599
PPO Batch Consumption Time: 0.06687
Total Iteration Time: 7.50889

Cumulative Model Updates: 17,976
Cumulative Timesteps: 300,102,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 300102450...
Checkpoint 300102450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,003.96911
Policy Entropy: 0.59406
Value Function Loss: 0.07378

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02383
Policy Update Magnitude: 0.02713
Value Function Update Magnitude: 0.03058

Collected Steps per Second: 7,775.21807
Overall Steps per Second: 6,705.45225

Timestep Collection Time: 6.43069
Timestep Consumption Time: 1.02593
PPO Batch Consumption Time: 0.10200
Total Iteration Time: 7.45662

Cumulative Model Updates: 17,979
Cumulative Timesteps: 300,152,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,406.93883
Policy Entropy: 0.59614
Value Function Loss: 0.06450

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.04415
Policy Update Magnitude: 0.02695
Value Function Update Magnitude: 0.03467

Collected Steps per Second: 6,232.51218
Overall Steps per Second: 5,475.36829

Timestep Collection Time: 8.02501
Timestep Consumption Time: 1.10971
PPO Batch Consumption Time: 0.10350
Total Iteration Time: 9.13473

Cumulative Model Updates: 17,982
Cumulative Timesteps: 300,202,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 300202466...
Checkpoint 300202466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,990.33548
Policy Entropy: 0.60729
Value Function Loss: 0.05630

Mean KL Divergence: 0.00216
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.02502
Value Function Update Magnitude: 0.03158

Collected Steps per Second: 5,939.38856
Overall Steps per Second: 5,255.49287

Timestep Collection Time: 8.41871
Timestep Consumption Time: 1.09552
PPO Batch Consumption Time: 0.10008
Total Iteration Time: 9.51424

Cumulative Model Updates: 17,985
Cumulative Timesteps: 300,252,468

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,287.70191
Policy Entropy: 0.60413
Value Function Loss: 0.05872

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.02538
Value Function Update Magnitude: 0.03342

Collected Steps per Second: 9,906.61125
Overall Steps per Second: 8,461.19739

Timestep Collection Time: 5.04794
Timestep Consumption Time: 0.86233
PPO Batch Consumption Time: 0.04328
Total Iteration Time: 5.91027

Cumulative Model Updates: 17,988
Cumulative Timesteps: 300,302,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 300302476...
Checkpoint 300302476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,992.58052
Policy Entropy: 0.60653
Value Function Loss: 0.05737

Mean KL Divergence: 0.00174
SB3 Clip Fraction: 0.01781
Policy Update Magnitude: 0.02752
Value Function Update Magnitude: 0.03159

Collected Steps per Second: 15,286.38469
Overall Steps per Second: 11,980.56245

Timestep Collection Time: 3.27206
Timestep Consumption Time: 0.90287
PPO Batch Consumption Time: 0.04354
Total Iteration Time: 4.17493

Cumulative Model Updates: 17,991
Cumulative Timesteps: 300,352,494

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,947.59021
Policy Entropy: 0.60643
Value Function Loss: 0.05477

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.02583
Value Function Update Magnitude: 0.03016

Collected Steps per Second: 16,374.38404
Overall Steps per Second: 12,667.50673

Timestep Collection Time: 3.05624
Timestep Consumption Time: 0.89434
PPO Batch Consumption Time: 0.06191
Total Iteration Time: 3.95058

Cumulative Model Updates: 17,994
Cumulative Timesteps: 300,402,538

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 300402538...
Checkpoint 300402538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,522.89725
Policy Entropy: 0.60495
Value Function Loss: 0.05393

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.03463
Policy Update Magnitude: 0.02348
Value Function Update Magnitude: 0.02937

Collected Steps per Second: 9,645.31817
Overall Steps per Second: 7,936.30328

Timestep Collection Time: 5.18511
Timestep Consumption Time: 1.11657
PPO Batch Consumption Time: 0.10033
Total Iteration Time: 6.30167

Cumulative Model Updates: 17,997
Cumulative Timesteps: 300,452,550

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,733.38605
Policy Entropy: 0.59584
Value Function Loss: 0.05975

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.02392
Value Function Update Magnitude: 0.02980

Collected Steps per Second: 6,026.72653
Overall Steps per Second: 5,380.12408

Timestep Collection Time: 8.29837
Timestep Consumption Time: 0.99733
PPO Batch Consumption Time: 0.07123
Total Iteration Time: 9.29570

Cumulative Model Updates: 18,000
Cumulative Timesteps: 300,502,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 300502562...
Checkpoint 300502562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,410.07632
Policy Entropy: 0.59591
Value Function Loss: 0.06085

Mean KL Divergence: 0.00196
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.02623
Value Function Update Magnitude: 0.03188

Collected Steps per Second: 9,131.02362
Overall Steps per Second: 7,788.02052

Timestep Collection Time: 5.47956
Timestep Consumption Time: 0.94492
PPO Batch Consumption Time: 0.05516
Total Iteration Time: 6.42448

Cumulative Model Updates: 18,003
Cumulative Timesteps: 300,552,596

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,054.51468
Policy Entropy: 0.60260
Value Function Loss: 0.05740

Mean KL Divergence: 0.00134
SB3 Clip Fraction: 0.01281
Policy Update Magnitude: 0.02627
Value Function Update Magnitude: 0.03163

Collected Steps per Second: 7,245.05412
Overall Steps per Second: 6,280.00123

Timestep Collection Time: 6.90678
Timestep Consumption Time: 1.06137
PPO Batch Consumption Time: 0.08291
Total Iteration Time: 7.96815

Cumulative Model Updates: 18,006
Cumulative Timesteps: 300,602,636

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 300602636...
Checkpoint 300602636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,986.62809
Policy Entropy: 0.60650
Value Function Loss: 0.05607

Mean KL Divergence: 0.00183
SB3 Clip Fraction: 0.01943
Policy Update Magnitude: 0.02446
Value Function Update Magnitude: 0.03114

Collected Steps per Second: 7,808.69548
Overall Steps per Second: 6,888.72441

Timestep Collection Time: 6.40645
Timestep Consumption Time: 0.85556
PPO Batch Consumption Time: 0.04077
Total Iteration Time: 7.26201

Cumulative Model Updates: 18,009
Cumulative Timesteps: 300,652,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,694.84722
Policy Entropy: 0.60786
Value Function Loss: 0.06107

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.03110
Policy Update Magnitude: 0.02500
Value Function Update Magnitude: 0.03341

Collected Steps per Second: 14,630.07761
Overall Steps per Second: 11,672.82528

Timestep Collection Time: 3.41857
Timestep Consumption Time: 0.86608
PPO Batch Consumption Time: 0.04418
Total Iteration Time: 4.28465

Cumulative Model Updates: 18,012
Cumulative Timesteps: 300,702,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 300702676...
Checkpoint 300702676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,927.74617
Policy Entropy: 0.59783
Value Function Loss: 0.05999

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.03303
Policy Update Magnitude: 0.02705
Value Function Update Magnitude: 0.03304

Collected Steps per Second: 14,630.64211
Overall Steps per Second: 11,658.00693

Timestep Collection Time: 3.41803
Timestep Consumption Time: 0.87155
PPO Batch Consumption Time: 0.04338
Total Iteration Time: 4.28958

Cumulative Model Updates: 18,015
Cumulative Timesteps: 300,752,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,674.79989
Policy Entropy: 0.60027
Value Function Loss: 0.05815

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04861
Policy Update Magnitude: 0.02929
Value Function Update Magnitude: 0.02885

Collected Steps per Second: 14,927.02384
Overall Steps per Second: 11,657.53024

Timestep Collection Time: 3.35271
Timestep Consumption Time: 0.94031
PPO Batch Consumption Time: 0.06430
Total Iteration Time: 4.29302

Cumulative Model Updates: 18,018
Cumulative Timesteps: 300,802,730

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 300802730...
Checkpoint 300802730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,212.57377
Policy Entropy: 0.59845
Value Function Loss: 0.05302

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.03725
Policy Update Magnitude: 0.02786
Value Function Update Magnitude: 0.03034

Collected Steps per Second: 15,069.43150
Overall Steps per Second: 11,409.11153

Timestep Collection Time: 3.31798
Timestep Consumption Time: 1.06449
PPO Batch Consumption Time: 0.08821
Total Iteration Time: 4.38246

Cumulative Model Updates: 18,021
Cumulative Timesteps: 300,852,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,144.11449
Policy Entropy: 0.59458
Value Function Loss: 0.05716

Mean KL Divergence: 0.00241
SB3 Clip Fraction: 0.02972
Policy Update Magnitude: 0.02652
Value Function Update Magnitude: 0.02922

Collected Steps per Second: 8,328.05856
Overall Steps per Second: 7,169.21800

Timestep Collection Time: 6.00500
Timestep Consumption Time: 0.97066
PPO Batch Consumption Time: 0.05429
Total Iteration Time: 6.97566

Cumulative Model Updates: 18,024
Cumulative Timesteps: 300,902,740

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 300902740...
Checkpoint 300902740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,699.08473
Policy Entropy: 0.59793
Value Function Loss: 0.05429

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.02874
Value Function Update Magnitude: 0.02696

Collected Steps per Second: 6,729.81822
Overall Steps per Second: 5,862.61836

Timestep Collection Time: 7.43319
Timestep Consumption Time: 1.09952
PPO Batch Consumption Time: 0.08590
Total Iteration Time: 8.53271

Cumulative Model Updates: 18,027
Cumulative Timesteps: 300,952,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,315.98210
Policy Entropy: 0.59847
Value Function Loss: 0.05852

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.02943
Policy Update Magnitude: 0.02768
Value Function Update Magnitude: 0.03198

Collected Steps per Second: 5,965.01592
Overall Steps per Second: 5,271.93522

Timestep Collection Time: 8.38221
Timestep Consumption Time: 1.10198
PPO Batch Consumption Time: 0.08956
Total Iteration Time: 9.48418

Cumulative Model Updates: 18,030
Cumulative Timesteps: 301,002,764

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 301002764...
Checkpoint 301002764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,088.49528
Policy Entropy: 0.59352
Value Function Loss: 0.05904

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.01961
Policy Update Magnitude: 0.02550
Value Function Update Magnitude: 0.03221

Collected Steps per Second: 5,707.04081
Overall Steps per Second: 5,087.41781

Timestep Collection Time: 8.76636
Timestep Consumption Time: 1.06770
PPO Batch Consumption Time: 0.08728
Total Iteration Time: 9.83407

Cumulative Model Updates: 18,033
Cumulative Timesteps: 301,052,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,805.76898
Policy Entropy: 0.59486
Value Function Loss: 0.06026

Mean KL Divergence: 0.00172
SB3 Clip Fraction: 0.02019
Policy Update Magnitude: 0.02619
Value Function Update Magnitude: 0.02924

Collected Steps per Second: 10,023.88858
Overall Steps per Second: 8,257.61174

Timestep Collection Time: 4.99088
Timestep Consumption Time: 1.06753
PPO Batch Consumption Time: 0.08422
Total Iteration Time: 6.05841

Cumulative Model Updates: 18,036
Cumulative Timesteps: 301,102,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 301102822...
Checkpoint 301102822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,131.24377
Policy Entropy: 0.59814
Value Function Loss: 0.05878

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.03895
Policy Update Magnitude: 0.02575
Value Function Update Magnitude: 0.03057

Collected Steps per Second: 10,103.06227
Overall Steps per Second: 8,491.92573

Timestep Collection Time: 4.94919
Timestep Consumption Time: 0.93899
PPO Batch Consumption Time: 0.09141
Total Iteration Time: 5.88818

Cumulative Model Updates: 18,039
Cumulative Timesteps: 301,152,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,761.56959
Policy Entropy: 0.59763
Value Function Loss: 0.06031

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.03446
Policy Update Magnitude: 0.02422
Value Function Update Magnitude: 0.03257

Collected Steps per Second: 6,072.71110
Overall Steps per Second: 5,406.39373

Timestep Collection Time: 8.23619
Timestep Consumption Time: 1.01508
PPO Batch Consumption Time: 0.11010
Total Iteration Time: 9.25127

Cumulative Model Updates: 18,042
Cumulative Timesteps: 301,202,840

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 301202840...
Checkpoint 301202840 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,881.54586
Policy Entropy: 0.59489
Value Function Loss: 0.06834

Mean KL Divergence: 0.00252
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 0.02520
Value Function Update Magnitude: 0.03727

Collected Steps per Second: 6,080.93108
Overall Steps per Second: 5,407.81988

Timestep Collection Time: 8.22736
Timestep Consumption Time: 1.02406
PPO Batch Consumption Time: 0.10920
Total Iteration Time: 9.25142

Cumulative Model Updates: 18,045
Cumulative Timesteps: 301,252,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,342.94664
Policy Entropy: 0.59144
Value Function Loss: 0.06427

Mean KL Divergence: 0.00229
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.02615
Value Function Update Magnitude: 0.03786

Collected Steps per Second: 5,479.58955
Overall Steps per Second: 4,943.01003

Timestep Collection Time: 9.12587
Timestep Consumption Time: 0.99064
PPO Batch Consumption Time: 0.09908
Total Iteration Time: 10.11651

Cumulative Model Updates: 18,048
Cumulative Timesteps: 301,302,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 301302876...
Checkpoint 301302876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,165.43860
Policy Entropy: 0.59197
Value Function Loss: 0.06713

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.02611
Value Function Update Magnitude: 0.03390

Collected Steps per Second: 5,475.69189
Overall Steps per Second: 4,932.59596

Timestep Collection Time: 9.13163
Timestep Consumption Time: 1.00542
PPO Batch Consumption Time: 0.10043
Total Iteration Time: 10.13706

Cumulative Model Updates: 18,051
Cumulative Timesteps: 301,352,878

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,349.47127
Policy Entropy: 0.59286
Value Function Loss: 0.06217

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.03450
Policy Update Magnitude: 0.02490
Value Function Update Magnitude: 0.03313

Collected Steps per Second: 5,787.72942
Overall Steps per Second: 5,131.59604

Timestep Collection Time: 8.64311
Timestep Consumption Time: 1.10512
PPO Batch Consumption Time: 0.09834
Total Iteration Time: 9.74823

Cumulative Model Updates: 18,054
Cumulative Timesteps: 301,402,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 301402902...
Checkpoint 301402902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,445.43942
Policy Entropy: 0.58832
Value Function Loss: 0.06624

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 0.02559
Value Function Update Magnitude: 0.03200

Collected Steps per Second: 5,633.88045
Overall Steps per Second: 5,042.53444

Timestep Collection Time: 8.88198
Timestep Consumption Time: 1.04160
PPO Batch Consumption Time: 0.09606
Total Iteration Time: 9.92358

Cumulative Model Updates: 18,057
Cumulative Timesteps: 301,452,942

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,270.43399
Policy Entropy: 0.59121
Value Function Loss: 0.06282

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.04513
Policy Update Magnitude: 0.02549
Value Function Update Magnitude: 0.03367

Collected Steps per Second: 6,571.78619
Overall Steps per Second: 5,777.51052

Timestep Collection Time: 7.61406
Timestep Consumption Time: 1.04676
PPO Batch Consumption Time: 0.09355
Total Iteration Time: 8.66082

Cumulative Model Updates: 18,060
Cumulative Timesteps: 301,502,980

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 301502980...
Checkpoint 301502980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,180.33661
Policy Entropy: 0.60048
Value Function Loss: 0.05887

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.03564
Policy Update Magnitude: 0.02448
Value Function Update Magnitude: 0.03373

Collected Steps per Second: 5,742.57129
Overall Steps per Second: 5,125.97012

Timestep Collection Time: 8.70760
Timestep Consumption Time: 1.04743
PPO Batch Consumption Time: 0.09788
Total Iteration Time: 9.75503

Cumulative Model Updates: 18,063
Cumulative Timesteps: 301,552,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,946.62177
Policy Entropy: 0.60389
Value Function Loss: 0.06385

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.04701
Policy Update Magnitude: 0.02374
Value Function Update Magnitude: 0.03369

Collected Steps per Second: 6,184.08979
Overall Steps per Second: 5,445.88143

Timestep Collection Time: 8.08720
Timestep Consumption Time: 1.09625
PPO Batch Consumption Time: 0.10149
Total Iteration Time: 9.18345

Cumulative Model Updates: 18,066
Cumulative Timesteps: 301,602,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 301602996...
Checkpoint 301602996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,473.22053
Policy Entropy: 0.61206
Value Function Loss: 0.06829

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.02771
Policy Update Magnitude: 0.02389
Value Function Update Magnitude: 0.03460

Collected Steps per Second: 5,717.09516
Overall Steps per Second: 5,068.21685

Timestep Collection Time: 8.74885
Timestep Consumption Time: 1.12011
PPO Batch Consumption Time: 0.10144
Total Iteration Time: 9.86895

Cumulative Model Updates: 18,069
Cumulative Timesteps: 301,653,014

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,585.33656
Policy Entropy: 0.60755
Value Function Loss: 0.06795

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.04595
Policy Update Magnitude: 0.02511
Value Function Update Magnitude: 0.03354

Collected Steps per Second: 6,934.46627
Overall Steps per Second: 6,060.38387

Timestep Collection Time: 7.21123
Timestep Consumption Time: 1.04007
PPO Batch Consumption Time: 0.08562
Total Iteration Time: 8.25129

Cumulative Model Updates: 18,072
Cumulative Timesteps: 301,703,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 301703020...
Checkpoint 301703020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,295.39282
Policy Entropy: 0.60991
Value Function Loss: 0.06414

Mean KL Divergence: 0.00262
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 0.02802
Value Function Update Magnitude: 0.03774

Collected Steps per Second: 5,973.50676
Overall Steps per Second: 5,266.46279

Timestep Collection Time: 8.37029
Timestep Consumption Time: 1.12375
PPO Batch Consumption Time: 0.10068
Total Iteration Time: 9.49404

Cumulative Model Updates: 18,075
Cumulative Timesteps: 301,753,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,107.48262
Policy Entropy: 0.60538
Value Function Loss: 0.06016

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07539
Policy Update Magnitude: 0.02645
Value Function Update Magnitude: 0.03547

Collected Steps per Second: 6,586.46709
Overall Steps per Second: 5,713.01412

Timestep Collection Time: 7.59345
Timestep Consumption Time: 1.16095
PPO Batch Consumption Time: 0.09389
Total Iteration Time: 8.75440

Cumulative Model Updates: 18,078
Cumulative Timesteps: 301,803,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 301803034...
Checkpoint 301803034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,067.47690
Policy Entropy: 0.60974
Value Function Loss: 0.06114

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.06512
Policy Update Magnitude: 0.02413
Value Function Update Magnitude: 0.03294

Collected Steps per Second: 8,925.20180
Overall Steps per Second: 7,551.45585

Timestep Collection Time: 5.60256
Timestep Consumption Time: 1.01921
PPO Batch Consumption Time: 0.06852
Total Iteration Time: 6.62177

Cumulative Model Updates: 18,081
Cumulative Timesteps: 301,853,038

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,267.07203
Policy Entropy: 0.60988
Value Function Loss: 0.06191

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06846
Policy Update Magnitude: 0.02561
Value Function Update Magnitude: 0.03157

Collected Steps per Second: 7,097.16402
Overall Steps per Second: 6,200.21986

Timestep Collection Time: 7.04929
Timestep Consumption Time: 1.01977
PPO Batch Consumption Time: 0.08298
Total Iteration Time: 8.06907

Cumulative Model Updates: 18,084
Cumulative Timesteps: 301,903,068

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 301903068...
Checkpoint 301903068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,827.84910
Policy Entropy: 0.61441
Value Function Loss: 0.05967

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.04641
Policy Update Magnitude: 0.02334
Value Function Update Magnitude: 0.02846

Collected Steps per Second: 10,647.03337
Overall Steps per Second: 8,563.16695

Timestep Collection Time: 4.69727
Timestep Consumption Time: 1.14309
PPO Batch Consumption Time: 0.10734
Total Iteration Time: 5.84036

Cumulative Model Updates: 18,087
Cumulative Timesteps: 301,953,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,366.01999
Policy Entropy: 0.60640
Value Function Loss: 0.06294

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.05760
Policy Update Magnitude: 0.02422
Value Function Update Magnitude: 0.02746

Collected Steps per Second: 7,350.43344
Overall Steps per Second: 6,362.14561

Timestep Collection Time: 6.80776
Timestep Consumption Time: 1.05751
PPO Batch Consumption Time: 0.09176
Total Iteration Time: 7.86527

Cumulative Model Updates: 18,090
Cumulative Timesteps: 302,003,120

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 302003120...
Checkpoint 302003120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,786.88429
Policy Entropy: 0.60648
Value Function Loss: 0.06568

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.04560
Policy Update Magnitude: 0.02466
Value Function Update Magnitude: 0.02982

Collected Steps per Second: 5,620.61963
Overall Steps per Second: 4,991.17881

Timestep Collection Time: 8.90293
Timestep Consumption Time: 1.12275
PPO Batch Consumption Time: 0.10011
Total Iteration Time: 10.02569

Cumulative Model Updates: 18,093
Cumulative Timesteps: 302,053,160

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,182.06301
Policy Entropy: 0.59282
Value Function Loss: 0.06823

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.05539
Policy Update Magnitude: 0.02516
Value Function Update Magnitude: 0.03207

Collected Steps per Second: 5,261.30417
Overall Steps per Second: 4,714.86357

Timestep Collection Time: 9.50829
Timestep Consumption Time: 1.10199
PPO Batch Consumption Time: 0.10225
Total Iteration Time: 10.61028

Cumulative Model Updates: 18,096
Cumulative Timesteps: 302,103,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 302103186...
Checkpoint 302103186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,150.95524
Policy Entropy: 0.60061
Value Function Loss: 0.06525

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.03839
Policy Update Magnitude: 0.02827
Value Function Update Magnitude: 0.03012

Collected Steps per Second: 5,358.67097
Overall Steps per Second: 4,797.05577

Timestep Collection Time: 9.33104
Timestep Consumption Time: 1.09243
PPO Batch Consumption Time: 0.10555
Total Iteration Time: 10.42348

Cumulative Model Updates: 18,099
Cumulative Timesteps: 302,153,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,224.06098
Policy Entropy: 0.59965
Value Function Loss: 0.06884

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 0.02623
Value Function Update Magnitude: 0.03154

Collected Steps per Second: 6,410.58481
Overall Steps per Second: 5,568.24834

Timestep Collection Time: 7.80210
Timestep Consumption Time: 1.18026
PPO Batch Consumption Time: 0.10823
Total Iteration Time: 8.98236

Cumulative Model Updates: 18,102
Cumulative Timesteps: 302,203,204

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 302203204...
Checkpoint 302203204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,248.57483
Policy Entropy: 0.60530
Value Function Loss: 0.06752

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.06019
Policy Update Magnitude: 0.02398
Value Function Update Magnitude: 0.03111

Collected Steps per Second: 5,524.86700
Overall Steps per Second: 4,923.24557

Timestep Collection Time: 9.05615
Timestep Consumption Time: 1.10666
PPO Batch Consumption Time: 0.10408
Total Iteration Time: 10.16281

Cumulative Model Updates: 18,105
Cumulative Timesteps: 302,253,238

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,401.71303
Policy Entropy: 0.60772
Value Function Loss: 0.07057

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.05255
Policy Update Magnitude: 0.02650
Value Function Update Magnitude: 0.03214

Collected Steps per Second: 5,598.29958
Overall Steps per Second: 4,981.31087

Timestep Collection Time: 8.93628
Timestep Consumption Time: 1.10685
PPO Batch Consumption Time: 0.10114
Total Iteration Time: 10.04314

Cumulative Model Updates: 18,108
Cumulative Timesteps: 302,303,266

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 302303266...
Checkpoint 302303266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,697.39031
Policy Entropy: 0.60202
Value Function Loss: 0.06034

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.04410
Policy Update Magnitude: 0.02480
Value Function Update Magnitude: 0.03115

Collected Steps per Second: 5,683.77599
Overall Steps per Second: 5,038.81036

Timestep Collection Time: 8.80014
Timestep Consumption Time: 1.12641
PPO Batch Consumption Time: 0.09711
Total Iteration Time: 9.92655

Cumulative Model Updates: 18,111
Cumulative Timesteps: 302,353,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,183.43470
Policy Entropy: 0.60794
Value Function Loss: 0.05126

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03469
Policy Update Magnitude: 0.02600
Value Function Update Magnitude: 0.03586

Collected Steps per Second: 6,106.39180
Overall Steps per Second: 5,374.47451

Timestep Collection Time: 8.19469
Timestep Consumption Time: 1.11599
PPO Batch Consumption Time: 0.10496
Total Iteration Time: 9.31068

Cumulative Model Updates: 18,114
Cumulative Timesteps: 302,403,324

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 302403324...
Checkpoint 302403324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,893.33467
Policy Entropy: 0.60531
Value Function Loss: 0.04963

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.03436
Policy Update Magnitude: 0.02823
Value Function Update Magnitude: 0.04246

Collected Steps per Second: 6,405.78283
Overall Steps per Second: 5,613.63630

Timestep Collection Time: 7.80795
Timestep Consumption Time: 1.10179
PPO Batch Consumption Time: 0.10641
Total Iteration Time: 8.90973

Cumulative Model Updates: 18,117
Cumulative Timesteps: 302,453,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,880.42030
Policy Entropy: 0.61146
Value Function Loss: 0.05149

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.03563
Policy Update Magnitude: 0.02381
Value Function Update Magnitude: 0.04010

Collected Steps per Second: 5,923.20912
Overall Steps per Second: 5,252.31852

Timestep Collection Time: 8.44238
Timestep Consumption Time: 1.07836
PPO Batch Consumption Time: 0.08174
Total Iteration Time: 9.52075

Cumulative Model Updates: 18,120
Cumulative Timesteps: 302,503,346

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 302503346...
Checkpoint 302503346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,538.95754
Policy Entropy: 0.60983
Value Function Loss: 0.05428

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03865
Policy Update Magnitude: 0.02207
Value Function Update Magnitude: 0.03976

Collected Steps per Second: 8,158.08539
Overall Steps per Second: 6,918.98645

Timestep Collection Time: 6.13232
Timestep Consumption Time: 1.09822
PPO Batch Consumption Time: 0.09973
Total Iteration Time: 7.23054

Cumulative Model Updates: 18,123
Cumulative Timesteps: 302,553,374

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,415.09572
Policy Entropy: 0.61611
Value Function Loss: 0.05443

Mean KL Divergence: 0.00232
SB3 Clip Fraction: 0.02671
Policy Update Magnitude: 0.02267
Value Function Update Magnitude: 0.04117

Collected Steps per Second: 5,711.59764
Overall Steps per Second: 5,065.74613

Timestep Collection Time: 8.75762
Timestep Consumption Time: 1.11654
PPO Batch Consumption Time: 0.08846
Total Iteration Time: 9.87416

Cumulative Model Updates: 18,126
Cumulative Timesteps: 302,603,394

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 302603394...
Checkpoint 302603394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,540.26140
Policy Entropy: 0.61512
Value Function Loss: 0.05557

Mean KL Divergence: 0.00245
SB3 Clip Fraction: 0.03109
Policy Update Magnitude: 0.02472
Value Function Update Magnitude: 0.04902

Collected Steps per Second: 6,075.80953
Overall Steps per Second: 5,374.11651

Timestep Collection Time: 8.23265
Timestep Consumption Time: 1.07493
PPO Batch Consumption Time: 0.08642
Total Iteration Time: 9.30758

Cumulative Model Updates: 18,129
Cumulative Timesteps: 302,653,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,636.61542
Policy Entropy: 0.61462
Value Function Loss: 0.06154

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.05391
Policy Update Magnitude: 0.02457
Value Function Update Magnitude: 0.05440

Collected Steps per Second: 5,534.47387
Overall Steps per Second: 5,028.60862

Timestep Collection Time: 9.03464
Timestep Consumption Time: 0.90886
PPO Batch Consumption Time: 0.03567
Total Iteration Time: 9.94351

Cumulative Model Updates: 18,132
Cumulative Timesteps: 302,703,416

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 302703416...
Checkpoint 302703416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,965.00421
Policy Entropy: 0.61538
Value Function Loss: 0.06345

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.05083
Policy Update Magnitude: 0.02723
Value Function Update Magnitude: 0.06362

Collected Steps per Second: 7,330.15818
Overall Steps per Second: 6,500.28525

Timestep Collection Time: 6.82414
Timestep Consumption Time: 0.87122
PPO Batch Consumption Time: 0.06375
Total Iteration Time: 7.69535

Cumulative Model Updates: 18,135
Cumulative Timesteps: 302,753,438

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,540.75134
Policy Entropy: 0.61350
Value Function Loss: 0.06412

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06852
Policy Update Magnitude: 0.02590
Value Function Update Magnitude: 0.06939

Collected Steps per Second: 7,716.32612
Overall Steps per Second: 6,579.79683

Timestep Collection Time: 6.48262
Timestep Consumption Time: 1.11974
PPO Batch Consumption Time: 0.09632
Total Iteration Time: 7.60236

Cumulative Model Updates: 18,138
Cumulative Timesteps: 302,803,460

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 302803460...
Checkpoint 302803460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,478.87432
Policy Entropy: 0.61783
Value Function Loss: 0.06090

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.04049
Policy Update Magnitude: 0.02418
Value Function Update Magnitude: 0.07737

Collected Steps per Second: 5,876.02874
Overall Steps per Second: 5,192.46085

Timestep Collection Time: 8.50915
Timestep Consumption Time: 1.12020
PPO Batch Consumption Time: 0.10156
Total Iteration Time: 9.62935

Cumulative Model Updates: 18,141
Cumulative Timesteps: 302,853,460

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,029.42941
Policy Entropy: 0.62741
Value Function Loss: 0.05658

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.03433
Policy Update Magnitude: 0.02463
Value Function Update Magnitude: 0.07776

Collected Steps per Second: 5,926.16230
Overall Steps per Second: 5,223.78210

Timestep Collection Time: 8.43851
Timestep Consumption Time: 1.13463
PPO Batch Consumption Time: 0.10487
Total Iteration Time: 9.57314

Cumulative Model Updates: 18,144
Cumulative Timesteps: 302,903,468

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 302903468...
Checkpoint 302903468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,187.04689
Policy Entropy: 0.63188
Value Function Loss: 0.05865

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.03794
Policy Update Magnitude: 0.02370
Value Function Update Magnitude: 0.06502

Collected Steps per Second: 5,539.56958
Overall Steps per Second: 4,950.36762

Timestep Collection Time: 9.02669
Timestep Consumption Time: 1.07437
PPO Batch Consumption Time: 0.09553
Total Iteration Time: 10.10107

Cumulative Model Updates: 18,147
Cumulative Timesteps: 302,953,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,450.50348
Policy Entropy: 0.63033
Value Function Loss: 0.05584

Mean KL Divergence: 0.00235
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.02335
Value Function Update Magnitude: 0.05682

Collected Steps per Second: 5,542.05067
Overall Steps per Second: 4,919.54028

Timestep Collection Time: 9.02879
Timestep Consumption Time: 1.14249
PPO Batch Consumption Time: 0.10611
Total Iteration Time: 10.17128

Cumulative Model Updates: 18,150
Cumulative Timesteps: 303,003,510

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 303003510...
Checkpoint 303003510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,050.08455
Policy Entropy: 0.62634
Value Function Loss: 0.05964

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.03570
Policy Update Magnitude: 0.02462
Value Function Update Magnitude: 0.05280

Collected Steps per Second: 5,407.48439
Overall Steps per Second: 4,814.27307

Timestep Collection Time: 9.24829
Timestep Consumption Time: 1.13957
PPO Batch Consumption Time: 0.10783
Total Iteration Time: 10.38786

Cumulative Model Updates: 18,153
Cumulative Timesteps: 303,053,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,192.32587
Policy Entropy: 0.62961
Value Function Loss: 0.05693

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.02576
Value Function Update Magnitude: 0.05097

Collected Steps per Second: 6,624.01876
Overall Steps per Second: 5,734.48394

Timestep Collection Time: 7.54829
Timestep Consumption Time: 1.17089
PPO Batch Consumption Time: 0.10574
Total Iteration Time: 8.71918

Cumulative Model Updates: 18,156
Cumulative Timesteps: 303,103,520

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 303103520...
Checkpoint 303103520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,469.74631
Policy Entropy: 0.62382
Value Function Loss: 0.06076

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04705
Policy Update Magnitude: 0.02554
Value Function Update Magnitude: 0.05481

Collected Steps per Second: 5,272.60931
Overall Steps per Second: 4,728.32577

Timestep Collection Time: 9.48752
Timestep Consumption Time: 1.09212
PPO Batch Consumption Time: 0.09701
Total Iteration Time: 10.57964

Cumulative Model Updates: 18,159
Cumulative Timesteps: 303,153,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,908.39619
Policy Entropy: 0.63219
Value Function Loss: 0.06295

Mean KL Divergence: 0.00248
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.02574
Value Function Update Magnitude: 0.05275

Collected Steps per Second: 6,325.52232
Overall Steps per Second: 5,606.31781

Timestep Collection Time: 7.90575
Timestep Consumption Time: 1.01419
PPO Batch Consumption Time: 0.10336
Total Iteration Time: 8.91994

Cumulative Model Updates: 18,162
Cumulative Timesteps: 303,203,552

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 303203552...
Checkpoint 303203552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,885.15041
Policy Entropy: 0.62950
Value Function Loss: 0.06411

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.03852
Policy Update Magnitude: 0.02788
Value Function Update Magnitude: 0.05346

Collected Steps per Second: 5,806.58617
Overall Steps per Second: 5,211.38460

Timestep Collection Time: 8.61504
Timestep Consumption Time: 0.98394
PPO Batch Consumption Time: 0.10814
Total Iteration Time: 9.59898

Cumulative Model Updates: 18,165
Cumulative Timesteps: 303,253,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,610.13962
Policy Entropy: 0.63598
Value Function Loss: 0.05526

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.04075
Policy Update Magnitude: 0.02837
Value Function Update Magnitude: 0.05275

Collected Steps per Second: 5,682.21547
Overall Steps per Second: 5,145.45735

Timestep Collection Time: 8.80396
Timestep Consumption Time: 0.91840
PPO Batch Consumption Time: 0.05382
Total Iteration Time: 9.72236

Cumulative Model Updates: 18,168
Cumulative Timesteps: 303,303,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 303303602...
Checkpoint 303303602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,936.34527
Policy Entropy: 0.63735
Value Function Loss: 0.05278

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04377
Policy Update Magnitude: 0.02739
Value Function Update Magnitude: 0.04979

Collected Steps per Second: 16,557.32807
Overall Steps per Second: 13,427.29812

Timestep Collection Time: 3.02162
Timestep Consumption Time: 0.70437
PPO Batch Consumption Time: 0.03962
Total Iteration Time: 3.72599

Cumulative Model Updates: 18,171
Cumulative Timesteps: 303,353,632

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,003.38941
Policy Entropy: 0.63939
Value Function Loss: 0.05543

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.05469
Policy Update Magnitude: 0.02804
Value Function Update Magnitude: 0.05473

Collected Steps per Second: 17,285.90669
Overall Steps per Second: 13,314.30615

Timestep Collection Time: 2.89380
Timestep Consumption Time: 0.86321
PPO Batch Consumption Time: 0.06579
Total Iteration Time: 3.75701

Cumulative Model Updates: 18,174
Cumulative Timesteps: 303,403,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 303403654...
Checkpoint 303403654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,490.65362
Policy Entropy: 0.63519
Value Function Loss: 0.06271

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.04851
Policy Update Magnitude: 0.02829
Value Function Update Magnitude: 0.05400

Collected Steps per Second: 16,658.50256
Overall Steps per Second: 12,999.56321

Timestep Collection Time: 3.00339
Timestep Consumption Time: 0.84535
PPO Batch Consumption Time: 0.06337
Total Iteration Time: 3.84874

Cumulative Model Updates: 18,177
Cumulative Timesteps: 303,453,686

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,302.49341
Policy Entropy: 0.63325
Value Function Loss: 0.05899

Mean KL Divergence: 0.00691
SB3 Clip Fraction: 0.08413
Policy Update Magnitude: 0.02792
Value Function Update Magnitude: 0.06055

Collected Steps per Second: 17,353.10349
Overall Steps per Second: 13,411.19866

Timestep Collection Time: 2.88202
Timestep Consumption Time: 0.84710
PPO Batch Consumption Time: 0.06562
Total Iteration Time: 3.72912

Cumulative Model Updates: 18,180
Cumulative Timesteps: 303,503,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 303503698...
Checkpoint 303503698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,028.09246
Policy Entropy: 0.62884
Value Function Loss: 0.05126

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06794
Policy Update Magnitude: 0.02461
Value Function Update Magnitude: 0.05877

Collected Steps per Second: 17,820.27798
Overall Steps per Second: 13,788.59027

Timestep Collection Time: 2.80837
Timestep Consumption Time: 0.82115
PPO Batch Consumption Time: 0.06200
Total Iteration Time: 3.62952

Cumulative Model Updates: 18,183
Cumulative Timesteps: 303,553,744

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,084.98060
Policy Entropy: 0.63496
Value Function Loss: 0.04573

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05335
Policy Update Magnitude: 0.02485
Value Function Update Magnitude: 0.05204

Collected Steps per Second: 18,284.65908
Overall Steps per Second: 13,933.35642

Timestep Collection Time: 2.73453
Timestep Consumption Time: 0.85398
PPO Batch Consumption Time: 0.05864
Total Iteration Time: 3.58851

Cumulative Model Updates: 18,186
Cumulative Timesteps: 303,603,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 303603744...
Checkpoint 303603744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,774.25944
Policy Entropy: 0.64147
Value Function Loss: 0.04972

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.05955
Policy Update Magnitude: 0.02650
Value Function Update Magnitude: 0.05161

Collected Steps per Second: 18,048.96426
Overall Steps per Second: 13,845.76694

Timestep Collection Time: 2.77179
Timestep Consumption Time: 0.84144
PPO Batch Consumption Time: 0.05765
Total Iteration Time: 3.61323

Cumulative Model Updates: 18,189
Cumulative Timesteps: 303,653,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,129.31201
Policy Entropy: 0.64347
Value Function Loss: 0.05240

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.04489
Policy Update Magnitude: 0.02605
Value Function Update Magnitude: 0.04834

Collected Steps per Second: 18,076.61610
Overall Steps per Second: 13,788.27073

Timestep Collection Time: 2.76678
Timestep Consumption Time: 0.86051
PPO Batch Consumption Time: 0.05781
Total Iteration Time: 3.62729

Cumulative Model Updates: 18,192
Cumulative Timesteps: 303,703,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 303703786...
Checkpoint 303703786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,828.89058
Policy Entropy: 0.64010
Value Function Loss: 0.05824

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05885
Policy Update Magnitude: 0.02357
Value Function Update Magnitude: 0.04953

Collected Steps per Second: 18,018.87759
Overall Steps per Second: 13,490.26039

Timestep Collection Time: 2.77531
Timestep Consumption Time: 0.93166
PPO Batch Consumption Time: 0.07237
Total Iteration Time: 3.70697

Cumulative Model Updates: 18,195
Cumulative Timesteps: 303,753,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,352.26384
Policy Entropy: 0.63420
Value Function Loss: 0.05358

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.03266
Policy Update Magnitude: 0.02594
Value Function Update Magnitude: 0.04118

Collected Steps per Second: 6,727.55531
Overall Steps per Second: 5,902.71319

Timestep Collection Time: 7.43301
Timestep Consumption Time: 1.03869
PPO Batch Consumption Time: 0.08222
Total Iteration Time: 8.47170

Cumulative Model Updates: 18,198
Cumulative Timesteps: 303,803,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 303803800...
Checkpoint 303803800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,115.47798
Policy Entropy: 0.63452
Value Function Loss: 0.05454

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.05425
Policy Update Magnitude: 0.02561
Value Function Update Magnitude: 0.04019

Collected Steps per Second: 6,089.29867
Overall Steps per Second: 5,382.25552

Timestep Collection Time: 8.21605
Timestep Consumption Time: 1.07931
PPO Batch Consumption Time: 0.10576
Total Iteration Time: 9.29536

Cumulative Model Updates: 18,201
Cumulative Timesteps: 303,853,830

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,449.58762
Policy Entropy: 0.63941
Value Function Loss: 0.05366

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.04795
Policy Update Magnitude: 0.02521
Value Function Update Magnitude: 0.03660

Collected Steps per Second: 10,902.72787
Overall Steps per Second: 8,946.97172

Timestep Collection Time: 4.58894
Timestep Consumption Time: 1.00312
PPO Batch Consumption Time: 0.08230
Total Iteration Time: 5.59206

Cumulative Model Updates: 18,204
Cumulative Timesteps: 303,903,862

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 303903862...
Checkpoint 303903862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,193.34314
Policy Entropy: 0.63558
Value Function Loss: 0.06169

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.09593
Policy Update Magnitude: 0.02440
Value Function Update Magnitude: 0.03482

Collected Steps per Second: 17,554.68824
Overall Steps per Second: 13,311.63564

Timestep Collection Time: 2.84870
Timestep Consumption Time: 0.90802
PPO Batch Consumption Time: 0.02977
Total Iteration Time: 3.75671

Cumulative Model Updates: 18,207
Cumulative Timesteps: 303,953,870

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,363.78377
Policy Entropy: 0.62763
Value Function Loss: 0.06595

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.10207
Policy Update Magnitude: 0.02466
Value Function Update Magnitude: 0.04199

Collected Steps per Second: 16,993.96643
Overall Steps per Second: 13,392.90615

Timestep Collection Time: 2.94340
Timestep Consumption Time: 0.79142
PPO Batch Consumption Time: 0.03815
Total Iteration Time: 3.73481

Cumulative Model Updates: 18,210
Cumulative Timesteps: 304,003,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 304003890...
Checkpoint 304003890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,994.32822
Policy Entropy: 0.61982
Value Function Loss: 0.07407

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.07157
Policy Update Magnitude: 0.02511
Value Function Update Magnitude: 0.04386

Collected Steps per Second: 18,435.58765
Overall Steps per Second: 13,902.40473

Timestep Collection Time: 2.71377
Timestep Consumption Time: 0.88489
PPO Batch Consumption Time: 0.06530
Total Iteration Time: 3.59866

Cumulative Model Updates: 18,213
Cumulative Timesteps: 304,053,920

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,374.71973
Policy Entropy: 0.61563
Value Function Loss: 0.06586

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07065
Policy Update Magnitude: 0.02869
Value Function Update Magnitude: 0.04985

Collected Steps per Second: 8,777.48264
Overall Steps per Second: 7,337.68300

Timestep Collection Time: 5.69776
Timestep Consumption Time: 1.11801
PPO Batch Consumption Time: 0.10753
Total Iteration Time: 6.81578

Cumulative Model Updates: 18,216
Cumulative Timesteps: 304,103,932

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 304103932...
Checkpoint 304103932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,311.65796
Policy Entropy: 0.61795
Value Function Loss: 0.06609

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.06179
Policy Update Magnitude: 0.02784
Value Function Update Magnitude: 0.05802

Collected Steps per Second: 5,609.39789
Overall Steps per Second: 4,982.15285

Timestep Collection Time: 8.91718
Timestep Consumption Time: 1.12266
PPO Batch Consumption Time: 0.10897
Total Iteration Time: 10.03984

Cumulative Model Updates: 18,219
Cumulative Timesteps: 304,153,952

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,868.62605
Policy Entropy: 0.61351
Value Function Loss: 0.06286

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.09753
Policy Update Magnitude: 0.02962
Value Function Update Magnitude: 0.06027

Collected Steps per Second: 6,175.00738
Overall Steps per Second: 5,426.29312

Timestep Collection Time: 8.10234
Timestep Consumption Time: 1.11795
PPO Batch Consumption Time: 0.11063
Total Iteration Time: 9.22029

Cumulative Model Updates: 18,222
Cumulative Timesteps: 304,203,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 304203984...
Checkpoint 304203984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,000.73025
Policy Entropy: 0.61568
Value Function Loss: 0.06565

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.10135
Policy Update Magnitude: 0.02688
Value Function Update Magnitude: 0.05974

Collected Steps per Second: 5,560.90421
Overall Steps per Second: 4,955.77293

Timestep Collection Time: 8.99530
Timestep Consumption Time: 1.09838
PPO Batch Consumption Time: 0.10661
Total Iteration Time: 10.09368

Cumulative Model Updates: 18,225
Cumulative Timesteps: 304,254,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,560.92188
Policy Entropy: 0.61905
Value Function Loss: 0.06222

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07309
Policy Update Magnitude: 0.02714
Value Function Update Magnitude: 0.05866

Collected Steps per Second: 5,388.08265
Overall Steps per Second: 4,812.97260

Timestep Collection Time: 9.28568
Timestep Consumption Time: 1.10956
PPO Batch Consumption Time: 0.11004
Total Iteration Time: 10.39524

Cumulative Model Updates: 18,228
Cumulative Timesteps: 304,304,038

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 304304038...
Checkpoint 304304038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,328.03691
Policy Entropy: 0.62267
Value Function Loss: 0.05426

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07553
Policy Update Magnitude: 0.02388
Value Function Update Magnitude: 0.05707

Collected Steps per Second: 5,920.86508
Overall Steps per Second: 5,234.25854

Timestep Collection Time: 8.45147
Timestep Consumption Time: 1.10863
PPO Batch Consumption Time: 0.10689
Total Iteration Time: 9.56009

Cumulative Model Updates: 18,231
Cumulative Timesteps: 304,354,078

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,269.73665
Policy Entropy: 0.62597
Value Function Loss: 0.05291

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03812
Policy Update Magnitude: 0.02237
Value Function Update Magnitude: 0.05281

Collected Steps per Second: 5,623.10508
Overall Steps per Second: 4,994.16989

Timestep Collection Time: 8.89544
Timestep Consumption Time: 1.12024
PPO Batch Consumption Time: 0.10813
Total Iteration Time: 10.01568

Cumulative Model Updates: 18,234
Cumulative Timesteps: 304,404,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 304404098...
Checkpoint 304404098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,860.24022
Policy Entropy: 0.62015
Value Function Loss: 0.06022

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07308
Policy Update Magnitude: 0.02451
Value Function Update Magnitude: 0.05761

Collected Steps per Second: 8,623.76825
Overall Steps per Second: 7,513.39388

Timestep Collection Time: 5.80118
Timestep Consumption Time: 0.85733
PPO Batch Consumption Time: 0.05713
Total Iteration Time: 6.65851

Cumulative Model Updates: 18,237
Cumulative Timesteps: 304,454,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,312.99696
Policy Entropy: 0.61515
Value Function Loss: 0.06528

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.04590
Policy Update Magnitude: 0.02425
Value Function Update Magnitude: 0.06332

Collected Steps per Second: 19,532.54611
Overall Steps per Second: 13,913.84827

Timestep Collection Time: 2.56024
Timestep Consumption Time: 1.03388
PPO Batch Consumption Time: 0.12089
Total Iteration Time: 3.59412

Cumulative Model Updates: 18,240
Cumulative Timesteps: 304,504,134

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 304504134...
Checkpoint 304504134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,708.75403
Policy Entropy: 0.61261
Value Function Loss: 0.05812

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06679
Policy Update Magnitude: 0.02341
Value Function Update Magnitude: 0.05968

Collected Steps per Second: 17,737.28164
Overall Steps per Second: 12,838.93859

Timestep Collection Time: 2.81903
Timestep Consumption Time: 1.07552
PPO Batch Consumption Time: 0.07531
Total Iteration Time: 3.89456

Cumulative Model Updates: 18,243
Cumulative Timesteps: 304,554,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,913.97216
Policy Entropy: 0.61150
Value Function Loss: 0.05715

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.04368
Policy Update Magnitude: 0.02284
Value Function Update Magnitude: 0.05691

Collected Steps per Second: 16,580.81311
Overall Steps per Second: 12,281.19335

Timestep Collection Time: 3.01577
Timestep Consumption Time: 1.05582
PPO Batch Consumption Time: 0.08996
Total Iteration Time: 4.07159

Cumulative Model Updates: 18,246
Cumulative Timesteps: 304,604,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 304604140...
Checkpoint 304604140 saved!
