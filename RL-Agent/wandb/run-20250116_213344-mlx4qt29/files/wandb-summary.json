{"Mean KL Divergence":0.003378060491134723,"Timestep Collection Time":3.015774899999087,"_step":12179,"Policy Entropy":0.6114996075630188,"SB3 Clip Fraction":0.04367999856670698,"y_vel":3.236142915891168,"Value Function Loss":0.05715193351109823,"z_vel":0.20056850234251097,"Policy Reward":30913.972162163176,"Total Iteration Time":4.071591300000364,"Overall Steps per Second":12281.193350618352,"Collected Steps per Second":16580.81311042649,"Cumulative Timesteps":304604140,"Policy Update Magnitude":0.02283572405576706,"_wandb":{"runtime":26122},"_timestamp":1.7370901931216998e+09,"_runtime":26122.0878878,"Value Function Update Magnitude":0.056912485510110855,"Timestep Consumption Time":1.0558164000012766,"x_vel":17.171713685285372,"PPO Batch Consumption Time":0.08996423085530598,"Timesteps Collected":50004,"Cumulative Model Updates":18246}