Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.22014
Policy Entropy: 3.95210
Value Function Loss: 0.00437

Mean KL Divergence: 0.00026
SB3 Clip Fraction: 0.00175
Policy Update Magnitude: 0.08178
Value Function Update Magnitude: 0.08916

Collected Steps per Second: 6,333.65062
Overall Steps per Second: 3,905.48050

Timestep Collection Time: 7.89624
Timestep Consumption Time: 4.90936
PPO Batch Consumption Time: 1.94641
Total Iteration Time: 12.80559

Cumulative Model Updates: 362,626
Cumulative Timesteps: 3,024,306,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.37278
Policy Entropy: 3.99741
Value Function Loss: 0.00500

Mean KL Divergence: 0.00103
SB3 Clip Fraction: 0.00745
Policy Update Magnitude: 0.08213
Value Function Update Magnitude: 0.08653

Collected Steps per Second: 21,830.72957
Overall Steps per Second: 13,648.86783

Timestep Collection Time: 2.29117
Timestep Consumption Time: 1.37345
PPO Batch Consumption Time: 0.31630
Total Iteration Time: 3.66463

Cumulative Model Updates: 362,628
Cumulative Timesteps: 3,024,356,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3024356462...
Checkpoint 3024356462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.92701
Policy Entropy: 3.96473
Value Function Loss: 0.00545

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.01826
Policy Update Magnitude: 0.15915
Value Function Update Magnitude: 0.17037

Collected Steps per Second: 22,460.70993
Overall Steps per Second: 12,170.19967

Timestep Collection Time: 2.22629
Timestep Consumption Time: 1.88244
PPO Batch Consumption Time: 0.29471
Total Iteration Time: 4.10872

Cumulative Model Updates: 362,632
Cumulative Timesteps: 3,024,406,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.72874
Policy Entropy: 3.97849
Value Function Loss: 0.00553

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02120
Policy Update Magnitude: 0.22447
Value Function Update Magnitude: 0.26602

Collected Steps per Second: 22,520.51714
Overall Steps per Second: 10,797.96075

Timestep Collection Time: 2.22038
Timestep Consumption Time: 2.41050
PPO Batch Consumption Time: 0.27664
Total Iteration Time: 4.63087

Cumulative Model Updates: 362,638
Cumulative Timesteps: 3,024,456,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3024456470...
Checkpoint 3024456470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.40242
Policy Entropy: 3.91657
Value Function Loss: 0.00601

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.22344
Value Function Update Magnitude: 0.29343

Collected Steps per Second: 22,457.93380
Overall Steps per Second: 10,705.21612

Timestep Collection Time: 2.22736
Timestep Consumption Time: 2.44531
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.67268

Cumulative Model Updates: 362,644
Cumulative Timesteps: 3,024,506,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.36205
Policy Entropy: 3.94198
Value Function Loss: 0.00546

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02387
Policy Update Magnitude: 0.22399
Value Function Update Magnitude: 0.30288

Collected Steps per Second: 23,320.58359
Overall Steps per Second: 11,009.07397

Timestep Collection Time: 2.14420
Timestep Consumption Time: 2.39787
PPO Batch Consumption Time: 0.27419
Total Iteration Time: 4.54207

Cumulative Model Updates: 362,650
Cumulative Timesteps: 3,024,556,496

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3024556496...
Checkpoint 3024556496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.22887
Policy Entropy: 3.89559
Value Function Loss: 0.00601

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02803
Policy Update Magnitude: 0.22997
Value Function Update Magnitude: 0.29995

Collected Steps per Second: 22,546.52610
Overall Steps per Second: 10,648.39949

Timestep Collection Time: 2.21870
Timestep Consumption Time: 2.47909
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.69780

Cumulative Model Updates: 362,656
Cumulative Timesteps: 3,024,606,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.39208
Policy Entropy: 3.89454
Value Function Loss: 0.00639

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.23551
Value Function Update Magnitude: 0.29548

Collected Steps per Second: 22,177.92391
Overall Steps per Second: 10,902.84235

Timestep Collection Time: 2.25567
Timestep Consumption Time: 2.33268
PPO Batch Consumption Time: 0.27408
Total Iteration Time: 4.58834

Cumulative Model Updates: 362,662
Cumulative Timesteps: 3,024,656,546

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3024656546...
Checkpoint 3024656546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.07123
Policy Entropy: 3.86885
Value Function Loss: 0.00726

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.24242
Value Function Update Magnitude: 0.29915

Collected Steps per Second: 21,704.86838
Overall Steps per Second: 10,576.52216

Timestep Collection Time: 2.30455
Timestep Consumption Time: 2.42479
PPO Batch Consumption Time: 0.27602
Total Iteration Time: 4.72934

Cumulative Model Updates: 362,668
Cumulative Timesteps: 3,024,706,566

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.96575
Policy Entropy: 3.92250
Value Function Loss: 0.00608

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.23005
Value Function Update Magnitude: 0.29827

Collected Steps per Second: 22,065.21270
Overall Steps per Second: 10,391.63425

Timestep Collection Time: 2.26728
Timestep Consumption Time: 2.54698
PPO Batch Consumption Time: 0.29919
Total Iteration Time: 4.81426

Cumulative Model Updates: 362,674
Cumulative Timesteps: 3,024,756,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3024756594...
Checkpoint 3024756594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.23660
Policy Entropy: 3.93088
Value Function Loss: 0.00582

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.21446
Value Function Update Magnitude: 0.28024

Collected Steps per Second: 22,017.67242
Overall Steps per Second: 10,852.53947

Timestep Collection Time: 2.27172
Timestep Consumption Time: 2.33715
PPO Batch Consumption Time: 0.27567
Total Iteration Time: 4.60888

Cumulative Model Updates: 362,680
Cumulative Timesteps: 3,024,806,612

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.39593
Policy Entropy: 3.91344
Value Function Loss: 0.00599

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.21838
Value Function Update Magnitude: 0.27237

Collected Steps per Second: 22,434.47362
Overall Steps per Second: 10,493.50125

Timestep Collection Time: 2.22969
Timestep Consumption Time: 2.53726
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.76695

Cumulative Model Updates: 362,686
Cumulative Timesteps: 3,024,856,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3024856634...
Checkpoint 3024856634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.67079
Policy Entropy: 3.87419
Value Function Loss: 0.00719

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02961
Policy Update Magnitude: 0.22103
Value Function Update Magnitude: 0.29782

Collected Steps per Second: 22,535.02035
Overall Steps per Second: 10,674.78959

Timestep Collection Time: 2.21912
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.68468

Cumulative Model Updates: 362,692
Cumulative Timesteps: 3,024,906,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.67061
Policy Entropy: 3.87367
Value Function Loss: 0.00763

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.03236
Policy Update Magnitude: 0.22274
Value Function Update Magnitude: 0.32486

Collected Steps per Second: 23,660.56383
Overall Steps per Second: 10,776.02972

Timestep Collection Time: 2.11356
Timestep Consumption Time: 2.52711
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.64067

Cumulative Model Updates: 362,698
Cumulative Timesteps: 3,024,956,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3024956650...
Checkpoint 3024956650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.34540
Policy Entropy: 3.89664
Value Function Loss: 0.00723

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.03155
Policy Update Magnitude: 0.22632
Value Function Update Magnitude: 0.31515

Collected Steps per Second: 22,434.15318
Overall Steps per Second: 10,642.41276

Timestep Collection Time: 2.22892
Timestep Consumption Time: 2.46964
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.69856

Cumulative Model Updates: 362,704
Cumulative Timesteps: 3,025,006,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.67134
Policy Entropy: 3.89101
Value Function Loss: 0.00684

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.03328
Policy Update Magnitude: 0.22800
Value Function Update Magnitude: 0.30172

Collected Steps per Second: 22,079.26452
Overall Steps per Second: 10,851.63718

Timestep Collection Time: 2.26502
Timestep Consumption Time: 2.34350
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.60852

Cumulative Model Updates: 362,710
Cumulative Timesteps: 3,025,056,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3025056664...
Checkpoint 3025056664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.77992
Policy Entropy: 3.84278
Value Function Loss: 0.00717

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.03123
Policy Update Magnitude: 0.24092
Value Function Update Magnitude: 0.29708

Collected Steps per Second: 22,395.51212
Overall Steps per Second: 10,742.97594

Timestep Collection Time: 2.23357
Timestep Consumption Time: 2.42268
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.65625

Cumulative Model Updates: 362,716
Cumulative Timesteps: 3,025,106,686

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.72090
Policy Entropy: 3.83592
Value Function Loss: 0.00748

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.03263
Policy Update Magnitude: 0.25122
Value Function Update Magnitude: 0.31326

Collected Steps per Second: 21,775.92702
Overall Steps per Second: 10,410.13041

Timestep Collection Time: 2.29611
Timestep Consumption Time: 2.50690
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.80301

Cumulative Model Updates: 362,722
Cumulative Timesteps: 3,025,156,686

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3025156686...
Checkpoint 3025156686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.08059
Policy Entropy: 3.87962
Value Function Loss: 0.00708

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.03364
Policy Update Magnitude: 0.24420
Value Function Update Magnitude: 0.32012

Collected Steps per Second: 21,796.81560
Overall Steps per Second: 10,674.79829

Timestep Collection Time: 2.29446
Timestep Consumption Time: 2.39059
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.68505

Cumulative Model Updates: 362,728
Cumulative Timesteps: 3,025,206,698

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.19925
Policy Entropy: 3.92732
Value Function Loss: 0.00625

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02944
Policy Update Magnitude: 0.22759
Value Function Update Magnitude: 0.29786

Collected Steps per Second: 22,216.81928
Overall Steps per Second: 10,567.77025

Timestep Collection Time: 2.25145
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.73326

Cumulative Model Updates: 362,734
Cumulative Timesteps: 3,025,256,718

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3025256718...
Checkpoint 3025256718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.69301
Policy Entropy: 3.91218
Value Function Loss: 0.00681

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02818
Policy Update Magnitude: 0.23073
Value Function Update Magnitude: 0.27707

Collected Steps per Second: 21,864.55004
Overall Steps per Second: 10,553.31185

Timestep Collection Time: 2.28754
Timestep Consumption Time: 2.45183
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.73937

Cumulative Model Updates: 362,740
Cumulative Timesteps: 3,025,306,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.65801
Policy Entropy: 3.87879
Value Function Loss: 0.00691

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.23248
Value Function Update Magnitude: 0.26329

Collected Steps per Second: 22,535.77483
Overall Steps per Second: 10,581.94258

Timestep Collection Time: 2.22127
Timestep Consumption Time: 2.50924
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.73051

Cumulative Model Updates: 362,746
Cumulative Timesteps: 3,025,356,792

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


Saving checkpoint 3025356792...
Checkpoint 3025356792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.77754
Policy Entropy: 3.89296
Value Function Loss: 0.00666

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.22306
Value Function Update Magnitude: 0.24927

Collected Steps per Second: 22,100.46332
Overall Steps per Second: 10,341.06509

Timestep Collection Time: 2.26258
Timestep Consumption Time: 2.57290
PPO Batch Consumption Time: 0.29983
Total Iteration Time: 4.83548

Cumulative Model Updates: 362,752
Cumulative Timesteps: 3,025,406,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.72041
Policy Entropy: 3.94333
Value Function Loss: 0.00531

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.21020
Value Function Update Magnitude: 0.24522

Collected Steps per Second: 22,429.97090
Overall Steps per Second: 10,572.84587

Timestep Collection Time: 2.23041
Timestep Consumption Time: 2.50134
PPO Batch Consumption Time: 0.29599
Total Iteration Time: 4.73174

Cumulative Model Updates: 362,758
Cumulative Timesteps: 3,025,456,824

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3025456824...
Checkpoint 3025456824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.67666
Policy Entropy: 3.94244
Value Function Loss: 0.00504

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02328
Policy Update Magnitude: 0.19826
Value Function Update Magnitude: 0.24339

Collected Steps per Second: 22,265.78768
Overall Steps per Second: 10,686.00265

Timestep Collection Time: 2.24587
Timestep Consumption Time: 2.43371
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.67958

Cumulative Model Updates: 362,764
Cumulative Timesteps: 3,025,506,830

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.28940
Policy Entropy: 3.92059
Value Function Loss: 0.00550

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02213
Policy Update Magnitude: 0.21138
Value Function Update Magnitude: 0.25052

Collected Steps per Second: 22,276.49084
Overall Steps per Second: 10,626.72869

Timestep Collection Time: 2.24587
Timestep Consumption Time: 2.46207
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.70794

Cumulative Model Updates: 362,770
Cumulative Timesteps: 3,025,556,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3025556860...
Checkpoint 3025556860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.97658
Policy Entropy: 3.93113
Value Function Loss: 0.00528

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.21794
Value Function Update Magnitude: 0.26468

Collected Steps per Second: 22,439.94709
Overall Steps per Second: 10,916.22884

Timestep Collection Time: 2.22835
Timestep Consumption Time: 2.35236
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.58070

Cumulative Model Updates: 362,776
Cumulative Timesteps: 3,025,606,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.87534
Policy Entropy: 3.95221
Value Function Loss: 0.00571

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02231
Policy Update Magnitude: 0.20970
Value Function Update Magnitude: 0.26858

Collected Steps per Second: 22,868.51541
Overall Steps per Second: 10,835.02269

Timestep Collection Time: 2.18772
Timestep Consumption Time: 2.42971
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.61743

Cumulative Model Updates: 362,782
Cumulative Timesteps: 3,025,656,894

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3025656894...
Checkpoint 3025656894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.02655
Policy Entropy: 3.99248
Value Function Loss: 0.00534

Mean KL Divergence: 0.00221
SB3 Clip Fraction: 0.01701
Policy Update Magnitude: 0.20225
Value Function Update Magnitude: 0.26789

Collected Steps per Second: 22,492.12169
Overall Steps per Second: 10,706.54828

Timestep Collection Time: 2.22389
Timestep Consumption Time: 2.44802
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.67191

Cumulative Model Updates: 362,788
Cumulative Timesteps: 3,025,706,914

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.88546
Policy Entropy: 3.95575
Value Function Loss: 0.00686

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02176
Policy Update Magnitude: 0.20951
Value Function Update Magnitude: 0.27618

Collected Steps per Second: 22,716.01636
Overall Steps per Second: 10,645.41552

Timestep Collection Time: 2.20118
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.69705

Cumulative Model Updates: 362,794
Cumulative Timesteps: 3,025,756,916

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3025756916...
Checkpoint 3025756916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.07837
Policy Entropy: 3.95961
Value Function Loss: 0.00658

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02332
Policy Update Magnitude: 0.21617
Value Function Update Magnitude: 0.29600

Collected Steps per Second: 21,347.27813
Overall Steps per Second: 10,473.77767

Timestep Collection Time: 2.34372
Timestep Consumption Time: 2.43316
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.77688

Cumulative Model Updates: 362,800
Cumulative Timesteps: 3,025,806,948

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.57453
Policy Entropy: 3.91479
Value Function Loss: 0.00734

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02836
Policy Update Magnitude: 0.23042
Value Function Update Magnitude: 0.30912

Collected Steps per Second: 21,912.62041
Overall Steps per Second: 10,448.22173

Timestep Collection Time: 2.28206
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.78608

Cumulative Model Updates: 362,806
Cumulative Timesteps: 3,025,856,954

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3025856954...
Checkpoint 3025856954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.04121
Policy Entropy: 3.95109
Value Function Loss: 0.00638

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.24053
Value Function Update Magnitude: 0.32034

Collected Steps per Second: 22,980.86167
Overall Steps per Second: 10,686.98037

Timestep Collection Time: 2.17703
Timestep Consumption Time: 2.50437
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.68140

Cumulative Model Updates: 362,812
Cumulative Timesteps: 3,025,906,984

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.66691
Policy Entropy: 3.91284
Value Function Loss: 0.00637

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.22960
Value Function Update Magnitude: 0.31878

Collected Steps per Second: 22,630.17465
Overall Steps per Second: 10,499.70530

Timestep Collection Time: 2.20953
Timestep Consumption Time: 2.55270
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.76223

Cumulative Model Updates: 362,818
Cumulative Timesteps: 3,025,956,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3025956986...
Checkpoint 3025956986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.99418
Policy Entropy: 3.93193
Value Function Loss: 0.00637

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.22925
Value Function Update Magnitude: 0.31022

Collected Steps per Second: 22,546.24001
Overall Steps per Second: 10,811.28199

Timestep Collection Time: 2.21802
Timestep Consumption Time: 2.40752
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.62554

Cumulative Model Updates: 362,824
Cumulative Timesteps: 3,026,006,994

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.07150
Policy Entropy: 3.94308
Value Function Loss: 0.00593

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02236
Policy Update Magnitude: 0.22936
Value Function Update Magnitude: 0.30212

Collected Steps per Second: 22,927.86109
Overall Steps per Second: 10,697.03348

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.67531

Cumulative Model Updates: 362,830
Cumulative Timesteps: 3,026,057,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3026057006...
Checkpoint 3026057006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.57226
Policy Entropy: 3.98297
Value Function Loss: 0.00592

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02109
Policy Update Magnitude: 0.22495
Value Function Update Magnitude: 0.28583

Collected Steps per Second: 22,077.47786
Overall Steps per Second: 10,549.84457

Timestep Collection Time: 2.26520
Timestep Consumption Time: 2.47515
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.74035

Cumulative Model Updates: 362,836
Cumulative Timesteps: 3,026,107,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.18346
Policy Entropy: 3.96429
Value Function Loss: 0.00605

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02300
Policy Update Magnitude: 0.21423
Value Function Update Magnitude: 0.28119

Collected Steps per Second: 22,329.85144
Overall Steps per Second: 10,750.55534

Timestep Collection Time: 2.23933
Timestep Consumption Time: 2.41196
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.65129

Cumulative Model Updates: 362,842
Cumulative Timesteps: 3,026,157,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3026157020...
Checkpoint 3026157020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.80290
Policy Entropy: 3.93892
Value Function Loss: 0.00627

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02120
Policy Update Magnitude: 0.22089
Value Function Update Magnitude: 0.29709

Collected Steps per Second: 22,758.23472
Overall Steps per Second: 10,689.18080

Timestep Collection Time: 2.19815
Timestep Consumption Time: 2.48191
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.68006

Cumulative Model Updates: 362,848
Cumulative Timesteps: 3,026,207,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.11104
Policy Entropy: 3.93862
Value Function Loss: 0.00601

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02117
Policy Update Magnitude: 0.22737
Value Function Update Magnitude: 0.30636

Collected Steps per Second: 22,418.66452
Overall Steps per Second: 10,687.48852

Timestep Collection Time: 2.23028
Timestep Consumption Time: 2.44808
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.67837

Cumulative Model Updates: 362,854
Cumulative Timesteps: 3,026,257,046

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3026257046...
Checkpoint 3026257046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.16088
Policy Entropy: 4.00835
Value Function Loss: 0.00529

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.01979
Policy Update Magnitude: 0.22966
Value Function Update Magnitude: 0.29210

Collected Steps per Second: 22,509.31419
Overall Steps per Second: 10,612.13491

Timestep Collection Time: 2.22201
Timestep Consumption Time: 2.49108
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.71309

Cumulative Model Updates: 362,860
Cumulative Timesteps: 3,026,307,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.98525
Policy Entropy: 4.00040
Value Function Loss: 0.00547

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.01887
Policy Update Magnitude: 0.22058
Value Function Update Magnitude: 0.28985

Collected Steps per Second: 22,052.24492
Overall Steps per Second: 10,476.87041

Timestep Collection Time: 2.26816
Timestep Consumption Time: 2.50598
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.77414

Cumulative Model Updates: 362,866
Cumulative Timesteps: 3,026,357,080

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3026357080...
Checkpoint 3026357080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.06191
Policy Entropy: 3.94554
Value Function Loss: 0.00600

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.02091
Policy Update Magnitude: 0.21670
Value Function Update Magnitude: 0.29327

Collected Steps per Second: 21,359.23848
Overall Steps per Second: 10,387.89018

Timestep Collection Time: 2.34109
Timestep Consumption Time: 2.47259
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.81368

Cumulative Model Updates: 362,872
Cumulative Timesteps: 3,026,407,084

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.48572
Policy Entropy: 3.88173
Value Function Loss: 0.00673

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.22628
Value Function Update Magnitude: 0.30229

Collected Steps per Second: 23,172.84276
Overall Steps per Second: 10,707.00693

Timestep Collection Time: 2.15822
Timestep Consumption Time: 2.51274
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.67096

Cumulative Model Updates: 362,878
Cumulative Timesteps: 3,026,457,096

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3026457096...
Checkpoint 3026457096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.39504
Policy Entropy: 3.91467
Value Function Loss: 0.00667

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02302
Policy Update Magnitude: 0.22622
Value Function Update Magnitude: 0.30585

Collected Steps per Second: 22,080.08449
Overall Steps per Second: 10,589.22111

Timestep Collection Time: 2.26575
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.72443

Cumulative Model Updates: 362,884
Cumulative Timesteps: 3,026,507,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.00233
Policy Entropy: 3.94123
Value Function Loss: 0.00634

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.22452
Value Function Update Magnitude: 0.28838

Collected Steps per Second: 22,599.23367
Overall Steps per Second: 10,894.11934

Timestep Collection Time: 2.21255
Timestep Consumption Time: 2.37726
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.58982

Cumulative Model Updates: 362,890
Cumulative Timesteps: 3,026,557,126

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3026557126...
Checkpoint 3026557126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43667
Policy Entropy: 3.93818
Value Function Loss: 0.00588

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.22975
Value Function Update Magnitude: 0.28568

Collected Steps per Second: 22,462.58359
Overall Steps per Second: 10,757.53423

Timestep Collection Time: 2.22610
Timestep Consumption Time: 2.42218
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.64828

Cumulative Model Updates: 362,896
Cumulative Timesteps: 3,026,607,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.11484
Policy Entropy: 3.96711
Value Function Loss: 0.00539

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.21924
Value Function Update Magnitude: 0.28536

Collected Steps per Second: 22,713.46455
Overall Steps per Second: 10,828.12285

Timestep Collection Time: 2.20275
Timestep Consumption Time: 2.41781
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.62056

Cumulative Model Updates: 362,902
Cumulative Timesteps: 3,026,657,162

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3026657162...
Checkpoint 3026657162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.39876
Policy Entropy: 3.96488
Value Function Loss: 0.00607

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.22287
Value Function Update Magnitude: 0.28227

Collected Steps per Second: 23,447.26010
Overall Steps per Second: 10,814.55273

Timestep Collection Time: 2.13313
Timestep Consumption Time: 2.49175
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.62488

Cumulative Model Updates: 362,908
Cumulative Timesteps: 3,026,707,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.14307
Policy Entropy: 3.98722
Value Function Loss: 0.00646

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02265
Policy Update Magnitude: 0.22809
Value Function Update Magnitude: 0.28478

Collected Steps per Second: 22,631.47444
Overall Steps per Second: 10,779.31758

Timestep Collection Time: 2.20940
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.63870

Cumulative Model Updates: 362,914
Cumulative Timesteps: 3,026,757,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3026757180...
Checkpoint 3026757180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.43757
Policy Entropy: 3.93809
Value Function Loss: 0.00686

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.22323
Value Function Update Magnitude: 0.28550

Collected Steps per Second: 22,065.31995
Overall Steps per Second: 10,699.81712

Timestep Collection Time: 2.26663
Timestep Consumption Time: 2.40765
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.67429

Cumulative Model Updates: 362,920
Cumulative Timesteps: 3,026,807,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.83123
Policy Entropy: 3.92943
Value Function Loss: 0.00723

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02381
Policy Update Magnitude: 0.23483
Value Function Update Magnitude: 0.29201

Collected Steps per Second: 22,284.44181
Overall Steps per Second: 10,589.35286

Timestep Collection Time: 2.24417
Timestep Consumption Time: 2.47850
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.72267

Cumulative Model Updates: 362,926
Cumulative Timesteps: 3,026,857,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3026857204...
Checkpoint 3026857204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.30300
Policy Entropy: 3.92218
Value Function Loss: 0.00602

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03192
Policy Update Magnitude: 0.23652
Value Function Update Magnitude: 0.29723

Collected Steps per Second: 22,244.79843
Overall Steps per Second: 10,514.49791

Timestep Collection Time: 2.24898
Timestep Consumption Time: 2.50903
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.75800

Cumulative Model Updates: 362,932
Cumulative Timesteps: 3,026,907,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.07003
Policy Entropy: 3.91456
Value Function Loss: 0.00573

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.03694
Policy Update Magnitude: 0.24121
Value Function Update Magnitude: 0.28983

Collected Steps per Second: 22,028.51851
Overall Steps per Second: 10,551.41113

Timestep Collection Time: 2.27042
Timestep Consumption Time: 2.46961
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.74003

Cumulative Model Updates: 362,938
Cumulative Timesteps: 3,026,957,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3026957246...
Checkpoint 3026957246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.76169
Policy Entropy: 3.93120
Value Function Loss: 0.00570

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.02989
Policy Update Magnitude: 0.22822
Value Function Update Magnitude: 0.28504

Collected Steps per Second: 21,977.01248
Overall Steps per Second: 10,476.18712

Timestep Collection Time: 2.27510
Timestep Consumption Time: 2.49762
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.77273

Cumulative Model Updates: 362,944
Cumulative Timesteps: 3,027,007,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.47736
Policy Entropy: 3.94287
Value Function Loss: 0.00622

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02501
Policy Update Magnitude: 0.22365
Value Function Update Magnitude: 0.28752

Collected Steps per Second: 22,083.24073
Overall Steps per Second: 10,468.39553

Timestep Collection Time: 2.26588
Timestep Consumption Time: 2.51403
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.77991

Cumulative Model Updates: 362,950
Cumulative Timesteps: 3,027,057,284

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3027057284...
Checkpoint 3027057284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.90244
Policy Entropy: 3.93640
Value Function Loss: 0.00646

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.22750
Value Function Update Magnitude: 0.28405

Collected Steps per Second: 22,036.84076
Overall Steps per Second: 10,642.15968

Timestep Collection Time: 2.26929
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.69905

Cumulative Model Updates: 362,956
Cumulative Timesteps: 3,027,107,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.26116
Policy Entropy: 3.91965
Value Function Loss: 0.00705

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02617
Policy Update Magnitude: 0.23366
Value Function Update Magnitude: 0.28550

Collected Steps per Second: 21,363.74740
Overall Steps per Second: 10,394.82071

Timestep Collection Time: 2.34116
Timestep Consumption Time: 2.47046
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.81163

Cumulative Model Updates: 362,962
Cumulative Timesteps: 3,027,157,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3027157308...
Checkpoint 3027157308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.03950
Policy Entropy: 3.89738
Value Function Loss: 0.00689

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.24059
Value Function Update Magnitude: 0.27898

Collected Steps per Second: 22,168.42738
Overall Steps per Second: 10,695.13593

Timestep Collection Time: 2.25573
Timestep Consumption Time: 2.41985
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.67558

Cumulative Model Updates: 362,968
Cumulative Timesteps: 3,027,207,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.69503
Policy Entropy: 3.90836
Value Function Loss: 0.00684

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.03221
Policy Update Magnitude: 0.23662
Value Function Update Magnitude: 0.27098

Collected Steps per Second: 22,559.25831
Overall Steps per Second: 10,900.12258

Timestep Collection Time: 2.21683
Timestep Consumption Time: 2.37119
PPO Batch Consumption Time: 0.27960
Total Iteration Time: 4.58802

Cumulative Model Updates: 362,974
Cumulative Timesteps: 3,027,257,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3027257324...
Checkpoint 3027257324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.64850
Policy Entropy: 3.91005
Value Function Loss: 0.00700

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03125
Policy Update Magnitude: 0.23140
Value Function Update Magnitude: 0.28756

Collected Steps per Second: 22,308.12915
Overall Steps per Second: 10,653.26168

Timestep Collection Time: 2.24214
Timestep Consumption Time: 2.45295
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.69509

Cumulative Model Updates: 362,980
Cumulative Timesteps: 3,027,307,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.46310
Policy Entropy: 3.90752
Value Function Loss: 0.00651

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.23100
Value Function Update Magnitude: 0.29617

Collected Steps per Second: 22,238.81332
Overall Steps per Second: 10,604.20612

Timestep Collection Time: 2.24913
Timestep Consumption Time: 2.46768
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.71681

Cumulative Model Updates: 362,986
Cumulative Timesteps: 3,027,357,360

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3027357360...
Checkpoint 3027357360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.05314
Policy Entropy: 3.90935
Value Function Loss: 0.00620

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02905
Policy Update Magnitude: 0.21991
Value Function Update Magnitude: 0.29202

Collected Steps per Second: 22,960.94963
Overall Steps per Second: 10,623.35050

Timestep Collection Time: 2.17796
Timestep Consumption Time: 2.52941
PPO Batch Consumption Time: 0.29454
Total Iteration Time: 4.70737

Cumulative Model Updates: 362,992
Cumulative Timesteps: 3,027,407,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.05204
Policy Entropy: 3.93786
Value Function Loss: 0.00537

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02418
Policy Update Magnitude: 0.21207
Value Function Update Magnitude: 0.28799

Collected Steps per Second: 22,330.67541
Overall Steps per Second: 10,710.20013

Timestep Collection Time: 2.24015
Timestep Consumption Time: 2.43054
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.67069

Cumulative Model Updates: 362,998
Cumulative Timesteps: 3,027,457,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3027457392...
Checkpoint 3027457392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.38524
Policy Entropy: 3.95784
Value Function Loss: 0.00549

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.21718
Value Function Update Magnitude: 0.27878

Collected Steps per Second: 21,445.81026
Overall Steps per Second: 10,355.84953

Timestep Collection Time: 2.33174
Timestep Consumption Time: 2.49703
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.82877

Cumulative Model Updates: 363,004
Cumulative Timesteps: 3,027,507,398

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.63260
Policy Entropy: 3.96766
Value Function Loss: 0.00580

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.21919
Value Function Update Magnitude: 0.27334

Collected Steps per Second: 23,012.75969
Overall Steps per Second: 10,842.85406

Timestep Collection Time: 2.17384
Timestep Consumption Time: 2.43989
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.61373

Cumulative Model Updates: 363,010
Cumulative Timesteps: 3,027,557,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3027557424...
Checkpoint 3027557424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.01216
Policy Entropy: 3.92861
Value Function Loss: 0.00710

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.22941
Value Function Update Magnitude: 0.27796

Collected Steps per Second: 21,819.86296
Overall Steps per Second: 10,586.72919

Timestep Collection Time: 2.29195
Timestep Consumption Time: 2.43189
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.72384

Cumulative Model Updates: 363,016
Cumulative Timesteps: 3,027,607,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.50549
Policy Entropy: 3.89972
Value Function Loss: 0.00694

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.24782
Value Function Update Magnitude: 0.30204

Collected Steps per Second: 22,360.85497
Overall Steps per Second: 10,473.05549

Timestep Collection Time: 2.23614
Timestep Consumption Time: 2.53821
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.77435

Cumulative Model Updates: 363,022
Cumulative Timesteps: 3,027,657,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3027657436...
Checkpoint 3027657436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.56871
Policy Entropy: 3.83627
Value Function Loss: 0.00717

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.03237
Policy Update Magnitude: 0.24616
Value Function Update Magnitude: 0.31235

Collected Steps per Second: 22,721.48496
Overall Steps per Second: 10,622.88690

Timestep Collection Time: 2.20135
Timestep Consumption Time: 2.50716
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.70851

Cumulative Model Updates: 363,028
Cumulative Timesteps: 3,027,707,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.36087
Policy Entropy: 3.86787
Value Function Loss: 0.00669

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.03119
Policy Update Magnitude: 0.23996
Value Function Update Magnitude: 0.30623

Collected Steps per Second: 22,393.58925
Overall Steps per Second: 10,525.22573

Timestep Collection Time: 2.23305
Timestep Consumption Time: 2.51801
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.75106

Cumulative Model Updates: 363,034
Cumulative Timesteps: 3,027,757,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3027757460...
Checkpoint 3027757460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.64832
Policy Entropy: 3.90565
Value Function Loss: 0.00621

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02836
Policy Update Magnitude: 0.23688
Value Function Update Magnitude: 0.30684

Collected Steps per Second: 22,515.45883
Overall Steps per Second: 10,814.19476

Timestep Collection Time: 2.22079
Timestep Consumption Time: 2.40295
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.62374

Cumulative Model Updates: 363,040
Cumulative Timesteps: 3,027,807,462

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.33513
Policy Entropy: 3.93553
Value Function Loss: 0.00648

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.22413
Value Function Update Magnitude: 0.31453

Collected Steps per Second: 22,689.98919
Overall Steps per Second: 10,703.16865

Timestep Collection Time: 2.20406
Timestep Consumption Time: 2.46839
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.67245

Cumulative Model Updates: 363,046
Cumulative Timesteps: 3,027,857,472

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3027857472...
Checkpoint 3027857472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.03549
Policy Entropy: 3.96340
Value Function Loss: 0.00574

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02097
Policy Update Magnitude: 0.22365
Value Function Update Magnitude: 0.32219

Collected Steps per Second: 22,280.04438
Overall Steps per Second: 10,632.84481

Timestep Collection Time: 2.24416
Timestep Consumption Time: 2.45825
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.70241

Cumulative Model Updates: 363,052
Cumulative Timesteps: 3,027,907,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.37392
Policy Entropy: 3.97541
Value Function Loss: 0.00553

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01957
Policy Update Magnitude: 0.22754
Value Function Update Magnitude: 0.30260

Collected Steps per Second: 23,256.79491
Overall Steps per Second: 10,935.79774

Timestep Collection Time: 2.15025
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.57287

Cumulative Model Updates: 363,058
Cumulative Timesteps: 3,027,957,480

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3027957480...
Checkpoint 3027957480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.47200
Policy Entropy: 3.96857
Value Function Loss: 0.00581

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02163
Policy Update Magnitude: 0.22354
Value Function Update Magnitude: 0.27793

Collected Steps per Second: 21,709.60091
Overall Steps per Second: 10,554.72968

Timestep Collection Time: 2.30433
Timestep Consumption Time: 2.43535
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.73968

Cumulative Model Updates: 363,064
Cumulative Timesteps: 3,028,007,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.22117
Policy Entropy: 3.92157
Value Function Loss: 0.00631

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02308
Policy Update Magnitude: 0.22502
Value Function Update Magnitude: 0.26792

Collected Steps per Second: 21,867.48305
Overall Steps per Second: 10,464.18536

Timestep Collection Time: 2.28741
Timestep Consumption Time: 2.49270
PPO Batch Consumption Time: 0.30511
Total Iteration Time: 4.78011

Cumulative Model Updates: 363,070
Cumulative Timesteps: 3,028,057,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3028057526...
Checkpoint 3028057526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.87618
Policy Entropy: 3.91158
Value Function Loss: 0.00658

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.22948
Value Function Update Magnitude: 0.26999

Collected Steps per Second: 22,072.39663
Overall Steps per Second: 10,533.69123

Timestep Collection Time: 2.26600
Timestep Consumption Time: 2.48220
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.74819

Cumulative Model Updates: 363,076
Cumulative Timesteps: 3,028,107,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.30693
Policy Entropy: 3.91895
Value Function Loss: 0.00594

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.23398
Value Function Update Magnitude: 0.27802

Collected Steps per Second: 22,147.73705
Overall Steps per Second: 10,647.23274

Timestep Collection Time: 2.25802
Timestep Consumption Time: 2.43898
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.69700

Cumulative Model Updates: 363,082
Cumulative Timesteps: 3,028,157,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3028157552...
Checkpoint 3028157552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.89081
Policy Entropy: 3.94497
Value Function Loss: 0.00585

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.22630
Value Function Update Magnitude: 0.28132

Collected Steps per Second: 21,873.45825
Overall Steps per Second: 10,651.21883

Timestep Collection Time: 2.28798
Timestep Consumption Time: 2.41064
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.69862

Cumulative Model Updates: 363,088
Cumulative Timesteps: 3,028,207,598

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.42514
Policy Entropy: 3.90628
Value Function Loss: 0.00651

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.22524
Value Function Update Magnitude: 0.28523

Collected Steps per Second: 22,662.42690
Overall Steps per Second: 10,540.80478

Timestep Collection Time: 2.20691
Timestep Consumption Time: 2.53789
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.74480

Cumulative Model Updates: 363,094
Cumulative Timesteps: 3,028,257,612

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3028257612...
Checkpoint 3028257612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.34594
Policy Entropy: 3.91077
Value Function Loss: 0.00761

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02573
Policy Update Magnitude: 0.23121
Value Function Update Magnitude: 0.29593

Collected Steps per Second: 22,495.30250
Overall Steps per Second: 10,539.18463

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.52192
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.74496

Cumulative Model Updates: 363,100
Cumulative Timesteps: 3,028,307,620

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.81499
Policy Entropy: 3.91459
Value Function Loss: 0.00764

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.23477
Value Function Update Magnitude: 0.30848

Collected Steps per Second: 22,657.50585
Overall Steps per Second: 10,906.53642

Timestep Collection Time: 2.20686
Timestep Consumption Time: 2.37773
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.58459

Cumulative Model Updates: 363,106
Cumulative Timesteps: 3,028,357,622

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3028357622...
Checkpoint 3028357622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.69374
Policy Entropy: 3.95092
Value Function Loss: 0.00626

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02753
Policy Update Magnitude: 0.22913
Value Function Update Magnitude: 0.30647

Collected Steps per Second: 22,425.41657
Overall Steps per Second: 10,648.28457

Timestep Collection Time: 2.23068
Timestep Consumption Time: 2.46716
PPO Batch Consumption Time: 0.28379
Total Iteration Time: 4.69785

Cumulative Model Updates: 363,112
Cumulative Timesteps: 3,028,407,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.10009
Policy Entropy: 3.92034
Value Function Loss: 0.00636

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.23095
Value Function Update Magnitude: 0.29580

Collected Steps per Second: 22,572.14726
Overall Steps per Second: 10,816.28672

Timestep Collection Time: 2.21618
Timestep Consumption Time: 2.40869
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.62488

Cumulative Model Updates: 363,118
Cumulative Timesteps: 3,028,457,670

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3028457670...
Checkpoint 3028457670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.89341
Policy Entropy: 3.90158
Value Function Loss: 0.00645

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.23671
Value Function Update Magnitude: 0.29685

Collected Steps per Second: 22,228.78515
Overall Steps per Second: 10,706.85913

Timestep Collection Time: 2.24934
Timestep Consumption Time: 2.42057
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.66990

Cumulative Model Updates: 363,124
Cumulative Timesteps: 3,028,507,670

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.65488
Policy Entropy: 3.89046
Value Function Loss: 0.00646

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.23243
Value Function Update Magnitude: 0.29541

Collected Steps per Second: 22,203.65776
Overall Steps per Second: 10,463.95406

Timestep Collection Time: 2.25233
Timestep Consumption Time: 2.52693
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.77926

Cumulative Model Updates: 363,130
Cumulative Timesteps: 3,028,557,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3028557680...
Checkpoint 3028557680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.45488
Policy Entropy: 3.93079
Value Function Loss: 0.00555

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02286
Policy Update Magnitude: 0.22190
Value Function Update Magnitude: 0.29256

Collected Steps per Second: 21,901.52100
Overall Steps per Second: 10,670.32306

Timestep Collection Time: 2.28413
Timestep Consumption Time: 2.40420
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.68833

Cumulative Model Updates: 363,136
Cumulative Timesteps: 3,028,607,706

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.72601
Policy Entropy: 3.92634
Value Function Loss: 0.00557

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.21503
Value Function Update Magnitude: 0.28506

Collected Steps per Second: 22,324.50830
Overall Steps per Second: 10,861.94518

Timestep Collection Time: 2.24103
Timestep Consumption Time: 2.36495
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.60599

Cumulative Model Updates: 363,142
Cumulative Timesteps: 3,028,657,736

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3028657736...
Checkpoint 3028657736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.02492
Policy Entropy: 3.92178
Value Function Loss: 0.00600

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.21638
Value Function Update Magnitude: 0.28758

Collected Steps per Second: 21,837.12286
Overall Steps per Second: 10,578.44554

Timestep Collection Time: 2.28986
Timestep Consumption Time: 2.43711
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.72697

Cumulative Model Updates: 363,148
Cumulative Timesteps: 3,028,707,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.45204
Policy Entropy: 3.89958
Value Function Loss: 0.00673

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.22212
Value Function Update Magnitude: 0.28926

Collected Steps per Second: 21,824.88574
Overall Steps per Second: 10,420.63698

Timestep Collection Time: 2.29206
Timestep Consumption Time: 2.50841
PPO Batch Consumption Time: 0.29594
Total Iteration Time: 4.80047

Cumulative Model Updates: 363,154
Cumulative Timesteps: 3,028,757,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3028757764...
Checkpoint 3028757764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.82865
Policy Entropy: 3.95438
Value Function Loss: 0.00624

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.22760
Value Function Update Magnitude: 0.29385

Collected Steps per Second: 22,851.94191
Overall Steps per Second: 10,823.86108

Timestep Collection Time: 2.18861
Timestep Consumption Time: 2.43211
PPO Batch Consumption Time: 0.27656
Total Iteration Time: 4.62072

Cumulative Model Updates: 363,160
Cumulative Timesteps: 3,028,807,778

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.41053
Policy Entropy: 4.00785
Value Function Loss: 0.00555

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.21727
Value Function Update Magnitude: 0.28469

Collected Steps per Second: 22,980.84369
Overall Steps per Second: 10,773.87140

Timestep Collection Time: 2.17642
Timestep Consumption Time: 2.46592
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.64234

Cumulative Model Updates: 363,166
Cumulative Timesteps: 3,028,857,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3028857794...
Checkpoint 3028857794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.35359
Policy Entropy: 4.00246
Value Function Loss: 0.00621

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02017
Policy Update Magnitude: 0.21312
Value Function Update Magnitude: 0.27103

Collected Steps per Second: 22,173.77341
Overall Steps per Second: 10,714.43133

Timestep Collection Time: 2.25654
Timestep Consumption Time: 2.41342
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.66996

Cumulative Model Updates: 363,172
Cumulative Timesteps: 3,028,907,830

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.96926
Policy Entropy: 3.97417
Value Function Loss: 0.00673

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.21825
Value Function Update Magnitude: 0.26768

Collected Steps per Second: 22,754.01458
Overall Steps per Second: 10,697.36109

Timestep Collection Time: 2.19821
Timestep Consumption Time: 2.47753
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.67573

Cumulative Model Updates: 363,178
Cumulative Timesteps: 3,028,957,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3028957848...
Checkpoint 3028957848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.58770
Policy Entropy: 3.94301
Value Function Loss: 0.00684

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.22207
Value Function Update Magnitude: 0.27445

Collected Steps per Second: 22,124.70798
Overall Steps per Second: 10,572.91882

Timestep Collection Time: 2.26082
Timestep Consumption Time: 2.47013
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.73095

Cumulative Model Updates: 363,184
Cumulative Timesteps: 3,029,007,868

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.92720
Policy Entropy: 3.95644
Value Function Loss: 0.00647

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.22937
Value Function Update Magnitude: 0.27612

Collected Steps per Second: 22,770.94585
Overall Steps per Second: 10,811.24289

Timestep Collection Time: 2.19648
Timestep Consumption Time: 2.42981
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.62630

Cumulative Model Updates: 363,190
Cumulative Timesteps: 3,029,057,884

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3029057884...
Checkpoint 3029057884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.61111
Policy Entropy: 3.90245
Value Function Loss: 0.00707

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.23221
Value Function Update Magnitude: 0.30001

Collected Steps per Second: 22,358.35468
Overall Steps per Second: 10,635.05348

Timestep Collection Time: 2.23800
Timestep Consumption Time: 2.46701
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.70501

Cumulative Model Updates: 363,196
Cumulative Timesteps: 3,029,107,922

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.87285
Policy Entropy: 3.88216
Value Function Loss: 0.00697

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.24333
Value Function Update Magnitude: 0.30663

Collected Steps per Second: 21,983.67840
Overall Steps per Second: 10,517.37816

Timestep Collection Time: 2.27496
Timestep Consumption Time: 2.48022
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.75518

Cumulative Model Updates: 363,202
Cumulative Timesteps: 3,029,157,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3029157934...
Checkpoint 3029157934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.74269
Policy Entropy: 3.87699
Value Function Loss: 0.00665

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02883
Policy Update Magnitude: 0.24839
Value Function Update Magnitude: 0.30655

Collected Steps per Second: 21,943.00468
Overall Steps per Second: 10,625.76441

Timestep Collection Time: 2.27982
Timestep Consumption Time: 2.42818
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.70799

Cumulative Model Updates: 363,208
Cumulative Timesteps: 3,029,207,960

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.35052
Policy Entropy: 3.92672
Value Function Loss: 0.00587

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.23541
Value Function Update Magnitude: 0.30203

Collected Steps per Second: 22,481.75240
Overall Steps per Second: 10,576.12268

Timestep Collection Time: 2.22429
Timestep Consumption Time: 2.50391
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.72820

Cumulative Model Updates: 363,214
Cumulative Timesteps: 3,029,257,966

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3029257966...
Checkpoint 3029257966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.70569
Policy Entropy: 3.95946
Value Function Loss: 0.00556

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02443
Policy Update Magnitude: 0.22337
Value Function Update Magnitude: 0.29283

Collected Steps per Second: 22,151.58218
Overall Steps per Second: 10,541.91187

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.74316

Cumulative Model Updates: 363,220
Cumulative Timesteps: 3,029,307,968

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.22553
Policy Entropy: 3.96316
Value Function Loss: 0.00571

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02214
Policy Update Magnitude: 0.21540
Value Function Update Magnitude: 0.29415

Collected Steps per Second: 23,377.20669
Overall Steps per Second: 10,858.19064

Timestep Collection Time: 2.13961
Timestep Consumption Time: 2.46687
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.60648

Cumulative Model Updates: 363,226
Cumulative Timesteps: 3,029,357,986

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3029357986...
Checkpoint 3029357986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.36103
Policy Entropy: 3.96502
Value Function Loss: 0.00537

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02054
Policy Update Magnitude: 0.21656
Value Function Update Magnitude: 0.28710

Collected Steps per Second: 22,253.83668
Overall Steps per Second: 10,635.92114

Timestep Collection Time: 2.24707
Timestep Consumption Time: 2.45454
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.70161

Cumulative Model Updates: 363,232
Cumulative Timesteps: 3,029,407,992

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.54728
Policy Entropy: 3.94521
Value Function Loss: 0.00661

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02035
Policy Update Magnitude: 0.23026
Value Function Update Magnitude: 0.28297

Collected Steps per Second: 22,300.92759
Overall Steps per Second: 10,629.34491

Timestep Collection Time: 2.24260
Timestep Consumption Time: 2.46249
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.70509

Cumulative Model Updates: 363,238
Cumulative Timesteps: 3,029,458,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3029458004...
Checkpoint 3029458004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.98414
Policy Entropy: 3.95647
Value Function Loss: 0.00600

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02033
Policy Update Magnitude: 0.22688
Value Function Update Magnitude: 0.29303

Collected Steps per Second: 23,173.29459
Overall Steps per Second: 10,879.64139

Timestep Collection Time: 2.15792
Timestep Consumption Time: 2.43838
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.59629

Cumulative Model Updates: 363,244
Cumulative Timesteps: 3,029,508,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.88843
Policy Entropy: 3.92425
Value Function Loss: 0.00580

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02039
Policy Update Magnitude: 0.22525
Value Function Update Magnitude: 0.30353

Collected Steps per Second: 22,598.14330
Overall Steps per Second: 10,599.87222

Timestep Collection Time: 2.21399
Timestep Consumption Time: 2.50607
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.72006

Cumulative Model Updates: 363,250
Cumulative Timesteps: 3,029,558,042

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3029558042...
Checkpoint 3029558042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.65152
Policy Entropy: 3.90528
Value Function Loss: 0.00554

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02238
Policy Update Magnitude: 0.23126
Value Function Update Magnitude: 0.30300

Collected Steps per Second: 21,328.81720
Overall Steps per Second: 10,577.89938

Timestep Collection Time: 2.34537
Timestep Consumption Time: 2.38373
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.72911

Cumulative Model Updates: 363,256
Cumulative Timesteps: 3,029,608,066

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.51028
Policy Entropy: 3.90555
Value Function Loss: 0.00524

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02227
Policy Update Magnitude: 0.22726
Value Function Update Magnitude: 0.28897

Collected Steps per Second: 22,170.58205
Overall Steps per Second: 10,498.14354

Timestep Collection Time: 2.25668
Timestep Consumption Time: 2.50911
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.76580

Cumulative Model Updates: 363,262
Cumulative Timesteps: 3,029,658,098

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3029658098...
Checkpoint 3029658098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94.73460
Policy Entropy: 3.90468
Value Function Loss: 0.00599

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02304
Policy Update Magnitude: 0.22872
Value Function Update Magnitude: 0.29380

Collected Steps per Second: 22,106.25673
Overall Steps per Second: 10,563.50689

Timestep Collection Time: 2.26180
Timestep Consumption Time: 2.47147
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.73328

Cumulative Model Updates: 363,268
Cumulative Timesteps: 3,029,708,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.38363
Policy Entropy: 3.91100
Value Function Loss: 0.00598

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.23686
Value Function Update Magnitude: 0.30179

Collected Steps per Second: 22,109.44822
Overall Steps per Second: 10,607.94016

Timestep Collection Time: 2.26238
Timestep Consumption Time: 2.45295
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.71534

Cumulative Model Updates: 363,274
Cumulative Timesteps: 3,029,758,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3029758118...
Checkpoint 3029758118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.59740
Policy Entropy: 3.90654
Value Function Loss: 0.00671

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.02946
Policy Update Magnitude: 0.23798
Value Function Update Magnitude: 0.30478

Collected Steps per Second: 22,629.58431
Overall Steps per Second: 10,546.61570

Timestep Collection Time: 2.20976
Timestep Consumption Time: 2.53166
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.74143

Cumulative Model Updates: 363,280
Cumulative Timesteps: 3,029,808,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.08773
Policy Entropy: 3.93692
Value Function Loss: 0.00668

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.04457
Policy Update Magnitude: 0.28952
Value Function Update Magnitude: 0.30336

Collected Steps per Second: 22,720.98156
Overall Steps per Second: 10,822.72746

Timestep Collection Time: 2.20114
Timestep Consumption Time: 2.41988
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.62102

Cumulative Model Updates: 363,286
Cumulative Timesteps: 3,029,858,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3029858136...
Checkpoint 3029858136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.78511
Policy Entropy: 3.91326
Value Function Loss: 0.00798

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.05176
Policy Update Magnitude: 0.29738
Value Function Update Magnitude: 0.31537

Collected Steps per Second: 23,060.13699
Overall Steps per Second: 10,669.50891

Timestep Collection Time: 2.16842
Timestep Consumption Time: 2.51821
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.68663

Cumulative Model Updates: 363,292
Cumulative Timesteps: 3,029,908,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.56134
Policy Entropy: 3.91738
Value Function Loss: 0.00849

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.05234
Policy Update Magnitude: 0.27031
Value Function Update Magnitude: 0.34896

Collected Steps per Second: 22,577.58676
Overall Steps per Second: 10,620.21012

Timestep Collection Time: 2.21600
Timestep Consumption Time: 2.49501
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.71102

Cumulative Model Updates: 363,298
Cumulative Timesteps: 3,029,958,172

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3029958172...
Checkpoint 3029958172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.37499
Policy Entropy: 3.84763
Value Function Loss: 0.00879

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.04608
Policy Update Magnitude: 0.26980
Value Function Update Magnitude: 0.37061

Collected Steps per Second: 22,369.11191
Overall Steps per Second: 10,679.14369

Timestep Collection Time: 2.23540
Timestep Consumption Time: 2.44699
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.68240

Cumulative Model Updates: 363,304
Cumulative Timesteps: 3,030,008,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.94143
Policy Entropy: 3.84832
Value Function Loss: 0.00879

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.03842
Policy Update Magnitude: 0.26720
Value Function Update Magnitude: 0.37143

Collected Steps per Second: 23,458.74471
Overall Steps per Second: 10,652.03482

Timestep Collection Time: 2.13149
Timestep Consumption Time: 2.56264
PPO Batch Consumption Time: 0.29890
Total Iteration Time: 4.69413

Cumulative Model Updates: 363,310
Cumulative Timesteps: 3,030,058,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3030058178...
Checkpoint 3030058178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.82559
Policy Entropy: 3.88203
Value Function Loss: 0.00724

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.03260
Policy Update Magnitude: 0.25867
Value Function Update Magnitude: 0.35707

Collected Steps per Second: 21,687.22386
Overall Steps per Second: 10,480.17867

Timestep Collection Time: 2.30569
Timestep Consumption Time: 2.46560
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.77129

Cumulative Model Updates: 363,316
Cumulative Timesteps: 3,030,108,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.03394
Policy Entropy: 3.90398
Value Function Loss: 0.00671

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02818
Policy Update Magnitude: 0.24265
Value Function Update Magnitude: 0.34147

Collected Steps per Second: 22,163.34652
Overall Steps per Second: 10,741.32385

Timestep Collection Time: 2.25598
Timestep Consumption Time: 2.39894
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.65492

Cumulative Model Updates: 363,322
Cumulative Timesteps: 3,030,158,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3030158182...
Checkpoint 3030158182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.61187
Policy Entropy: 3.92307
Value Function Loss: 0.00634

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02799
Policy Update Magnitude: 0.23921
Value Function Update Magnitude: 0.33147

Collected Steps per Second: 21,669.02922
Overall Steps per Second: 10,504.20389

Timestep Collection Time: 2.30753
Timestep Consumption Time: 2.45266
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.76019

Cumulative Model Updates: 363,328
Cumulative Timesteps: 3,030,208,184

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.78621
Policy Entropy: 3.89430
Value Function Loss: 0.00736

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03236
Policy Update Magnitude: 0.24025
Value Function Update Magnitude: 0.33097

Collected Steps per Second: 20,693.58504
Overall Steps per Second: 10,032.18247

Timestep Collection Time: 2.41756
Timestep Consumption Time: 2.56919
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.98675

Cumulative Model Updates: 363,334
Cumulative Timesteps: 3,030,258,212

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3030258212...
Checkpoint 3030258212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.19343
Policy Entropy: 3.91667
Value Function Loss: 0.00743

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.23744
Value Function Update Magnitude: 0.33455

Collected Steps per Second: 19,675.67748
Overall Steps per Second: 9,862.40243

Timestep Collection Time: 2.54172
Timestep Consumption Time: 2.52906
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 5.07077

Cumulative Model Updates: 363,340
Cumulative Timesteps: 3,030,308,222

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.08940
Policy Entropy: 3.96566
Value Function Loss: 0.00645

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.22972
Value Function Update Magnitude: 0.33099

Collected Steps per Second: 22,592.26190
Overall Steps per Second: 10,601.96986

Timestep Collection Time: 2.21332
Timestep Consumption Time: 2.50316
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.71648

Cumulative Model Updates: 363,346
Cumulative Timesteps: 3,030,358,226

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3030358226...
Checkpoint 3030358226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.80302
Policy Entropy: 3.93508
Value Function Loss: 0.00683

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.22549
Value Function Update Magnitude: 0.31752

Collected Steps per Second: 22,391.64141
Overall Steps per Second: 10,484.00690

Timestep Collection Time: 2.23441
Timestep Consumption Time: 2.53782
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.77222

Cumulative Model Updates: 363,352
Cumulative Timesteps: 3,030,408,258

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.95733
Policy Entropy: 3.97581
Value Function Loss: 0.00620

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.22464
Value Function Update Magnitude: 0.29896

Collected Steps per Second: 22,768.76109
Overall Steps per Second: 10,871.34263

Timestep Collection Time: 2.19722
Timestep Consumption Time: 2.40460
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.60182

Cumulative Model Updates: 363,358
Cumulative Timesteps: 3,030,458,286

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3030458286...
Checkpoint 3030458286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.28557
Policy Entropy: 3.92883
Value Function Loss: 0.00641

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.23003
Value Function Update Magnitude: 0.29551

Collected Steps per Second: 22,223.02677
Overall Steps per Second: 10,635.90626

Timestep Collection Time: 2.25109
Timestep Consumption Time: 2.45241
PPO Batch Consumption Time: 0.27957
Total Iteration Time: 4.70350

Cumulative Model Updates: 363,364
Cumulative Timesteps: 3,030,508,312

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.20660
Policy Entropy: 3.96783
Value Function Loss: 0.00535

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02402
Policy Update Magnitude: 0.22225
Value Function Update Magnitude: 0.29180

Collected Steps per Second: 22,563.93483
Overall Steps per Second: 10,659.41492

Timestep Collection Time: 2.21601
Timestep Consumption Time: 2.47486
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.69088

Cumulative Model Updates: 363,370
Cumulative Timesteps: 3,030,558,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3030558314...
Checkpoint 3030558314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.52159
Policy Entropy: 3.95407
Value Function Loss: 0.00505

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02470
Policy Update Magnitude: 0.21420
Value Function Update Magnitude: 0.29824

Collected Steps per Second: 23,084.28585
Overall Steps per Second: 10,791.65147

Timestep Collection Time: 2.16641
Timestep Consumption Time: 2.46773
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.63414

Cumulative Model Updates: 363,376
Cumulative Timesteps: 3,030,608,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.40166
Policy Entropy: 3.95915
Value Function Loss: 0.00477

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02464
Policy Update Magnitude: 0.21111
Value Function Update Magnitude: 0.28392

Collected Steps per Second: 22,671.25399
Overall Steps per Second: 10,687.66638

Timestep Collection Time: 2.20588
Timestep Consumption Time: 2.47335
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.67923

Cumulative Model Updates: 363,382
Cumulative Timesteps: 3,030,658,334

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3030658334...
Checkpoint 3030658334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.94379
Policy Entropy: 3.97056
Value Function Loss: 0.00531

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02083
Policy Update Magnitude: 0.21534
Value Function Update Magnitude: 0.27074

Collected Steps per Second: 22,416.77801
Overall Steps per Second: 10,465.53141

Timestep Collection Time: 2.23145
Timestep Consumption Time: 2.54824
PPO Batch Consumption Time: 0.30093
Total Iteration Time: 4.77969

Cumulative Model Updates: 363,388
Cumulative Timesteps: 3,030,708,356

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.63105
Policy Entropy: 3.96524
Value Function Loss: 0.00548

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02058
Policy Update Magnitude: 0.21220
Value Function Update Magnitude: 0.28530

Collected Steps per Second: 22,740.67732
Overall Steps per Second: 10,640.84194

Timestep Collection Time: 2.19870
Timestep Consumption Time: 2.50017
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.69888

Cumulative Model Updates: 363,394
Cumulative Timesteps: 3,030,758,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3030758356...
Checkpoint 3030758356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.43391
Policy Entropy: 3.97014
Value Function Loss: 0.00642

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01776
Policy Update Magnitude: 0.21487
Value Function Update Magnitude: 0.30390

Collected Steps per Second: 21,728.97046
Overall Steps per Second: 10,558.33465

Timestep Collection Time: 2.30144
Timestep Consumption Time: 2.43491
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.73635

Cumulative Model Updates: 363,400
Cumulative Timesteps: 3,030,808,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.01436
Policy Entropy: 3.92544
Value Function Loss: 0.00686

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02361
Policy Update Magnitude: 0.22844
Value Function Update Magnitude: 0.32307

Collected Steps per Second: 22,170.89111
Overall Steps per Second: 10,707.58831

Timestep Collection Time: 2.25620
Timestep Consumption Time: 2.41544
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.67164

Cumulative Model Updates: 363,406
Cumulative Timesteps: 3,030,858,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3030858386...
Checkpoint 3030858386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.50388
Policy Entropy: 3.92577
Value Function Loss: 0.00651

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.22643
Value Function Update Magnitude: 0.33294

Collected Steps per Second: 21,920.47989
Overall Steps per Second: 10,434.08785

Timestep Collection Time: 2.28106
Timestep Consumption Time: 2.51111
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.79218

Cumulative Model Updates: 363,412
Cumulative Timesteps: 3,030,908,388

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.53495
Policy Entropy: 3.94307
Value Function Loss: 0.00640

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.22684
Value Function Update Magnitude: 0.32365

Collected Steps per Second: 22,251.74612
Overall Steps per Second: 10,574.59350

Timestep Collection Time: 2.24827
Timestep Consumption Time: 2.48269
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.73096

Cumulative Model Updates: 363,418
Cumulative Timesteps: 3,030,958,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3030958416...
Checkpoint 3030958416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.99280
Policy Entropy: 3.96908
Value Function Loss: 0.00587

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02080
Policy Update Magnitude: 0.22145
Value Function Update Magnitude: 0.30856

Collected Steps per Second: 21,953.16436
Overall Steps per Second: 10,596.33543

Timestep Collection Time: 2.27794
Timestep Consumption Time: 2.44143
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.71937

Cumulative Model Updates: 363,424
Cumulative Timesteps: 3,031,008,424

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.18731
Policy Entropy: 3.97224
Value Function Loss: 0.00572

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02090
Policy Update Magnitude: 0.22187
Value Function Update Magnitude: 0.30329

Collected Steps per Second: 22,621.99783
Overall Steps per Second: 10,503.94489

Timestep Collection Time: 2.21086
Timestep Consumption Time: 2.55059
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.76145

Cumulative Model Updates: 363,430
Cumulative Timesteps: 3,031,058,438

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3031058438...
Checkpoint 3031058438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.70734
Policy Entropy: 3.96880
Value Function Loss: 0.00576

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.02066
Policy Update Magnitude: 0.21355
Value Function Update Magnitude: 0.30091

Collected Steps per Second: 22,378.45212
Overall Steps per Second: 10,547.28690

Timestep Collection Time: 2.23510
Timestep Consumption Time: 2.50717
PPO Batch Consumption Time: 0.29340
Total Iteration Time: 4.74226

Cumulative Model Updates: 363,436
Cumulative Timesteps: 3,031,108,456

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.93995
Policy Entropy: 3.95507
Value Function Loss: 0.00589

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02128
Policy Update Magnitude: 0.21864
Value Function Update Magnitude: 0.31219

Collected Steps per Second: 23,332.53882
Overall Steps per Second: 10,900.44468

Timestep Collection Time: 2.14387
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.58899

Cumulative Model Updates: 363,442
Cumulative Timesteps: 3,031,158,478

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3031158478...
Checkpoint 3031158478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.33366
Policy Entropy: 3.93396
Value Function Loss: 0.00566

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.22077
Value Function Update Magnitude: 0.31870

Collected Steps per Second: 22,273.36914
Overall Steps per Second: 10,647.61738

Timestep Collection Time: 2.24573
Timestep Consumption Time: 2.45203
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.69776

Cumulative Model Updates: 363,448
Cumulative Timesteps: 3,031,208,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.04113
Policy Entropy: 3.91101
Value Function Loss: 0.00584

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02583
Policy Update Magnitude: 0.22183
Value Function Update Magnitude: 0.31052

Collected Steps per Second: 22,578.44405
Overall Steps per Second: 10,666.88723

Timestep Collection Time: 2.21618
Timestep Consumption Time: 2.47478
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.69097

Cumulative Model Updates: 363,454
Cumulative Timesteps: 3,031,258,536

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3031258536...
Checkpoint 3031258536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.78196
Policy Entropy: 3.88695
Value Function Loss: 0.00627

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.23770
Value Function Update Magnitude: 0.31035

Collected Steps per Second: 23,257.28759
Overall Steps per Second: 10,891.59788

Timestep Collection Time: 2.15098
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.59308

Cumulative Model Updates: 363,460
Cumulative Timesteps: 3,031,308,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.50768
Policy Entropy: 3.87127
Value Function Loss: 0.00672

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.24548
Value Function Update Magnitude: 0.33771

Collected Steps per Second: 22,267.66359
Overall Steps per Second: 10,395.27079

Timestep Collection Time: 2.24568
Timestep Consumption Time: 2.56478
PPO Batch Consumption Time: 0.30227
Total Iteration Time: 4.81046

Cumulative Model Updates: 363,466
Cumulative Timesteps: 3,031,358,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3031358568...
Checkpoint 3031358568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.81612
Policy Entropy: 3.88628
Value Function Loss: 0.00643

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 0.24915
Value Function Update Magnitude: 0.33412

Collected Steps per Second: 21,635.13515
Overall Steps per Second: 10,356.86729

Timestep Collection Time: 2.31152
Timestep Consumption Time: 2.51716
PPO Batch Consumption Time: 0.29611
Total Iteration Time: 4.82868

Cumulative Model Updates: 363,472
Cumulative Timesteps: 3,031,408,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.93911
Policy Entropy: 3.93108
Value Function Loss: 0.00605

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02942
Policy Update Magnitude: 0.23845
Value Function Update Magnitude: 0.31865

Collected Steps per Second: 23,019.03293
Overall Steps per Second: 10,822.98956

Timestep Collection Time: 2.17255
Timestep Consumption Time: 2.44817
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.62072

Cumulative Model Updates: 363,478
Cumulative Timesteps: 3,031,458,588

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3031458588...
Checkpoint 3031458588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.25516
Policy Entropy: 3.96959
Value Function Loss: 0.00624

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.22843
Value Function Update Magnitude: 0.31052

Collected Steps per Second: 21,779.24204
Overall Steps per Second: 10,389.30819

Timestep Collection Time: 2.29604
Timestep Consumption Time: 2.51718
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.81322

Cumulative Model Updates: 363,484
Cumulative Timesteps: 3,031,508,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.87344
Policy Entropy: 3.94916
Value Function Loss: 0.00645

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02628
Policy Update Magnitude: 0.22983
Value Function Update Magnitude: 0.31282

Collected Steps per Second: 22,343.30343
Overall Steps per Second: 10,739.41239

Timestep Collection Time: 2.23808
Timestep Consumption Time: 2.41823
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.65631

Cumulative Model Updates: 363,490
Cumulative Timesteps: 3,031,558,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3031558600...
Checkpoint 3031558600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.22735
Policy Entropy: 3.93615
Value Function Loss: 0.00662

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.23954
Value Function Update Magnitude: 0.31316

Collected Steps per Second: 22,727.15085
Overall Steps per Second: 10,576.32132

Timestep Collection Time: 2.20045
Timestep Consumption Time: 2.52804
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.72849

Cumulative Model Updates: 363,496
Cumulative Timesteps: 3,031,608,610

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.52368
Policy Entropy: 3.90041
Value Function Loss: 0.00636

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.24057
Value Function Update Magnitude: 0.31460

Collected Steps per Second: 22,359.50220
Overall Steps per Second: 10,518.05212

Timestep Collection Time: 2.23762
Timestep Consumption Time: 2.51916
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.75677

Cumulative Model Updates: 363,502
Cumulative Timesteps: 3,031,658,642

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3031658642...
Checkpoint 3031658642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.91585
Policy Entropy: 3.94671
Value Function Loss: 0.00595

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02318
Policy Update Magnitude: 0.23947
Value Function Update Magnitude: 0.30411

Collected Steps per Second: 22,604.99818
Overall Steps per Second: 10,780.80102

Timestep Collection Time: 2.21190
Timestep Consumption Time: 2.42597
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.63787

Cumulative Model Updates: 363,508
Cumulative Timesteps: 3,031,708,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.99547
Policy Entropy: 3.97151
Value Function Loss: 0.00599

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02322
Policy Update Magnitude: 0.23616
Value Function Update Magnitude: 0.29746

Collected Steps per Second: 22,921.43595
Overall Steps per Second: 10,749.50631

Timestep Collection Time: 2.18215
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.65305

Cumulative Model Updates: 363,514
Cumulative Timesteps: 3,031,758,660

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3031758660...
Checkpoint 3031758660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.71155
Policy Entropy: 3.98612
Value Function Loss: 0.00580

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01968
Policy Update Magnitude: 0.22029
Value Function Update Magnitude: 0.29052

Collected Steps per Second: 22,522.70912
Overall Steps per Second: 10,670.31880

Timestep Collection Time: 2.22096
Timestep Consumption Time: 2.46700
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.68796

Cumulative Model Updates: 363,520
Cumulative Timesteps: 3,031,808,682

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65491
Policy Entropy: 3.99938
Value Function Loss: 0.00546

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.21554
Value Function Update Magnitude: 0.29638

Collected Steps per Second: 22,040.93935
Overall Steps per Second: 10,657.49742

Timestep Collection Time: 2.26996
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.69454

Cumulative Model Updates: 363,526
Cumulative Timesteps: 3,031,858,714

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3031858714...
Checkpoint 3031858714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.49088
Policy Entropy: 3.99992
Value Function Loss: 0.00517

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02291
Policy Update Magnitude: 0.22722
Value Function Update Magnitude: 0.29987

Collected Steps per Second: 22,295.02526
Overall Steps per Second: 10,553.50309

Timestep Collection Time: 2.24319
Timestep Consumption Time: 2.49571
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.73890

Cumulative Model Updates: 363,532
Cumulative Timesteps: 3,031,908,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.52019
Policy Entropy: 3.99415
Value Function Loss: 0.00494

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.22278
Value Function Update Magnitude: 0.30605

Collected Steps per Second: 22,020.47212
Overall Steps per Second: 10,584.23253

Timestep Collection Time: 2.27080
Timestep Consumption Time: 2.45359
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.72439

Cumulative Model Updates: 363,538
Cumulative Timesteps: 3,031,958,730

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3031958730...
Checkpoint 3031958730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.96692
Policy Entropy: 3.90055
Value Function Loss: 0.00612

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.23131
Value Function Update Magnitude: 0.30450

Collected Steps per Second: 21,757.59072
Overall Steps per Second: 10,773.54422

Timestep Collection Time: 2.29906
Timestep Consumption Time: 2.34398
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.64304

Cumulative Model Updates: 363,544
Cumulative Timesteps: 3,032,008,752

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.05037
Policy Entropy: 3.83953
Value Function Loss: 0.00747

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.25023
Value Function Update Magnitude: 0.33237

Collected Steps per Second: 21,759.59437
Overall Steps per Second: 10,380.91431

Timestep Collection Time: 2.29885
Timestep Consumption Time: 2.51980
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.81865

Cumulative Model Updates: 363,550
Cumulative Timesteps: 3,032,058,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3032058774...
Checkpoint 3032058774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.75543
Policy Entropy: 3.78684
Value Function Loss: 0.00801

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 0.26227
Value Function Update Magnitude: 0.36034

Collected Steps per Second: 21,812.63170
Overall Steps per Second: 10,469.39409

Timestep Collection Time: 2.29289
Timestep Consumption Time: 2.48427
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.77716

Cumulative Model Updates: 363,556
Cumulative Timesteps: 3,032,108,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.58782
Policy Entropy: 3.82342
Value Function Loss: 0.00754

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.03593
Policy Update Magnitude: 0.26788
Value Function Update Magnitude: 0.37734

Collected Steps per Second: 22,374.36256
Overall Steps per Second: 10,680.10113

Timestep Collection Time: 2.23497
Timestep Consumption Time: 2.44720
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.68217

Cumulative Model Updates: 363,562
Cumulative Timesteps: 3,032,158,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3032158794...
Checkpoint 3032158794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.14252
Policy Entropy: 3.82990
Value Function Loss: 0.00786

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.03619
Policy Update Magnitude: 0.26861
Value Function Update Magnitude: 0.37030

Collected Steps per Second: 22,698.52116
Overall Steps per Second: 10,773.53689

Timestep Collection Time: 2.20296
Timestep Consumption Time: 2.43841
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.64137

Cumulative Model Updates: 363,568
Cumulative Timesteps: 3,032,208,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.92292
Policy Entropy: 3.88120
Value Function Loss: 0.00717

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.03429
Policy Update Magnitude: 0.25993
Value Function Update Magnitude: 0.36810

Collected Steps per Second: 22,575.37604
Overall Steps per Second: 10,774.40149

Timestep Collection Time: 2.21516
Timestep Consumption Time: 2.42621
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.64137

Cumulative Model Updates: 363,574
Cumulative Timesteps: 3,032,258,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3032258806...
Checkpoint 3032258806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.03149
Policy Entropy: 3.92945
Value Function Loss: 0.00648

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02894
Policy Update Magnitude: 0.25455
Value Function Update Magnitude: 0.35123

Collected Steps per Second: 22,861.29917
Overall Steps per Second: 10,870.94417

Timestep Collection Time: 2.18710
Timestep Consumption Time: 2.41231
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.59942

Cumulative Model Updates: 363,580
Cumulative Timesteps: 3,032,308,806

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.58374
Policy Entropy: 3.90469
Value Function Loss: 0.00678

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.24522
Value Function Update Magnitude: 0.33396

Collected Steps per Second: 22,181.22637
Overall Steps per Second: 10,552.56739

Timestep Collection Time: 2.25470
Timestep Consumption Time: 2.48462
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.73932

Cumulative Model Updates: 363,586
Cumulative Timesteps: 3,032,358,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3032358818...
Checkpoint 3032358818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.30960
Policy Entropy: 3.88892
Value Function Loss: 0.00692

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.03026
Policy Update Magnitude: 0.24679
Value Function Update Magnitude: 0.33312

Collected Steps per Second: 22,436.35443
Overall Steps per Second: 10,821.22747

Timestep Collection Time: 2.22888
Timestep Consumption Time: 2.39240
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.62129

Cumulative Model Updates: 363,592
Cumulative Timesteps: 3,032,408,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.22257
Policy Entropy: 3.85929
Value Function Loss: 0.00707

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.03550
Policy Update Magnitude: 0.24414
Value Function Update Magnitude: 0.32980

Collected Steps per Second: 22,598.18087
Overall Steps per Second: 10,605.24937

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.71634

Cumulative Model Updates: 363,598
Cumulative Timesteps: 3,032,458,844

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3032458844...
Checkpoint 3032458844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.09653
Policy Entropy: 3.90472
Value Function Loss: 0.00638

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03081
Policy Update Magnitude: 0.23854
Value Function Update Magnitude: 0.31930

Collected Steps per Second: 21,719.26411
Overall Steps per Second: 10,593.43710

Timestep Collection Time: 2.30256
Timestep Consumption Time: 2.41828
PPO Batch Consumption Time: 0.27676
Total Iteration Time: 4.72085

Cumulative Model Updates: 363,604
Cumulative Timesteps: 3,032,508,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.42775
Policy Entropy: 3.91680
Value Function Loss: 0.00670

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02910
Policy Update Magnitude: 0.24457
Value Function Update Magnitude: 0.31397

Collected Steps per Second: 22,041.19286
Overall Steps per Second: 10,814.20601

Timestep Collection Time: 2.26902
Timestep Consumption Time: 2.35563
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.62466

Cumulative Model Updates: 363,610
Cumulative Timesteps: 3,032,558,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3032558866...
Checkpoint 3032558866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.51435
Policy Entropy: 3.87922
Value Function Loss: 0.00788

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.03461
Policy Update Magnitude: 0.25852
Value Function Update Magnitude: 0.31893

Collected Steps per Second: 22,044.19929
Overall Steps per Second: 10,639.42846

Timestep Collection Time: 2.26890
Timestep Consumption Time: 2.43211
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.70100

Cumulative Model Updates: 363,616
Cumulative Timesteps: 3,032,608,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.19205
Policy Entropy: 3.88373
Value Function Loss: 0.00794

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.26726
Value Function Update Magnitude: 0.33315

Collected Steps per Second: 22,176.63460
Overall Steps per Second: 10,568.99695

Timestep Collection Time: 2.25544
Timestep Consumption Time: 2.47708
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.73252

Cumulative Model Updates: 363,622
Cumulative Timesteps: 3,032,658,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3032658900...
Checkpoint 3032658900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.96273
Policy Entropy: 3.88602
Value Function Loss: 0.00721

Mean KL Divergence: 0.00602
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.27042
Value Function Update Magnitude: 0.33665

Collected Steps per Second: 21,996.84106
Overall Steps per Second: 10,608.77085

Timestep Collection Time: 2.27405
Timestep Consumption Time: 2.44110
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.71516

Cumulative Model Updates: 363,628
Cumulative Timesteps: 3,032,708,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.89780
Policy Entropy: 3.93004
Value Function Loss: 0.00608

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.25654
Value Function Update Magnitude: 0.31352

Collected Steps per Second: 22,585.07231
Overall Steps per Second: 10,635.55568

Timestep Collection Time: 2.21456
Timestep Consumption Time: 2.48816
PPO Batch Consumption Time: 0.28566
Total Iteration Time: 4.70272

Cumulative Model Updates: 363,634
Cumulative Timesteps: 3,032,758,938

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3032758938...
Checkpoint 3032758938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.90153
Policy Entropy: 3.87555
Value Function Loss: 0.00629

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.02944
Policy Update Magnitude: 0.24353
Value Function Update Magnitude: 0.28924

Collected Steps per Second: 22,522.29936
Overall Steps per Second: 10,799.66526

Timestep Collection Time: 2.22029
Timestep Consumption Time: 2.41004
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.63033

Cumulative Model Updates: 363,640
Cumulative Timesteps: 3,032,808,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.40024
Policy Entropy: 3.87991
Value Function Loss: 0.00642

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02657
Policy Update Magnitude: 0.23777
Value Function Update Magnitude: 0.29606

Collected Steps per Second: 22,569.48872
Overall Steps per Second: 10,913.37202

Timestep Collection Time: 2.21556
Timestep Consumption Time: 2.36634
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.58190

Cumulative Model Updates: 363,646
Cumulative Timesteps: 3,032,858,948

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3032858948...
Checkpoint 3032858948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.33252
Policy Entropy: 3.87913
Value Function Loss: 0.00599

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.24305
Value Function Update Magnitude: 0.31559

Collected Steps per Second: 22,418.62892
Overall Steps per Second: 10,712.41157

Timestep Collection Time: 2.23073
Timestep Consumption Time: 2.43768
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.66842

Cumulative Model Updates: 363,652
Cumulative Timesteps: 3,032,908,958

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.86714
Policy Entropy: 3.92593
Value Function Loss: 0.00662

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03147
Policy Update Magnitude: 0.25167
Value Function Update Magnitude: 0.31990

Collected Steps per Second: 22,925.02556
Overall Steps per Second: 10,887.69922

Timestep Collection Time: 2.18198
Timestep Consumption Time: 2.41238
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.59436

Cumulative Model Updates: 363,658
Cumulative Timesteps: 3,032,958,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3032958980...
Checkpoint 3032958980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.86580
Policy Entropy: 3.93988
Value Function Loss: 0.00652

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.24747
Value Function Update Magnitude: 0.33730

Collected Steps per Second: 22,128.82910
Overall Steps per Second: 10,648.07497

Timestep Collection Time: 2.26067
Timestep Consumption Time: 2.43746
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.69813

Cumulative Model Updates: 363,664
Cumulative Timesteps: 3,033,009,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.15996
Policy Entropy: 3.92932
Value Function Loss: 0.00685

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 0.25052
Value Function Update Magnitude: 0.34093

Collected Steps per Second: 22,166.06052
Overall Steps per Second: 9,988.54223

Timestep Collection Time: 2.25705
Timestep Consumption Time: 2.75168
PPO Batch Consumption Time: 0.31225
Total Iteration Time: 5.00874

Cumulative Model Updates: 363,670
Cumulative Timesteps: 3,033,059,036

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3033059036...
Checkpoint 3033059036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.10560
Policy Entropy: 3.94970
Value Function Loss: 0.00680

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.03031
Policy Update Magnitude: 0.25259
Value Function Update Magnitude: 0.33930

Collected Steps per Second: 19,826.41756
Overall Steps per Second: 9,874.90068

Timestep Collection Time: 2.52259
Timestep Consumption Time: 2.54217
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 5.06476

Cumulative Model Updates: 363,676
Cumulative Timesteps: 3,033,109,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.51796
Policy Entropy: 3.92062
Value Function Loss: 0.00677

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.03432
Policy Update Magnitude: 0.24909
Value Function Update Magnitude: 0.33553

Collected Steps per Second: 19,066.59396
Overall Steps per Second: 9,502.81467

Timestep Collection Time: 2.62291
Timestep Consumption Time: 2.63974
PPO Batch Consumption Time: 0.30165
Total Iteration Time: 5.26265

Cumulative Model Updates: 363,682
Cumulative Timesteps: 3,033,159,060

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3033159060...
Checkpoint 3033159060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.92249
Policy Entropy: 3.89917
Value Function Loss: 0.00702

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.03294
Policy Update Magnitude: 0.26966
Value Function Update Magnitude: 0.32264

Collected Steps per Second: 18,408.42592
Overall Steps per Second: 9,442.25796

Timestep Collection Time: 2.71876
Timestep Consumption Time: 2.58167
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 5.30043

Cumulative Model Updates: 363,688
Cumulative Timesteps: 3,033,209,108

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.92356
Policy Entropy: 3.87230
Value Function Loss: 0.00680

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.03390
Policy Update Magnitude: 0.26572
Value Function Update Magnitude: 0.33054

Collected Steps per Second: 19,420.99960
Overall Steps per Second: 9,599.86025

Timestep Collection Time: 2.57494
Timestep Consumption Time: 2.63430
PPO Batch Consumption Time: 0.31064
Total Iteration Time: 5.20924

Cumulative Model Updates: 363,694
Cumulative Timesteps: 3,033,259,116

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3033259116...
Checkpoint 3033259116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.96725
Policy Entropy: 3.87045
Value Function Loss: 0.00728

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.03100
Policy Update Magnitude: 0.25406
Value Function Update Magnitude: 0.33872

Collected Steps per Second: 21,834.50545
Overall Steps per Second: 10,357.09889

Timestep Collection Time: 2.28995
Timestep Consumption Time: 2.53765
PPO Batch Consumption Time: 0.30292
Total Iteration Time: 4.82761

Cumulative Model Updates: 363,700
Cumulative Timesteps: 3,033,309,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.69835
Policy Entropy: 3.90683
Value Function Loss: 0.00677

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.03563
Policy Update Magnitude: 0.24747
Value Function Update Magnitude: 0.33946

Collected Steps per Second: 22,456.38660
Overall Steps per Second: 10,814.44488

Timestep Collection Time: 2.22743
Timestep Consumption Time: 2.39787
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.62530

Cumulative Model Updates: 363,706
Cumulative Timesteps: 3,033,359,136

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3033359136...
Checkpoint 3033359136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.49348
Policy Entropy: 3.88815
Value Function Loss: 0.00648

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.03338
Policy Update Magnitude: 0.25187
Value Function Update Magnitude: 0.32979

Collected Steps per Second: 22,219.77824
Overall Steps per Second: 10,547.74220

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.49030
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.74073

Cumulative Model Updates: 363,712
Cumulative Timesteps: 3,033,409,140

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.31721
Policy Entropy: 3.90771
Value Function Loss: 0.00524

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02824
Policy Update Magnitude: 0.23942
Value Function Update Magnitude: 0.31133

Collected Steps per Second: 22,770.89822
Overall Steps per Second: 10,802.41300

Timestep Collection Time: 2.19622
Timestep Consumption Time: 2.43330
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.62952

Cumulative Model Updates: 363,718
Cumulative Timesteps: 3,033,459,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3033459150...
Checkpoint 3033459150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.79825
Policy Entropy: 3.86660
Value Function Loss: 0.00534

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.02961
Policy Update Magnitude: 0.23073
Value Function Update Magnitude: 0.29511

Collected Steps per Second: 22,381.97315
Overall Steps per Second: 10,587.62191

Timestep Collection Time: 2.23492
Timestep Consumption Time: 2.48965
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.72457

Cumulative Model Updates: 363,724
Cumulative Timesteps: 3,033,509,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.48288
Policy Entropy: 3.87302
Value Function Loss: 0.00572

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02927
Policy Update Magnitude: 0.22994
Value Function Update Magnitude: 0.30566

Collected Steps per Second: 22,486.97164
Overall Steps per Second: 10,597.33770

Timestep Collection Time: 2.22369
Timestep Consumption Time: 2.49486
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.71854

Cumulative Model Updates: 363,730
Cumulative Timesteps: 3,033,559,176

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3033559176...
Checkpoint 3033559176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.37119
Policy Entropy: 3.91515
Value Function Loss: 0.00503

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.22516
Value Function Update Magnitude: 0.30652

Collected Steps per Second: 23,326.84666
Overall Steps per Second: 10,831.89584

Timestep Collection Time: 2.14362
Timestep Consumption Time: 2.47274
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.61637

Cumulative Model Updates: 363,736
Cumulative Timesteps: 3,033,609,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.56386
Policy Entropy: 3.94740
Value Function Loss: 0.00517

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02297
Policy Update Magnitude: 0.22163
Value Function Update Magnitude: 0.29214

Collected Steps per Second: 21,379.23190
Overall Steps per Second: 10,308.24888

Timestep Collection Time: 2.33937
Timestep Consumption Time: 2.51247
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.85184

Cumulative Model Updates: 363,742
Cumulative Timesteps: 3,033,659,194

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3033659194...
Checkpoint 3033659194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.10719
Policy Entropy: 3.96501
Value Function Loss: 0.00539

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.22144
Value Function Update Magnitude: 0.29789

Collected Steps per Second: 21,481.62831
Overall Steps per Second: 10,461.71016

Timestep Collection Time: 2.32766
Timestep Consumption Time: 2.45186
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.77952

Cumulative Model Updates: 363,748
Cumulative Timesteps: 3,033,709,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.83452
Policy Entropy: 3.88917
Value Function Loss: 0.00778

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.02986
Policy Update Magnitude: 0.25236
Value Function Update Magnitude: 0.32899

Collected Steps per Second: 22,528.37920
Overall Steps per Second: 10,525.93887

Timestep Collection Time: 2.22084
Timestep Consumption Time: 2.53237
PPO Batch Consumption Time: 0.29325
Total Iteration Time: 4.75321

Cumulative Model Updates: 363,754
Cumulative Timesteps: 3,033,759,228

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3033759228...
Checkpoint 3033759228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.60022
Policy Entropy: 3.90304
Value Function Loss: 0.00782

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.03213
Policy Update Magnitude: 0.26895
Value Function Update Magnitude: 0.34187

Collected Steps per Second: 22,495.66216
Overall Steps per Second: 10,625.71352

Timestep Collection Time: 2.22363
Timestep Consumption Time: 2.48401
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.70764

Cumulative Model Updates: 363,760
Cumulative Timesteps: 3,033,809,250

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.69205
Policy Entropy: 3.89585
Value Function Loss: 0.00741

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.03056
Policy Update Magnitude: 0.25405
Value Function Update Magnitude: 0.32986

Collected Steps per Second: 22,531.79025
Overall Steps per Second: 10,862.15022

Timestep Collection Time: 2.22024
Timestep Consumption Time: 2.38529
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.60553

Cumulative Model Updates: 363,766
Cumulative Timesteps: 3,033,859,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3033859276...
Checkpoint 3033859276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.25825
Policy Entropy: 3.91733
Value Function Loss: 0.00676

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02614
Policy Update Magnitude: 0.24526
Value Function Update Magnitude: 0.30883

Collected Steps per Second: 22,079.04831
Overall Steps per Second: 10,580.77482

Timestep Collection Time: 2.26604
Timestep Consumption Time: 2.46254
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.72858

Cumulative Model Updates: 363,772
Cumulative Timesteps: 3,033,909,308

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.99112
Policy Entropy: 3.93697
Value Function Loss: 0.00580

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02548
Policy Update Magnitude: 0.23002
Value Function Update Magnitude: 0.30416

Collected Steps per Second: 20,978.19981
Overall Steps per Second: 10,106.86753

Timestep Collection Time: 2.38362
Timestep Consumption Time: 2.56391
PPO Batch Consumption Time: 0.29567
Total Iteration Time: 4.94753

Cumulative Model Updates: 363,778
Cumulative Timesteps: 3,033,959,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3033959312...
Checkpoint 3033959312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.14244
Policy Entropy: 3.96025
Value Function Loss: 0.00542

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02489
Policy Update Magnitude: 0.21984
Value Function Update Magnitude: 0.29292

Collected Steps per Second: 19,790.66067
Overall Steps per Second: 10,137.45386

Timestep Collection Time: 2.52766
Timestep Consumption Time: 2.40692
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.93457

Cumulative Model Updates: 363,784
Cumulative Timesteps: 3,034,009,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87.67178
Policy Entropy: 3.96516
Value Function Loss: 0.00541

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02010
Policy Update Magnitude: 0.21633
Value Function Update Magnitude: 0.27820

Collected Steps per Second: 21,187.44957
Overall Steps per Second: 10,135.66119

Timestep Collection Time: 2.36036
Timestep Consumption Time: 2.57370
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.93406

Cumulative Model Updates: 363,790
Cumulative Timesteps: 3,034,059,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3034059346...
Checkpoint 3034059346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90.73087
Policy Entropy: 3.89852
Value Function Loss: 0.00697

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02068
Policy Update Magnitude: 0.23464
Value Function Update Magnitude: 0.28510

Collected Steps per Second: 21,043.03684
Overall Steps per Second: 10,248.12704

Timestep Collection Time: 2.37608
Timestep Consumption Time: 2.50286
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.87894

Cumulative Model Updates: 363,796
Cumulative Timesteps: 3,034,109,346

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.98839
Policy Entropy: 3.84099
Value Function Loss: 0.00750

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02884
Policy Update Magnitude: 0.25205
Value Function Update Magnitude: 0.29821

Collected Steps per Second: 22,430.78455
Overall Steps per Second: 10,864.61415

Timestep Collection Time: 2.22935
Timestep Consumption Time: 2.37330
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.60265

Cumulative Model Updates: 363,802
Cumulative Timesteps: 3,034,159,352

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3034159352...
Checkpoint 3034159352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.35070
Policy Entropy: 3.85466
Value Function Loss: 0.00737

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 0.25913
Value Function Update Magnitude: 0.30596

Collected Steps per Second: 22,277.82076
Overall Steps per Second: 10,633.65155

Timestep Collection Time: 2.24510
Timestep Consumption Time: 2.45846
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.70356

Cumulative Model Updates: 363,808
Cumulative Timesteps: 3,034,209,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.81710
Policy Entropy: 3.91612
Value Function Loss: 0.00584

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02899
Policy Update Magnitude: 0.24531
Value Function Update Magnitude: 0.29929

Collected Steps per Second: 22,524.39685
Overall Steps per Second: 10,898.11511

Timestep Collection Time: 2.22061
Timestep Consumption Time: 2.36899
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.58960

Cumulative Model Updates: 363,814
Cumulative Timesteps: 3,034,259,386

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3034259386...
Checkpoint 3034259386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.17405
Policy Entropy: 3.95538
Value Function Loss: 0.00521

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.23230
Value Function Update Magnitude: 0.28824

Collected Steps per Second: 22,431.76672
Overall Steps per Second: 10,736.15679

Timestep Collection Time: 2.23032
Timestep Consumption Time: 2.42964
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.65995

Cumulative Model Updates: 363,820
Cumulative Timesteps: 3,034,309,416

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.63008
Policy Entropy: 3.98120
Value Function Loss: 0.00543

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.22919
Value Function Update Magnitude: 0.29129

Collected Steps per Second: 22,755.67461
Overall Steps per Second: 10,748.34867

Timestep Collection Time: 2.19752
Timestep Consumption Time: 2.45492
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.65244

Cumulative Model Updates: 363,826
Cumulative Timesteps: 3,034,359,422

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3034359422...
Checkpoint 3034359422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.03363
Policy Entropy: 3.95297
Value Function Loss: 0.00716

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.23603
Value Function Update Magnitude: 0.33086

Collected Steps per Second: 22,143.40473
Overall Steps per Second: 10,709.06826

Timestep Collection Time: 2.25900
Timestep Consumption Time: 2.41199
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.67099

Cumulative Model Updates: 363,832
Cumulative Timesteps: 3,034,409,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.93133
Policy Entropy: 3.94863
Value Function Loss: 0.00697

Mean KL Divergence: 0.00251
SB3 Clip Fraction: 0.02047
Policy Update Magnitude: 0.23655
Value Function Update Magnitude: 0.35530

Collected Steps per Second: 22,691.58956
Overall Steps per Second: 10,574.62904

Timestep Collection Time: 2.20469
Timestep Consumption Time: 2.52625
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.73095

Cumulative Model Updates: 363,838
Cumulative Timesteps: 3,034,459,472

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3034459472...
Checkpoint 3034459472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.61208
Policy Entropy: 3.92397
Value Function Loss: 0.00680

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.25400
Value Function Update Magnitude: 0.33455

Collected Steps per Second: 22,575.74586
Overall Steps per Second: 10,604.44623

Timestep Collection Time: 2.21618
Timestep Consumption Time: 2.50184
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.71802

Cumulative Model Updates: 363,844
Cumulative Timesteps: 3,034,509,504

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.10687
Policy Entropy: 3.95191
Value Function Loss: 0.00567

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.24064
Value Function Update Magnitude: 0.31260

Collected Steps per Second: 22,744.18696
Overall Steps per Second: 10,870.38533

Timestep Collection Time: 2.19933
Timestep Consumption Time: 2.40235
PPO Batch Consumption Time: 0.28377
Total Iteration Time: 4.60168

Cumulative Model Updates: 363,850
Cumulative Timesteps: 3,034,559,526

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3034559526...
Checkpoint 3034559526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.52213
Policy Entropy: 3.93390
Value Function Loss: 0.00602

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.23159
Value Function Update Magnitude: 0.30998

Collected Steps per Second: 22,274.54361
Overall Steps per Second: 10,654.64664

Timestep Collection Time: 2.24552
Timestep Consumption Time: 2.44895
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.69448

Cumulative Model Updates: 363,856
Cumulative Timesteps: 3,034,609,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.49524
Policy Entropy: 3.91528
Value Function Loss: 0.00647

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.23667
Value Function Update Magnitude: 0.32289

Collected Steps per Second: 22,448.91850
Overall Steps per Second: 10,651.46575

Timestep Collection Time: 2.22817
Timestep Consumption Time: 2.46790
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.69607

Cumulative Model Updates: 363,862
Cumulative Timesteps: 3,034,659,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3034659564...
Checkpoint 3034659564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.51158
Policy Entropy: 3.90324
Value Function Loss: 0.00719

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02863
Policy Update Magnitude: 0.24586
Value Function Update Magnitude: 0.33713

Collected Steps per Second: 22,363.34711
Overall Steps per Second: 10,855.88002

Timestep Collection Time: 2.23643
Timestep Consumption Time: 2.37066
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.60709

Cumulative Model Updates: 363,868
Cumulative Timesteps: 3,034,709,578

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.44068
Policy Entropy: 3.90542
Value Function Loss: 0.00739

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02885
Policy Update Magnitude: 0.25099
Value Function Update Magnitude: 0.35753

Collected Steps per Second: 22,567.72811
Overall Steps per Second: 10,534.71947

Timestep Collection Time: 2.21635
Timestep Consumption Time: 2.53157
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.74792

Cumulative Model Updates: 363,874
Cumulative Timesteps: 3,034,759,596

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3034759596...
Checkpoint 3034759596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31140
Policy Entropy: 3.93676
Value Function Loss: 0.00659

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02752
Policy Update Magnitude: 0.24871
Value Function Update Magnitude: 0.35538

Collected Steps per Second: 21,686.31498
Overall Steps per Second: 10,550.29075

Timestep Collection Time: 2.30643
Timestep Consumption Time: 2.43448
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.74091

Cumulative Model Updates: 363,880
Cumulative Timesteps: 3,034,809,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.09817
Policy Entropy: 3.94864
Value Function Loss: 0.00582

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.25331
Value Function Update Magnitude: 0.34060

Collected Steps per Second: 22,319.64357
Overall Steps per Second: 10,024.44501

Timestep Collection Time: 2.24090
Timestep Consumption Time: 2.74851
PPO Batch Consumption Time: 0.34298
Total Iteration Time: 4.98940

Cumulative Model Updates: 363,886
Cumulative Timesteps: 3,034,859,630

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3034859630...
Checkpoint 3034859630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.70664
Policy Entropy: 3.94082
Value Function Loss: 0.00622

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.25185
Value Function Update Magnitude: 0.31999

Collected Steps per Second: 20,494.29085
Overall Steps per Second: 10,029.10961

Timestep Collection Time: 2.44000
Timestep Consumption Time: 2.54609
PPO Batch Consumption Time: 0.30308
Total Iteration Time: 4.98609

Cumulative Model Updates: 363,892
Cumulative Timesteps: 3,034,909,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.46718
Policy Entropy: 3.92978
Value Function Loss: 0.00690

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.24489
Value Function Update Magnitude: 0.32454

Collected Steps per Second: 23,123.13434
Overall Steps per Second: 10,744.87208

Timestep Collection Time: 2.16251
Timestep Consumption Time: 2.49125
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.65375

Cumulative Model Updates: 363,898
Cumulative Timesteps: 3,034,959,640

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3034959640...
Checkpoint 3034959640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.27761
Policy Entropy: 3.92281
Value Function Loss: 0.00699

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02606
Policy Update Magnitude: 0.23791
Value Function Update Magnitude: 0.32199

Collected Steps per Second: 21,673.13106
Overall Steps per Second: 10,407.26003

Timestep Collection Time: 2.30839
Timestep Consumption Time: 2.49883
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.80722

Cumulative Model Updates: 363,904
Cumulative Timesteps: 3,035,009,670

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.51042
Policy Entropy: 3.93721
Value Function Loss: 0.00658

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02306
Policy Update Magnitude: 0.22784
Value Function Update Magnitude: 0.30344

Collected Steps per Second: 22,388.18895
Overall Steps per Second: 10,695.89899

Timestep Collection Time: 2.23457
Timestep Consumption Time: 2.44274
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.67731

Cumulative Model Updates: 363,910
Cumulative Timesteps: 3,035,059,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3035059698...
Checkpoint 3035059698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.86062
Policy Entropy: 3.92700
Value Function Loss: 0.00731

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.23917
Value Function Update Magnitude: 0.29821

Collected Steps per Second: 19,566.60475
Overall Steps per Second: 9,833.05844

Timestep Collection Time: 2.55568
Timestep Consumption Time: 2.52982
PPO Batch Consumption Time: 0.30480
Total Iteration Time: 5.08550

Cumulative Model Updates: 363,916
Cumulative Timesteps: 3,035,109,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.06568
Policy Entropy: 3.91179
Value Function Loss: 0.00749

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.24551
Value Function Update Magnitude: 0.32065

Collected Steps per Second: 23,343.71828
Overall Steps per Second: 10,908.76343

Timestep Collection Time: 2.14208
Timestep Consumption Time: 2.44176
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.58384

Cumulative Model Updates: 363,922
Cumulative Timesteps: 3,035,159,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3035159708...
Checkpoint 3035159708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.74609
Policy Entropy: 3.90106
Value Function Loss: 0.00686

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.03118
Policy Update Magnitude: 0.24408
Value Function Update Magnitude: 0.32005

Collected Steps per Second: 21,142.28698
Overall Steps per Second: 10,432.72081

Timestep Collection Time: 2.36625
Timestep Consumption Time: 2.42904
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.79530

Cumulative Model Updates: 363,928
Cumulative Timesteps: 3,035,209,736

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.71852
Policy Entropy: 3.90506
Value Function Loss: 0.00646

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.24082
Value Function Update Magnitude: 0.31307

Collected Steps per Second: 22,876.93991
Overall Steps per Second: 10,847.23524

Timestep Collection Time: 2.18561
Timestep Consumption Time: 2.42386
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.60947

Cumulative Model Updates: 363,934
Cumulative Timesteps: 3,035,259,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3035259736...
Checkpoint 3035259736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.70046
Policy Entropy: 3.91540
Value Function Loss: 0.00641

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.23819
Value Function Update Magnitude: 0.31166

Collected Steps per Second: 21,886.75757
Overall Steps per Second: 10,483.17191

Timestep Collection Time: 2.28449
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.76955

Cumulative Model Updates: 363,940
Cumulative Timesteps: 3,035,309,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.29899
Policy Entropy: 3.94949
Value Function Loss: 0.00628

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.02877
Policy Update Magnitude: 0.23288
Value Function Update Magnitude: 0.30491

Collected Steps per Second: 22,362.55371
Overall Steps per Second: 10,544.33239

Timestep Collection Time: 2.23588
Timestep Consumption Time: 2.50600
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.74188

Cumulative Model Updates: 363,946
Cumulative Timesteps: 3,035,359,736

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3035359736...
Checkpoint 3035359736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.55293
Policy Entropy: 3.92446
Value Function Loss: 0.00723

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02650
Policy Update Magnitude: 0.23309
Value Function Update Magnitude: 0.30646

Collected Steps per Second: 20,986.22237
Overall Steps per Second: 10,708.64766

Timestep Collection Time: 2.38318
Timestep Consumption Time: 2.28725
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.67043

Cumulative Model Updates: 363,952
Cumulative Timesteps: 3,035,409,750

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.88580
Policy Entropy: 3.93121
Value Function Loss: 0.00669

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.23467
Value Function Update Magnitude: 0.32119

Collected Steps per Second: 22,434.32829
Overall Steps per Second: 10,590.26788

Timestep Collection Time: 2.22908
Timestep Consumption Time: 2.49299
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.72207

Cumulative Model Updates: 363,958
Cumulative Timesteps: 3,035,459,758

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3035459758...
Checkpoint 3035459758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.50039
Policy Entropy: 3.89686
Value Function Loss: 0.00653

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.23345
Value Function Update Magnitude: 0.31967

Collected Steps per Second: 22,660.10901
Overall Steps per Second: 10,839.37435

Timestep Collection Time: 2.20679
Timestep Consumption Time: 2.40658
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.61337

Cumulative Model Updates: 363,964
Cumulative Timesteps: 3,035,509,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.68282
Policy Entropy: 3.95345
Value Function Loss: 0.00568

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.22559
Value Function Update Magnitude: 0.30556

Collected Steps per Second: 23,258.72848
Overall Steps per Second: 10,789.25297

Timestep Collection Time: 2.15042
Timestep Consumption Time: 2.48531
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.63572

Cumulative Model Updates: 363,970
Cumulative Timesteps: 3,035,559,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3035559780...
Checkpoint 3035559780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.44486
Policy Entropy: 3.96440
Value Function Loss: 0.00585

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02450
Policy Update Magnitude: 0.21773
Value Function Update Magnitude: 0.29436

Collected Steps per Second: 22,256.69030
Overall Steps per Second: 10,486.29749

Timestep Collection Time: 2.24768
Timestep Consumption Time: 2.52292
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.77061

Cumulative Model Updates: 363,976
Cumulative Timesteps: 3,035,609,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.17525
Policy Entropy: 3.99821
Value Function Loss: 0.00608

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02343
Policy Update Magnitude: 0.21934
Value Function Update Magnitude: 0.29762

Collected Steps per Second: 22,250.56124
Overall Steps per Second: 10,892.79532

Timestep Collection Time: 2.24731
Timestep Consumption Time: 2.34324
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.59056

Cumulative Model Updates: 363,982
Cumulative Timesteps: 3,035,659,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3035659810...
Checkpoint 3035659810 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.53196
Policy Entropy: 3.99931
Value Function Loss: 0.00534

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.21774
Value Function Update Magnitude: 0.29368

Collected Steps per Second: 22,886.20412
Overall Steps per Second: 10,502.00583

Timestep Collection Time: 2.18612
Timestep Consumption Time: 2.57792
PPO Batch Consumption Time: 0.30160
Total Iteration Time: 4.76404

Cumulative Model Updates: 363,988
Cumulative Timesteps: 3,035,709,842

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.52110
Policy Entropy: 3.98552
Value Function Loss: 0.00629

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.22046
Value Function Update Magnitude: 0.28157

Collected Steps per Second: 22,332.40674
Overall Steps per Second: 10,459.56546

Timestep Collection Time: 2.24024
Timestep Consumption Time: 2.54294
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 4.78318

Cumulative Model Updates: 363,994
Cumulative Timesteps: 3,035,759,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3035759872...
Checkpoint 3035759872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.84455
Policy Entropy: 3.99335
Value Function Loss: 0.00676

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02193
Policy Update Magnitude: 0.22379
Value Function Update Magnitude: 0.29421

Collected Steps per Second: 22,264.98115
Overall Steps per Second: 10,490.52047

Timestep Collection Time: 2.24577
Timestep Consumption Time: 2.52063
PPO Batch Consumption Time: 0.30508
Total Iteration Time: 4.76640

Cumulative Model Updates: 364,000
Cumulative Timesteps: 3,035,809,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.18183
Policy Entropy: 3.96757
Value Function Loss: 0.00717

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02221
Policy Update Magnitude: 0.24006
Value Function Update Magnitude: 0.32566

Collected Steps per Second: 22,902.39064
Overall Steps per Second: 10,588.64478

Timestep Collection Time: 2.18414
Timestep Consumption Time: 2.53998
PPO Batch Consumption Time: 0.29556
Total Iteration Time: 4.72412

Cumulative Model Updates: 364,006
Cumulative Timesteps: 3,035,859,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3035859896...
Checkpoint 3035859896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.87478
Policy Entropy: 3.97122
Value Function Loss: 0.00612

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.24340
Value Function Update Magnitude: 0.33557

Collected Steps per Second: 21,779.46994
Overall Steps per Second: 10,537.98712

Timestep Collection Time: 2.29703
Timestep Consumption Time: 2.45037
PPO Batch Consumption Time: 0.28257
Total Iteration Time: 4.74740

Cumulative Model Updates: 364,012
Cumulative Timesteps: 3,035,909,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.64493
Policy Entropy: 4.01991
Value Function Loss: 0.00552

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02130
Policy Update Magnitude: 0.22594
Value Function Update Magnitude: 0.30993

Collected Steps per Second: 21,440.93437
Overall Steps per Second: 10,600.53969

Timestep Collection Time: 2.33255
Timestep Consumption Time: 2.38533
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.71787

Cumulative Model Updates: 364,018
Cumulative Timesteps: 3,035,959,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3035959936...
Checkpoint 3035959936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.82246
Policy Entropy: 4.02961
Value Function Loss: 0.00555

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01957
Policy Update Magnitude: 0.21865
Value Function Update Magnitude: 0.29632

Collected Steps per Second: 22,199.46712
Overall Steps per Second: 10,582.15137

Timestep Collection Time: 2.25366
Timestep Consumption Time: 2.47411
PPO Batch Consumption Time: 0.28093
Total Iteration Time: 4.72777

Cumulative Model Updates: 364,024
Cumulative Timesteps: 3,036,009,966

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.98194
Policy Entropy: 4.04514
Value Function Loss: 0.00547

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.02080
Policy Update Magnitude: 0.21946
Value Function Update Magnitude: 0.29079

Collected Steps per Second: 22,465.80116
Overall Steps per Second: 10,584.70852

Timestep Collection Time: 2.22587
Timestep Consumption Time: 2.49849
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.72436

Cumulative Model Updates: 364,030
Cumulative Timesteps: 3,036,059,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3036059972...
Checkpoint 3036059972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.12293
Policy Entropy: 3.99997
Value Function Loss: 0.00532

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02200
Policy Update Magnitude: 0.21777
Value Function Update Magnitude: 0.26648

Collected Steps per Second: 23,009.67295
Overall Steps per Second: 10,702.62266

Timestep Collection Time: 2.17361
Timestep Consumption Time: 2.49945
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.67306

Cumulative Model Updates: 364,036
Cumulative Timesteps: 3,036,109,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.36432
Policy Entropy: 4.00487
Value Function Loss: 0.00541

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.21415
Value Function Update Magnitude: 0.25933

Collected Steps per Second: 22,648.75875
Overall Steps per Second: 10,709.16222

Timestep Collection Time: 2.20763
Timestep Consumption Time: 2.46127
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.66890

Cumulative Model Updates: 364,042
Cumulative Timesteps: 3,036,159,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3036159986...
Checkpoint 3036159986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.12822
Policy Entropy: 4.01335
Value Function Loss: 0.00524

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.21733
Value Function Update Magnitude: 0.27090

Collected Steps per Second: 22,365.86329
Overall Steps per Second: 10,680.39297

Timestep Collection Time: 2.23618
Timestep Consumption Time: 2.44661
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.68279

Cumulative Model Updates: 364,048
Cumulative Timesteps: 3,036,210,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.01735
Policy Entropy: 3.98289
Value Function Loss: 0.00480

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.21535
Value Function Update Magnitude: 0.27342

Collected Steps per Second: 22,390.36214
Overall Steps per Second: 10,521.34703

Timestep Collection Time: 2.23319
Timestep Consumption Time: 2.51924
PPO Batch Consumption Time: 0.29339
Total Iteration Time: 4.75243

Cumulative Model Updates: 364,054
Cumulative Timesteps: 3,036,260,002

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3036260002...
Checkpoint 3036260002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.37168
Policy Entropy: 3.97069
Value Function Loss: 0.00552

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.22038
Value Function Update Magnitude: 0.26820

Collected Steps per Second: 22,189.76620
Overall Steps per Second: 10,589.81685

Timestep Collection Time: 2.25392
Timestep Consumption Time: 2.46892
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.72284

Cumulative Model Updates: 364,060
Cumulative Timesteps: 3,036,310,016

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.00091
Policy Entropy: 3.98295
Value Function Loss: 0.00562

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02548
Policy Update Magnitude: 0.22787
Value Function Update Magnitude: 0.29663

Collected Steps per Second: 22,383.77943
Overall Steps per Second: 10,619.95122

Timestep Collection Time: 2.23465
Timestep Consumption Time: 2.47535
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.71000

Cumulative Model Updates: 364,066
Cumulative Timesteps: 3,036,360,036

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3036360036...
Checkpoint 3036360036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.57210
Policy Entropy: 4.00957
Value Function Loss: 0.00618

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.01986
Policy Update Magnitude: 0.22922
Value Function Update Magnitude: 0.31564

Collected Steps per Second: 22,389.36972
Overall Steps per Second: 10,505.24273

Timestep Collection Time: 2.23365
Timestep Consumption Time: 2.52683
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.76048

Cumulative Model Updates: 364,072
Cumulative Timesteps: 3,036,410,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.23771
Policy Entropy: 4.03876
Value Function Loss: 0.00562

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02016
Policy Update Magnitude: 0.22126
Value Function Update Magnitude: 0.29674

Collected Steps per Second: 22,590.72881
Overall Steps per Second: 10,778.86097

Timestep Collection Time: 2.21374
Timestep Consumption Time: 2.42590
PPO Batch Consumption Time: 0.27997
Total Iteration Time: 4.63964

Cumulative Model Updates: 364,078
Cumulative Timesteps: 3,036,460,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3036460056...
Checkpoint 3036460056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.63909
Policy Entropy: 4.03802
Value Function Loss: 0.00556

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.21434
Value Function Update Magnitude: 0.28242

Collected Steps per Second: 23,193.29180
Overall Steps per Second: 10,716.35427

Timestep Collection Time: 2.15700
Timestep Consumption Time: 2.51138
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.66838

Cumulative Model Updates: 364,084
Cumulative Timesteps: 3,036,510,084

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.72613
Policy Entropy: 3.99994
Value Function Loss: 0.00641

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02785
Policy Update Magnitude: 0.22595
Value Function Update Magnitude: 0.29010

Collected Steps per Second: 22,653.29478
Overall Steps per Second: 10,571.23569

Timestep Collection Time: 2.20754
Timestep Consumption Time: 2.52304
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.73057

Cumulative Model Updates: 364,090
Cumulative Timesteps: 3,036,560,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3036560092...
Checkpoint 3036560092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.01588
Policy Entropy: 3.92346
Value Function Loss: 0.00724

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02783
Policy Update Magnitude: 0.23741
Value Function Update Magnitude: 0.31674

Collected Steps per Second: 22,319.90055
Overall Steps per Second: 10,522.21145

Timestep Collection Time: 2.24087
Timestep Consumption Time: 2.51250
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.75337

Cumulative Model Updates: 364,096
Cumulative Timesteps: 3,036,610,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.41078
Policy Entropy: 3.87101
Value Function Loss: 0.00752

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 0.24804
Value Function Update Magnitude: 0.33978

Collected Steps per Second: 23,326.93932
Overall Steps per Second: 10,899.70168

Timestep Collection Time: 2.14456
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.58967

Cumulative Model Updates: 364,102
Cumulative Timesteps: 3,036,660,134

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3036660134...
Checkpoint 3036660134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.18075
Policy Entropy: 3.92064
Value Function Loss: 0.00618

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.03522
Policy Update Magnitude: 0.23975
Value Function Update Magnitude: 0.33544

Collected Steps per Second: 22,270.02242
Overall Steps per Second: 10,624.06732

Timestep Collection Time: 2.24625
Timestep Consumption Time: 2.46231
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.70855

Cumulative Model Updates: 364,108
Cumulative Timesteps: 3,036,710,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.47200
Policy Entropy: 3.96414
Value Function Loss: 0.00563

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.23250
Value Function Update Magnitude: 0.31395

Collected Steps per Second: 20,264.09690
Overall Steps per Second: 9,913.56492

Timestep Collection Time: 2.46821
Timestep Consumption Time: 2.57700
PPO Batch Consumption Time: 0.29842
Total Iteration Time: 5.04521

Cumulative Model Updates: 364,114
Cumulative Timesteps: 3,036,760,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3036760174...
Checkpoint 3036760174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.44828
Policy Entropy: 3.96282
Value Function Loss: 0.00617

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.23283
Value Function Update Magnitude: 0.29963

Collected Steps per Second: 23,198.41195
Overall Steps per Second: 11,060.55326

Timestep Collection Time: 2.15635
Timestep Consumption Time: 2.36638
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.52274

Cumulative Model Updates: 364,120
Cumulative Timesteps: 3,036,810,198

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.58047
Policy Entropy: 3.94612
Value Function Loss: 0.00664

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.23564
Value Function Update Magnitude: 0.30573

Collected Steps per Second: 22,549.99164
Overall Steps per Second: 10,415.44185

Timestep Collection Time: 2.21863
Timestep Consumption Time: 2.58482
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.80344

Cumulative Model Updates: 364,126
Cumulative Timesteps: 3,036,860,228

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3036860228...
Checkpoint 3036860228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.01124
Policy Entropy: 3.99287
Value Function Loss: 0.00577

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02309
Policy Update Magnitude: 0.22091
Value Function Update Magnitude: 0.29419

Collected Steps per Second: 22,687.56505
Overall Steps per Second: 10,998.55292

Timestep Collection Time: 2.20429
Timestep Consumption Time: 2.34267
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.54696

Cumulative Model Updates: 364,132
Cumulative Timesteps: 3,036,910,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.17718
Policy Entropy: 3.99224
Value Function Loss: 0.00584

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.21919
Value Function Update Magnitude: 0.28150

Collected Steps per Second: 22,665.36871
Overall Steps per Second: 10,750.76883

Timestep Collection Time: 2.20716
Timestep Consumption Time: 2.44609
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.65325

Cumulative Model Updates: 364,138
Cumulative Timesteps: 3,036,960,264

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3036960264...
Checkpoint 3036960264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.48663
Policy Entropy: 3.98808
Value Function Loss: 0.00547

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.22423
Value Function Update Magnitude: 0.26956

Collected Steps per Second: 21,894.24297
Overall Steps per Second: 10,501.14615

Timestep Collection Time: 2.28416
Timestep Consumption Time: 2.47818
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.76234

Cumulative Model Updates: 364,144
Cumulative Timesteps: 3,037,010,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.82090
Policy Entropy: 3.93599
Value Function Loss: 0.00643

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.24048
Value Function Update Magnitude: 0.28827

Collected Steps per Second: 23,553.28997
Overall Steps per Second: 10,778.91024

Timestep Collection Time: 2.12293
Timestep Consumption Time: 2.51594
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.63887

Cumulative Model Updates: 364,150
Cumulative Timesteps: 3,037,060,276

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3037060276...
Checkpoint 3037060276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.16971
Policy Entropy: 3.92455
Value Function Loss: 0.00691

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.25235
Value Function Update Magnitude: 0.31875

Collected Steps per Second: 21,817.93694
Overall Steps per Second: 10,581.25693

Timestep Collection Time: 2.29279
Timestep Consumption Time: 2.43481
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.72760

Cumulative Model Updates: 364,156
Cumulative Timesteps: 3,037,110,300

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.07294
Policy Entropy: 3.92289
Value Function Loss: 0.00725

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.03261
Policy Update Magnitude: 0.25802
Value Function Update Magnitude: 0.34107

Collected Steps per Second: 22,548.48565
Overall Steps per Second: 10,664.65025

Timestep Collection Time: 2.21798
Timestep Consumption Time: 2.47154
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.68951

Cumulative Model Updates: 364,162
Cumulative Timesteps: 3,037,160,312

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3037160312...
Checkpoint 3037160312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.30684
Policy Entropy: 3.96041
Value Function Loss: 0.00610

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.03828
Policy Update Magnitude: 0.24869
Value Function Update Magnitude: 0.33116

Collected Steps per Second: 23,344.77656
Overall Steps per Second: 10,919.02293

Timestep Collection Time: 2.14258
Timestep Consumption Time: 2.43824
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.58081

Cumulative Model Updates: 364,168
Cumulative Timesteps: 3,037,210,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.21098
Policy Entropy: 3.98234
Value Function Loss: 0.00651

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.03230
Policy Update Magnitude: 0.23970
Value Function Update Magnitude: 0.31710

Collected Steps per Second: 22,504.66511
Overall Steps per Second: 10,526.61907

Timestep Collection Time: 2.22256
Timestep Consumption Time: 2.52901
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.75157

Cumulative Model Updates: 364,174
Cumulative Timesteps: 3,037,260,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3037260348...
Checkpoint 3037260348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.12898
Policy Entropy: 4.00490
Value Function Loss: 0.00696

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03259
Policy Update Magnitude: 0.24310
Value Function Update Magnitude: 0.33361

Collected Steps per Second: 22,183.77740
Overall Steps per Second: 10,539.85987

Timestep Collection Time: 2.25489
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.74598

Cumulative Model Updates: 364,180
Cumulative Timesteps: 3,037,310,370

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.83027
Policy Entropy: 4.00342
Value Function Loss: 0.00678

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02745
Policy Update Magnitude: 0.23177
Value Function Update Magnitude: 0.33824

Collected Steps per Second: 23,227.73247
Overall Steps per Second: 10,857.83449

Timestep Collection Time: 2.15320
Timestep Consumption Time: 2.45306
PPO Batch Consumption Time: 0.28030
Total Iteration Time: 4.60626

Cumulative Model Updates: 364,186
Cumulative Timesteps: 3,037,360,384

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3037360384...
Checkpoint 3037360384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.62796
Policy Entropy: 4.00934
Value Function Loss: 0.00610

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02003
Policy Update Magnitude: 0.22051
Value Function Update Magnitude: 0.31796

Collected Steps per Second: 20,523.34615
Overall Steps per Second: 10,369.34444

Timestep Collection Time: 2.43625
Timestep Consumption Time: 2.38566
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.82191

Cumulative Model Updates: 364,192
Cumulative Timesteps: 3,037,410,384

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.13653
Policy Entropy: 3.99378
Value Function Loss: 0.00563

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.22774
Value Function Update Magnitude: 0.31137

Collected Steps per Second: 22,707.37440
Overall Steps per Second: 10,846.99655

Timestep Collection Time: 2.20210
Timestep Consumption Time: 2.40784
PPO Batch Consumption Time: 0.28735
Total Iteration Time: 4.60994

Cumulative Model Updates: 364,198
Cumulative Timesteps: 3,037,460,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3037460388...
Checkpoint 3037460388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.42160
Policy Entropy: 3.98755
Value Function Loss: 0.00614

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.24610
Value Function Update Magnitude: 0.31889

Collected Steps per Second: 22,028.91661
Overall Steps per Second: 10,633.69399

Timestep Collection Time: 2.27011
Timestep Consumption Time: 2.43268
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.70279

Cumulative Model Updates: 364,204
Cumulative Timesteps: 3,037,510,396

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.18274
Policy Entropy: 4.01647
Value Function Loss: 0.00626

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02405
Policy Update Magnitude: 0.23591
Value Function Update Magnitude: 0.33852

Collected Steps per Second: 21,926.97225
Overall Steps per Second: 10,380.04646

Timestep Collection Time: 2.28039
Timestep Consumption Time: 2.53674
PPO Batch Consumption Time: 0.29546
Total Iteration Time: 4.81713

Cumulative Model Updates: 364,210
Cumulative Timesteps: 3,037,560,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3037560398...
Checkpoint 3037560398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.88580
Policy Entropy: 4.02543
Value Function Loss: 0.00534

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.21929
Value Function Update Magnitude: 0.32762

Collected Steps per Second: 20,597.29860
Overall Steps per Second: 10,230.13320

Timestep Collection Time: 2.42828
Timestep Consumption Time: 2.46081
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.88909

Cumulative Model Updates: 364,216
Cumulative Timesteps: 3,037,610,414

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.01605
Policy Entropy: 4.01044
Value Function Loss: 0.00525

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02081
Policy Update Magnitude: 0.21967
Value Function Update Magnitude: 0.30601

Collected Steps per Second: 22,502.82984
Overall Steps per Second: 10,538.51904

Timestep Collection Time: 2.22221
Timestep Consumption Time: 2.52286
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.74507

Cumulative Model Updates: 364,222
Cumulative Timesteps: 3,037,660,420

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3037660420...
Checkpoint 3037660420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.68897
Policy Entropy: 4.00282
Value Function Loss: 0.00565

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02191
Policy Update Magnitude: 0.22857
Value Function Update Magnitude: 0.32306

Collected Steps per Second: 22,409.10518
Overall Steps per Second: 10,561.27281

Timestep Collection Time: 2.23141
Timestep Consumption Time: 2.50324
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.73466

Cumulative Model Updates: 364,228
Cumulative Timesteps: 3,037,710,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.92590
Policy Entropy: 3.97472
Value Function Loss: 0.00619

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02276
Policy Update Magnitude: 0.22852
Value Function Update Magnitude: 0.34025

Collected Steps per Second: 23,427.08272
Overall Steps per Second: 10,866.02558

Timestep Collection Time: 2.13505
Timestep Consumption Time: 2.46810
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.60316

Cumulative Model Updates: 364,234
Cumulative Timesteps: 3,037,760,442

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3037760442...
Checkpoint 3037760442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.30345
Policy Entropy: 3.96153
Value Function Loss: 0.00687

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.23565
Value Function Update Magnitude: 0.34314

Collected Steps per Second: 22,175.71159
Overall Steps per Second: 10,628.37917

Timestep Collection Time: 2.25535
Timestep Consumption Time: 2.45035
PPO Batch Consumption Time: 0.27965
Total Iteration Time: 4.70570

Cumulative Model Updates: 364,240
Cumulative Timesteps: 3,037,810,456

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.53295
Policy Entropy: 3.91755
Value Function Loss: 0.00710

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.24383
Value Function Update Magnitude: 0.35518

Collected Steps per Second: 22,464.65970
Overall Steps per Second: 10,579.96504

Timestep Collection Time: 2.22661
Timestep Consumption Time: 2.50120
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.72780

Cumulative Model Updates: 364,246
Cumulative Timesteps: 3,037,860,476

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3037860476...
Checkpoint 3037860476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.48197
Policy Entropy: 3.95353
Value Function Loss: 0.00704

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.03290
Policy Update Magnitude: 0.25127
Value Function Update Magnitude: 0.35225

Collected Steps per Second: 22,990.46854
Overall Steps per Second: 10,675.23679

Timestep Collection Time: 2.17612
Timestep Consumption Time: 2.51043
PPO Batch Consumption Time: 0.29464
Total Iteration Time: 4.68655

Cumulative Model Updates: 364,252
Cumulative Timesteps: 3,037,910,506

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.78374
Policy Entropy: 3.92107
Value Function Loss: 0.00727

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.03631
Policy Update Magnitude: 0.24721
Value Function Update Magnitude: 0.32840

Collected Steps per Second: 22,543.85412
Overall Steps per Second: 10,590.15562

Timestep Collection Time: 2.21914
Timestep Consumption Time: 2.50487
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.72401

Cumulative Model Updates: 364,258
Cumulative Timesteps: 3,037,960,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3037960534...
Checkpoint 3037960534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.88361
Policy Entropy: 3.93071
Value Function Loss: 0.00705

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.03370
Policy Update Magnitude: 0.25183
Value Function Update Magnitude: 0.31181

Collected Steps per Second: 22,140.21095
Overall Steps per Second: 10,296.46805

Timestep Collection Time: 2.25942
Timestep Consumption Time: 2.59895
PPO Batch Consumption Time: 0.30892
Total Iteration Time: 4.85837

Cumulative Model Updates: 364,264
Cumulative Timesteps: 3,038,010,558

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.25163
Policy Entropy: 3.93786
Value Function Loss: 0.00608

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.03104
Policy Update Magnitude: 0.24721
Value Function Update Magnitude: 0.31322

Collected Steps per Second: 20,425.17763
Overall Steps per Second: 10,148.65420

Timestep Collection Time: 2.44835
Timestep Consumption Time: 2.47920
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.92755

Cumulative Model Updates: 364,270
Cumulative Timesteps: 3,038,060,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3038060566...
Checkpoint 3038060566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.28837
Policy Entropy: 4.00336
Value Function Loss: 0.00556

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.22867
Value Function Update Magnitude: 0.30809

Collected Steps per Second: 21,554.78740
Overall Steps per Second: 10,114.86768

Timestep Collection Time: 2.32032
Timestep Consumption Time: 2.62428
PPO Batch Consumption Time: 0.30252
Total Iteration Time: 4.94460

Cumulative Model Updates: 364,276
Cumulative Timesteps: 3,038,110,580

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.24725
Policy Entropy: 4.03710
Value Function Loss: 0.00553

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02305
Policy Update Magnitude: 0.22158
Value Function Update Magnitude: 0.29979

Collected Steps per Second: 22,667.43509
Overall Steps per Second: 10,648.91731

Timestep Collection Time: 2.20643
Timestep Consumption Time: 2.49020
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.69663

Cumulative Model Updates: 364,282
Cumulative Timesteps: 3,038,160,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3038160594...
Checkpoint 3038160594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.13443
Policy Entropy: 3.98163
Value Function Loss: 0.00666

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.22819
Value Function Update Magnitude: 0.29178

Collected Steps per Second: 21,863.84372
Overall Steps per Second: 10,452.56278

Timestep Collection Time: 2.28761
Timestep Consumption Time: 2.49743
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.78505

Cumulative Model Updates: 364,288
Cumulative Timesteps: 3,038,210,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.46888
Policy Entropy: 3.94929
Value Function Loss: 0.00714

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.23318
Value Function Update Magnitude: 0.30784

Collected Steps per Second: 22,281.15581
Overall Steps per Second: 10,821.87868

Timestep Collection Time: 2.24513
Timestep Consumption Time: 2.37736
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.62249

Cumulative Model Updates: 364,294
Cumulative Timesteps: 3,038,260,634

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3038260634...
Checkpoint 3038260634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.04492
Policy Entropy: 3.91169
Value Function Loss: 0.00702

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.23665
Value Function Update Magnitude: 0.32204

Collected Steps per Second: 22,344.07989
Overall Steps per Second: 10,852.67221

Timestep Collection Time: 2.23871
Timestep Consumption Time: 2.37047
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.60919

Cumulative Model Updates: 364,300
Cumulative Timesteps: 3,038,310,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.14939
Policy Entropy: 3.95281
Value Function Loss: 0.00636

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.03263
Policy Update Magnitude: 0.24530
Value Function Update Magnitude: 0.31466

Collected Steps per Second: 22,385.92982
Overall Steps per Second: 10,518.78668

Timestep Collection Time: 2.23542
Timestep Consumption Time: 2.52197
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.75739

Cumulative Model Updates: 364,306
Cumulative Timesteps: 3,038,360,698

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 3038360698...
Checkpoint 3038360698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.07808
Policy Entropy: 3.99865
Value Function Loss: 0.00551

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.03730
Policy Update Magnitude: 0.23558
Value Function Update Magnitude: 0.31138

Collected Steps per Second: 21,850.86616
Overall Steps per Second: 10,581.30077

Timestep Collection Time: 2.28851
Timestep Consumption Time: 2.43737
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.72588

Cumulative Model Updates: 364,312
Cumulative Timesteps: 3,038,410,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.42979
Policy Entropy: 4.02582
Value Function Loss: 0.00541

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.22226
Value Function Update Magnitude: 0.30395

Collected Steps per Second: 21,586.52500
Overall Steps per Second: 10,394.26667

Timestep Collection Time: 2.31719
Timestep Consumption Time: 2.49508
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.81227

Cumulative Model Updates: 364,318
Cumulative Timesteps: 3,038,460,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3038460724...
Checkpoint 3038460724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.39656
Policy Entropy: 3.98551
Value Function Loss: 0.00631

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02948
Policy Update Magnitude: 0.23397
Value Function Update Magnitude: 0.30509

Collected Steps per Second: 22,072.95788
Overall Steps per Second: 10,415.74589

Timestep Collection Time: 2.26612
Timestep Consumption Time: 2.53622
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.80234

Cumulative Model Updates: 364,324
Cumulative Timesteps: 3,038,510,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.61185
Policy Entropy: 3.96064
Value Function Loss: 0.00595

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.03287
Policy Update Magnitude: 0.23932
Value Function Update Magnitude: 0.30883

Collected Steps per Second: 20,428.30600
Overall Steps per Second: 9,918.67932

Timestep Collection Time: 2.44905
Timestep Consumption Time: 2.59497
PPO Batch Consumption Time: 0.30391
Total Iteration Time: 5.04402

Cumulative Model Updates: 364,330
Cumulative Timesteps: 3,038,560,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3038560774...
Checkpoint 3038560774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.04305
Policy Entropy: 3.95763
Value Function Loss: 0.00604

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.03500
Policy Update Magnitude: 0.24121
Value Function Update Magnitude: 0.30053

Collected Steps per Second: 21,829.57672
Overall Steps per Second: 10,691.53186

Timestep Collection Time: 2.29129
Timestep Consumption Time: 2.38699
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.67828

Cumulative Model Updates: 364,336
Cumulative Timesteps: 3,038,610,792

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.34864
Policy Entropy: 4.01742
Value Function Loss: 0.00501

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.02969
Policy Update Magnitude: 0.22842
Value Function Update Magnitude: 0.29210

Collected Steps per Second: 20,332.64384
Overall Steps per Second: 10,101.22045

Timestep Collection Time: 2.45959
Timestep Consumption Time: 2.49130
PPO Batch Consumption Time: 0.27975
Total Iteration Time: 4.95089

Cumulative Model Updates: 364,342
Cumulative Timesteps: 3,038,660,802

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3038660802...
Checkpoint 3038660802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.24630
Policy Entropy: 3.98117
Value Function Loss: 0.00611

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02507
Policy Update Magnitude: 0.23922
Value Function Update Magnitude: 0.29808

Collected Steps per Second: 21,086.08867
Overall Steps per Second: 10,508.21463

Timestep Collection Time: 2.37256
Timestep Consumption Time: 2.38829
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.76085

Cumulative Model Updates: 364,348
Cumulative Timesteps: 3,038,710,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.21865
Policy Entropy: 3.97668
Value Function Loss: 0.00668

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.24366
Value Function Update Magnitude: 0.33528

Collected Steps per Second: 22,342.46780
Overall Steps per Second: 10,529.99331

Timestep Collection Time: 2.23870
Timestep Consumption Time: 2.51135
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.75005

Cumulative Model Updates: 364,354
Cumulative Timesteps: 3,038,760,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3038760848...
Checkpoint 3038760848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.93628
Policy Entropy: 3.96413
Value Function Loss: 0.00672

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03026
Policy Update Magnitude: 0.25656
Value Function Update Magnitude: 0.34128

Collected Steps per Second: 22,308.63459
Overall Steps per Second: 10,623.29775

Timestep Collection Time: 2.24209
Timestep Consumption Time: 2.46624
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.70833

Cumulative Model Updates: 364,360
Cumulative Timesteps: 3,038,810,866

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.35680
Policy Entropy: 4.01068
Value Function Loss: 0.00628

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.02698
Policy Update Magnitude: 0.25756
Value Function Update Magnitude: 0.33657

Collected Steps per Second: 22,530.52882
Overall Steps per Second: 10,878.17965

Timestep Collection Time: 2.22010
Timestep Consumption Time: 2.37810
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.59820

Cumulative Model Updates: 364,366
Cumulative Timesteps: 3,038,860,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3038860886...
Checkpoint 3038860886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.06170
Policy Entropy: 4.02485
Value Function Loss: 0.00560

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.23915
Value Function Update Magnitude: 0.32656

Collected Steps per Second: 19,901.07394
Overall Steps per Second: 9,818.48368

Timestep Collection Time: 2.51333
Timestep Consumption Time: 2.58094
PPO Batch Consumption Time: 0.29763
Total Iteration Time: 5.09427

Cumulative Model Updates: 364,372
Cumulative Timesteps: 3,038,910,904

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.10336
Policy Entropy: 4.01890
Value Function Loss: 0.00552

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.23122
Value Function Update Magnitude: 0.32171

Collected Steps per Second: 21,913.80282
Overall Steps per Second: 10,260.00549

Timestep Collection Time: 2.28212
Timestep Consumption Time: 2.59214
PPO Batch Consumption Time: 0.30420
Total Iteration Time: 4.87427

Cumulative Model Updates: 364,378
Cumulative Timesteps: 3,038,960,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3038960914...
Checkpoint 3038960914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.11771
Policy Entropy: 4.00052
Value Function Loss: 0.00567

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02037
Policy Update Magnitude: 0.23005
Value Function Update Magnitude: 0.31974

Collected Steps per Second: 20,252.72669
Overall Steps per Second: 10,288.26622

Timestep Collection Time: 2.46999
Timestep Consumption Time: 2.39225
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.86224

Cumulative Model Updates: 364,384
Cumulative Timesteps: 3,039,010,938

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.13636
Policy Entropy: 3.99253
Value Function Loss: 0.00497

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.21994
Value Function Update Magnitude: 0.30820

Collected Steps per Second: 21,507.15647
Overall Steps per Second: 10,458.60948

Timestep Collection Time: 2.32555
Timestep Consumption Time: 2.45673
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.78228

Cumulative Model Updates: 364,390
Cumulative Timesteps: 3,039,060,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3039060954...
Checkpoint 3039060954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.15239
Policy Entropy: 3.99177
Value Function Loss: 0.00586

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02181
Policy Update Magnitude: 0.21782
Value Function Update Magnitude: 0.29255

Collected Steps per Second: 21,767.27178
Overall Steps per Second: 10,316.20265

Timestep Collection Time: 2.29749
Timestep Consumption Time: 2.55023
PPO Batch Consumption Time: 0.30019
Total Iteration Time: 4.84771

Cumulative Model Updates: 364,396
Cumulative Timesteps: 3,039,110,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.10499
Policy Entropy: 3.96903
Value Function Loss: 0.00662

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.23477
Value Function Update Magnitude: 0.28664

Collected Steps per Second: 22,030.91763
Overall Steps per Second: 10,910.72631

Timestep Collection Time: 2.27045
Timestep Consumption Time: 2.31403
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.58448

Cumulative Model Updates: 364,402
Cumulative Timesteps: 3,039,160,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3039160984...
Checkpoint 3039160984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.46034
Policy Entropy: 3.96503
Value Function Loss: 0.00694

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.24297
Value Function Update Magnitude: 0.31353

Collected Steps per Second: 22,367.80696
Overall Steps per Second: 10,695.76826

Timestep Collection Time: 2.23544
Timestep Consumption Time: 2.43949
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.67493

Cumulative Model Updates: 364,408
Cumulative Timesteps: 3,039,210,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.10420
Policy Entropy: 3.92911
Value Function Loss: 0.00653

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02474
Policy Update Magnitude: 0.24317
Value Function Update Magnitude: 0.33014

Collected Steps per Second: 22,377.80085
Overall Steps per Second: 10,463.55008

Timestep Collection Time: 2.23498
Timestep Consumption Time: 2.54485
PPO Batch Consumption Time: 0.29767
Total Iteration Time: 4.77983

Cumulative Model Updates: 364,414
Cumulative Timesteps: 3,039,261,000

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3039261000...
Checkpoint 3039261000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.94567
Policy Entropy: 3.95100
Value Function Loss: 0.00609

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02523
Policy Update Magnitude: 0.24911
Value Function Update Magnitude: 0.33830

Collected Steps per Second: 22,076.55353
Overall Steps per Second: 10,705.31148

Timestep Collection Time: 2.26593
Timestep Consumption Time: 2.40689
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.67282

Cumulative Model Updates: 364,420
Cumulative Timesteps: 3,039,311,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.03016
Policy Entropy: 3.92819
Value Function Loss: 0.00621

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02439
Policy Update Magnitude: 0.24293
Value Function Update Magnitude: 0.32775

Collected Steps per Second: 21,251.08461
Overall Steps per Second: 10,306.13882

Timestep Collection Time: 2.35292
Timestep Consumption Time: 2.49876
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.85167

Cumulative Model Updates: 364,426
Cumulative Timesteps: 3,039,361,026

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3039361026...
Checkpoint 3039361026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.77112
Policy Entropy: 3.95599
Value Function Loss: 0.00648

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.24456
Value Function Update Magnitude: 0.32778

Collected Steps per Second: 20,998.08149
Overall Steps per Second: 10,210.18190

Timestep Collection Time: 2.38174
Timestep Consumption Time: 2.51651
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.89825

Cumulative Model Updates: 364,432
Cumulative Timesteps: 3,039,411,038

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.59840
Policy Entropy: 3.97057
Value Function Loss: 0.00634

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.24036
Value Function Update Magnitude: 0.32466

Collected Steps per Second: 21,910.32707
Overall Steps per Second: 10,592.64338

Timestep Collection Time: 2.28212
Timestep Consumption Time: 2.43833
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.72045

Cumulative Model Updates: 364,438
Cumulative Timesteps: 3,039,461,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3039461040...
Checkpoint 3039461040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.81869
Policy Entropy: 3.98229
Value Function Loss: 0.00594

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.03329
Policy Update Magnitude: 0.24857
Value Function Update Magnitude: 0.32170

Collected Steps per Second: 22,234.34054
Overall Steps per Second: 10,575.85648

Timestep Collection Time: 2.24985
Timestep Consumption Time: 2.48017
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.73002

Cumulative Model Updates: 364,444
Cumulative Timesteps: 3,039,511,064

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.05409
Policy Entropy: 3.97688
Value Function Loss: 0.00586

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.04370
Policy Update Magnitude: 0.24603
Value Function Update Magnitude: 0.33224

Collected Steps per Second: 22,272.78912
Overall Steps per Second: 10,477.16037

Timestep Collection Time: 2.24543
Timestep Consumption Time: 2.52800
PPO Batch Consumption Time: 0.29561
Total Iteration Time: 4.77343

Cumulative Model Updates: 364,450
Cumulative Timesteps: 3,039,561,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3039561076...
Checkpoint 3039561076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.82027
Policy Entropy: 3.95084
Value Function Loss: 0.00538

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.03771
Policy Update Magnitude: 0.24153
Value Function Update Magnitude: 0.33529

Collected Steps per Second: 22,625.56144
Overall Steps per Second: 10,530.68428

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.53844
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.74860

Cumulative Model Updates: 364,456
Cumulative Timesteps: 3,039,611,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.83629
Policy Entropy: 3.93953
Value Function Loss: 0.00673

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 0.24233
Value Function Update Magnitude: 0.32576

Collected Steps per Second: 22,166.62169
Overall Steps per Second: 10,565.69222

Timestep Collection Time: 2.25573
Timestep Consumption Time: 2.47675
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.73249

Cumulative Model Updates: 364,462
Cumulative Timesteps: 3,039,661,084

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3039661084...
Checkpoint 3039661084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.59145
Policy Entropy: 3.94404
Value Function Loss: 0.00626

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.03181
Policy Update Magnitude: 0.24785
Value Function Update Magnitude: 0.31602

Collected Steps per Second: 22,172.77498
Overall Steps per Second: 10,683.59611

Timestep Collection Time: 2.25520
Timestep Consumption Time: 2.42525
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.68045

Cumulative Model Updates: 364,468
Cumulative Timesteps: 3,039,711,088

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.27353
Policy Entropy: 3.94547
Value Function Loss: 0.00702

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.24584
Value Function Update Magnitude: 0.30564

Collected Steps per Second: 22,335.08903
Overall Steps per Second: 10,419.66821

Timestep Collection Time: 2.23926
Timestep Consumption Time: 2.56070
PPO Batch Consumption Time: 0.29737
Total Iteration Time: 4.79996

Cumulative Model Updates: 364,474
Cumulative Timesteps: 3,039,761,102

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3039761102...
Checkpoint 3039761102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.70071
Policy Entropy: 3.97189
Value Function Loss: 0.00576

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.24136
Value Function Update Magnitude: 0.29965

Collected Steps per Second: 22,033.98953
Overall Steps per Second: 10,569.01659

Timestep Collection Time: 2.27031
Timestep Consumption Time: 2.46277
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.73308

Cumulative Model Updates: 364,480
Cumulative Timesteps: 3,039,811,126

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.75914
Policy Entropy: 3.96281
Value Function Loss: 0.00643

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.23491
Value Function Update Magnitude: 0.30200

Collected Steps per Second: 23,228.83823
Overall Steps per Second: 10,702.02100

Timestep Collection Time: 2.15362
Timestep Consumption Time: 2.52083
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.67444

Cumulative Model Updates: 364,486
Cumulative Timesteps: 3,039,861,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3039861152...
Checkpoint 3039861152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.21530
Policy Entropy: 3.98903
Value Function Loss: 0.00595

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02819
Policy Update Magnitude: 0.23705
Value Function Update Magnitude: 0.30243

Collected Steps per Second: 22,270.71815
Overall Steps per Second: 10,499.98069

Timestep Collection Time: 2.24555
Timestep Consumption Time: 2.51732
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.76287

Cumulative Model Updates: 364,492
Cumulative Timesteps: 3,039,911,162

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.67510
Policy Entropy: 3.98803
Value Function Loss: 0.00669

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.02863
Policy Update Magnitude: 0.24077
Value Function Update Magnitude: 0.31284

Collected Steps per Second: 21,058.46696
Overall Steps per Second: 10,365.15694

Timestep Collection Time: 2.37463
Timestep Consumption Time: 2.44981
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.82443

Cumulative Model Updates: 364,498
Cumulative Timesteps: 3,039,961,168

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3039961168...
Checkpoint 3039961168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.28067
Policy Entropy: 4.00130
Value Function Loss: 0.00613

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.24214
Value Function Update Magnitude: 0.32231

Collected Steps per Second: 22,922.74435
Overall Steps per Second: 10,741.07372

Timestep Collection Time: 2.18124
Timestep Consumption Time: 2.47379
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.65503

Cumulative Model Updates: 364,504
Cumulative Timesteps: 3,040,011,168

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.24059
Policy Entropy: 3.97862
Value Function Loss: 0.00543

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.23336
Value Function Update Magnitude: 0.32211

Collected Steps per Second: 21,047.73657
Overall Steps per Second: 10,098.99465

Timestep Collection Time: 2.37707
Timestep Consumption Time: 2.57708
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.95416

Cumulative Model Updates: 364,510
Cumulative Timesteps: 3,040,061,200

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3040061200...
Checkpoint 3040061200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.78484
Policy Entropy: 3.95949
Value Function Loss: 0.00541

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02144
Policy Update Magnitude: 0.23382
Value Function Update Magnitude: 0.31706

Collected Steps per Second: 22,542.16231
Overall Steps per Second: 10,548.72437

Timestep Collection Time: 2.21833
Timestep Consumption Time: 2.52215
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.74048

Cumulative Model Updates: 364,516
Cumulative Timesteps: 3,040,111,206

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.56060
Policy Entropy: 3.94956
Value Function Loss: 0.00518

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02094
Policy Update Magnitude: 0.23620
Value Function Update Magnitude: 0.30933

Collected Steps per Second: 22,040.22650
Overall Steps per Second: 10,438.60707

Timestep Collection Time: 2.26894
Timestep Consumption Time: 2.52174
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.79068

Cumulative Model Updates: 364,522
Cumulative Timesteps: 3,040,161,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3040161214...
Checkpoint 3040161214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.01653
Policy Entropy: 3.96316
Value Function Loss: 0.00512

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02072
Policy Update Magnitude: 0.22777
Value Function Update Magnitude: 0.29462

Collected Steps per Second: 21,384.92192
Overall Steps per Second: 10,356.91426

Timestep Collection Time: 2.33856
Timestep Consumption Time: 2.49009
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.82866

Cumulative Model Updates: 364,528
Cumulative Timesteps: 3,040,211,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.43150
Policy Entropy: 3.97634
Value Function Loss: 0.00524

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.23790
Value Function Update Magnitude: 0.28937

Collected Steps per Second: 22,490.60827
Overall Steps per Second: 10,794.08439

Timestep Collection Time: 2.22422
Timestep Consumption Time: 2.41017
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.63439

Cumulative Model Updates: 364,534
Cumulative Timesteps: 3,040,261,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3040261248...
Checkpoint 3040261248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.07456
Policy Entropy: 4.01010
Value Function Loss: 0.00544

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01953
Policy Update Magnitude: 0.23996
Value Function Update Magnitude: 0.29471

Collected Steps per Second: 22,473.56081
Overall Steps per Second: 10,782.28702

Timestep Collection Time: 2.22582
Timestep Consumption Time: 2.41346
PPO Batch Consumption Time: 0.27637
Total Iteration Time: 4.63928

Cumulative Model Updates: 364,540
Cumulative Timesteps: 3,040,311,270

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.72884
Policy Entropy: 4.01829
Value Function Loss: 0.00542

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02267
Policy Update Magnitude: 0.23998
Value Function Update Magnitude: 0.30177

Collected Steps per Second: 22,803.80930
Overall Steps per Second: 10,877.09633

Timestep Collection Time: 2.19402
Timestep Consumption Time: 2.40574
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.59976

Cumulative Model Updates: 364,546
Cumulative Timesteps: 3,040,361,302

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3040361302...
Checkpoint 3040361302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.24165
Policy Entropy: 4.01780
Value Function Loss: 0.00581

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02339
Policy Update Magnitude: 0.23838
Value Function Update Magnitude: 0.30904

Collected Steps per Second: 22,967.12458
Overall Steps per Second: 10,681.95125

Timestep Collection Time: 2.17798
Timestep Consumption Time: 2.50487
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.68285

Cumulative Model Updates: 364,552
Cumulative Timesteps: 3,040,411,324

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.09645
Policy Entropy: 4.00031
Value Function Loss: 0.00614

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02668
Policy Update Magnitude: 0.24783
Value Function Update Magnitude: 0.32144

Collected Steps per Second: 22,598.51973
Overall Steps per Second: 10,539.70134

Timestep Collection Time: 2.21262
Timestep Consumption Time: 2.53153
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.74416

Cumulative Model Updates: 364,558
Cumulative Timesteps: 3,040,461,326

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3040461326...
Checkpoint 3040461326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.30701
Policy Entropy: 3.99542
Value Function Loss: 0.00638

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.24908
Value Function Update Magnitude: 0.32672

Collected Steps per Second: 21,560.64336
Overall Steps per Second: 10,288.36207

Timestep Collection Time: 2.32015
Timestep Consumption Time: 2.54204
PPO Batch Consumption Time: 0.29904
Total Iteration Time: 4.86219

Cumulative Model Updates: 364,564
Cumulative Timesteps: 3,040,511,350

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.70873
Policy Entropy: 4.00229
Value Function Loss: 0.00616

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.24294
Value Function Update Magnitude: 0.32165

Collected Steps per Second: 23,196.05790
Overall Steps per Second: 10,728.78539

Timestep Collection Time: 2.15562
Timestep Consumption Time: 2.50492
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.66055

Cumulative Model Updates: 364,570
Cumulative Timesteps: 3,040,561,352

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3040561352...
Checkpoint 3040561352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.40915
Policy Entropy: 4.02057
Value Function Loss: 0.00583

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.23809
Value Function Update Magnitude: 0.31813

Collected Steps per Second: 22,544.24335
Overall Steps per Second: 10,549.34508

Timestep Collection Time: 2.21857
Timestep Consumption Time: 2.52258
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.74115

Cumulative Model Updates: 364,576
Cumulative Timesteps: 3,040,611,368

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.41935
Policy Entropy: 4.00481
Value Function Loss: 0.00579

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.24243
Value Function Update Magnitude: 0.31347

Collected Steps per Second: 18,733.75281
Overall Steps per Second: 10,018.20503

Timestep Collection Time: 2.66919
Timestep Consumption Time: 2.32212
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.99131

Cumulative Model Updates: 364,582
Cumulative Timesteps: 3,040,661,372

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3040661372...
Checkpoint 3040661372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.55927
Policy Entropy: 4.03153
Value Function Loss: 0.00497

Mean KL Divergence: 0.00273
SB3 Clip Fraction: 0.01918
Policy Update Magnitude: 0.23069
Value Function Update Magnitude: 0.31031

Collected Steps per Second: 21,397.25797
Overall Steps per Second: 10,279.89773

Timestep Collection Time: 2.33740
Timestep Consumption Time: 2.52782
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.86522

Cumulative Model Updates: 364,588
Cumulative Timesteps: 3,040,711,386

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.24690
Policy Entropy: 4.04927
Value Function Loss: 0.00518

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01937
Policy Update Magnitude: 0.22928
Value Function Update Magnitude: 0.29874

Collected Steps per Second: 19,480.35760
Overall Steps per Second: 9,749.17493

Timestep Collection Time: 2.56730
Timestep Consumption Time: 2.56257
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 5.12987

Cumulative Model Updates: 364,594
Cumulative Timesteps: 3,040,761,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3040761398...
Checkpoint 3040761398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.03790
Policy Entropy: 4.04495
Value Function Loss: 0.00562

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02012
Policy Update Magnitude: 0.22935
Value Function Update Magnitude: 0.29950

Collected Steps per Second: 22,092.10318
Overall Steps per Second: 10,564.75667

Timestep Collection Time: 2.26461
Timestep Consumption Time: 2.47095
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.73556

Cumulative Model Updates: 364,600
Cumulative Timesteps: 3,040,811,428

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.11237
Policy Entropy: 4.00524
Value Function Loss: 0.00629

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02312
Policy Update Magnitude: 0.23486
Value Function Update Magnitude: 0.30983

Collected Steps per Second: 21,917.20369
Overall Steps per Second: 10,398.90492

Timestep Collection Time: 2.28232
Timestep Consumption Time: 2.52800
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.81031

Cumulative Model Updates: 364,606
Cumulative Timesteps: 3,040,861,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3040861450...
Checkpoint 3040861450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.71698
Policy Entropy: 4.00226
Value Function Loss: 0.00546

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.23204
Value Function Update Magnitude: 0.32344

Collected Steps per Second: 21,836.27093
Overall Steps per Second: 10,240.42370

Timestep Collection Time: 2.29032
Timestep Consumption Time: 2.59346
PPO Batch Consumption Time: 0.30302
Total Iteration Time: 4.88378

Cumulative Model Updates: 364,612
Cumulative Timesteps: 3,040,911,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.42849
Policy Entropy: 4.00935
Value Function Loss: 0.00579

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02166
Policy Update Magnitude: 0.23198
Value Function Update Magnitude: 0.32451

Collected Steps per Second: 21,987.02786
Overall Steps per Second: 10,704.45154

Timestep Collection Time: 2.27470
Timestep Consumption Time: 2.39756
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.67226

Cumulative Model Updates: 364,618
Cumulative Timesteps: 3,040,961,476

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3040961476...
Checkpoint 3040961476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.23750
Policy Entropy: 3.99833
Value Function Loss: 0.00637

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02156
Policy Update Magnitude: 0.23557
Value Function Update Magnitude: 0.31940

Collected Steps per Second: 21,639.79594
Overall Steps per Second: 10,256.68090

Timestep Collection Time: 2.31167
Timestep Consumption Time: 2.56554
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.87721

Cumulative Model Updates: 364,624
Cumulative Timesteps: 3,041,011,500

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.17904
Policy Entropy: 3.94473
Value Function Loss: 0.00656

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02208
Policy Update Magnitude: 0.24088
Value Function Update Magnitude: 0.31986

Collected Steps per Second: 22,167.00169
Overall Steps per Second: 10,389.14683

Timestep Collection Time: 2.25633
Timestep Consumption Time: 2.55793
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.81425

Cumulative Model Updates: 364,630
Cumulative Timesteps: 3,041,061,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3041061516...
Checkpoint 3041061516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.36608
Policy Entropy: 3.92913
Value Function Loss: 0.00628

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.24663
Value Function Update Magnitude: 0.32549

Collected Steps per Second: 22,677.69675
Overall Steps per Second: 10,576.63536

Timestep Collection Time: 2.20534
Timestep Consumption Time: 2.52320
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.72854

Cumulative Model Updates: 364,636
Cumulative Timesteps: 3,041,111,528

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51639
Policy Entropy: 3.93865
Value Function Loss: 0.00544

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.24151
Value Function Update Magnitude: 0.31686

Collected Steps per Second: 22,274.25269
Overall Steps per Second: 10,345.77040

Timestep Collection Time: 2.24492
Timestep Consumption Time: 2.58836
PPO Batch Consumption Time: 0.29962
Total Iteration Time: 4.83328

Cumulative Model Updates: 364,642
Cumulative Timesteps: 3,041,161,532

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3041161532...
Checkpoint 3041161532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.61202
Policy Entropy: 3.94334
Value Function Loss: 0.00552

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.23255
Value Function Update Magnitude: 0.30313

Collected Steps per Second: 22,362.86246
Overall Steps per Second: 10,365.66892

Timestep Collection Time: 2.23630
Timestep Consumption Time: 2.58828
PPO Batch Consumption Time: 0.30627
Total Iteration Time: 4.82458

Cumulative Model Updates: 364,648
Cumulative Timesteps: 3,041,211,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.08619
Policy Entropy: 3.93861
Value Function Loss: 0.00533

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.23418
Value Function Update Magnitude: 0.29165

Collected Steps per Second: 22,633.52761
Overall Steps per Second: 10,680.32965

Timestep Collection Time: 2.20964
Timestep Consumption Time: 2.47298
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.68263

Cumulative Model Updates: 364,654
Cumulative Timesteps: 3,041,261,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3041261554...
Checkpoint 3041261554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.25012
Policy Entropy: 3.90170
Value Function Loss: 0.00641

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02397
Policy Update Magnitude: 0.23777
Value Function Update Magnitude: 0.28505

Collected Steps per Second: 21,795.54411
Overall Steps per Second: 10,491.74969

Timestep Collection Time: 2.29496
Timestep Consumption Time: 2.47259
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.76756

Cumulative Model Updates: 364,660
Cumulative Timesteps: 3,041,311,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.54228
Policy Entropy: 3.90831
Value Function Loss: 0.00647

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02372
Policy Update Magnitude: 0.24391
Value Function Update Magnitude: 0.29462

Collected Steps per Second: 20,421.16269
Overall Steps per Second: 10,181.40802

Timestep Collection Time: 2.44893
Timestep Consumption Time: 2.46296
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.91189

Cumulative Model Updates: 364,666
Cumulative Timesteps: 3,041,361,584

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3041361584...
Checkpoint 3041361584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.87781
Policy Entropy: 3.88442
Value Function Loss: 0.00804

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.26006
Value Function Update Magnitude: 0.31424

Collected Steps per Second: 22,691.41925
Overall Steps per Second: 10,500.90735

Timestep Collection Time: 2.20348
Timestep Consumption Time: 2.55802
PPO Batch Consumption Time: 0.29766
Total Iteration Time: 4.76149

Cumulative Model Updates: 364,672
Cumulative Timesteps: 3,041,411,584

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.07482
Policy Entropy: 3.91772
Value Function Loss: 0.00783

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.02947
Policy Update Magnitude: 0.26885
Value Function Update Magnitude: 0.33679

Collected Steps per Second: 22,171.43687
Overall Steps per Second: 10,593.00526

Timestep Collection Time: 2.25669
Timestep Consumption Time: 2.46662
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.72331

Cumulative Model Updates: 364,678
Cumulative Timesteps: 3,041,461,618

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3041461618...
Checkpoint 3041461618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.84116
Policy Entropy: 3.92448
Value Function Loss: 0.00703

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.26006
Value Function Update Magnitude: 0.34309

Collected Steps per Second: 19,798.11213
Overall Steps per Second: 9,479.24699

Timestep Collection Time: 2.52691
Timestep Consumption Time: 2.75073
PPO Batch Consumption Time: 0.32895
Total Iteration Time: 5.27763

Cumulative Model Updates: 364,684
Cumulative Timesteps: 3,041,511,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.31246
Policy Entropy: 3.94436
Value Function Loss: 0.00581

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02645
Policy Update Magnitude: 0.26052
Value Function Update Magnitude: 0.31955

Collected Steps per Second: 20,682.96449
Overall Steps per Second: 9,872.35305

Timestep Collection Time: 2.41880
Timestep Consumption Time: 2.64868
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 5.06748

Cumulative Model Updates: 364,690
Cumulative Timesteps: 3,041,561,674

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3041561674...
Checkpoint 3041561674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.49109
Policy Entropy: 3.91401
Value Function Loss: 0.00610

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 0.25694
Value Function Update Magnitude: 0.30982

Collected Steps per Second: 22,738.56140
Overall Steps per Second: 10,690.60903

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.47968
PPO Batch Consumption Time: 0.29925
Total Iteration Time: 4.68000

Cumulative Model Updates: 364,696
Cumulative Timesteps: 3,041,611,706

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.40761
Policy Entropy: 3.92465
Value Function Loss: 0.00661

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.03048
Policy Update Magnitude: 0.26202
Value Function Update Magnitude: 0.32838

Collected Steps per Second: 22,110.10925
Overall Steps per Second: 10,463.76335

Timestep Collection Time: 2.26286
Timestep Consumption Time: 2.51860
PPO Batch Consumption Time: 0.30668
Total Iteration Time: 4.78145

Cumulative Model Updates: 364,702
Cumulative Timesteps: 3,041,661,738

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3041661738...
Checkpoint 3041661738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.53628
Policy Entropy: 3.92127
Value Function Loss: 0.00767

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.03547
Policy Update Magnitude: 0.26927
Value Function Update Magnitude: 0.34905

Collected Steps per Second: 22,228.32887
Overall Steps per Second: 10,382.75593

Timestep Collection Time: 2.25037
Timestep Consumption Time: 2.56742
PPO Batch Consumption Time: 0.29565
Total Iteration Time: 4.81780

Cumulative Model Updates: 364,708
Cumulative Timesteps: 3,041,711,760

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.39423
Policy Entropy: 3.95861
Value Function Loss: 0.00733

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.03391
Policy Update Magnitude: 0.26358
Value Function Update Magnitude: 0.36327

Collected Steps per Second: 22,469.04732
Overall Steps per Second: 10,608.30398

Timestep Collection Time: 2.22537
Timestep Consumption Time: 2.48810
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.71348

Cumulative Model Updates: 364,714
Cumulative Timesteps: 3,041,761,762

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3041761762...
Checkpoint 3041761762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.18385
Policy Entropy: 3.96478
Value Function Loss: 0.00685

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.03153
Policy Update Magnitude: 0.25885
Value Function Update Magnitude: 0.34585

Collected Steps per Second: 21,789.53899
Overall Steps per Second: 10,553.72973

Timestep Collection Time: 2.29477
Timestep Consumption Time: 2.44308
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.73785

Cumulative Model Updates: 364,720
Cumulative Timesteps: 3,041,811,764

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.10851
Policy Entropy: 3.97267
Value Function Loss: 0.00622

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.02904
Policy Update Magnitude: 0.24695
Value Function Update Magnitude: 0.32750

Collected Steps per Second: 22,688.32580
Overall Steps per Second: 10,742.87969

Timestep Collection Time: 2.20510
Timestep Consumption Time: 2.45194
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.65704

Cumulative Model Updates: 364,726
Cumulative Timesteps: 3,041,861,794

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3041861794...
Checkpoint 3041861794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.57460
Policy Entropy: 3.96458
Value Function Loss: 0.00639

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02568
Policy Update Magnitude: 0.24392
Value Function Update Magnitude: 0.32110

Collected Steps per Second: 22,077.14413
Overall Steps per Second: 10,651.92167

Timestep Collection Time: 2.26569
Timestep Consumption Time: 2.43017
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.69587

Cumulative Model Updates: 364,732
Cumulative Timesteps: 3,041,911,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.89030
Policy Entropy: 3.96178
Value Function Loss: 0.00614

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.23644
Value Function Update Magnitude: 0.33627

Collected Steps per Second: 21,278.19285
Overall Steps per Second: 10,066.32483

Timestep Collection Time: 2.35133
Timestep Consumption Time: 2.61891
PPO Batch Consumption Time: 0.30662
Total Iteration Time: 4.97024

Cumulative Model Updates: 364,738
Cumulative Timesteps: 3,041,961,846

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3041961846...
Checkpoint 3041961846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.12562
Policy Entropy: 3.99432
Value Function Loss: 0.00600

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02497
Policy Update Magnitude: 0.23356
Value Function Update Magnitude: 0.33881

Collected Steps per Second: 20,832.99322
Overall Steps per Second: 10,269.17625

Timestep Collection Time: 2.40119
Timestep Consumption Time: 2.47009
PPO Batch Consumption Time: 0.28184
Total Iteration Time: 4.87128

Cumulative Model Updates: 364,744
Cumulative Timesteps: 3,042,011,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.39267
Policy Entropy: 4.00024
Value Function Loss: 0.00604

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02426
Policy Update Magnitude: 0.23885
Value Function Update Magnitude: 0.33322

Collected Steps per Second: 22,362.20078
Overall Steps per Second: 10,864.57739

Timestep Collection Time: 2.23717
Timestep Consumption Time: 2.36752
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.60469

Cumulative Model Updates: 364,750
Cumulative Timesteps: 3,042,061,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3042061898...
Checkpoint 3042061898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.35458
Policy Entropy: 3.95241
Value Function Loss: 0.00740

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02674
Policy Update Magnitude: 0.24260
Value Function Update Magnitude: 0.32833

Collected Steps per Second: 20,301.83875
Overall Steps per Second: 9,779.26918

Timestep Collection Time: 2.46352
Timestep Consumption Time: 2.65077
PPO Batch Consumption Time: 0.31174
Total Iteration Time: 5.11429

Cumulative Model Updates: 364,756
Cumulative Timesteps: 3,042,111,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.96240
Policy Entropy: 3.87582
Value Function Loss: 0.00798

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.03171
Policy Update Magnitude: 0.25609
Value Function Update Magnitude: 0.33415

Collected Steps per Second: 19,969.07962
Overall Steps per Second: 9,599.21291

Timestep Collection Time: 2.50527
Timestep Consumption Time: 2.70640
PPO Batch Consumption Time: 0.31436
Total Iteration Time: 5.21168

Cumulative Model Updates: 364,762
Cumulative Timesteps: 3,042,161,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3042161940...
Checkpoint 3042161940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98305
Policy Entropy: 3.87458
Value Function Loss: 0.00768

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.03514
Policy Update Magnitude: 0.26286
Value Function Update Magnitude: 0.34493

Collected Steps per Second: 19,227.33058
Overall Steps per Second: 9,972.69533

Timestep Collection Time: 2.60109
Timestep Consumption Time: 2.41380
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 5.01489

Cumulative Model Updates: 364,768
Cumulative Timesteps: 3,042,211,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.72009
Policy Entropy: 3.91937
Value Function Loss: 0.00640

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.26002
Value Function Update Magnitude: 0.34539

Collected Steps per Second: 22,501.11253
Overall Steps per Second: 10,523.67880

Timestep Collection Time: 2.22353
Timestep Consumption Time: 2.53070
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.75423

Cumulative Model Updates: 364,774
Cumulative Timesteps: 3,042,261,984

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3042261984...
Checkpoint 3042261984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.70418
Policy Entropy: 3.96428
Value Function Loss: 0.00599

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02318
Policy Update Magnitude: 0.24429
Value Function Update Magnitude: 0.33001

Collected Steps per Second: 21,355.87927
Overall Steps per Second: 10,350.74624

Timestep Collection Time: 2.34174
Timestep Consumption Time: 2.48979
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.83154

Cumulative Model Updates: 364,780
Cumulative Timesteps: 3,042,311,994

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.26932
Policy Entropy: 3.96809
Value Function Loss: 0.00611

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02389
Policy Update Magnitude: 0.24385
Value Function Update Magnitude: 0.31916

Collected Steps per Second: 23,550.90215
Overall Steps per Second: 10,778.23972

Timestep Collection Time: 2.12374
Timestep Consumption Time: 2.51672
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.64046

Cumulative Model Updates: 364,786
Cumulative Timesteps: 3,042,362,010

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3042362010...
Checkpoint 3042362010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.41386
Policy Entropy: 3.96315
Value Function Loss: 0.00600

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.23758
Value Function Update Magnitude: 0.31914

Collected Steps per Second: 22,182.67342
Overall Steps per Second: 10,530.54644

Timestep Collection Time: 2.25482
Timestep Consumption Time: 2.49498
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.74980

Cumulative Model Updates: 364,792
Cumulative Timesteps: 3,042,412,028

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.72638
Policy Entropy: 3.93636
Value Function Loss: 0.00727

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.24859
Value Function Update Magnitude: 0.32168

Collected Steps per Second: 22,602.75598
Overall Steps per Second: 10,632.05071

Timestep Collection Time: 2.21283
Timestep Consumption Time: 2.49144
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.70427

Cumulative Model Updates: 364,798
Cumulative Timesteps: 3,042,462,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3042462044...
Checkpoint 3042462044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.67137
Policy Entropy: 3.94130
Value Function Loss: 0.00688

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.02909
Policy Update Magnitude: 0.25802
Value Function Update Magnitude: 0.34127

Collected Steps per Second: 23,052.91248
Overall Steps per Second: 10,857.15763

Timestep Collection Time: 2.16901
Timestep Consumption Time: 2.43643
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.60544

Cumulative Model Updates: 364,804
Cumulative Timesteps: 3,042,512,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.35700
Policy Entropy: 3.97833
Value Function Loss: 0.00621

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.03214
Policy Update Magnitude: 0.24754
Value Function Update Magnitude: 0.33981

Collected Steps per Second: 22,492.17934
Overall Steps per Second: 10,309.24202

Timestep Collection Time: 2.22388
Timestep Consumption Time: 2.62807
PPO Batch Consumption Time: 0.30707
Total Iteration Time: 4.85196

Cumulative Model Updates: 364,810
Cumulative Timesteps: 3,042,562,066

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3042562066...
Checkpoint 3042562066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.02524
Policy Entropy: 3.99431
Value Function Loss: 0.00551

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02323
Policy Update Magnitude: 0.23400
Value Function Update Magnitude: 0.31840

Collected Steps per Second: 22,147.63406
Overall Steps per Second: 10,822.11854

Timestep Collection Time: 2.25803
Timestep Consumption Time: 2.36306
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.62109

Cumulative Model Updates: 364,816
Cumulative Timesteps: 3,042,612,076

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.46659
Policy Entropy: 3.99974
Value Function Loss: 0.00603

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.23624
Value Function Update Magnitude: 0.30866

Collected Steps per Second: 22,671.45235
Overall Steps per Second: 10,585.93589

Timestep Collection Time: 2.20586
Timestep Consumption Time: 2.51833
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 4.72419

Cumulative Model Updates: 364,822
Cumulative Timesteps: 3,042,662,086

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3042662086...
Checkpoint 3042662086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.57619
Policy Entropy: 3.97041
Value Function Loss: 0.00697

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.25286
Value Function Update Magnitude: 0.31121

Collected Steps per Second: 21,549.00379
Overall Steps per Second: 10,412.49723

Timestep Collection Time: 2.32048
Timestep Consumption Time: 2.48183
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.80231

Cumulative Model Updates: 364,828
Cumulative Timesteps: 3,042,712,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.55743
Policy Entropy: 4.00177
Value Function Loss: 0.00671

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02636
Policy Update Magnitude: 0.24749
Value Function Update Magnitude: 0.32232

Collected Steps per Second: 22,234.21387
Overall Steps per Second: 10,673.20447

Timestep Collection Time: 2.24879
Timestep Consumption Time: 2.43584
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.68463

Cumulative Model Updates: 364,834
Cumulative Timesteps: 3,042,762,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3042762090...
Checkpoint 3042762090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.35387
Policy Entropy: 3.97069
Value Function Loss: 0.00682

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02873
Policy Update Magnitude: 0.25028
Value Function Update Magnitude: 0.32871

Collected Steps per Second: 22,098.38531
Overall Steps per Second: 10,607.57718

Timestep Collection Time: 2.26360
Timestep Consumption Time: 2.45208
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.71569

Cumulative Model Updates: 364,840
Cumulative Timesteps: 3,042,812,112

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.84659
Policy Entropy: 3.97100
Value Function Loss: 0.00632

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02906
Policy Update Magnitude: 0.24917
Value Function Update Magnitude: 0.34006

Collected Steps per Second: 22,610.85429
Overall Steps per Second: 10,437.26994

Timestep Collection Time: 2.21195
Timestep Consumption Time: 2.57992
PPO Batch Consumption Time: 0.30483
Total Iteration Time: 4.79187

Cumulative Model Updates: 364,846
Cumulative Timesteps: 3,042,862,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3042862126...
Checkpoint 3042862126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.25457
Policy Entropy: 3.97895
Value Function Loss: 0.00584

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02984
Policy Update Magnitude: 0.24355
Value Function Update Magnitude: 0.32372

Collected Steps per Second: 20,349.01960
Overall Steps per Second: 9,682.15919

Timestep Collection Time: 2.45928
Timestep Consumption Time: 2.70940
PPO Batch Consumption Time: 0.31630
Total Iteration Time: 5.16868

Cumulative Model Updates: 364,852
Cumulative Timesteps: 3,042,912,170

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.69399
Policy Entropy: 4.00398
Value Function Loss: 0.00573

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.23423
Value Function Update Magnitude: 0.30311

Collected Steps per Second: 21,495.70097
Overall Steps per Second: 10,156.65400

Timestep Collection Time: 2.32605
Timestep Consumption Time: 2.59683
PPO Batch Consumption Time: 0.30209
Total Iteration Time: 4.92288

Cumulative Model Updates: 364,858
Cumulative Timesteps: 3,042,962,170

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3042962170...
Checkpoint 3042962170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.11473
Policy Entropy: 3.98339
Value Function Loss: 0.00604

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02439
Policy Update Magnitude: 0.23814
Value Function Update Magnitude: 0.30111

Collected Steps per Second: 22,066.66864
Overall Steps per Second: 10,694.56216

Timestep Collection Time: 2.26659
Timestep Consumption Time: 2.41018
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.67677

Cumulative Model Updates: 364,864
Cumulative Timesteps: 3,043,012,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.34410
Policy Entropy: 3.93989
Value Function Loss: 0.00751

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02904
Policy Update Magnitude: 0.25915
Value Function Update Magnitude: 0.31774

Collected Steps per Second: 22,627.59039
Overall Steps per Second: 10,628.42083

Timestep Collection Time: 2.21155
Timestep Consumption Time: 2.49677
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.70832

Cumulative Model Updates: 364,870
Cumulative Timesteps: 3,043,062,228

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 3043062228...
Checkpoint 3043062228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.45196
Policy Entropy: 3.95861
Value Function Loss: 0.00725

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 0.25979
Value Function Update Magnitude: 0.33298

Collected Steps per Second: 22,456.34743
Overall Steps per Second: 10,539.56997

Timestep Collection Time: 2.22717
Timestep Consumption Time: 2.51819
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.74535

Cumulative Model Updates: 364,876
Cumulative Timesteps: 3,043,112,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.06150
Policy Entropy: 3.96650
Value Function Loss: 0.00766

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02524
Policy Update Magnitude: 0.25391
Value Function Update Magnitude: 0.33358

Collected Steps per Second: 21,242.21758
Overall Steps per Second: 10,700.98533

Timestep Collection Time: 2.35540
Timestep Consumption Time: 2.32024
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.67564

Cumulative Model Updates: 364,882
Cumulative Timesteps: 3,043,162,276

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3043162276...
Checkpoint 3043162276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.53347
Policy Entropy: 3.99625
Value Function Loss: 0.00653

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.24975
Value Function Update Magnitude: 0.32659

Collected Steps per Second: 22,305.05891
Overall Steps per Second: 10,658.86480

Timestep Collection Time: 2.24173
Timestep Consumption Time: 2.44939
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.69112

Cumulative Model Updates: 364,888
Cumulative Timesteps: 3,043,212,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.42749
Policy Entropy: 3.98932
Value Function Loss: 0.00640

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.24560
Value Function Update Magnitude: 0.32618

Collected Steps per Second: 21,313.84159
Overall Steps per Second: 10,463.88605

Timestep Collection Time: 2.34646
Timestep Consumption Time: 2.43303
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.77949

Cumulative Model Updates: 364,894
Cumulative Timesteps: 3,043,262,290

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3043262290...
Checkpoint 3043262290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.28565
Policy Entropy: 3.98843
Value Function Loss: 0.00656

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.24575
Value Function Update Magnitude: 0.32742

Collected Steps per Second: 22,781.71396
Overall Steps per Second: 10,609.68076

Timestep Collection Time: 2.19544
Timestep Consumption Time: 2.51874
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.71419

Cumulative Model Updates: 364,900
Cumulative Timesteps: 3,043,312,306

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.59024
Policy Entropy: 3.97319
Value Function Loss: 0.00650

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.23820
Value Function Update Magnitude: 0.33815

Collected Steps per Second: 22,105.18029
Overall Steps per Second: 10,512.90940

Timestep Collection Time: 2.26246
Timestep Consumption Time: 2.49474
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.75720

Cumulative Model Updates: 364,906
Cumulative Timesteps: 3,043,362,318

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3043362318...
Checkpoint 3043362318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.52139
Policy Entropy: 3.94534
Value Function Loss: 0.00622

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02107
Policy Update Magnitude: 0.23614
Value Function Update Magnitude: 0.35163

Collected Steps per Second: 22,167.26537
Overall Steps per Second: 10,732.82862

Timestep Collection Time: 2.25567
Timestep Consumption Time: 2.40312
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.65879

Cumulative Model Updates: 364,912
Cumulative Timesteps: 3,043,412,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.25292
Policy Entropy: 3.92818
Value Function Loss: 0.00608

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.24579
Value Function Update Magnitude: 0.34557

Collected Steps per Second: 21,786.80841
Overall Steps per Second: 10,425.77059

Timestep Collection Time: 2.29561
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.79715

Cumulative Model Updates: 364,918
Cumulative Timesteps: 3,043,462,334

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3043462334...
Checkpoint 3043462334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.14311
Policy Entropy: 3.96997
Value Function Loss: 0.00577

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.24620
Value Function Update Magnitude: 0.33890

Collected Steps per Second: 22,209.96820
Overall Steps per Second: 10,610.40679

Timestep Collection Time: 2.25232
Timestep Consumption Time: 2.46229
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.71462

Cumulative Model Updates: 364,924
Cumulative Timesteps: 3,043,512,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.54192
Policy Entropy: 3.96558
Value Function Loss: 0.00628

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02499
Policy Update Magnitude: 0.24525
Value Function Update Magnitude: 0.33039

Collected Steps per Second: 22,411.94711
Overall Steps per Second: 10,849.44951

Timestep Collection Time: 2.23149
Timestep Consumption Time: 2.37815
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.60963

Cumulative Model Updates: 364,930
Cumulative Timesteps: 3,043,562,370

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3043562370...
Checkpoint 3043562370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.95093
Policy Entropy: 3.97781
Value Function Loss: 0.00730

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.25711
Value Function Update Magnitude: 0.32954

Collected Steps per Second: 22,352.49558
Overall Steps per Second: 10,666.74401

Timestep Collection Time: 2.23760
Timestep Consumption Time: 2.45136
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.68897

Cumulative Model Updates: 364,936
Cumulative Timesteps: 3,043,612,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.71998
Policy Entropy: 3.96266
Value Function Loss: 0.00700

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.25234
Value Function Update Magnitude: 0.34557

Collected Steps per Second: 22,447.58961
Overall Steps per Second: 10,528.98820

Timestep Collection Time: 2.22848
Timestep Consumption Time: 2.52259
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.75107

Cumulative Model Updates: 364,942
Cumulative Timesteps: 3,043,662,410

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3043662410...
Checkpoint 3043662410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.95383
Policy Entropy: 3.98791
Value Function Loss: 0.00661

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.24296
Value Function Update Magnitude: 0.34161

Collected Steps per Second: 22,335.02438
Overall Steps per Second: 10,676.52843

Timestep Collection Time: 2.23891
Timestep Consumption Time: 2.44483
PPO Batch Consumption Time: 0.29312
Total Iteration Time: 4.68373

Cumulative Model Updates: 364,948
Cumulative Timesteps: 3,043,712,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.91802
Policy Entropy: 3.97695
Value Function Loss: 0.00494

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02718
Policy Update Magnitude: 0.23383
Value Function Update Magnitude: 0.31474

Collected Steps per Second: 21,374.93598
Overall Steps per Second: 10,495.38014

Timestep Collection Time: 2.34003
Timestep Consumption Time: 2.42569
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.76572

Cumulative Model Updates: 364,954
Cumulative Timesteps: 3,043,762,434

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3043762434...
Checkpoint 3043762434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.88120
Policy Entropy: 3.98340
Value Function Loss: 0.00507

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.23073
Value Function Update Magnitude: 0.29320

Collected Steps per Second: 21,811.71153
Overall Steps per Second: 10,437.82072

Timestep Collection Time: 2.29345
Timestep Consumption Time: 2.49912
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.79257

Cumulative Model Updates: 364,960
Cumulative Timesteps: 3,043,812,458

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.53066
Policy Entropy: 3.97864
Value Function Loss: 0.00522

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.03214
Policy Update Magnitude: 0.23698
Value Function Update Magnitude: 0.29679

Collected Steps per Second: 22,166.55521
Overall Steps per Second: 10,621.51130

Timestep Collection Time: 2.25655
Timestep Consumption Time: 2.45276
PPO Batch Consumption Time: 0.29368
Total Iteration Time: 4.70931

Cumulative Model Updates: 364,966
Cumulative Timesteps: 3,043,862,478

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3043862478...
Checkpoint 3043862478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.84075
Policy Entropy: 3.99930
Value Function Loss: 0.00613

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.23460
Value Function Update Magnitude: 0.31168

Collected Steps per Second: 22,367.31249
Overall Steps per Second: 10,624.68075

Timestep Collection Time: 2.23594
Timestep Consumption Time: 2.47121
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.70715

Cumulative Model Updates: 364,972
Cumulative Timesteps: 3,043,912,490

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.76806
Policy Entropy: 3.97493
Value Function Loss: 0.00649

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 0.24776
Value Function Update Magnitude: 0.33143

Collected Steps per Second: 22,676.42161
Overall Steps per Second: 10,798.09632

Timestep Collection Time: 2.20582
Timestep Consumption Time: 2.42648
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.63230

Cumulative Model Updates: 364,978
Cumulative Timesteps: 3,043,962,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3043962510...
Checkpoint 3043962510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.38533
Policy Entropy: 3.97453
Value Function Loss: 0.00631

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.03289
Policy Update Magnitude: 0.25272
Value Function Update Magnitude: 0.33393

Collected Steps per Second: 21,907.01326
Overall Steps per Second: 10,726.34397

Timestep Collection Time: 2.28265
Timestep Consumption Time: 2.37933
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.66198

Cumulative Model Updates: 364,984
Cumulative Timesteps: 3,044,012,516

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.40173
Policy Entropy: 3.94223
Value Function Loss: 0.00645

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.03313
Policy Update Magnitude: 0.24950
Value Function Update Magnitude: 0.32310

Collected Steps per Second: 22,492.37362
Overall Steps per Second: 10,487.77707

Timestep Collection Time: 2.22298
Timestep Consumption Time: 2.54448
PPO Batch Consumption Time: 0.29420
Total Iteration Time: 4.76745

Cumulative Model Updates: 364,990
Cumulative Timesteps: 3,044,062,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3044062516...
Checkpoint 3044062516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.60735
Policy Entropy: 3.96559
Value Function Loss: 0.00664

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02882
Policy Update Magnitude: 0.25613
Value Function Update Magnitude: 0.31481

Collected Steps per Second: 22,308.50127
Overall Steps per Second: 10,624.32897

Timestep Collection Time: 2.24210
Timestep Consumption Time: 2.46577
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.70787

Cumulative Model Updates: 364,996
Cumulative Timesteps: 3,044,112,534

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.94384
Policy Entropy: 3.95117
Value Function Loss: 0.00666

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02707
Policy Update Magnitude: 0.26026
Value Function Update Magnitude: 0.32638

Collected Steps per Second: 22,441.62795
Overall Steps per Second: 10,854.96719

Timestep Collection Time: 2.22952
Timestep Consumption Time: 2.37980
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.60932

Cumulative Model Updates: 365,002
Cumulative Timesteps: 3,044,162,568

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3044162568...
Checkpoint 3044162568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.12266
Policy Entropy: 3.97600
Value Function Loss: 0.00628

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.25717
Value Function Update Magnitude: 0.32637

Collected Steps per Second: 22,293.73625
Overall Steps per Second: 10,580.86588

Timestep Collection Time: 2.24332
Timestep Consumption Time: 2.48332
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.72665

Cumulative Model Updates: 365,008
Cumulative Timesteps: 3,044,212,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.71892
Policy Entropy: 3.98360
Value Function Loss: 0.00526

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.24253
Value Function Update Magnitude: 0.31051

Collected Steps per Second: 20,970.85806
Overall Steps per Second: 10,328.09024

Timestep Collection Time: 2.38474
Timestep Consumption Time: 2.45740
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.84213

Cumulative Model Updates: 365,014
Cumulative Timesteps: 3,044,262,590

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3044262590...
Checkpoint 3044262590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.66398
Policy Entropy: 4.01040
Value Function Loss: 0.00530

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02052
Policy Update Magnitude: 0.22928
Value Function Update Magnitude: 0.28570

Collected Steps per Second: 22,751.56290
Overall Steps per Second: 10,461.89258

Timestep Collection Time: 2.19879
Timestep Consumption Time: 2.58294
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.78174

Cumulative Model Updates: 365,020
Cumulative Timesteps: 3,044,312,616

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.22982
Policy Entropy: 4.01976
Value Function Loss: 0.00551

Mean KL Divergence: 0.00253
SB3 Clip Fraction: 0.01995
Policy Update Magnitude: 0.22812
Value Function Update Magnitude: 0.27200

Collected Steps per Second: 22,551.20439
Overall Steps per Second: 10,566.17444

Timestep Collection Time: 2.21842
Timestep Consumption Time: 2.51631
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.73473

Cumulative Model Updates: 365,026
Cumulative Timesteps: 3,044,362,644

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3044362644...
Checkpoint 3044362644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.92125
Policy Entropy: 3.99114
Value Function Loss: 0.00667

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02550
Policy Update Magnitude: 0.23560
Value Function Update Magnitude: 0.28275

Collected Steps per Second: 21,561.30481
Overall Steps per Second: 10,515.32711

Timestep Collection Time: 2.32036
Timestep Consumption Time: 2.43746
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.75782

Cumulative Model Updates: 365,032
Cumulative Timesteps: 3,044,412,674

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.19210
Policy Entropy: 3.96601
Value Function Loss: 0.00654

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.23726
Value Function Update Magnitude: 0.30588

Collected Steps per Second: 22,487.02142
Overall Steps per Second: 10,554.27518

Timestep Collection Time: 2.22484
Timestep Consumption Time: 2.51542
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.74026

Cumulative Model Updates: 365,038
Cumulative Timesteps: 3,044,462,704

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3044462704...
Checkpoint 3044462704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.17240
Policy Entropy: 3.94832
Value Function Loss: 0.00617

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.03114
Policy Update Magnitude: 0.25398
Value Function Update Magnitude: 0.31543

Collected Steps per Second: 22,211.48487
Overall Steps per Second: 10,569.49790

Timestep Collection Time: 2.25154
Timestep Consumption Time: 2.48000
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.73154

Cumulative Model Updates: 365,044
Cumulative Timesteps: 3,044,512,714

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.25863
Policy Entropy: 3.93087
Value Function Loss: 0.00639

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.03925
Policy Update Magnitude: 0.25692
Value Function Update Magnitude: 0.30718

Collected Steps per Second: 22,211.04114
Overall Steps per Second: 10,784.51606

Timestep Collection Time: 2.25122
Timestep Consumption Time: 2.38524
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.63646

Cumulative Model Updates: 365,050
Cumulative Timesteps: 3,044,562,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3044562716...
Checkpoint 3044562716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.31515
Policy Entropy: 3.91368
Value Function Loss: 0.00649

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.03877
Policy Update Magnitude: 0.25424
Value Function Update Magnitude: 0.30863

Collected Steps per Second: 22,302.21607
Overall Steps per Second: 10,654.71775

Timestep Collection Time: 2.24301
Timestep Consumption Time: 2.45200
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.69501

Cumulative Model Updates: 365,056
Cumulative Timesteps: 3,044,612,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.11984
Policy Entropy: 3.93728
Value Function Loss: 0.00652

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.26596
Value Function Update Magnitude: 0.32371

Collected Steps per Second: 21,533.36667
Overall Steps per Second: 10,373.24866

Timestep Collection Time: 2.32300
Timestep Consumption Time: 2.49921
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.82221

Cumulative Model Updates: 365,062
Cumulative Timesteps: 3,044,662,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3044662762...
Checkpoint 3044662762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.42234
Policy Entropy: 3.97902
Value Function Loss: 0.00622

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02866
Policy Update Magnitude: 0.26027
Value Function Update Magnitude: 0.33737

Collected Steps per Second: 22,235.80761
Overall Steps per Second: 10,806.48447

Timestep Collection Time: 2.24899
Timestep Consumption Time: 2.37861
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.62759

Cumulative Model Updates: 365,068
Cumulative Timesteps: 3,044,712,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.48182
Policy Entropy: 4.01805
Value Function Loss: 0.00641

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.25531
Value Function Update Magnitude: 0.34338

Collected Steps per Second: 22,093.87978
Overall Steps per Second: 10,450.44925

Timestep Collection Time: 2.26443
Timestep Consumption Time: 2.52293
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.78735

Cumulative Model Updates: 365,074
Cumulative Timesteps: 3,044,762,800

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3044762800...
Checkpoint 3044762800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.57943
Policy Entropy: 4.00655
Value Function Loss: 0.00619

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.03382
Policy Update Magnitude: 0.25122
Value Function Update Magnitude: 0.33782

Collected Steps per Second: 20,526.79503
Overall Steps per Second: 10,233.67394

Timestep Collection Time: 2.43652
Timestep Consumption Time: 2.45068
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.88720

Cumulative Model Updates: 365,080
Cumulative Timesteps: 3,044,812,814

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.21957
Policy Entropy: 3.98345
Value Function Loss: 0.00636

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.03434
Policy Update Magnitude: 0.25082
Value Function Update Magnitude: 0.31876

Collected Steps per Second: 22,250.15259
Overall Steps per Second: 10,690.08245

Timestep Collection Time: 2.24718
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.67723

Cumulative Model Updates: 365,086
Cumulative Timesteps: 3,044,862,814

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3044862814...
Checkpoint 3044862814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.11025
Policy Entropy: 3.96781
Value Function Loss: 0.00570

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.03687
Policy Update Magnitude: 0.25536
Value Function Update Magnitude: 0.30240

Collected Steps per Second: 21,009.24102
Overall Steps per Second: 10,266.08234

Timestep Collection Time: 2.38010
Timestep Consumption Time: 2.49070
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.87080

Cumulative Model Updates: 365,092
Cumulative Timesteps: 3,044,912,818

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.23172
Policy Entropy: 3.99616
Value Function Loss: 0.00564

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.03321
Policy Update Magnitude: 0.24626
Value Function Update Magnitude: 0.29089

Collected Steps per Second: 19,735.50243
Overall Steps per Second: 9,684.11183

Timestep Collection Time: 2.53351
Timestep Consumption Time: 2.62959
PPO Batch Consumption Time: 0.30600
Total Iteration Time: 5.16310

Cumulative Model Updates: 365,098
Cumulative Timesteps: 3,044,962,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3044962818...
Checkpoint 3044962818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.57684
Policy Entropy: 4.00993
Value Function Loss: 0.00585

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.23759
Value Function Update Magnitude: 0.30383

Collected Steps per Second: 23,324.17383
Overall Steps per Second: 10,791.80446

Timestep Collection Time: 2.14378
Timestep Consumption Time: 2.48955
PPO Batch Consumption Time: 0.28669
Total Iteration Time: 4.63333

Cumulative Model Updates: 365,104
Cumulative Timesteps: 3,045,012,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.84176
Policy Entropy: 4.02462
Value Function Loss: 0.00572

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02434
Policy Update Magnitude: 0.22944
Value Function Update Magnitude: 0.31653

Collected Steps per Second: 22,065.05694
Overall Steps per Second: 10,256.18186

Timestep Collection Time: 2.26684
Timestep Consumption Time: 2.61002
PPO Batch Consumption Time: 0.30439
Total Iteration Time: 4.87686

Cumulative Model Updates: 365,110
Cumulative Timesteps: 3,045,062,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3045062838...
Checkpoint 3045062838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.54683
Policy Entropy: 4.01330
Value Function Loss: 0.00604

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02224
Policy Update Magnitude: 0.22895
Value Function Update Magnitude: 0.30116

Collected Steps per Second: 22,154.84362
Overall Steps per Second: 10,863.59144

Timestep Collection Time: 2.25729
Timestep Consumption Time: 2.34616
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60345

Cumulative Model Updates: 365,116
Cumulative Timesteps: 3,045,112,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.52931
Policy Entropy: 4.02855
Value Function Loss: 0.00616

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02717
Policy Update Magnitude: 0.25357
Value Function Update Magnitude: 0.29130

Collected Steps per Second: 23,088.92425
Overall Steps per Second: 10,821.95858

Timestep Collection Time: 2.16684
Timestep Consumption Time: 2.45617
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.62301

Cumulative Model Updates: 365,122
Cumulative Timesteps: 3,045,162,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3045162878...
Checkpoint 3045162878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.13957
Policy Entropy: 4.00236
Value Function Loss: 0.00640

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.02890
Policy Update Magnitude: 0.27238
Value Function Update Magnitude: 0.31481

Collected Steps per Second: 22,628.36329
Overall Steps per Second: 10,547.55281

Timestep Collection Time: 2.21068
Timestep Consumption Time: 2.53203
PPO Batch Consumption Time: 0.29614
Total Iteration Time: 4.74271

Cumulative Model Updates: 365,128
Cumulative Timesteps: 3,045,212,902

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.42862
Policy Entropy: 3.97060
Value Function Loss: 0.00581

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.02855
Policy Update Magnitude: 0.25664
Value Function Update Magnitude: 0.32206

Collected Steps per Second: 21,194.20499
Overall Steps per Second: 10,509.76170

Timestep Collection Time: 2.35923
Timestep Consumption Time: 2.39844
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.75767

Cumulative Model Updates: 365,134
Cumulative Timesteps: 3,045,262,904

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3045262904...
Checkpoint 3045262904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.29988
Policy Entropy: 3.96151
Value Function Loss: 0.00579

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.24494
Value Function Update Magnitude: 0.32387

Collected Steps per Second: 22,065.15662
Overall Steps per Second: 10,438.25391

Timestep Collection Time: 2.26692
Timestep Consumption Time: 2.52507
PPO Batch Consumption Time: 0.29548
Total Iteration Time: 4.79199

Cumulative Model Updates: 365,140
Cumulative Timesteps: 3,045,312,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.38730
Policy Entropy: 3.97819
Value Function Loss: 0.00527

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02298
Policy Update Magnitude: 0.23823
Value Function Update Magnitude: 0.32387

Collected Steps per Second: 21,741.22131
Overall Steps per Second: 10,429.75625

Timestep Collection Time: 2.30088
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.79628

Cumulative Model Updates: 365,146
Cumulative Timesteps: 3,045,362,948

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3045362948...
Checkpoint 3045362948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.49457
Policy Entropy: 4.00827
Value Function Loss: 0.00472

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.22870
Value Function Update Magnitude: 0.29561

Collected Steps per Second: 22,827.03132
Overall Steps per Second: 10,708.25844

Timestep Collection Time: 2.19056
Timestep Consumption Time: 2.47911
PPO Batch Consumption Time: 0.29817
Total Iteration Time: 4.66967

Cumulative Model Updates: 365,152
Cumulative Timesteps: 3,045,412,952

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.67869
Policy Entropy: 3.98585
Value Function Loss: 0.00504

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.22516
Value Function Update Magnitude: 0.28436

Collected Steps per Second: 21,633.78141
Overall Steps per Second: 10,318.58178

Timestep Collection Time: 2.31139
Timestep Consumption Time: 2.53463
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.84601

Cumulative Model Updates: 365,158
Cumulative Timesteps: 3,045,462,956

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3045462956...
Checkpoint 3045462956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.86192
Policy Entropy: 3.98488
Value Function Loss: 0.00587

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.23024
Value Function Update Magnitude: 0.28228

Collected Steps per Second: 22,050.76721
Overall Steps per Second: 10,482.42793

Timestep Collection Time: 2.26777
Timestep Consumption Time: 2.50269
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.77046

Cumulative Model Updates: 365,164
Cumulative Timesteps: 3,045,512,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.44337
Policy Entropy: 3.95976
Value Function Loss: 0.00648

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.23195
Value Function Update Magnitude: 0.29811

Collected Steps per Second: 22,244.71149
Overall Steps per Second: 10,245.85944

Timestep Collection Time: 2.24808
Timestep Consumption Time: 2.63272
PPO Batch Consumption Time: 0.30928
Total Iteration Time: 4.88080

Cumulative Model Updates: 365,170
Cumulative Timesteps: 3,045,562,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3045562970...
Checkpoint 3045562970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.89498
Policy Entropy: 3.94357
Value Function Loss: 0.00603

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.23318
Value Function Update Magnitude: 0.30330

Collected Steps per Second: 21,909.34232
Overall Steps per Second: 10,598.80965

Timestep Collection Time: 2.28268
Timestep Consumption Time: 2.43596
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.71864

Cumulative Model Updates: 365,176
Cumulative Timesteps: 3,045,612,982

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.54660
Policy Entropy: 3.95614
Value Function Loss: 0.00625

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.03304
Policy Update Magnitude: 0.23937
Value Function Update Magnitude: 0.29667

Collected Steps per Second: 22,501.13707
Overall Steps per Second: 10,633.21750

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.48093
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.70375

Cumulative Model Updates: 365,182
Cumulative Timesteps: 3,045,662,998

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3045662998...
Checkpoint 3045662998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.41737
Policy Entropy: 4.00248
Value Function Loss: 0.00612

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.23286
Value Function Update Magnitude: 0.29133

Collected Steps per Second: 22,192.26035
Overall Steps per Second: 10,398.96304

Timestep Collection Time: 2.25331
Timestep Consumption Time: 2.55544
PPO Batch Consumption Time: 0.30024
Total Iteration Time: 4.80875

Cumulative Model Updates: 365,188
Cumulative Timesteps: 3,045,713,004

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.08848
Policy Entropy: 4.06144
Value Function Loss: 0.00611

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02588
Policy Update Magnitude: 0.21794
Value Function Update Magnitude: 0.30321

Collected Steps per Second: 21,495.79800
Overall Steps per Second: 10,399.68896

Timestep Collection Time: 2.32604
Timestep Consumption Time: 2.48180
PPO Batch Consumption Time: 0.28270
Total Iteration Time: 4.80784

Cumulative Model Updates: 365,194
Cumulative Timesteps: 3,045,763,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3045763004...
Checkpoint 3045763004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.65607
Policy Entropy: 4.03666
Value Function Loss: 0.00624

Mean KL Divergence: 0.00243
SB3 Clip Fraction: 0.01865
Policy Update Magnitude: 0.21990
Value Function Update Magnitude: 0.30654

Collected Steps per Second: 22,165.48483
Overall Steps per Second: 10,321.43783

Timestep Collection Time: 2.25675
Timestep Consumption Time: 2.58967
PPO Batch Consumption Time: 0.30482
Total Iteration Time: 4.84642

Cumulative Model Updates: 365,200
Cumulative Timesteps: 3,045,813,026

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.22914
Policy Entropy: 3.99982
Value Function Loss: 0.00606

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.23019
Value Function Update Magnitude: 0.31458

Collected Steps per Second: 22,692.04652
Overall Steps per Second: 10,703.02794

Timestep Collection Time: 2.20368
Timestep Consumption Time: 2.46846
PPO Batch Consumption Time: 0.28664
Total Iteration Time: 4.67214

Cumulative Model Updates: 365,206
Cumulative Timesteps: 3,045,863,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3045863032...
Checkpoint 3045863032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.90143
Policy Entropy: 3.97321
Value Function Loss: 0.00661

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.24081
Value Function Update Magnitude: 0.31889

Collected Steps per Second: 21,469.79612
Overall Steps per Second: 10,612.98427

Timestep Collection Time: 2.33016
Timestep Consumption Time: 2.38369
PPO Batch Consumption Time: 0.28121
Total Iteration Time: 4.71385

Cumulative Model Updates: 365,212
Cumulative Timesteps: 3,045,913,060

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.90968
Policy Entropy: 3.97628
Value Function Loss: 0.00671

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.24235
Value Function Update Magnitude: 0.31179

Collected Steps per Second: 22,839.96399
Overall Steps per Second: 10,698.89074

Timestep Collection Time: 2.18993
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.67506

Cumulative Model Updates: 365,218
Cumulative Timesteps: 3,045,963,078

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3045963078...
Checkpoint 3045963078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.74429
Policy Entropy: 4.00741
Value Function Loss: 0.00623

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.24044
Value Function Update Magnitude: 0.32344

Collected Steps per Second: 23,480.68425
Overall Steps per Second: 10,450.95451

Timestep Collection Time: 2.13026
Timestep Consumption Time: 2.65590
PPO Batch Consumption Time: 0.31604
Total Iteration Time: 4.78617

Cumulative Model Updates: 365,224
Cumulative Timesteps: 3,046,013,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.44482
Policy Entropy: 3.98109
Value Function Loss: 0.00599

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.23464
Value Function Update Magnitude: 0.32397

Collected Steps per Second: 22,345.52396
Overall Steps per Second: 10,648.84194

Timestep Collection Time: 2.23794
Timestep Consumption Time: 2.45815
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.69610

Cumulative Model Updates: 365,230
Cumulative Timesteps: 3,046,063,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3046063106...
Checkpoint 3046063106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.16627
Policy Entropy: 4.02341
Value Function Loss: 0.00523

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.22586
Value Function Update Magnitude: 0.30679

Collected Steps per Second: 22,283.95034
Overall Steps per Second: 10,525.14047

Timestep Collection Time: 2.24493
Timestep Consumption Time: 2.50807
PPO Batch Consumption Time: 0.30633
Total Iteration Time: 4.75300

Cumulative Model Updates: 365,236
Cumulative Timesteps: 3,046,113,132

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.49456
Policy Entropy: 4.00254
Value Function Loss: 0.00550

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02282
Policy Update Magnitude: 0.21892
Value Function Update Magnitude: 0.29156

Collected Steps per Second: 21,912.36927
Overall Steps per Second: 10,686.79146

Timestep Collection Time: 2.28328
Timestep Consumption Time: 2.39839
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.68167

Cumulative Model Updates: 365,242
Cumulative Timesteps: 3,046,163,164

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3046163164...
Checkpoint 3046163164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.30920
Policy Entropy: 4.02783
Value Function Loss: 0.00544

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02327
Policy Update Magnitude: 0.22493
Value Function Update Magnitude: 0.29695

Collected Steps per Second: 22,509.24337
Overall Steps per Second: 10,457.12591

Timestep Collection Time: 2.22238
Timestep Consumption Time: 2.56135
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.78372

Cumulative Model Updates: 365,248
Cumulative Timesteps: 3,046,213,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.14413
Policy Entropy: 4.00368
Value Function Loss: 0.00629

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02316
Policy Update Magnitude: 0.23679
Value Function Update Magnitude: 0.32695

Collected Steps per Second: 21,602.19162
Overall Steps per Second: 10,557.54095

Timestep Collection Time: 2.31551
Timestep Consumption Time: 2.42234
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.73785

Cumulative Model Updates: 365,254
Cumulative Timesteps: 3,046,263,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3046263208...
Checkpoint 3046263208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.10153
Policy Entropy: 3.99968
Value Function Loss: 0.00607

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.23742
Value Function Update Magnitude: 0.32994

Collected Steps per Second: 22,361.73983
Overall Steps per Second: 10,585.65470

Timestep Collection Time: 2.23695
Timestep Consumption Time: 2.48851
PPO Batch Consumption Time: 0.28380
Total Iteration Time: 4.72545

Cumulative Model Updates: 365,260
Cumulative Timesteps: 3,046,313,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.92389
Policy Entropy: 3.99349
Value Function Loss: 0.00601

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.22966
Value Function Update Magnitude: 0.31942

Collected Steps per Second: 22,125.97513
Overall Steps per Second: 10,568.74236

Timestep Collection Time: 2.25988
Timestep Consumption Time: 2.47124
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.73112

Cumulative Model Updates: 365,266
Cumulative Timesteps: 3,046,363,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3046363232...
Checkpoint 3046363232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.70476
Policy Entropy: 3.97807
Value Function Loss: 0.00541

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.22474
Value Function Update Magnitude: 0.30066

Collected Steps per Second: 22,955.83473
Overall Steps per Second: 10,713.63663

Timestep Collection Time: 2.17888
Timestep Consumption Time: 2.48975
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.66863

Cumulative Model Updates: 365,272
Cumulative Timesteps: 3,046,413,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.70432
Policy Entropy: 3.96119
Value Function Loss: 0.00709

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.23803
Value Function Update Magnitude: 0.30588

Collected Steps per Second: 23,007.93699
Overall Steps per Second: 10,786.61871

Timestep Collection Time: 2.17377
Timestep Consumption Time: 2.46290
PPO Batch Consumption Time: 0.28265
Total Iteration Time: 4.63667

Cumulative Model Updates: 365,278
Cumulative Timesteps: 3,046,463,264

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3046463264...
Checkpoint 3046463264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.54004
Policy Entropy: 3.95565
Value Function Loss: 0.00693

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.24137
Value Function Update Magnitude: 0.32877

Collected Steps per Second: 22,216.19808
Overall Steps per Second: 10,587.68061

Timestep Collection Time: 2.25205
Timestep Consumption Time: 2.47344
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.72549

Cumulative Model Updates: 365,284
Cumulative Timesteps: 3,046,513,296

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.30525
Policy Entropy: 3.95264
Value Function Loss: 0.00739

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.02994
Policy Update Magnitude: 0.25566
Value Function Update Magnitude: 0.34071

Collected Steps per Second: 23,013.34327
Overall Steps per Second: 10,817.70185

Timestep Collection Time: 2.17413
Timestep Consumption Time: 2.45107
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.62520

Cumulative Model Updates: 365,290
Cumulative Timesteps: 3,046,563,330

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3046563330...
Checkpoint 3046563330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.20035
Policy Entropy: 3.92774
Value Function Loss: 0.00650

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.26482
Value Function Update Magnitude: 0.33055

Collected Steps per Second: 20,434.69349
Overall Steps per Second: 10,146.11987

Timestep Collection Time: 2.44711
Timestep Consumption Time: 2.48147
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.92858

Cumulative Model Updates: 365,296
Cumulative Timesteps: 3,046,613,336

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.78106
Policy Entropy: 3.89620
Value Function Loss: 0.00703

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.03884
Policy Update Magnitude: 0.26031
Value Function Update Magnitude: 0.31842

Collected Steps per Second: 21,971.83440
Overall Steps per Second: 10,592.27396

Timestep Collection Time: 2.27610
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.28310
Total Iteration Time: 4.72137

Cumulative Model Updates: 365,302
Cumulative Timesteps: 3,046,663,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3046663346...
Checkpoint 3046663346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.88799
Policy Entropy: 3.95427
Value Function Loss: 0.00612

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.03244
Policy Update Magnitude: 0.25925
Value Function Update Magnitude: 0.32436

Collected Steps per Second: 22,359.04767
Overall Steps per Second: 10,609.26280

Timestep Collection Time: 2.23623
Timestep Consumption Time: 2.47663
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.71286

Cumulative Model Updates: 365,308
Cumulative Timesteps: 3,046,713,346

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.31179
Policy Entropy: 3.99465
Value Function Loss: 0.00672

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.02992
Policy Update Magnitude: 0.25263
Value Function Update Magnitude: 0.33374

Collected Steps per Second: 22,154.83112
Overall Steps per Second: 10,471.50590

Timestep Collection Time: 2.25721
Timestep Consumption Time: 2.51842
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.77563

Cumulative Model Updates: 365,314
Cumulative Timesteps: 3,046,763,354

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3046763354...
Checkpoint 3046763354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.85465
Policy Entropy: 4.03208
Value Function Loss: 0.00592

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.25856
Value Function Update Magnitude: 0.33890

Collected Steps per Second: 22,088.12570
Overall Steps per Second: 10,641.02673

Timestep Collection Time: 2.26366
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.69879

Cumulative Model Updates: 365,320
Cumulative Timesteps: 3,046,813,354

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.82391
Policy Entropy: 4.03458
Value Function Loss: 0.00539

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02885
Policy Update Magnitude: 0.23502
Value Function Update Magnitude: 0.34062

Collected Steps per Second: 22,324.31815
Overall Steps per Second: 10,483.26647

Timestep Collection Time: 2.24096
Timestep Consumption Time: 2.53121
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.77218

Cumulative Model Updates: 365,326
Cumulative Timesteps: 3,046,863,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3046863382...
Checkpoint 3046863382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.15907
Policy Entropy: 4.01007
Value Function Loss: 0.00550

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.23621
Value Function Update Magnitude: 0.32946

Collected Steps per Second: 21,935.50866
Overall Steps per Second: 10,562.92451

Timestep Collection Time: 2.28014
Timestep Consumption Time: 2.45491
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.73505

Cumulative Model Updates: 365,332
Cumulative Timesteps: 3,046,913,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.05631
Policy Entropy: 4.01308
Value Function Loss: 0.00522

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02280
Policy Update Magnitude: 0.23534
Value Function Update Magnitude: 0.32838

Collected Steps per Second: 21,787.11499
Overall Steps per Second: 10,611.77322

Timestep Collection Time: 2.29549
Timestep Consumption Time: 2.41739
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.71288

Cumulative Model Updates: 365,338
Cumulative Timesteps: 3,046,963,410

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3046963410...
Checkpoint 3046963410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.15772
Policy Entropy: 3.97469
Value Function Loss: 0.00550

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.23465
Value Function Update Magnitude: 0.32713

Collected Steps per Second: 22,216.28943
Overall Steps per Second: 10,531.13723

Timestep Collection Time: 2.25114
Timestep Consumption Time: 2.49782
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.74896

Cumulative Model Updates: 365,344
Cumulative Timesteps: 3,047,013,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.22066
Policy Entropy: 3.98201
Value Function Loss: 0.00503

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02426
Policy Update Magnitude: 0.23366
Value Function Update Magnitude: 0.31370

Collected Steps per Second: 22,018.79155
Overall Steps per Second: 10,560.83877

Timestep Collection Time: 2.27179
Timestep Consumption Time: 2.46477
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.73656

Cumulative Model Updates: 365,350
Cumulative Timesteps: 3,047,063,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3047063444...
Checkpoint 3047063444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.32333
Policy Entropy: 3.98186
Value Function Loss: 0.00468

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02440
Policy Update Magnitude: 0.23049
Value Function Update Magnitude: 0.30031

Collected Steps per Second: 23,214.27668
Overall Steps per Second: 10,733.35260

Timestep Collection Time: 2.15402
Timestep Consumption Time: 2.50473
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.65875

Cumulative Model Updates: 365,356
Cumulative Timesteps: 3,047,113,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.34384
Policy Entropy: 4.02170
Value Function Loss: 0.00487

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.23038
Value Function Update Magnitude: 0.29362

Collected Steps per Second: 21,798.86667
Overall Steps per Second: 9,875.12772

Timestep Collection Time: 2.29480
Timestep Consumption Time: 2.77086
PPO Batch Consumption Time: 0.33438
Total Iteration Time: 5.06566

Cumulative Model Updates: 365,362
Cumulative Timesteps: 3,047,163,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3047163472...
Checkpoint 3047163472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.62684
Policy Entropy: 4.04517
Value Function Loss: 0.00489

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01889
Policy Update Magnitude: 0.22933
Value Function Update Magnitude: 0.30432

Collected Steps per Second: 20,041.12917
Overall Steps per Second: 9,558.38693

Timestep Collection Time: 2.49497
Timestep Consumption Time: 2.73625
PPO Batch Consumption Time: 0.32593
Total Iteration Time: 5.23122

Cumulative Model Updates: 365,368
Cumulative Timesteps: 3,047,213,474

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.94407
Policy Entropy: 3.99868
Value Function Loss: 0.00618

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.24053
Value Function Update Magnitude: 0.30502

Collected Steps per Second: 20,725.17994
Overall Steps per Second: 9,957.49680

Timestep Collection Time: 2.41359
Timestep Consumption Time: 2.60997
PPO Batch Consumption Time: 0.30528
Total Iteration Time: 5.02355

Cumulative Model Updates: 365,374
Cumulative Timesteps: 3,047,263,496

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3047263496...
Checkpoint 3047263496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.23277
Policy Entropy: 3.96657
Value Function Loss: 0.00698

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.25983
Value Function Update Magnitude: 0.32763

Collected Steps per Second: 20,095.52688
Overall Steps per Second: 9,580.11822

Timestep Collection Time: 2.48891
Timestep Consumption Time: 2.73190
PPO Batch Consumption Time: 0.32146
Total Iteration Time: 5.22081

Cumulative Model Updates: 365,380
Cumulative Timesteps: 3,047,313,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.25407
Policy Entropy: 3.97065
Value Function Loss: 0.00656

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.25659
Value Function Update Magnitude: 0.34914

Collected Steps per Second: 21,968.11804
Overall Steps per Second: 10,390.26372

Timestep Collection Time: 2.27748
Timestep Consumption Time: 2.53779
PPO Batch Consumption Time: 0.30444
Total Iteration Time: 4.81528

Cumulative Model Updates: 365,386
Cumulative Timesteps: 3,047,363,544

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3047363544...
Checkpoint 3047363544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.08486
Policy Entropy: 3.98417
Value Function Loss: 0.00679

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.24691
Value Function Update Magnitude: 0.34762

Collected Steps per Second: 22,587.64135
Overall Steps per Second: 10,097.26428

Timestep Collection Time: 2.21466
Timestep Consumption Time: 2.73955
PPO Batch Consumption Time: 0.31056
Total Iteration Time: 4.95421

Cumulative Model Updates: 365,392
Cumulative Timesteps: 3,047,413,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.79945
Policy Entropy: 3.97250
Value Function Loss: 0.00661

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.24607
Value Function Update Magnitude: 0.34114

Collected Steps per Second: 19,715.72145
Overall Steps per Second: 10,060.97846

Timestep Collection Time: 2.53655
Timestep Consumption Time: 2.43414
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.97069

Cumulative Model Updates: 365,398
Cumulative Timesteps: 3,047,463,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3047463578...
Checkpoint 3047463578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.92399
Policy Entropy: 3.95086
Value Function Loss: 0.00678

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02977
Policy Update Magnitude: 0.24578
Value Function Update Magnitude: 0.33256

Collected Steps per Second: 22,625.15500
Overall Steps per Second: 10,287.69102

Timestep Collection Time: 2.21028
Timestep Consumption Time: 2.65067
PPO Batch Consumption Time: 0.32881
Total Iteration Time: 4.86095

Cumulative Model Updates: 365,404
Cumulative Timesteps: 3,047,513,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.59448
Policy Entropy: 3.94351
Value Function Loss: 0.00618

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.25254
Value Function Update Magnitude: 0.34001

Collected Steps per Second: 21,079.81253
Overall Steps per Second: 10,158.99834

Timestep Collection Time: 2.37279
Timestep Consumption Time: 2.55073
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.92352

Cumulative Model Updates: 365,410
Cumulative Timesteps: 3,047,563,604

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3047563604...
Checkpoint 3047563604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.08123
Policy Entropy: 3.96636
Value Function Loss: 0.00560

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.25228
Value Function Update Magnitude: 0.35012

Collected Steps per Second: 20,801.81952
Overall Steps per Second: 10,170.21600

Timestep Collection Time: 2.40450
Timestep Consumption Time: 2.51359
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.91809

Cumulative Model Updates: 365,416
Cumulative Timesteps: 3,047,613,622

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.27848
Policy Entropy: 3.95043
Value Function Loss: 0.00573

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.25463
Value Function Update Magnitude: 0.34004

Collected Steps per Second: 22,145.78642
Overall Steps per Second: 10,572.08036

Timestep Collection Time: 2.25831
Timestep Consumption Time: 2.47227
PPO Batch Consumption Time: 0.29753
Total Iteration Time: 4.73057

Cumulative Model Updates: 365,422
Cumulative Timesteps: 3,047,663,634

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3047663634...
Checkpoint 3047663634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.44453
Policy Entropy: 3.94866
Value Function Loss: 0.00657

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.24888
Value Function Update Magnitude: 0.34235

Collected Steps per Second: 20,770.93302
Overall Steps per Second: 10,174.37945

Timestep Collection Time: 2.40731
Timestep Consumption Time: 2.50719
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.91450

Cumulative Model Updates: 365,428
Cumulative Timesteps: 3,047,713,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.42374
Policy Entropy: 3.91993
Value Function Loss: 0.00789

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.25790
Value Function Update Magnitude: 0.35534

Collected Steps per Second: 21,439.04386
Overall Steps per Second: 10,301.40368

Timestep Collection Time: 2.33341
Timestep Consumption Time: 2.52283
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.85623

Cumulative Model Updates: 365,434
Cumulative Timesteps: 3,047,763,662

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3047763662...
Checkpoint 3047763662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.97481
Policy Entropy: 3.95087
Value Function Loss: 0.00827

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.27125
Value Function Update Magnitude: 0.36549

Collected Steps per Second: 20,310.79728
Overall Steps per Second: 9,975.10154

Timestep Collection Time: 2.46214
Timestep Consumption Time: 2.55114
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 5.01328

Cumulative Model Updates: 365,440
Cumulative Timesteps: 3,047,813,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.04275
Policy Entropy: 3.96021
Value Function Loss: 0.00794

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.26542
Value Function Update Magnitude: 0.36538

Collected Steps per Second: 20,954.73739
Overall Steps per Second: 10,217.62562

Timestep Collection Time: 2.38657
Timestep Consumption Time: 2.50791
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.89448

Cumulative Model Updates: 365,446
Cumulative Timesteps: 3,047,863,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3047863680...
Checkpoint 3047863680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.29233
Policy Entropy: 3.98565
Value Function Loss: 0.00758

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.02783
Policy Update Magnitude: 0.25638
Value Function Update Magnitude: 0.35854

Collected Steps per Second: 21,636.13200
Overall Steps per Second: 10,359.07976

Timestep Collection Time: 2.31141
Timestep Consumption Time: 2.51624
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.82765

Cumulative Model Updates: 365,452
Cumulative Timesteps: 3,047,913,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.44125
Policy Entropy: 4.00567
Value Function Loss: 0.00662

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.24824
Value Function Update Magnitude: 0.33492

Collected Steps per Second: 22,929.09492
Overall Steps per Second: 10,631.59107

Timestep Collection Time: 2.18142
Timestep Consumption Time: 2.52324
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.70466

Cumulative Model Updates: 365,458
Cumulative Timesteps: 3,047,963,708

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3047963708...
Checkpoint 3047963708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.38794
Policy Entropy: 4.04131
Value Function Loss: 0.00628

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.23844
Value Function Update Magnitude: 0.32454

Collected Steps per Second: 22,420.68313
Overall Steps per Second: 10,595.38454

Timestep Collection Time: 2.23008
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.71904

Cumulative Model Updates: 365,464
Cumulative Timesteps: 3,048,013,708

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.04079
Policy Entropy: 4.06488
Value Function Loss: 0.00594

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.23482
Value Function Update Magnitude: 0.31558

Collected Steps per Second: 22,340.29361
Overall Steps per Second: 10,617.90622

Timestep Collection Time: 2.23865
Timestep Consumption Time: 2.47151
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.71016

Cumulative Model Updates: 365,470
Cumulative Timesteps: 3,048,063,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3048063720...
Checkpoint 3048063720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.13949
Policy Entropy: 4.05929
Value Function Loss: 0.00631

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.22698
Value Function Update Magnitude: 0.29893

Collected Steps per Second: 22,448.80936
Overall Steps per Second: 10,806.84729

Timestep Collection Time: 2.22747
Timestep Consumption Time: 2.39960
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.62707

Cumulative Model Updates: 365,476
Cumulative Timesteps: 3,048,113,724

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.67983
Policy Entropy: 3.99898
Value Function Loss: 0.00666

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02618
Policy Update Magnitude: 0.23865
Value Function Update Magnitude: 0.30058

Collected Steps per Second: 22,101.39623
Overall Steps per Second: 10,532.46597

Timestep Collection Time: 2.26357
Timestep Consumption Time: 2.48632
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.74988

Cumulative Model Updates: 365,482
Cumulative Timesteps: 3,048,163,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3048163752...
Checkpoint 3048163752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.54357
Policy Entropy: 3.96004
Value Function Loss: 0.00668

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.03164
Policy Update Magnitude: 0.25025
Value Function Update Magnitude: 0.31854

Collected Steps per Second: 22,614.82053
Overall Steps per Second: 10,623.60949

Timestep Collection Time: 2.21094
Timestep Consumption Time: 2.49556
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.70650

Cumulative Model Updates: 365,488
Cumulative Timesteps: 3,048,213,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.88064
Policy Entropy: 3.94913
Value Function Loss: 0.00689

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.03293
Policy Update Magnitude: 0.26166
Value Function Update Magnitude: 0.33505

Collected Steps per Second: 22,361.18841
Overall Steps per Second: 10,533.51204

Timestep Collection Time: 2.23664
Timestep Consumption Time: 2.51144
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.74808

Cumulative Model Updates: 365,494
Cumulative Timesteps: 3,048,263,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3048263766...
Checkpoint 3048263766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.00488
Policy Entropy: 3.94744
Value Function Loss: 0.00682

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.03394
Policy Update Magnitude: 0.26478
Value Function Update Magnitude: 0.33819

Collected Steps per Second: 20,325.00755
Overall Steps per Second: 9,976.04318

Timestep Collection Time: 2.46140
Timestep Consumption Time: 2.55341
PPO Batch Consumption Time: 0.30423
Total Iteration Time: 5.01481

Cumulative Model Updates: 365,500
Cumulative Timesteps: 3,048,313,794

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.09376
Policy Entropy: 3.94068
Value Function Loss: 0.00656

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.03341
Policy Update Magnitude: 0.26702
Value Function Update Magnitude: 0.35182

Collected Steps per Second: 21,671.65151
Overall Steps per Second: 10,584.04115

Timestep Collection Time: 2.30716
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.72409

Cumulative Model Updates: 365,506
Cumulative Timesteps: 3,048,363,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3048363794...
Checkpoint 3048363794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.43869
Policy Entropy: 3.94816
Value Function Loss: 0.00597

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 0.25511
Value Function Update Magnitude: 0.34925

Collected Steps per Second: 22,023.52628
Overall Steps per Second: 10,550.08990

Timestep Collection Time: 2.27130
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.74138

Cumulative Model Updates: 365,512
Cumulative Timesteps: 3,048,413,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.08359
Policy Entropy: 3.96605
Value Function Loss: 0.00541

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02963
Policy Update Magnitude: 0.24290
Value Function Update Magnitude: 0.32937

Collected Steps per Second: 21,916.60481
Overall Steps per Second: 10,467.63866

Timestep Collection Time: 2.28211
Timestep Consumption Time: 2.49605
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.77816

Cumulative Model Updates: 365,518
Cumulative Timesteps: 3,048,463,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3048463832...
Checkpoint 3048463832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.11286
Policy Entropy: 4.01704
Value Function Loss: 0.00513

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.23130
Value Function Update Magnitude: 0.30172

Collected Steps per Second: 22,791.50096
Overall Steps per Second: 10,597.07737

Timestep Collection Time: 2.19477
Timestep Consumption Time: 2.52559
PPO Batch Consumption Time: 0.29919
Total Iteration Time: 4.72036

Cumulative Model Updates: 365,524
Cumulative Timesteps: 3,048,513,854

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.51683
Policy Entropy: 3.96313
Value Function Loss: 0.00680

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02457
Policy Update Magnitude: 0.24399
Value Function Update Magnitude: 0.29142

Collected Steps per Second: 20,644.31749
Overall Steps per Second: 9,871.44426

Timestep Collection Time: 2.42285
Timestep Consumption Time: 2.64409
PPO Batch Consumption Time: 0.30480
Total Iteration Time: 5.06694

Cumulative Model Updates: 365,530
Cumulative Timesteps: 3,048,563,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3048563872...
Checkpoint 3048563872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.64665
Policy Entropy: 3.96881
Value Function Loss: 0.00723

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02853
Policy Update Magnitude: 0.25538
Value Function Update Magnitude: 0.32424

Collected Steps per Second: 22,502.79755
Overall Steps per Second: 10,857.03428

Timestep Collection Time: 2.22257
Timestep Consumption Time: 2.38403
PPO Batch Consumption Time: 0.28428
Total Iteration Time: 4.60660

Cumulative Model Updates: 365,536
Cumulative Timesteps: 3,048,613,886

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93341
Policy Entropy: 3.96800
Value Function Loss: 0.00669

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.03054
Policy Update Magnitude: 0.25552
Value Function Update Magnitude: 0.35413

Collected Steps per Second: 21,967.75276
Overall Steps per Second: 10,486.77688

Timestep Collection Time: 2.27716
Timestep Consumption Time: 2.49304
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.77020

Cumulative Model Updates: 365,542
Cumulative Timesteps: 3,048,663,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3048663910...
Checkpoint 3048663910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.18327
Policy Entropy: 3.99206
Value Function Loss: 0.00678

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.03057
Policy Update Magnitude: 0.26224
Value Function Update Magnitude: 0.35345

Collected Steps per Second: 22,476.15885
Overall Steps per Second: 10,629.15289

Timestep Collection Time: 2.22511
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.70517

Cumulative Model Updates: 365,548
Cumulative Timesteps: 3,048,713,922

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.77919
Policy Entropy: 4.00938
Value Function Loss: 0.00657

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.02964
Policy Update Magnitude: 0.26858
Value Function Update Magnitude: 0.35426

Collected Steps per Second: 23,091.35851
Overall Steps per Second: 10,804.10697

Timestep Collection Time: 2.16609
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.62954

Cumulative Model Updates: 365,554
Cumulative Timesteps: 3,048,763,940

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3048763940...
Checkpoint 3048763940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.07629
Policy Entropy: 4.00572
Value Function Loss: 0.00660

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.03714
Policy Update Magnitude: 0.25369
Value Function Update Magnitude: 0.35166

Collected Steps per Second: 22,357.14693
Overall Steps per Second: 10,685.81375

Timestep Collection Time: 2.23749
Timestep Consumption Time: 2.44385
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.68135

Cumulative Model Updates: 365,560
Cumulative Timesteps: 3,048,813,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.53171
Policy Entropy: 3.98999
Value Function Loss: 0.00613

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.03386
Policy Update Magnitude: 0.24735
Value Function Update Magnitude: 0.33983

Collected Steps per Second: 22,216.79877
Overall Steps per Second: 10,470.18590

Timestep Collection Time: 2.25154
Timestep Consumption Time: 2.52603
PPO Batch Consumption Time: 0.29709
Total Iteration Time: 4.77757

Cumulative Model Updates: 365,566
Cumulative Timesteps: 3,048,863,986

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3048863986...
Checkpoint 3048863986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.39442
Policy Entropy: 3.95290
Value Function Loss: 0.00638

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.03012
Policy Update Magnitude: 0.24208
Value Function Update Magnitude: 0.33621

Collected Steps per Second: 22,072.32379
Overall Steps per Second: 10,653.27283

Timestep Collection Time: 2.26537
Timestep Consumption Time: 2.42821
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.69358

Cumulative Model Updates: 365,572
Cumulative Timesteps: 3,048,913,988

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.73613
Policy Entropy: 3.95422
Value Function Loss: 0.00655

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.24452
Value Function Update Magnitude: 0.33328

Collected Steps per Second: 21,903.79571
Overall Steps per Second: 10,391.77646

Timestep Collection Time: 2.28289
Timestep Consumption Time: 2.52899
PPO Batch Consumption Time: 0.29739
Total Iteration Time: 4.81188

Cumulative Model Updates: 365,578
Cumulative Timesteps: 3,048,963,992

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3048963992...
Checkpoint 3048963992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.61607
Policy Entropy: 3.97475
Value Function Loss: 0.00613

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.24552
Value Function Update Magnitude: 0.31501

Collected Steps per Second: 20,780.82871
Overall Steps per Second: 10,304.77669

Timestep Collection Time: 2.40626
Timestep Consumption Time: 2.44625
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 4.85251

Cumulative Model Updates: 365,584
Cumulative Timesteps: 3,049,013,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.91073
Policy Entropy: 4.00385
Value Function Loss: 0.00584

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02140
Policy Update Magnitude: 0.24574
Value Function Update Magnitude: 0.29105

Collected Steps per Second: 22,540.40825
Overall Steps per Second: 10,507.21403

Timestep Collection Time: 2.21992
Timestep Consumption Time: 2.54233
PPO Batch Consumption Time: 0.29640
Total Iteration Time: 4.76225

Cumulative Model Updates: 365,590
Cumulative Timesteps: 3,049,064,034

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3049064034...
Checkpoint 3049064034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.05880
Policy Entropy: 3.95738
Value Function Loss: 0.00609

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.24220
Value Function Update Magnitude: 0.28906

Collected Steps per Second: 21,759.55096
Overall Steps per Second: 10,486.14092

Timestep Collection Time: 2.29894
Timestep Consumption Time: 2.47154
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.77049

Cumulative Model Updates: 365,596
Cumulative Timesteps: 3,049,114,058

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.25791
Policy Entropy: 3.96221
Value Function Loss: 0.00654

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02648
Policy Update Magnitude: 0.24246
Value Function Update Magnitude: 0.30471

Collected Steps per Second: 22,038.29896
Overall Steps per Second: 10,359.98815

Timestep Collection Time: 2.26923
Timestep Consumption Time: 2.55799
PPO Batch Consumption Time: 0.31006
Total Iteration Time: 4.82723

Cumulative Model Updates: 365,602
Cumulative Timesteps: 3,049,164,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3049164068...
Checkpoint 3049164068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.55425
Policy Entropy: 3.92902
Value Function Loss: 0.00696

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02919
Policy Update Magnitude: 0.25578
Value Function Update Magnitude: 0.31654

Collected Steps per Second: 22,733.02074
Overall Steps per Second: 10,804.12624

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.42900
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.62897

Cumulative Model Updates: 365,608
Cumulative Timesteps: 3,049,214,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.72629
Policy Entropy: 3.97695
Value Function Loss: 0.00635

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02520
Policy Update Magnitude: 0.25985
Value Function Update Magnitude: 0.31346

Collected Steps per Second: 23,018.63199
Overall Steps per Second: 10,914.96311

Timestep Collection Time: 2.17285
Timestep Consumption Time: 2.40948
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.58233

Cumulative Model Updates: 365,614
Cumulative Timesteps: 3,049,264,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3049264096...
Checkpoint 3049264096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.66319
Policy Entropy: 3.96957
Value Function Loss: 0.00606

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02622
Policy Update Magnitude: 0.24720
Value Function Update Magnitude: 0.29337

Collected Steps per Second: 22,764.65470
Overall Steps per Second: 10,841.53738

Timestep Collection Time: 2.19691
Timestep Consumption Time: 2.41608
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.61300

Cumulative Model Updates: 365,620
Cumulative Timesteps: 3,049,314,108

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.22269
Policy Entropy: 4.03379
Value Function Loss: 0.00561

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02199
Policy Update Magnitude: 0.23787
Value Function Update Magnitude: 0.28318

Collected Steps per Second: 20,072.60917
Overall Steps per Second: 10,109.05921

Timestep Collection Time: 2.49126
Timestep Consumption Time: 2.45540
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.94665

Cumulative Model Updates: 365,626
Cumulative Timesteps: 3,049,364,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3049364114...
Checkpoint 3049364114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.76799
Policy Entropy: 3.98676
Value Function Loss: 0.00715

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.25114
Value Function Update Magnitude: 0.28739

Collected Steps per Second: 21,816.37786
Overall Steps per Second: 10,362.54061

Timestep Collection Time: 2.29314
Timestep Consumption Time: 2.53463
PPO Batch Consumption Time: 0.29822
Total Iteration Time: 4.82777

Cumulative Model Updates: 365,632
Cumulative Timesteps: 3,049,414,142

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.50766
Policy Entropy: 3.96626
Value Function Loss: 0.00779

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02478
Policy Update Magnitude: 0.26403
Value Function Update Magnitude: 0.31318

Collected Steps per Second: 22,169.49078
Overall Steps per Second: 10,454.65651

Timestep Collection Time: 2.25562
Timestep Consumption Time: 2.52751
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.78313

Cumulative Model Updates: 365,638
Cumulative Timesteps: 3,049,464,148

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3049464148...
Checkpoint 3049464148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.47060
Policy Entropy: 3.95325
Value Function Loss: 0.00774

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.26393
Value Function Update Magnitude: 0.33376

Collected Steps per Second: 21,966.05646
Overall Steps per Second: 10,542.70484

Timestep Collection Time: 2.27742
Timestep Consumption Time: 2.46766
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.74508

Cumulative Model Updates: 365,644
Cumulative Timesteps: 3,049,514,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.63865
Policy Entropy: 3.99617
Value Function Loss: 0.00707

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.25377
Value Function Update Magnitude: 0.32811

Collected Steps per Second: 22,159.28319
Overall Steps per Second: 10,590.04540

Timestep Collection Time: 2.25675
Timestep Consumption Time: 2.46542
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.72217

Cumulative Model Updates: 365,650
Cumulative Timesteps: 3,049,564,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3049564182...
Checkpoint 3049564182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.70617
Policy Entropy: 4.02007
Value Function Loss: 0.00730

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02266
Policy Update Magnitude: 0.25335
Value Function Update Magnitude: 0.32643

Collected Steps per Second: 21,561.82470
Overall Steps per Second: 10,601.86967

Timestep Collection Time: 2.31956
Timestep Consumption Time: 2.39791
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.71747

Cumulative Model Updates: 365,656
Cumulative Timesteps: 3,049,614,196

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.19335
Policy Entropy: 4.00580
Value Function Loss: 0.00751

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02836
Policy Update Magnitude: 0.26635
Value Function Update Magnitude: 0.33582

Collected Steps per Second: 20,625.93119
Overall Steps per Second: 9,945.81424

Timestep Collection Time: 2.42491
Timestep Consumption Time: 2.60394
PPO Batch Consumption Time: 0.29841
Total Iteration Time: 5.02885

Cumulative Model Updates: 365,662
Cumulative Timesteps: 3,049,664,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3049664212...
Checkpoint 3049664212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.67294
Policy Entropy: 4.03216
Value Function Loss: 0.00679

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.02950
Policy Update Magnitude: 0.26245
Value Function Update Magnitude: 0.32375

Collected Steps per Second: 20,907.39761
Overall Steps per Second: 10,381.21970

Timestep Collection Time: 2.39179
Timestep Consumption Time: 2.42518
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.81697

Cumulative Model Updates: 365,668
Cumulative Timesteps: 3,049,714,218

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.97756
Policy Entropy: 4.03902
Value Function Loss: 0.00639

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.24930
Value Function Update Magnitude: 0.29971

Collected Steps per Second: 22,413.32043
Overall Steps per Second: 10,210.78705

Timestep Collection Time: 2.23198
Timestep Consumption Time: 2.66735
PPO Batch Consumption Time: 0.30000
Total Iteration Time: 4.89933

Cumulative Model Updates: 365,674
Cumulative Timesteps: 3,049,764,244

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3049764244...
Checkpoint 3049764244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.28482
Policy Entropy: 4.00201
Value Function Loss: 0.00592

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.24276
Value Function Update Magnitude: 0.28320

Collected Steps per Second: 21,900.84040
Overall Steps per Second: 10,385.62849

Timestep Collection Time: 2.28384
Timestep Consumption Time: 2.53224
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.81608

Cumulative Model Updates: 365,680
Cumulative Timesteps: 3,049,814,262

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.62060
Policy Entropy: 3.94602
Value Function Loss: 0.00612

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 0.24898
Value Function Update Magnitude: 0.27957

Collected Steps per Second: 22,285.45681
Overall Steps per Second: 10,679.60174

Timestep Collection Time: 2.24469
Timestep Consumption Time: 2.43938
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.68407

Cumulative Model Updates: 365,686
Cumulative Timesteps: 3,049,864,286

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3049864286...
Checkpoint 3049864286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.43933
Policy Entropy: 3.92730
Value Function Loss: 0.00656

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.24814
Value Function Update Magnitude: 0.29935

Collected Steps per Second: 22,317.80452
Overall Steps per Second: 10,495.73869

Timestep Collection Time: 2.24135
Timestep Consumption Time: 2.52458
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.76593

Cumulative Model Updates: 365,692
Cumulative Timesteps: 3,049,914,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.34092
Policy Entropy: 3.98577
Value Function Loss: 0.00530

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.23842
Value Function Update Magnitude: 0.30791

Collected Steps per Second: 22,129.33932
Overall Steps per Second: 10,281.97186

Timestep Collection Time: 2.25971
Timestep Consumption Time: 2.60375
PPO Batch Consumption Time: 0.30977
Total Iteration Time: 4.86346

Cumulative Model Updates: 365,698
Cumulative Timesteps: 3,049,964,314

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3049964314...
Checkpoint 3049964314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.83127
Policy Entropy: 3.99092
Value Function Loss: 0.00489

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02166
Policy Update Magnitude: 0.22968
Value Function Update Magnitude: 0.29770

Collected Steps per Second: 19,221.37411
Overall Steps per Second: 9,863.76150

Timestep Collection Time: 2.60242
Timestep Consumption Time: 2.46888
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 5.07129

Cumulative Model Updates: 365,704
Cumulative Timesteps: 3,050,014,336

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.42778
Policy Entropy: 4.02255
Value Function Loss: 0.00414

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01930
Policy Update Magnitude: 0.21806
Value Function Update Magnitude: 0.28763

Collected Steps per Second: 21,325.61296
Overall Steps per Second: 10,150.37505

Timestep Collection Time: 2.34572
Timestep Consumption Time: 2.58257
PPO Batch Consumption Time: 0.29685
Total Iteration Time: 4.92829

Cumulative Model Updates: 365,710
Cumulative Timesteps: 3,050,064,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3050064360...
Checkpoint 3050064360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.87625
Policy Entropy: 4.00763
Value Function Loss: 0.00501

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02180
Policy Update Magnitude: 0.22731
Value Function Update Magnitude: 0.28995

Collected Steps per Second: 20,836.52972
Overall Steps per Second: 10,245.24454

Timestep Collection Time: 2.40050
Timestep Consumption Time: 2.48157
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.88207

Cumulative Model Updates: 365,716
Cumulative Timesteps: 3,050,114,378

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.14315
Policy Entropy: 3.98686
Value Function Loss: 0.00513

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02390
Policy Update Magnitude: 0.23282
Value Function Update Magnitude: 0.29312

Collected Steps per Second: 22,926.80755
Overall Steps per Second: 10,612.01604

Timestep Collection Time: 2.18129
Timestep Consumption Time: 2.53129
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.71258

Cumulative Model Updates: 365,722
Cumulative Timesteps: 3,050,164,388

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3050164388...
Checkpoint 3050164388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.91618
Policy Entropy: 3.97216
Value Function Loss: 0.00585

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.03092
Policy Update Magnitude: 0.23720
Value Function Update Magnitude: 0.29063

Collected Steps per Second: 22,263.39040
Overall Steps per Second: 10,464.83308

Timestep Collection Time: 2.24710
Timestep Consumption Time: 2.53349
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.78058

Cumulative Model Updates: 365,728
Cumulative Timesteps: 3,050,214,416

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.67475
Policy Entropy: 3.96860
Value Function Loss: 0.00635

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.24248
Value Function Update Magnitude: 0.29975

Collected Steps per Second: 22,082.73630
Overall Steps per Second: 10,475.49093

Timestep Collection Time: 2.26467
Timestep Consumption Time: 2.50934
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.77400

Cumulative Model Updates: 365,734
Cumulative Timesteps: 3,050,264,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3050264426...
Checkpoint 3050264426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.93411
Policy Entropy: 4.03727
Value Function Loss: 0.00608

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.23613
Value Function Update Magnitude: 0.30420

Collected Steps per Second: 23,151.79066
Overall Steps per Second: 10,646.50511

Timestep Collection Time: 2.16070
Timestep Consumption Time: 2.53793
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.69863

Cumulative Model Updates: 365,740
Cumulative Timesteps: 3,050,314,450

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.62098
Policy Entropy: 4.02976
Value Function Loss: 0.00609

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02646
Policy Update Magnitude: 0.23302
Value Function Update Magnitude: 0.31403

Collected Steps per Second: 20,772.99511
Overall Steps per Second: 10,172.70911

Timestep Collection Time: 2.40813
Timestep Consumption Time: 2.50934
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.91747

Cumulative Model Updates: 365,746
Cumulative Timesteps: 3,050,364,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3050364474...
Checkpoint 3050364474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.95779
Policy Entropy: 4.00176
Value Function Loss: 0.00553

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.03116
Policy Update Magnitude: 0.23715
Value Function Update Magnitude: 0.30084

Collected Steps per Second: 20,771.67728
Overall Steps per Second: 10,277.06396

Timestep Collection Time: 2.40751
Timestep Consumption Time: 2.45847
PPO Batch Consumption Time: 0.29638
Total Iteration Time: 4.86598

Cumulative Model Updates: 365,752
Cumulative Timesteps: 3,050,414,482

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.94872
Policy Entropy: 3.97268
Value Function Loss: 0.00565

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.03486
Policy Update Magnitude: 0.23339
Value Function Update Magnitude: 0.30077

Collected Steps per Second: 22,525.80915
Overall Steps per Second: 10,549.45170

Timestep Collection Time: 2.22030
Timestep Consumption Time: 2.52061
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.74091

Cumulative Model Updates: 365,758
Cumulative Timesteps: 3,050,464,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3050464496...
Checkpoint 3050464496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.88763
Policy Entropy: 4.00391
Value Function Loss: 0.00483

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 0.23477
Value Function Update Magnitude: 0.29418

Collected Steps per Second: 22,286.32842
Overall Steps per Second: 10,535.27782

Timestep Collection Time: 2.24371
Timestep Consumption Time: 2.50263
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.74634

Cumulative Model Updates: 365,764
Cumulative Timesteps: 3,050,514,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.11000
Policy Entropy: 4.02922
Value Function Loss: 0.00484

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.22729
Value Function Update Magnitude: 0.28651

Collected Steps per Second: 22,637.26592
Overall Steps per Second: 10,714.17592

Timestep Collection Time: 2.20928
Timestep Consumption Time: 2.45856
PPO Batch Consumption Time: 0.29537
Total Iteration Time: 4.66783

Cumulative Model Updates: 365,770
Cumulative Timesteps: 3,050,564,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3050564512...
Checkpoint 3050564512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.34633
Policy Entropy: 3.99488
Value Function Loss: 0.00534

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02386
Policy Update Magnitude: 0.22927
Value Function Update Magnitude: 0.29028

Collected Steps per Second: 22,381.42456
Overall Steps per Second: 10,698.62702

Timestep Collection Time: 2.23471
Timestep Consumption Time: 2.44028
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.67499

Cumulative Model Updates: 365,776
Cumulative Timesteps: 3,050,614,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.66264
Policy Entropy: 3.95439
Value Function Loss: 0.00630

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.23730
Value Function Update Magnitude: 0.30535

Collected Steps per Second: 22,498.86500
Overall Steps per Second: 10,545.26137

Timestep Collection Time: 2.22269
Timestep Consumption Time: 2.51953
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.74222

Cumulative Model Updates: 365,782
Cumulative Timesteps: 3,050,664,536

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3050664536...
Checkpoint 3050664536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.53240
Policy Entropy: 3.99113
Value Function Loss: 0.00568

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02570
Policy Update Magnitude: 0.24049
Value Function Update Magnitude: 0.30710

Collected Steps per Second: 21,426.50279
Overall Steps per Second: 10,834.77258

Timestep Collection Time: 2.33487
Timestep Consumption Time: 2.28249
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.61736

Cumulative Model Updates: 365,788
Cumulative Timesteps: 3,050,714,564

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.12766
Policy Entropy: 4.03019
Value Function Loss: 0.00487

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.22855
Value Function Update Magnitude: 0.29223

Collected Steps per Second: 21,681.98891
Overall Steps per Second: 10,138.26878

Timestep Collection Time: 2.30735
Timestep Consumption Time: 2.62722
PPO Batch Consumption Time: 0.29713
Total Iteration Time: 4.93457

Cumulative Model Updates: 365,794
Cumulative Timesteps: 3,050,764,592

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3050764592...
Checkpoint 3050764592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.19587
Policy Entropy: 4.03797
Value Function Loss: 0.00461

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02028
Policy Update Magnitude: 0.21927
Value Function Update Magnitude: 0.28034

Collected Steps per Second: 21,667.89220
Overall Steps per Second: 10,571.29487

Timestep Collection Time: 2.30812
Timestep Consumption Time: 2.42281
PPO Batch Consumption Time: 0.28103
Total Iteration Time: 4.73092

Cumulative Model Updates: 365,800
Cumulative Timesteps: 3,050,814,604

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.03352
Policy Entropy: 3.99692
Value Function Loss: 0.00535

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02337
Policy Update Magnitude: 0.22875
Value Function Update Magnitude: 0.28880

Collected Steps per Second: 22,310.62900
Overall Steps per Second: 10,750.74025

Timestep Collection Time: 2.24153
Timestep Consumption Time: 2.41024
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.65177

Cumulative Model Updates: 365,806
Cumulative Timesteps: 3,050,864,614

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3050864614...
Checkpoint 3050864614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.80602
Policy Entropy: 3.98767
Value Function Loss: 0.00644

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.22913
Value Function Update Magnitude: 0.30694

Collected Steps per Second: 22,454.46805
Overall Steps per Second: 10,544.86490

Timestep Collection Time: 2.22708
Timestep Consumption Time: 2.51532
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.74240

Cumulative Model Updates: 365,812
Cumulative Timesteps: 3,050,914,622

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.09003
Policy Entropy: 3.99129
Value Function Loss: 0.00669

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.23378
Value Function Update Magnitude: 0.32058

Collected Steps per Second: 22,048.34610
Overall Steps per Second: 10,519.13051

Timestep Collection Time: 2.26874
Timestep Consumption Time: 2.48659
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.75534

Cumulative Model Updates: 365,818
Cumulative Timesteps: 3,050,964,644

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3050964644...
Checkpoint 3050964644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.56511
Policy Entropy: 3.96670
Value Function Loss: 0.00631

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.23468
Value Function Update Magnitude: 0.32900

Collected Steps per Second: 19,831.40372
Overall Steps per Second: 9,721.40531

Timestep Collection Time: 2.52186
Timestep Consumption Time: 2.62266
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 5.14452

Cumulative Model Updates: 365,824
Cumulative Timesteps: 3,051,014,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.84999
Policy Entropy: 3.95611
Value Function Loss: 0.00595

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.23911
Value Function Update Magnitude: 0.32789

Collected Steps per Second: 20,468.99483
Overall Steps per Second: 9,947.56769

Timestep Collection Time: 2.44301
Timestep Consumption Time: 2.58395
PPO Batch Consumption Time: 0.30407
Total Iteration Time: 5.02696

Cumulative Model Updates: 365,830
Cumulative Timesteps: 3,051,064,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3051064662...
Checkpoint 3051064662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.18085
Policy Entropy: 3.94932
Value Function Loss: 0.00694

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03166
Policy Update Magnitude: 0.24567
Value Function Update Magnitude: 0.32834

Collected Steps per Second: 22,140.51809
Overall Steps per Second: 10,363.91479

Timestep Collection Time: 2.25866
Timestep Consumption Time: 2.56654
PPO Batch Consumption Time: 0.30882
Total Iteration Time: 4.82520

Cumulative Model Updates: 365,836
Cumulative Timesteps: 3,051,114,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.94721
Policy Entropy: 3.97732
Value Function Loss: 0.00644

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.03025
Policy Update Magnitude: 0.25028
Value Function Update Magnitude: 0.32632

Collected Steps per Second: 21,939.03046
Overall Steps per Second: 10,405.72595

Timestep Collection Time: 2.27995
Timestep Consumption Time: 2.52701
PPO Batch Consumption Time: 0.29576
Total Iteration Time: 4.80697

Cumulative Model Updates: 365,842
Cumulative Timesteps: 3,051,164,690

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3051164690...
Checkpoint 3051164690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.61500
Policy Entropy: 3.98535
Value Function Loss: 0.00605

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02991
Policy Update Magnitude: 0.24926
Value Function Update Magnitude: 0.32104

Collected Steps per Second: 21,973.54667
Overall Steps per Second: 10,480.35183

Timestep Collection Time: 2.27574
Timestep Consumption Time: 2.49567
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.77140

Cumulative Model Updates: 365,848
Cumulative Timesteps: 3,051,214,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.32748
Policy Entropy: 3.99062
Value Function Loss: 0.00629

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.02933
Policy Update Magnitude: 0.24739
Value Function Update Magnitude: 0.31440

Collected Steps per Second: 22,088.18245
Overall Steps per Second: 10,578.02707

Timestep Collection Time: 2.26447
Timestep Consumption Time: 2.46401
PPO Batch Consumption Time: 0.29657
Total Iteration Time: 4.72848

Cumulative Model Updates: 365,854
Cumulative Timesteps: 3,051,264,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3051264714...
Checkpoint 3051264714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.56314
Policy Entropy: 3.98215
Value Function Loss: 0.00652

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 0.25291
Value Function Update Magnitude: 0.31199

Collected Steps per Second: 21,678.42804
Overall Steps per Second: 10,301.74574

Timestep Collection Time: 2.30709
Timestep Consumption Time: 2.54782
PPO Batch Consumption Time: 0.29453
Total Iteration Time: 4.85491

Cumulative Model Updates: 365,860
Cumulative Timesteps: 3,051,314,728

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.83904
Policy Entropy: 3.95310
Value Function Loss: 0.00774

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.03189
Policy Update Magnitude: 0.25831
Value Function Update Magnitude: 0.33807

Collected Steps per Second: 21,497.00313
Overall Steps per Second: 10,277.86648

Timestep Collection Time: 2.32693
Timestep Consumption Time: 2.54003
PPO Batch Consumption Time: 0.29508
Total Iteration Time: 4.86696

Cumulative Model Updates: 365,866
Cumulative Timesteps: 3,051,364,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3051364750...
Checkpoint 3051364750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.22628
Policy Entropy: 3.97512
Value Function Loss: 0.00637

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.26132
Value Function Update Magnitude: 0.36296

Collected Steps per Second: 21,833.61797
Overall Steps per Second: 10,714.71130

Timestep Collection Time: 2.29096
Timestep Consumption Time: 2.37739
PPO Batch Consumption Time: 0.28196
Total Iteration Time: 4.66835

Cumulative Model Updates: 365,872
Cumulative Timesteps: 3,051,414,770

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.67202
Policy Entropy: 3.99398
Value Function Loss: 0.00605

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.25449
Value Function Update Magnitude: 0.34390

Collected Steps per Second: 22,162.00690
Overall Steps per Second: 10,354.32686

Timestep Collection Time: 2.25638
Timestep Consumption Time: 2.57309
PPO Batch Consumption Time: 0.29811
Total Iteration Time: 4.82948

Cumulative Model Updates: 365,878
Cumulative Timesteps: 3,051,464,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3051464776...
Checkpoint 3051464776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.09982
Policy Entropy: 3.98394
Value Function Loss: 0.00597

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.24230
Value Function Update Magnitude: 0.32369

Collected Steps per Second: 22,576.16680
Overall Steps per Second: 10,808.12953

Timestep Collection Time: 2.21517
Timestep Consumption Time: 2.41190
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.62707

Cumulative Model Updates: 365,884
Cumulative Timesteps: 3,051,514,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.28870
Policy Entropy: 3.93976
Value Function Loss: 0.00673

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.24549
Value Function Update Magnitude: 0.32648

Collected Steps per Second: 22,249.79402
Overall Steps per Second: 10,795.15721

Timestep Collection Time: 2.24811
Timestep Consumption Time: 2.38545
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.63356

Cumulative Model Updates: 365,890
Cumulative Timesteps: 3,051,564,806

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3051564806...
Checkpoint 3051564806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.84299
Policy Entropy: 3.93024
Value Function Loss: 0.00678

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.24088
Value Function Update Magnitude: 0.33832

Collected Steps per Second: 21,833.90383
Overall Steps per Second: 10,437.27102

Timestep Collection Time: 2.29020
Timestep Consumption Time: 2.50071
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.79091

Cumulative Model Updates: 365,896
Cumulative Timesteps: 3,051,614,810

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70409
Policy Entropy: 3.95996
Value Function Loss: 0.00653

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02280
Policy Update Magnitude: 0.23982
Value Function Update Magnitude: 0.33436

Collected Steps per Second: 22,528.14555
Overall Steps per Second: 10,736.16400

Timestep Collection Time: 2.22060
Timestep Consumption Time: 2.43898
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.65958

Cumulative Model Updates: 365,902
Cumulative Timesteps: 3,051,664,836

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3051664836...
Checkpoint 3051664836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.97405
Policy Entropy: 3.93998
Value Function Loss: 0.00751

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.25462
Value Function Update Magnitude: 0.32611

Collected Steps per Second: 22,678.80182
Overall Steps per Second: 10,337.27718

Timestep Collection Time: 2.20479
Timestep Consumption Time: 2.63227
PPO Batch Consumption Time: 0.30918
Total Iteration Time: 4.83706

Cumulative Model Updates: 365,908
Cumulative Timesteps: 3,051,714,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.18332
Policy Entropy: 3.93457
Value Function Loss: 0.00802

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.03330
Policy Update Magnitude: 0.27064
Value Function Update Magnitude: 0.34269

Collected Steps per Second: 22,619.85150
Overall Steps per Second: 10,500.56493

Timestep Collection Time: 2.21116
Timestep Consumption Time: 2.55202
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.76317

Cumulative Model Updates: 365,914
Cumulative Timesteps: 3,051,764,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3051764854...
Checkpoint 3051764854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.97307
Policy Entropy: 3.93390
Value Function Loss: 0.00766

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.03799
Policy Update Magnitude: 0.28852
Value Function Update Magnitude: 0.34970

Collected Steps per Second: 22,103.00840
Overall Steps per Second: 10,516.02271

Timestep Collection Time: 2.26277
Timestep Consumption Time: 2.49321
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.75598

Cumulative Model Updates: 365,920
Cumulative Timesteps: 3,051,814,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.63772
Policy Entropy: 3.95942
Value Function Loss: 0.00657

Mean KL Divergence: 0.00726
SB3 Clip Fraction: 0.04238
Policy Update Magnitude: 0.27164
Value Function Update Magnitude: 0.34855

Collected Steps per Second: 23,495.91508
Overall Steps per Second: 10,859.23484

Timestep Collection Time: 2.12931
Timestep Consumption Time: 2.47783
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.60714

Cumulative Model Updates: 365,926
Cumulative Timesteps: 3,051,864,898

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3051864898...
Checkpoint 3051864898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3.71071
Policy Entropy: 3.98839
Value Function Loss: 0.00576

Mean KL Divergence: 0.00568
SB3 Clip Fraction: 0.03508
Policy Update Magnitude: 0.26016
Value Function Update Magnitude: 0.34872

Collected Steps per Second: 22,216.92162
Overall Steps per Second: 10,604.55439

Timestep Collection Time: 2.25090
Timestep Consumption Time: 2.46481
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.71571

Cumulative Model Updates: 365,932
Cumulative Timesteps: 3,051,914,906

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.93349
Policy Entropy: 3.97229
Value Function Loss: 0.00608

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.03281
Policy Update Magnitude: 0.25407
Value Function Update Magnitude: 0.33482

Collected Steps per Second: 22,512.24440
Overall Steps per Second: 10,871.76291

Timestep Collection Time: 2.22155
Timestep Consumption Time: 2.37863
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.60017

Cumulative Model Updates: 365,938
Cumulative Timesteps: 3,051,964,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3051964918...
Checkpoint 3051964918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.94357
Policy Entropy: 3.95999
Value Function Loss: 0.00575

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.03005
Policy Update Magnitude: 0.24854
Value Function Update Magnitude: 0.31959

Collected Steps per Second: 22,152.06104
Overall Steps per Second: 10,605.18936

Timestep Collection Time: 2.25785
Timestep Consumption Time: 2.45833
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.71618

Cumulative Model Updates: 365,944
Cumulative Timesteps: 3,052,014,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.43918
Policy Entropy: 3.94241
Value Function Loss: 0.00570

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.25105
Value Function Update Magnitude: 0.31143

Collected Steps per Second: 22,528.06549
Overall Steps per Second: 10,593.66190

Timestep Collection Time: 2.22016
Timestep Consumption Time: 2.50115
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.72131

Cumulative Model Updates: 365,950
Cumulative Timesteps: 3,052,064,950

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3052064950...
Checkpoint 3052064950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.60762
Policy Entropy: 3.96209
Value Function Loss: 0.00605

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.24769
Value Function Update Magnitude: 0.32170

Collected Steps per Second: 22,220.49199
Overall Steps per Second: 10,656.76855

Timestep Collection Time: 2.25018
Timestep Consumption Time: 2.44168
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.69185

Cumulative Model Updates: 365,956
Cumulative Timesteps: 3,052,114,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.95223
Policy Entropy: 3.99132
Value Function Loss: 0.00554

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02211
Policy Update Magnitude: 0.23683
Value Function Update Magnitude: 0.32933

Collected Steps per Second: 22,646.92618
Overall Steps per Second: 10,566.48777

Timestep Collection Time: 2.20825
Timestep Consumption Time: 2.52464
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.73289

Cumulative Model Updates: 365,962
Cumulative Timesteps: 3,052,164,960

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3052164960...
Checkpoint 3052164960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.12674
Policy Entropy: 3.98769
Value Function Loss: 0.00613

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02483
Policy Update Magnitude: 0.23291
Value Function Update Magnitude: 0.32601

Collected Steps per Second: 22,271.11477
Overall Steps per Second: 10,523.55851

Timestep Collection Time: 2.24515
Timestep Consumption Time: 2.50628
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.75143

Cumulative Model Updates: 365,968
Cumulative Timesteps: 3,052,214,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.87432
Policy Entropy: 4.00941
Value Function Loss: 0.00531

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02204
Policy Update Magnitude: 0.23036
Value Function Update Magnitude: 0.31782

Collected Steps per Second: 23,686.93211
Overall Steps per Second: 10,868.41518

Timestep Collection Time: 2.11197
Timestep Consumption Time: 2.49091
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.60288

Cumulative Model Updates: 365,974
Cumulative Timesteps: 3,052,264,988

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3052264988...
Checkpoint 3052264988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.83452
Policy Entropy: 4.01992
Value Function Loss: 0.00517

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02201
Policy Update Magnitude: 0.23098
Value Function Update Magnitude: 0.31402

Collected Steps per Second: 21,991.43155
Overall Steps per Second: 10,586.53273

Timestep Collection Time: 2.27425
Timestep Consumption Time: 2.45005
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.72430

Cumulative Model Updates: 365,980
Cumulative Timesteps: 3,052,315,002

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.63339
Policy Entropy: 4.04163
Value Function Loss: 0.00537

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.22960
Value Function Update Magnitude: 0.29864

Collected Steps per Second: 22,493.54494
Overall Steps per Second: 10,360.81033

Timestep Collection Time: 2.22322
Timestep Consumption Time: 2.60343
PPO Batch Consumption Time: 0.29926
Total Iteration Time: 4.82665

Cumulative Model Updates: 365,986
Cumulative Timesteps: 3,052,365,010

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3052365010...
Checkpoint 3052365010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.60251
Policy Entropy: 3.99700
Value Function Loss: 0.00588

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02012
Policy Update Magnitude: 0.23625
Value Function Update Magnitude: 0.31070

Collected Steps per Second: 22,827.47223
Overall Steps per Second: 10,748.80536

Timestep Collection Time: 2.19122
Timestep Consumption Time: 2.46232
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.65354

Cumulative Model Updates: 365,992
Cumulative Timesteps: 3,052,415,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.86996
Policy Entropy: 3.97922
Value Function Loss: 0.00574

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02124
Policy Update Magnitude: 0.24965
Value Function Update Magnitude: 0.32664

Collected Steps per Second: 22,503.10727
Overall Steps per Second: 10,492.23981

Timestep Collection Time: 2.22334
Timestep Consumption Time: 2.54514
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.76848

Cumulative Model Updates: 365,998
Cumulative Timesteps: 3,052,465,062

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3052465062...
Checkpoint 3052465062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.52881
Policy Entropy: 3.92800
Value Function Loss: 0.00636

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02247
Policy Update Magnitude: 0.25312
Value Function Update Magnitude: 0.33727

Collected Steps per Second: 22,138.50995
Overall Steps per Second: 10,658.79126

Timestep Collection Time: 2.25914
Timestep Consumption Time: 2.43314
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.69228

Cumulative Model Updates: 366,004
Cumulative Timesteps: 3,052,515,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.74306
Policy Entropy: 3.91366
Value Function Loss: 0.00698

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.26652
Value Function Update Magnitude: 0.34555

Collected Steps per Second: 22,708.95719
Overall Steps per Second: 10,644.64373

Timestep Collection Time: 2.20230
Timestep Consumption Time: 2.49602
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.69833

Cumulative Model Updates: 366,010
Cumulative Timesteps: 3,052,565,088

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3052565088...
Checkpoint 3052565088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.93106
Policy Entropy: 3.91873
Value Function Loss: 0.00652

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.03106
Policy Update Magnitude: 0.26754
Value Function Update Magnitude: 0.35791

Collected Steps per Second: 22,475.62713
Overall Steps per Second: 10,534.67278

Timestep Collection Time: 2.22481
Timestep Consumption Time: 2.52180
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.74661

Cumulative Model Updates: 366,016
Cumulative Timesteps: 3,052,615,092

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.44539
Policy Entropy: 3.95894
Value Function Loss: 0.00641

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.03150
Policy Update Magnitude: 0.25926
Value Function Update Magnitude: 0.35356

Collected Steps per Second: 22,496.47464
Overall Steps per Second: 10,815.80059

Timestep Collection Time: 2.22382
Timestep Consumption Time: 2.40164
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.62546

Cumulative Model Updates: 366,022
Cumulative Timesteps: 3,052,665,120

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3052665120...
Checkpoint 3052665120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.21673
Policy Entropy: 4.02576
Value Function Loss: 0.00574

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02437
Policy Update Magnitude: 0.24553
Value Function Update Magnitude: 0.33478

Collected Steps per Second: 22,467.24889
Overall Steps per Second: 10,637.36895

Timestep Collection Time: 2.22635
Timestep Consumption Time: 2.47594
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.70229

Cumulative Model Updates: 366,028
Cumulative Timesteps: 3,052,715,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.34276
Policy Entropy: 4.01089
Value Function Loss: 0.00619

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.23787
Value Function Update Magnitude: 0.32296

Collected Steps per Second: 22,501.67073
Overall Steps per Second: 10,615.25251

Timestep Collection Time: 2.22268
Timestep Consumption Time: 2.48884
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.71152

Cumulative Model Updates: 366,034
Cumulative Timesteps: 3,052,765,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3052765154...
Checkpoint 3052765154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.82854
Policy Entropy: 3.99940
Value Function Loss: 0.00599

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.24058
Value Function Update Magnitude: 0.31487

Collected Steps per Second: 22,152.79413
Overall Steps per Second: 10,682.57384

Timestep Collection Time: 2.25768
Timestep Consumption Time: 2.42415
PPO Batch Consumption Time: 0.29088
Total Iteration Time: 4.68183

Cumulative Model Updates: 366,040
Cumulative Timesteps: 3,052,815,168

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.01896
Policy Entropy: 3.97392
Value Function Loss: 0.00657

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02548
Policy Update Magnitude: 0.24168
Value Function Update Magnitude: 0.34316

Collected Steps per Second: 22,555.43091
Overall Steps per Second: 10,738.48654

Timestep Collection Time: 2.21712
Timestep Consumption Time: 2.43978
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.65689

Cumulative Model Updates: 366,046
Cumulative Timesteps: 3,052,865,176

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3052865176...
Checkpoint 3052865176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.89371
Policy Entropy: 3.95764
Value Function Loss: 0.00601

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.24569
Value Function Update Magnitude: 0.35882

Collected Steps per Second: 22,194.48602
Overall Steps per Second: 10,633.93728

Timestep Collection Time: 2.25281
Timestep Consumption Time: 2.44912
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.70193

Cumulative Model Updates: 366,052
Cumulative Timesteps: 3,052,915,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.14367
Policy Entropy: 3.96822
Value Function Loss: 0.00541

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02473
Policy Update Magnitude: 0.25192
Value Function Update Magnitude: 0.35619

Collected Steps per Second: 22,477.97547
Overall Steps per Second: 10,836.96335

Timestep Collection Time: 2.22520
Timestep Consumption Time: 2.39030
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.61550

Cumulative Model Updates: 366,058
Cumulative Timesteps: 3,052,965,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3052965194...
Checkpoint 3052965194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.50238
Policy Entropy: 3.99663
Value Function Loss: 0.00442

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.24129
Value Function Update Magnitude: 0.33374

Collected Steps per Second: 22,511.74351
Overall Steps per Second: 10,664.01168

Timestep Collection Time: 2.22195
Timestep Consumption Time: 2.46859
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.69054

Cumulative Model Updates: 366,064
Cumulative Timesteps: 3,053,015,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.60678
Policy Entropy: 4.04445
Value Function Loss: 0.00460

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.23749
Value Function Update Magnitude: 0.30379

Collected Steps per Second: 22,510.22182
Overall Steps per Second: 10,875.01075

Timestep Collection Time: 2.22228
Timestep Consumption Time: 2.37762
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.59990

Cumulative Model Updates: 366,070
Cumulative Timesteps: 3,053,065,238

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3053065238...
Checkpoint 3053065238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.11701
Policy Entropy: 4.01060
Value Function Loss: 0.00628

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02091
Policy Update Magnitude: 0.23504
Value Function Update Magnitude: 0.29877

Collected Steps per Second: 21,913.55669
Overall Steps per Second: 10,470.19447

Timestep Collection Time: 2.28224
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.77661

Cumulative Model Updates: 366,076
Cumulative Timesteps: 3,053,115,250

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.85635
Policy Entropy: 3.97627
Value Function Loss: 0.00679

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02293
Policy Update Magnitude: 0.24081
Value Function Update Magnitude: 0.31053

Collected Steps per Second: 22,322.86691
Overall Steps per Second: 10,641.63888

Timestep Collection Time: 2.24093
Timestep Consumption Time: 2.45985
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.70078

Cumulative Model Updates: 366,082
Cumulative Timesteps: 3,053,165,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3053165274...
Checkpoint 3053165274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.73714
Policy Entropy: 3.92039
Value Function Loss: 0.00733

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.24621
Value Function Update Magnitude: 0.32249

Collected Steps per Second: 22,338.17288
Overall Steps per Second: 10,710.12448

Timestep Collection Time: 2.23850
Timestep Consumption Time: 2.43035
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.66885

Cumulative Model Updates: 366,088
Cumulative Timesteps: 3,053,215,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.82453
Policy Entropy: 3.88349
Value Function Loss: 0.00847

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02932
Policy Update Magnitude: 0.26178
Value Function Update Magnitude: 0.33395

Collected Steps per Second: 22,779.21545
Overall Steps per Second: 10,652.40248

Timestep Collection Time: 2.19630
Timestep Consumption Time: 2.50029
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.69659

Cumulative Model Updates: 366,094
Cumulative Timesteps: 3,053,265,308

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3053265308...
Checkpoint 3053265308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.19123
Policy Entropy: 3.87238
Value Function Loss: 0.00861

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.03462
Policy Update Magnitude: 0.26849
Value Function Update Magnitude: 0.35954

Collected Steps per Second: 22,309.86899
Overall Steps per Second: 10,580.75786

Timestep Collection Time: 2.24188
Timestep Consumption Time: 2.48519
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.72707

Cumulative Model Updates: 366,100
Cumulative Timesteps: 3,053,315,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.95790
Policy Entropy: 3.91461
Value Function Loss: 0.00733

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 0.25945
Value Function Update Magnitude: 0.36680

Collected Steps per Second: 22,719.04173
Overall Steps per Second: 10,749.76437

Timestep Collection Time: 2.20177
Timestep Consumption Time: 2.45155
PPO Batch Consumption Time: 0.29372
Total Iteration Time: 4.65331

Cumulative Model Updates: 366,106
Cumulative Timesteps: 3,053,365,346

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3053365346...
Checkpoint 3053365346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.89030
Policy Entropy: 3.99474
Value Function Loss: 0.00511

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.24522
Value Function Update Magnitude: 0.32800

Collected Steps per Second: 22,328.43929
Overall Steps per Second: 10,630.12093

Timestep Collection Time: 2.24019
Timestep Consumption Time: 2.46530
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.70550

Cumulative Model Updates: 366,112
Cumulative Timesteps: 3,053,415,366

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.87524
Policy Entropy: 3.98708
Value Function Loss: 0.00494

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02394
Policy Update Magnitude: 0.24842
Value Function Update Magnitude: 0.30325

Collected Steps per Second: 22,518.55084
Overall Steps per Second: 10,630.37404

Timestep Collection Time: 2.22181
Timestep Consumption Time: 2.48470
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.70651

Cumulative Model Updates: 366,118
Cumulative Timesteps: 3,053,465,398

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3053465398...
Checkpoint 3053465398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.81844
Policy Entropy: 3.94375
Value Function Loss: 0.00593

Mean KL Divergence: 0.00489
SB3 Clip Fraction: 0.03305
Policy Update Magnitude: 0.24603
Value Function Update Magnitude: 0.31663

Collected Steps per Second: 22,166.06606
Overall Steps per Second: 10,709.28645

Timestep Collection Time: 2.25597
Timestep Consumption Time: 2.41343
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.66941

Cumulative Model Updates: 366,124
Cumulative Timesteps: 3,053,515,404

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.16159
Policy Entropy: 3.91551
Value Function Loss: 0.00699

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.03279
Policy Update Magnitude: 0.24811
Value Function Update Magnitude: 0.34872

Collected Steps per Second: 22,690.98335
Overall Steps per Second: 10,712.06268

Timestep Collection Time: 2.20475
Timestep Consumption Time: 2.46550
PPO Batch Consumption Time: 0.28062
Total Iteration Time: 4.67025

Cumulative Model Updates: 366,130
Cumulative Timesteps: 3,053,565,432

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3053565432...
Checkpoint 3053565432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.75341
Policy Entropy: 3.93728
Value Function Loss: 0.00656

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.03071
Policy Update Magnitude: 0.25494
Value Function Update Magnitude: 0.35031

Collected Steps per Second: 22,149.53094
Overall Steps per Second: 10,711.33340

Timestep Collection Time: 2.25829
Timestep Consumption Time: 2.41153
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.66982

Cumulative Model Updates: 366,136
Cumulative Timesteps: 3,053,615,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.74543
Policy Entropy: 3.97603
Value Function Loss: 0.00572

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.02958
Policy Update Magnitude: 0.24177
Value Function Update Magnitude: 0.32871

Collected Steps per Second: 23,268.44082
Overall Steps per Second: 10,882.22436

Timestep Collection Time: 2.14935
Timestep Consumption Time: 2.44640
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.59575

Cumulative Model Updates: 366,142
Cumulative Timesteps: 3,053,665,464

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3053665464...
Checkpoint 3053665464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.83163
Policy Entropy: 3.97501
Value Function Loss: 0.00589

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.03140
Policy Update Magnitude: 0.24145
Value Function Update Magnitude: 0.31259

Collected Steps per Second: 22,131.66843
Overall Steps per Second: 10,589.10082

Timestep Collection Time: 2.26002
Timestep Consumption Time: 2.46352
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.72354

Cumulative Model Updates: 366,148
Cumulative Timesteps: 3,053,715,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.64574
Policy Entropy: 3.90706
Value Function Loss: 0.00743

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02954
Policy Update Magnitude: 0.25372
Value Function Update Magnitude: 0.32068

Collected Steps per Second: 22,305.31416
Overall Steps per Second: 10,498.91950

Timestep Collection Time: 2.24234
Timestep Consumption Time: 2.52158
PPO Batch Consumption Time: 0.29414
Total Iteration Time: 4.76392

Cumulative Model Updates: 366,154
Cumulative Timesteps: 3,053,765,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3053765498...
Checkpoint 3053765498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.46764
Policy Entropy: 3.89369
Value Function Loss: 0.00786

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.03045
Policy Update Magnitude: 0.26675
Value Function Update Magnitude: 0.34707

Collected Steps per Second: 23,290.89864
Overall Steps per Second: 10,737.08498

Timestep Collection Time: 2.14736
Timestep Consumption Time: 2.51070
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.65806

Cumulative Model Updates: 366,160
Cumulative Timesteps: 3,053,815,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.06048
Policy Entropy: 3.86325
Value Function Loss: 0.00729

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.03038
Policy Update Magnitude: 0.26833
Value Function Update Magnitude: 0.36627

Collected Steps per Second: 22,692.51211
Overall Steps per Second: 10,752.43810

Timestep Collection Time: 2.20443
Timestep Consumption Time: 2.44791
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.65234

Cumulative Model Updates: 366,166
Cumulative Timesteps: 3,053,865,536

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3053865536...
Checkpoint 3053865536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.82256
Policy Entropy: 3.91330
Value Function Loss: 0.00686

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.27121
Value Function Update Magnitude: 0.35769

Collected Steps per Second: 22,046.86144
Overall Steps per Second: 10,628.54615

Timestep Collection Time: 2.26844
Timestep Consumption Time: 2.43700
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.70544

Cumulative Model Updates: 366,172
Cumulative Timesteps: 3,053,915,548

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.49578
Policy Entropy: 3.91964
Value Function Loss: 0.00636

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.03028
Policy Update Magnitude: 0.25944
Value Function Update Magnitude: 0.33268

Collected Steps per Second: 23,151.38552
Overall Steps per Second: 10,726.44096

Timestep Collection Time: 2.16082
Timestep Consumption Time: 2.50298
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.66380

Cumulative Model Updates: 366,178
Cumulative Timesteps: 3,053,965,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3053965574...
Checkpoint 3053965574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.35097
Policy Entropy: 3.94179
Value Function Loss: 0.00657

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.25350
Value Function Update Magnitude: 0.32239

Collected Steps per Second: 22,395.78621
Overall Steps per Second: 10,554.02183

Timestep Collection Time: 2.23480
Timestep Consumption Time: 2.50747
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.74227

Cumulative Model Updates: 366,184
Cumulative Timesteps: 3,054,015,624

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.25256
Policy Entropy: 3.97647
Value Function Loss: 0.00582

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.24998
Value Function Update Magnitude: 0.32710

Collected Steps per Second: 22,058.84624
Overall Steps per Second: 10,772.22984

Timestep Collection Time: 2.26676
Timestep Consumption Time: 2.37500
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.64175

Cumulative Model Updates: 366,190
Cumulative Timesteps: 3,054,065,626

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3054065626...
Checkpoint 3054065626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.51879
Policy Entropy: 4.00290
Value Function Loss: 0.00623

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.23582
Value Function Update Magnitude: 0.31579

Collected Steps per Second: 22,301.91596
Overall Steps per Second: 10,637.01588

Timestep Collection Time: 2.24214
Timestep Consumption Time: 2.45880
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.70094

Cumulative Model Updates: 366,196
Cumulative Timesteps: 3,054,115,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.75862
Policy Entropy: 4.04456
Value Function Loss: 0.00632

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.22275
Value Function Update Magnitude: 0.29483

Collected Steps per Second: 22,593.44089
Overall Steps per Second: 10,628.82686

Timestep Collection Time: 2.21445
Timestep Consumption Time: 2.49275
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.70720

Cumulative Model Updates: 366,202
Cumulative Timesteps: 3,054,165,662

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3054165662...
Checkpoint 3054165662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.41995
Policy Entropy: 3.99029
Value Function Loss: 0.00693

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02707
Policy Update Magnitude: 0.22505
Value Function Update Magnitude: 0.30439

Collected Steps per Second: 22,261.63444
Overall Steps per Second: 10,831.27654

Timestep Collection Time: 2.24629
Timestep Consumption Time: 2.37053
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.61682

Cumulative Model Updates: 366,208
Cumulative Timesteps: 3,054,215,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05329
Policy Entropy: 3.97000
Value Function Loss: 0.00641

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.24290
Value Function Update Magnitude: 0.32534

Collected Steps per Second: 22,588.07545
Overall Steps per Second: 10,577.76359

Timestep Collection Time: 2.21391
Timestep Consumption Time: 2.51374
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.72765

Cumulative Model Updates: 366,214
Cumulative Timesteps: 3,054,265,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3054265676...
Checkpoint 3054265676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.72109
Policy Entropy: 3.94480
Value Function Loss: 0.00661

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02872
Policy Update Magnitude: 0.24493
Value Function Update Magnitude: 0.32818

Collected Steps per Second: 22,066.97175
Overall Steps per Second: 10,669.89868

Timestep Collection Time: 2.26665
Timestep Consumption Time: 2.42112
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.68777

Cumulative Model Updates: 366,220
Cumulative Timesteps: 3,054,315,694

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.55406
Policy Entropy: 3.94557
Value Function Loss: 0.00690

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02498
Policy Update Magnitude: 0.24239
Value Function Update Magnitude: 0.33403

Collected Steps per Second: 22,504.53871
Overall Steps per Second: 10,854.95454

Timestep Collection Time: 2.22222
Timestep Consumption Time: 2.38489
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.60711

Cumulative Model Updates: 366,226
Cumulative Timesteps: 3,054,365,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3054365704...
Checkpoint 3054365704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.35783
Policy Entropy: 3.93864
Value Function Loss: 0.00706

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.25354
Value Function Update Magnitude: 0.33098

Collected Steps per Second: 22,418.76772
Overall Steps per Second: 10,705.92830

Timestep Collection Time: 2.23081
Timestep Consumption Time: 2.44062
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.67143

Cumulative Model Updates: 366,232
Cumulative Timesteps: 3,054,415,716

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.77892
Policy Entropy: 3.94813
Value Function Loss: 0.00639

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.24548
Value Function Update Magnitude: 0.32443

Collected Steps per Second: 22,298.03272
Overall Steps per Second: 10,566.41992

Timestep Collection Time: 2.24361
Timestep Consumption Time: 2.49102
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.73462

Cumulative Model Updates: 366,238
Cumulative Timesteps: 3,054,465,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3054465744...
Checkpoint 3054465744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.47145
Policy Entropy: 3.96061
Value Function Loss: 0.00605

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02696
Policy Update Magnitude: 0.24578
Value Function Update Magnitude: 0.31003

Collected Steps per Second: 22,327.96308
Overall Steps per Second: 10,863.66766

Timestep Collection Time: 2.24051
Timestep Consumption Time: 2.36438
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.60489

Cumulative Model Updates: 366,244
Cumulative Timesteps: 3,054,515,770

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.89668
Policy Entropy: 3.96988
Value Function Loss: 0.00532

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.23680
Value Function Update Magnitude: 0.30120

Collected Steps per Second: 22,502.65162
Overall Steps per Second: 10,507.97129

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.53664
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.75886

Cumulative Model Updates: 366,250
Cumulative Timesteps: 3,054,565,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3054565776...
Checkpoint 3054565776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.46062
Policy Entropy: 3.97506
Value Function Loss: 0.00551

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02361
Policy Update Magnitude: 0.23466
Value Function Update Magnitude: 0.30544

Collected Steps per Second: 22,107.72348
Overall Steps per Second: 10,650.79487

Timestep Collection Time: 2.26256
Timestep Consumption Time: 2.43381
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.69636

Cumulative Model Updates: 366,256
Cumulative Timesteps: 3,054,615,796

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.57135
Policy Entropy: 4.00045
Value Function Loss: 0.00579

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02462
Policy Update Magnitude: 0.23760
Value Function Update Magnitude: 0.29906

Collected Steps per Second: 22,606.82384
Overall Steps per Second: 10,599.63767

Timestep Collection Time: 2.21278
Timestep Consumption Time: 2.50662
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.71941

Cumulative Model Updates: 366,262
Cumulative Timesteps: 3,054,665,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3054665820...
Checkpoint 3054665820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.03513
Policy Entropy: 4.01343
Value Function Loss: 0.00663

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.24024
Value Function Update Magnitude: 0.30184

Collected Steps per Second: 22,256.45951
Overall Steps per Second: 10,532.90740

Timestep Collection Time: 2.24843
Timestep Consumption Time: 2.50259
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.75101

Cumulative Model Updates: 366,268
Cumulative Timesteps: 3,054,715,862

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.78921
Policy Entropy: 3.99471
Value Function Loss: 0.00636

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02594
Policy Update Magnitude: 0.23386
Value Function Update Magnitude: 0.31519

Collected Steps per Second: 22,353.66217
Overall Steps per Second: 10,821.93042

Timestep Collection Time: 2.23695
Timestep Consumption Time: 2.38367
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.62062

Cumulative Model Updates: 366,274
Cumulative Timesteps: 3,054,765,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3054765866...
Checkpoint 3054765866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.98069
Policy Entropy: 3.97161
Value Function Loss: 0.00531

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02878
Policy Update Magnitude: 0.23482
Value Function Update Magnitude: 0.32398

Collected Steps per Second: 22,275.50792
Overall Steps per Second: 10,666.00765

Timestep Collection Time: 2.24596
Timestep Consumption Time: 2.44464
PPO Batch Consumption Time: 0.28124
Total Iteration Time: 4.69060

Cumulative Model Updates: 366,280
Cumulative Timesteps: 3,054,815,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.75361
Policy Entropy: 3.93658
Value Function Loss: 0.00622

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.03010
Policy Update Magnitude: 0.24560
Value Function Update Magnitude: 0.33340

Collected Steps per Second: 22,618.19358
Overall Steps per Second: 10,518.78493

Timestep Collection Time: 2.21176
Timestep Consumption Time: 2.54411
PPO Batch Consumption Time: 0.29467
Total Iteration Time: 4.75587

Cumulative Model Updates: 366,286
Cumulative Timesteps: 3,054,865,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3054865922...
Checkpoint 3054865922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.43176
Policy Entropy: 3.94535
Value Function Loss: 0.00628

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.03278
Policy Update Magnitude: 0.25187
Value Function Update Magnitude: 0.35619

Collected Steps per Second: 21,684.96466
Overall Steps per Second: 10,622.25975

Timestep Collection Time: 2.30713
Timestep Consumption Time: 2.40279
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.70992

Cumulative Model Updates: 366,292
Cumulative Timesteps: 3,054,915,952

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.46195
Policy Entropy: 3.98237
Value Function Loss: 0.00678

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02913
Policy Update Magnitude: 0.24868
Value Function Update Magnitude: 0.34600

Collected Steps per Second: 22,636.11931
Overall Steps per Second: 10,538.24450

Timestep Collection Time: 2.20921
Timestep Consumption Time: 2.53617
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.74538

Cumulative Model Updates: 366,298
Cumulative Timesteps: 3,054,965,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3054965960...
Checkpoint 3054965960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.13371
Policy Entropy: 3.98137
Value Function Loss: 0.00589

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02938
Policy Update Magnitude: 0.24626
Value Function Update Magnitude: 0.32560

Collected Steps per Second: 22,456.98102
Overall Steps per Second: 10,589.90886

Timestep Collection Time: 2.22746
Timestep Consumption Time: 2.49609
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.72355

Cumulative Model Updates: 366,304
Cumulative Timesteps: 3,055,015,982

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.32816
Policy Entropy: 3.95433
Value Function Loss: 0.00640

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.24552
Value Function Update Magnitude: 0.31665

Collected Steps per Second: 22,530.09152
Overall Steps per Second: 10,871.32782

Timestep Collection Time: 2.21952
Timestep Consumption Time: 2.38029
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.59981

Cumulative Model Updates: 366,310
Cumulative Timesteps: 3,055,065,988

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3055065988...
Checkpoint 3055065988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.18900
Policy Entropy: 3.93654
Value Function Loss: 0.00711

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.25021
Value Function Update Magnitude: 0.32892

Collected Steps per Second: 22,164.79044
Overall Steps per Second: 10,623.74680

Timestep Collection Time: 2.25682
Timestep Consumption Time: 2.45169
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.70851

Cumulative Model Updates: 366,316
Cumulative Timesteps: 3,055,116,010

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.98617
Policy Entropy: 3.93423
Value Function Loss: 0.00696

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 0.25226
Value Function Update Magnitude: 0.34083

Collected Steps per Second: 22,598.71490
Overall Steps per Second: 10,584.95871

Timestep Collection Time: 2.21384
Timestep Consumption Time: 2.51268
PPO Batch Consumption Time: 0.29256
Total Iteration Time: 4.72652

Cumulative Model Updates: 366,322
Cumulative Timesteps: 3,055,166,040

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3055166040...
Checkpoint 3055166040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.77776
Policy Entropy: 3.94762
Value Function Loss: 0.00715

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.25630
Value Function Update Magnitude: 0.33526

Collected Steps per Second: 22,245.91391
Overall Steps per Second: 10,666.36252

Timestep Collection Time: 2.24823
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.68895

Cumulative Model Updates: 366,328
Cumulative Timesteps: 3,055,216,054

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.31645
Policy Entropy: 3.93004
Value Function Loss: 0.00723

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 0.25577
Value Function Update Magnitude: 0.34317

Collected Steps per Second: 22,677.66225
Overall Steps per Second: 10,727.02544

Timestep Collection Time: 2.20481
Timestep Consumption Time: 2.45631
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.66112

Cumulative Model Updates: 366,334
Cumulative Timesteps: 3,055,266,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3055266054...
Checkpoint 3055266054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.00717
Policy Entropy: 3.94748
Value Function Loss: 0.00749

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.03198
Policy Update Magnitude: 0.26794
Value Function Update Magnitude: 0.36090

Collected Steps per Second: 22,124.53103
Overall Steps per Second: 10,641.19487

Timestep Collection Time: 2.26021
Timestep Consumption Time: 2.43908
PPO Batch Consumption Time: 0.28029
Total Iteration Time: 4.69928

Cumulative Model Updates: 366,340
Cumulative Timesteps: 3,055,316,060

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.22179
Policy Entropy: 3.91212
Value Function Loss: 0.00690

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 0.26471
Value Function Update Magnitude: 0.36058

Collected Steps per Second: 22,534.03029
Overall Steps per Second: 10,871.61112

Timestep Collection Time: 2.21922
Timestep Consumption Time: 2.38065
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.59987

Cumulative Model Updates: 366,346
Cumulative Timesteps: 3,055,366,068

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3055366068...
Checkpoint 3055366068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.40041
Policy Entropy: 3.91800
Value Function Loss: 0.00662

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.03092
Policy Update Magnitude: 0.25639
Value Function Update Magnitude: 0.34184

Collected Steps per Second: 21,874.53789
Overall Steps per Second: 10,391.22631

Timestep Collection Time: 2.28704
Timestep Consumption Time: 2.52740
PPO Batch Consumption Time: 0.29302
Total Iteration Time: 4.81445

Cumulative Model Updates: 366,352
Cumulative Timesteps: 3,055,416,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.14057
Policy Entropy: 3.89863
Value Function Loss: 0.00634

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 0.25729
Value Function Update Magnitude: 0.33841

Collected Steps per Second: 22,498.37288
Overall Steps per Second: 10,762.80892

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.42402
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.64711

Cumulative Model Updates: 366,358
Cumulative Timesteps: 3,055,466,112

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3055466112...
Checkpoint 3055466112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.86092
Policy Entropy: 3.92456
Value Function Loss: 0.00635

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.03219
Policy Update Magnitude: 0.25628
Value Function Update Magnitude: 0.34541

Collected Steps per Second: 22,146.98875
Overall Steps per Second: 10,728.89466

Timestep Collection Time: 2.25819
Timestep Consumption Time: 2.40325
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.66143

Cumulative Model Updates: 366,364
Cumulative Timesteps: 3,055,516,124

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.09826
Policy Entropy: 3.90464
Value Function Loss: 0.00590

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.03379
Policy Update Magnitude: 0.25295
Value Function Update Magnitude: 0.34179

Collected Steps per Second: 21,665.51948
Overall Steps per Second: 10,444.40614

Timestep Collection Time: 2.30781
Timestep Consumption Time: 2.47944
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.78725

Cumulative Model Updates: 366,370
Cumulative Timesteps: 3,055,566,124

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3055566124...
Checkpoint 3055566124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.43202
Policy Entropy: 3.86855
Value Function Loss: 0.00777

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.03814
Policy Update Magnitude: 0.26006
Value Function Update Magnitude: 0.34460

Collected Steps per Second: 22,031.25434
Overall Steps per Second: 10,667.30747

Timestep Collection Time: 2.27041
Timestep Consumption Time: 2.41868
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.68909

Cumulative Model Updates: 366,376
Cumulative Timesteps: 3,055,616,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.28892
Policy Entropy: 3.84766
Value Function Loss: 0.00808

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.03307
Policy Update Magnitude: 0.26763
Value Function Update Magnitude: 0.37345

Collected Steps per Second: 22,722.13751
Overall Steps per Second: 10,934.58102

Timestep Collection Time: 2.20182
Timestep Consumption Time: 2.37358
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.57539

Cumulative Model Updates: 366,382
Cumulative Timesteps: 3,055,666,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3055666174...
Checkpoint 3055666174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.57618
Policy Entropy: 3.88744
Value Function Loss: 0.00751

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.03554
Policy Update Magnitude: 0.25771
Value Function Update Magnitude: 0.39883

Collected Steps per Second: 22,265.38226
Overall Steps per Second: 10,620.98881

Timestep Collection Time: 2.24699
Timestep Consumption Time: 2.46350
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.71048

Cumulative Model Updates: 366,388
Cumulative Timesteps: 3,055,716,204

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.36834
Policy Entropy: 3.92666
Value Function Loss: 0.00656

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.24821
Value Function Update Magnitude: 0.37653

Collected Steps per Second: 22,572.54416
Overall Steps per Second: 10,652.31815

Timestep Collection Time: 2.21526
Timestep Consumption Time: 2.47893
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.69419

Cumulative Model Updates: 366,394
Cumulative Timesteps: 3,055,766,208

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3055766208...
Checkpoint 3055766208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.68345
Policy Entropy: 3.93422
Value Function Loss: 0.00601

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02700
Policy Update Magnitude: 0.24336
Value Function Update Magnitude: 0.35144

Collected Steps per Second: 22,298.84599
Overall Steps per Second: 10,817.83826

Timestep Collection Time: 2.24326
Timestep Consumption Time: 2.38077
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.62403

Cumulative Model Updates: 366,400
Cumulative Timesteps: 3,055,816,230

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.97472
Policy Entropy: 3.92945
Value Function Loss: 0.00597

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.23844
Value Function Update Magnitude: 0.33976

Collected Steps per Second: 22,460.01846
Overall Steps per Second: 10,545.09469

Timestep Collection Time: 2.22760
Timestep Consumption Time: 2.51697
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.74458

Cumulative Model Updates: 366,406
Cumulative Timesteps: 3,055,866,262

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3055866262...
Checkpoint 3055866262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.70251
Policy Entropy: 3.92583
Value Function Loss: 0.00631

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.24227
Value Function Update Magnitude: 0.32879

Collected Steps per Second: 22,061.88274
Overall Steps per Second: 10,702.27874

Timestep Collection Time: 2.26726
Timestep Consumption Time: 2.40651
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.67377

Cumulative Model Updates: 366,412
Cumulative Timesteps: 3,055,916,282

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.85367
Policy Entropy: 3.95305
Value Function Loss: 0.00653

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.25354
Value Function Update Magnitude: 0.33578

Collected Steps per Second: 22,177.66809
Overall Steps per Second: 10,779.05636

Timestep Collection Time: 2.25578
Timestep Consumption Time: 2.38544
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.64122

Cumulative Model Updates: 366,418
Cumulative Timesteps: 3,055,966,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3055966310...
Checkpoint 3055966310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.86973
Policy Entropy: 3.94813
Value Function Loss: 0.00685

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.03148
Policy Update Magnitude: 0.25579
Value Function Update Magnitude: 0.34570

Collected Steps per Second: 22,228.71301
Overall Steps per Second: 10,631.53034

Timestep Collection Time: 2.24934
Timestep Consumption Time: 2.45365
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.70299

Cumulative Model Updates: 366,424
Cumulative Timesteps: 3,056,016,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.38807
Policy Entropy: 4.00016
Value Function Loss: 0.00545

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.02743
Policy Update Magnitude: 0.23571
Value Function Update Magnitude: 0.33806

Collected Steps per Second: 22,656.60260
Overall Steps per Second: 10,633.05603

Timestep Collection Time: 2.20792
Timestep Consumption Time: 2.49665
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.70457

Cumulative Model Updates: 366,430
Cumulative Timesteps: 3,056,066,334

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3056066334...
Checkpoint 3056066334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.30876
Policy Entropy: 3.99343
Value Function Loss: 0.00623

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.02213
Policy Update Magnitude: 0.23477
Value Function Update Magnitude: 0.32465

Collected Steps per Second: 22,977.59209
Overall Steps per Second: 10,697.93786

Timestep Collection Time: 2.17612
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.67398

Cumulative Model Updates: 366,436
Cumulative Timesteps: 3,056,116,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.66141
Policy Entropy: 3.97788
Value Function Loss: 0.00647

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02475
Policy Update Magnitude: 0.24419
Value Function Update Magnitude: 0.31168

Collected Steps per Second: 22,713.21943
Overall Steps per Second: 10,609.79985

Timestep Collection Time: 2.20233
Timestep Consumption Time: 2.51237
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.71470

Cumulative Model Updates: 366,442
Cumulative Timesteps: 3,056,166,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3056166358...
Checkpoint 3056166358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.31398
Policy Entropy: 3.95078
Value Function Loss: 0.00727

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.03081
Policy Update Magnitude: 0.24670
Value Function Update Magnitude: 0.32716

Collected Steps per Second: 22,306.79617
Overall Steps per Second: 10,835.03760

Timestep Collection Time: 2.24246
Timestep Consumption Time: 2.37423
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.61669

Cumulative Model Updates: 366,448
Cumulative Timesteps: 3,056,216,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.92566
Policy Entropy: 3.95607
Value Function Loss: 0.00622

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.24620
Value Function Update Magnitude: 0.33448

Collected Steps per Second: 22,756.42211
Overall Steps per Second: 10,560.77995

Timestep Collection Time: 2.19894
Timestep Consumption Time: 2.53935
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.73829

Cumulative Model Updates: 366,454
Cumulative Timesteps: 3,056,266,420

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 3056266420...
Checkpoint 3056266420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.61758
Policy Entropy: 3.94106
Value Function Loss: 0.00617

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.24467
Value Function Update Magnitude: 0.32108

Collected Steps per Second: 22,125.08024
Overall Steps per Second: 10,631.98682

Timestep Collection Time: 2.26006
Timestep Consumption Time: 2.44311
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.70317

Cumulative Model Updates: 366,460
Cumulative Timesteps: 3,056,316,424

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43761
Policy Entropy: 3.93581
Value Function Loss: 0.00573

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02660
Policy Update Magnitude: 0.24156
Value Function Update Magnitude: 0.31194

Collected Steps per Second: 22,589.05339
Overall Steps per Second: 10,880.16692

Timestep Collection Time: 2.21461
Timestep Consumption Time: 2.38329
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.59791

Cumulative Model Updates: 366,466
Cumulative Timesteps: 3,056,366,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3056366450...
Checkpoint 3056366450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.54267
Policy Entropy: 3.91800
Value Function Loss: 0.00597

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.24392
Value Function Update Magnitude: 0.31641

Collected Steps per Second: 22,350.37933
Overall Steps per Second: 10,710.26245

Timestep Collection Time: 2.23764
Timestep Consumption Time: 2.43190
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.66954

Cumulative Model Updates: 366,472
Cumulative Timesteps: 3,056,416,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.26144
Policy Entropy: 3.96216
Value Function Loss: 0.00552

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.23569
Value Function Update Magnitude: 0.30805

Collected Steps per Second: 22,801.55633
Overall Steps per Second: 10,817.10013

Timestep Collection Time: 2.19301
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.62268

Cumulative Model Updates: 366,478
Cumulative Timesteps: 3,056,466,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3056466466...
Checkpoint 3056466466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.28574
Policy Entropy: 3.97595
Value Function Loss: 0.00600

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.22264
Value Function Update Magnitude: 0.29168

Collected Steps per Second: 22,058.06422
Overall Steps per Second: 10,723.50221

Timestep Collection Time: 2.26792
Timestep Consumption Time: 2.39716
PPO Batch Consumption Time: 0.28452
Total Iteration Time: 4.66508

Cumulative Model Updates: 366,484
Cumulative Timesteps: 3,056,516,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.18945
Policy Entropy: 4.03499
Value Function Loss: 0.00610

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.02066
Policy Update Magnitude: 0.22250
Value Function Update Magnitude: 0.30413

Collected Steps per Second: 22,551.29371
Overall Steps per Second: 10,511.67948

Timestep Collection Time: 2.21850
Timestep Consumption Time: 2.54097
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.75947

Cumulative Model Updates: 366,490
Cumulative Timesteps: 3,056,566,522

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3056566522...
Checkpoint 3056566522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.08000
Policy Entropy: 4.02391
Value Function Loss: 0.00580

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02234
Policy Update Magnitude: 0.22450
Value Function Update Magnitude: 0.32543

Collected Steps per Second: 22,235.60102
Overall Steps per Second: 10,555.39212

Timestep Collection Time: 2.25000
Timestep Consumption Time: 2.48976
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.73976

Cumulative Model Updates: 366,496
Cumulative Timesteps: 3,056,616,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.67919
Policy Entropy: 4.03503
Value Function Loss: 0.00555

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02723
Policy Update Magnitude: 0.23086
Value Function Update Magnitude: 0.33207

Collected Steps per Second: 23,324.26916
Overall Steps per Second: 10,886.43458

Timestep Collection Time: 2.14515
Timestep Consumption Time: 2.45085
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.59600

Cumulative Model Updates: 366,502
Cumulative Timesteps: 3,056,666,586

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3056666586...
Checkpoint 3056666586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.87925
Policy Entropy: 3.98233
Value Function Loss: 0.00595

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02838
Policy Update Magnitude: 0.23972
Value Function Update Magnitude: 0.33784

Collected Steps per Second: 21,830.59058
Overall Steps per Second: 10,403.76213

Timestep Collection Time: 2.29064
Timestep Consumption Time: 2.51589
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.80653

Cumulative Model Updates: 366,508
Cumulative Timesteps: 3,056,716,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.23951
Policy Entropy: 3.95726
Value Function Loss: 0.00622

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02801
Policy Update Magnitude: 0.24093
Value Function Update Magnitude: 0.33845

Collected Steps per Second: 22,482.87865
Overall Steps per Second: 10,716.10016

Timestep Collection Time: 2.22516
Timestep Consumption Time: 2.44333
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.66849

Cumulative Model Updates: 366,514
Cumulative Timesteps: 3,056,766,620

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3056766620...
Checkpoint 3056766620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.38757
Policy Entropy: 3.95162
Value Function Loss: 0.00618

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.25575
Value Function Update Magnitude: 0.33597

Collected Steps per Second: 22,878.11727
Overall Steps per Second: 10,682.59675

Timestep Collection Time: 2.18672
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.68313

Cumulative Model Updates: 366,520
Cumulative Timesteps: 3,056,816,648

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.04768
Policy Entropy: 3.94989
Value Function Loss: 0.00616

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02485
Policy Update Magnitude: 0.24991
Value Function Update Magnitude: 0.33399

Collected Steps per Second: 22,761.36874
Overall Steps per Second: 10,596.60280

Timestep Collection Time: 2.19767
Timestep Consumption Time: 2.52290
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.72057

Cumulative Model Updates: 366,526
Cumulative Timesteps: 3,056,866,670

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3056866670...
Checkpoint 3056866670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.25126
Policy Entropy: 3.97363
Value Function Loss: 0.00584

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02347
Policy Update Magnitude: 0.24465
Value Function Update Magnitude: 0.32356

Collected Steps per Second: 22,174.40365
Overall Steps per Second: 10,714.64158

Timestep Collection Time: 2.25593
Timestep Consumption Time: 2.41282
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.66875

Cumulative Model Updates: 366,532
Cumulative Timesteps: 3,056,916,694

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.21369
Policy Entropy: 3.97678
Value Function Loss: 0.00586

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02614
Policy Update Magnitude: 0.24007
Value Function Update Magnitude: 0.32055

Collected Steps per Second: 22,761.57548
Overall Steps per Second: 10,654.64036

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.69335

Cumulative Model Updates: 366,538
Cumulative Timesteps: 3,056,966,700

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3056966700...
Checkpoint 3056966700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.38377
Policy Entropy: 3.95618
Value Function Loss: 0.00627

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.23837
Value Function Update Magnitude: 0.32651

Collected Steps per Second: 22,298.84988
Overall Steps per Second: 10,724.27878

Timestep Collection Time: 2.24334
Timestep Consumption Time: 2.42121
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.66456

Cumulative Model Updates: 366,544
Cumulative Timesteps: 3,057,016,724

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.54342
Policy Entropy: 3.97586
Value Function Loss: 0.00642

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02284
Policy Update Magnitude: 0.24525
Value Function Update Magnitude: 0.31659

Collected Steps per Second: 22,701.79295
Overall Steps per Second: 10,934.36795

Timestep Collection Time: 2.20326
Timestep Consumption Time: 2.37112
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.57438

Cumulative Model Updates: 366,550
Cumulative Timesteps: 3,057,066,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3057066742...
Checkpoint 3057066742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.48243
Policy Entropy: 3.98841
Value Function Loss: 0.00601

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02512
Policy Update Magnitude: 0.24169
Value Function Update Magnitude: 0.31357

Collected Steps per Second: 22,395.44471
Overall Steps per Second: 10,589.83541

Timestep Collection Time: 2.23304
Timestep Consumption Time: 2.48941
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.72245

Cumulative Model Updates: 366,556
Cumulative Timesteps: 3,057,116,752

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.55229
Policy Entropy: 4.00993
Value Function Loss: 0.00561

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02333
Policy Update Magnitude: 0.22840
Value Function Update Magnitude: 0.30646

Collected Steps per Second: 22,397.63851
Overall Steps per Second: 10,606.71436

Timestep Collection Time: 2.23425
Timestep Consumption Time: 2.48370
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.71795

Cumulative Model Updates: 366,562
Cumulative Timesteps: 3,057,166,794

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 3057166794...
Checkpoint 3057166794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.55093
Policy Entropy: 3.99016
Value Function Loss: 0.00546

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.22599
Value Function Update Magnitude: 0.32720

Collected Steps per Second: 22,260.32540
Overall Steps per Second: 10,713.82291

Timestep Collection Time: 2.24741
Timestep Consumption Time: 2.42208
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.66948

Cumulative Model Updates: 366,568
Cumulative Timesteps: 3,057,216,822

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.77051
Policy Entropy: 3.94449
Value Function Loss: 0.00606

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.23155
Value Function Update Magnitude: 0.32603

Collected Steps per Second: 22,901.84002
Overall Steps per Second: 10,705.69943

Timestep Collection Time: 2.18445
Timestep Consumption Time: 2.48857
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.67302

Cumulative Model Updates: 366,574
Cumulative Timesteps: 3,057,266,850

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3057266850...
Checkpoint 3057266850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.58100
Policy Entropy: 3.94619
Value Function Loss: 0.00644

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02835
Policy Update Magnitude: 0.23902
Value Function Update Magnitude: 0.34840

Collected Steps per Second: 21,889.45723
Overall Steps per Second: 10,597.38449

Timestep Collection Time: 2.28521
Timestep Consumption Time: 2.43501
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.72022

Cumulative Model Updates: 366,580
Cumulative Timesteps: 3,057,316,872

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.76234
Policy Entropy: 3.93367
Value Function Loss: 0.00644

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.03300
Policy Update Magnitude: 0.24256
Value Function Update Magnitude: 0.35146

Collected Steps per Second: 22,127.42999
Overall Steps per Second: 10,652.44568

Timestep Collection Time: 2.25982
Timestep Consumption Time: 2.43431
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.69413

Cumulative Model Updates: 366,586
Cumulative Timesteps: 3,057,366,876

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3057366876...
Checkpoint 3057366876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.31235
Policy Entropy: 3.93370
Value Function Loss: 0.00628

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.03356
Policy Update Magnitude: 0.24944
Value Function Update Magnitude: 0.34398

Collected Steps per Second: 22,386.79201
Overall Steps per Second: 10,524.97590

Timestep Collection Time: 2.23346
Timestep Consumption Time: 2.51714
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.75060

Cumulative Model Updates: 366,592
Cumulative Timesteps: 3,057,416,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.91326
Policy Entropy: 3.95792
Value Function Loss: 0.00632

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.03002
Policy Update Magnitude: 0.25134
Value Function Update Magnitude: 0.34017

Collected Steps per Second: 21,747.87575
Overall Steps per Second: 10,409.74893

Timestep Collection Time: 2.30036
Timestep Consumption Time: 2.50552
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.80588

Cumulative Model Updates: 366,598
Cumulative Timesteps: 3,057,466,904

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3057466904...
Checkpoint 3057466904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.47720
Policy Entropy: 3.96553
Value Function Loss: 0.00623

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.02931
Policy Update Magnitude: 0.24645
Value Function Update Magnitude: 0.32873

Collected Steps per Second: 22,040.39040
Overall Steps per Second: 10,634.84327

Timestep Collection Time: 2.26865
Timestep Consumption Time: 2.43306
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.70171

Cumulative Model Updates: 366,604
Cumulative Timesteps: 3,057,516,906

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.52756
Policy Entropy: 3.96800
Value Function Loss: 0.00634

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02727
Policy Update Magnitude: 0.23859
Value Function Update Magnitude: 0.30983

Collected Steps per Second: 22,528.63598
Overall Steps per Second: 10,553.55246

Timestep Collection Time: 2.21966
Timestep Consumption Time: 2.51865
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.73831

Cumulative Model Updates: 366,610
Cumulative Timesteps: 3,057,566,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3057566912...
Checkpoint 3057566912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.84071
Policy Entropy: 3.95426
Value Function Loss: 0.00633

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.24623
Value Function Update Magnitude: 0.29993

Collected Steps per Second: 21,867.26542
Overall Steps per Second: 10,586.03823

Timestep Collection Time: 2.28689
Timestep Consumption Time: 2.43707
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.72396

Cumulative Model Updates: 366,616
Cumulative Timesteps: 3,057,616,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.77254
Policy Entropy: 3.91916
Value Function Loss: 0.00639

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02952
Policy Update Magnitude: 0.24686
Value Function Update Magnitude: 0.31683

Collected Steps per Second: 22,740.27082
Overall Steps per Second: 10,862.45547

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.40561
PPO Batch Consumption Time: 0.28501
Total Iteration Time: 4.60559

Cumulative Model Updates: 366,622
Cumulative Timesteps: 3,057,666,948

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3057666948...
Checkpoint 3057666948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.63316
Policy Entropy: 3.94507
Value Function Loss: 0.00691

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02839
Policy Update Magnitude: 0.25533
Value Function Update Magnitude: 0.33445

Collected Steps per Second: 22,300.73384
Overall Steps per Second: 10,686.54618

Timestep Collection Time: 2.24307
Timestep Consumption Time: 2.43777
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.68084

Cumulative Model Updates: 366,628
Cumulative Timesteps: 3,057,716,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.26457
Policy Entropy: 3.93445
Value Function Loss: 0.00727

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02907
Policy Update Magnitude: 0.25964
Value Function Update Magnitude: 0.34037

Collected Steps per Second: 22,790.67395
Overall Steps per Second: 10,763.05209

Timestep Collection Time: 2.19414
Timestep Consumption Time: 2.45194
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.64608

Cumulative Model Updates: 366,634
Cumulative Timesteps: 3,057,766,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3057766976...
Checkpoint 3057766976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.88471
Policy Entropy: 3.98826
Value Function Loss: 0.00712

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.02990
Policy Update Magnitude: 0.25059
Value Function Update Magnitude: 0.33061

Collected Steps per Second: 23,014.25551
Overall Steps per Second: 10,728.39905

Timestep Collection Time: 2.17335
Timestep Consumption Time: 2.48886
PPO Batch Consumption Time: 0.28596
Total Iteration Time: 4.66221

Cumulative Model Updates: 366,640
Cumulative Timesteps: 3,057,816,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.24251
Policy Entropy: 4.00309
Value Function Loss: 0.00545

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.23155
Value Function Update Magnitude: 0.32426

Collected Steps per Second: 22,689.07956
Overall Steps per Second: 10,576.56911

Timestep Collection Time: 2.20476
Timestep Consumption Time: 2.52494
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.72970

Cumulative Model Updates: 366,646
Cumulative Timesteps: 3,057,867,018

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3057867018...
Checkpoint 3057867018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.42832
Policy Entropy: 4.01585
Value Function Loss: 0.00508

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.22602
Value Function Update Magnitude: 0.31269

Collected Steps per Second: 22,348.58574
Overall Steps per Second: 10,545.67967

Timestep Collection Time: 2.23764
Timestep Consumption Time: 2.50440
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.74204

Cumulative Model Updates: 366,652
Cumulative Timesteps: 3,057,917,026

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.93634
Policy Entropy: 4.02525
Value Function Loss: 0.00501

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02574
Policy Update Magnitude: 0.23441
Value Function Update Magnitude: 0.30702

Collected Steps per Second: 23,121.45034
Overall Steps per Second: 10,807.71941

Timestep Collection Time: 2.16345
Timestep Consumption Time: 2.46491
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.62836

Cumulative Model Updates: 366,658
Cumulative Timesteps: 3,057,967,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3057967048...
Checkpoint 3057967048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.35433
Policy Entropy: 3.98572
Value Function Loss: 0.00717

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.23778
Value Function Update Magnitude: 0.32089

Collected Steps per Second: 22,112.14099
Overall Steps per Second: 10,480.34041

Timestep Collection Time: 2.26174
Timestep Consumption Time: 2.51024
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.77198

Cumulative Model Updates: 366,664
Cumulative Timesteps: 3,058,017,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.73458
Policy Entropy: 3.99509
Value Function Loss: 0.00718

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02538
Policy Update Magnitude: 0.23829
Value Function Update Magnitude: 0.34236

Collected Steps per Second: 22,528.54918
Overall Steps per Second: 10,722.27571

Timestep Collection Time: 2.21949
Timestep Consumption Time: 2.44388
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 4.66338

Cumulative Model Updates: 366,670
Cumulative Timesteps: 3,058,067,062

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3058067062...
Checkpoint 3058067062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.65077
Policy Entropy: 3.97977
Value Function Loss: 0.00750

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.03050
Policy Update Magnitude: 0.23990
Value Function Update Magnitude: 0.34417

Collected Steps per Second: 22,261.77162
Overall Steps per Second: 10,691.84128

Timestep Collection Time: 2.24771
Timestep Consumption Time: 2.43231
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.68002

Cumulative Model Updates: 366,676
Cumulative Timesteps: 3,058,117,100

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.70017
Policy Entropy: 3.93971
Value Function Loss: 0.00815

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.24845
Value Function Update Magnitude: 0.34302

Collected Steps per Second: 22,443.31797
Overall Steps per Second: 10,606.17697

Timestep Collection Time: 2.22926
Timestep Consumption Time: 2.48799
PPO Batch Consumption Time: 0.28934
Total Iteration Time: 4.71725

Cumulative Model Updates: 366,682
Cumulative Timesteps: 3,058,167,132

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3058167132...
Checkpoint 3058167132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.39714
Policy Entropy: 3.92886
Value Function Loss: 0.00748

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.03151
Policy Update Magnitude: 0.25232
Value Function Update Magnitude: 0.35611

Collected Steps per Second: 22,467.76207
Overall Steps per Second: 10,870.97508

Timestep Collection Time: 2.22550
Timestep Consumption Time: 2.37409
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.59959

Cumulative Model Updates: 366,688
Cumulative Timesteps: 3,058,217,134

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.54087
Policy Entropy: 3.91565
Value Function Loss: 0.00658

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.03470
Policy Update Magnitude: 0.25313
Value Function Update Magnitude: 0.36763

Collected Steps per Second: 22,348.26599
Overall Steps per Second: 10,490.56259

Timestep Collection Time: 2.23785
Timestep Consumption Time: 2.52949
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.76733

Cumulative Model Updates: 366,694
Cumulative Timesteps: 3,058,267,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3058267146...
Checkpoint 3058267146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.34050
Policy Entropy: 3.98287
Value Function Loss: 0.00508

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.24158
Value Function Update Magnitude: 0.34136

Collected Steps per Second: 22,251.42428
Overall Steps per Second: 10,647.03453

Timestep Collection Time: 2.24840
Timestep Consumption Time: 2.45057
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.69896

Cumulative Model Updates: 366,700
Cumulative Timesteps: 3,058,317,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.71694
Policy Entropy: 3.96895
Value Function Loss: 0.00625

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.03059
Policy Update Magnitude: 0.22671
Value Function Update Magnitude: 0.30905

Collected Steps per Second: 22,414.88162
Overall Steps per Second: 10,834.00448

Timestep Collection Time: 2.23066
Timestep Consumption Time: 2.38444
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.61510

Cumulative Model Updates: 366,706
Cumulative Timesteps: 3,058,367,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3058367176...
Checkpoint 3058367176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.99268
Policy Entropy: 3.99250
Value Function Loss: 0.00590

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.22814
Value Function Update Magnitude: 0.30326

Collected Steps per Second: 22,029.64955
Overall Steps per Second: 10,593.71983

Timestep Collection Time: 2.27121
Timestep Consumption Time: 2.45178
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.72299

Cumulative Model Updates: 366,712
Cumulative Timesteps: 3,058,417,210

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.99719
Policy Entropy: 4.00625
Value Function Loss: 0.00628

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.23724
Value Function Update Magnitude: 0.30313

Collected Steps per Second: 22,646.11633
Overall Steps per Second: 10,621.72223

Timestep Collection Time: 2.20850
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.29353
Total Iteration Time: 4.70865

Cumulative Model Updates: 366,718
Cumulative Timesteps: 3,058,467,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3058467224...
Checkpoint 3058467224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.11919
Policy Entropy: 4.04565
Value Function Loss: 0.00548

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02280
Policy Update Magnitude: 0.23002
Value Function Update Magnitude: 0.30236

Collected Steps per Second: 22,236.68438
Overall Steps per Second: 10,675.77265

Timestep Collection Time: 2.24863
Timestep Consumption Time: 2.43506
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.68369

Cumulative Model Updates: 366,724
Cumulative Timesteps: 3,058,517,226

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.44369
Policy Entropy: 4.01970
Value Function Loss: 0.00586

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02237
Policy Update Magnitude: 0.22662
Value Function Update Magnitude: 0.31000

Collected Steps per Second: 22,792.66221
Overall Steps per Second: 10,582.71288

Timestep Collection Time: 2.19395
Timestep Consumption Time: 2.53130
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.72525

Cumulative Model Updates: 366,730
Cumulative Timesteps: 3,058,567,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3058567232...
Checkpoint 3058567232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.69823
Policy Entropy: 3.94019
Value Function Loss: 0.00590

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02188
Policy Update Magnitude: 0.23683
Value Function Update Magnitude: 0.30934

Collected Steps per Second: 21,979.23692
Overall Steps per Second: 10,478.43818

Timestep Collection Time: 2.27569
Timestep Consumption Time: 2.49773
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.77342

Cumulative Model Updates: 366,736
Cumulative Timesteps: 3,058,617,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.90242
Policy Entropy: 3.91394
Value Function Loss: 0.00684

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.25759
Value Function Update Magnitude: 0.33024

Collected Steps per Second: 22,327.01686
Overall Steps per Second: 10,836.92513

Timestep Collection Time: 2.23962
Timestep Consumption Time: 2.37461
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.61422

Cumulative Model Updates: 366,742
Cumulative Timesteps: 3,058,667,254

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3058667254...
Checkpoint 3058667254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.46762
Policy Entropy: 3.93846
Value Function Loss: 0.00613

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02491
Policy Update Magnitude: 0.26124
Value Function Update Magnitude: 0.35385

Collected Steps per Second: 22,358.38386
Overall Steps per Second: 10,689.31116

Timestep Collection Time: 2.23666
Timestep Consumption Time: 2.44166
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.67832

Cumulative Model Updates: 366,748
Cumulative Timesteps: 3,058,717,262

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.59034
Policy Entropy: 4.01278
Value Function Loss: 0.00508

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02141
Policy Update Magnitude: 0.23729
Value Function Update Magnitude: 0.34125

Collected Steps per Second: 22,303.95850
Overall Steps per Second: 10,553.76693

Timestep Collection Time: 2.24184
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.73783

Cumulative Model Updates: 366,754
Cumulative Timesteps: 3,058,767,264

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3058767264...
Checkpoint 3058767264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.55853
Policy Entropy: 4.02137
Value Function Loss: 0.00466

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02275
Policy Update Magnitude: 0.22011
Value Function Update Magnitude: 0.30116

Collected Steps per Second: 22,376.94948
Overall Steps per Second: 10,870.04207

Timestep Collection Time: 2.23560
Timestep Consumption Time: 2.36659
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.60219

Cumulative Model Updates: 366,760
Cumulative Timesteps: 3,058,817,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.86014
Policy Entropy: 4.01353
Value Function Loss: 0.00541

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.22051
Value Function Update Magnitude: 0.29028

Collected Steps per Second: 22,384.63648
Overall Steps per Second: 10,565.13390

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.49957
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.73387

Cumulative Model Updates: 366,766
Cumulative Timesteps: 3,058,867,304

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3058867304...
Checkpoint 3058867304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.51023
Policy Entropy: 4.01604
Value Function Loss: 0.00489

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02170
Policy Update Magnitude: 0.21698
Value Function Update Magnitude: 0.31748

Collected Steps per Second: 22,070.35341
Overall Steps per Second: 10,681.34524

Timestep Collection Time: 2.26630
Timestep Consumption Time: 2.41645
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.68274

Cumulative Model Updates: 366,772
Cumulative Timesteps: 3,058,917,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.75695
Policy Entropy: 3.99074
Value Function Loss: 0.00487

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02314
Policy Update Magnitude: 0.21613
Value Function Update Magnitude: 0.31892

Collected Steps per Second: 23,444.35052
Overall Steps per Second: 10,811.28083

Timestep Collection Time: 2.13407
Timestep Consumption Time: 2.49368
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.62776

Cumulative Model Updates: 366,778
Cumulative Timesteps: 3,058,967,354

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3058967354...
Checkpoint 3058967354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50345
Policy Entropy: 3.97578
Value Function Loss: 0.00530

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02131
Policy Update Magnitude: 0.23078
Value Function Update Magnitude: 0.30110

Collected Steps per Second: 22,282.76863
Overall Steps per Second: 10,658.75342

Timestep Collection Time: 2.24416
Timestep Consumption Time: 2.44739
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.69154

Cumulative Model Updates: 366,784
Cumulative Timesteps: 3,059,017,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.39265
Policy Entropy: 3.94719
Value Function Loss: 0.00716

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02675
Policy Update Magnitude: 0.25314
Value Function Update Magnitude: 0.31465

Collected Steps per Second: 22,169.55846
Overall Steps per Second: 10,511.66238

Timestep Collection Time: 2.25553
Timestep Consumption Time: 2.50148
PPO Batch Consumption Time: 0.29337
Total Iteration Time: 4.75700

Cumulative Model Updates: 366,790
Cumulative Timesteps: 3,059,067,364

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3059067364...
Checkpoint 3059067364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.26586
Policy Entropy: 3.99342
Value Function Loss: 0.00719

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 0.26031
Value Function Update Magnitude: 0.34075

Collected Steps per Second: 22,960.52516
Overall Steps per Second: 10,619.65879

Timestep Collection Time: 2.17852
Timestep Consumption Time: 2.53161
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.71013

Cumulative Model Updates: 366,796
Cumulative Timesteps: 3,059,117,384

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3.84079
Policy Entropy: 4.00069
Value Function Loss: 0.00723

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.03055
Policy Update Magnitude: 0.24436
Value Function Update Magnitude: 0.35733

Collected Steps per Second: 22,912.92780
Overall Steps per Second: 10,650.75119

Timestep Collection Time: 2.18287
Timestep Consumption Time: 2.51313
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.69601

Cumulative Model Updates: 366,802
Cumulative Timesteps: 3,059,167,400

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3059167400...
Checkpoint 3059167400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.08078
Policy Entropy: 4.00426
Value Function Loss: 0.00643

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02786
Policy Update Magnitude: 0.24118
Value Function Update Magnitude: 0.34147

Collected Steps per Second: 22,340.09078
Overall Steps per Second: 10,830.02869

Timestep Collection Time: 2.23858
Timestep Consumption Time: 2.37914
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.61772

Cumulative Model Updates: 366,808
Cumulative Timesteps: 3,059,217,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.40836
Policy Entropy: 4.02168
Value Function Loss: 0.00531

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02443
Policy Update Magnitude: 0.23678
Value Function Update Magnitude: 0.33004

Collected Steps per Second: 22,515.46390
Overall Steps per Second: 10,520.85115

Timestep Collection Time: 2.22078
Timestep Consumption Time: 2.53187
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.75266

Cumulative Model Updates: 366,814
Cumulative Timesteps: 3,059,267,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3059267412...
Checkpoint 3059267412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.86373
Policy Entropy: 4.04224
Value Function Loss: 0.00548

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.22220
Value Function Update Magnitude: 0.31083

Collected Steps per Second: 22,276.92769
Overall Steps per Second: 10,653.76476

Timestep Collection Time: 2.24564
Timestep Consumption Time: 2.44998
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.69562

Cumulative Model Updates: 366,820
Cumulative Timesteps: 3,059,317,438

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.70258
Policy Entropy: 4.06470
Value Function Loss: 0.00529

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.02182
Policy Update Magnitude: 0.21785
Value Function Update Magnitude: 0.29727

Collected Steps per Second: 23,654.39560
Overall Steps per Second: 10,950.52486

Timestep Collection Time: 2.11487
Timestep Consumption Time: 2.45349
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.56837

Cumulative Model Updates: 366,826
Cumulative Timesteps: 3,059,367,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3059367464...
Checkpoint 3059367464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.30955
Policy Entropy: 4.02059
Value Function Loss: 0.00580

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02270
Policy Update Magnitude: 0.22469
Value Function Update Magnitude: 0.30290

Collected Steps per Second: 22,404.36821
Overall Steps per Second: 10,595.28711

Timestep Collection Time: 2.23242
Timestep Consumption Time: 2.48817
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.72059

Cumulative Model Updates: 366,832
Cumulative Timesteps: 3,059,417,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.46924
Policy Entropy: 4.00603
Value Function Loss: 0.00557

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.23229
Value Function Update Magnitude: 0.31404

Collected Steps per Second: 22,360.29631
Overall Steps per Second: 10,563.90597

Timestep Collection Time: 2.23727
Timestep Consumption Time: 2.49829
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.73556

Cumulative Model Updates: 366,838
Cumulative Timesteps: 3,059,467,506

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3059467506...
Checkpoint 3059467506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.82406
Policy Entropy: 3.98774
Value Function Loss: 0.00614

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02405
Policy Update Magnitude: 0.22964
Value Function Update Magnitude: 0.31861

Collected Steps per Second: 23,198.80786
Overall Steps per Second: 10,781.03053

Timestep Collection Time: 2.15632
Timestep Consumption Time: 2.48368
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.64000

Cumulative Model Updates: 366,844
Cumulative Timesteps: 3,059,517,530

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.16069
Policy Entropy: 3.97907
Value Function Loss: 0.00720

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.23810
Value Function Update Magnitude: 0.32940

Collected Steps per Second: 22,521.22512
Overall Steps per Second: 10,709.29367

Timestep Collection Time: 2.22031
Timestep Consumption Time: 2.44891
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.66922

Cumulative Model Updates: 366,850
Cumulative Timesteps: 3,059,567,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3059567534...
Checkpoint 3059567534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.12175
Policy Entropy: 3.99465
Value Function Loss: 0.00688

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02506
Policy Update Magnitude: 0.24233
Value Function Update Magnitude: 0.34108

Collected Steps per Second: 22,461.45298
Overall Steps per Second: 10,742.22190

Timestep Collection Time: 2.22675
Timestep Consumption Time: 2.42927
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.65602

Cumulative Model Updates: 366,856
Cumulative Timesteps: 3,059,617,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.38522
Policy Entropy: 3.99803
Value Function Loss: 0.00618

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.02507
Policy Update Magnitude: 0.23998
Value Function Update Magnitude: 0.34194

Collected Steps per Second: 22,749.01420
Overall Steps per Second: 10,740.60081

Timestep Collection Time: 2.19825
Timestep Consumption Time: 2.45773
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.65598

Cumulative Model Updates: 366,862
Cumulative Timesteps: 3,059,667,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3059667558...
Checkpoint 3059667558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.93987
Policy Entropy: 4.01188
Value Function Loss: 0.00516

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02323
Policy Update Magnitude: 0.23197
Value Function Update Magnitude: 0.32393

Collected Steps per Second: 22,076.81958
Overall Steps per Second: 10,673.05312

Timestep Collection Time: 2.26582
Timestep Consumption Time: 2.42094
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.68676

Cumulative Model Updates: 366,868
Cumulative Timesteps: 3,059,717,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.56039
Policy Entropy: 3.97994
Value Function Loss: 0.00601

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02220
Policy Update Magnitude: 0.23929
Value Function Update Magnitude: 0.31728

Collected Steps per Second: 22,462.85174
Overall Steps per Second: 10,841.08404

Timestep Collection Time: 2.22750
Timestep Consumption Time: 2.38791
PPO Batch Consumption Time: 0.28142
Total Iteration Time: 4.61541

Cumulative Model Updates: 366,874
Cumulative Timesteps: 3,059,767,616

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 3059767616...
Checkpoint 3059767616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.98681
Policy Entropy: 3.99496
Value Function Loss: 0.00552

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02362
Policy Update Magnitude: 0.23645
Value Function Update Magnitude: 0.32287

Collected Steps per Second: 22,337.60684
Overall Steps per Second: 10,632.20936

Timestep Collection Time: 2.23900
Timestep Consumption Time: 2.46500
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.70401

Cumulative Model Updates: 366,880
Cumulative Timesteps: 3,059,817,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.43256
Policy Entropy: 4.00306
Value Function Loss: 0.00577

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02314
Policy Update Magnitude: 0.23646
Value Function Update Magnitude: 0.32008

Collected Steps per Second: 22,437.51073
Overall Steps per Second: 10,515.51201

Timestep Collection Time: 2.22868
Timestep Consumption Time: 2.52677
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.75545

Cumulative Model Updates: 366,886
Cumulative Timesteps: 3,059,867,636

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3059867636...
Checkpoint 3059867636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.12142
Policy Entropy: 4.02133
Value Function Loss: 0.00571

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.23803
Value Function Update Magnitude: 0.32261

Collected Steps per Second: 22,963.94814
Overall Steps per Second: 10,664.89359

Timestep Collection Time: 2.17785
Timestep Consumption Time: 2.51156
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.68940

Cumulative Model Updates: 366,892
Cumulative Timesteps: 3,059,917,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.78200
Policy Entropy: 3.99127
Value Function Loss: 0.00675

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.24453
Value Function Update Magnitude: 0.33518

Collected Steps per Second: 22,402.91190
Overall Steps per Second: 10,478.16339

Timestep Collection Time: 2.23194
Timestep Consumption Time: 2.54008
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.77202

Cumulative Model Updates: 366,898
Cumulative Timesteps: 3,059,967,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3059967650...
Checkpoint 3059967650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.41298
Policy Entropy: 3.97125
Value Function Loss: 0.00640

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.25079
Value Function Update Magnitude: 0.33789

Collected Steps per Second: 22,208.68508
Overall Steps per Second: 10,657.20579

Timestep Collection Time: 2.25191
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.69279

Cumulative Model Updates: 366,904
Cumulative Timesteps: 3,060,017,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.64321
Policy Entropy: 3.96646
Value Function Loss: 0.00662

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.25668
Value Function Update Magnitude: 0.33650

Collected Steps per Second: 22,647.76082
Overall Steps per Second: 10,600.76804

Timestep Collection Time: 2.20896
Timestep Consumption Time: 2.51032
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.71928

Cumulative Model Updates: 366,910
Cumulative Timesteps: 3,060,067,690

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3060067690...
Checkpoint 3060067690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.60109
Policy Entropy: 3.98042
Value Function Loss: 0.00628

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03065
Policy Update Magnitude: 0.25200
Value Function Update Magnitude: 0.33050

Collected Steps per Second: 22,529.94166
Overall Steps per Second: 10,552.11788

Timestep Collection Time: 2.22033
Timestep Consumption Time: 2.52033
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.74066

Cumulative Model Updates: 366,916
Cumulative Timesteps: 3,060,117,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.48845
Policy Entropy: 3.97119
Value Function Loss: 0.00624

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.23963
Value Function Update Magnitude: 0.32981

Collected Steps per Second: 22,562.69132
Overall Steps per Second: 10,822.77993

Timestep Collection Time: 2.21649
Timestep Consumption Time: 2.40432
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.62081

Cumulative Model Updates: 366,922
Cumulative Timesteps: 3,060,167,724

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3060167724...
Checkpoint 3060167724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.31500
Policy Entropy: 3.97490
Value Function Loss: 0.00598

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.24459
Value Function Update Magnitude: 0.31629

Collected Steps per Second: 22,423.55931
Overall Steps per Second: 10,630.18253

Timestep Collection Time: 2.23042
Timestep Consumption Time: 2.47448
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.70491

Cumulative Model Updates: 366,928
Cumulative Timesteps: 3,060,217,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.81416
Policy Entropy: 3.97514
Value Function Loss: 0.00602

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.24307
Value Function Update Magnitude: 0.32473

Collected Steps per Second: 22,431.07457
Overall Steps per Second: 10,554.15519

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.50892
PPO Batch Consumption Time: 0.29393
Total Iteration Time: 4.73842

Cumulative Model Updates: 366,934
Cumulative Timesteps: 3,060,267,748

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3060267748...
Checkpoint 3060267748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.72417
Policy Entropy: 3.97906
Value Function Loss: 0.00619

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.23445
Value Function Update Magnitude: 0.31007

Collected Steps per Second: 21,995.52461
Overall Steps per Second: 10,638.96315

Timestep Collection Time: 2.27319
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.69971

Cumulative Model Updates: 366,940
Cumulative Timesteps: 3,060,317,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.67590
Policy Entropy: 3.96503
Value Function Loss: 0.00612

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.23549
Value Function Update Magnitude: 0.30563

Collected Steps per Second: 22,596.17953
Overall Steps per Second: 10,695.46680

Timestep Collection Time: 2.21409
Timestep Consumption Time: 2.46359
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.67768

Cumulative Model Updates: 366,946
Cumulative Timesteps: 3,060,367,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3060367778...
Checkpoint 3060367778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.68647
Policy Entropy: 3.97446
Value Function Loss: 0.00647

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.24094
Value Function Update Magnitude: 0.30547

Collected Steps per Second: 22,321.85996
Overall Steps per Second: 10,729.53961

Timestep Collection Time: 2.24049
Timestep Consumption Time: 2.42066
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.66115

Cumulative Model Updates: 366,952
Cumulative Timesteps: 3,060,417,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.48237
Policy Entropy: 3.98745
Value Function Loss: 0.00644

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.24016
Value Function Update Magnitude: 0.31025

Collected Steps per Second: 23,409.48569
Overall Steps per Second: 10,887.51604

Timestep Collection Time: 2.13683
Timestep Consumption Time: 2.45761
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.59444

Cumulative Model Updates: 366,958
Cumulative Timesteps: 3,060,467,812

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3060467812...
Checkpoint 3060467812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.35006
Policy Entropy: 3.96712
Value Function Loss: 0.00699

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.24068
Value Function Update Magnitude: 0.30501

Collected Steps per Second: 22,449.50455
Overall Steps per Second: 10,683.99373

Timestep Collection Time: 2.22758
Timestep Consumption Time: 2.45307
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.68065

Cumulative Model Updates: 366,964
Cumulative Timesteps: 3,060,517,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.33611
Policy Entropy: 3.96394
Value Function Loss: 0.00674

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.24483
Value Function Update Magnitude: 0.30416

Collected Steps per Second: 22,475.78116
Overall Steps per Second: 10,854.56504

Timestep Collection Time: 2.22568
Timestep Consumption Time: 2.38288
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.60857

Cumulative Model Updates: 366,970
Cumulative Timesteps: 3,060,567,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3060567844...
Checkpoint 3060567844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.95868
Policy Entropy: 3.98896
Value Function Loss: 0.00675

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.03020
Policy Update Magnitude: 0.23813
Value Function Update Magnitude: 0.31124

Collected Steps per Second: 22,522.68376
Overall Steps per Second: 10,697.57757

Timestep Collection Time: 2.22096
Timestep Consumption Time: 2.45505
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.67601

Cumulative Model Updates: 366,976
Cumulative Timesteps: 3,060,617,866

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.35103
Policy Entropy: 4.01843
Value Function Loss: 0.00625

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02371
Policy Update Magnitude: 0.23929
Value Function Update Magnitude: 0.32724

Collected Steps per Second: 22,219.94214
Overall Steps per Second: 10,495.21158

Timestep Collection Time: 2.25041
Timestep Consumption Time: 2.51405
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.76446

Cumulative Model Updates: 366,982
Cumulative Timesteps: 3,060,667,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3060667870...
Checkpoint 3060667870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.58432
Policy Entropy: 4.02031
Value Function Loss: 0.00590

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.23215
Value Function Update Magnitude: 0.33819

Collected Steps per Second: 22,261.56646
Overall Steps per Second: 10,683.45849

Timestep Collection Time: 2.24638
Timestep Consumption Time: 2.43450
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.68088

Cumulative Model Updates: 366,988
Cumulative Timesteps: 3,060,717,878

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.00669
Policy Entropy: 3.97665
Value Function Loss: 0.00562

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02391
Policy Update Magnitude: 0.24026
Value Function Update Magnitude: 0.35347

Collected Steps per Second: 22,419.79345
Overall Steps per Second: 10,516.98187

Timestep Collection Time: 2.23151
Timestep Consumption Time: 2.52556
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.75707

Cumulative Model Updates: 366,994
Cumulative Timesteps: 3,060,767,908

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3060767908...
Checkpoint 3060767908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.43365
Policy Entropy: 3.96770
Value Function Loss: 0.00626

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.24479
Value Function Update Magnitude: 0.34086

Collected Steps per Second: 22,444.59135
Overall Steps per Second: 10,529.22455

Timestep Collection Time: 2.22887
Timestep Consumption Time: 2.52229
PPO Batch Consumption Time: 0.29583
Total Iteration Time: 4.75116

Cumulative Model Updates: 367,000
Cumulative Timesteps: 3,060,817,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.64941
Policy Entropy: 3.93971
Value Function Loss: 0.00708

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.24592
Value Function Update Magnitude: 0.34504

Collected Steps per Second: 22,536.67661
Overall Steps per Second: 10,879.07634

Timestep Collection Time: 2.21994
Timestep Consumption Time: 2.37880
PPO Batch Consumption Time: 0.27989
Total Iteration Time: 4.59874

Cumulative Model Updates: 367,006
Cumulative Timesteps: 3,060,867,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3060867964...
Checkpoint 3060867964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.72033
Policy Entropy: 3.93920
Value Function Loss: 0.00759

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02515
Policy Update Magnitude: 0.25062
Value Function Update Magnitude: 0.34470

Collected Steps per Second: 22,391.20783
Overall Steps per Second: 10,674.19050

Timestep Collection Time: 2.23373
Timestep Consumption Time: 2.45196
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.68569

Cumulative Model Updates: 367,012
Cumulative Timesteps: 3,060,917,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.53878
Policy Entropy: 3.94607
Value Function Loss: 0.00683

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.25417
Value Function Update Magnitude: 0.33594

Collected Steps per Second: 22,694.72863
Overall Steps per Second: 10,609.43825

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.51083
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.71505

Cumulative Model Updates: 367,018
Cumulative Timesteps: 3,060,968,004

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3060968004...
Checkpoint 3060968004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.84687
Policy Entropy: 3.98562
Value Function Loss: 0.00616

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.24813
Value Function Update Magnitude: 0.32380

Collected Steps per Second: 23,315.77138
Overall Steps per Second: 10,846.19983

Timestep Collection Time: 2.14524
Timestep Consumption Time: 2.46633
PPO Batch Consumption Time: 0.28001
Total Iteration Time: 4.61157

Cumulative Model Updates: 367,024
Cumulative Timesteps: 3,061,018,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.35781
Policy Entropy: 3.95285
Value Function Loss: 0.00634

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02526
Policy Update Magnitude: 0.23700
Value Function Update Magnitude: 0.31009

Collected Steps per Second: 22,436.00971
Overall Steps per Second: 10,593.48956

Timestep Collection Time: 2.22945
Timestep Consumption Time: 2.49232
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.72177

Cumulative Model Updates: 367,030
Cumulative Timesteps: 3,061,068,042

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3061068042...
Checkpoint 3061068042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.37065
Policy Entropy: 3.96465
Value Function Loss: 0.00558

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.24049
Value Function Update Magnitude: 0.30201

Collected Steps per Second: 22,240.61357
Overall Steps per Second: 10,620.38908

Timestep Collection Time: 2.24949
Timestep Consumption Time: 2.46126
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.71075

Cumulative Model Updates: 367,036
Cumulative Timesteps: 3,061,118,072

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.33098
Policy Entropy: 3.97794
Value Function Loss: 0.00541

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.23875
Value Function Update Magnitude: 0.30859

Collected Steps per Second: 23,564.62341
Overall Steps per Second: 10,879.79080

Timestep Collection Time: 2.12182
Timestep Consumption Time: 2.47385
PPO Batch Consumption Time: 0.28088
Total Iteration Time: 4.59568

Cumulative Model Updates: 367,042
Cumulative Timesteps: 3,061,168,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3061168072...
Checkpoint 3061168072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.94118
Policy Entropy: 4.03839
Value Function Loss: 0.00557

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.23057
Value Function Update Magnitude: 0.31000

Collected Steps per Second: 22,458.70036
Overall Steps per Second: 10,654.96768

Timestep Collection Time: 2.22631
Timestep Consumption Time: 2.46634
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.69265

Cumulative Model Updates: 367,048
Cumulative Timesteps: 3,061,218,072

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.68818
Policy Entropy: 3.99247
Value Function Loss: 0.00646

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.23300
Value Function Update Magnitude: 0.31256

Collected Steps per Second: 22,261.38247
Overall Steps per Second: 10,501.13113

Timestep Collection Time: 2.24712
Timestep Consumption Time: 2.51656
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.76368

Cumulative Model Updates: 367,054
Cumulative Timesteps: 3,061,268,096

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3061268096...
Checkpoint 3061268096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.08679
Policy Entropy: 3.97348
Value Function Loss: 0.00656

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.03439
Policy Update Magnitude: 0.24189
Value Function Update Magnitude: 0.32418

Collected Steps per Second: 23,163.91608
Overall Steps per Second: 10,663.68989

Timestep Collection Time: 2.15965
Timestep Consumption Time: 2.53159
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.69125

Cumulative Model Updates: 367,060
Cumulative Timesteps: 3,061,318,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.17139
Policy Entropy: 3.95193
Value Function Loss: 0.00726

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.03383
Policy Update Magnitude: 0.25113
Value Function Update Magnitude: 0.32708

Collected Steps per Second: 22,666.64129
Overall Steps per Second: 10,586.79979

Timestep Collection Time: 2.20633
Timestep Consumption Time: 2.51748
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.72381

Cumulative Model Updates: 367,066
Cumulative Timesteps: 3,061,368,132

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3061368132...
Checkpoint 3061368132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.23012
Policy Entropy: 3.97229
Value Function Loss: 0.00748

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 0.26300
Value Function Update Magnitude: 0.32695

Collected Steps per Second: 22,644.05249
Overall Steps per Second: 10,936.23644

Timestep Collection Time: 2.20950
Timestep Consumption Time: 2.36538
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.57488

Cumulative Model Updates: 367,072
Cumulative Timesteps: 3,061,418,164

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.00188
Policy Entropy: 3.95973
Value Function Loss: 0.00759

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.03368
Policy Update Magnitude: 0.26778
Value Function Update Magnitude: 0.33912

Collected Steps per Second: 22,379.92307
Overall Steps per Second: 10,514.82192

Timestep Collection Time: 2.23441
Timestep Consumption Time: 2.52135
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.75576

Cumulative Model Updates: 367,078
Cumulative Timesteps: 3,061,468,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3061468170...
Checkpoint 3061468170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.71032
Policy Entropy: 3.95936
Value Function Loss: 0.00682

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 0.25678
Value Function Update Magnitude: 0.33884

Collected Steps per Second: 22,398.97912
Overall Steps per Second: 10,586.04908

Timestep Collection Time: 2.23305
Timestep Consumption Time: 2.49185
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.72490

Cumulative Model Updates: 367,084
Cumulative Timesteps: 3,061,518,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.63248
Policy Entropy: 3.94946
Value Function Loss: 0.00688

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.24849
Value Function Update Magnitude: 0.32618

Collected Steps per Second: 23,447.08641
Overall Steps per Second: 10,835.25196

Timestep Collection Time: 2.13323
Timestep Consumption Time: 2.48300
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.61623

Cumulative Model Updates: 367,090
Cumulative Timesteps: 3,061,568,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3061568206...
Checkpoint 3061568206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.56607
Policy Entropy: 3.97808
Value Function Loss: 0.00550

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.23779
Value Function Update Magnitude: 0.31856

Collected Steps per Second: 22,182.22051
Overall Steps per Second: 10,636.83374

Timestep Collection Time: 2.25496
Timestep Consumption Time: 2.44757
PPO Batch Consumption Time: 0.27971
Total Iteration Time: 4.70253

Cumulative Model Updates: 367,096
Cumulative Timesteps: 3,061,618,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.72120
Policy Entropy: 3.93739
Value Function Loss: 0.00608

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02842
Policy Update Magnitude: 0.23679
Value Function Update Magnitude: 0.30881

Collected Steps per Second: 22,189.88570
Overall Steps per Second: 10,555.14423

Timestep Collection Time: 2.25373
Timestep Consumption Time: 2.48424
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.73797

Cumulative Model Updates: 367,102
Cumulative Timesteps: 3,061,668,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3061668236...
Checkpoint 3061668236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.21690
Policy Entropy: 3.96002
Value Function Loss: 0.00606

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02482
Policy Update Magnitude: 0.24585
Value Function Update Magnitude: 0.32002

Collected Steps per Second: 23,153.87047
Overall Steps per Second: 10,704.15380

Timestep Collection Time: 2.16016
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.67258

Cumulative Model Updates: 367,108
Cumulative Timesteps: 3,061,718,252

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.13912
Policy Entropy: 3.94230
Value Function Loss: 0.00715

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.02568
Policy Update Magnitude: 0.25055
Value Function Update Magnitude: 0.33391

Collected Steps per Second: 22,478.62481
Overall Steps per Second: 10,555.18964

Timestep Collection Time: 2.22487
Timestep Consumption Time: 2.51327
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.73814

Cumulative Model Updates: 367,114
Cumulative Timesteps: 3,061,768,264

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3061768264...
Checkpoint 3061768264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.76273
Policy Entropy: 3.97254
Value Function Loss: 0.00723

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02496
Policy Update Magnitude: 0.24667
Value Function Update Magnitude: 0.33489

Collected Steps per Second: 22,476.56971
Overall Steps per Second: 10,603.08738

Timestep Collection Time: 2.22472
Timestep Consumption Time: 2.49127
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.71598

Cumulative Model Updates: 367,120
Cumulative Timesteps: 3,061,818,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.61519
Policy Entropy: 3.97290
Value Function Loss: 0.00784

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02488
Policy Update Magnitude: 0.24899
Value Function Update Magnitude: 0.34378

Collected Steps per Second: 23,166.59649
Overall Steps per Second: 10,795.95206

Timestep Collection Time: 2.15906
Timestep Consumption Time: 2.47398
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.63303

Cumulative Model Updates: 367,126
Cumulative Timesteps: 3,061,868,286

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3061868286...
Checkpoint 3061868286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.32568
Policy Entropy: 3.96656
Value Function Loss: 0.00688

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02774
Policy Update Magnitude: 0.25454
Value Function Update Magnitude: 0.33960

Collected Steps per Second: 22,413.44577
Overall Steps per Second: 10,630.84655

Timestep Collection Time: 2.23080
Timestep Consumption Time: 2.47249
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.70329

Cumulative Model Updates: 367,132
Cumulative Timesteps: 3,061,918,286

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.54308
Policy Entropy: 3.96237
Value Function Loss: 0.00686

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.03491
Policy Update Magnitude: 0.24276
Value Function Update Magnitude: 0.32153

Collected Steps per Second: 22,421.17579
Overall Steps per Second: 10,835.77661

Timestep Collection Time: 2.23012
Timestep Consumption Time: 2.38440
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.61453

Cumulative Model Updates: 367,138
Cumulative Timesteps: 3,061,968,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3061968288...
Checkpoint 3061968288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.32590
Policy Entropy: 3.93412
Value Function Loss: 0.00648

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.03282
Policy Update Magnitude: 0.25356
Value Function Update Magnitude: 0.34313

Collected Steps per Second: 22,357.58938
Overall Steps per Second: 10,661.15829

Timestep Collection Time: 2.23709
Timestep Consumption Time: 2.45433
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.69142

Cumulative Model Updates: 367,144
Cumulative Timesteps: 3,062,018,304

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.69888
Policy Entropy: 3.94957
Value Function Loss: 0.00649

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.03795
Policy Update Magnitude: 0.25647
Value Function Update Magnitude: 0.33833

Collected Steps per Second: 22,299.54814
Overall Steps per Second: 10,544.63949

Timestep Collection Time: 2.24220
Timestep Consumption Time: 2.49955
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.74175

Cumulative Model Updates: 367,150
Cumulative Timesteps: 3,062,068,304

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3062068304...
Checkpoint 3062068304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.33530
Policy Entropy: 3.93872
Value Function Loss: 0.00643

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.03122
Policy Update Magnitude: 0.24895
Value Function Update Magnitude: 0.33529

Collected Steps per Second: 21,515.00844
Overall Steps per Second: 10,655.83512

Timestep Collection Time: 2.32489
Timestep Consumption Time: 2.36925
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.69414

Cumulative Model Updates: 367,156
Cumulative Timesteps: 3,062,118,324

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.93811
Policy Entropy: 3.96358
Value Function Loss: 0.00667

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.03170
Policy Update Magnitude: 0.24302
Value Function Update Magnitude: 0.32924

Collected Steps per Second: 22,460.76586
Overall Steps per Second: 10,553.94626

Timestep Collection Time: 2.22637
Timestep Consumption Time: 2.51176
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.73813

Cumulative Model Updates: 367,162
Cumulative Timesteps: 3,062,168,330

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3062168330...
Checkpoint 3062168330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.15543
Policy Entropy: 3.92890
Value Function Loss: 0.00669

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.03365
Policy Update Magnitude: 0.24848
Value Function Update Magnitude: 0.32930

Collected Steps per Second: 22,335.04678
Overall Steps per Second: 10,563.77249

Timestep Collection Time: 2.23899
Timestep Consumption Time: 2.49492
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.73391

Cumulative Model Updates: 367,168
Cumulative Timesteps: 3,062,218,338

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.25238
Policy Entropy: 3.96736
Value Function Loss: 0.00585

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.24373
Value Function Update Magnitude: 0.32719

Collected Steps per Second: 23,019.20479
Overall Steps per Second: 10,789.37757

Timestep Collection Time: 2.17297
Timestep Consumption Time: 2.46307
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.63604

Cumulative Model Updates: 367,174
Cumulative Timesteps: 3,062,268,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3062268358...
Checkpoint 3062268358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.84552
Policy Entropy: 4.01357
Value Function Loss: 0.00563

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.23485
Value Function Update Magnitude: 0.30534

Collected Steps per Second: 22,422.96002
Overall Steps per Second: 10,651.19160

Timestep Collection Time: 2.23066
Timestep Consumption Time: 2.46534
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.69600

Cumulative Model Updates: 367,180
Cumulative Timesteps: 3,062,318,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.09586
Policy Entropy: 4.01535
Value Function Loss: 0.00554

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.23370
Value Function Update Magnitude: 0.29465

Collected Steps per Second: 22,096.51158
Overall Steps per Second: 10,487.56262

Timestep Collection Time: 2.26343
Timestep Consumption Time: 2.50545
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.76889

Cumulative Model Updates: 367,186
Cumulative Timesteps: 3,062,368,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3062368390...
Checkpoint 3062368390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.42562
Policy Entropy: 4.04702
Value Function Loss: 0.00558

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.23169
Value Function Update Magnitude: 0.29730

Collected Steps per Second: 23,201.22422
Overall Steps per Second: 10,651.70979

Timestep Collection Time: 2.15523
Timestep Consumption Time: 2.53923
PPO Batch Consumption Time: 0.29394
Total Iteration Time: 4.69446

Cumulative Model Updates: 367,192
Cumulative Timesteps: 3,062,418,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.62800
Policy Entropy: 4.03000
Value Function Loss: 0.00514

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02262
Policy Update Magnitude: 0.22703
Value Function Update Magnitude: 0.30098

Collected Steps per Second: 22,331.05691
Overall Steps per Second: 10,433.10247

Timestep Collection Time: 2.23948
Timestep Consumption Time: 2.55391
PPO Batch Consumption Time: 0.29557
Total Iteration Time: 4.79340

Cumulative Model Updates: 367,198
Cumulative Timesteps: 3,062,468,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3062468404...
Checkpoint 3062468404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.44067
Policy Entropy: 4.00734
Value Function Loss: 0.00636

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02027
Policy Update Magnitude: 0.23993
Value Function Update Magnitude: 0.30463

Collected Steps per Second: 22,480.38899
Overall Steps per Second: 10,712.23007

Timestep Collection Time: 2.22469
Timestep Consumption Time: 2.44399
PPO Batch Consumption Time: 0.29470
Total Iteration Time: 4.66868

Cumulative Model Updates: 367,204
Cumulative Timesteps: 3,062,518,416

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.31617
Policy Entropy: 4.00161
Value Function Loss: 0.00612

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.24074
Value Function Update Magnitude: 0.32510

Collected Steps per Second: 22,708.27904
Overall Steps per Second: 10,597.26892

Timestep Collection Time: 2.20193
Timestep Consumption Time: 2.51646
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.71839

Cumulative Model Updates: 367,210
Cumulative Timesteps: 3,062,568,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3062568418...
Checkpoint 3062568418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.58424
Policy Entropy: 3.98918
Value Function Loss: 0.00643

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02340
Policy Update Magnitude: 0.24386
Value Function Update Magnitude: 0.33647

Collected Steps per Second: 22,503.20616
Overall Steps per Second: 10,587.06241

Timestep Collection Time: 2.22306
Timestep Consumption Time: 2.50214
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.72520

Cumulative Model Updates: 367,216
Cumulative Timesteps: 3,062,618,444

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.82754
Policy Entropy: 4.08092
Value Function Loss: 0.00484

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02001
Policy Update Magnitude: 0.22953
Value Function Update Magnitude: 0.31430

Collected Steps per Second: 22,543.51818
Overall Steps per Second: 10,816.19711

Timestep Collection Time: 2.21882
Timestep Consumption Time: 2.40573
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.62455

Cumulative Model Updates: 367,222
Cumulative Timesteps: 3,062,668,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3062668464...
Checkpoint 3062668464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.74284
Policy Entropy: 4.06924
Value Function Loss: 0.00500

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02001
Policy Update Magnitude: 0.21951
Value Function Update Magnitude: 0.29675

Collected Steps per Second: 22,548.05256
Overall Steps per Second: 10,632.84858

Timestep Collection Time: 2.21820
Timestep Consumption Time: 2.48572
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.70391

Cumulative Model Updates: 367,228
Cumulative Timesteps: 3,062,718,480

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.10171
Policy Entropy: 4.06356
Value Function Loss: 0.00520

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.01831
Policy Update Magnitude: 0.21990
Value Function Update Magnitude: 0.30370

Collected Steps per Second: 22,665.99110
Overall Steps per Second: 10,781.04301

Timestep Collection Time: 2.20595
Timestep Consumption Time: 2.43182
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.63777

Cumulative Model Updates: 367,234
Cumulative Timesteps: 3,062,768,480

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3062768480...
Checkpoint 3062768480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.03224
Policy Entropy: 4.02882
Value Function Loss: 0.00543

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.03099
Policy Update Magnitude: 0.29457
Value Function Update Magnitude: 0.31686

Collected Steps per Second: 22,418.65662
Overall Steps per Second: 10,740.94482

Timestep Collection Time: 2.23118
Timestep Consumption Time: 2.42577
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.65695

Cumulative Model Updates: 367,240
Cumulative Timesteps: 3,062,818,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.57817
Policy Entropy: 3.99629
Value Function Loss: 0.00533

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.04418
Policy Update Magnitude: 0.26446
Value Function Update Magnitude: 0.32081

Collected Steps per Second: 22,485.62145
Overall Steps per Second: 10,536.58867

Timestep Collection Time: 2.22435
Timestep Consumption Time: 2.52253
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.74689

Cumulative Model Updates: 367,246
Cumulative Timesteps: 3,062,868,516

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3062868516...
Checkpoint 3062868516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.85093
Policy Entropy: 3.99403
Value Function Loss: 0.00614

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.03987
Policy Update Magnitude: 0.25253
Value Function Update Magnitude: 0.31438

Collected Steps per Second: 22,175.20629
Overall Steps per Second: 10,598.08092

Timestep Collection Time: 2.25630
Timestep Consumption Time: 2.46474
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.72104

Cumulative Model Updates: 367,252
Cumulative Timesteps: 3,062,918,550

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.28773
Policy Entropy: 3.96530
Value Function Loss: 0.00638

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.03585
Policy Update Magnitude: 0.25348
Value Function Update Magnitude: 0.32709

Collected Steps per Second: 22,494.18332
Overall Steps per Second: 10,839.72599

Timestep Collection Time: 2.22386
Timestep Consumption Time: 2.39101
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.61488

Cumulative Model Updates: 367,258
Cumulative Timesteps: 3,062,968,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3062968574...
Checkpoint 3062968574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.10260
Policy Entropy: 3.96637
Value Function Loss: 0.00578

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.03369
Policy Update Magnitude: 0.24389
Value Function Update Magnitude: 0.32745

Collected Steps per Second: 22,410.80148
Overall Steps per Second: 10,652.27015

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.46434
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.69684

Cumulative Model Updates: 367,264
Cumulative Timesteps: 3,063,018,606

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.23958
Policy Entropy: 3.94421
Value Function Loss: 0.00618

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02919
Policy Update Magnitude: 0.24644
Value Function Update Magnitude: 0.33093

Collected Steps per Second: 22,304.60765
Overall Steps per Second: 10,546.30158

Timestep Collection Time: 2.24303
Timestep Consumption Time: 2.50081
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.74384

Cumulative Model Updates: 367,270
Cumulative Timesteps: 3,063,068,636

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3063068636...
Checkpoint 3063068636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.03322
Policy Entropy: 3.90162
Value Function Loss: 0.00657

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03057
Policy Update Magnitude: 0.26783
Value Function Update Magnitude: 0.33840

Collected Steps per Second: 22,490.57982
Overall Steps per Second: 10,792.98430

Timestep Collection Time: 2.22315
Timestep Consumption Time: 2.40949
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.63264

Cumulative Model Updates: 367,276
Cumulative Timesteps: 3,063,118,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.69634
Policy Entropy: 3.92682
Value Function Loss: 0.00679

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.03864
Policy Update Magnitude: 0.26345
Value Function Update Magnitude: 0.34009

Collected Steps per Second: 22,740.45894
Overall Steps per Second: 10,719.53336

Timestep Collection Time: 2.19996
Timestep Consumption Time: 2.46704
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.66699

Cumulative Model Updates: 367,282
Cumulative Timesteps: 3,063,168,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3063168664...
Checkpoint 3063168664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.23647
Policy Entropy: 3.98500
Value Function Loss: 0.00577

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.03355
Policy Update Magnitude: 0.24741
Value Function Update Magnitude: 0.33582

Collected Steps per Second: 22,231.97930
Overall Steps per Second: 10,625.72193

Timestep Collection Time: 2.25090
Timestep Consumption Time: 2.45861
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.70952

Cumulative Model Updates: 367,288
Cumulative Timesteps: 3,063,218,706

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.64949
Policy Entropy: 4.00192
Value Function Loss: 0.00597

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02583
Policy Update Magnitude: 0.23172
Value Function Update Magnitude: 0.32937

Collected Steps per Second: 22,243.68647
Overall Steps per Second: 10,833.95532

Timestep Collection Time: 2.24891
Timestep Consumption Time: 2.36843
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.61733

Cumulative Model Updates: 367,294
Cumulative Timesteps: 3,063,268,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3063268730...
Checkpoint 3063268730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.85406
Policy Entropy: 3.98777
Value Function Loss: 0.00515

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.22823
Value Function Update Magnitude: 0.32428

Collected Steps per Second: 22,448.05516
Overall Steps per Second: 10,696.40166

Timestep Collection Time: 2.22817
Timestep Consumption Time: 2.44799
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.67615

Cumulative Model Updates: 367,300
Cumulative Timesteps: 3,063,318,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.51091
Policy Entropy: 3.95228
Value Function Loss: 0.00550

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.23069
Value Function Update Magnitude: 0.32074

Collected Steps per Second: 22,380.20688
Overall Steps per Second: 10,511.18200

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.52292
PPO Batch Consumption Time: 0.29432
Total Iteration Time: 4.75722

Cumulative Model Updates: 367,306
Cumulative Timesteps: 3,063,368,752

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3063368752...
Checkpoint 3063368752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.85557
Policy Entropy: 3.95755
Value Function Loss: 0.00574

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02170
Policy Update Magnitude: 0.23791
Value Function Update Magnitude: 0.31281

Collected Steps per Second: 22,435.23778
Overall Steps per Second: 10,717.11339

Timestep Collection Time: 2.22873
Timestep Consumption Time: 2.43690
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.66562

Cumulative Model Updates: 367,312
Cumulative Timesteps: 3,063,418,754

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.63530
Policy Entropy: 3.89968
Value Function Loss: 0.00743

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02633
Policy Update Magnitude: 0.24906
Value Function Update Magnitude: 0.31070

Collected Steps per Second: 22,530.24290
Overall Steps per Second: 10,688.47898

Timestep Collection Time: 2.22093
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.68149

Cumulative Model Updates: 367,318
Cumulative Timesteps: 3,063,468,792

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3063468792...
Checkpoint 3063468792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.58881
Policy Entropy: 3.90655
Value Function Loss: 0.00733

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02769
Policy Update Magnitude: 0.25563
Value Function Update Magnitude: 0.33075

Collected Steps per Second: 22,292.88063
Overall Steps per Second: 10,699.12579

Timestep Collection Time: 2.24341
Timestep Consumption Time: 2.43099
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.67440

Cumulative Model Updates: 367,324
Cumulative Timesteps: 3,063,518,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.88730
Policy Entropy: 3.90176
Value Function Loss: 0.00734

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02859
Policy Update Magnitude: 0.25679
Value Function Update Magnitude: 0.33866

Collected Steps per Second: 23,070.85880
Overall Steps per Second: 10,665.58077

Timestep Collection Time: 2.16793
Timestep Consumption Time: 2.52155
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.68948

Cumulative Model Updates: 367,330
Cumulative Timesteps: 3,063,568,820

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3063568820...
Checkpoint 3063568820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.13582
Policy Entropy: 3.94947
Value Function Loss: 0.00617

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02314
Policy Update Magnitude: 0.24654
Value Function Update Magnitude: 0.33022

Collected Steps per Second: 22,510.80124
Overall Steps per Second: 10,545.28998

Timestep Collection Time: 2.22222
Timestep Consumption Time: 2.52151
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.74373

Cumulative Model Updates: 367,336
Cumulative Timesteps: 3,063,618,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.41309
Policy Entropy: 3.92366
Value Function Loss: 0.00679

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.24809
Value Function Update Magnitude: 0.32820

Collected Steps per Second: 22,276.26946
Overall Steps per Second: 10,557.71256

Timestep Collection Time: 2.24598
Timestep Consumption Time: 2.49293
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.73891

Cumulative Model Updates: 367,342
Cumulative Timesteps: 3,063,668,876

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3063668876...
Checkpoint 3063668876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.28479
Policy Entropy: 3.93640
Value Function Loss: 0.00727

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02810
Policy Update Magnitude: 0.25548
Value Function Update Magnitude: 0.32692

Collected Steps per Second: 23,094.50268
Overall Steps per Second: 10,856.32668

Timestep Collection Time: 2.16580
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.60727

Cumulative Model Updates: 367,348
Cumulative Timesteps: 3,063,718,894

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.24635
Policy Entropy: 3.93072
Value Function Loss: 0.00838

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.03214
Policy Update Magnitude: 0.26124
Value Function Update Magnitude: 0.34031

Collected Steps per Second: 22,381.14993
Overall Steps per Second: 10,546.95556

Timestep Collection Time: 2.23456
Timestep Consumption Time: 2.50728
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.74184

Cumulative Model Updates: 367,354
Cumulative Timesteps: 3,063,768,906

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3063768906...
Checkpoint 3063768906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.25041
Policy Entropy: 3.96860
Value Function Loss: 0.00731

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.03070
Policy Update Magnitude: 0.26044
Value Function Update Magnitude: 0.33649

Collected Steps per Second: 22,238.56905
Overall Steps per Second: 10,671.35022

Timestep Collection Time: 2.24835
Timestep Consumption Time: 2.43710
PPO Batch Consumption Time: 0.29362
Total Iteration Time: 4.68544

Cumulative Model Updates: 367,360
Cumulative Timesteps: 3,063,818,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61801
Policy Entropy: 4.01078
Value Function Loss: 0.00633

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02868
Policy Update Magnitude: 0.24022
Value Function Update Magnitude: 0.31314

Collected Steps per Second: 22,389.82776
Overall Steps per Second: 10,468.37641

Timestep Collection Time: 2.23325
Timestep Consumption Time: 2.54323
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.77648

Cumulative Model Updates: 367,366
Cumulative Timesteps: 3,063,868,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3063868908...
Checkpoint 3063868908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.19203
Policy Entropy: 3.97836
Value Function Loss: 0.00631

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.23231
Value Function Update Magnitude: 0.30992

Collected Steps per Second: 22,037.19511
Overall Steps per Second: 10,649.89050

Timestep Collection Time: 2.26989
Timestep Consumption Time: 2.42706
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.69695

Cumulative Model Updates: 367,372
Cumulative Timesteps: 3,063,918,930

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.06088
Policy Entropy: 3.99457
Value Function Loss: 0.00585

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02218
Policy Update Magnitude: 0.23224
Value Function Update Magnitude: 0.33841

Collected Steps per Second: 22,540.84717
Overall Steps per Second: 10,846.85678

Timestep Collection Time: 2.21837
Timestep Consumption Time: 2.39163
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.61000

Cumulative Model Updates: 367,378
Cumulative Timesteps: 3,063,968,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3063968934...
Checkpoint 3063968934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.19582
Policy Entropy: 3.95963
Value Function Loss: 0.00539

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.22589
Value Function Update Magnitude: 0.34040

Collected Steps per Second: 22,445.63863
Overall Steps per Second: 10,664.82149

Timestep Collection Time: 2.22867
Timestep Consumption Time: 2.46189
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.69056

Cumulative Model Updates: 367,384
Cumulative Timesteps: 3,064,018,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.19556
Policy Entropy: 3.96958
Value Function Loss: 0.00640

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02335
Policy Update Magnitude: 0.23227
Value Function Update Magnitude: 0.32028

Collected Steps per Second: 22,442.54802
Overall Steps per Second: 10,592.73299

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.49280
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.72116

Cumulative Model Updates: 367,390
Cumulative Timesteps: 3,064,068,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3064068968...
Checkpoint 3064068968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.04867
Policy Entropy: 3.93488
Value Function Loss: 0.00680

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.23587
Value Function Update Magnitude: 0.33157

Collected Steps per Second: 22,187.05622
Overall Steps per Second: 10,738.23624

Timestep Collection Time: 2.25420
Timestep Consumption Time: 2.40336
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.65756

Cumulative Model Updates: 367,396
Cumulative Timesteps: 3,064,118,982

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.43442
Policy Entropy: 3.89562
Value Function Loss: 0.00731

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02613
Policy Update Magnitude: 0.24532
Value Function Update Magnitude: 0.33596

Collected Steps per Second: 22,485.33566
Overall Steps per Second: 10,641.28560

Timestep Collection Time: 2.22501
Timestep Consumption Time: 2.47649
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.70150

Cumulative Model Updates: 367,402
Cumulative Timesteps: 3,064,169,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3064169012...
Checkpoint 3064169012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.70531
Policy Entropy: 3.93210
Value Function Loss: 0.00660

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.25526
Value Function Update Magnitude: 0.32390

Collected Steps per Second: 22,241.37642
Overall Steps per Second: 10,719.77828

Timestep Collection Time: 2.24923
Timestep Consumption Time: 2.41747
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.66670

Cumulative Model Updates: 367,408
Cumulative Timesteps: 3,064,219,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.17284
Policy Entropy: 3.89331
Value Function Loss: 0.00668

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02793
Policy Update Magnitude: 0.25977
Value Function Update Magnitude: 0.33642

Collected Steps per Second: 22,478.06537
Overall Steps per Second: 10,890.67321

Timestep Collection Time: 2.22519
Timestep Consumption Time: 2.36755
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.59274

Cumulative Model Updates: 367,414
Cumulative Timesteps: 3,064,269,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3064269056...
Checkpoint 3064269056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.78564
Policy Entropy: 3.95350
Value Function Loss: 0.00563

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.24927
Value Function Update Magnitude: 0.34062

Collected Steps per Second: 22,100.46316
Overall Steps per Second: 10,641.07724

Timestep Collection Time: 2.26294
Timestep Consumption Time: 2.43696
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.69990

Cumulative Model Updates: 367,420
Cumulative Timesteps: 3,064,319,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69711
Policy Entropy: 3.92840
Value Function Loss: 0.00564

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.02915
Policy Update Magnitude: 0.24136
Value Function Update Magnitude: 0.33046

Collected Steps per Second: 22,345.48238
Overall Steps per Second: 10,550.18649

Timestep Collection Time: 2.23884
Timestep Consumption Time: 2.50306
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.74191

Cumulative Model Updates: 367,426
Cumulative Timesteps: 3,064,369,096

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3064369096...
Checkpoint 3064369096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.17114
Policy Entropy: 3.95338
Value Function Loss: 0.00558

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.24157
Value Function Update Magnitude: 0.31764

Collected Steps per Second: 23,135.21290
Overall Steps per Second: 10,686.33354

Timestep Collection Time: 2.16320
Timestep Consumption Time: 2.51998
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.68318

Cumulative Model Updates: 367,432
Cumulative Timesteps: 3,064,419,142

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.16685
Policy Entropy: 3.93678
Value Function Loss: 0.00583

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.03593
Policy Update Magnitude: 0.24319
Value Function Update Magnitude: 0.30663

Collected Steps per Second: 22,445.43660
Overall Steps per Second: 10,593.21697

Timestep Collection Time: 2.22762
Timestep Consumption Time: 2.49238
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.72000

Cumulative Model Updates: 367,438
Cumulative Timesteps: 3,064,469,142

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3064469142...
Checkpoint 3064469142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.47966
Policy Entropy: 3.94358
Value Function Loss: 0.00645

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.03611
Policy Update Magnitude: 0.24178
Value Function Update Magnitude: 0.31120

Collected Steps per Second: 22,455.92782
Overall Steps per Second: 10,775.61128

Timestep Collection Time: 2.22676
Timestep Consumption Time: 2.41372
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.64048

Cumulative Model Updates: 367,444
Cumulative Timesteps: 3,064,519,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.56427
Policy Entropy: 3.93394
Value Function Loss: 0.00704

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 0.24133
Value Function Update Magnitude: 0.33339

Collected Steps per Second: 23,498.02704
Overall Steps per Second: 10,892.61058

Timestep Collection Time: 2.12835
Timestep Consumption Time: 2.46302
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.59137

Cumulative Model Updates: 367,450
Cumulative Timesteps: 3,064,569,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3064569158...
Checkpoint 3064569158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.28841
Policy Entropy: 3.94572
Value Function Loss: 0.00763

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.24311
Value Function Update Magnitude: 0.34923

Collected Steps per Second: 22,361.25480
Overall Steps per Second: 10,672.52392

Timestep Collection Time: 2.23673
Timestep Consumption Time: 2.44970
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.68643

Cumulative Model Updates: 367,456
Cumulative Timesteps: 3,064,619,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.23819
Policy Entropy: 3.95540
Value Function Loss: 0.00726

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02855
Policy Update Magnitude: 0.24942
Value Function Update Magnitude: 0.33537

Collected Steps per Second: 22,373.32638
Overall Steps per Second: 10,511.85843

Timestep Collection Time: 2.23516
Timestep Consumption Time: 2.52213
PPO Batch Consumption Time: 0.29299
Total Iteration Time: 4.75729

Cumulative Model Updates: 367,462
Cumulative Timesteps: 3,064,669,182

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3064669182...
Checkpoint 3064669182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.99643
Policy Entropy: 3.97493
Value Function Loss: 0.00717

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02955
Policy Update Magnitude: 0.24866
Value Function Update Magnitude: 0.31401

Collected Steps per Second: 23,253.53547
Overall Steps per Second: 10,702.86773

Timestep Collection Time: 2.15055
Timestep Consumption Time: 2.52184
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.67239

Cumulative Model Updates: 367,468
Cumulative Timesteps: 3,064,719,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.58611
Policy Entropy: 3.97828
Value Function Loss: 0.00634

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.24711
Value Function Update Magnitude: 0.31597

Collected Steps per Second: 22,595.13333
Overall Steps per Second: 10,566.77990

Timestep Collection Time: 2.21349
Timestep Consumption Time: 2.51965
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.73314

Cumulative Model Updates: 367,474
Cumulative Timesteps: 3,064,769,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3064769204...
Checkpoint 3064769204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.52273
Policy Entropy: 3.99644
Value Function Loss: 0.00590

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.23158
Value Function Update Magnitude: 0.32177

Collected Steps per Second: 22,328.00447
Overall Steps per Second: 10,815.72752

Timestep Collection Time: 2.24033
Timestep Consumption Time: 2.38461
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.62493

Cumulative Model Updates: 367,480
Cumulative Timesteps: 3,064,819,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.16702
Policy Entropy: 4.03704
Value Function Loss: 0.00567

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02435
Policy Update Magnitude: 0.21508
Value Function Update Magnitude: 0.30176

Collected Steps per Second: 22,487.99939
Overall Steps per Second: 10,562.40755

Timestep Collection Time: 2.22439
Timestep Consumption Time: 2.51147
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.73585

Cumulative Model Updates: 367,486
Cumulative Timesteps: 3,064,869,248

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3064869248...
Checkpoint 3064869248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.37658
Policy Entropy: 4.05671
Value Function Loss: 0.00560

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.01804
Policy Update Magnitude: 0.21489
Value Function Update Magnitude: 0.27985

Collected Steps per Second: 22,471.45967
Overall Steps per Second: 10,624.57996

Timestep Collection Time: 2.22504
Timestep Consumption Time: 2.48102
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.70607

Cumulative Model Updates: 367,492
Cumulative Timesteps: 3,064,919,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.59590
Policy Entropy: 4.03833
Value Function Loss: 0.00585

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02307
Policy Update Magnitude: 0.21932
Value Function Update Magnitude: 0.28042

Collected Steps per Second: 22,249.66865
Overall Steps per Second: 10,838.09760

Timestep Collection Time: 2.24785
Timestep Consumption Time: 2.36679
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.61465

Cumulative Model Updates: 367,498
Cumulative Timesteps: 3,064,969,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3064969262...
Checkpoint 3064969262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.76124
Policy Entropy: 3.99582
Value Function Loss: 0.00603

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.23825
Value Function Update Magnitude: 0.29263

Collected Steps per Second: 22,365.28269
Overall Steps per Second: 10,666.87003

Timestep Collection Time: 2.23641
Timestep Consumption Time: 2.45269
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.68910

Cumulative Model Updates: 367,504
Cumulative Timesteps: 3,065,019,280

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.49332
Policy Entropy: 3.98011
Value Function Loss: 0.00610

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02929
Policy Update Magnitude: 0.24832
Value Function Update Magnitude: 0.31903

Collected Steps per Second: 22,508.87533
Overall Steps per Second: 10,629.77226

Timestep Collection Time: 2.22268
Timestep Consumption Time: 2.48391
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.70659

Cumulative Model Updates: 367,510
Cumulative Timesteps: 3,065,069,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3065069310...
Checkpoint 3065069310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.07290
Policy Entropy: 3.97367
Value Function Loss: 0.00633

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.23964
Value Function Update Magnitude: 0.33322

Collected Steps per Second: 23,285.18025
Overall Steps per Second: 10,757.47958

Timestep Collection Time: 2.14841
Timestep Consumption Time: 2.50194
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.65035

Cumulative Model Updates: 367,516
Cumulative Timesteps: 3,065,119,336

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.80513
Policy Entropy: 3.97925
Value Function Loss: 0.00598

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02701
Policy Update Magnitude: 0.24184
Value Function Update Magnitude: 0.33869

Collected Steps per Second: 22,477.19161
Overall Steps per Second: 10,681.41458

Timestep Collection Time: 2.22528
Timestep Consumption Time: 2.45744
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.68271

Cumulative Model Updates: 367,522
Cumulative Timesteps: 3,065,169,354

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3065169354...
Checkpoint 3065169354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.37014
Policy Entropy: 3.97467
Value Function Loss: 0.00607

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02601
Policy Update Magnitude: 0.23788
Value Function Update Magnitude: 0.34348

Collected Steps per Second: 22,374.26699
Overall Steps per Second: 10,716.81004

Timestep Collection Time: 2.23534
Timestep Consumption Time: 2.43154
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.66687

Cumulative Model Updates: 367,528
Cumulative Timesteps: 3,065,219,368

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.17206
Policy Entropy: 3.99384
Value Function Loss: 0.00572

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02517
Policy Update Magnitude: 0.23379
Value Function Update Magnitude: 0.34235

Collected Steps per Second: 22,951.55512
Overall Steps per Second: 10,805.71926

Timestep Collection Time: 2.17955
Timestep Consumption Time: 2.44985
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.62940

Cumulative Model Updates: 367,534
Cumulative Timesteps: 3,065,269,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3065269392...
Checkpoint 3065269392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.03693
Policy Entropy: 4.00536
Value Function Loss: 0.00584

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.24175
Value Function Update Magnitude: 0.34014

Collected Steps per Second: 22,458.18644
Overall Steps per Second: 10,645.74076

Timestep Collection Time: 2.22645
Timestep Consumption Time: 2.47045
PPO Batch Consumption Time: 0.28005
Total Iteration Time: 4.69690

Cumulative Model Updates: 367,540
Cumulative Timesteps: 3,065,319,394

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.84520
Policy Entropy: 4.01623
Value Function Loss: 0.00622

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.24240
Value Function Update Magnitude: 0.33030

Collected Steps per Second: 22,089.21688
Overall Steps per Second: 10,620.14864

Timestep Collection Time: 2.26554
Timestep Consumption Time: 2.44664
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.71218

Cumulative Model Updates: 367,546
Cumulative Timesteps: 3,065,369,438

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 3065369438...
Checkpoint 3065369438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.79538
Policy Entropy: 4.02628
Value Function Loss: 0.00598

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.23994
Value Function Update Magnitude: 0.32840

Collected Steps per Second: 22,547.12771
Overall Steps per Second: 10,541.98120

Timestep Collection Time: 2.21864
Timestep Consumption Time: 2.52658
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.74522

Cumulative Model Updates: 367,552
Cumulative Timesteps: 3,065,419,462

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.59909
Policy Entropy: 4.01940
Value Function Loss: 0.00576

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.22556
Value Function Update Magnitude: 0.31963

Collected Steps per Second: 22,069.23362
Overall Steps per Second: 10,463.23995

Timestep Collection Time: 2.26569
Timestep Consumption Time: 2.51314
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.77883

Cumulative Model Updates: 367,558
Cumulative Timesteps: 3,065,469,464

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3065469464...
Checkpoint 3065469464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.97631
Policy Entropy: 4.02257
Value Function Loss: 0.00617

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02286
Policy Update Magnitude: 0.22400
Value Function Update Magnitude: 0.31322

Collected Steps per Second: 22,452.20971
Overall Steps per Second: 10,738.40546

Timestep Collection Time: 2.22775
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.29322
Total Iteration Time: 4.65786

Cumulative Model Updates: 367,564
Cumulative Timesteps: 3,065,519,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.65292
Policy Entropy: 3.99071
Value Function Loss: 0.00550

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.23427
Value Function Update Magnitude: 0.32681

Collected Steps per Second: 22,679.12792
Overall Steps per Second: 10,668.48830

Timestep Collection Time: 2.20608
Timestep Consumption Time: 2.48362
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.68970

Cumulative Model Updates: 367,570
Cumulative Timesteps: 3,065,569,514

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3065569514...
Checkpoint 3065569514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.49624
Policy Entropy: 3.96545
Value Function Loss: 0.00580

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02149
Policy Update Magnitude: 0.24367
Value Function Update Magnitude: 0.33371

Collected Steps per Second: 22,285.81294
Overall Steps per Second: 10,711.90730

Timestep Collection Time: 2.24439
Timestep Consumption Time: 2.42500
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.66938

Cumulative Model Updates: 367,576
Cumulative Timesteps: 3,065,619,532

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.62886
Policy Entropy: 3.96852
Value Function Loss: 0.00579

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.24222
Value Function Update Magnitude: 0.32433

Collected Steps per Second: 22,067.69122
Overall Steps per Second: 10,587.69161

Timestep Collection Time: 2.26657
Timestep Consumption Time: 2.45759
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.72416

Cumulative Model Updates: 367,582
Cumulative Timesteps: 3,065,669,550

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3065669550...
Checkpoint 3065669550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.90144
Policy Entropy: 4.00036
Value Function Loss: 0.00658

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.23993
Value Function Update Magnitude: 0.31924

Collected Steps per Second: 22,485.74487
Overall Steps per Second: 10,596.31296

Timestep Collection Time: 2.22416
Timestep Consumption Time: 2.49559
PPO Batch Consumption Time: 0.28767
Total Iteration Time: 4.71975

Cumulative Model Updates: 367,588
Cumulative Timesteps: 3,065,719,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.35077
Policy Entropy: 3.99656
Value Function Loss: 0.00695

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.23196
Value Function Update Magnitude: 0.31281

Collected Steps per Second: 22,480.33544
Overall Steps per Second: 10,607.08240

Timestep Collection Time: 2.22470
Timestep Consumption Time: 2.49026
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.71496

Cumulative Model Updates: 367,594
Cumulative Timesteps: 3,065,769,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3065769574...
Checkpoint 3065769574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104.04529
Policy Entropy: 3.96420
Value Function Loss: 0.00717

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02361
Policy Update Magnitude: 0.24346
Value Function Update Magnitude: 0.32265

Collected Steps per Second: 22,310.35640
Overall Steps per Second: 10,850.36229

Timestep Collection Time: 2.24299
Timestep Consumption Time: 2.36902
PPO Batch Consumption Time: 0.28046
Total Iteration Time: 4.61201

Cumulative Model Updates: 367,600
Cumulative Timesteps: 3,065,819,616

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.94935
Policy Entropy: 3.90195
Value Function Loss: 0.00719

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.25586
Value Function Update Magnitude: 0.34201

Collected Steps per Second: 22,247.46050
Overall Steps per Second: 10,558.00520

Timestep Collection Time: 2.24844
Timestep Consumption Time: 2.48939
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.73783

Cumulative Model Updates: 367,606
Cumulative Timesteps: 3,065,869,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3065869638...
Checkpoint 3065869638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.68898
Policy Entropy: 3.90353
Value Function Loss: 0.00700

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03244
Policy Update Magnitude: 0.26000
Value Function Update Magnitude: 0.35473

Collected Steps per Second: 22,359.45976
Overall Steps per Second: 10,624.13964

Timestep Collection Time: 2.23753
Timestep Consumption Time: 2.47156
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.70909

Cumulative Model Updates: 367,612
Cumulative Timesteps: 3,065,919,668

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.70486
Policy Entropy: 3.95699
Value Function Loss: 0.00610

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.03003
Policy Update Magnitude: 0.25258
Value Function Update Magnitude: 0.36050

Collected Steps per Second: 23,295.53519
Overall Steps per Second: 10,871.15043

Timestep Collection Time: 2.14676
Timestep Consumption Time: 2.45349
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.60025

Cumulative Model Updates: 367,618
Cumulative Timesteps: 3,065,969,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3065969678...
Checkpoint 3065969678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.81281
Policy Entropy: 3.99057
Value Function Loss: 0.00559

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02652
Policy Update Magnitude: 0.24054
Value Function Update Magnitude: 0.34136

Collected Steps per Second: 22,314.46251
Overall Steps per Second: 10,655.78908

Timestep Collection Time: 2.24142
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.69379

Cumulative Model Updates: 367,624
Cumulative Timesteps: 3,066,019,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.20001
Policy Entropy: 4.00519
Value Function Loss: 0.00531

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02458
Policy Update Magnitude: 0.23701
Value Function Update Magnitude: 0.32128

Collected Steps per Second: 22,455.11099
Overall Steps per Second: 10,555.37994

Timestep Collection Time: 2.22711
Timestep Consumption Time: 2.51076
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.73787

Cumulative Model Updates: 367,630
Cumulative Timesteps: 3,066,069,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3066069704...
Checkpoint 3066069704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.12030
Policy Entropy: 3.95681
Value Function Loss: 0.00607

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02823
Policy Update Magnitude: 0.23788
Value Function Update Magnitude: 0.31774

Collected Steps per Second: 22,929.74258
Overall Steps per Second: 10,671.18417

Timestep Collection Time: 2.18180
Timestep Consumption Time: 2.50634
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.68814

Cumulative Model Updates: 367,636
Cumulative Timesteps: 3,066,119,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.94033
Policy Entropy: 3.94627
Value Function Loss: 0.00670

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.24554
Value Function Update Magnitude: 0.33209

Collected Steps per Second: 22,743.02164
Overall Steps per Second: 10,740.74402

Timestep Collection Time: 2.19856
Timestep Consumption Time: 2.45679
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.65536

Cumulative Model Updates: 367,642
Cumulative Timesteps: 3,066,169,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3066169734...
Checkpoint 3066169734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.05838
Policy Entropy: 3.95610
Value Function Loss: 0.00640

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02862
Policy Update Magnitude: 0.24975
Value Function Update Magnitude: 0.35567

Collected Steps per Second: 22,119.23185
Overall Steps per Second: 10,703.11217

Timestep Collection Time: 2.26129
Timestep Consumption Time: 2.41193
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.67322

Cumulative Model Updates: 367,648
Cumulative Timesteps: 3,066,219,752

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.88639
Policy Entropy: 3.94440
Value Function Loss: 0.00662

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02724
Policy Update Magnitude: 0.24915
Value Function Update Magnitude: 0.35574

Collected Steps per Second: 22,525.18870
Overall Steps per Second: 10,549.04459

Timestep Collection Time: 2.22000
Timestep Consumption Time: 2.52033
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.74033

Cumulative Model Updates: 367,654
Cumulative Timesteps: 3,066,269,758

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3066269758...
Checkpoint 3066269758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.90317
Policy Entropy: 3.95555
Value Function Loss: 0.00668

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.24709
Value Function Update Magnitude: 0.35690

Collected Steps per Second: 22,372.05625
Overall Steps per Second: 10,546.33789

Timestep Collection Time: 2.23520
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.74155

Cumulative Model Updates: 367,660
Cumulative Timesteps: 3,066,319,764

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.59673
Policy Entropy: 3.92941
Value Function Loss: 0.00726

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.25298
Value Function Update Magnitude: 0.36508

Collected Steps per Second: 22,461.40078
Overall Steps per Second: 10,874.80528

Timestep Collection Time: 2.22702
Timestep Consumption Time: 2.37279
PPO Batch Consumption Time: 0.28044
Total Iteration Time: 4.59981

Cumulative Model Updates: 367,666
Cumulative Timesteps: 3,066,369,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3066369786...
Checkpoint 3066369786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.80247
Policy Entropy: 3.97805
Value Function Loss: 0.00645

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.24781
Value Function Update Magnitude: 0.35722

Collected Steps per Second: 22,217.24479
Overall Steps per Second: 10,622.04178

Timestep Collection Time: 2.25149
Timestep Consumption Time: 2.45777
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.70926

Cumulative Model Updates: 367,672
Cumulative Timesteps: 3,066,419,808

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.93356
Policy Entropy: 3.95882
Value Function Loss: 0.00698

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.03109
Policy Update Magnitude: 0.24570
Value Function Update Magnitude: 0.34045

Collected Steps per Second: 22,306.09153
Overall Steps per Second: 10,551.44260

Timestep Collection Time: 2.24262
Timestep Consumption Time: 2.49835
PPO Batch Consumption Time: 0.29385
Total Iteration Time: 4.74096

Cumulative Model Updates: 367,678
Cumulative Timesteps: 3,066,469,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3066469832...
Checkpoint 3066469832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.31890
Policy Entropy: 3.98709
Value Function Loss: 0.00609

Mean KL Divergence: 0.00591
SB3 Clip Fraction: 0.03877
Policy Update Magnitude: 0.24489
Value Function Update Magnitude: 0.33651

Collected Steps per Second: 22,327.94116
Overall Steps per Second: 10,683.02649

Timestep Collection Time: 2.24051
Timestep Consumption Time: 2.44224
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.68276

Cumulative Model Updates: 367,684
Cumulative Timesteps: 3,066,519,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.74085
Policy Entropy: 3.97749
Value Function Loss: 0.00570

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.04196
Policy Update Magnitude: 0.23469
Value Function Update Magnitude: 0.31203

Collected Steps per Second: 22,819.67614
Overall Steps per Second: 10,740.34680

Timestep Collection Time: 2.19135
Timestep Consumption Time: 2.46455
PPO Batch Consumption Time: 0.28020
Total Iteration Time: 4.65590

Cumulative Model Updates: 367,690
Cumulative Timesteps: 3,066,569,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3066569864...
Checkpoint 3066569864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.33847
Policy Entropy: 4.01497
Value Function Loss: 0.00464

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.03725
Policy Update Magnitude: 0.22689
Value Function Update Magnitude: 0.29053

Collected Steps per Second: 22,272.91112
Overall Steps per Second: 10,678.29051

Timestep Collection Time: 2.24542
Timestep Consumption Time: 2.43810
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.68352

Cumulative Model Updates: 367,696
Cumulative Timesteps: 3,066,619,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.20193
Policy Entropy: 4.02641
Value Function Loss: 0.00430

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02827
Policy Update Magnitude: 0.21638
Value Function Update Magnitude: 0.27475

Collected Steps per Second: 23,046.96128
Overall Steps per Second: 10,736.70914

Timestep Collection Time: 2.16992
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.65785

Cumulative Model Updates: 367,702
Cumulative Timesteps: 3,066,669,886

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3066669886...
Checkpoint 3066669886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.01914
Policy Entropy: 4.02346
Value Function Loss: 0.00489

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.21008
Value Function Update Magnitude: 0.28084

Collected Steps per Second: 22,272.52709
Overall Steps per Second: 10,572.83382

Timestep Collection Time: 2.24591
Timestep Consumption Time: 2.48528
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.73118

Cumulative Model Updates: 367,708
Cumulative Timesteps: 3,066,719,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.87356
Policy Entropy: 3.99811
Value Function Loss: 0.00617

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02302
Policy Update Magnitude: 0.22280
Value Function Update Magnitude: 0.30675

Collected Steps per Second: 22,680.20919
Overall Steps per Second: 10,732.32680

Timestep Collection Time: 2.20509
Timestep Consumption Time: 2.45485
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.65994

Cumulative Model Updates: 367,714
Cumulative Timesteps: 3,066,769,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3066769920...
Checkpoint 3066769920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.43148
Policy Entropy: 3.98995
Value Function Loss: 0.00657

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.23940
Value Function Update Magnitude: 0.31579

Collected Steps per Second: 23,138.46580
Overall Steps per Second: 10,711.82255

Timestep Collection Time: 2.16220
Timestep Consumption Time: 2.50834
PPO Batch Consumption Time: 0.29333
Total Iteration Time: 4.67054

Cumulative Model Updates: 367,720
Cumulative Timesteps: 3,066,819,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.11136
Policy Entropy: 3.99466
Value Function Loss: 0.00668

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02406
Policy Update Magnitude: 0.23837
Value Function Update Magnitude: 0.31581

Collected Steps per Second: 22,583.70517
Overall Steps per Second: 10,597.71884

Timestep Collection Time: 2.21505
Timestep Consumption Time: 2.50521
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.72026

Cumulative Model Updates: 367,726
Cumulative Timesteps: 3,066,869,974

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3066869974...
Checkpoint 3066869974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.42639
Policy Entropy: 4.02537
Value Function Loss: 0.00555

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02413
Policy Update Magnitude: 0.22688
Value Function Update Magnitude: 0.31444

Collected Steps per Second: 22,345.21644
Overall Steps per Second: 10,867.19938

Timestep Collection Time: 2.23797
Timestep Consumption Time: 2.36376
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.60174

Cumulative Model Updates: 367,732
Cumulative Timesteps: 3,066,919,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.35869
Policy Entropy: 4.01815
Value Function Loss: 0.00593

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02196
Policy Update Magnitude: 0.22750
Value Function Update Magnitude: 0.31758

Collected Steps per Second: 22,528.40098
Overall Steps per Second: 10,531.41146

Timestep Collection Time: 2.21951
Timestep Consumption Time: 2.52838
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.74789

Cumulative Model Updates: 367,738
Cumulative Timesteps: 3,066,969,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3066969984...
Checkpoint 3066969984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.14191
Policy Entropy: 4.00045
Value Function Loss: 0.00588

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.22847
Value Function Update Magnitude: 0.32273

Collected Steps per Second: 22,493.98115
Overall Steps per Second: 10,603.48286

Timestep Collection Time: 2.22397
Timestep Consumption Time: 2.49391
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.71788

Cumulative Model Updates: 367,744
Cumulative Timesteps: 3,067,020,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.32432
Policy Entropy: 3.97338
Value Function Loss: 0.00625

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02200
Policy Update Magnitude: 0.22718
Value Function Update Magnitude: 0.33091

Collected Steps per Second: 22,111.20396
Overall Steps per Second: 10,772.58385

Timestep Collection Time: 2.26193
Timestep Consumption Time: 2.38078
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.64271

Cumulative Model Updates: 367,750
Cumulative Timesteps: 3,067,070,024

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3067070024...
Checkpoint 3067070024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.44714
Policy Entropy: 3.96997
Value Function Loss: 0.00627

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02367
Policy Update Magnitude: 0.22513
Value Function Update Magnitude: 0.32904

Collected Steps per Second: 22,265.85253
Overall Steps per Second: 10,671.78614

Timestep Collection Time: 2.24640
Timestep Consumption Time: 2.44054
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.68694

Cumulative Model Updates: 367,756
Cumulative Timesteps: 3,067,120,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.02794
Policy Entropy: 4.01170
Value Function Loss: 0.00561

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02114
Policy Update Magnitude: 0.22303
Value Function Update Magnitude: 0.32884

Collected Steps per Second: 22,582.15731
Overall Steps per Second: 10,586.31784

Timestep Collection Time: 2.21476
Timestep Consumption Time: 2.50964
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.72440

Cumulative Model Updates: 367,762
Cumulative Timesteps: 3,067,170,056

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3067170056...
Checkpoint 3067170056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.50677
Policy Entropy: 3.98992
Value Function Loss: 0.00580

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02151
Policy Update Magnitude: 0.22131
Value Function Update Magnitude: 0.32127

Collected Steps per Second: 22,584.90998
Overall Steps per Second: 10,756.56099

Timestep Collection Time: 2.21520
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.65111

Cumulative Model Updates: 367,768
Cumulative Timesteps: 3,067,220,086

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.35873
Policy Entropy: 4.01984
Value Function Loss: 0.00561

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02124
Policy Update Magnitude: 0.21982
Value Function Update Magnitude: 0.31494

Collected Steps per Second: 22,631.13427
Overall Steps per Second: 10,714.08620

Timestep Collection Time: 2.21014
Timestep Consumption Time: 2.45829
PPO Batch Consumption Time: 0.27976
Total Iteration Time: 4.66843

Cumulative Model Updates: 367,774
Cumulative Timesteps: 3,067,270,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3067270104...
Checkpoint 3067270104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.80568
Policy Entropy: 4.01673
Value Function Loss: 0.00577

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02439
Policy Update Magnitude: 0.22447
Value Function Update Magnitude: 0.32852

Collected Steps per Second: 22,377.65291
Overall Steps per Second: 10,681.01574

Timestep Collection Time: 2.23562
Timestep Consumption Time: 2.44820
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.68382

Cumulative Model Updates: 367,780
Cumulative Timesteps: 3,067,320,132

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.37901
Policy Entropy: 4.04058
Value Function Loss: 0.00565

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.23293
Value Function Update Magnitude: 0.33454

Collected Steps per Second: 22,475.85245
Overall Steps per Second: 10,848.93420

Timestep Collection Time: 2.22648
Timestep Consumption Time: 2.38614
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.61262

Cumulative Model Updates: 367,786
Cumulative Timesteps: 3,067,370,174

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 3067370174...
Checkpoint 3067370174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.21166
Policy Entropy: 4.02984
Value Function Loss: 0.00622

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02088
Policy Update Magnitude: 0.23563
Value Function Update Magnitude: 0.34844

Collected Steps per Second: 22,318.12310
Overall Steps per Second: 10,531.56675

Timestep Collection Time: 2.24060
Timestep Consumption Time: 2.50760
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.74820

Cumulative Model Updates: 367,792
Cumulative Timesteps: 3,067,420,180

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.74957
Policy Entropy: 3.99277
Value Function Loss: 0.00615

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.25504
Value Function Update Magnitude: 0.35746

Collected Steps per Second: 22,444.76277
Overall Steps per Second: 10,665.97334

Timestep Collection Time: 2.22912
Timestep Consumption Time: 2.46169
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.69080

Cumulative Model Updates: 367,798
Cumulative Timesteps: 3,067,470,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3067470212...
Checkpoint 3067470212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.51551
Policy Entropy: 4.00894
Value Function Loss: 0.00676

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.24792
Value Function Update Magnitude: 0.35641

Collected Steps per Second: 23,282.87624
Overall Steps per Second: 10,749.48015

Timestep Collection Time: 2.14870
Timestep Consumption Time: 2.50529
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.65399

Cumulative Model Updates: 367,804
Cumulative Timesteps: 3,067,520,240

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.92010
Policy Entropy: 3.98282
Value Function Loss: 0.00648

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02942
Policy Update Magnitude: 0.23501
Value Function Update Magnitude: 0.34647

Collected Steps per Second: 22,908.02876
Overall Steps per Second: 10,774.72138

Timestep Collection Time: 2.18299
Timestep Consumption Time: 2.45824
PPO Batch Consumption Time: 0.27967
Total Iteration Time: 4.64123

Cumulative Model Updates: 367,810
Cumulative Timesteps: 3,067,570,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3067570248...
Checkpoint 3067570248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.34666
Policy Entropy: 3.97876
Value Function Loss: 0.00665

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.23296
Value Function Update Magnitude: 0.32990

Collected Steps per Second: 22,322.36697
Overall Steps per Second: 10,585.80935

Timestep Collection Time: 2.24071
Timestep Consumption Time: 2.48429
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.72500

Cumulative Model Updates: 367,816
Cumulative Timesteps: 3,067,620,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.58154
Policy Entropy: 3.93052
Value Function Loss: 0.00656

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.23972
Value Function Update Magnitude: 0.33282

Collected Steps per Second: 22,583.59812
Overall Steps per Second: 10,884.31951

Timestep Collection Time: 2.21462
Timestep Consumption Time: 2.38043
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.59505

Cumulative Model Updates: 367,822
Cumulative Timesteps: 3,067,670,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3067670280...
Checkpoint 3067670280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.05556
Policy Entropy: 3.96361
Value Function Loss: 0.00597

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.24377
Value Function Update Magnitude: 0.34393

Collected Steps per Second: 22,488.81766
Overall Steps per Second: 10,744.86245

Timestep Collection Time: 2.22333
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.65339

Cumulative Model Updates: 367,828
Cumulative Timesteps: 3,067,720,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.10984
Policy Entropy: 3.96268
Value Function Loss: 0.00528

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02704
Policy Update Magnitude: 0.24335
Value Function Update Magnitude: 0.34567

Collected Steps per Second: 22,571.59022
Overall Steps per Second: 10,760.87144

Timestep Collection Time: 2.21633
Timestep Consumption Time: 2.43255
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.64888

Cumulative Model Updates: 367,834
Cumulative Timesteps: 3,067,770,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3067770306...
Checkpoint 3067770306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.54553
Policy Entropy: 3.99459
Value Function Loss: 0.00556

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.23349
Value Function Update Magnitude: 0.32988

Collected Steps per Second: 22,855.27145
Overall Steps per Second: 10,776.12577

Timestep Collection Time: 2.18873
Timestep Consumption Time: 2.45338
PPO Batch Consumption Time: 0.27951
Total Iteration Time: 4.64211

Cumulative Model Updates: 367,840
Cumulative Timesteps: 3,067,820,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.04492
Policy Entropy: 4.00775
Value Function Loss: 0.00506

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.23402
Value Function Update Magnitude: 0.32497

Collected Steps per Second: 22,534.19816
Overall Steps per Second: 10,552.38433

Timestep Collection Time: 2.21991
Timestep Consumption Time: 2.52063
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.74054

Cumulative Model Updates: 367,846
Cumulative Timesteps: 3,067,870,354

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3067870354...
Checkpoint 3067870354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.15698
Policy Entropy: 4.02254
Value Function Loss: 0.00566

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02148
Policy Update Magnitude: 0.23402
Value Function Update Magnitude: 0.32123

Collected Steps per Second: 22,289.22416
Overall Steps per Second: 10,723.03488

Timestep Collection Time: 2.24431
Timestep Consumption Time: 2.42078
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.66510

Cumulative Model Updates: 367,852
Cumulative Timesteps: 3,067,920,378

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.90001
Policy Entropy: 4.00822
Value Function Loss: 0.00577

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02341
Policy Update Magnitude: 0.24091
Value Function Update Magnitude: 0.33614

Collected Steps per Second: 22,841.58503
Overall Steps per Second: 10,782.24228

Timestep Collection Time: 2.19039
Timestep Consumption Time: 2.44983
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.64022

Cumulative Model Updates: 367,858
Cumulative Timesteps: 3,067,970,410

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3067970410...
Checkpoint 3067970410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.73475
Policy Entropy: 3.95665
Value Function Loss: 0.00635

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 0.25224
Value Function Update Magnitude: 0.34397

Collected Steps per Second: 21,916.49213
Overall Steps per Second: 10,633.75694

Timestep Collection Time: 2.28157
Timestep Consumption Time: 2.42081
PPO Batch Consumption Time: 0.27914
Total Iteration Time: 4.70238

Cumulative Model Updates: 367,864
Cumulative Timesteps: 3,068,020,414

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.84047
Policy Entropy: 3.93387
Value Function Loss: 0.00663

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.03176
Policy Update Magnitude: 0.25053
Value Function Update Magnitude: 0.34110

Collected Steps per Second: 22,591.09406
Overall Steps per Second: 10,904.87623

Timestep Collection Time: 2.21397
Timestep Consumption Time: 2.37260
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.58657

Cumulative Model Updates: 367,870
Cumulative Timesteps: 3,068,070,430

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3068070430...
Checkpoint 3068070430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.02309
Policy Entropy: 3.94340
Value Function Loss: 0.00645

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02870
Policy Update Magnitude: 0.25195
Value Function Update Magnitude: 0.33685

Collected Steps per Second: 22,274.77288
Overall Steps per Second: 10,673.51306

Timestep Collection Time: 2.24541
Timestep Consumption Time: 2.44058
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.68599

Cumulative Model Updates: 367,876
Cumulative Timesteps: 3,068,120,446

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.63903
Policy Entropy: 3.96480
Value Function Loss: 0.00646

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.25898
Value Function Update Magnitude: 0.33647

Collected Steps per Second: 22,452.35845
Overall Steps per Second: 10,762.56533

Timestep Collection Time: 2.22712
Timestep Consumption Time: 2.41899
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.64610

Cumulative Model Updates: 367,882
Cumulative Timesteps: 3,068,170,450

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3068170450...
Checkpoint 3068170450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.64475
Policy Entropy: 4.00333
Value Function Loss: 0.00608

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02914
Policy Update Magnitude: 0.23698
Value Function Update Magnitude: 0.32879

Collected Steps per Second: 22,946.56522
Overall Steps per Second: 10,742.68317

Timestep Collection Time: 2.17993
Timestep Consumption Time: 2.47644
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.65638

Cumulative Model Updates: 367,888
Cumulative Timesteps: 3,068,220,472

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.28649
Policy Entropy: 4.03708
Value Function Loss: 0.00550

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.22245
Value Function Update Magnitude: 0.31291

Collected Steps per Second: 22,573.30437
Overall Steps per Second: 10,578.56635

Timestep Collection Time: 2.21660
Timestep Consumption Time: 2.51334
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.72994

Cumulative Model Updates: 367,894
Cumulative Timesteps: 3,068,270,508

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 3068270508...
Checkpoint 3068270508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.26139
Policy Entropy: 4.03403
Value Function Loss: 0.00530

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02315
Policy Update Magnitude: 0.21194
Value Function Update Magnitude: 0.29118

Collected Steps per Second: 22,405.23263
Overall Steps per Second: 10,891.09920

Timestep Collection Time: 2.23251
Timestep Consumption Time: 2.36023
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.59274

Cumulative Model Updates: 367,900
Cumulative Timesteps: 3,068,320,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.86765
Policy Entropy: 4.03022
Value Function Loss: 0.00469

Mean KL Divergence: 0.00256
SB3 Clip Fraction: 0.01931
Policy Update Magnitude: 0.20917
Value Function Update Magnitude: 0.29724

Collected Steps per Second: 22,912.65368
Overall Steps per Second: 10,635.64314

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.51907
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.70136

Cumulative Model Updates: 367,906
Cumulative Timesteps: 3,068,370,530

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3068370530...
Checkpoint 3068370530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.13940
Policy Entropy: 3.98193
Value Function Loss: 0.00493

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.21378
Value Function Update Magnitude: 0.30724

Collected Steps per Second: 22,502.76560
Overall Steps per Second: 10,537.64848

Timestep Collection Time: 2.22239
Timestep Consumption Time: 2.52345
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.74584

Cumulative Model Updates: 367,912
Cumulative Timesteps: 3,068,420,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.32895
Policy Entropy: 4.00474
Value Function Loss: 0.00513

Mean KL Divergence: 0.00249
SB3 Clip Fraction: 0.01987
Policy Update Magnitude: 0.22781
Value Function Update Magnitude: 0.32449

Collected Steps per Second: 22,394.65953
Overall Steps per Second: 10,840.28509

Timestep Collection Time: 2.23321
Timestep Consumption Time: 2.38032
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61353

Cumulative Model Updates: 367,918
Cumulative Timesteps: 3,068,470,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3068470552...
Checkpoint 3068470552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.67243
Policy Entropy: 3.98105
Value Function Loss: 0.00595

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02388
Policy Update Magnitude: 0.24567
Value Function Update Magnitude: 0.33459

Collected Steps per Second: 22,453.81026
Overall Steps per Second: 10,702.11838

Timestep Collection Time: 2.22697
Timestep Consumption Time: 2.44537
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.67235

Cumulative Model Updates: 367,924
Cumulative Timesteps: 3,068,520,556

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.04193
Policy Entropy: 3.99156
Value Function Loss: 0.00698

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.24583
Value Function Update Magnitude: 0.34609

Collected Steps per Second: 22,563.37111
Overall Steps per Second: 10,650.65552

Timestep Collection Time: 2.21660
Timestep Consumption Time: 2.47926
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.69586

Cumulative Model Updates: 367,930
Cumulative Timesteps: 3,068,570,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3068570570...
Checkpoint 3068570570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.95276
Policy Entropy: 3.94968
Value Function Loss: 0.00722

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02626
Policy Update Magnitude: 0.23943
Value Function Update Magnitude: 0.35553

Collected Steps per Second: 22,250.44795
Overall Steps per Second: 10,719.12805

Timestep Collection Time: 2.24822
Timestep Consumption Time: 2.41857
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.66680

Cumulative Model Updates: 367,936
Cumulative Timesteps: 3,068,620,594

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.46116
Policy Entropy: 3.95416
Value Function Loss: 0.00720

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02730
Policy Update Magnitude: 0.25141
Value Function Update Magnitude: 0.34979

Collected Steps per Second: 22,423.08178
Overall Steps per Second: 10,681.34140

Timestep Collection Time: 2.23047
Timestep Consumption Time: 2.45190
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.68237

Cumulative Model Updates: 367,942
Cumulative Timesteps: 3,068,670,608

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3068670608...
Checkpoint 3068670608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.24634
Policy Entropy: 3.95698
Value Function Loss: 0.00621

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02888
Policy Update Magnitude: 0.25407
Value Function Update Magnitude: 0.33616

Collected Steps per Second: 22,040.18130
Overall Steps per Second: 10,676.26990

Timestep Collection Time: 2.26967
Timestep Consumption Time: 2.41586
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.68553

Cumulative Model Updates: 367,948
Cumulative Timesteps: 3,068,720,632

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.41360
Policy Entropy: 3.98098
Value Function Loss: 0.00614

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.24097
Value Function Update Magnitude: 0.33957

Collected Steps per Second: 23,360.55991
Overall Steps per Second: 10,862.95260

Timestep Collection Time: 2.14062
Timestep Consumption Time: 2.46274
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.60335

Cumulative Model Updates: 367,954
Cumulative Timesteps: 3,068,770,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3068770638...
Checkpoint 3068770638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.82793
Policy Entropy: 3.99787
Value Function Loss: 0.00556

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02729
Policy Update Magnitude: 0.23551
Value Function Update Magnitude: 0.34128

Collected Steps per Second: 22,449.24152
Overall Steps per Second: 10,679.72745

Timestep Collection Time: 2.22760
Timestep Consumption Time: 2.45491
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.68252

Cumulative Model Updates: 367,960
Cumulative Timesteps: 3,068,820,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.38718
Policy Entropy: 3.97542
Value Function Loss: 0.00608

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02935
Policy Update Magnitude: 0.24278
Value Function Update Magnitude: 0.33371

Collected Steps per Second: 22,237.74527
Overall Steps per Second: 10,838.67869

Timestep Collection Time: 2.24870
Timestep Consumption Time: 2.36496
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.61366

Cumulative Model Updates: 367,966
Cumulative Timesteps: 3,068,870,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3068870652...
Checkpoint 3068870652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.32946
Policy Entropy: 3.97693
Value Function Loss: 0.00563

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.24985
Value Function Update Magnitude: 0.35056

Collected Steps per Second: 22,424.52549
Overall Steps per Second: 10,677.44040

Timestep Collection Time: 2.23033
Timestep Consumption Time: 2.45376
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.68408

Cumulative Model Updates: 367,972
Cumulative Timesteps: 3,068,920,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.53898
Policy Entropy: 3.97012
Value Function Loss: 0.00566

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02715
Policy Update Magnitude: 0.25148
Value Function Update Magnitude: 0.35930

Collected Steps per Second: 22,563.62725
Overall Steps per Second: 10,519.64174

Timestep Collection Time: 2.21649
Timestep Consumption Time: 2.53767
PPO Batch Consumption Time: 0.29449
Total Iteration Time: 4.75415

Cumulative Model Updates: 367,978
Cumulative Timesteps: 3,068,970,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3068970678...
Checkpoint 3068970678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.27324
Policy Entropy: 3.96929
Value Function Loss: 0.00630

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02632
Policy Update Magnitude: 0.24469
Value Function Update Magnitude: 0.34343

Collected Steps per Second: 22,040.00799
Overall Steps per Second: 10,622.98364

Timestep Collection Time: 2.27042
Timestep Consumption Time: 2.44012
PPO Batch Consumption Time: 0.29408
Total Iteration Time: 4.71054

Cumulative Model Updates: 367,984
Cumulative Timesteps: 3,069,020,718

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.28428
Policy Entropy: 3.94926
Value Function Loss: 0.00649

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.24084
Value Function Update Magnitude: 0.33670

Collected Steps per Second: 22,604.92772
Overall Steps per Second: 10,634.25140

Timestep Collection Time: 2.21226
Timestep Consumption Time: 2.49028
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.70254

Cumulative Model Updates: 367,990
Cumulative Timesteps: 3,069,070,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3069070726...
Checkpoint 3069070726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.95062
Policy Entropy: 3.95711
Value Function Loss: 0.00733

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02958
Policy Update Magnitude: 0.24691
Value Function Update Magnitude: 0.33612

Collected Steps per Second: 22,417.11202
Overall Steps per Second: 10,657.05804

Timestep Collection Time: 2.23115
Timestep Consumption Time: 2.46208
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.69323

Cumulative Model Updates: 367,996
Cumulative Timesteps: 3,069,120,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.56250
Policy Entropy: 3.96736
Value Function Loss: 0.00770

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02867
Policy Update Magnitude: 0.25132
Value Function Update Magnitude: 0.33633

Collected Steps per Second: 22,752.86986
Overall Steps per Second: 10,776.80030

Timestep Collection Time: 2.19884
Timestep Consumption Time: 2.44354
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.64238

Cumulative Model Updates: 368,002
Cumulative Timesteps: 3,069,170,772

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3069170772...
Checkpoint 3069170772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.82353
Policy Entropy: 4.00813
Value Function Loss: 0.00703

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 0.24631
Value Function Update Magnitude: 0.35023

Collected Steps per Second: 22,608.84275
Overall Steps per Second: 10,547.46319

Timestep Collection Time: 2.21214
Timestep Consumption Time: 2.52966
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.74180

Cumulative Model Updates: 368,008
Cumulative Timesteps: 3,069,220,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.21052
Policy Entropy: 3.99900
Value Function Loss: 0.00726

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03021
Policy Update Magnitude: 0.24166
Value Function Update Magnitude: 0.34827

Collected Steps per Second: 22,374.35743
Overall Steps per Second: 10,614.47535

Timestep Collection Time: 2.23506
Timestep Consumption Time: 2.47624
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.71130

Cumulative Model Updates: 368,014
Cumulative Timesteps: 3,069,270,794

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3069270794...
Checkpoint 3069270794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.86565
Policy Entropy: 4.02338
Value Function Loss: 0.00631

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02948
Policy Update Magnitude: 0.23022
Value Function Update Magnitude: 0.35157

Collected Steps per Second: 22,560.93086
Overall Steps per Second: 10,918.41889

Timestep Collection Time: 2.21711
Timestep Consumption Time: 2.36414
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.58125

Cumulative Model Updates: 368,020
Cumulative Timesteps: 3,069,320,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.80013
Policy Entropy: 4.02181
Value Function Loss: 0.00559

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.22555
Value Function Update Magnitude: 0.34919

Collected Steps per Second: 22,682.43512
Overall Steps per Second: 10,611.82428

Timestep Collection Time: 2.20523
Timestep Consumption Time: 2.50838
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.71361

Cumulative Model Updates: 368,026
Cumulative Timesteps: 3,069,370,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3069370834...
Checkpoint 3069370834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.49789
Policy Entropy: 4.02875
Value Function Loss: 0.00527

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.21842
Value Function Update Magnitude: 0.33214

Collected Steps per Second: 21,849.41113
Overall Steps per Second: 10,512.16767

Timestep Collection Time: 2.28867
Timestep Consumption Time: 2.46830
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.75696

Cumulative Model Updates: 368,032
Cumulative Timesteps: 3,069,420,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.81734
Policy Entropy: 4.02224
Value Function Loss: 0.00510

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02424
Policy Update Magnitude: 0.21996
Value Function Update Magnitude: 0.33024

Collected Steps per Second: 23,480.86448
Overall Steps per Second: 10,884.98681

Timestep Collection Time: 2.13042
Timestep Consumption Time: 2.46527
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.59569

Cumulative Model Updates: 368,038
Cumulative Timesteps: 3,069,470,864

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3069470864...
Checkpoint 3069470864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.95012
Policy Entropy: 3.99595
Value Function Loss: 0.00539

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02304
Policy Update Magnitude: 0.22698
Value Function Update Magnitude: 0.32127

Collected Steps per Second: 22,338.02154
Overall Steps per Second: 10,707.82876

Timestep Collection Time: 2.23887
Timestep Consumption Time: 2.43173
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.67060

Cumulative Model Updates: 368,044
Cumulative Timesteps: 3,069,520,876

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.30629
Policy Entropy: 3.97087
Value Function Loss: 0.00639

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02358
Policy Update Magnitude: 0.24283
Value Function Update Magnitude: 0.31936

Collected Steps per Second: 22,568.24438
Overall Steps per Second: 10,645.18732

Timestep Collection Time: 2.21719
Timestep Consumption Time: 2.48334
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.70053

Cumulative Model Updates: 368,050
Cumulative Timesteps: 3,069,570,914

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3069570914...
Checkpoint 3069570914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.88025
Policy Entropy: 3.99856
Value Function Loss: 0.00616

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.24325
Value Function Update Magnitude: 0.34096

Collected Steps per Second: 22,865.95437
Overall Steps per Second: 10,643.93758

Timestep Collection Time: 2.18727
Timestep Consumption Time: 2.51156
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.69882

Cumulative Model Updates: 368,056
Cumulative Timesteps: 3,069,620,928

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73.28423
Policy Entropy: 3.98350
Value Function Loss: 0.00580

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02836
Policy Update Magnitude: 0.23519
Value Function Update Magnitude: 0.32999

Collected Steps per Second: 22,660.52850
Overall Steps per Second: 10,665.73679

Timestep Collection Time: 2.20772
Timestep Consumption Time: 2.48282
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.69053

Cumulative Model Updates: 368,062
Cumulative Timesteps: 3,069,670,956

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3069670956...
Checkpoint 3069670956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.87825
Policy Entropy: 3.98105
Value Function Loss: 0.00615

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02249
Policy Update Magnitude: 0.23194
Value Function Update Magnitude: 0.30760

Collected Steps per Second: 21,957.17766
Overall Steps per Second: 10,632.41233

Timestep Collection Time: 2.27780
Timestep Consumption Time: 2.42612
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.70392

Cumulative Model Updates: 368,068
Cumulative Timesteps: 3,069,720,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.92600
Policy Entropy: 3.95733
Value Function Loss: 0.00621

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02581
Policy Update Magnitude: 0.23640
Value Function Update Magnitude: 0.30643

Collected Steps per Second: 23,345.18420
Overall Steps per Second: 10,884.96976

Timestep Collection Time: 2.14280
Timestep Consumption Time: 2.45290
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.59569

Cumulative Model Updates: 368,074
Cumulative Timesteps: 3,069,770,994

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3069770994...
Checkpoint 3069770994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.88444
Policy Entropy: 3.97474
Value Function Loss: 0.00678

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.23492
Value Function Update Magnitude: 0.31513

Collected Steps per Second: 22,435.46931
Overall Steps per Second: 10,676.90675

Timestep Collection Time: 2.22870
Timestep Consumption Time: 2.45449
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.68319

Cumulative Model Updates: 368,080
Cumulative Timesteps: 3,069,820,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.54557
Policy Entropy: 3.98564
Value Function Loss: 0.00583

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.23504
Value Function Update Magnitude: 0.30891

Collected Steps per Second: 22,562.51290
Overall Steps per Second: 10,610.52197

Timestep Collection Time: 2.21624
Timestep Consumption Time: 2.49644
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.71268

Cumulative Model Updates: 368,086
Cumulative Timesteps: 3,069,871,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3069871000...
Checkpoint 3069871000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.04196
Policy Entropy: 3.95595
Value Function Loss: 0.00600

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02566
Policy Update Magnitude: 0.22931
Value Function Update Magnitude: 0.30888

Collected Steps per Second: 23,241.37483
Overall Steps per Second: 10,908.34515

Timestep Collection Time: 2.15194
Timestep Consumption Time: 2.43299
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.58493

Cumulative Model Updates: 368,092
Cumulative Timesteps: 3,069,921,014

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.25308
Policy Entropy: 3.94829
Value Function Loss: 0.00627

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02733
Policy Update Magnitude: 0.24355
Value Function Update Magnitude: 0.31254

Collected Steps per Second: 22,739.13144
Overall Steps per Second: 10,598.90848

Timestep Collection Time: 2.19938
Timestep Consumption Time: 2.51922
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.71860

Cumulative Model Updates: 368,098
Cumulative Timesteps: 3,069,971,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3069971026...
Checkpoint 3069971026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.29708
Policy Entropy: 3.93639
Value Function Loss: 0.00683

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.03255
Policy Update Magnitude: 0.24970
Value Function Update Magnitude: 0.31654

Collected Steps per Second: 22,128.37119
Overall Steps per Second: 10,675.43669

Timestep Collection Time: 2.25963
Timestep Consumption Time: 2.42420
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.68384

Cumulative Model Updates: 368,104
Cumulative Timesteps: 3,070,021,028

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.97475
Policy Entropy: 3.94392
Value Function Loss: 0.00665

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02720
Policy Update Magnitude: 0.25962
Value Function Update Magnitude: 0.33973

Collected Steps per Second: 22,929.10593
Overall Steps per Second: 10,820.55258

Timestep Collection Time: 2.18090
Timestep Consumption Time: 2.44049
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.62139

Cumulative Model Updates: 368,110
Cumulative Timesteps: 3,070,071,034

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3070071034...
Checkpoint 3070071034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.94485
Policy Entropy: 3.95529
Value Function Loss: 0.00600

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02926
Policy Update Magnitude: 0.25436
Value Function Update Magnitude: 0.34925

Collected Steps per Second: 22,283.09898
Overall Steps per Second: 10,597.48783

Timestep Collection Time: 2.24457
Timestep Consumption Time: 2.47504
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.71961

Cumulative Model Updates: 368,116
Cumulative Timesteps: 3,070,121,050

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.17874
Policy Entropy: 3.97907
Value Function Loss: 0.00542

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02669
Policy Update Magnitude: 0.24170
Value Function Update Magnitude: 0.33306

Collected Steps per Second: 22,554.98098
Overall Steps per Second: 10,876.76443

Timestep Collection Time: 2.21725
Timestep Consumption Time: 2.38063
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.59787

Cumulative Model Updates: 368,122
Cumulative Timesteps: 3,070,171,060

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3070171060...
Checkpoint 3070171060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.64750
Policy Entropy: 3.99988
Value Function Loss: 0.00545

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02529
Policy Update Magnitude: 0.23307
Value Function Update Magnitude: 0.32168

Collected Steps per Second: 22,429.89816
Overall Steps per Second: 10,658.18218

Timestep Collection Time: 2.22970
Timestep Consumption Time: 2.46265
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.69236

Cumulative Model Updates: 368,128
Cumulative Timesteps: 3,070,221,072

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.64682
Policy Entropy: 4.00053
Value Function Loss: 0.00597

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02765
Policy Update Magnitude: 0.24979
Value Function Update Magnitude: 0.33221

Collected Steps per Second: 22,218.90243
Overall Steps per Second: 10,468.69129

Timestep Collection Time: 2.25115
Timestep Consumption Time: 2.52672
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.77787

Cumulative Model Updates: 368,134
Cumulative Timesteps: 3,070,271,090

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3070271090...
Checkpoint 3070271090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.25299
Policy Entropy: 3.98751
Value Function Loss: 0.00626

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.03031
Policy Update Magnitude: 0.24995
Value Function Update Magnitude: 0.35681

Collected Steps per Second: 22,324.42108
Overall Steps per Second: 10,656.95142

Timestep Collection Time: 2.23997
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.69234

Cumulative Model Updates: 368,140
Cumulative Timesteps: 3,070,321,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.45771
Policy Entropy: 3.95978
Value Function Loss: 0.00612

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.03207
Policy Update Magnitude: 0.25297
Value Function Update Magnitude: 0.36034

Collected Steps per Second: 22,340.64965
Overall Steps per Second: 10,461.46372

Timestep Collection Time: 2.23852
Timestep Consumption Time: 2.54188
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.78040

Cumulative Model Updates: 368,146
Cumulative Timesteps: 3,070,371,106

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3070371106...
Checkpoint 3070371106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.48658
Policy Entropy: 3.94668
Value Function Loss: 0.00581

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02824
Policy Update Magnitude: 0.25451
Value Function Update Magnitude: 0.36368

Collected Steps per Second: 22,269.66807
Overall Steps per Second: 10,605.39156

Timestep Collection Time: 2.24583
Timestep Consumption Time: 2.47007
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.71590

Cumulative Model Updates: 368,152
Cumulative Timesteps: 3,070,421,120

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.15838
Policy Entropy: 3.93250
Value Function Loss: 0.00600

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.24768
Value Function Update Magnitude: 0.37097

Collected Steps per Second: 22,515.45857
Overall Steps per Second: 10,889.50801

Timestep Collection Time: 2.22230
Timestep Consumption Time: 2.37259
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.59488

Cumulative Model Updates: 368,158
Cumulative Timesteps: 3,070,471,156

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 3070471156...
Checkpoint 3070471156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.85319
Policy Entropy: 3.92425
Value Function Loss: 0.00664

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02906
Policy Update Magnitude: 0.25290
Value Function Update Magnitude: 0.35963

Collected Steps per Second: 22,405.47174
Overall Steps per Second: 10,715.66002

Timestep Collection Time: 2.23169
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.27901
Total Iteration Time: 4.66625

Cumulative Model Updates: 368,164
Cumulative Timesteps: 3,070,521,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.81691
Policy Entropy: 3.94046
Value Function Loss: 0.00697

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.03554
Policy Update Magnitude: 0.26580
Value Function Update Magnitude: 0.34582

Collected Steps per Second: 22,635.41600
Overall Steps per Second: 10,764.01342

Timestep Collection Time: 2.20999
Timestep Consumption Time: 2.43735
PPO Batch Consumption Time: 0.28019
Total Iteration Time: 4.64734

Cumulative Model Updates: 368,170
Cumulative Timesteps: 3,070,571,182

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3070571182...
Checkpoint 3070571182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.43848
Policy Entropy: 3.95755
Value Function Loss: 0.00686

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.03047
Policy Update Magnitude: 0.25056
Value Function Update Magnitude: 0.34271

Collected Steps per Second: 22,897.19926
Overall Steps per Second: 10,738.66595

Timestep Collection Time: 2.18463
Timestep Consumption Time: 2.47349
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.65812

Cumulative Model Updates: 368,176
Cumulative Timesteps: 3,070,621,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.22631
Policy Entropy: 3.98892
Value Function Loss: 0.00586

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02691
Policy Update Magnitude: 0.23904
Value Function Update Magnitude: 0.34827

Collected Steps per Second: 22,483.05612
Overall Steps per Second: 10,524.53029

Timestep Collection Time: 2.22461
Timestep Consumption Time: 2.52772
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.75233

Cumulative Model Updates: 368,182
Cumulative Timesteps: 3,070,671,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3070671220...
Checkpoint 3070671220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.81416
Policy Entropy: 3.92881
Value Function Loss: 0.00620

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02308
Policy Update Magnitude: 0.24219
Value Function Update Magnitude: 0.34024

Collected Steps per Second: 22,198.34124
Overall Steps per Second: 10,599.76734

Timestep Collection Time: 2.25386
Timestep Consumption Time: 2.46624
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.72010

Cumulative Model Updates: 368,188
Cumulative Timesteps: 3,070,721,252

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.16741
Policy Entropy: 3.92355
Value Function Loss: 0.00671

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.26059
Value Function Update Magnitude: 0.34437

Collected Steps per Second: 23,538.26561
Overall Steps per Second: 10,946.29803

Timestep Collection Time: 2.12497
Timestep Consumption Time: 2.44443
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.56940

Cumulative Model Updates: 368,194
Cumulative Timesteps: 3,070,771,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3070771270...
Checkpoint 3070771270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.72664
Policy Entropy: 3.88021
Value Function Loss: 0.00744

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03001
Policy Update Magnitude: 0.26480
Value Function Update Magnitude: 0.36695

Collected Steps per Second: 22,236.86678
Overall Steps per Second: 10,630.98919

Timestep Collection Time: 2.24915
Timestep Consumption Time: 2.45540
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.70455

Cumulative Model Updates: 368,200
Cumulative Timesteps: 3,070,821,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.43576
Policy Entropy: 3.96297
Value Function Loss: 0.00745

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.25959
Value Function Update Magnitude: 0.37674

Collected Steps per Second: 22,458.63961
Overall Steps per Second: 10,863.45438

Timestep Collection Time: 2.22729
Timestep Consumption Time: 2.37732
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.60461

Cumulative Model Updates: 368,206
Cumulative Timesteps: 3,070,871,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3070871306...
Checkpoint 3070871306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.46466
Policy Entropy: 3.95700
Value Function Loss: 0.00771

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03064
Policy Update Magnitude: 0.24968
Value Function Update Magnitude: 0.36460

Collected Steps per Second: 22,397.88028
Overall Steps per Second: 10,705.17154

Timestep Collection Time: 2.23244
Timestep Consumption Time: 2.43838
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.67083

Cumulative Model Updates: 368,212
Cumulative Timesteps: 3,070,921,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.01978
Policy Entropy: 3.99846
Value Function Loss: 0.00705

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02945
Policy Update Magnitude: 0.24224
Value Function Update Magnitude: 0.35270

Collected Steps per Second: 22,825.70697
Overall Steps per Second: 10,752.56033

Timestep Collection Time: 2.19113
Timestep Consumption Time: 2.46023
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.65136

Cumulative Model Updates: 368,218
Cumulative Timesteps: 3,070,971,322

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3070971322...
Checkpoint 3070971322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.03541
Policy Entropy: 3.99231
Value Function Loss: 0.00624

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02823
Policy Update Magnitude: 0.23449
Value Function Update Magnitude: 0.34793

Collected Steps per Second: 22,256.38202
Overall Steps per Second: 10,731.14658

Timestep Collection Time: 2.24709
Timestep Consumption Time: 2.41337
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.66045

Cumulative Model Updates: 368,224
Cumulative Timesteps: 3,071,021,334

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.30671
Policy Entropy: 4.04211
Value Function Loss: 0.00512

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.22225
Value Function Update Magnitude: 0.34505

Collected Steps per Second: 22,790.20253
Overall Steps per Second: 10,615.14696

Timestep Collection Time: 2.19498
Timestep Consumption Time: 2.51753
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.71251

Cumulative Model Updates: 368,230
Cumulative Timesteps: 3,071,071,358

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3071071358...
Checkpoint 3071071358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.62990
Policy Entropy: 4.05501
Value Function Loss: 0.00457

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02439
Policy Update Magnitude: 0.22014
Value Function Update Magnitude: 0.33767

Collected Steps per Second: 22,460.86669
Overall Steps per Second: 10,654.84870

Timestep Collection Time: 2.22716
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.69495

Cumulative Model Updates: 368,236
Cumulative Timesteps: 3,071,121,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.43228
Policy Entropy: 4.03294
Value Function Loss: 0.00490

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02741
Policy Update Magnitude: 0.21559
Value Function Update Magnitude: 0.32216

Collected Steps per Second: 22,739.20548
Overall Steps per Second: 10,745.66373

Timestep Collection Time: 2.19964
Timestep Consumption Time: 2.45508
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.65471

Cumulative Model Updates: 368,242
Cumulative Timesteps: 3,071,171,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3071171400...
Checkpoint 3071171400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.05979
Policy Entropy: 3.99662
Value Function Loss: 0.00597

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02596
Policy Update Magnitude: 0.23074
Value Function Update Magnitude: 0.31153

Collected Steps per Second: 21,989.28817
Overall Steps per Second: 10,549.36227

Timestep Collection Time: 2.27502
Timestep Consumption Time: 2.46707
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.74209

Cumulative Model Updates: 368,248
Cumulative Timesteps: 3,071,221,426

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.44761
Policy Entropy: 3.95510
Value Function Loss: 0.00600

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.24598
Value Function Update Magnitude: 0.31426

Collected Steps per Second: 22,352.61671
Overall Steps per Second: 10,561.05193

Timestep Collection Time: 2.23822
Timestep Consumption Time: 2.49900
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.73722

Cumulative Model Updates: 368,254
Cumulative Timesteps: 3,071,271,456

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3071271456...
Checkpoint 3071271456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.29660
Policy Entropy: 3.96519
Value Function Loss: 0.00579

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 0.24492
Value Function Update Magnitude: 0.31804

Collected Steps per Second: 22,250.93588
Overall Steps per Second: 10,664.96791

Timestep Collection Time: 2.24818
Timestep Consumption Time: 2.44232
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.69050

Cumulative Model Updates: 368,260
Cumulative Timesteps: 3,071,321,480

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.41589
Policy Entropy: 3.98952
Value Function Loss: 0.00570

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.22934
Value Function Update Magnitude: 0.30636

Collected Steps per Second: 22,654.95780
Overall Steps per Second: 10,636.84834

Timestep Collection Time: 2.20808
Timestep Consumption Time: 2.49481
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.70290

Cumulative Model Updates: 368,266
Cumulative Timesteps: 3,071,371,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3071371504...
Checkpoint 3071371504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.79041
Policy Entropy: 3.97927
Value Function Loss: 0.00598

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.23151
Value Function Update Magnitude: 0.30713

Collected Steps per Second: 22,182.71828
Overall Steps per Second: 10,505.34556

Timestep Collection Time: 2.25491
Timestep Consumption Time: 2.50648
PPO Batch Consumption Time: 0.29274
Total Iteration Time: 4.76139

Cumulative Model Updates: 368,272
Cumulative Timesteps: 3,071,421,524

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74061
Policy Entropy: 3.95885
Value Function Loss: 0.00675

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.24648
Value Function Update Magnitude: 0.31666

Collected Steps per Second: 23,336.41705
Overall Steps per Second: 10,886.33917

Timestep Collection Time: 2.14309
Timestep Consumption Time: 2.45093
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.59401

Cumulative Model Updates: 368,278
Cumulative Timesteps: 3,071,471,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3071471536...
Checkpoint 3071471536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.44406
Policy Entropy: 3.93374
Value Function Loss: 0.00659

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.24698
Value Function Update Magnitude: 0.33150

Collected Steps per Second: 22,236.54151
Overall Steps per Second: 10,659.99418

Timestep Collection Time: 2.24918
Timestep Consumption Time: 2.44257
PPO Batch Consumption Time: 0.27938
Total Iteration Time: 4.69175

Cumulative Model Updates: 368,284
Cumulative Timesteps: 3,071,521,550

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.86940
Policy Entropy: 3.91489
Value Function Loss: 0.00698

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02726
Policy Update Magnitude: 0.24960
Value Function Update Magnitude: 0.33568

Collected Steps per Second: 22,759.98753
Overall Steps per Second: 10,822.04292

Timestep Collection Time: 2.19736
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.62131

Cumulative Model Updates: 368,290
Cumulative Timesteps: 3,071,571,562

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3071571562...
Checkpoint 3071571562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.37644
Policy Entropy: 3.86948
Value Function Loss: 0.00794

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02832
Policy Update Magnitude: 0.25694
Value Function Update Magnitude: 0.34549

Collected Steps per Second: 22,218.83671
Overall Steps per Second: 10,627.32918

Timestep Collection Time: 2.25142
Timestep Consumption Time: 2.45569
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.70711

Cumulative Model Updates: 368,296
Cumulative Timesteps: 3,071,621,586

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.30448
Policy Entropy: 3.85810
Value Function Loss: 0.00787

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.03365
Policy Update Magnitude: 0.27176
Value Function Update Magnitude: 0.35795

Collected Steps per Second: 22,053.12737
Overall Steps per Second: 10,526.75609

Timestep Collection Time: 2.26752
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.75037

Cumulative Model Updates: 368,302
Cumulative Timesteps: 3,071,671,592

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3071671592...
Checkpoint 3071671592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.16014
Policy Entropy: 3.88963
Value Function Loss: 0.00707

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.03563
Policy Update Magnitude: 0.26617
Value Function Update Magnitude: 0.36073

Collected Steps per Second: 22,269.27282
Overall Steps per Second: 10,702.72727

Timestep Collection Time: 2.24623
Timestep Consumption Time: 2.42753
PPO Batch Consumption Time: 0.29426
Total Iteration Time: 4.67376

Cumulative Model Updates: 368,308
Cumulative Timesteps: 3,071,721,614

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.96504
Policy Entropy: 3.92950
Value Function Loss: 0.00647

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.03407
Policy Update Magnitude: 0.25271
Value Function Update Magnitude: 0.34416

Collected Steps per Second: 22,731.86546
Overall Steps per Second: 10,734.87913

Timestep Collection Time: 2.20061
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.28007
Total Iteration Time: 4.65995

Cumulative Model Updates: 368,314
Cumulative Timesteps: 3,071,771,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3071771638...
Checkpoint 3071771638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.90677
Policy Entropy: 3.97445
Value Function Loss: 0.00633

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.02934
Policy Update Magnitude: 0.24395
Value Function Update Magnitude: 0.33769

Collected Steps per Second: 22,206.55282
Overall Steps per Second: 10,680.14827

Timestep Collection Time: 2.25195
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.68233

Cumulative Model Updates: 368,320
Cumulative Timesteps: 3,071,821,646

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.21514
Policy Entropy: 3.93087
Value Function Loss: 0.00716

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.03276
Policy Update Magnitude: 0.25099
Value Function Update Magnitude: 0.33194

Collected Steps per Second: 22,326.87732
Overall Steps per Second: 10,756.25837

Timestep Collection Time: 2.24044
Timestep Consumption Time: 2.41006
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.65050

Cumulative Model Updates: 368,326
Cumulative Timesteps: 3,071,871,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3071871668...
Checkpoint 3071871668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.55254
Policy Entropy: 3.95416
Value Function Loss: 0.00633

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02674
Policy Update Magnitude: 0.24984
Value Function Update Magnitude: 0.33918

Collected Steps per Second: 22,424.72318
Overall Steps per Second: 10,578.32386

Timestep Collection Time: 2.23057
Timestep Consumption Time: 2.49796
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.72854

Cumulative Model Updates: 368,332
Cumulative Timesteps: 3,071,921,688

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63310
Policy Entropy: 3.93590
Value Function Loss: 0.00651

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.24095
Value Function Update Magnitude: 0.34166

Collected Steps per Second: 22,587.91585
Overall Steps per Second: 10,789.54338

Timestep Collection Time: 2.21384
Timestep Consumption Time: 2.42083
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.63467

Cumulative Model Updates: 368,338
Cumulative Timesteps: 3,071,971,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3071971694...
Checkpoint 3071971694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.56917
Policy Entropy: 3.99129
Value Function Loss: 0.00560

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.22929
Value Function Update Magnitude: 0.32894

Collected Steps per Second: 21,770.81132
Overall Steps per Second: 10,587.99792

Timestep Collection Time: 2.29785
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.72478

Cumulative Model Updates: 368,344
Cumulative Timesteps: 3,072,021,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.87104
Policy Entropy: 4.00827
Value Function Loss: 0.00587

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.21808
Value Function Update Magnitude: 0.31508

Collected Steps per Second: 22,570.79047
Overall Steps per Second: 10,613.28649

Timestep Collection Time: 2.21614
Timestep Consumption Time: 2.49682
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.71296

Cumulative Model Updates: 368,350
Cumulative Timesteps: 3,072,071,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3072071740...
Checkpoint 3072071740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.86481
Policy Entropy: 4.04888
Value Function Loss: 0.00495

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.20836
Value Function Update Magnitude: 0.31147

Collected Steps per Second: 22,552.29386
Overall Steps per Second: 10,637.33954

Timestep Collection Time: 2.21796
Timestep Consumption Time: 2.48435
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.70230

Cumulative Model Updates: 368,356
Cumulative Timesteps: 3,072,121,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2.10377
Policy Entropy: 4.07403
Value Function Loss: 0.00450

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.01886
Policy Update Magnitude: 0.21231
Value Function Update Magnitude: 0.29953

Collected Steps per Second: 23,500.05259
Overall Steps per Second: 10,764.77036

Timestep Collection Time: 2.12885
Timestep Consumption Time: 2.51854
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.64738

Cumulative Model Updates: 368,362
Cumulative Timesteps: 3,072,171,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3072171788...
Checkpoint 3072171788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.69035
Policy Entropy: 4.06368
Value Function Loss: 0.00456

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02317
Policy Update Magnitude: 0.21180
Value Function Update Magnitude: 0.27861

Collected Steps per Second: 21,944.32030
Overall Steps per Second: 10,568.88201

Timestep Collection Time: 2.27941
Timestep Consumption Time: 2.45336
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.73276

Cumulative Model Updates: 368,368
Cumulative Timesteps: 3,072,221,808

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.83062
Policy Entropy: 4.02823
Value Function Loss: 0.00537

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02297
Policy Update Magnitude: 0.21022
Value Function Update Magnitude: 0.29059

Collected Steps per Second: 22,418.81082
Overall Steps per Second: 10,549.77290

Timestep Collection Time: 2.23072
Timestep Consumption Time: 2.50967
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.74039

Cumulative Model Updates: 368,374
Cumulative Timesteps: 3,072,271,818

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3072271818...
Checkpoint 3072271818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.97579
Policy Entropy: 3.98151
Value Function Loss: 0.00614

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02211
Policy Update Magnitude: 0.21827
Value Function Update Magnitude: 0.31436

Collected Steps per Second: 23,123.69606
Overall Steps per Second: 10,726.66232

Timestep Collection Time: 2.16315
Timestep Consumption Time: 2.50000
PPO Batch Consumption Time: 0.29327
Total Iteration Time: 4.66315

Cumulative Model Updates: 368,380
Cumulative Timesteps: 3,072,321,838

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.11777
Policy Entropy: 3.96108
Value Function Loss: 0.00655

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.22742
Value Function Update Magnitude: 0.31914

Collected Steps per Second: 22,865.03852
Overall Steps per Second: 10,767.09502

Timestep Collection Time: 2.18709
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.64452

Cumulative Model Updates: 368,386
Cumulative Timesteps: 3,072,371,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3072371846...
Checkpoint 3072371846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.98612
Policy Entropy: 3.92228
Value Function Loss: 0.00675

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02359
Policy Update Magnitude: 0.23845
Value Function Update Magnitude: 0.32998

Collected Steps per Second: 22,177.98802
Overall Steps per Second: 10,648.33149

Timestep Collection Time: 2.25557
Timestep Consumption Time: 2.44226
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.69783

Cumulative Model Updates: 368,392
Cumulative Timesteps: 3,072,421,870

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.62329
Policy Entropy: 3.94726
Value Function Loss: 0.00675

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.23899
Value Function Update Magnitude: 0.32427

Collected Steps per Second: 23,504.31667
Overall Steps per Second: 10,892.94092

Timestep Collection Time: 2.12837
Timestep Consumption Time: 2.46414
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.59252

Cumulative Model Updates: 368,398
Cumulative Timesteps: 3,072,471,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3072471896...
Checkpoint 3072471896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.57670
Policy Entropy: 3.95046
Value Function Loss: 0.00686

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.03974
Policy Update Magnitude: 0.28199
Value Function Update Magnitude: 0.31835

Collected Steps per Second: 22,200.81492
Overall Steps per Second: 10,631.77831

Timestep Collection Time: 2.25271
Timestep Consumption Time: 2.45130
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.70401

Cumulative Model Updates: 368,404
Cumulative Timesteps: 3,072,521,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.97893
Policy Entropy: 3.98875
Value Function Loss: 0.00676

Mean KL Divergence: 0.00718
SB3 Clip Fraction: 0.04305
Policy Update Magnitude: 0.24988
Value Function Update Magnitude: 0.31760

Collected Steps per Second: 22,712.63293
Overall Steps per Second: 10,899.81556

Timestep Collection Time: 2.20212
Timestep Consumption Time: 2.38658
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.58870

Cumulative Model Updates: 368,410
Cumulative Timesteps: 3,072,571,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3072571924...
Checkpoint 3072571924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.56512
Policy Entropy: 3.97159
Value Function Loss: 0.00636

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.04110
Policy Update Magnitude: 0.23820
Value Function Update Magnitude: 0.31598

Collected Steps per Second: 22,323.35235
Overall Steps per Second: 10,638.52868

Timestep Collection Time: 2.24052
Timestep Consumption Time: 2.46088
PPO Batch Consumption Time: 0.28034
Total Iteration Time: 4.70140

Cumulative Model Updates: 368,416
Cumulative Timesteps: 3,072,621,940

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.90570
Policy Entropy: 3.93324
Value Function Loss: 0.00665

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02975
Policy Update Magnitude: 0.23906
Value Function Update Magnitude: 0.32754

Collected Steps per Second: 22,462.02656
Overall Steps per Second: 10,577.92965

Timestep Collection Time: 2.22660
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.29445
Total Iteration Time: 4.72815

Cumulative Model Updates: 368,422
Cumulative Timesteps: 3,072,671,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3072671954...
Checkpoint 3072671954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.51675
Policy Entropy: 3.92605
Value Function Loss: 0.00630

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.03050
Policy Update Magnitude: 0.24566
Value Function Update Magnitude: 0.33896

Collected Steps per Second: 22,381.89171
Overall Steps per Second: 10,687.24631

Timestep Collection Time: 2.23457
Timestep Consumption Time: 2.44521
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.67978

Cumulative Model Updates: 368,428
Cumulative Timesteps: 3,072,721,968

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.25558
Policy Entropy: 3.90607
Value Function Loss: 0.00684

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.04077
Policy Update Magnitude: 0.25895
Value Function Update Magnitude: 0.34891

Collected Steps per Second: 22,752.73203
Overall Steps per Second: 10,725.00028

Timestep Collection Time: 2.19771
Timestep Consumption Time: 2.46466
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.66238

Cumulative Model Updates: 368,434
Cumulative Timesteps: 3,072,771,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3072771972...
Checkpoint 3072771972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.45523
Policy Entropy: 3.91753
Value Function Loss: 0.00685

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.03949
Policy Update Magnitude: 0.25352
Value Function Update Magnitude: 0.35587

Collected Steps per Second: 21,907.77459
Overall Steps per Second: 10,609.67700

Timestep Collection Time: 2.28339
Timestep Consumption Time: 2.43155
PPO Batch Consumption Time: 0.28048
Total Iteration Time: 4.71494

Cumulative Model Updates: 368,440
Cumulative Timesteps: 3,072,821,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.72104
Policy Entropy: 3.92171
Value Function Loss: 0.00665

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.03668
Policy Update Magnitude: 0.24889
Value Function Update Magnitude: 0.34504

Collected Steps per Second: 22,371.39768
Overall Steps per Second: 10,743.72375

Timestep Collection Time: 2.23500
Timestep Consumption Time: 2.41888
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.65388

Cumulative Model Updates: 368,446
Cumulative Timesteps: 3,072,871,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3072871996...
Checkpoint 3072871996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.91231
Policy Entropy: 3.93954
Value Function Loss: 0.00569

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.03728
Policy Update Magnitude: 0.24064
Value Function Update Magnitude: 0.32054

Collected Steps per Second: 22,336.96648
Overall Steps per Second: 10,546.30910

Timestep Collection Time: 2.23862
Timestep Consumption Time: 2.50275
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.74137

Cumulative Model Updates: 368,452
Cumulative Timesteps: 3,072,922,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.75150
Policy Entropy: 3.94160
Value Function Loss: 0.00612

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.03053
Policy Update Magnitude: 0.22648
Value Function Update Magnitude: 0.30717

Collected Steps per Second: 22,691.45999
Overall Steps per Second: 10,767.96211

Timestep Collection Time: 2.20382
Timestep Consumption Time: 2.44032
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.64415

Cumulative Model Updates: 368,458
Cumulative Timesteps: 3,072,972,008

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3072972008...
Checkpoint 3072972008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.83415
Policy Entropy: 3.93154
Value Function Loss: 0.00616

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03023
Policy Update Magnitude: 0.22742
Value Function Update Magnitude: 0.31785

Collected Steps per Second: 22,175.49941
Overall Steps per Second: 10,696.47964

Timestep Collection Time: 2.25519
Timestep Consumption Time: 2.42018
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.67537

Cumulative Model Updates: 368,464
Cumulative Timesteps: 3,073,022,018

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.38420
Policy Entropy: 3.93118
Value Function Loss: 0.00685

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.02848
Policy Update Magnitude: 0.24184
Value Function Update Magnitude: 0.32178

Collected Steps per Second: 22,578.30928
Overall Steps per Second: 10,571.84261

Timestep Collection Time: 2.21496
Timestep Consumption Time: 2.51553
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.73049

Cumulative Model Updates: 368,470
Cumulative Timesteps: 3,073,072,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3073072028...
Checkpoint 3073072028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.15609
Policy Entropy: 3.96939
Value Function Loss: 0.00645

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.02712
Policy Update Magnitude: 0.23978
Value Function Update Magnitude: 0.33439

Collected Steps per Second: 22,430.18090
Overall Steps per Second: 10,604.73726

Timestep Collection Time: 2.22914
Timestep Consumption Time: 2.48573
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.71487

Cumulative Model Updates: 368,476
Cumulative Timesteps: 3,073,122,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.44695
Policy Entropy: 3.96618
Value Function Loss: 0.00698

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02764
Policy Update Magnitude: 0.24360
Value Function Update Magnitude: 0.34272

Collected Steps per Second: 23,057.22944
Overall Steps per Second: 10,782.79415

Timestep Collection Time: 2.16860
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.63720

Cumulative Model Updates: 368,482
Cumulative Timesteps: 3,073,172,030

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3073172030...
Checkpoint 3073172030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.22135
Policy Entropy: 3.96550
Value Function Loss: 0.00679

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02959
Policy Update Magnitude: 0.24729
Value Function Update Magnitude: 0.35107

Collected Steps per Second: 22,326.73070
Overall Steps per Second: 10,641.55236

Timestep Collection Time: 2.24135
Timestep Consumption Time: 2.46116
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.70251

Cumulative Model Updates: 368,488
Cumulative Timesteps: 3,073,222,072

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.00777
Policy Entropy: 3.94657
Value Function Loss: 0.00678

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02911
Policy Update Magnitude: 0.24399
Value Function Update Magnitude: 0.33981

Collected Steps per Second: 22,416.88302
Overall Steps per Second: 10,579.59895

Timestep Collection Time: 2.23073
Timestep Consumption Time: 2.49591
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.72664

Cumulative Model Updates: 368,494
Cumulative Timesteps: 3,073,272,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3073272078...
Checkpoint 3073272078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.41465
Policy Entropy: 3.96978
Value Function Loss: 0.00693

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.25123
Value Function Update Magnitude: 0.32460

Collected Steps per Second: 23,013.46952
Overall Steps per Second: 10,738.43397

Timestep Collection Time: 2.17299
Timestep Consumption Time: 2.48393
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.65692

Cumulative Model Updates: 368,500
Cumulative Timesteps: 3,073,322,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.70082
Policy Entropy: 3.98179
Value Function Loss: 0.00607

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.24091
Value Function Update Magnitude: 0.32305

Collected Steps per Second: 22,924.09425
Overall Steps per Second: 10,700.64760

Timestep Collection Time: 2.18120
Timestep Consumption Time: 2.49160
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.67280

Cumulative Model Updates: 368,506
Cumulative Timesteps: 3,073,372,088

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3073372088...
Checkpoint 3073372088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.10678
Policy Entropy: 3.98790
Value Function Loss: 0.00575

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02616
Policy Update Magnitude: 0.22746
Value Function Update Magnitude: 0.31247

Collected Steps per Second: 22,154.08269
Overall Steps per Second: 10,656.55634

Timestep Collection Time: 2.25827
Timestep Consumption Time: 2.43649
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.69476

Cumulative Model Updates: 368,512
Cumulative Timesteps: 3,073,422,118

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.05860
Policy Entropy: 3.97963
Value Function Loss: 0.00596

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02635
Policy Update Magnitude: 0.23195
Value Function Update Magnitude: 0.31625

Collected Steps per Second: 22,368.50975
Overall Steps per Second: 10,462.38039

Timestep Collection Time: 2.23564
Timestep Consumption Time: 2.54415
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.77979

Cumulative Model Updates: 368,518
Cumulative Timesteps: 3,073,472,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3073472126...
Checkpoint 3073472126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.67295
Policy Entropy: 3.97215
Value Function Loss: 0.00705

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02673
Policy Update Magnitude: 0.23952
Value Function Update Magnitude: 0.33629

Collected Steps per Second: 22,445.90958
Overall Steps per Second: 10,725.65421

Timestep Collection Time: 2.22874
Timestep Consumption Time: 2.43541
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.66414

Cumulative Model Updates: 368,524
Cumulative Timesteps: 3,073,522,152

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.33453
Policy Entropy: 3.96100
Value Function Loss: 0.00792

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02401
Policy Update Magnitude: 0.23963
Value Function Update Magnitude: 0.35148

Collected Steps per Second: 22,617.79631
Overall Steps per Second: 10,825.09347

Timestep Collection Time: 2.21198
Timestep Consumption Time: 2.40969
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.62167

Cumulative Model Updates: 368,530
Cumulative Timesteps: 3,073,572,182

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3073572182...
Checkpoint 3073572182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.53429
Policy Entropy: 3.96173
Value Function Loss: 0.00702

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02438
Policy Update Magnitude: 0.24602
Value Function Update Magnitude: 0.36292

Collected Steps per Second: 21,931.74601
Overall Steps per Second: 10,574.63361

Timestep Collection Time: 2.28035
Timestep Consumption Time: 2.44908
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.72943

Cumulative Model Updates: 368,536
Cumulative Timesteps: 3,073,622,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.78252
Policy Entropy: 3.95144
Value Function Loss: 0.00686

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02646
Policy Update Magnitude: 0.24562
Value Function Update Magnitude: 0.35623

Collected Steps per Second: 22,451.98757
Overall Steps per Second: 10,575.00015

Timestep Collection Time: 2.22795
Timestep Consumption Time: 2.50226
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.73021

Cumulative Model Updates: 368,542
Cumulative Timesteps: 3,073,672,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3073672216...
Checkpoint 3073672216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.64565
Policy Entropy: 3.94398
Value Function Loss: 0.00701

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02691
Policy Update Magnitude: 0.24267
Value Function Update Magnitude: 0.33072

Collected Steps per Second: 22,493.65618
Overall Steps per Second: 10,742.78998

Timestep Collection Time: 2.22445
Timestep Consumption Time: 2.43319
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.65764

Cumulative Model Updates: 368,548
Cumulative Timesteps: 3,073,722,252

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.69572
Policy Entropy: 3.95835
Value Function Loss: 0.00693

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.24204
Value Function Update Magnitude: 0.32117

Collected Steps per Second: 22,538.12765
Overall Steps per Second: 10,705.43386

Timestep Collection Time: 2.21962
Timestep Consumption Time: 2.45334
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.67295

Cumulative Model Updates: 368,554
Cumulative Timesteps: 3,073,772,278

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3073772278...
Checkpoint 3073772278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.14662
Policy Entropy: 3.97319
Value Function Loss: 0.00620

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02786
Policy Update Magnitude: 0.22971
Value Function Update Magnitude: 0.31325

Collected Steps per Second: 22,127.93575
Overall Steps per Second: 10,654.23138

Timestep Collection Time: 2.26004
Timestep Consumption Time: 2.43387
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.69391

Cumulative Model Updates: 368,560
Cumulative Timesteps: 3,073,822,288

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.02163
Policy Entropy: 3.97952
Value Function Loss: 0.00593

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02300
Policy Update Magnitude: 0.24061
Value Function Update Magnitude: 0.30271

Collected Steps per Second: 23,423.90057
Overall Steps per Second: 10,926.27513

Timestep Collection Time: 2.13508
Timestep Consumption Time: 2.44214
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.57722

Cumulative Model Updates: 368,566
Cumulative Timesteps: 3,073,872,300

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3073872300...
Checkpoint 3073872300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.05781
Policy Entropy: 3.96380
Value Function Loss: 0.00567

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.23325
Value Function Update Magnitude: 0.30690

Collected Steps per Second: 22,331.29305
Overall Steps per Second: 10,677.76799

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.44440
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.68412

Cumulative Model Updates: 368,572
Cumulative Timesteps: 3,073,922,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.72679
Policy Entropy: 3.95896
Value Function Loss: 0.00542

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.23397
Value Function Update Magnitude: 0.31065

Collected Steps per Second: 22,368.49289
Overall Steps per Second: 10,560.38274

Timestep Collection Time: 2.23654
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.73733

Cumulative Model Updates: 368,578
Cumulative Timesteps: 3,073,972,344

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3073972344...
Checkpoint 3073972344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.41244
Policy Entropy: 3.96547
Value Function Loss: 0.00577

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.23110
Value Function Update Magnitude: 0.30649

Collected Steps per Second: 22,278.50655
Overall Steps per Second: 10,720.44347

Timestep Collection Time: 2.24467
Timestep Consumption Time: 2.42006
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.66473

Cumulative Model Updates: 368,584
Cumulative Timesteps: 3,074,022,352

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.91548
Policy Entropy: 3.97533
Value Function Loss: 0.00653

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02737
Policy Update Magnitude: 0.24039
Value Function Update Magnitude: 0.32717

Collected Steps per Second: 22,714.08929
Overall Steps per Second: 10,706.31466

Timestep Collection Time: 2.20145
Timestep Consumption Time: 2.46906
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.67051

Cumulative Model Updates: 368,590
Cumulative Timesteps: 3,074,072,356

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3074072356...
Checkpoint 3074072356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.38183
Policy Entropy: 3.96328
Value Function Loss: 0.00672

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.02838
Policy Update Magnitude: 0.24946
Value Function Update Magnitude: 0.34617

Collected Steps per Second: 22,123.49656
Overall Steps per Second: 10,667.90548

Timestep Collection Time: 2.26113
Timestep Consumption Time: 2.42808
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.68921

Cumulative Model Updates: 368,596
Cumulative Timesteps: 3,074,122,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50058
Policy Entropy: 3.97003
Value Function Loss: 0.00666

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02822
Policy Update Magnitude: 0.25187
Value Function Update Magnitude: 0.34380

Collected Steps per Second: 23,456.51435
Overall Steps per Second: 10,871.88443

Timestep Collection Time: 2.13186
Timestep Consumption Time: 2.46771
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.59957

Cumulative Model Updates: 368,602
Cumulative Timesteps: 3,074,172,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3074172386...
Checkpoint 3074172386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.23538
Policy Entropy: 3.96903
Value Function Loss: 0.00662

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02784
Policy Update Magnitude: 0.24482
Value Function Update Magnitude: 0.33467

Collected Steps per Second: 22,243.72178
Overall Steps per Second: 10,623.24007

Timestep Collection Time: 2.24801
Timestep Consumption Time: 2.45903
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.70704

Cumulative Model Updates: 368,608
Cumulative Timesteps: 3,074,222,390

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.35237
Policy Entropy: 3.98499
Value Function Loss: 0.00576

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.23841
Value Function Update Magnitude: 0.32849

Collected Steps per Second: 22,313.86342
Overall Steps per Second: 10,734.05886

Timestep Collection Time: 2.24183
Timestep Consumption Time: 2.41847
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.66031

Cumulative Model Updates: 368,614
Cumulative Timesteps: 3,074,272,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3074272414...
Checkpoint 3074272414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.41084
Policy Entropy: 3.97004
Value Function Loss: 0.00560

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02328
Policy Update Magnitude: 0.23083
Value Function Update Magnitude: 0.33142

Collected Steps per Second: 22,541.57903
Overall Steps per Second: 10,577.77126

Timestep Collection Time: 2.21910
Timestep Consumption Time: 2.50987
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.72897

Cumulative Model Updates: 368,620
Cumulative Timesteps: 3,074,322,436

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.86466
Policy Entropy: 3.94657
Value Function Loss: 0.00550

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02264
Policy Update Magnitude: 0.23100
Value Function Update Magnitude: 0.33904

Collected Steps per Second: 22,784.81301
Overall Steps per Second: 10,749.49838

Timestep Collection Time: 2.19471
Timestep Consumption Time: 2.45723
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.65194

Cumulative Model Updates: 368,626
Cumulative Timesteps: 3,074,372,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3074372442...
Checkpoint 3074372442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.53366
Policy Entropy: 3.94507
Value Function Loss: 0.00627

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02228
Policy Update Magnitude: 0.23733
Value Function Update Magnitude: 0.33206

Collected Steps per Second: 21,927.99603
Overall Steps per Second: 10,682.95199

Timestep Collection Time: 2.28229
Timestep Consumption Time: 2.40237
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.68466

Cumulative Model Updates: 368,632
Cumulative Timesteps: 3,074,422,488

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.36710
Policy Entropy: 3.92273
Value Function Loss: 0.00637

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.24132
Value Function Update Magnitude: 0.33252

Collected Steps per Second: 22,720.48229
Overall Steps per Second: 10,633.81712

Timestep Collection Time: 2.20163
Timestep Consumption Time: 2.50242
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.70405

Cumulative Model Updates: 368,638
Cumulative Timesteps: 3,074,472,510

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3074472510...
Checkpoint 3074472510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.27388
Policy Entropy: 3.89066
Value Function Loss: 0.00765

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02927
Policy Update Magnitude: 0.25643
Value Function Update Magnitude: 0.33770

Collected Steps per Second: 22,305.69939
Overall Steps per Second: 10,513.39281

Timestep Collection Time: 2.24248
Timestep Consumption Time: 2.51526
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.75774

Cumulative Model Updates: 368,644
Cumulative Timesteps: 3,074,522,530

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.50626
Policy Entropy: 3.88440
Value Function Loss: 0.00860

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.03081
Policy Update Magnitude: 0.26340
Value Function Update Magnitude: 0.34813

Collected Steps per Second: 22,678.69117
Overall Steps per Second: 10,911.20376

Timestep Collection Time: 2.20524
Timestep Consumption Time: 2.37830
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.58355

Cumulative Model Updates: 368,650
Cumulative Timesteps: 3,074,572,542

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3074572542...
Checkpoint 3074572542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.10799
Policy Entropy: 3.93013
Value Function Loss: 0.00739

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.03084
Policy Update Magnitude: 0.25514
Value Function Update Magnitude: 0.35366

Collected Steps per Second: 22,370.51895
Overall Steps per Second: 10,572.13353

Timestep Collection Time: 2.23526
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.72979

Cumulative Model Updates: 368,656
Cumulative Timesteps: 3,074,622,546

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.84447
Policy Entropy: 3.95965
Value Function Loss: 0.00600

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.23413
Value Function Update Magnitude: 0.33558

Collected Steps per Second: 22,463.14099
Overall Steps per Second: 10,554.86886

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.51188
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.73829

Cumulative Model Updates: 368,662
Cumulative Timesteps: 3,074,672,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3074672558...
Checkpoint 3074672558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.25859
Policy Entropy: 3.95903
Value Function Loss: 0.00536

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.24089
Value Function Update Magnitude: 0.33622

Collected Steps per Second: 22,333.34110
Overall Steps per Second: 10,754.45509

Timestep Collection Time: 2.23916
Timestep Consumption Time: 2.41082
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.64998

Cumulative Model Updates: 368,668
Cumulative Timesteps: 3,074,722,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.04359
Policy Entropy: 3.94842
Value Function Loss: 0.00601

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02370
Policy Update Magnitude: 0.24196
Value Function Update Magnitude: 0.35890

Collected Steps per Second: 22,553.26442
Overall Steps per Second: 10,674.08765

Timestep Collection Time: 2.21724
Timestep Consumption Time: 2.46756
PPO Batch Consumption Time: 0.28177
Total Iteration Time: 4.68480

Cumulative Model Updates: 368,674
Cumulative Timesteps: 3,074,772,572

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3074772572...
Checkpoint 3074772572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.20085
Policy Entropy: 3.95596
Value Function Loss: 0.00626

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.03093
Policy Update Magnitude: 0.24035
Value Function Update Magnitude: 0.35125

Collected Steps per Second: 22,265.02603
Overall Steps per Second: 10,693.83562

Timestep Collection Time: 2.24585
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.27972
Total Iteration Time: 4.67596

Cumulative Model Updates: 368,680
Cumulative Timesteps: 3,074,822,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.89175
Policy Entropy: 3.95221
Value Function Loss: 0.00704

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.23795
Value Function Update Magnitude: 0.35363

Collected Steps per Second: 22,507.36997
Overall Steps per Second: 10,892.86875

Timestep Collection Time: 2.22229
Timestep Consumption Time: 2.36952
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.59181

Cumulative Model Updates: 368,686
Cumulative Timesteps: 3,074,872,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3074872594...
Checkpoint 3074872594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.34547
Policy Entropy: 3.94275
Value Function Loss: 0.00712

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02803
Policy Update Magnitude: 0.24177
Value Function Update Magnitude: 0.35878

Collected Steps per Second: 22,377.86122
Overall Steps per Second: 10,690.50064

Timestep Collection Time: 2.23453
Timestep Consumption Time: 2.44289
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.67742

Cumulative Model Updates: 368,692
Cumulative Timesteps: 3,074,922,598

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.74802
Policy Entropy: 3.97918
Value Function Loss: 0.00642

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02509
Policy Update Magnitude: 0.24592
Value Function Update Magnitude: 0.35248

Collected Steps per Second: 22,217.80825
Overall Steps per Second: 10,535.74568

Timestep Collection Time: 2.25144
Timestep Consumption Time: 2.49640
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.74784

Cumulative Model Updates: 368,698
Cumulative Timesteps: 3,074,972,620

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3074972620...
Checkpoint 3074972620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.65982
Policy Entropy: 3.95866
Value Function Loss: 0.00714

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02400
Policy Update Magnitude: 0.24506
Value Function Update Magnitude: 0.36296

Collected Steps per Second: 23,046.56042
Overall Steps per Second: 10,747.16480

Timestep Collection Time: 2.16969
Timestep Consumption Time: 2.48307
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.65276

Cumulative Model Updates: 368,704
Cumulative Timesteps: 3,075,022,624

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.49064
Policy Entropy: 3.93986
Value Function Loss: 0.00674

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.24656
Value Function Update Magnitude: 0.36719

Collected Steps per Second: 22,512.80504
Overall Steps per Second: 10,714.62003

Timestep Collection Time: 2.22131
Timestep Consumption Time: 2.44595
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.66727

Cumulative Model Updates: 368,710
Cumulative Timesteps: 3,075,072,632

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3075072632...
Checkpoint 3075072632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.35532
Policy Entropy: 3.91649
Value Function Loss: 0.00708

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.25100
Value Function Update Magnitude: 0.37586

Collected Steps per Second: 22,577.43732
Overall Steps per Second: 10,763.94489

Timestep Collection Time: 2.21584
Timestep Consumption Time: 2.43190
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.64774

Cumulative Model Updates: 368,716
Cumulative Timesteps: 3,075,122,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.33094
Policy Entropy: 3.98155
Value Function Loss: 0.00666

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02920
Policy Update Magnitude: 0.25140
Value Function Update Magnitude: 0.35029

Collected Steps per Second: 22,754.91538
Overall Steps per Second: 10,718.49424

Timestep Collection Time: 2.19785
Timestep Consumption Time: 2.46810
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.66595

Cumulative Model Updates: 368,722
Cumulative Timesteps: 3,075,172,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3075172672...
Checkpoint 3075172672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.40071
Policy Entropy: 3.96807
Value Function Loss: 0.00753

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03016
Policy Update Magnitude: 0.25271
Value Function Update Magnitude: 0.33211

Collected Steps per Second: 22,116.55541
Overall Steps per Second: 10,607.54081

Timestep Collection Time: 2.26202
Timestep Consumption Time: 2.45425
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.71627

Cumulative Model Updates: 368,728
Cumulative Timesteps: 3,075,222,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.21314
Policy Entropy: 3.98532
Value Function Loss: 0.00710

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.03022
Policy Update Magnitude: 0.25490
Value Function Update Magnitude: 0.34579

Collected Steps per Second: 22,571.60156
Overall Steps per Second: 10,886.39661

Timestep Collection Time: 2.21650
Timestep Consumption Time: 2.37914
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.59564

Cumulative Model Updates: 368,734
Cumulative Timesteps: 3,075,272,730

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3075272730...
Checkpoint 3075272730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.87273
Policy Entropy: 3.93927
Value Function Loss: 0.00721

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.03683
Policy Update Magnitude: 0.25461
Value Function Update Magnitude: 0.35099

Collected Steps per Second: 22,355.14870
Overall Steps per Second: 10,690.60784

Timestep Collection Time: 2.23769
Timestep Consumption Time: 2.44155
PPO Batch Consumption Time: 0.27977
Total Iteration Time: 4.67925

Cumulative Model Updates: 368,740
Cumulative Timesteps: 3,075,322,754

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.87213
Policy Entropy: 3.97979
Value Function Loss: 0.00700

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.24875
Value Function Update Magnitude: 0.32359

Collected Steps per Second: 22,477.94650
Overall Steps per Second: 10,569.13566

Timestep Collection Time: 2.22583
Timestep Consumption Time: 2.50796
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.73378

Cumulative Model Updates: 368,746
Cumulative Timesteps: 3,075,372,786

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3075372786...
Checkpoint 3075372786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.56121
Policy Entropy: 3.95163
Value Function Loss: 0.00720

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.24841
Value Function Update Magnitude: 0.32288

Collected Steps per Second: 23,154.95150
Overall Steps per Second: 10,725.20434

Timestep Collection Time: 2.15988
Timestep Consumption Time: 2.50315
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.66303

Cumulative Model Updates: 368,752
Cumulative Timesteps: 3,075,422,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.39922
Policy Entropy: 3.97060
Value Function Loss: 0.00698

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02285
Policy Update Magnitude: 0.24186
Value Function Update Magnitude: 0.32358

Collected Steps per Second: 22,705.84560
Overall Steps per Second: 10,739.94517

Timestep Collection Time: 2.20313
Timestep Consumption Time: 2.45462
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.65775

Cumulative Model Updates: 368,758
Cumulative Timesteps: 3,075,472,822

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3075472822...
Checkpoint 3075472822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.59315
Policy Entropy: 3.95567
Value Function Loss: 0.00644

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.23852
Value Function Update Magnitude: 0.32929

Collected Steps per Second: 22,159.94109
Overall Steps per Second: 10,715.64103

Timestep Collection Time: 2.25668
Timestep Consumption Time: 2.41014
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.66682

Cumulative Model Updates: 368,764
Cumulative Timesteps: 3,075,522,830

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.32053
Policy Entropy: 3.96180
Value Function Loss: 0.00641

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.23276
Value Function Update Magnitude: 0.33596

Collected Steps per Second: 23,499.70307
Overall Steps per Second: 10,835.80929

Timestep Collection Time: 2.12930
Timestep Consumption Time: 2.48853
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.61784

Cumulative Model Updates: 368,770
Cumulative Timesteps: 3,075,572,868

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3075572868...
Checkpoint 3075572868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.69355
Policy Entropy: 3.94733
Value Function Loss: 0.00615

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.23132
Value Function Update Magnitude: 0.33029

Collected Steps per Second: 22,154.12850
Overall Steps per Second: 10,627.71752

Timestep Collection Time: 2.25800
Timestep Consumption Time: 2.44894
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.70694

Cumulative Model Updates: 368,776
Cumulative Timesteps: 3,075,622,892

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.88876
Policy Entropy: 3.96803
Value Function Loss: 0.00599

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02612
Policy Update Magnitude: 0.22824
Value Function Update Magnitude: 0.32270

Collected Steps per Second: 22,331.94756
Overall Steps per Second: 10,866.55626

Timestep Collection Time: 2.23957
Timestep Consumption Time: 2.36299
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.60256

Cumulative Model Updates: 368,782
Cumulative Timesteps: 3,075,672,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3075672906...
Checkpoint 3075672906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.51516
Policy Entropy: 3.97880
Value Function Loss: 0.00580

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.22653
Value Function Update Magnitude: 0.31701

Collected Steps per Second: 22,059.65352
Overall Steps per Second: 10,631.10658

Timestep Collection Time: 2.26703
Timestep Consumption Time: 2.43709
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.70412

Cumulative Model Updates: 368,788
Cumulative Timesteps: 3,075,722,916

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.86538
Policy Entropy: 3.97640
Value Function Loss: 0.00618

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02649
Policy Update Magnitude: 0.23305
Value Function Update Magnitude: 0.32053

Collected Steps per Second: 22,607.95638
Overall Steps per Second: 10,580.90457

Timestep Collection Time: 2.21205
Timestep Consumption Time: 2.51439
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.72644

Cumulative Model Updates: 368,794
Cumulative Timesteps: 3,075,772,926

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3075772926...
Checkpoint 3075772926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.51866
Policy Entropy: 3.96436
Value Function Loss: 0.00611

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02247
Policy Update Magnitude: 0.24050
Value Function Update Magnitude: 0.32625

Collected Steps per Second: 22,372.07930
Overall Steps per Second: 10,742.95699

Timestep Collection Time: 2.23511
Timestep Consumption Time: 2.41948
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.65458

Cumulative Model Updates: 368,800
Cumulative Timesteps: 3,075,822,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.99498
Policy Entropy: 3.97061
Value Function Loss: 0.00588

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02262
Policy Update Magnitude: 0.23863
Value Function Update Magnitude: 0.31334

Collected Steps per Second: 22,658.68963
Overall Steps per Second: 10,742.67040

Timestep Collection Time: 2.20807
Timestep Consumption Time: 2.44924
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.65732

Cumulative Model Updates: 368,806
Cumulative Timesteps: 3,075,872,962

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3075872962...
Checkpoint 3075872962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.35061
Policy Entropy: 3.99639
Value Function Loss: 0.00568

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02311
Policy Update Magnitude: 0.23795
Value Function Update Magnitude: 0.29619

Collected Steps per Second: 22,308.54714
Overall Steps per Second: 10,688.92595

Timestep Collection Time: 2.24264
Timestep Consumption Time: 2.43791
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.68055

Cumulative Model Updates: 368,812
Cumulative Timesteps: 3,075,922,992

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.55813
Policy Entropy: 4.00220
Value Function Loss: 0.00562

Mean KL Divergence: 0.00257
SB3 Clip Fraction: 0.02037
Policy Update Magnitude: 0.22876
Value Function Update Magnitude: 0.29465

Collected Steps per Second: 23,396.38597
Overall Steps per Second: 10,899.44741

Timestep Collection Time: 2.13760
Timestep Consumption Time: 2.45089
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.58849

Cumulative Model Updates: 368,818
Cumulative Timesteps: 3,075,973,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3075973004...
Checkpoint 3075973004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.58843
Policy Entropy: 3.98289
Value Function Loss: 0.00530

Mean KL Divergence: 0.00265
SB3 Clip Fraction: 0.02029
Policy Update Magnitude: 0.22754
Value Function Update Magnitude: 0.29323

Collected Steps per Second: 22,280.43714
Overall Steps per Second: 10,610.79615

Timestep Collection Time: 2.24448
Timestep Consumption Time: 2.46846
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.71294

Cumulative Model Updates: 368,824
Cumulative Timesteps: 3,076,023,012

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.62303
Policy Entropy: 3.95318
Value Function Loss: 0.00592

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.23232
Value Function Update Magnitude: 0.30527

Collected Steps per Second: 22,492.23232
Overall Steps per Second: 10,573.01631

Timestep Collection Time: 2.22406
Timestep Consumption Time: 2.50723
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.73129

Cumulative Model Updates: 368,830
Cumulative Timesteps: 3,076,073,036

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3076073036...
Checkpoint 3076073036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.76022
Policy Entropy: 3.93845
Value Function Loss: 0.00636

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02777
Policy Update Magnitude: 0.24165
Value Function Update Magnitude: 0.32046

Collected Steps per Second: 23,146.49313
Overall Steps per Second: 10,754.94636

Timestep Collection Time: 2.16093
Timestep Consumption Time: 2.48977
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.65070

Cumulative Model Updates: 368,836
Cumulative Timesteps: 3,076,123,054

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.96887
Policy Entropy: 3.94387
Value Function Loss: 0.00799

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.03029
Policy Update Magnitude: 0.24208
Value Function Update Magnitude: 0.34540

Collected Steps per Second: 22,720.64508
Overall Steps per Second: 10,737.07601

Timestep Collection Time: 2.20152
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.65862

Cumulative Model Updates: 368,842
Cumulative Timesteps: 3,076,173,074

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3076173074...
Checkpoint 3076173074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.60133
Policy Entropy: 3.94779
Value Function Loss: 0.00762

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.03001
Policy Update Magnitude: 0.25521
Value Function Update Magnitude: 0.36941

Collected Steps per Second: 22,061.89539
Overall Steps per Second: 10,502.24829

Timestep Collection Time: 2.26726
Timestep Consumption Time: 2.49553
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.76279

Cumulative Model Updates: 368,848
Cumulative Timesteps: 3,076,223,094

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.66624
Policy Entropy: 3.96353
Value Function Loss: 0.00730

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02981
Policy Update Magnitude: 0.25516
Value Function Update Magnitude: 0.35240

Collected Steps per Second: 23,457.89524
Overall Steps per Second: 10,916.16327

Timestep Collection Time: 2.13216
Timestep Consumption Time: 2.44967
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.58183

Cumulative Model Updates: 368,854
Cumulative Timesteps: 3,076,273,110

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3076273110...
Checkpoint 3076273110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.82349
Policy Entropy: 4.01346
Value Function Loss: 0.00599

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02958
Policy Update Magnitude: 0.24035
Value Function Update Magnitude: 0.33337

Collected Steps per Second: 22,309.21906
Overall Steps per Second: 10,640.51951

Timestep Collection Time: 2.24302
Timestep Consumption Time: 2.45976
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.70278

Cumulative Model Updates: 368,860
Cumulative Timesteps: 3,076,323,150

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.45625
Policy Entropy: 4.01678
Value Function Loss: 0.00491

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.02808
Policy Update Magnitude: 0.22484
Value Function Update Magnitude: 0.32400

Collected Steps per Second: 21,173.36784
Overall Steps per Second: 10,222.73147

Timestep Collection Time: 2.36193
Timestep Consumption Time: 2.53011
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.89204

Cumulative Model Updates: 368,866
Cumulative Timesteps: 3,076,373,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3076373160...
Checkpoint 3076373160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.93220
Policy Entropy: 4.02091
Value Function Loss: 0.00492

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.22120
Value Function Update Magnitude: 0.30830

Collected Steps per Second: 22,864.39576
Overall Steps per Second: 10,642.13499

Timestep Collection Time: 2.18742
Timestep Consumption Time: 2.51220
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.69962

Cumulative Model Updates: 368,872
Cumulative Timesteps: 3,076,423,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.50823
Policy Entropy: 3.96519
Value Function Loss: 0.00577

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.03040
Policy Update Magnitude: 0.24157
Value Function Update Magnitude: 0.30816

Collected Steps per Second: 22,627.63182
Overall Steps per Second: 10,746.87840

Timestep Collection Time: 2.21048
Timestep Consumption Time: 2.44371
PPO Batch Consumption Time: 0.27999
Total Iteration Time: 4.65419

Cumulative Model Updates: 368,878
Cumulative Timesteps: 3,076,473,192

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3076473192...
Checkpoint 3076473192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.90189
Policy Entropy: 3.94622
Value Function Loss: 0.00690

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.03591
Policy Update Magnitude: 0.25656
Value Function Update Magnitude: 0.32310

Collected Steps per Second: 22,202.37885
Overall Steps per Second: 10,663.07055

Timestep Collection Time: 2.25264
Timestep Consumption Time: 2.43775
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.69039

Cumulative Model Updates: 368,884
Cumulative Timesteps: 3,076,523,206

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.73969
Policy Entropy: 3.95888
Value Function Loss: 0.00657

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.03241
Policy Update Magnitude: 0.26565
Value Function Update Magnitude: 0.33832

Collected Steps per Second: 23,543.27737
Overall Steps per Second: 10,909.93048

Timestep Collection Time: 2.12409
Timestep Consumption Time: 2.45963
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.58371

Cumulative Model Updates: 368,890
Cumulative Timesteps: 3,076,573,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3076573214...
Checkpoint 3076573214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.96239
Policy Entropy: 3.96631
Value Function Loss: 0.00769

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.03037
Policy Update Magnitude: 0.25467
Value Function Update Magnitude: 0.35459

Collected Steps per Second: 21,760.66058
Overall Steps per Second: 10,365.91828

Timestep Collection Time: 2.29809
Timestep Consumption Time: 2.52618
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.82427

Cumulative Model Updates: 368,896
Cumulative Timesteps: 3,076,623,222

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.84960
Policy Entropy: 3.94726
Value Function Loss: 0.00798

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.03091
Policy Update Magnitude: 0.25868
Value Function Update Magnitude: 0.35717

Collected Steps per Second: 22,483.41206
Overall Steps per Second: 10,813.84137

Timestep Collection Time: 2.22395
Timestep Consumption Time: 2.39994
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.62389

Cumulative Model Updates: 368,902
Cumulative Timesteps: 3,076,673,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3076673224...
Checkpoint 3076673224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.24386
Policy Entropy: 3.91855
Value Function Loss: 0.00833

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 0.26331
Value Function Update Magnitude: 0.35721

Collected Steps per Second: 22,420.53582
Overall Steps per Second: 10,628.94505

Timestep Collection Time: 2.23117
Timestep Consumption Time: 2.47522
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.70639

Cumulative Model Updates: 368,908
Cumulative Timesteps: 3,076,723,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.55439
Policy Entropy: 3.92792
Value Function Loss: 0.00741

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.02933
Policy Update Magnitude: 0.26180
Value Function Update Magnitude: 0.33773

Collected Steps per Second: 22,623.35804
Overall Steps per Second: 10,658.36848

Timestep Collection Time: 2.21125
Timestep Consumption Time: 2.48233
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.69359

Cumulative Model Updates: 368,914
Cumulative Timesteps: 3,076,773,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3076773274...
Checkpoint 3076773274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.34798
Policy Entropy: 3.96319
Value Function Loss: 0.00651

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02750
Policy Update Magnitude: 0.26193
Value Function Update Magnitude: 0.31508

Collected Steps per Second: 22,364.40840
Overall Steps per Second: 10,818.59490

Timestep Collection Time: 2.23641
Timestep Consumption Time: 2.38674
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.62315

Cumulative Model Updates: 368,920
Cumulative Timesteps: 3,076,823,290

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.72280
Policy Entropy: 3.98305
Value Function Loss: 0.00705

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02227
Policy Update Magnitude: 0.24868
Value Function Update Magnitude: 0.30438

Collected Steps per Second: 22,558.79327
Overall Steps per Second: 10,502.50488

Timestep Collection Time: 2.21749
Timestep Consumption Time: 2.54556
PPO Batch Consumption Time: 0.29512
Total Iteration Time: 4.76305

Cumulative Model Updates: 368,926
Cumulative Timesteps: 3,076,873,314

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3076873314...
Checkpoint 3076873314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.49573
Policy Entropy: 3.98868
Value Function Loss: 0.00644

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.24320
Value Function Update Magnitude: 0.30226

Collected Steps per Second: 22,205.51975
Overall Steps per Second: 10,706.70139

Timestep Collection Time: 2.25196
Timestep Consumption Time: 2.41857
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.67053

Cumulative Model Updates: 368,932
Cumulative Timesteps: 3,076,923,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.82413
Policy Entropy: 3.95236
Value Function Loss: 0.00680

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02762
Policy Update Magnitude: 0.23995
Value Function Update Magnitude: 0.29397

Collected Steps per Second: 22,513.18723
Overall Steps per Second: 10,835.52505

Timestep Collection Time: 2.22154
Timestep Consumption Time: 2.39420
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.61574

Cumulative Model Updates: 368,938
Cumulative Timesteps: 3,076,973,334

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3076973334...
Checkpoint 3076973334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.36075
Policy Entropy: 3.92521
Value Function Loss: 0.00704

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02935
Policy Update Magnitude: 0.24565
Value Function Update Magnitude: 0.29633

Collected Steps per Second: 22,285.10231
Overall Steps per Second: 10,642.11308

Timestep Collection Time: 2.24491
Timestep Consumption Time: 2.45604
PPO Batch Consumption Time: 0.28087
Total Iteration Time: 4.70095

Cumulative Model Updates: 368,944
Cumulative Timesteps: 3,077,023,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.26502
Policy Entropy: 3.92610
Value Function Loss: 0.00726

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02977
Policy Update Magnitude: 0.25452
Value Function Update Magnitude: 0.31955

Collected Steps per Second: 22,519.53245
Overall Steps per Second: 10,630.21400

Timestep Collection Time: 2.22056
Timestep Consumption Time: 2.48358
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.70414

Cumulative Model Updates: 368,950
Cumulative Timesteps: 3,077,073,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3077073368...
Checkpoint 3077073368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.19060
Policy Entropy: 3.93127
Value Function Loss: 0.00797

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.03402
Policy Update Magnitude: 0.26532
Value Function Update Magnitude: 0.35067

Collected Steps per Second: 23,273.02645
Overall Steps per Second: 10,881.81738

Timestep Collection Time: 2.14987
Timestep Consumption Time: 2.44807
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.59795

Cumulative Model Updates: 368,956
Cumulative Timesteps: 3,077,123,402

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.29656
Policy Entropy: 3.94701
Value Function Loss: 0.00767

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.03892
Policy Update Magnitude: 0.25994
Value Function Update Magnitude: 0.36631

Collected Steps per Second: 22,525.99149
Overall Steps per Second: 10,520.21626

Timestep Collection Time: 2.22046
Timestep Consumption Time: 2.53401
PPO Batch Consumption Time: 0.29389
Total Iteration Time: 4.75446

Cumulative Model Updates: 368,962
Cumulative Timesteps: 3,077,173,420

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3077173420...
Checkpoint 3077173420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.66535
Policy Entropy: 3.95654
Value Function Loss: 0.00676

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.03881
Policy Update Magnitude: 0.24588
Value Function Update Magnitude: 0.36742

Collected Steps per Second: 21,981.09376
Overall Steps per Second: 10,628.62633

Timestep Collection Time: 2.27523
Timestep Consumption Time: 2.43018
PPO Batch Consumption Time: 0.28136
Total Iteration Time: 4.70541

Cumulative Model Updates: 368,968
Cumulative Timesteps: 3,077,223,432

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.15936
Policy Entropy: 3.97676
Value Function Loss: 0.00691

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03035
Policy Update Magnitude: 0.24556
Value Function Update Magnitude: 0.35606

Collected Steps per Second: 23,327.94114
Overall Steps per Second: 10,866.69165

Timestep Collection Time: 2.14421
Timestep Consumption Time: 2.45885
PPO Batch Consumption Time: 0.28148
Total Iteration Time: 4.60306

Cumulative Model Updates: 368,974
Cumulative Timesteps: 3,077,273,452

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3077273452...
Checkpoint 3077273452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.89512
Policy Entropy: 3.98963
Value Function Loss: 0.00687

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.03308
Policy Update Magnitude: 0.24078
Value Function Update Magnitude: 0.35039

Collected Steps per Second: 21,943.70222
Overall Steps per Second: 10,633.17662

Timestep Collection Time: 2.28011
Timestep Consumption Time: 2.42535
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.70546

Cumulative Model Updates: 368,980
Cumulative Timesteps: 3,077,323,486

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.89845
Policy Entropy: 3.97416
Value Function Loss: 0.00745

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02730
Policy Update Magnitude: 0.23742
Value Function Update Magnitude: 0.33932

Collected Steps per Second: 22,523.46250
Overall Steps per Second: 10,903.56292

Timestep Collection Time: 2.22115
Timestep Consumption Time: 2.36707
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.58822

Cumulative Model Updates: 368,986
Cumulative Timesteps: 3,077,373,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3077373514...
Checkpoint 3077373514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.67351
Policy Entropy: 3.98370
Value Function Loss: 0.00696

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02615
Policy Update Magnitude: 0.24364
Value Function Update Magnitude: 0.33188

Collected Steps per Second: 22,443.51454
Overall Steps per Second: 10,710.58867

Timestep Collection Time: 2.22871
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.67014

Cumulative Model Updates: 368,992
Cumulative Timesteps: 3,077,423,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.29305
Policy Entropy: 3.95135
Value Function Loss: 0.00714

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.24453
Value Function Update Magnitude: 0.33318

Collected Steps per Second: 22,421.02603
Overall Steps per Second: 10,484.69060

Timestep Collection Time: 2.23032
Timestep Consumption Time: 2.53911
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.76943

Cumulative Model Updates: 368,998
Cumulative Timesteps: 3,077,473,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3077473540...
Checkpoint 3077473540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.46416
Policy Entropy: 3.95648
Value Function Loss: 0.00647

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02861
Policy Update Magnitude: 0.25198
Value Function Update Magnitude: 0.33241

Collected Steps per Second: 22,382.99122
Overall Steps per Second: 10,715.95997

Timestep Collection Time: 2.23491
Timestep Consumption Time: 2.43327
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.66818

Cumulative Model Updates: 369,004
Cumulative Timesteps: 3,077,523,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.34965
Policy Entropy: 3.95515
Value Function Loss: 0.00633

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02992
Policy Update Magnitude: 0.24408
Value Function Update Magnitude: 0.32101

Collected Steps per Second: 22,737.96149
Overall Steps per Second: 10,716.72685

Timestep Collection Time: 2.19985
Timestep Consumption Time: 2.46762
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.66747

Cumulative Model Updates: 369,010
Cumulative Timesteps: 3,077,573,584

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3077573584...
Checkpoint 3077573584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.04945
Policy Entropy: 3.98512
Value Function Loss: 0.00605

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02634
Policy Update Magnitude: 0.23778
Value Function Update Magnitude: 0.31095

Collected Steps per Second: 22,075.52082
Overall Steps per Second: 10,470.04267

Timestep Collection Time: 2.26613
Timestep Consumption Time: 2.51188
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.77801

Cumulative Model Updates: 369,016
Cumulative Timesteps: 3,077,623,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.87220
Policy Entropy: 3.97985
Value Function Loss: 0.00658

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.03304
Policy Update Magnitude: 0.24245
Value Function Update Magnitude: 0.30786

Collected Steps per Second: 22,784.59018
Overall Steps per Second: 10,785.07947

Timestep Collection Time: 2.19499
Timestep Consumption Time: 2.44215
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.63715

Cumulative Model Updates: 369,022
Cumulative Timesteps: 3,077,673,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3077673622...
Checkpoint 3077673622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.55036
Policy Entropy: 3.93277
Value Function Loss: 0.00667

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.03255
Policy Update Magnitude: 0.24570
Value Function Update Magnitude: 0.30936

Collected Steps per Second: 22,528.46631
Overall Steps per Second: 10,629.18366

Timestep Collection Time: 2.22012
Timestep Consumption Time: 2.48541
PPO Batch Consumption Time: 0.28843
Total Iteration Time: 4.70554

Cumulative Model Updates: 369,028
Cumulative Timesteps: 3,077,723,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.32869
Policy Entropy: 3.92536
Value Function Loss: 0.00706

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.03269
Policy Update Magnitude: 0.25568
Value Function Update Magnitude: 0.32704

Collected Steps per Second: 22,534.35773
Overall Steps per Second: 10,787.64802

Timestep Collection Time: 2.21910
Timestep Consumption Time: 2.41639
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.63549

Cumulative Model Updates: 369,034
Cumulative Timesteps: 3,077,773,644

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3077773644...
Checkpoint 3077773644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41787
Policy Entropy: 3.93630
Value Function Loss: 0.00710

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02828
Policy Update Magnitude: 0.25765
Value Function Update Magnitude: 0.33850

Collected Steps per Second: 22,292.36606
Overall Steps per Second: 10,743.57821

Timestep Collection Time: 2.24301
Timestep Consumption Time: 2.41112
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.65413

Cumulative Model Updates: 369,040
Cumulative Timesteps: 3,077,823,646

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.00779
Policy Entropy: 3.94976
Value Function Loss: 0.00756

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.25443
Value Function Update Magnitude: 0.33665

Collected Steps per Second: 22,514.77279
Overall Steps per Second: 10,594.44668

Timestep Collection Time: 2.22094
Timestep Consumption Time: 2.49889
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.71983

Cumulative Model Updates: 369,046
Cumulative Timesteps: 3,077,873,650

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3077873650...
Checkpoint 3077873650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.62900
Policy Entropy: 3.97547
Value Function Loss: 0.00729

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02640
Policy Update Magnitude: 0.25960
Value Function Update Magnitude: 0.33001

Collected Steps per Second: 22,390.30570
Overall Steps per Second: 10,575.31301

Timestep Collection Time: 2.23382
Timestep Consumption Time: 2.49568
PPO Batch Consumption Time: 0.29345
Total Iteration Time: 4.72951

Cumulative Model Updates: 369,052
Cumulative Timesteps: 3,077,923,666

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.05653
Policy Entropy: 3.95786
Value Function Loss: 0.00690

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02844
Policy Update Magnitude: 0.24884
Value Function Update Magnitude: 0.32562

Collected Steps per Second: 23,324.63299
Overall Steps per Second: 10,878.55273

Timestep Collection Time: 2.14486
Timestep Consumption Time: 2.45392
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.59877

Cumulative Model Updates: 369,058
Cumulative Timesteps: 3,077,973,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3077973694...
Checkpoint 3077973694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.50601
Policy Entropy: 3.97417
Value Function Loss: 0.00655

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.03288
Policy Update Magnitude: 0.24845
Value Function Update Magnitude: 0.32941

Collected Steps per Second: 22,178.94726
Overall Steps per Second: 10,670.12414

Timestep Collection Time: 2.25601
Timestep Consumption Time: 2.43334
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.68936

Cumulative Model Updates: 369,064
Cumulative Timesteps: 3,078,023,730

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.59173
Policy Entropy: 3.94271
Value Function Loss: 0.00688

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.03129
Policy Update Magnitude: 0.24733
Value Function Update Magnitude: 0.34019

Collected Steps per Second: 22,502.10727
Overall Steps per Second: 10,773.69856

Timestep Collection Time: 2.22255
Timestep Consumption Time: 2.41950
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.64205

Cumulative Model Updates: 369,070
Cumulative Timesteps: 3,078,073,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3078073742...
Checkpoint 3078073742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.65064
Policy Entropy: 3.97005
Value Function Loss: 0.00713

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.24878
Value Function Update Magnitude: 0.34421

Collected Steps per Second: 22,753.68016
Overall Steps per Second: 10,798.25844

Timestep Collection Time: 2.19859
Timestep Consumption Time: 2.43419
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.63278

Cumulative Model Updates: 369,076
Cumulative Timesteps: 3,078,123,768

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.44398
Policy Entropy: 3.93108
Value Function Loss: 0.00697

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.25328
Value Function Update Magnitude: 0.33485

Collected Steps per Second: 22,687.31022
Overall Steps per Second: 10,758.45726

Timestep Collection Time: 2.20502
Timestep Consumption Time: 2.44490
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.64992

Cumulative Model Updates: 369,082
Cumulative Timesteps: 3,078,173,794

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3078173794...
Checkpoint 3078173794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.05406
Policy Entropy: 3.95436
Value Function Loss: 0.00634

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02322
Policy Update Magnitude: 0.25197
Value Function Update Magnitude: 0.33396

Collected Steps per Second: 22,153.40468
Overall Steps per Second: 10,649.52429

Timestep Collection Time: 2.25708
Timestep Consumption Time: 2.43815
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.69523

Cumulative Model Updates: 369,088
Cumulative Timesteps: 3,078,223,796

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.00921
Policy Entropy: 3.97228
Value Function Loss: 0.00581

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02894
Policy Update Magnitude: 0.24863
Value Function Update Magnitude: 0.32238

Collected Steps per Second: 23,163.52537
Overall Steps per Second: 10,723.45182

Timestep Collection Time: 2.15943
Timestep Consumption Time: 2.50511
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.66454

Cumulative Model Updates: 369,094
Cumulative Timesteps: 3,078,273,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3078273816...
Checkpoint 3078273816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.60048
Policy Entropy: 3.99335
Value Function Loss: 0.00743

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.24727
Value Function Update Magnitude: 0.31548

Collected Steps per Second: 22,282.06980
Overall Steps per Second: 10,495.33093

Timestep Collection Time: 2.24441
Timestep Consumption Time: 2.52057
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.76498

Cumulative Model Updates: 369,100
Cumulative Timesteps: 3,078,323,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.52778
Policy Entropy: 3.96521
Value Function Loss: 0.00832

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02721
Policy Update Magnitude: 0.25581
Value Function Update Magnitude: 0.33429

Collected Steps per Second: 22,548.82825
Overall Steps per Second: 10,781.63141

Timestep Collection Time: 2.21794
Timestep Consumption Time: 2.42069
PPO Batch Consumption Time: 0.27986
Total Iteration Time: 4.63863

Cumulative Model Updates: 369,106
Cumulative Timesteps: 3,078,373,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3078373838...
Checkpoint 3078373838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.79711
Policy Entropy: 3.93039
Value Function Loss: 0.00806

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.03184
Policy Update Magnitude: 0.25916
Value Function Update Magnitude: 0.34361

Collected Steps per Second: 23,073.41932
Overall Steps per Second: 10,712.63715

Timestep Collection Time: 2.16734
Timestep Consumption Time: 2.50079
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.66813

Cumulative Model Updates: 369,112
Cumulative Timesteps: 3,078,423,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.62978
Policy Entropy: 3.95622
Value Function Loss: 0.00635

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02864
Policy Update Magnitude: 0.24751
Value Function Update Magnitude: 0.31400

Collected Steps per Second: 22,575.04755
Overall Steps per Second: 10,601.90246

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.50220
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.71783

Cumulative Model Updates: 369,118
Cumulative Timesteps: 3,078,473,864

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3078473864...
Checkpoint 3078473864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.81682
Policy Entropy: 4.01152
Value Function Loss: 0.00588

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.23518
Value Function Update Magnitude: 0.29868

Collected Steps per Second: 22,374.57364
Overall Steps per Second: 10,577.51646

Timestep Collection Time: 2.23575
Timestep Consumption Time: 2.49352
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.72928

Cumulative Model Updates: 369,124
Cumulative Timesteps: 3,078,523,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.39839
Policy Entropy: 4.01363
Value Function Loss: 0.00594

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.23149
Value Function Update Magnitude: 0.30564

Collected Steps per Second: 23,398.78100
Overall Steps per Second: 10,825.56068

Timestep Collection Time: 2.13772
Timestep Consumption Time: 2.48283
PPO Batch Consumption Time: 0.28453
Total Iteration Time: 4.62055

Cumulative Model Updates: 369,130
Cumulative Timesteps: 3,078,573,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3078573908...
Checkpoint 3078573908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.62049
Policy Entropy: 3.95701
Value Function Loss: 0.00704

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02349
Policy Update Magnitude: 0.23515
Value Function Update Magnitude: 0.30692

Collected Steps per Second: 22,509.12881
Overall Steps per Second: 10,630.34846

Timestep Collection Time: 2.22203
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.70502

Cumulative Model Updates: 369,136
Cumulative Timesteps: 3,078,623,924

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.78649
Policy Entropy: 3.93890
Value Function Loss: 0.00713

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.03094
Policy Update Magnitude: 0.24994
Value Function Update Magnitude: 0.32016

Collected Steps per Second: 22,286.72389
Overall Steps per Second: 10,831.09013

Timestep Collection Time: 2.24483
Timestep Consumption Time: 2.37428
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.61911

Cumulative Model Updates: 369,142
Cumulative Timesteps: 3,078,673,954

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3078673954...
Checkpoint 3078673954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.01260
Policy Entropy: 3.91930
Value Function Loss: 0.00702

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.03582
Policy Update Magnitude: 0.24992
Value Function Update Magnitude: 0.33006

Collected Steps per Second: 22,444.53426
Overall Steps per Second: 10,673.74237

Timestep Collection Time: 2.22816
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.68533

Cumulative Model Updates: 369,148
Cumulative Timesteps: 3,078,723,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.07709
Policy Entropy: 3.98745
Value Function Loss: 0.00593

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02658
Policy Update Magnitude: 0.24848
Value Function Update Magnitude: 0.32927

Collected Steps per Second: 22,247.57536
Overall Steps per Second: 10,520.00625

Timestep Collection Time: 2.24816
Timestep Consumption Time: 2.50621
PPO Batch Consumption Time: 0.29468
Total Iteration Time: 4.75437

Cumulative Model Updates: 369,154
Cumulative Timesteps: 3,078,773,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3078773980...
Checkpoint 3078773980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.29127
Policy Entropy: 3.98381
Value Function Loss: 0.00564

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02325
Policy Update Magnitude: 0.24158
Value Function Update Magnitude: 0.32087

Collected Steps per Second: 23,045.65077
Overall Steps per Second: 10,662.59518

Timestep Collection Time: 2.17056
Timestep Consumption Time: 2.52079
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.69135

Cumulative Model Updates: 369,160
Cumulative Timesteps: 3,078,824,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.12607
Policy Entropy: 3.97617
Value Function Loss: 0.00596

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.23925
Value Function Update Magnitude: 0.32551

Collected Steps per Second: 22,567.00366
Overall Steps per Second: 10,589.57186

Timestep Collection Time: 2.21589
Timestep Consumption Time: 2.50630
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.72219

Cumulative Model Updates: 369,166
Cumulative Timesteps: 3,078,874,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3078874008...
Checkpoint 3078874008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.54011
Policy Entropy: 3.97749
Value Function Loss: 0.00640

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02045
Policy Update Magnitude: 0.24568
Value Function Update Magnitude: 0.34638

Collected Steps per Second: 22,287.13639
Overall Steps per Second: 10,539.05290

Timestep Collection Time: 2.24443
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.74635

Cumulative Model Updates: 369,172
Cumulative Timesteps: 3,078,924,030

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.77418
Policy Entropy: 3.95953
Value Function Loss: 0.00669

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02493
Policy Update Magnitude: 0.25108
Value Function Update Magnitude: 0.34629

Collected Steps per Second: 23,289.11165
Overall Steps per Second: 10,821.79762

Timestep Collection Time: 2.14778
Timestep Consumption Time: 2.47437
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.62215

Cumulative Model Updates: 369,178
Cumulative Timesteps: 3,078,974,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3078974050...
Checkpoint 3078974050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.01238
Policy Entropy: 3.97542
Value Function Loss: 0.00739

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.03174
Policy Update Magnitude: 0.24835
Value Function Update Magnitude: 0.35896

Collected Steps per Second: 22,209.23416
Overall Steps per Second: 10,615.98652

Timestep Collection Time: 2.25267
Timestep Consumption Time: 2.46004
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.71270

Cumulative Model Updates: 369,184
Cumulative Timesteps: 3,079,024,080

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.24447
Policy Entropy: 3.95823
Value Function Loss: 0.00727

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.03659
Policy Update Magnitude: 0.24565
Value Function Update Magnitude: 0.36542

Collected Steps per Second: 22,221.48076
Overall Steps per Second: 10,684.02268

Timestep Collection Time: 2.25080
Timestep Consumption Time: 2.43059
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.68138

Cumulative Model Updates: 369,190
Cumulative Timesteps: 3,079,074,096

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3079074096...
Checkpoint 3079074096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.58801
Policy Entropy: 3.92963
Value Function Loss: 0.00807

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.03239
Policy Update Magnitude: 0.25011
Value Function Update Magnitude: 0.36089

Collected Steps per Second: 22,529.00260
Overall Steps per Second: 10,577.75365

Timestep Collection Time: 2.22025
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29374
Total Iteration Time: 4.72879

Cumulative Model Updates: 369,196
Cumulative Timesteps: 3,079,124,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.53291
Policy Entropy: 3.91570
Value Function Loss: 0.00810

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.03400
Policy Update Magnitude: 0.27131
Value Function Update Magnitude: 0.36116

Collected Steps per Second: 22,457.49780
Overall Steps per Second: 10,691.29403

Timestep Collection Time: 2.22687
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.67764

Cumulative Model Updates: 369,202
Cumulative Timesteps: 3,079,174,126

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3079174126...
Checkpoint 3079174126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.87796
Policy Entropy: 3.90091
Value Function Loss: 0.00803

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.03439
Policy Update Magnitude: 0.27218
Value Function Update Magnitude: 0.36698

Collected Steps per Second: 21,866.21008
Overall Steps per Second: 10,718.54082

Timestep Collection Time: 2.28746
Timestep Consumption Time: 2.37904
PPO Batch Consumption Time: 0.28130
Total Iteration Time: 4.66649

Cumulative Model Updates: 369,208
Cumulative Timesteps: 3,079,224,144

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.40040
Policy Entropy: 3.94337
Value Function Loss: 0.00660

Mean KL Divergence: 0.00504
SB3 Clip Fraction: 0.03291
Policy Update Magnitude: 0.26850
Value Function Update Magnitude: 0.35622

Collected Steps per Second: 22,716.44332
Overall Steps per Second: 10,602.63006

Timestep Collection Time: 2.20255
Timestep Consumption Time: 2.51647
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.71902

Cumulative Model Updates: 369,214
Cumulative Timesteps: 3,079,274,178

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3079274178...
Checkpoint 3079274178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.81325
Policy Entropy: 3.94936
Value Function Loss: 0.00676

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 0.25647
Value Function Update Magnitude: 0.34022

Collected Steps per Second: 22,456.64262
Overall Steps per Second: 10,601.06850

Timestep Collection Time: 2.22651
Timestep Consumption Time: 2.48999
PPO Batch Consumption Time: 0.29406
Total Iteration Time: 4.71651

Cumulative Model Updates: 369,220
Cumulative Timesteps: 3,079,324,178

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.85395
Policy Entropy: 3.95064
Value Function Loss: 0.00651

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02479
Policy Update Magnitude: 0.24819
Value Function Update Magnitude: 0.32468

Collected Steps per Second: 22,738.23851
Overall Steps per Second: 10,827.39268

Timestep Collection Time: 2.19982
Timestep Consumption Time: 2.41995
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.61976

Cumulative Model Updates: 369,226
Cumulative Timesteps: 3,079,374,198

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3079374198...
Checkpoint 3079374198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.44858
Policy Entropy: 3.94740
Value Function Loss: 0.00601

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.24269
Value Function Update Magnitude: 0.31792

Collected Steps per Second: 22,280.67414
Overall Steps per Second: 10,688.21453

Timestep Collection Time: 2.24526
Timestep Consumption Time: 2.43522
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.68048

Cumulative Model Updates: 369,232
Cumulative Timesteps: 3,079,424,224

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.20336
Policy Entropy: 3.95554
Value Function Loss: 0.00558

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02278
Policy Update Magnitude: 0.23689
Value Function Update Magnitude: 0.31269

Collected Steps per Second: 22,531.20208
Overall Steps per Second: 10,791.71375

Timestep Collection Time: 2.21941
Timestep Consumption Time: 2.41433
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.63374

Cumulative Model Updates: 369,238
Cumulative Timesteps: 3,079,474,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3079474230...
Checkpoint 3079474230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.61807
Policy Entropy: 3.99726
Value Function Loss: 0.00513

Mean KL Divergence: 0.00287
SB3 Clip Fraction: 0.02263
Policy Update Magnitude: 0.23752
Value Function Update Magnitude: 0.32336

Collected Steps per Second: 22,866.86367
Overall Steps per Second: 10,711.42664

Timestep Collection Time: 2.18771
Timestep Consumption Time: 2.48263
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.67034

Cumulative Model Updates: 369,244
Cumulative Timesteps: 3,079,524,256

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.91104
Policy Entropy: 3.97930
Value Function Loss: 0.00633

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.24007
Value Function Update Magnitude: 0.34149

Collected Steps per Second: 22,294.50803
Overall Steps per Second: 10,497.64290

Timestep Collection Time: 2.24279
Timestep Consumption Time: 2.52037
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.76316

Cumulative Model Updates: 369,250
Cumulative Timesteps: 3,079,574,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3079574258...
Checkpoint 3079574258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.21830
Policy Entropy: 3.97029
Value Function Loss: 0.00717

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.24707
Value Function Update Magnitude: 0.35659

Collected Steps per Second: 22,269.48562
Overall Steps per Second: 10,586.81711

Timestep Collection Time: 2.24585
Timestep Consumption Time: 2.47832
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.72418

Cumulative Model Updates: 369,256
Cumulative Timesteps: 3,079,624,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.50780
Policy Entropy: 3.98423
Value Function Loss: 0.00592

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.24523
Value Function Update Magnitude: 0.36532

Collected Steps per Second: 23,462.78203
Overall Steps per Second: 10,917.24358

Timestep Collection Time: 2.13189
Timestep Consumption Time: 2.44986
PPO Batch Consumption Time: 0.28008
Total Iteration Time: 4.58174

Cumulative Model Updates: 369,262
Cumulative Timesteps: 3,079,674,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3079674292...
Checkpoint 3079674292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.07162
Policy Entropy: 4.00197
Value Function Loss: 0.00555

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.24262
Value Function Update Magnitude: 0.34454

Collected Steps per Second: 22,365.97767
Overall Steps per Second: 10,689.27985

Timestep Collection Time: 2.23590
Timestep Consumption Time: 2.44244
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.67833

Cumulative Model Updates: 369,268
Cumulative Timesteps: 3,079,724,300

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.59793
Policy Entropy: 3.99316
Value Function Loss: 0.00594

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02809
Policy Update Magnitude: 0.25477
Value Function Update Magnitude: 0.33793

Collected Steps per Second: 22,233.61579
Overall Steps per Second: 10,794.71572

Timestep Collection Time: 2.24903
Timestep Consumption Time: 2.38324
PPO Batch Consumption Time: 0.28149
Total Iteration Time: 4.63227

Cumulative Model Updates: 369,274
Cumulative Timesteps: 3,079,774,304

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3079774304...
Checkpoint 3079774304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.31567
Policy Entropy: 3.94654
Value Function Loss: 0.00617

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.24579
Value Function Update Magnitude: 0.35802

Collected Steps per Second: 22,261.60618
Overall Steps per Second: 10,654.67128

Timestep Collection Time: 2.24728
Timestep Consumption Time: 2.44813
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.69541

Cumulative Model Updates: 369,280
Cumulative Timesteps: 3,079,824,332

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.49201
Policy Entropy: 3.94250
Value Function Loss: 0.00592

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.03253
Policy Update Magnitude: 0.24312
Value Function Update Magnitude: 0.35647

Collected Steps per Second: 22,473.16301
Overall Steps per Second: 10,533.25936

Timestep Collection Time: 2.22585
Timestep Consumption Time: 2.52310
PPO Batch Consumption Time: 0.29500
Total Iteration Time: 4.74896

Cumulative Model Updates: 369,286
Cumulative Timesteps: 3,079,874,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3079874354...
Checkpoint 3079874354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.11956
Policy Entropy: 3.93783
Value Function Loss: 0.00665

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.24750
Value Function Update Magnitude: 0.33731

Collected Steps per Second: 22,320.89453
Overall Steps per Second: 10,697.95984

Timestep Collection Time: 2.24032
Timestep Consumption Time: 2.43403
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.67435

Cumulative Model Updates: 369,292
Cumulative Timesteps: 3,079,924,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.89878
Policy Entropy: 3.95795
Value Function Loss: 0.00612

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02651
Policy Update Magnitude: 0.24584
Value Function Update Magnitude: 0.33516

Collected Steps per Second: 22,831.33052
Overall Steps per Second: 10,761.29227

Timestep Collection Time: 2.19111
Timestep Consumption Time: 2.45759
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.64870

Cumulative Model Updates: 369,298
Cumulative Timesteps: 3,079,974,386

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3079974386...
Checkpoint 3079974386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.18828
Policy Entropy: 3.96027
Value Function Loss: 0.00695

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.27205
Value Function Update Magnitude: 0.33761

Collected Steps per Second: 22,271.44313
Overall Steps per Second: 10,678.72358

Timestep Collection Time: 2.24530
Timestep Consumption Time: 2.43747
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.68277

Cumulative Model Updates: 369,304
Cumulative Timesteps: 3,080,024,392

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.93536
Policy Entropy: 4.00225
Value Function Loss: 0.00650

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.24939
Value Function Update Magnitude: 0.34316

Collected Steps per Second: 23,179.45651
Overall Steps per Second: 10,865.63021

Timestep Collection Time: 2.15708
Timestep Consumption Time: 2.44458
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.60167

Cumulative Model Updates: 369,310
Cumulative Timesteps: 3,080,074,392

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3080074392...
Checkpoint 3080074392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.11530
Policy Entropy: 3.96702
Value Function Loss: 0.00699

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.24740
Value Function Update Magnitude: 0.34712

Collected Steps per Second: 22,311.52104
Overall Steps per Second: 10,667.53549

Timestep Collection Time: 2.24171
Timestep Consumption Time: 2.44691
PPO Batch Consumption Time: 0.27990
Total Iteration Time: 4.68862

Cumulative Model Updates: 369,316
Cumulative Timesteps: 3,080,124,408

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.42302
Policy Entropy: 3.97111
Value Function Loss: 0.00616

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.24428
Value Function Update Magnitude: 0.33638

Collected Steps per Second: 22,444.88568
Overall Steps per Second: 10,565.34416

Timestep Collection Time: 2.22795
Timestep Consumption Time: 2.50508
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.73302

Cumulative Model Updates: 369,322
Cumulative Timesteps: 3,080,174,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3080174414...
Checkpoint 3080174414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.04670
Policy Entropy: 4.00373
Value Function Loss: 0.00468

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02725
Policy Update Magnitude: 0.22965
Value Function Update Magnitude: 0.32759

Collected Steps per Second: 23,095.53163
Overall Steps per Second: 10,711.85437

Timestep Collection Time: 2.16596
Timestep Consumption Time: 2.50401
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.66997

Cumulative Model Updates: 369,328
Cumulative Timesteps: 3,080,224,438

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.87423
Policy Entropy: 4.03426
Value Function Loss: 0.00512

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.22773
Value Function Update Magnitude: 0.30458

Collected Steps per Second: 22,737.13621
Overall Steps per Second: 10,749.37076

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.45298
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.65255

Cumulative Model Updates: 369,334
Cumulative Timesteps: 3,080,274,450

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3080274450...
Checkpoint 3080274450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.67332
Policy Entropy: 4.03057
Value Function Loss: 0.00657

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01968
Policy Update Magnitude: 0.23569
Value Function Update Magnitude: 0.30532

Collected Steps per Second: 22,451.53847
Overall Steps per Second: 10,757.78122

Timestep Collection Time: 2.22738
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.29352
Total Iteration Time: 4.64854

Cumulative Model Updates: 369,340
Cumulative Timesteps: 3,080,324,458

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69312
Policy Entropy: 4.01924
Value Function Loss: 0.00703

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02301
Policy Update Magnitude: 0.24570
Value Function Update Magnitude: 0.33047

Collected Steps per Second: 22,733.04382
Overall Steps per Second: 10,747.71094

Timestep Collection Time: 2.19944
Timestep Consumption Time: 2.45271
PPO Batch Consumption Time: 0.28059
Total Iteration Time: 4.65215

Cumulative Model Updates: 369,346
Cumulative Timesteps: 3,080,374,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3080374458...
Checkpoint 3080374458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.86543
Policy Entropy: 4.01501
Value Function Loss: 0.00657

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.24494
Value Function Update Magnitude: 0.33723

Collected Steps per Second: 22,228.93599
Overall Steps per Second: 10,731.97637

Timestep Collection Time: 2.24977
Timestep Consumption Time: 2.41014
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.65991

Cumulative Model Updates: 369,352
Cumulative Timesteps: 3,080,424,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.21541
Policy Entropy: 3.99037
Value Function Loss: 0.00654

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02541
Policy Update Magnitude: 0.24345
Value Function Update Magnitude: 0.33703

Collected Steps per Second: 22,306.42393
Overall Steps per Second: 10,819.23794

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.38027
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.62214

Cumulative Model Updates: 369,358
Cumulative Timesteps: 3,080,474,476

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3080474476...
Checkpoint 3080474476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.15965
Policy Entropy: 3.96964
Value Function Loss: 0.00690

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02939
Policy Update Magnitude: 0.24885
Value Function Update Magnitude: 0.34468

Collected Steps per Second: 22,185.09379
Overall Steps per Second: 10,636.33998

Timestep Collection Time: 2.25440
Timestep Consumption Time: 2.44778
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.70218

Cumulative Model Updates: 369,364
Cumulative Timesteps: 3,080,524,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.39268
Policy Entropy: 3.97669
Value Function Loss: 0.00718

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.23896
Value Function Update Magnitude: 0.32647

Collected Steps per Second: 22,385.50657
Overall Steps per Second: 10,558.21451

Timestep Collection Time: 2.23430
Timestep Consumption Time: 2.50286
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 4.73716

Cumulative Model Updates: 369,370
Cumulative Timesteps: 3,080,574,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3080574506...
Checkpoint 3080574506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.62951
Policy Entropy: 4.03010
Value Function Loss: 0.00688

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02346
Policy Update Magnitude: 0.23488
Value Function Update Magnitude: 0.31557

Collected Steps per Second: 23,141.75759
Overall Steps per Second: 10,706.22600

Timestep Collection Time: 2.16103
Timestep Consumption Time: 2.51009
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.67111

Cumulative Model Updates: 369,376
Cumulative Timesteps: 3,080,624,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.41592
Policy Entropy: 4.05178
Value Function Loss: 0.00593

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.22609
Value Function Update Magnitude: 0.31220

Collected Steps per Second: 22,726.95048
Overall Steps per Second: 10,723.06431

Timestep Collection Time: 2.20047
Timestep Consumption Time: 2.46331
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.66378

Cumulative Model Updates: 369,382
Cumulative Timesteps: 3,080,674,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3080674526...
Checkpoint 3080674526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.69880
Policy Entropy: 4.01049
Value Function Loss: 0.00645

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02250
Policy Update Magnitude: 0.23798
Value Function Update Magnitude: 0.31225

Collected Steps per Second: 21,764.61432
Overall Steps per Second: 10,746.64010

Timestep Collection Time: 2.29804
Timestep Consumption Time: 2.35606
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.65411

Cumulative Model Updates: 369,388
Cumulative Timesteps: 3,080,724,542

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.57869
Policy Entropy: 3.97732
Value Function Loss: 0.00619

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.24601
Value Function Update Magnitude: 0.33248

Collected Steps per Second: 22,230.83945
Overall Steps per Second: 10,459.93559

Timestep Collection Time: 2.24976
Timestep Consumption Time: 2.53173
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.78148

Cumulative Model Updates: 369,394
Cumulative Timesteps: 3,080,774,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3080774556...
Checkpoint 3080774556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.57045
Policy Entropy: 3.91720
Value Function Loss: 0.00686

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 0.25460
Value Function Update Magnitude: 0.36252

Collected Steps per Second: 22,216.90851
Overall Steps per Second: 10,646.33472

Timestep Collection Time: 2.25162
Timestep Consumption Time: 2.44709
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.69871

Cumulative Model Updates: 369,400
Cumulative Timesteps: 3,080,824,580

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.01177
Policy Entropy: 3.95961
Value Function Loss: 0.00644

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02717
Policy Update Magnitude: 0.25426
Value Function Update Magnitude: 0.36398

Collected Steps per Second: 22,233.97282
Overall Steps per Second: 10,812.08120

Timestep Collection Time: 2.24953
Timestep Consumption Time: 2.37641
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.62594

Cumulative Model Updates: 369,406
Cumulative Timesteps: 3,080,874,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3080874596...
Checkpoint 3080874596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.33286
Policy Entropy: 3.99877
Value Function Loss: 0.00527

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02805
Policy Update Magnitude: 0.24693
Value Function Update Magnitude: 0.34327

Collected Steps per Second: 22,656.22498
Overall Steps per Second: 10,765.52447

Timestep Collection Time: 2.20796
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.64668

Cumulative Model Updates: 369,412
Cumulative Timesteps: 3,080,924,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.60248
Policy Entropy: 4.02588
Value Function Loss: 0.00517

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02441
Policy Update Magnitude: 0.23451
Value Function Update Magnitude: 0.32037

Collected Steps per Second: 22,467.99701
Overall Steps per Second: 10,732.79059

Timestep Collection Time: 2.22646
Timestep Consumption Time: 2.43440
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.66086

Cumulative Model Updates: 369,418
Cumulative Timesteps: 3,080,974,644

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3080974644...
Checkpoint 3080974644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.84749
Policy Entropy: 4.01342
Value Function Loss: 0.00516

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02017
Policy Update Magnitude: 0.22793
Value Function Update Magnitude: 0.31761

Collected Steps per Second: 22,230.89236
Overall Steps per Second: 10,757.34639

Timestep Collection Time: 2.25038
Timestep Consumption Time: 2.40021
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.65059

Cumulative Model Updates: 369,424
Cumulative Timesteps: 3,081,024,672

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.55908
Policy Entropy: 3.98629
Value Function Loss: 0.00591

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02215
Policy Update Magnitude: 0.23220
Value Function Update Magnitude: 0.34285

Collected Steps per Second: 22,804.35770
Overall Steps per Second: 10,651.25109

Timestep Collection Time: 2.19265
Timestep Consumption Time: 2.50182
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.69447

Cumulative Model Updates: 369,430
Cumulative Timesteps: 3,081,074,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3081074674...
Checkpoint 3081074674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.96262
Policy Entropy: 3.98338
Value Function Loss: 0.00589

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02211
Policy Update Magnitude: 0.23472
Value Function Update Magnitude: 0.34911

Collected Steps per Second: 22,435.69071
Overall Steps per Second: 10,645.52057

Timestep Collection Time: 2.22948
Timestep Consumption Time: 2.46921
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.69869

Cumulative Model Updates: 369,436
Cumulative Timesteps: 3,081,124,694

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.12017
Policy Entropy: 3.97302
Value Function Loss: 0.00587

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02310
Policy Update Magnitude: 0.25407
Value Function Update Magnitude: 0.33489

Collected Steps per Second: 23,245.40193
Overall Steps per Second: 10,715.53428

Timestep Collection Time: 2.15114
Timestep Consumption Time: 2.51536
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 4.66650

Cumulative Model Updates: 369,442
Cumulative Timesteps: 3,081,174,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3081174698...
Checkpoint 3081174698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.20150
Policy Entropy: 3.94711
Value Function Loss: 0.00606

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02441
Policy Update Magnitude: 0.23909
Value Function Update Magnitude: 0.32434

Collected Steps per Second: 22,368.36315
Overall Steps per Second: 10,606.86602

Timestep Collection Time: 2.23602
Timestep Consumption Time: 2.47942
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.71544

Cumulative Model Updates: 369,448
Cumulative Timesteps: 3,081,224,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.39846
Policy Entropy: 3.95284
Value Function Loss: 0.00609

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02633
Policy Update Magnitude: 0.23673
Value Function Update Magnitude: 0.31504

Collected Steps per Second: 22,405.56245
Overall Steps per Second: 10,557.20324

Timestep Collection Time: 2.23257
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29435
Total Iteration Time: 4.73819

Cumulative Model Updates: 369,454
Cumulative Timesteps: 3,081,274,736

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3081274736...
Checkpoint 3081274736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.38109
Policy Entropy: 3.92195
Value Function Loss: 0.00676

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02875
Policy Update Magnitude: 0.24271
Value Function Update Magnitude: 0.31954

Collected Steps per Second: 22,317.41866
Overall Steps per Second: 10,743.83836

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.41478
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.65644

Cumulative Model Updates: 369,460
Cumulative Timesteps: 3,081,324,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.61504
Policy Entropy: 3.91912
Value Function Loss: 0.00649

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02945
Policy Update Magnitude: 0.24777
Value Function Update Magnitude: 0.33159

Collected Steps per Second: 22,556.62902
Overall Steps per Second: 10,697.52408

Timestep Collection Time: 2.21735
Timestep Consumption Time: 2.45812
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.67547

Cumulative Model Updates: 369,466
Cumulative Timesteps: 3,081,374,780

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3081374780...
Checkpoint 3081374780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.30039
Policy Entropy: 3.93377
Value Function Loss: 0.00658

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02849
Policy Update Magnitude: 0.24769
Value Function Update Magnitude: 0.33267

Collected Steps per Second: 22,155.35735
Overall Steps per Second: 10,661.72804

Timestep Collection Time: 2.25679
Timestep Consumption Time: 2.43288
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.68967

Cumulative Model Updates: 369,472
Cumulative Timesteps: 3,081,424,780

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.16544
Policy Entropy: 3.99916
Value Function Loss: 0.00627

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.24222
Value Function Update Magnitude: 0.32361

Collected Steps per Second: 23,357.75534
Overall Steps per Second: 10,870.93366

Timestep Collection Time: 2.14079
Timestep Consumption Time: 2.45900
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.59979

Cumulative Model Updates: 369,478
Cumulative Timesteps: 3,081,474,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3081474784...
Checkpoint 3081474784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.58683
Policy Entropy: 4.01284
Value Function Loss: 0.00666

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.23758
Value Function Update Magnitude: 0.31380

Collected Steps per Second: 22,345.89258
Overall Steps per Second: 10,664.26797

Timestep Collection Time: 2.23871
Timestep Consumption Time: 2.45228
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.69099

Cumulative Model Updates: 369,484
Cumulative Timesteps: 3,081,524,810

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.89749
Policy Entropy: 4.00281
Value Function Loss: 0.00618

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.02825
Policy Update Magnitude: 0.23571
Value Function Update Magnitude: 0.31230

Collected Steps per Second: 22,292.63121
Overall Steps per Second: 10,530.91237

Timestep Collection Time: 2.24343
Timestep Consumption Time: 2.50563
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.74907

Cumulative Model Updates: 369,490
Cumulative Timesteps: 3,081,574,822

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3081574822...
Checkpoint 3081574822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.94454
Policy Entropy: 4.00114
Value Function Loss: 0.00576

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02577
Policy Update Magnitude: 0.23584
Value Function Update Magnitude: 0.30434

Collected Steps per Second: 23,060.77674
Overall Steps per Second: 10,691.98378

Timestep Collection Time: 2.16948
Timestep Consumption Time: 2.50972
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.67921

Cumulative Model Updates: 369,496
Cumulative Timesteps: 3,081,624,852

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.74949
Policy Entropy: 4.02165
Value Function Loss: 0.00517

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02138
Policy Update Magnitude: 0.22191
Value Function Update Magnitude: 0.29686

Collected Steps per Second: 22,596.45052
Overall Steps per Second: 10,727.66972

Timestep Collection Time: 2.21362
Timestep Consumption Time: 2.44909
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.66271

Cumulative Model Updates: 369,502
Cumulative Timesteps: 3,081,674,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3081674872...
Checkpoint 3081674872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.44035
Policy Entropy: 4.01692
Value Function Loss: 0.00488

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02208
Policy Update Magnitude: 0.21928
Value Function Update Magnitude: 0.29317

Collected Steps per Second: 22,275.53088
Overall Steps per Second: 10,740.69488

Timestep Collection Time: 2.24471
Timestep Consumption Time: 2.41067
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.65538

Cumulative Model Updates: 369,508
Cumulative Timesteps: 3,081,724,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.66383
Policy Entropy: 4.00079
Value Function Loss: 0.00566

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.23167
Value Function Update Magnitude: 0.28540

Collected Steps per Second: 22,631.32741
Overall Steps per Second: 10,583.54182

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.51529
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.72488

Cumulative Model Updates: 369,514
Cumulative Timesteps: 3,081,774,880

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3081774880...
Checkpoint 3081774880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.28551
Policy Entropy: 3.99728
Value Function Loss: 0.00619

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02663
Policy Update Magnitude: 0.24922
Value Function Update Magnitude: 0.31691

Collected Steps per Second: 22,383.56264
Overall Steps per Second: 10,638.96727

Timestep Collection Time: 2.23512
Timestep Consumption Time: 2.46740
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.70252

Cumulative Model Updates: 369,520
Cumulative Timesteps: 3,081,824,910

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.99449
Policy Entropy: 3.98830
Value Function Loss: 0.00692

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.25834
Value Function Update Magnitude: 0.34943

Collected Steps per Second: 22,621.34578
Overall Steps per Second: 10,774.17461

Timestep Collection Time: 2.21145
Timestep Consumption Time: 2.43169
PPO Batch Consumption Time: 0.28961
Total Iteration Time: 4.64314

Cumulative Model Updates: 369,526
Cumulative Timesteps: 3,081,874,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3081874936...
Checkpoint 3081874936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.36730
Policy Entropy: 3.97380
Value Function Loss: 0.00740

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.25782
Value Function Update Magnitude: 0.36264

Collected Steps per Second: 22,348.85671
Overall Steps per Second: 10,690.43029

Timestep Collection Time: 2.23734
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.67727

Cumulative Model Updates: 369,532
Cumulative Timesteps: 3,081,924,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.15011
Policy Entropy: 3.96294
Value Function Loss: 0.00701

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02380
Policy Update Magnitude: 0.25315
Value Function Update Magnitude: 0.37289

Collected Steps per Second: 22,624.97184
Overall Steps per Second: 10,767.95096

Timestep Collection Time: 2.21004
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.28000
Total Iteration Time: 4.64359

Cumulative Model Updates: 369,538
Cumulative Timesteps: 3,081,974,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3081974940...
Checkpoint 3081974940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.33576
Policy Entropy: 3.96921
Value Function Loss: 0.00712

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.25828
Value Function Update Magnitude: 0.36643

Collected Steps per Second: 22,936.91276
Overall Steps per Second: 10,683.79287

Timestep Collection Time: 2.18033
Timestep Consumption Time: 2.50059
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.68092

Cumulative Model Updates: 369,544
Cumulative Timesteps: 3,082,024,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.23403
Policy Entropy: 3.99374
Value Function Loss: 0.00728

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02309
Policy Update Magnitude: 0.25263
Value Function Update Magnitude: 0.35574

Collected Steps per Second: 22,491.35804
Overall Steps per Second: 10,519.64726

Timestep Collection Time: 2.22316
Timestep Consumption Time: 2.53004
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.75320

Cumulative Model Updates: 369,550
Cumulative Timesteps: 3,082,074,952

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3082074952...
Checkpoint 3082074952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.46521
Policy Entropy: 3.99385
Value Function Loss: 0.00666

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02292
Policy Update Magnitude: 0.24936
Value Function Update Magnitude: 0.36135

Collected Steps per Second: 21,885.70780
Overall Steps per Second: 10,639.10518

Timestep Collection Time: 2.28560
Timestep Consumption Time: 2.41611
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.70171

Cumulative Model Updates: 369,556
Cumulative Timesteps: 3,082,124,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.65050
Policy Entropy: 3.97779
Value Function Loss: 0.00625

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02463
Policy Update Magnitude: 0.24219
Value Function Update Magnitude: 0.35123

Collected Steps per Second: 23,449.40263
Overall Steps per Second: 10,859.54200

Timestep Collection Time: 2.13293
Timestep Consumption Time: 2.47279
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.60572

Cumulative Model Updates: 369,562
Cumulative Timesteps: 3,082,174,990

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3082174990...
Checkpoint 3082174990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.03206
Policy Entropy: 3.97877
Value Function Loss: 0.00659

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02398
Policy Update Magnitude: 0.24425
Value Function Update Magnitude: 0.33543

Collected Steps per Second: 22,413.73375
Overall Steps per Second: 10,691.04532

Timestep Collection Time: 2.23095
Timestep Consumption Time: 2.44623
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.67719

Cumulative Model Updates: 369,568
Cumulative Timesteps: 3,082,224,994

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.68631
Policy Entropy: 3.98842
Value Function Loss: 0.00708

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.24628
Value Function Update Magnitude: 0.36229

Collected Steps per Second: 22,567.61906
Overall Steps per Second: 10,775.09335

Timestep Collection Time: 2.21672
Timestep Consumption Time: 2.42603
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.64274

Cumulative Model Updates: 369,574
Cumulative Timesteps: 3,082,275,020

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3082275020...
Checkpoint 3082275020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.01499
Policy Entropy: 4.01102
Value Function Loss: 0.00668

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02143
Policy Update Magnitude: 0.24493
Value Function Update Magnitude: 0.36654

Collected Steps per Second: 23,070.67852
Overall Steps per Second: 10,753.59580

Timestep Collection Time: 2.16743
Timestep Consumption Time: 2.48255
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.64998

Cumulative Model Updates: 369,580
Cumulative Timesteps: 3,082,325,024

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.76041
Policy Entropy: 4.00431
Value Function Loss: 0.00685

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02471
Policy Update Magnitude: 0.24593
Value Function Update Magnitude: 0.35439

Collected Steps per Second: 22,337.47387
Overall Steps per Second: 10,514.99754

Timestep Collection Time: 2.23920
Timestep Consumption Time: 2.51763
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.75682

Cumulative Model Updates: 369,586
Cumulative Timesteps: 3,082,375,042

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3082375042...
Checkpoint 3082375042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.95651
Policy Entropy: 3.98558
Value Function Loss: 0.00735

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.24646
Value Function Update Magnitude: 0.36107

Collected Steps per Second: 22,380.63512
Overall Steps per Second: 10,774.93853

Timestep Collection Time: 2.23461
Timestep Consumption Time: 2.40690
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.64151

Cumulative Model Updates: 369,592
Cumulative Timesteps: 3,082,425,054

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.81150
Policy Entropy: 3.98793
Value Function Loss: 0.00673

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.24439
Value Function Update Magnitude: 0.36349

Collected Steps per Second: 22,803.95855
Overall Steps per Second: 10,713.75061

Timestep Collection Time: 2.19313
Timestep Consumption Time: 2.47489
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.66802

Cumulative Model Updates: 369,598
Cumulative Timesteps: 3,082,475,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3082475066...
Checkpoint 3082475066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.53366
Policy Entropy: 3.99191
Value Function Loss: 0.00665

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02609
Policy Update Magnitude: 0.24587
Value Function Update Magnitude: 0.35876

Collected Steps per Second: 22,404.34375
Overall Steps per Second: 10,628.24461

Timestep Collection Time: 2.23225
Timestep Consumption Time: 2.47333
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.70557

Cumulative Model Updates: 369,604
Cumulative Timesteps: 3,082,525,078

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.25845
Policy Entropy: 3.98328
Value Function Loss: 0.00623

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02674
Policy Update Magnitude: 0.25980
Value Function Update Magnitude: 0.35181

Collected Steps per Second: 23,263.63404
Overall Steps per Second: 10,863.56810

Timestep Collection Time: 2.15039
Timestep Consumption Time: 2.45454
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.60493

Cumulative Model Updates: 369,610
Cumulative Timesteps: 3,082,575,104

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3082575104...
Checkpoint 3082575104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.14412
Policy Entropy: 3.94279
Value Function Loss: 0.00656

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.03072
Policy Update Magnitude: 0.25767
Value Function Update Magnitude: 0.35492

Collected Steps per Second: 22,407.60269
Overall Steps per Second: 10,736.22595

Timestep Collection Time: 2.23201
Timestep Consumption Time: 2.42642
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.65843

Cumulative Model Updates: 369,616
Cumulative Timesteps: 3,082,625,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.63455
Policy Entropy: 3.95052
Value Function Loss: 0.00605

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.03019
Policy Update Magnitude: 0.25896
Value Function Update Magnitude: 0.36256

Collected Steps per Second: 22,567.27025
Overall Steps per Second: 10,775.43852

Timestep Collection Time: 2.21578
Timestep Consumption Time: 2.42478
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.64055

Cumulative Model Updates: 369,622
Cumulative Timesteps: 3,082,675,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3082675122...
Checkpoint 3082675122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.73569
Policy Entropy: 4.00561
Value Function Loss: 0.00534

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02580
Policy Update Magnitude: 0.24098
Value Function Update Magnitude: 0.34500

Collected Steps per Second: 23,200.67433
Overall Steps per Second: 10,744.32439

Timestep Collection Time: 2.15563
Timestep Consumption Time: 2.49911
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.65474

Cumulative Model Updates: 369,628
Cumulative Timesteps: 3,082,725,134

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.33134
Policy Entropy: 4.00983
Value Function Loss: 0.00579

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02385
Policy Update Magnitude: 0.23146
Value Function Update Magnitude: 0.32978

Collected Steps per Second: 22,507.56973
Overall Steps per Second: 10,541.75365

Timestep Collection Time: 2.22201
Timestep Consumption Time: 2.52217
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.74418

Cumulative Model Updates: 369,634
Cumulative Timesteps: 3,082,775,146

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3082775146...
Checkpoint 3082775146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.63949
Policy Entropy: 4.02239
Value Function Loss: 0.00513

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.22831
Value Function Update Magnitude: 0.34258

Collected Steps per Second: 22,514.96124
Overall Steps per Second: 10,580.22853

Timestep Collection Time: 2.22119
Timestep Consumption Time: 2.50555
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.72674

Cumulative Model Updates: 369,640
Cumulative Timesteps: 3,082,825,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.48151
Policy Entropy: 3.96385
Value Function Loss: 0.00678

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 0.24810
Value Function Update Magnitude: 0.34991

Collected Steps per Second: 23,454.61553
Overall Steps per Second: 10,936.19380

Timestep Collection Time: 2.13289
Timestep Consumption Time: 2.44147
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.57435

Cumulative Model Updates: 369,646
Cumulative Timesteps: 3,082,875,182

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3082875182...
Checkpoint 3082875182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.72296
Policy Entropy: 3.96104
Value Function Loss: 0.00698

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02701
Policy Update Magnitude: 0.27121
Value Function Update Magnitude: 0.36642

Collected Steps per Second: 22,134.14047
Overall Steps per Second: 10,630.50922

Timestep Collection Time: 2.25932
Timestep Consumption Time: 2.44488
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.70420

Cumulative Model Updates: 369,652
Cumulative Timesteps: 3,082,925,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.22742
Policy Entropy: 3.92014
Value Function Loss: 0.00757

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.03516
Policy Update Magnitude: 0.27262
Value Function Update Magnitude: 0.37243

Collected Steps per Second: 22,195.18962
Overall Steps per Second: 10,533.53722

Timestep Collection Time: 2.25382
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.74902

Cumulative Model Updates: 369,658
Cumulative Timesteps: 3,082,975,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3082975214...
Checkpoint 3082975214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.54423
Policy Entropy: 3.91702
Value Function Loss: 0.00728

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.04016
Policy Update Magnitude: 0.27166
Value Function Update Magnitude: 0.36643

Collected Steps per Second: 23,265.78412
Overall Steps per Second: 10,887.92497

Timestep Collection Time: 2.15037
Timestep Consumption Time: 2.44463
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.59500

Cumulative Model Updates: 369,664
Cumulative Timesteps: 3,083,025,244

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.06724
Policy Entropy: 3.96696
Value Function Loss: 0.00579

Mean KL Divergence: 0.00659
SB3 Clip Fraction: 0.03948
Policy Update Magnitude: 0.26614
Value Function Update Magnitude: 0.36126

Collected Steps per Second: 22,548.99525
Overall Steps per Second: 10,539.83718

Timestep Collection Time: 2.21739
Timestep Consumption Time: 2.52651
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.74391

Cumulative Model Updates: 369,670
Cumulative Timesteps: 3,083,075,244

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3083075244...
Checkpoint 3083075244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.62650
Policy Entropy: 3.96869
Value Function Loss: 0.00603

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.04113
Policy Update Magnitude: 0.25304
Value Function Update Magnitude: 0.33200

Collected Steps per Second: 22,252.27649
Overall Steps per Second: 10,721.44179

Timestep Collection Time: 2.24786
Timestep Consumption Time: 2.41756
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.66542

Cumulative Model Updates: 369,676
Cumulative Timesteps: 3,083,125,264

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.74833
Policy Entropy: 4.00592
Value Function Loss: 0.00646

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.25945
Value Function Update Magnitude: 0.33225

Collected Steps per Second: 23,218.41478
Overall Steps per Second: 10,871.80581

Timestep Collection Time: 2.15364
Timestep Consumption Time: 2.44578
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.59942

Cumulative Model Updates: 369,682
Cumulative Timesteps: 3,083,175,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3083175268...
Checkpoint 3083175268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.00911
Policy Entropy: 3.97114
Value Function Loss: 0.00720

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.02975
Policy Update Magnitude: 0.25602
Value Function Update Magnitude: 0.36290

Collected Steps per Second: 22,180.22933
Overall Steps per Second: 10,612.42063

Timestep Collection Time: 2.25435
Timestep Consumption Time: 2.45730
PPO Batch Consumption Time: 0.28114
Total Iteration Time: 4.71165

Cumulative Model Updates: 369,688
Cumulative Timesteps: 3,083,225,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.14901
Policy Entropy: 4.02106
Value Function Loss: 0.00587

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02454
Policy Update Magnitude: 0.24983
Value Function Update Magnitude: 0.36961

Collected Steps per Second: 22,521.27364
Overall Steps per Second: 10,907.76149

Timestep Collection Time: 2.22181
Timestep Consumption Time: 2.36557
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.58738

Cumulative Model Updates: 369,694
Cumulative Timesteps: 3,083,275,308

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3083275308...
Checkpoint 3083275308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.77521
Policy Entropy: 3.97884
Value Function Loss: 0.00659

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.26784
Value Function Update Magnitude: 0.35153

Collected Steps per Second: 22,320.58395
Overall Steps per Second: 10,671.62044

Timestep Collection Time: 2.24107
Timestep Consumption Time: 2.44632
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.68739

Cumulative Model Updates: 369,700
Cumulative Timesteps: 3,083,325,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.02771
Policy Entropy: 3.94214
Value Function Loss: 0.00685

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.27550
Value Function Update Magnitude: 0.35167

Collected Steps per Second: 22,283.57267
Overall Steps per Second: 10,566.05348

Timestep Collection Time: 2.24506
Timestep Consumption Time: 2.48972
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.73479

Cumulative Model Updates: 369,706
Cumulative Timesteps: 3,083,375,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3083375358...
Checkpoint 3083375358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.33537
Policy Entropy: 3.88295
Value Function Loss: 0.00697

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.03205
Policy Update Magnitude: 0.27281
Value Function Update Magnitude: 0.37624

Collected Steps per Second: 22,114.99915
Overall Steps per Second: 10,633.07235

Timestep Collection Time: 2.26172
Timestep Consumption Time: 2.44228
PPO Batch Consumption Time: 0.29428
Total Iteration Time: 4.70400

Cumulative Model Updates: 369,712
Cumulative Timesteps: 3,083,425,376

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.26911
Policy Entropy: 3.91879
Value Function Loss: 0.00601

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.26351
Value Function Update Magnitude: 0.37187

Collected Steps per Second: 22,683.16792
Overall Steps per Second: 10,764.87302

Timestep Collection Time: 2.20534
Timestep Consumption Time: 2.44163
PPO Batch Consumption Time: 0.27955
Total Iteration Time: 4.64697

Cumulative Model Updates: 369,718
Cumulative Timesteps: 3,083,475,400

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3083475400...
Checkpoint 3083475400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.04878
Policy Entropy: 3.95662
Value Function Loss: 0.00633

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.25511
Value Function Update Magnitude: 0.34270

Collected Steps per Second: 22,353.94537
Overall Steps per Second: 10,767.80676

Timestep Collection Time: 2.23710
Timestep Consumption Time: 2.40711
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.64421

Cumulative Model Updates: 369,724
Cumulative Timesteps: 3,083,525,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.95638
Policy Entropy: 3.99020
Value Function Loss: 0.00633

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.25031
Value Function Update Magnitude: 0.33900

Collected Steps per Second: 23,259.34326
Overall Steps per Second: 10,845.03747

Timestep Collection Time: 2.15010
Timestep Consumption Time: 2.46122
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.61133

Cumulative Model Updates: 369,730
Cumulative Timesteps: 3,083,575,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3083575418...
Checkpoint 3083575418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.57933
Policy Entropy: 3.98331
Value Function Loss: 0.00661

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.24764
Value Function Update Magnitude: 0.34301

Collected Steps per Second: 22,445.56117
Overall Steps per Second: 10,720.29643

Timestep Collection Time: 2.22886
Timestep Consumption Time: 2.43780
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.66666

Cumulative Model Updates: 369,736
Cumulative Timesteps: 3,083,625,446

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.16975
Policy Entropy: 3.98472
Value Function Loss: 0.00558

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02378
Policy Update Magnitude: 0.24527
Value Function Update Magnitude: 0.34173

Collected Steps per Second: 22,509.42657
Overall Steps per Second: 10,765.10031

Timestep Collection Time: 2.22165
Timestep Consumption Time: 2.42373
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.64538

Cumulative Model Updates: 369,742
Cumulative Timesteps: 3,083,675,454

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3083675454...
Checkpoint 3083675454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.13980
Policy Entropy: 3.99416
Value Function Loss: 0.00606

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02625
Policy Update Magnitude: 0.24216
Value Function Update Magnitude: 0.34957

Collected Steps per Second: 23,085.69565
Overall Steps per Second: 10,758.58942

Timestep Collection Time: 2.16602
Timestep Consumption Time: 2.48180
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.64782

Cumulative Model Updates: 369,748
Cumulative Timesteps: 3,083,725,458

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.83545
Policy Entropy: 3.94368
Value Function Loss: 0.00677

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02701
Policy Update Magnitude: 0.24843
Value Function Update Magnitude: 0.34859

Collected Steps per Second: 22,411.83531
Overall Steps per Second: 10,564.96532

Timestep Collection Time: 2.23096
Timestep Consumption Time: 2.50166
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.73262

Cumulative Model Updates: 369,754
Cumulative Timesteps: 3,083,775,458

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3083775458...
Checkpoint 3083775458 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.36217
Policy Entropy: 3.94397
Value Function Loss: 0.00760

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.25712
Value Function Update Magnitude: 0.34377

Collected Steps per Second: 22,459.12919
Overall Steps per Second: 10,596.33576

Timestep Collection Time: 2.22751
Timestep Consumption Time: 2.49374
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.72125

Cumulative Model Updates: 369,760
Cumulative Timesteps: 3,083,825,486

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.06632
Policy Entropy: 3.94666
Value Function Loss: 0.00661

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 0.25546
Value Function Update Magnitude: 0.33446

Collected Steps per Second: 23,406.82209
Overall Steps per Second: 10,801.57908

Timestep Collection Time: 2.13639
Timestep Consumption Time: 2.49312
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.62951

Cumulative Model Updates: 369,766
Cumulative Timesteps: 3,083,875,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3083875492...
Checkpoint 3083875492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.08142
Policy Entropy: 3.97013
Value Function Loss: 0.00672

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02781
Policy Update Magnitude: 0.25171
Value Function Update Magnitude: 0.32030

Collected Steps per Second: 22,392.76009
Overall Steps per Second: 10,713.59074

Timestep Collection Time: 2.23322
Timestep Consumption Time: 2.43449
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.66772

Cumulative Model Updates: 369,772
Cumulative Timesteps: 3,083,925,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.51062
Policy Entropy: 3.95454
Value Function Loss: 0.00714

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.25926
Value Function Update Magnitude: 0.33954

Collected Steps per Second: 21,783.62085
Overall Steps per Second: 10,431.38290

Timestep Collection Time: 2.29585
Timestep Consumption Time: 2.49853
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.79438

Cumulative Model Updates: 369,778
Cumulative Timesteps: 3,083,975,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3083975512...
Checkpoint 3083975512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.99541
Policy Entropy: 3.94635
Value Function Loss: 0.00721

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.02786
Policy Update Magnitude: 0.25582
Value Function Update Magnitude: 0.36500

Collected Steps per Second: 23,003.09166
Overall Steps per Second: 10,663.86357

Timestep Collection Time: 2.17388
Timestep Consumption Time: 2.51541
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.68929

Cumulative Model Updates: 369,784
Cumulative Timesteps: 3,084,025,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.60143
Policy Entropy: 3.96139
Value Function Loss: 0.00699

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.25795
Value Function Update Magnitude: 0.37165

Collected Steps per Second: 22,559.34533
Overall Steps per Second: 10,613.16382

Timestep Collection Time: 2.21771
Timestep Consumption Time: 2.49625
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.71396

Cumulative Model Updates: 369,790
Cumulative Timesteps: 3,084,075,548

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3084075548...
Checkpoint 3084075548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.89703
Policy Entropy: 4.00374
Value Function Loss: 0.00624

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02327
Policy Update Magnitude: 0.24860
Value Function Update Magnitude: 0.36664

Collected Steps per Second: 22,408.99671
Overall Steps per Second: 10,904.07110

Timestep Collection Time: 2.23214
Timestep Consumption Time: 2.35514
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.58728

Cumulative Model Updates: 369,796
Cumulative Timesteps: 3,084,125,568

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.97997
Policy Entropy: 3.97673
Value Function Loss: 0.00702

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.25207
Value Function Update Magnitude: 0.35948

Collected Steps per Second: 22,467.05843
Overall Steps per Second: 10,542.53044

Timestep Collection Time: 2.22557
Timestep Consumption Time: 2.51731
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.74288

Cumulative Model Updates: 369,802
Cumulative Timesteps: 3,084,175,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3084175570...
Checkpoint 3084175570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.64143
Policy Entropy: 3.98396
Value Function Loss: 0.00615

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.24940
Value Function Update Magnitude: 0.35881

Collected Steps per Second: 22,371.33864
Overall Steps per Second: 10,585.05415

Timestep Collection Time: 2.23599
Timestep Consumption Time: 2.48973
PPO Batch Consumption Time: 0.29446
Total Iteration Time: 4.72572

Cumulative Model Updates: 369,808
Cumulative Timesteps: 3,084,225,592

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.94627
Policy Entropy: 3.98921
Value Function Loss: 0.00585

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02518
Policy Update Magnitude: 0.24577
Value Function Update Magnitude: 0.35145

Collected Steps per Second: 22,129.25785
Overall Steps per Second: 10,790.61382

Timestep Collection Time: 2.26063
Timestep Consumption Time: 2.37544
PPO Batch Consumption Time: 0.27983
Total Iteration Time: 4.63607

Cumulative Model Updates: 369,814
Cumulative Timesteps: 3,084,275,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3084275618...
Checkpoint 3084275618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.52180
Policy Entropy: 4.02699
Value Function Loss: 0.00593

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02036
Policy Update Magnitude: 0.24397
Value Function Update Magnitude: 0.33005

Collected Steps per Second: 22,418.62064
Overall Steps per Second: 10,697.74860

Timestep Collection Time: 2.23056
Timestep Consumption Time: 2.44389
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.67444

Cumulative Model Updates: 369,820
Cumulative Timesteps: 3,084,325,624

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.80632
Policy Entropy: 4.00968
Value Function Loss: 0.00647

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.02014
Policy Update Magnitude: 0.24063
Value Function Update Magnitude: 0.30728

Collected Steps per Second: 22,360.29810
Overall Steps per Second: 10,559.43447

Timestep Collection Time: 2.23682
Timestep Consumption Time: 2.49980
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.73662

Cumulative Model Updates: 369,826
Cumulative Timesteps: 3,084,375,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3084375640...
Checkpoint 3084375640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.20966
Policy Entropy: 3.97581
Value Function Loss: 0.00713

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.24608
Value Function Update Magnitude: 0.31524

Collected Steps per Second: 22,642.16786
Overall Steps per Second: 10,596.98451

Timestep Collection Time: 2.20880
Timestep Consumption Time: 2.51066
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.71946

Cumulative Model Updates: 369,832
Cumulative Timesteps: 3,084,425,652

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.88140
Policy Entropy: 3.96030
Value Function Loss: 0.00654

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.02895
Policy Update Magnitude: 0.24281
Value Function Update Magnitude: 0.32629

Collected Steps per Second: 22,685.63863
Overall Steps per Second: 10,770.79811

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.43834
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.64255

Cumulative Model Updates: 369,838
Cumulative Timesteps: 3,084,475,656

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3084475656...
Checkpoint 3084475656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.62967
Policy Entropy: 3.99325
Value Function Loss: 0.00576

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02355
Policy Update Magnitude: 0.23362
Value Function Update Magnitude: 0.33187

Collected Steps per Second: 22,357.57115
Overall Steps per Second: 10,745.71586

Timestep Collection Time: 2.23754
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.65544

Cumulative Model Updates: 369,844
Cumulative Timesteps: 3,084,525,682

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.20925
Policy Entropy: 4.00470
Value Function Loss: 0.00571

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02191
Policy Update Magnitude: 0.23147
Value Function Update Magnitude: 0.31431

Collected Steps per Second: 23,224.17602
Overall Steps per Second: 10,847.68728

Timestep Collection Time: 2.15388
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.61131

Cumulative Model Updates: 369,850
Cumulative Timesteps: 3,084,575,704

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3084575704...
Checkpoint 3084575704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.54040
Policy Entropy: 3.98567
Value Function Loss: 0.00662

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.23581
Value Function Update Magnitude: 0.30384

Collected Steps per Second: 22,434.57013
Overall Steps per Second: 10,742.38790

Timestep Collection Time: 2.23004
Timestep Consumption Time: 2.42721
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.65725

Cumulative Model Updates: 369,856
Cumulative Timesteps: 3,084,625,734

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.06187
Policy Entropy: 3.94316
Value Function Loss: 0.00707

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02568
Policy Update Magnitude: 0.24688
Value Function Update Magnitude: 0.31578

Collected Steps per Second: 22,522.49210
Overall Steps per Second: 10,872.57052

Timestep Collection Time: 2.22071
Timestep Consumption Time: 2.37949
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.60020

Cumulative Model Updates: 369,862
Cumulative Timesteps: 3,084,675,750

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3084675750...
Checkpoint 3084675750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.17158
Policy Entropy: 3.94263
Value Function Loss: 0.00720

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02716
Policy Update Magnitude: 0.24918
Value Function Update Magnitude: 0.32700

Collected Steps per Second: 22,732.39808
Overall Steps per Second: 10,663.76570

Timestep Collection Time: 2.20074
Timestep Consumption Time: 2.49067
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.69140

Cumulative Model Updates: 369,868
Cumulative Timesteps: 3,084,725,778

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.17135
Policy Entropy: 3.97323
Value Function Loss: 0.00637

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02791
Policy Update Magnitude: 0.24433
Value Function Update Magnitude: 0.32496

Collected Steps per Second: 22,450.38019
Overall Steps per Second: 10,612.72107

Timestep Collection Time: 2.22820
Timestep Consumption Time: 2.48539
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.71359

Cumulative Model Updates: 369,874
Cumulative Timesteps: 3,084,775,802

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3084775802...
Checkpoint 3084775802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.15643
Policy Entropy: 3.99349
Value Function Loss: 0.00610

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02509
Policy Update Magnitude: 0.23134
Value Function Update Magnitude: 0.31868

Collected Steps per Second: 22,260.06852
Overall Steps per Second: 10,823.73965

Timestep Collection Time: 2.24698
Timestep Consumption Time: 2.37416
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.62114

Cumulative Model Updates: 369,880
Cumulative Timesteps: 3,084,825,820

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.74829
Policy Entropy: 3.99315
Value Function Loss: 0.00598

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.23742
Value Function Update Magnitude: 0.32485

Collected Steps per Second: 22,558.27494
Overall Steps per Second: 10,514.48868

Timestep Collection Time: 2.21657
Timestep Consumption Time: 2.53896
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 4.75553

Cumulative Model Updates: 369,886
Cumulative Timesteps: 3,084,875,822

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3084875822...
Checkpoint 3084875822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.51364
Policy Entropy: 3.96228
Value Function Loss: 0.00598

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02490
Policy Update Magnitude: 0.23862
Value Function Update Magnitude: 0.33149

Collected Steps per Second: 22,280.61943
Overall Steps per Second: 10,694.65929

Timestep Collection Time: 2.24455
Timestep Consumption Time: 2.43161
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.67617

Cumulative Model Updates: 369,892
Cumulative Timesteps: 3,084,925,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.20023
Policy Entropy: 3.95319
Value Function Loss: 0.00736

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.02908
Policy Update Magnitude: 0.24213
Value Function Update Magnitude: 0.32955

Collected Steps per Second: 22,540.26731
Overall Steps per Second: 10,858.43709

Timestep Collection Time: 2.21941
Timestep Consumption Time: 2.38770
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.60711

Cumulative Model Updates: 369,898
Cumulative Timesteps: 3,084,975,858

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3084975858...
Checkpoint 3084975858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.73350
Policy Entropy: 3.89579
Value Function Loss: 0.00798

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 0.25282
Value Function Update Magnitude: 0.34209

Collected Steps per Second: 22,044.45654
Overall Steps per Second: 10,602.58940

Timestep Collection Time: 2.26914
Timestep Consumption Time: 2.44876
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.71790

Cumulative Model Updates: 369,904
Cumulative Timesteps: 3,085,025,880

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.80961
Policy Entropy: 3.86020
Value Function Loss: 0.00872

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.03537
Policy Update Magnitude: 0.27398
Value Function Update Magnitude: 0.36911

Collected Steps per Second: 22,408.35982
Overall Steps per Second: 10,517.98744

Timestep Collection Time: 2.23247
Timestep Consumption Time: 2.52376
PPO Batch Consumption Time: 0.29484
Total Iteration Time: 4.75623

Cumulative Model Updates: 369,910
Cumulative Timesteps: 3,085,075,906

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3085075906...
Checkpoint 3085075906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.79206
Policy Entropy: 3.88177
Value Function Loss: 0.00824

Mean KL Divergence: 0.00456
SB3 Clip Fraction: 0.03397
Policy Update Magnitude: 0.27675
Value Function Update Magnitude: 0.38035

Collected Steps per Second: 23,359.11229
Overall Steps per Second: 10,729.88497

Timestep Collection Time: 2.14049
Timestep Consumption Time: 2.51939
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.65988

Cumulative Model Updates: 369,916
Cumulative Timesteps: 3,085,125,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.54034
Policy Entropy: 3.92185
Value Function Loss: 0.00724

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.03087
Policy Update Magnitude: 0.26038
Value Function Update Magnitude: 0.36633

Collected Steps per Second: 22,635.84142
Overall Steps per Second: 10,734.42488

Timestep Collection Time: 2.20889
Timestep Consumption Time: 2.44903
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.65791

Cumulative Model Updates: 369,922
Cumulative Timesteps: 3,085,175,906

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3085175906...
Checkpoint 3085175906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.50057
Policy Entropy: 3.94518
Value Function Loss: 0.00635

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.03023
Policy Update Magnitude: 0.24464
Value Function Update Magnitude: 0.32605

Collected Steps per Second: 22,260.83965
Overall Steps per Second: 10,711.28883

Timestep Collection Time: 2.24637
Timestep Consumption Time: 2.42217
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.66853

Cumulative Model Updates: 369,928
Cumulative Timesteps: 3,085,225,912

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.76981
Policy Entropy: 3.93498
Value Function Loss: 0.00595

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.24319
Value Function Update Magnitude: 0.30316

Collected Steps per Second: 22,693.58101
Overall Steps per Second: 10,632.55991

Timestep Collection Time: 2.20327
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.70254

Cumulative Model Updates: 369,934
Cumulative Timesteps: 3,085,275,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3085275912...
Checkpoint 3085275912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.59342
Policy Entropy: 3.91369
Value Function Loss: 0.00590

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.24169
Value Function Update Magnitude: 0.29957

Collected Steps per Second: 22,558.01629
Overall Steps per Second: 10,549.72994

Timestep Collection Time: 2.21819
Timestep Consumption Time: 2.52487
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.74306

Cumulative Model Updates: 369,940
Cumulative Timesteps: 3,085,325,950

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.86061
Policy Entropy: 3.94242
Value Function Loss: 0.00610

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02692
Policy Update Magnitude: 0.24217
Value Function Update Magnitude: 0.30933

Collected Steps per Second: 22,510.38054
Overall Steps per Second: 10,897.54059

Timestep Collection Time: 2.22146
Timestep Consumption Time: 2.36728
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.58874

Cumulative Model Updates: 369,946
Cumulative Timesteps: 3,085,375,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3085375956...
Checkpoint 3085375956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.63507
Policy Entropy: 3.93949
Value Function Loss: 0.00636

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02551
Policy Update Magnitude: 0.24187
Value Function Update Magnitude: 0.32063

Collected Steps per Second: 22,349.30916
Overall Steps per Second: 10,604.62339

Timestep Collection Time: 2.23810
Timestep Consumption Time: 2.47871
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.71681

Cumulative Model Updates: 369,952
Cumulative Timesteps: 3,085,425,976

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.78067
Policy Entropy: 3.99549
Value Function Loss: 0.00617

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.24344
Value Function Update Magnitude: 0.32632

Collected Steps per Second: 22,552.70422
Overall Steps per Second: 10,678.01465

Timestep Collection Time: 2.21765
Timestep Consumption Time: 2.46618
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.68383

Cumulative Model Updates: 369,958
Cumulative Timesteps: 3,085,475,990

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3085475990...
Checkpoint 3085475990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.89814
Policy Entropy: 3.97848
Value Function Loss: 0.00650

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.24473
Value Function Update Magnitude: 0.33080

Collected Steps per Second: 22,689.00072
Overall Steps per Second: 10,867.50975

Timestep Collection Time: 2.20539
Timestep Consumption Time: 2.39898
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.60437

Cumulative Model Updates: 369,964
Cumulative Timesteps: 3,085,526,028

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.44875
Policy Entropy: 4.00261
Value Function Loss: 0.00651

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02427
Policy Update Magnitude: 0.24403
Value Function Update Magnitude: 0.34037

Collected Steps per Second: 22,455.91572
Overall Steps per Second: 10,512.07672

Timestep Collection Time: 2.22676
Timestep Consumption Time: 2.53005
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.75681

Cumulative Model Updates: 369,970
Cumulative Timesteps: 3,085,576,032

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3085576032...
Checkpoint 3085576032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.07930
Policy Entropy: 3.96331
Value Function Loss: 0.00647

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02467
Policy Update Magnitude: 0.23996
Value Function Update Magnitude: 0.33745

Collected Steps per Second: 22,390.02200
Overall Steps per Second: 10,575.31266

Timestep Collection Time: 2.23314
Timestep Consumption Time: 2.49485
PPO Batch Consumption Time: 0.29495
Total Iteration Time: 4.72799

Cumulative Model Updates: 369,976
Cumulative Timesteps: 3,085,626,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.71585
Policy Entropy: 3.98821
Value Function Loss: 0.00651

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02502
Policy Update Magnitude: 0.23915
Value Function Update Magnitude: 0.33190

Collected Steps per Second: 22,478.65849
Overall Steps per Second: 10,877.32067

Timestep Collection Time: 2.22442
Timestep Consumption Time: 2.37248
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.59690

Cumulative Model Updates: 369,982
Cumulative Timesteps: 3,085,676,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3085676034...
Checkpoint 3085676034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.06873
Policy Entropy: 3.97458
Value Function Loss: 0.00664

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.24753
Value Function Update Magnitude: 0.32636

Collected Steps per Second: 22,557.73173
Overall Steps per Second: 10,655.59277

Timestep Collection Time: 2.21680
Timestep Consumption Time: 2.47613
PPO Batch Consumption Time: 0.28456
Total Iteration Time: 4.69293

Cumulative Model Updates: 369,988
Cumulative Timesteps: 3,085,726,040

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.45403
Policy Entropy: 3.97737
Value Function Loss: 0.00618

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.23996
Value Function Update Magnitude: 0.33556

Collected Steps per Second: 22,117.31988
Overall Steps per Second: 10,477.68914

Timestep Collection Time: 2.26121
Timestep Consumption Time: 2.51198
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.77319

Cumulative Model Updates: 369,994
Cumulative Timesteps: 3,085,776,052

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3085776052...
Checkpoint 3085776052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.33022
Policy Entropy: 3.98980
Value Function Loss: 0.00552

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.22893
Value Function Update Magnitude: 0.34062

Collected Steps per Second: 22,477.69300
Overall Steps per Second: 10,783.79046

Timestep Collection Time: 2.22469
Timestep Consumption Time: 2.41245
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.63714

Cumulative Model Updates: 370,000
Cumulative Timesteps: 3,085,826,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.68466
Policy Entropy: 3.99503
Value Function Loss: 0.00579

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02607
Policy Update Magnitude: 0.22857
Value Function Update Magnitude: 0.33816

Collected Steps per Second: 22,748.60531
Overall Steps per Second: 10,748.68001

Timestep Collection Time: 2.19873
Timestep Consumption Time: 2.45468
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.65341

Cumulative Model Updates: 370,006
Cumulative Timesteps: 3,085,876,076

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3085876076...
Checkpoint 3085876076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.78933
Policy Entropy: 4.03070
Value Function Loss: 0.00579

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02211
Policy Update Magnitude: 0.22968
Value Function Update Magnitude: 0.33831

Collected Steps per Second: 22,558.80228
Overall Steps per Second: 10,657.23024

Timestep Collection Time: 2.21732
Timestep Consumption Time: 2.47621
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.69353

Cumulative Model Updates: 370,012
Cumulative Timesteps: 3,085,926,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.01851
Policy Entropy: 3.99083
Value Function Loss: 0.00703

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02432
Policy Update Magnitude: 0.24223
Value Function Update Magnitude: 0.34357

Collected Steps per Second: 23,023.36915
Overall Steps per Second: 10,795.04408

Timestep Collection Time: 2.17275
Timestep Consumption Time: 2.46123
PPO Batch Consumption Time: 0.28075
Total Iteration Time: 4.63398

Cumulative Model Updates: 370,018
Cumulative Timesteps: 3,085,976,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3085976120...
Checkpoint 3085976120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.91165
Policy Entropy: 3.98753
Value Function Loss: 0.00665

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02644
Policy Update Magnitude: 0.24873
Value Function Update Magnitude: 0.37520

Collected Steps per Second: 22,494.83573
Overall Steps per Second: 10,709.42062

Timestep Collection Time: 2.22282
Timestep Consumption Time: 2.44615
PPO Batch Consumption Time: 0.28105
Total Iteration Time: 4.66897

Cumulative Model Updates: 370,024
Cumulative Timesteps: 3,086,026,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.33034
Policy Entropy: 3.95210
Value Function Loss: 0.00652

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.25214
Value Function Update Magnitude: 0.38163

Collected Steps per Second: 22,394.51087
Overall Steps per Second: 10,889.91183

Timestep Collection Time: 2.23412
Timestep Consumption Time: 2.36023
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.59434

Cumulative Model Updates: 370,030
Cumulative Timesteps: 3,086,076,154

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3086076154...
Checkpoint 3086076154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.47822
Policy Entropy: 3.97542
Value Function Loss: 0.00618

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02360
Policy Update Magnitude: 0.24263
Value Function Update Magnitude: 0.36859

Collected Steps per Second: 22,437.07102
Overall Steps per Second: 10,735.68076

Timestep Collection Time: 2.22854
Timestep Consumption Time: 2.42901
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.65755

Cumulative Model Updates: 370,036
Cumulative Timesteps: 3,086,126,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.54594
Policy Entropy: 3.95930
Value Function Loss: 0.00687

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02274
Policy Update Magnitude: 0.24592
Value Function Update Magnitude: 0.35389

Collected Steps per Second: 22,519.85724
Overall Steps per Second: 10,557.54850

Timestep Collection Time: 2.22159
Timestep Consumption Time: 2.51719
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.73879

Cumulative Model Updates: 370,042
Cumulative Timesteps: 3,086,176,186

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3086176186...
Checkpoint 3086176186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.54148
Policy Entropy: 4.00257
Value Function Loss: 0.00667

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.24467
Value Function Update Magnitude: 0.36330

Collected Steps per Second: 22,473.32623
Overall Steps per Second: 10,879.10822

Timestep Collection Time: 2.22637
Timestep Consumption Time: 2.37272
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.59909

Cumulative Model Updates: 370,048
Cumulative Timesteps: 3,086,226,220

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.19230
Policy Entropy: 4.00241
Value Function Loss: 0.00676

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.02862
Policy Update Magnitude: 0.24518
Value Function Update Magnitude: 0.34890

Collected Steps per Second: 22,574.23372
Overall Steps per Second: 10,539.19077

Timestep Collection Time: 2.21509
Timestep Consumption Time: 2.52948
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.74458

Cumulative Model Updates: 370,054
Cumulative Timesteps: 3,086,276,224

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3086276224...
Checkpoint 3086276224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.31913
Policy Entropy: 4.04284
Value Function Loss: 0.00576

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.02554
Policy Update Magnitude: 0.23759
Value Function Update Magnitude: 0.33738

Collected Steps per Second: 22,217.75569
Overall Steps per Second: 10,701.02086

Timestep Collection Time: 2.25081
Timestep Consumption Time: 2.42239
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.67320

Cumulative Model Updates: 370,060
Cumulative Timesteps: 3,086,326,232

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.57606
Policy Entropy: 4.01677
Value Function Loss: 0.00646

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.03152
Policy Update Magnitude: 0.23588
Value Function Update Magnitude: 0.33053

Collected Steps per Second: 22,347.94991
Overall Steps per Second: 10,835.87016

Timestep Collection Time: 2.23859
Timestep Consumption Time: 2.37829
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.61689

Cumulative Model Updates: 370,066
Cumulative Timesteps: 3,086,376,260

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3086376260...
Checkpoint 3086376260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.48547
Policy Entropy: 3.99374
Value Function Loss: 0.00591

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02993
Policy Update Magnitude: 0.23712
Value Function Update Magnitude: 0.33088

Collected Steps per Second: 22,348.77953
Overall Steps per Second: 10,683.62790

Timestep Collection Time: 2.23851
Timestep Consumption Time: 2.44417
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.68268

Cumulative Model Updates: 370,072
Cumulative Timesteps: 3,086,426,288

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.66991
Policy Entropy: 3.95273
Value Function Loss: 0.00676

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.03341
Policy Update Magnitude: 0.24792
Value Function Update Magnitude: 0.34259

Collected Steps per Second: 22,469.98022
Overall Steps per Second: 10,633.80385

Timestep Collection Time: 2.22519
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.70199

Cumulative Model Updates: 370,078
Cumulative Timesteps: 3,086,476,288

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3086476288...
Checkpoint 3086476288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.54677
Policy Entropy: 3.94830
Value Function Loss: 0.00651

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.03175
Policy Update Magnitude: 0.24802
Value Function Update Magnitude: 0.34719

Collected Steps per Second: 23,253.69410
Overall Steps per Second: 10,865.66671

Timestep Collection Time: 2.15131
Timestep Consumption Time: 2.45273
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.60404

Cumulative Model Updates: 370,084
Cumulative Timesteps: 3,086,526,314

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.64800
Policy Entropy: 3.95038
Value Function Loss: 0.00649

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.02929
Policy Update Magnitude: 0.24660
Value Function Update Magnitude: 0.34669

Collected Steps per Second: 22,438.47790
Overall Steps per Second: 10,534.77151

Timestep Collection Time: 2.22903
Timestep Consumption Time: 2.51868
PPO Batch Consumption Time: 0.29409
Total Iteration Time: 4.74771

Cumulative Model Updates: 370,090
Cumulative Timesteps: 3,086,576,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3086576330...
Checkpoint 3086576330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.66126
Policy Entropy: 3.96115
Value Function Loss: 0.00637

Mean KL Divergence: 0.00396
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.25135
Value Function Update Magnitude: 0.33876

Collected Steps per Second: 22,142.14984
Overall Steps per Second: 10,567.94752

Timestep Collection Time: 2.25868
Timestep Consumption Time: 2.47374
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.73242

Cumulative Model Updates: 370,096
Cumulative Timesteps: 3,086,626,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.79653
Policy Entropy: 3.96574
Value Function Loss: 0.00618

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02935
Policy Update Magnitude: 0.24600
Value Function Update Magnitude: 0.34363

Collected Steps per Second: 23,215.45304
Overall Steps per Second: 10,848.55368

Timestep Collection Time: 2.15434
Timestep Consumption Time: 2.45586
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.61020

Cumulative Model Updates: 370,102
Cumulative Timesteps: 3,086,676,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3086676356...
Checkpoint 3086676356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.78142
Policy Entropy: 3.95551
Value Function Loss: 0.00612

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 0.24082
Value Function Update Magnitude: 0.34895

Collected Steps per Second: 22,266.07145
Overall Steps per Second: 10,658.50770

Timestep Collection Time: 2.24593
Timestep Consumption Time: 2.44591
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.69184

Cumulative Model Updates: 370,108
Cumulative Timesteps: 3,086,726,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.26640
Policy Entropy: 3.94209
Value Function Loss: 0.00579

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02761
Policy Update Magnitude: 0.24301
Value Function Update Magnitude: 0.33367

Collected Steps per Second: 22,116.46015
Overall Steps per Second: 10,650.34256

Timestep Collection Time: 2.26130
Timestep Consumption Time: 2.43451
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.69581

Cumulative Model Updates: 370,114
Cumulative Timesteps: 3,086,776,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3086776376...
Checkpoint 3086776376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.32871
Policy Entropy: 3.94626
Value Function Loss: 0.00653

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02690
Policy Update Magnitude: 0.24808
Value Function Update Magnitude: 0.33997

Collected Steps per Second: 22,629.15765
Overall Steps per Second: 10,554.10218

Timestep Collection Time: 2.20963
Timestep Consumption Time: 2.52806
PPO Batch Consumption Time: 0.29399
Total Iteration Time: 4.73768

Cumulative Model Updates: 370,120
Cumulative Timesteps: 3,086,826,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.45436
Policy Entropy: 3.97725
Value Function Loss: 0.00594

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.24648
Value Function Update Magnitude: 0.34402

Collected Steps per Second: 22,603.55014
Overall Steps per Second: 10,604.31600

Timestep Collection Time: 2.21204
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.71506

Cumulative Model Updates: 370,126
Cumulative Timesteps: 3,086,876,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3086876378...
Checkpoint 3086876378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.07858
Policy Entropy: 4.01455
Value Function Loss: 0.00634

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02225
Policy Update Magnitude: 0.24034
Value Function Update Magnitude: 0.33351

Collected Steps per Second: 22,450.41276
Overall Steps per Second: 10,874.38412

Timestep Collection Time: 2.22740
Timestep Consumption Time: 2.37112
PPO Batch Consumption Time: 0.28054
Total Iteration Time: 4.59851

Cumulative Model Updates: 370,132
Cumulative Timesteps: 3,086,926,384

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.79179
Policy Entropy: 4.03238
Value Function Loss: 0.00529

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02313
Policy Update Magnitude: 0.23355
Value Function Update Magnitude: 0.32772

Collected Steps per Second: 22,283.72092
Overall Steps per Second: 10,465.31805

Timestep Collection Time: 2.24424
Timestep Consumption Time: 2.53440
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.77864

Cumulative Model Updates: 370,138
Cumulative Timesteps: 3,086,976,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3086976394...
Checkpoint 3086976394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.05999
Policy Entropy: 4.02814
Value Function Loss: 0.00633

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02119
Policy Update Magnitude: 0.23342
Value Function Update Magnitude: 0.33275

Collected Steps per Second: 22,353.00532
Overall Steps per Second: 10,655.68058

Timestep Collection Time: 2.23746
Timestep Consumption Time: 2.45618
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.69365

Cumulative Model Updates: 370,144
Cumulative Timesteps: 3,087,026,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.64354
Policy Entropy: 4.01610
Value Function Loss: 0.00596

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02171
Policy Update Magnitude: 0.24114
Value Function Update Magnitude: 0.34703

Collected Steps per Second: 22,489.26677
Overall Steps per Second: 10,842.14402

Timestep Collection Time: 2.22328
Timestep Consumption Time: 2.38835
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.61163

Cumulative Model Updates: 370,150
Cumulative Timesteps: 3,087,076,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3087076408...
Checkpoint 3087076408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.42156
Policy Entropy: 4.04778
Value Function Loss: 0.00603

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02137
Policy Update Magnitude: 0.24273
Value Function Update Magnitude: 0.34109

Collected Steps per Second: 22,548.90532
Overall Steps per Second: 10,741.96640

Timestep Collection Time: 2.21838
Timestep Consumption Time: 2.43831
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.65669

Cumulative Model Updates: 370,156
Cumulative Timesteps: 3,087,126,430

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.68864
Policy Entropy: 4.00782
Value Function Loss: 0.00670

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02598
Policy Update Magnitude: 0.24302
Value Function Update Magnitude: 0.34215

Collected Steps per Second: 22,321.94440
Overall Steps per Second: 10,621.07408

Timestep Collection Time: 2.24156
Timestep Consumption Time: 2.46945
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.71101

Cumulative Model Updates: 370,162
Cumulative Timesteps: 3,087,176,466

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 3087176466...
Checkpoint 3087176466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.64930
Policy Entropy: 3.98821
Value Function Loss: 0.00691

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.24023
Value Function Update Magnitude: 0.33574

Collected Steps per Second: 22,354.33452
Overall Steps per Second: 10,863.97248

Timestep Collection Time: 2.23778
Timestep Consumption Time: 2.36680
PPO Batch Consumption Time: 0.28107
Total Iteration Time: 4.60458

Cumulative Model Updates: 370,168
Cumulative Timesteps: 3,087,226,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.87997
Policy Entropy: 3.96376
Value Function Loss: 0.00680

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02927
Policy Update Magnitude: 0.25156
Value Function Update Magnitude: 0.33297

Collected Steps per Second: 22,654.85571
Overall Steps per Second: 10,544.64656

Timestep Collection Time: 2.20739
Timestep Consumption Time: 2.53512
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.74250

Cumulative Model Updates: 370,174
Cumulative Timesteps: 3,087,276,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3087276498...
Checkpoint 3087276498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.04346
Policy Entropy: 4.00508
Value Function Loss: 0.00703

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.03280
Policy Update Magnitude: 0.24955
Value Function Update Magnitude: 0.32922

Collected Steps per Second: 22,507.65255
Overall Steps per Second: 10,834.78019

Timestep Collection Time: 2.22227
Timestep Consumption Time: 2.39416
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.61643

Cumulative Model Updates: 370,180
Cumulative Timesteps: 3,087,326,516

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.75647
Policy Entropy: 4.01279
Value Function Loss: 0.00628

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.02933
Policy Update Magnitude: 0.24794
Value Function Update Magnitude: 0.32969

Collected Steps per Second: 22,423.07424
Overall Steps per Second: 10,674.60631

Timestep Collection Time: 2.23118
Timestep Consumption Time: 2.45564
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.68682

Cumulative Model Updates: 370,186
Cumulative Timesteps: 3,087,376,546

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3087376546...
Checkpoint 3087376546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.78835
Policy Entropy: 3.98753
Value Function Loss: 0.00594

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.24110
Value Function Update Magnitude: 0.31781

Collected Steps per Second: 22,334.08970
Overall Steps per Second: 10,625.89614

Timestep Collection Time: 2.23882
Timestep Consumption Time: 2.46685
PPO Batch Consumption Time: 0.28514
Total Iteration Time: 4.70567

Cumulative Model Updates: 370,192
Cumulative Timesteps: 3,087,426,548

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.04126
Policy Entropy: 3.95562
Value Function Loss: 0.00707

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.25059
Value Function Update Magnitude: 0.31328

Collected Steps per Second: 22,359.59801
Overall Steps per Second: 10,849.41344

Timestep Collection Time: 2.23644
Timestep Consumption Time: 2.37265
PPO Batch Consumption Time: 0.28122
Total Iteration Time: 4.60910

Cumulative Model Updates: 370,198
Cumulative Timesteps: 3,087,476,554

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3087476554...
Checkpoint 3087476554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.02546
Policy Entropy: 3.97549
Value Function Loss: 0.00677

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.25799
Value Function Update Magnitude: 0.34362

Collected Steps per Second: 22,505.57511
Overall Steps per Second: 10,719.33312

Timestep Collection Time: 2.22283
Timestep Consumption Time: 2.44407
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.66689

Cumulative Model Updates: 370,204
Cumulative Timesteps: 3,087,526,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.95847
Policy Entropy: 3.97618
Value Function Loss: 0.00680

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02898
Policy Update Magnitude: 0.25542
Value Function Update Magnitude: 0.34786

Collected Steps per Second: 22,134.90191
Overall Steps per Second: 10,492.10150

Timestep Collection Time: 2.25960
Timestep Consumption Time: 2.50742
PPO Batch Consumption Time: 0.29450
Total Iteration Time: 4.76701

Cumulative Model Updates: 370,210
Cumulative Timesteps: 3,087,576,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3087576596...
Checkpoint 3087576596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.87014
Policy Entropy: 4.01877
Value Function Loss: 0.00552

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.24723
Value Function Update Magnitude: 0.33606

Collected Steps per Second: 22,317.35665
Overall Steps per Second: 10,716.17046

Timestep Collection Time: 2.24041
Timestep Consumption Time: 2.42544
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.66585

Cumulative Model Updates: 370,216
Cumulative Timesteps: 3,087,626,596

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.71972
Policy Entropy: 3.99190
Value Function Loss: 0.00621

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02560
Policy Update Magnitude: 0.23433
Value Function Update Magnitude: 0.32388

Collected Steps per Second: 22,849.55362
Overall Steps per Second: 10,764.58077

Timestep Collection Time: 2.18866
Timestep Consumption Time: 2.45713
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.64579

Cumulative Model Updates: 370,222
Cumulative Timesteps: 3,087,676,606

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3087676606...
Checkpoint 3087676606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.55025
Policy Entropy: 4.00056
Value Function Loss: 0.00571

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02355
Policy Update Magnitude: 0.23084
Value Function Update Magnitude: 0.33005

Collected Steps per Second: 22,005.76494
Overall Steps per Second: 10,617.17531

Timestep Collection Time: 2.27322
Timestep Consumption Time: 2.43839
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.71161

Cumulative Model Updates: 370,228
Cumulative Timesteps: 3,087,726,630

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.32376
Policy Entropy: 3.99044
Value Function Loss: 0.00581

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02525
Policy Update Magnitude: 0.23716
Value Function Update Magnitude: 0.33023

Collected Steps per Second: 22,079.85391
Overall Steps per Second: 10,683.97928

Timestep Collection Time: 2.26559
Timestep Consumption Time: 2.41656
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.68215

Cumulative Model Updates: 370,234
Cumulative Timesteps: 3,087,776,654

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3087776654...
Checkpoint 3087776654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.89336
Policy Entropy: 3.97907
Value Function Loss: 0.00556

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02556
Policy Update Magnitude: 0.23717
Value Function Update Magnitude: 0.31205

Collected Steps per Second: 22,196.90521
Overall Steps per Second: 10,469.55741

Timestep Collection Time: 2.25356
Timestep Consumption Time: 2.52430
PPO Batch Consumption Time: 0.29402
Total Iteration Time: 4.77785

Cumulative Model Updates: 370,240
Cumulative Timesteps: 3,087,826,676

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.75244
Policy Entropy: 4.00815
Value Function Loss: 0.00644

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02569
Policy Update Magnitude: 0.23351
Value Function Update Magnitude: 0.30232

Collected Steps per Second: 22,361.62865
Overall Steps per Second: 10,609.54898

Timestep Collection Time: 2.23714
Timestep Consumption Time: 2.47805
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.71519

Cumulative Model Updates: 370,246
Cumulative Timesteps: 3,087,876,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3087876702...
Checkpoint 3087876702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.16563
Policy Entropy: 4.00988
Value Function Loss: 0.00681

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02759
Policy Update Magnitude: 0.22839
Value Function Update Magnitude: 0.31130

Collected Steps per Second: 22,986.13142
Overall Steps per Second: 10,867.53331

Timestep Collection Time: 2.17557
Timestep Consumption Time: 2.42602
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.60160

Cumulative Model Updates: 370,252
Cumulative Timesteps: 3,087,926,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.64396
Policy Entropy: 4.00932
Value Function Loss: 0.00773

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02639
Policy Update Magnitude: 0.23976
Value Function Update Magnitude: 0.32554

Collected Steps per Second: 22,546.36776
Overall Steps per Second: 10,532.41561

Timestep Collection Time: 2.21898
Timestep Consumption Time: 2.53111
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.75010

Cumulative Model Updates: 370,258
Cumulative Timesteps: 3,087,976,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3087976740...
Checkpoint 3087976740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.91097
Policy Entropy: 3.96607
Value Function Loss: 0.00763

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.03120
Policy Update Magnitude: 0.25367
Value Function Update Magnitude: 0.34477

Collected Steps per Second: 22,468.55837
Overall Steps per Second: 10,751.55631

Timestep Collection Time: 2.22658
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.65309

Cumulative Model Updates: 370,264
Cumulative Timesteps: 3,088,026,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.37014
Policy Entropy: 3.95110
Value Function Loss: 0.00727

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.03186
Policy Update Magnitude: 0.25578
Value Function Update Magnitude: 0.33601

Collected Steps per Second: 22,620.91450
Overall Steps per Second: 10,758.34949

Timestep Collection Time: 2.21238
Timestep Consumption Time: 2.43945
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.65183

Cumulative Model Updates: 370,270
Cumulative Timesteps: 3,088,076,814

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 3088076814...
Checkpoint 3088076814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.10189
Policy Entropy: 3.96106
Value Function Loss: 0.00656

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.02898
Policy Update Magnitude: 0.24530
Value Function Update Magnitude: 0.31591

Collected Steps per Second: 22,285.62949
Overall Steps per Second: 10,737.56393

Timestep Collection Time: 2.24405
Timestep Consumption Time: 2.41343
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.65748

Cumulative Model Updates: 370,276
Cumulative Timesteps: 3,088,126,824

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.41537
Policy Entropy: 3.98700
Value Function Loss: 0.00592

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.23365
Value Function Update Magnitude: 0.30675

Collected Steps per Second: 22,596.19769
Overall Steps per Second: 10,852.97917

Timestep Collection Time: 2.21391
Timestep Consumption Time: 2.39551
PPO Batch Consumption Time: 0.28151
Total Iteration Time: 4.60943

Cumulative Model Updates: 370,282
Cumulative Timesteps: 3,088,176,850

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3088176850...
Checkpoint 3088176850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.41612
Policy Entropy: 3.97813
Value Function Loss: 0.00623

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02559
Policy Update Magnitude: 0.23500
Value Function Update Magnitude: 0.29531

Collected Steps per Second: 22,172.03073
Overall Steps per Second: 10,587.12426

Timestep Collection Time: 2.25527
Timestep Consumption Time: 2.46782
PPO Batch Consumption Time: 0.28055
Total Iteration Time: 4.72310

Cumulative Model Updates: 370,288
Cumulative Timesteps: 3,088,226,854

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.47567
Policy Entropy: 3.95827
Value Function Loss: 0.00677

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02331
Policy Update Magnitude: 0.25208
Value Function Update Magnitude: 0.30688

Collected Steps per Second: 22,568.74510
Overall Steps per Second: 10,600.50895

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.50150
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.71713

Cumulative Model Updates: 370,294
Cumulative Timesteps: 3,088,276,858

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3088276858...
Checkpoint 3088276858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.75723
Policy Entropy: 3.91711
Value Function Loss: 0.00712

Mean KL Divergence: 0.00329
SB3 Clip Fraction: 0.02396
Policy Update Magnitude: 0.26471
Value Function Update Magnitude: 0.33251

Collected Steps per Second: 22,367.12792
Overall Steps per Second: 10,779.07566

Timestep Collection Time: 2.23569
Timestep Consumption Time: 2.40348
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.63917

Cumulative Model Updates: 370,300
Cumulative Timesteps: 3,088,326,864

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.44259
Policy Entropy: 3.91388
Value Function Loss: 0.00683

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.02757
Policy Update Magnitude: 0.26448
Value Function Update Magnitude: 0.34682

Collected Steps per Second: 22,543.14804
Overall Steps per Second: 10,723.60854

Timestep Collection Time: 2.21823
Timestep Consumption Time: 2.44493
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.66317

Cumulative Model Updates: 370,306
Cumulative Timesteps: 3,088,376,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3088376870...
Checkpoint 3088376870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.07350
Policy Entropy: 3.94937
Value Function Loss: 0.00638

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.25842
Value Function Update Magnitude: 0.35390

Collected Steps per Second: 22,379.56285
Overall Steps per Second: 10,708.54234

Timestep Collection Time: 2.23463
Timestep Consumption Time: 2.43548
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.67010

Cumulative Model Updates: 370,312
Cumulative Timesteps: 3,088,426,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.92607
Policy Entropy: 3.98351
Value Function Loss: 0.00594

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.24811
Value Function Update Magnitude: 0.34378

Collected Steps per Second: 22,748.81637
Overall Steps per Second: 10,764.62876

Timestep Collection Time: 2.19818
Timestep Consumption Time: 2.44722
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.64540

Cumulative Model Updates: 370,318
Cumulative Timesteps: 3,088,476,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3088476886...
Checkpoint 3088476886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.71527
Policy Entropy: 4.00686
Value Function Loss: 0.00609

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02185
Policy Update Magnitude: 0.23769
Value Function Update Magnitude: 0.33000

Collected Steps per Second: 22,278.35574
Overall Steps per Second: 10,648.61585

Timestep Collection Time: 2.24568
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.28014
Total Iteration Time: 4.69826

Cumulative Model Updates: 370,324
Cumulative Timesteps: 3,088,526,916

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.32593
Policy Entropy: 4.02163
Value Function Loss: 0.00584

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02610
Policy Update Magnitude: 0.22829
Value Function Update Magnitude: 0.30268

Collected Steps per Second: 22,456.76305
Overall Steps per Second: 10,865.01917

Timestep Collection Time: 2.22686
Timestep Consumption Time: 2.37580
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.60266

Cumulative Model Updates: 370,330
Cumulative Timesteps: 3,088,576,924

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3088576924...
Checkpoint 3088576924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.97851
Policy Entropy: 3.99912
Value Function Loss: 0.00688

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02806
Policy Update Magnitude: 0.23725
Value Function Update Magnitude: 0.30638

Collected Steps per Second: 22,388.14289
Overall Steps per Second: 10,651.15510

Timestep Collection Time: 2.23377
Timestep Consumption Time: 2.46149
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.69527

Cumulative Model Updates: 370,336
Cumulative Timesteps: 3,088,626,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.31148
Policy Entropy: 3.98836
Value Function Loss: 0.00700

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.03118
Policy Update Magnitude: 0.24291
Value Function Update Magnitude: 0.30849

Collected Steps per Second: 22,566.03607
Overall Steps per Second: 10,634.83966

Timestep Collection Time: 2.21625
Timestep Consumption Time: 2.48641
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.70266

Cumulative Model Updates: 370,342
Cumulative Timesteps: 3,088,676,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3088676946...
Checkpoint 3088676946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.52743
Policy Entropy: 3.94367
Value Function Loss: 0.00706

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03027
Policy Update Magnitude: 0.24584
Value Function Update Magnitude: 0.30682

Collected Steps per Second: 22,415.31390
Overall Steps per Second: 10,915.42439

Timestep Collection Time: 2.23249
Timestep Consumption Time: 2.35203
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.58452

Cumulative Model Updates: 370,348
Cumulative Timesteps: 3,088,726,988

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.06072
Policy Entropy: 3.93745
Value Function Loss: 0.00730

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.03246
Policy Update Magnitude: 0.25947
Value Function Update Magnitude: 0.30536

Collected Steps per Second: 22,444.73480
Overall Steps per Second: 10,516.52294

Timestep Collection Time: 2.22823
Timestep Consumption Time: 2.52734
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.75556

Cumulative Model Updates: 370,354
Cumulative Timesteps: 3,088,777,000

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3088777000...
Checkpoint 3088777000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.64462
Policy Entropy: 3.93449
Value Function Loss: 0.00652

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.03416
Policy Update Magnitude: 0.25572
Value Function Update Magnitude: 0.31449

Collected Steps per Second: 22,505.18568
Overall Steps per Second: 10,652.81280

Timestep Collection Time: 2.22304
Timestep Consumption Time: 2.47337
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.69641

Cumulative Model Updates: 370,360
Cumulative Timesteps: 3,088,827,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.54285
Policy Entropy: 3.96112
Value Function Loss: 0.00656

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.02951
Policy Update Magnitude: 0.24844
Value Function Update Magnitude: 0.31313

Collected Steps per Second: 22,225.42239
Overall Steps per Second: 10,835.10147

Timestep Collection Time: 2.25058
Timestep Consumption Time: 2.36590
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.61648

Cumulative Model Updates: 370,366
Cumulative Timesteps: 3,088,877,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3088877050...
Checkpoint 3088877050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.47019
Policy Entropy: 3.94948
Value Function Loss: 0.00702

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.03046
Policy Update Magnitude: 0.25596
Value Function Update Magnitude: 0.31144

Collected Steps per Second: 22,365.17042
Overall Steps per Second: 10,701.47478

Timestep Collection Time: 2.23669
Timestep Consumption Time: 2.43780
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.67450

Cumulative Model Updates: 370,372
Cumulative Timesteps: 3,088,927,074

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.78542
Policy Entropy: 3.96631
Value Function Loss: 0.00699

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02921
Policy Update Magnitude: 0.26329
Value Function Update Magnitude: 0.32591

Collected Steps per Second: 22,370.58831
Overall Steps per Second: 10,571.36781

Timestep Collection Time: 2.23615
Timestep Consumption Time: 2.49588
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.73203

Cumulative Model Updates: 370,378
Cumulative Timesteps: 3,088,977,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3088977098...
Checkpoint 3088977098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.99163
Policy Entropy: 3.97547
Value Function Loss: 0.00651

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02779
Policy Update Magnitude: 0.24891
Value Function Update Magnitude: 0.33336

Collected Steps per Second: 23,258.03979
Overall Steps per Second: 10,758.52715

Timestep Collection Time: 2.15022
Timestep Consumption Time: 2.49818
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.64841

Cumulative Model Updates: 370,384
Cumulative Timesteps: 3,089,027,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.62704
Policy Entropy: 3.99054
Value Function Loss: 0.00569

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02500
Policy Update Magnitude: 0.23693
Value Function Update Magnitude: 0.32809

Collected Steps per Second: 22,329.01341
Overall Steps per Second: 10,688.63166

Timestep Collection Time: 2.24013
Timestep Consumption Time: 2.43960
PPO Batch Consumption Time: 0.28035
Total Iteration Time: 4.67974

Cumulative Model Updates: 370,390
Cumulative Timesteps: 3,089,077,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3089077128...
Checkpoint 3089077128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.25365
Policy Entropy: 3.96281
Value Function Loss: 0.00663

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02386
Policy Update Magnitude: 0.23924
Value Function Update Magnitude: 0.32196

Collected Steps per Second: 22,210.15357
Overall Steps per Second: 10,740.79795

Timestep Collection Time: 2.25248
Timestep Consumption Time: 2.40527
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.65775

Cumulative Model Updates: 370,396
Cumulative Timesteps: 3,089,127,156

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.06642
Policy Entropy: 3.94244
Value Function Loss: 0.00666

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.03108
Policy Update Magnitude: 0.24560
Value Function Update Magnitude: 0.32883

Collected Steps per Second: 23,204.14641
Overall Steps per Second: 10,813.94650

Timestep Collection Time: 2.15479
Timestep Consumption Time: 2.46887
PPO Batch Consumption Time: 0.28089
Total Iteration Time: 4.62366

Cumulative Model Updates: 370,402
Cumulative Timesteps: 3,089,177,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3089177156...
Checkpoint 3089177156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.81460
Policy Entropy: 3.98894
Value Function Loss: 0.00593

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.24352
Value Function Update Magnitude: 0.32703

Collected Steps per Second: 22,443.87729
Overall Steps per Second: 10,677.64048

Timestep Collection Time: 2.22805
Timestep Consumption Time: 2.45520
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.68324

Cumulative Model Updates: 370,408
Cumulative Timesteps: 3,089,227,162

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.86262
Policy Entropy: 3.99151
Value Function Loss: 0.00592

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02508
Policy Update Magnitude: 0.24136
Value Function Update Magnitude: 0.32141

Collected Steps per Second: 22,367.08158
Overall Steps per Second: 10,850.78470

Timestep Collection Time: 2.23605
Timestep Consumption Time: 2.37320
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.60925

Cumulative Model Updates: 370,414
Cumulative Timesteps: 3,089,277,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3089277176...
Checkpoint 3089277176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.27600
Policy Entropy: 4.03246
Value Function Loss: 0.00538

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02355
Policy Update Magnitude: 0.23564
Value Function Update Magnitude: 0.32240

Collected Steps per Second: 22,552.97982
Overall Steps per Second: 10,768.20751

Timestep Collection Time: 2.21718
Timestep Consumption Time: 2.42649
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.64367

Cumulative Model Updates: 370,420
Cumulative Timesteps: 3,089,327,180

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.13517
Policy Entropy: 4.02711
Value Function Loss: 0.00625

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02522
Policy Update Magnitude: 0.22971
Value Function Update Magnitude: 0.31821

Collected Steps per Second: 22,233.68658
Overall Steps per Second: 10,529.18093

Timestep Collection Time: 2.24929
Timestep Consumption Time: 2.50037
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.74966

Cumulative Model Updates: 370,426
Cumulative Timesteps: 3,089,377,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3089377190...
Checkpoint 3089377190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.18132
Policy Entropy: 4.03416
Value Function Loss: 0.00609

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02271
Policy Update Magnitude: 0.23473
Value Function Update Magnitude: 0.31440

Collected Steps per Second: 23,220.29491
Overall Steps per Second: 10,879.83216

Timestep Collection Time: 2.15449
Timestep Consumption Time: 2.44374
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.59823

Cumulative Model Updates: 370,432
Cumulative Timesteps: 3,089,427,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.92500
Policy Entropy: 4.01200
Value Function Loss: 0.00626

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.24523
Value Function Update Magnitude: 0.32268

Collected Steps per Second: 22,715.42849
Overall Steps per Second: 10,574.20776

Timestep Collection Time: 2.20264
Timestep Consumption Time: 2.52906
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.73170

Cumulative Model Updates: 370,438
Cumulative Timesteps: 3,089,477,252

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3089477252...
Checkpoint 3089477252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.66318
Policy Entropy: 3.95697
Value Function Loss: 0.00605

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.24470
Value Function Update Magnitude: 0.33938

Collected Steps per Second: 22,296.80852
Overall Steps per Second: 10,633.35585

Timestep Collection Time: 2.24247
Timestep Consumption Time: 2.45971
PPO Batch Consumption Time: 0.28588
Total Iteration Time: 4.70218

Cumulative Model Updates: 370,444
Cumulative Timesteps: 3,089,527,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.67465
Policy Entropy: 3.95348
Value Function Loss: 0.00650

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.24389
Value Function Update Magnitude: 0.33592

Collected Steps per Second: 23,319.76518
Overall Steps per Second: 10,841.91274

Timestep Collection Time: 2.14488
Timestep Consumption Time: 2.46852
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.61339

Cumulative Model Updates: 370,450
Cumulative Timesteps: 3,089,577,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3089577270...
Checkpoint 3089577270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.84602
Policy Entropy: 3.92601
Value Function Loss: 0.00675

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03037
Policy Update Magnitude: 0.24057
Value Function Update Magnitude: 0.33149

Collected Steps per Second: 22,242.30665
Overall Steps per Second: 10,633.22930

Timestep Collection Time: 2.24851
Timestep Consumption Time: 2.45486
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.70337

Cumulative Model Updates: 370,456
Cumulative Timesteps: 3,089,627,282

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.84468
Policy Entropy: 3.94410
Value Function Loss: 0.00681

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.24287
Value Function Update Magnitude: 0.33330

Collected Steps per Second: 22,283.57263
Overall Steps per Second: 10,521.23105

Timestep Collection Time: 2.24488
Timestep Consumption Time: 2.50969
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.75458

Cumulative Model Updates: 370,462
Cumulative Timesteps: 3,089,677,306

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3089677306...
Checkpoint 3089677306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.74526
Policy Entropy: 3.93407
Value Function Loss: 0.00664

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.24705
Value Function Update Magnitude: 0.33078

Collected Steps per Second: 23,368.71224
Overall Steps per Second: 10,826.99119

Timestep Collection Time: 2.14115
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.62141

Cumulative Model Updates: 370,468
Cumulative Timesteps: 3,089,727,342

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.59059
Policy Entropy: 3.97825
Value Function Loss: 0.00560

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.24739
Value Function Update Magnitude: 0.31978

Collected Steps per Second: 22,914.80119
Overall Steps per Second: 10,740.09704

Timestep Collection Time: 2.18287
Timestep Consumption Time: 2.47444
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.65731

Cumulative Model Updates: 370,474
Cumulative Timesteps: 3,089,777,362

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3089777362...
Checkpoint 3089777362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.08316
Policy Entropy: 3.98779
Value Function Loss: 0.00680

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.24712
Value Function Update Magnitude: 0.32872

Collected Steps per Second: 22,061.25860
Overall Steps per Second: 10,677.56837

Timestep Collection Time: 2.26741
Timestep Consumption Time: 2.41736
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.68477

Cumulative Model Updates: 370,480
Cumulative Timesteps: 3,089,827,384

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.21019
Policy Entropy: 3.99555
Value Function Loss: 0.00662

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.25299
Value Function Update Magnitude: 0.34918

Collected Steps per Second: 23,120.56032
Overall Steps per Second: 10,867.23011

Timestep Collection Time: 2.16405
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.60412

Cumulative Model Updates: 370,486
Cumulative Timesteps: 3,089,877,418

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3089877418...
Checkpoint 3089877418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.09660
Policy Entropy: 3.96758
Value Function Loss: 0.00650

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02782
Policy Update Magnitude: 0.25132
Value Function Update Magnitude: 0.35999

Collected Steps per Second: 22,076.62808
Overall Steps per Second: 10,609.19676

Timestep Collection Time: 2.26520
Timestep Consumption Time: 2.44845
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.71365

Cumulative Model Updates: 370,492
Cumulative Timesteps: 3,089,927,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.02557
Policy Entropy: 3.97960
Value Function Loss: 0.00573

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02717
Policy Update Magnitude: 0.24866
Value Function Update Magnitude: 0.34953

Collected Steps per Second: 22,369.77995
Overall Steps per Second: 10,532.19815

Timestep Collection Time: 2.23614
Timestep Consumption Time: 2.51329
PPO Batch Consumption Time: 0.29425
Total Iteration Time: 4.74944

Cumulative Model Updates: 370,498
Cumulative Timesteps: 3,089,977,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3089977448...
Checkpoint 3089977448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.52272
Policy Entropy: 3.98303
Value Function Loss: 0.00558

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02477
Policy Update Magnitude: 0.23933
Value Function Update Magnitude: 0.34549

Collected Steps per Second: 23,113.43294
Overall Steps per Second: 10,680.53956

Timestep Collection Time: 2.16350
Timestep Consumption Time: 2.51847
PPO Batch Consumption Time: 0.29387
Total Iteration Time: 4.68197

Cumulative Model Updates: 370,504
Cumulative Timesteps: 3,090,027,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.75816
Policy Entropy: 4.02188
Value Function Loss: 0.00509

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02224
Policy Update Magnitude: 0.22983
Value Function Update Magnitude: 0.33674

Collected Steps per Second: 22,507.18178
Overall Steps per Second: 10,531.36564

Timestep Collection Time: 2.22205
Timestep Consumption Time: 2.52682
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.74886

Cumulative Model Updates: 370,510
Cumulative Timesteps: 3,090,077,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3090077466...
Checkpoint 3090077466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.62643
Policy Entropy: 4.02621
Value Function Loss: 0.00542

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02207
Policy Update Magnitude: 0.23218
Value Function Update Magnitude: 0.31792

Collected Steps per Second: 22,269.06045
Overall Steps per Second: 10,770.16406

Timestep Collection Time: 2.24608
Timestep Consumption Time: 2.39805
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.64413

Cumulative Model Updates: 370,516
Cumulative Timesteps: 3,090,127,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.04909
Policy Entropy: 4.03103
Value Function Loss: 0.00603

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02027
Policy Update Magnitude: 0.23629
Value Function Update Magnitude: 0.31160

Collected Steps per Second: 22,541.17401
Overall Steps per Second: 10,615.78875

Timestep Collection Time: 2.21923
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.71223

Cumulative Model Updates: 370,522
Cumulative Timesteps: 3,090,177,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3090177508...
Checkpoint 3090177508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.03744
Policy Entropy: 3.99861
Value Function Loss: 0.00628

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02395
Policy Update Magnitude: 0.23436
Value Function Update Magnitude: 0.32912

Collected Steps per Second: 22,290.96150
Overall Steps per Second: 10,699.10710

Timestep Collection Time: 2.24342
Timestep Consumption Time: 2.43061
PPO Batch Consumption Time: 0.27958
Total Iteration Time: 4.67403

Cumulative Model Updates: 370,528
Cumulative Timesteps: 3,090,227,516

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.21257
Policy Entropy: 3.98209
Value Function Loss: 0.00626

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.23372
Value Function Update Magnitude: 0.31577

Collected Steps per Second: 22,324.43754
Overall Steps per Second: 10,836.22701

Timestep Collection Time: 2.24033
Timestep Consumption Time: 2.37512
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.61544

Cumulative Model Updates: 370,534
Cumulative Timesteps: 3,090,277,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3090277530...
Checkpoint 3090277530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.42381
Policy Entropy: 3.96747
Value Function Loss: 0.00676

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.23916
Value Function Update Magnitude: 0.29875

Collected Steps per Second: 22,448.91821
Overall Steps per Second: 10,680.00678

Timestep Collection Time: 2.22746
Timestep Consumption Time: 2.45456
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.68202

Cumulative Model Updates: 370,540
Cumulative Timesteps: 3,090,327,534

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.76141
Policy Entropy: 3.94722
Value Function Loss: 0.00705

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02929
Policy Update Magnitude: 0.25265
Value Function Update Magnitude: 0.32658

Collected Steps per Second: 22,005.65127
Overall Steps per Second: 10,476.85071

Timestep Collection Time: 2.27223
Timestep Consumption Time: 2.50038
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.77262

Cumulative Model Updates: 370,546
Cumulative Timesteps: 3,090,377,536

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3090377536...
Checkpoint 3090377536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.13672
Policy Entropy: 3.96271
Value Function Loss: 0.00647

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.03324
Policy Update Magnitude: 0.26286
Value Function Update Magnitude: 0.35236

Collected Steps per Second: 23,252.71376
Overall Steps per Second: 10,705.42493

Timestep Collection Time: 2.15140
Timestep Consumption Time: 2.52155
PPO Batch Consumption Time: 0.29437
Total Iteration Time: 4.67296

Cumulative Model Updates: 370,552
Cumulative Timesteps: 3,090,427,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.64246
Policy Entropy: 3.97478
Value Function Loss: 0.00665

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.03002
Policy Update Magnitude: 0.25452
Value Function Update Magnitude: 0.34358

Collected Steps per Second: 22,454.68478
Overall Steps per Second: 10,575.42834

Timestep Collection Time: 2.22680
Timestep Consumption Time: 2.50133
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.72813

Cumulative Model Updates: 370,558
Cumulative Timesteps: 3,090,477,564

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3090477564...
Checkpoint 3090477564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.94864
Policy Entropy: 3.99624
Value Function Loss: 0.00645

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.02980
Policy Update Magnitude: 0.24401
Value Function Update Magnitude: 0.32144

Collected Steps per Second: 22,621.28801
Overall Steps per Second: 10,661.24108

Timestep Collection Time: 2.21040
Timestep Consumption Time: 2.47968
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.69007

Cumulative Model Updates: 370,564
Cumulative Timesteps: 3,090,527,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.38133
Policy Entropy: 3.95448
Value Function Loss: 0.00798

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02768
Policy Update Magnitude: 0.24354
Value Function Update Magnitude: 0.32283

Collected Steps per Second: 23,248.85213
Overall Steps per Second: 10,724.14425

Timestep Collection Time: 2.15193
Timestep Consumption Time: 2.51324
PPO Batch Consumption Time: 0.29331
Total Iteration Time: 4.66517

Cumulative Model Updates: 370,570
Cumulative Timesteps: 3,090,577,596

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3090577596...
Checkpoint 3090577596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.69351
Policy Entropy: 3.96748
Value Function Loss: 0.00677

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02703
Policy Update Magnitude: 0.25084
Value Function Update Magnitude: 0.35166

Collected Steps per Second: 22,505.59468
Overall Steps per Second: 10,625.64705

Timestep Collection Time: 2.22247
Timestep Consumption Time: 2.48482
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.70729

Cumulative Model Updates: 370,576
Cumulative Timesteps: 3,090,627,614

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64.37325
Policy Entropy: 3.95764
Value Function Loss: 0.00588

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02721
Policy Update Magnitude: 0.24140
Value Function Update Magnitude: 0.35156

Collected Steps per Second: 22,620.36984
Overall Steps per Second: 10,946.45657

Timestep Collection Time: 2.21093
Timestep Consumption Time: 2.35786
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.56878

Cumulative Model Updates: 370,582
Cumulative Timesteps: 3,090,677,626

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3090677626...
Checkpoint 3090677626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.38785
Policy Entropy: 3.99769
Value Function Loss: 0.00551

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.23191
Value Function Update Magnitude: 0.32690

Collected Steps per Second: 22,502.07837
Overall Steps per Second: 10,637.46635

Timestep Collection Time: 2.22326
Timestep Consumption Time: 2.47974
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.70300

Cumulative Model Updates: 370,588
Cumulative Timesteps: 3,090,727,654

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.06177
Policy Entropy: 4.03994
Value Function Loss: 0.00584

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02377
Policy Update Magnitude: 0.22847
Value Function Update Magnitude: 0.31316

Collected Steps per Second: 22,348.75058
Overall Steps per Second: 10,500.00469

Timestep Collection Time: 2.23851
Timestep Consumption Time: 2.52605
PPO Batch Consumption Time: 0.29429
Total Iteration Time: 4.76457

Cumulative Model Updates: 370,594
Cumulative Timesteps: 3,090,777,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3090777682...
Checkpoint 3090777682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.43192
Policy Entropy: 4.07407
Value Function Loss: 0.00523

Mean KL Divergence: 0.00271
SB3 Clip Fraction: 0.02024
Policy Update Magnitude: 0.22407
Value Function Update Magnitude: 0.30589

Collected Steps per Second: 22,543.81352
Overall Steps per Second: 10,936.76607

Timestep Collection Time: 2.21861
Timestep Consumption Time: 2.35459
PPO Batch Consumption Time: 0.27948
Total Iteration Time: 4.57320

Cumulative Model Updates: 370,600
Cumulative Timesteps: 3,090,827,698

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.94414
Policy Entropy: 4.06637
Value Function Loss: 0.00523

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02238
Policy Update Magnitude: 0.22277
Value Function Update Magnitude: 0.29318

Collected Steps per Second: 22,502.53511
Overall Steps per Second: 10,545.74927

Timestep Collection Time: 2.22268
Timestep Consumption Time: 2.52008
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.74276

Cumulative Model Updates: 370,606
Cumulative Timesteps: 3,090,877,714

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3090877714...
Checkpoint 3090877714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.86861
Policy Entropy: 4.03082
Value Function Loss: 0.00503

Mean KL Divergence: 0.00261
SB3 Clip Fraction: 0.02201
Policy Update Magnitude: 0.21973
Value Function Update Magnitude: 0.28589

Collected Steps per Second: 22,505.32861
Overall Steps per Second: 10,639.11113

Timestep Collection Time: 2.22187
Timestep Consumption Time: 2.47814
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.70002

Cumulative Model Updates: 370,612
Cumulative Timesteps: 3,090,927,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.57575
Policy Entropy: 3.98777
Value Function Loss: 0.00621

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.02316
Policy Update Magnitude: 0.23349
Value Function Update Magnitude: 0.29034

Collected Steps per Second: 23,304.27488
Overall Steps per Second: 10,846.67904

Timestep Collection Time: 2.14673
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.61229

Cumulative Model Updates: 370,618
Cumulative Timesteps: 3,090,977,746

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3090977746...
Checkpoint 3090977746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.20395
Policy Entropy: 3.99106
Value Function Loss: 0.00630

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.24844
Value Function Update Magnitude: 0.30991

Collected Steps per Second: 22,282.28852
Overall Steps per Second: 10,632.05813

Timestep Collection Time: 2.24537
Timestep Consumption Time: 2.46040
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.70577

Cumulative Model Updates: 370,624
Cumulative Timesteps: 3,091,027,778

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.59832
Policy Entropy: 3.97287
Value Function Loss: 0.00667

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.25102
Value Function Update Magnitude: 0.32190

Collected Steps per Second: 22,551.73931
Overall Steps per Second: 10,566.48750

Timestep Collection Time: 2.21766
Timestep Consumption Time: 2.51542
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.73308

Cumulative Model Updates: 370,630
Cumulative Timesteps: 3,091,077,790

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3091077790...
Checkpoint 3091077790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.13139
Policy Entropy: 3.96954
Value Function Loss: 0.00582

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.02968
Policy Update Magnitude: 0.24889
Value Function Update Magnitude: 0.32390

Collected Steps per Second: 23,117.23997
Overall Steps per Second: 10,686.84985

Timestep Collection Time: 2.16367
Timestep Consumption Time: 2.51666
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.68033

Cumulative Model Updates: 370,636
Cumulative Timesteps: 3,091,127,808

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.64658
Policy Entropy: 3.95947
Value Function Loss: 0.00561

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.03277
Policy Update Magnitude: 0.24390
Value Function Update Magnitude: 0.32322

Collected Steps per Second: 22,517.40946
Overall Steps per Second: 10,725.69605

Timestep Collection Time: 2.22139
Timestep Consumption Time: 2.44217
PPO Batch Consumption Time: 0.27988
Total Iteration Time: 4.66357

Cumulative Model Updates: 370,642
Cumulative Timesteps: 3,091,177,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3091177828...
Checkpoint 3091177828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.62620
Policy Entropy: 3.93332
Value Function Loss: 0.00577

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.03712
Policy Update Magnitude: 0.24145
Value Function Update Magnitude: 0.32195

Collected Steps per Second: 22,518.61103
Overall Steps per Second: 10,721.49414

Timestep Collection Time: 2.22145
Timestep Consumption Time: 2.44432
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.66577

Cumulative Model Updates: 370,648
Cumulative Timesteps: 3,091,227,852

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.55906
Policy Entropy: 3.95667
Value Function Loss: 0.00626

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.03451
Policy Update Magnitude: 0.24238
Value Function Update Magnitude: 0.32129

Collected Steps per Second: 22,600.39555
Overall Steps per Second: 10,922.98431

Timestep Collection Time: 2.21324
Timestep Consumption Time: 2.36610
PPO Batch Consumption Time: 0.27982
Total Iteration Time: 4.57933

Cumulative Model Updates: 370,654
Cumulative Timesteps: 3,091,277,872

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3091277872...
Checkpoint 3091277872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.91212
Policy Entropy: 3.98268
Value Function Loss: 0.00610

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.02954
Policy Update Magnitude: 0.23732
Value Function Update Magnitude: 0.32951

Collected Steps per Second: 22,327.13557
Overall Steps per Second: 10,705.48715

Timestep Collection Time: 2.23996
Timestep Consumption Time: 2.43166
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.67162

Cumulative Model Updates: 370,660
Cumulative Timesteps: 3,091,327,884

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.73258
Policy Entropy: 4.01295
Value Function Loss: 0.00575

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02549
Policy Update Magnitude: 0.23557
Value Function Update Magnitude: 0.31975

Collected Steps per Second: 22,389.91049
Overall Steps per Second: 10,617.44094

Timestep Collection Time: 2.23342
Timestep Consumption Time: 2.47638
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.70980

Cumulative Model Updates: 370,666
Cumulative Timesteps: 3,091,377,890

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3091377890...
Checkpoint 3091377890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.38669
Policy Entropy: 3.99125
Value Function Loss: 0.00619

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02774
Policy Update Magnitude: 0.24712
Value Function Update Magnitude: 0.31228

Collected Steps per Second: 23,108.07221
Overall Steps per Second: 10,860.89261

Timestep Collection Time: 2.16453
Timestep Consumption Time: 2.44081
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.60533

Cumulative Model Updates: 370,672
Cumulative Timesteps: 3,091,427,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.72194
Policy Entropy: 3.97317
Value Function Loss: 0.00636

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.03050
Policy Update Magnitude: 0.24842
Value Function Update Magnitude: 0.32575

Collected Steps per Second: 22,700.25083
Overall Steps per Second: 10,589.41006

Timestep Collection Time: 2.20385
Timestep Consumption Time: 2.52049
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.72434

Cumulative Model Updates: 370,678
Cumulative Timesteps: 3,091,477,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3091477936...
Checkpoint 3091477936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.63082
Policy Entropy: 3.98330
Value Function Loss: 0.00703

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.03116
Policy Update Magnitude: 0.24383
Value Function Update Magnitude: 0.32250

Collected Steps per Second: 22,032.08814
Overall Steps per Second: 10,645.24649

Timestep Collection Time: 2.27023
Timestep Consumption Time: 2.42839
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.69862

Cumulative Model Updates: 370,684
Cumulative Timesteps: 3,091,527,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.61120
Policy Entropy: 3.95880
Value Function Loss: 0.00717

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02655
Policy Update Magnitude: 0.25511
Value Function Update Magnitude: 0.31547

Collected Steps per Second: 22,465.11136
Overall Steps per Second: 10,569.34444

Timestep Collection Time: 2.22612
Timestep Consumption Time: 2.50549
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.73161

Cumulative Model Updates: 370,690
Cumulative Timesteps: 3,091,577,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3091577964...
Checkpoint 3091577964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.35331
Policy Entropy: 3.94462
Value Function Loss: 0.00736

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02411
Policy Update Magnitude: 0.26309
Value Function Update Magnitude: 0.33173

Collected Steps per Second: 22,260.69200
Overall Steps per Second: 10,522.87967

Timestep Collection Time: 2.24719
Timestep Consumption Time: 2.50664
PPO Batch Consumption Time: 0.29314
Total Iteration Time: 4.75383

Cumulative Model Updates: 370,696
Cumulative Timesteps: 3,091,627,988

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.92978
Policy Entropy: 3.92639
Value Function Loss: 0.00759

Mean KL Divergence: 0.00413
SB3 Clip Fraction: 0.02840
Policy Update Magnitude: 0.26630
Value Function Update Magnitude: 0.32717

Collected Steps per Second: 22,605.89819
Overall Steps per Second: 10,938.77862

Timestep Collection Time: 2.21225
Timestep Consumption Time: 2.35955
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.57181

Cumulative Model Updates: 370,702
Cumulative Timesteps: 3,091,677,998

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3091677998...
Checkpoint 3091677998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.40914
Policy Entropy: 3.90129
Value Function Loss: 0.00811

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.03184
Policy Update Magnitude: 0.26741
Value Function Update Magnitude: 0.33320

Collected Steps per Second: 22,310.35971
Overall Steps per Second: 10,589.54761

Timestep Collection Time: 2.24246
Timestep Consumption Time: 2.48201
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.72447

Cumulative Model Updates: 370,708
Cumulative Timesteps: 3,091,728,028

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.19244
Policy Entropy: 3.92321
Value Function Loss: 0.00805

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.02900
Policy Update Magnitude: 0.26923
Value Function Update Magnitude: 0.34262

Collected Steps per Second: 22,406.47032
Overall Steps per Second: 10,611.28007

Timestep Collection Time: 2.23257
Timestep Consumption Time: 2.48166
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.71423

Cumulative Model Updates: 370,714
Cumulative Timesteps: 3,091,778,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3091778052...
Checkpoint 3091778052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.99253
Policy Entropy: 3.93111
Value Function Loss: 0.00810

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.03465
Policy Update Magnitude: 0.26482
Value Function Update Magnitude: 0.35082

Collected Steps per Second: 22,428.60070
Overall Steps per Second: 10,876.57406

Timestep Collection Time: 2.23010
Timestep Consumption Time: 2.36859
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.59869

Cumulative Model Updates: 370,720
Cumulative Timesteps: 3,091,828,070

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.12750
Policy Entropy: 3.96639
Value Function Loss: 0.00708

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.02995
Policy Update Magnitude: 0.25279
Value Function Update Magnitude: 0.33640

Collected Steps per Second: 22,537.06936
Overall Steps per Second: 10,549.59710

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.52196
PPO Batch Consumption Time: 0.29400
Total Iteration Time: 4.74141

Cumulative Model Updates: 370,726
Cumulative Timesteps: 3,091,878,090

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3091878090...
Checkpoint 3091878090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.37526
Policy Entropy: 3.93317
Value Function Loss: 0.00705

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 0.25280
Value Function Update Magnitude: 0.34039

Collected Steps per Second: 21,748.85702
Overall Steps per Second: 10,591.98712

Timestep Collection Time: 2.29962
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.28061
Total Iteration Time: 4.72187

Cumulative Model Updates: 370,732
Cumulative Timesteps: 3,091,928,104

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.47778
Policy Entropy: 3.95580
Value Function Loss: 0.00566

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02691
Policy Update Magnitude: 0.24421
Value Function Update Magnitude: 0.34895

Collected Steps per Second: 23,239.72962
Overall Steps per Second: 10,865.92891

Timestep Collection Time: 2.15261
Timestep Consumption Time: 2.45133
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.60393

Cumulative Model Updates: 370,738
Cumulative Timesteps: 3,091,978,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3091978130...
Checkpoint 3091978130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.04306
Policy Entropy: 3.96274
Value Function Loss: 0.00599

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.24046
Value Function Update Magnitude: 0.34633

Collected Steps per Second: 22,274.68745
Overall Steps per Second: 10,617.62467

Timestep Collection Time: 2.24551
Timestep Consumption Time: 2.46534
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.71085

Cumulative Model Updates: 370,744
Cumulative Timesteps: 3,092,028,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.17373
Policy Entropy: 3.96828
Value Function Loss: 0.00660

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.24852
Value Function Update Magnitude: 0.34404

Collected Steps per Second: 22,055.76853
Overall Steps per Second: 10,563.31648

Timestep Collection Time: 2.26798
Timestep Consumption Time: 2.46747
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.73544

Cumulative Model Updates: 370,750
Cumulative Timesteps: 3,092,078,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3092078170...
Checkpoint 3092078170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.46667
Policy Entropy: 3.92681
Value Function Loss: 0.00733

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.03786
Policy Update Magnitude: 0.26623
Value Function Update Magnitude: 0.35817

Collected Steps per Second: 23,320.54917
Overall Steps per Second: 10,787.22995

Timestep Collection Time: 2.14523
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.63771

Cumulative Model Updates: 370,756
Cumulative Timesteps: 3,092,128,198

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.66961
Policy Entropy: 3.95553
Value Function Loss: 0.00661

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.03156
Policy Update Magnitude: 0.25847
Value Function Update Magnitude: 0.35517

Collected Steps per Second: 22,667.21901
Overall Steps per Second: 10,700.98033

Timestep Collection Time: 2.20636
Timestep Consumption Time: 2.46723
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.67359

Cumulative Model Updates: 370,762
Cumulative Timesteps: 3,092,178,210

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3092178210...
Checkpoint 3092178210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.02742
Policy Entropy: 3.99828
Value Function Loss: 0.00641

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02510
Policy Update Magnitude: 0.24853
Value Function Update Magnitude: 0.33070

Collected Steps per Second: 22,475.33854
Overall Steps per Second: 10,682.01074

Timestep Collection Time: 2.22528
Timestep Consumption Time: 2.45679
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.68208

Cumulative Model Updates: 370,768
Cumulative Timesteps: 3,092,228,224

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.67704
Policy Entropy: 4.02989
Value Function Loss: 0.00670

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.24018
Value Function Update Magnitude: 0.31417

Collected Steps per Second: 23,467.57482
Overall Steps per Second: 10,974.37599

Timestep Collection Time: 2.13179
Timestep Consumption Time: 2.42683
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.55862

Cumulative Model Updates: 370,774
Cumulative Timesteps: 3,092,278,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3092278252...
Checkpoint 3092278252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.97351
Policy Entropy: 4.01308
Value Function Loss: 0.00660

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.22896
Value Function Update Magnitude: 0.32327

Collected Steps per Second: 22,483.64138
Overall Steps per Second: 10,584.60384

Timestep Collection Time: 2.22473
Timestep Consumption Time: 2.50100
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.72573

Cumulative Model Updates: 370,780
Cumulative Timesteps: 3,092,328,272

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.41491
Policy Entropy: 4.00152
Value Function Loss: 0.00582

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.23125
Value Function Update Magnitude: 0.31894

Collected Steps per Second: 22,240.53590
Overall Steps per Second: 10,488.38864

Timestep Collection Time: 2.24896
Timestep Consumption Time: 2.51994
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.76889

Cumulative Model Updates: 370,786
Cumulative Timesteps: 3,092,378,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3092378290...
Checkpoint 3092378290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.16305
Policy Entropy: 3.94971
Value Function Loss: 0.00638

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02330
Policy Update Magnitude: 0.24234
Value Function Update Magnitude: 0.32646

Collected Steps per Second: 23,116.18844
Overall Steps per Second: 10,686.60668

Timestep Collection Time: 2.16411
Timestep Consumption Time: 2.51708
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.68119

Cumulative Model Updates: 370,792
Cumulative Timesteps: 3,092,428,316

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.76945
Policy Entropy: 3.94981
Value Function Loss: 0.00762

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.26270
Value Function Update Magnitude: 0.34773

Collected Steps per Second: 22,448.27686
Overall Steps per Second: 10,589.54972

Timestep Collection Time: 2.22806
Timestep Consumption Time: 2.49509
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.72315

Cumulative Model Updates: 370,798
Cumulative Timesteps: 3,092,478,332

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3092478332...
Checkpoint 3092478332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.54494
Policy Entropy: 3.94500
Value Function Loss: 0.00749

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.03079
Policy Update Magnitude: 0.26628
Value Function Update Magnitude: 0.35574

Collected Steps per Second: 22,566.64658
Overall Steps per Second: 10,788.22051

Timestep Collection Time: 2.21672
Timestep Consumption Time: 2.42019
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.63691

Cumulative Model Updates: 370,804
Cumulative Timesteps: 3,092,528,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.58682
Policy Entropy: 3.97836
Value Function Loss: 0.00678

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02803
Policy Update Magnitude: 0.25560
Value Function Update Magnitude: 0.34349

Collected Steps per Second: 23,062.85722
Overall Steps per Second: 10,708.57185

Timestep Collection Time: 2.16799
Timestep Consumption Time: 2.50117
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.66916

Cumulative Model Updates: 370,810
Cumulative Timesteps: 3,092,578,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3092578356...
Checkpoint 3092578356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.58185
Policy Entropy: 3.97837
Value Function Loss: 0.00657

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.24457
Value Function Update Magnitude: 0.31696

Collected Steps per Second: 22,602.91623
Overall Steps per Second: 10,590.43462

Timestep Collection Time: 2.21343
Timestep Consumption Time: 2.51064
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.72407

Cumulative Model Updates: 370,816
Cumulative Timesteps: 3,092,628,386

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.63663
Policy Entropy: 3.97388
Value Function Loss: 0.00687

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02804
Policy Update Magnitude: 0.24610
Value Function Update Magnitude: 0.30271

Collected Steps per Second: 22,382.55525
Overall Steps per Second: 10,727.49338

Timestep Collection Time: 2.23442
Timestep Consumption Time: 2.42762
PPO Batch Consumption Time: 0.28032
Total Iteration Time: 4.66204

Cumulative Model Updates: 370,822
Cumulative Timesteps: 3,092,678,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3092678398...
Checkpoint 3092678398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.28769
Policy Entropy: 3.98483
Value Function Loss: 0.00689

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02536
Policy Update Magnitude: 0.24572
Value Function Update Magnitude: 0.30369

Collected Steps per Second: 22,984.13645
Overall Steps per Second: 10,720.24773

Timestep Collection Time: 2.17663
Timestep Consumption Time: 2.49005
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.66668

Cumulative Model Updates: 370,828
Cumulative Timesteps: 3,092,728,426

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.28460
Policy Entropy: 4.01424
Value Function Loss: 0.00613

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.03103
Policy Update Magnitude: 0.23788
Value Function Update Magnitude: 0.30832

Collected Steps per Second: 22,391.01472
Overall Steps per Second: 10,484.33190

Timestep Collection Time: 2.23349
Timestep Consumption Time: 2.53649
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.76997

Cumulative Model Updates: 370,834
Cumulative Timesteps: 3,092,778,436

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3092778436...
Checkpoint 3092778436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.61174
Policy Entropy: 3.98480
Value Function Loss: 0.00582

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.03008
Policy Update Magnitude: 0.23087
Value Function Update Magnitude: 0.30454

Collected Steps per Second: 22,393.88910
Overall Steps per Second: 10,768.43692

Timestep Collection Time: 2.23302
Timestep Consumption Time: 2.41074
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.64376

Cumulative Model Updates: 370,840
Cumulative Timesteps: 3,092,828,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.19784
Policy Entropy: 3.98537
Value Function Loss: 0.00622

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02641
Policy Update Magnitude: 0.23623
Value Function Update Magnitude: 0.30028

Collected Steps per Second: 22,920.31732
Overall Steps per Second: 10,817.32950

Timestep Collection Time: 2.18226
Timestep Consumption Time: 2.44162
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.62388

Cumulative Model Updates: 370,846
Cumulative Timesteps: 3,092,878,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3092878460...
Checkpoint 3092878460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.83844
Policy Entropy: 3.92964
Value Function Loss: 0.00696

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02911
Policy Update Magnitude: 0.24145
Value Function Update Magnitude: 0.31136

Collected Steps per Second: 22,237.48091
Overall Steps per Second: 10,609.17785

Timestep Collection Time: 2.24936
Timestep Consumption Time: 2.46543
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.71479

Cumulative Model Updates: 370,852
Cumulative Timesteps: 3,092,928,480

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.51561
Policy Entropy: 3.94436
Value Function Loss: 0.00710

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02514
Policy Update Magnitude: 0.25299
Value Function Update Magnitude: 0.33609

Collected Steps per Second: 23,159.60005
Overall Steps per Second: 10,819.68891

Timestep Collection Time: 2.15919
Timestep Consumption Time: 2.46257
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.62176

Cumulative Model Updates: 370,858
Cumulative Timesteps: 3,092,978,486

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3092978486...
Checkpoint 3092978486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.12966
Policy Entropy: 3.90985
Value Function Loss: 0.00695

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02666
Policy Update Magnitude: 0.25305
Value Function Update Magnitude: 0.33698

Collected Steps per Second: 22,227.95589
Overall Steps per Second: 10,639.21787

Timestep Collection Time: 2.24987
Timestep Consumption Time: 2.45066
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.70053

Cumulative Model Updates: 370,864
Cumulative Timesteps: 3,093,028,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.17345
Policy Entropy: 3.93942
Value Function Loss: 0.00700

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.25188
Value Function Update Magnitude: 0.32559

Collected Steps per Second: 22,421.25224
Overall Steps per Second: 10,580.55333

Timestep Collection Time: 2.23047
Timestep Consumption Time: 2.49612
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.72660

Cumulative Model Updates: 370,870
Cumulative Timesteps: 3,093,078,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3093078506...
Checkpoint 3093078506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.98826
Policy Entropy: 3.94192
Value Function Loss: 0.00685

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02845
Policy Update Magnitude: 0.25535
Value Function Update Magnitude: 0.32659

Collected Steps per Second: 23,303.80344
Overall Steps per Second: 10,774.05051

Timestep Collection Time: 2.14592
Timestep Consumption Time: 2.49561
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.64152

Cumulative Model Updates: 370,876
Cumulative Timesteps: 3,093,128,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.63241
Policy Entropy: 3.94228
Value Function Loss: 0.00722

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.25985
Value Function Update Magnitude: 0.34241

Collected Steps per Second: 22,632.69227
Overall Steps per Second: 10,750.53814

Timestep Collection Time: 2.21070
Timestep Consumption Time: 2.44340
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.65409

Cumulative Model Updates: 370,882
Cumulative Timesteps: 3,093,178,548

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3093178548...
Checkpoint 3093178548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.92062
Policy Entropy: 3.96359
Value Function Loss: 0.00680

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02890
Policy Update Magnitude: 0.25842
Value Function Update Magnitude: 0.35372

Collected Steps per Second: 21,899.17083
Overall Steps per Second: 10,584.59400

Timestep Collection Time: 2.28429
Timestep Consumption Time: 2.44183
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.72611

Cumulative Model Updates: 370,888
Cumulative Timesteps: 3,093,228,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.40204
Policy Entropy: 3.95383
Value Function Loss: 0.00719

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.02702
Policy Update Magnitude: 0.26486
Value Function Update Magnitude: 0.36243

Collected Steps per Second: 20,819.58663
Overall Steps per Second: 10,044.83487

Timestep Collection Time: 2.40255
Timestep Consumption Time: 2.57713
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.97967

Cumulative Model Updates: 370,894
Cumulative Timesteps: 3,093,278,592

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3093278592...
Checkpoint 3093278592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.33938
Policy Entropy: 3.97513
Value Function Loss: 0.00628

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.03173
Policy Update Magnitude: 0.25117
Value Function Update Magnitude: 0.35890

Collected Steps per Second: 22,123.82531
Overall Steps per Second: 10,678.90350

Timestep Collection Time: 2.26091
Timestep Consumption Time: 2.42309
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.68400

Cumulative Model Updates: 370,900
Cumulative Timesteps: 3,093,328,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.78060
Policy Entropy: 3.92624
Value Function Loss: 0.00701

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.03550
Policy Update Magnitude: 0.25350
Value Function Update Magnitude: 0.35892

Collected Steps per Second: 22,541.08333
Overall Steps per Second: 10,866.79399

Timestep Collection Time: 2.21915
Timestep Consumption Time: 2.38405
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.60320

Cumulative Model Updates: 370,906
Cumulative Timesteps: 3,093,378,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3093378634...
Checkpoint 3093378634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.76182
Policy Entropy: 3.93875
Value Function Loss: 0.00658

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.03796
Policy Update Magnitude: 0.25438
Value Function Update Magnitude: 0.35358

Collected Steps per Second: 22,279.71814
Overall Steps per Second: 10,602.97290

Timestep Collection Time: 2.24464
Timestep Consumption Time: 2.47196
PPO Batch Consumption Time: 0.28052
Total Iteration Time: 4.71660

Cumulative Model Updates: 370,912
Cumulative Timesteps: 3,093,428,644

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.83330
Policy Entropy: 3.91190
Value Function Loss: 0.00703

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.03268
Policy Update Magnitude: 0.25265
Value Function Update Magnitude: 0.34070

Collected Steps per Second: 22,330.91489
Overall Steps per Second: 10,573.50150

Timestep Collection Time: 2.24030
Timestep Consumption Time: 2.49115
PPO Batch Consumption Time: 0.29373
Total Iteration Time: 4.73145

Cumulative Model Updates: 370,918
Cumulative Timesteps: 3,093,478,672

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3093478672...
Checkpoint 3093478672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.62001
Policy Entropy: 3.93105
Value Function Loss: 0.00738

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.03223
Policy Update Magnitude: 0.25921
Value Function Update Magnitude: 0.34498

Collected Steps per Second: 22,409.10718
Overall Steps per Second: 10,713.72043

Timestep Collection Time: 2.23159
Timestep Consumption Time: 2.43607
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.66766

Cumulative Model Updates: 370,924
Cumulative Timesteps: 3,093,528,680

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.16416
Policy Entropy: 3.91734
Value Function Loss: 0.00771

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.03337
Policy Update Magnitude: 0.25876
Value Function Update Magnitude: 0.34514

Collected Steps per Second: 22,778.33776
Overall Steps per Second: 10,745.84617

Timestep Collection Time: 2.19551
Timestep Consumption Time: 2.45838
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.65389

Cumulative Model Updates: 370,930
Cumulative Timesteps: 3,093,578,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3093578690...
Checkpoint 3093578690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.78072
Policy Entropy: 3.93090
Value Function Loss: 0.00796

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.03169
Policy Update Magnitude: 0.25760
Value Function Update Magnitude: 0.34537

Collected Steps per Second: 21,979.97538
Overall Steps per Second: 10,613.10235

Timestep Collection Time: 2.27498
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.27992
Total Iteration Time: 4.71153

Cumulative Model Updates: 370,936
Cumulative Timesteps: 3,093,628,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.54320
Policy Entropy: 3.90830
Value Function Loss: 0.00775

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.03452
Policy Update Magnitude: 0.27083
Value Function Update Magnitude: 0.35304

Collected Steps per Second: 22,087.40553
Overall Steps per Second: 10,632.24583

Timestep Collection Time: 2.26482
Timestep Consumption Time: 2.44011
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.70493

Cumulative Model Updates: 370,942
Cumulative Timesteps: 3,093,678,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3093678718...
Checkpoint 3093678718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.16717
Policy Entropy: 3.96336
Value Function Loss: 0.00659

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.03271
Policy Update Magnitude: 0.26545
Value Function Update Magnitude: 0.35649

Collected Steps per Second: 22,473.78582
Overall Steps per Second: 10,510.36250

Timestep Collection Time: 2.22597
Timestep Consumption Time: 2.53371
PPO Batch Consumption Time: 0.29305
Total Iteration Time: 4.75968

Cumulative Model Updates: 370,948
Cumulative Timesteps: 3,093,728,744

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.31929
Policy Entropy: 3.99229
Value Function Loss: 0.00577

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.02748
Policy Update Magnitude: 0.25964
Value Function Update Magnitude: 0.34605

Collected Steps per Second: 22,488.25469
Overall Steps per Second: 10,609.67709

Timestep Collection Time: 2.22374
Timestep Consumption Time: 2.48969
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.71343

Cumulative Model Updates: 370,954
Cumulative Timesteps: 3,093,778,752

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3093778752...
Checkpoint 3093778752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.98127
Policy Entropy: 4.02696
Value Function Loss: 0.00552

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.24148
Value Function Update Magnitude: 0.32387

Collected Steps per Second: 23,177.73065
Overall Steps per Second: 10,869.19191

Timestep Collection Time: 2.15742
Timestep Consumption Time: 2.44311
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.60053

Cumulative Model Updates: 370,960
Cumulative Timesteps: 3,093,828,756

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.82070
Policy Entropy: 3.99877
Value Function Loss: 0.00571

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.23106
Value Function Update Magnitude: 0.33154

Collected Steps per Second: 22,592.98932
Overall Steps per Second: 10,552.00634

Timestep Collection Time: 2.21387
Timestep Consumption Time: 2.52627
PPO Batch Consumption Time: 0.29259
Total Iteration Time: 4.74014

Cumulative Model Updates: 370,966
Cumulative Timesteps: 3,093,878,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3093878774...
Checkpoint 3093878774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.08700
Policy Entropy: 3.95134
Value Function Loss: 0.00618

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.24481
Value Function Update Magnitude: 0.34369

Collected Steps per Second: 22,111.06036
Overall Steps per Second: 10,680.02637

Timestep Collection Time: 2.26231
Timestep Consumption Time: 2.42139
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.68370

Cumulative Model Updates: 370,972
Cumulative Timesteps: 3,093,928,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.97656
Policy Entropy: 3.90541
Value Function Loss: 0.00666

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.02764
Policy Update Magnitude: 0.24424
Value Function Update Magnitude: 0.35695

Collected Steps per Second: 23,143.03770
Overall Steps per Second: 10,791.40027

Timestep Collection Time: 2.16151
Timestep Consumption Time: 2.47403
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.63554

Cumulative Model Updates: 370,978
Cumulative Timesteps: 3,093,978,820

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3093978820...
Checkpoint 3093978820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.97729
Policy Entropy: 3.89238
Value Function Loss: 0.00733

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.03015
Policy Update Magnitude: 0.24854
Value Function Update Magnitude: 0.35827

Collected Steps per Second: 22,449.69652
Overall Steps per Second: 10,675.79216

Timestep Collection Time: 2.22720
Timestep Consumption Time: 2.45629
PPO Batch Consumption Time: 0.28133
Total Iteration Time: 4.68349

Cumulative Model Updates: 370,984
Cumulative Timesteps: 3,094,028,820

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.21902
Policy Entropy: 3.95588
Value Function Loss: 0.00635

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02620
Policy Update Magnitude: 0.25216
Value Function Update Magnitude: 0.35123

Collected Steps per Second: 22,629.02659
Overall Steps per Second: 10,910.55214

Timestep Collection Time: 2.21061
Timestep Consumption Time: 2.37431
PPO Batch Consumption Time: 0.27984
Total Iteration Time: 4.58492

Cumulative Model Updates: 370,990
Cumulative Timesteps: 3,094,078,844

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3094078844...
Checkpoint 3094078844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.48665
Policy Entropy: 3.97987
Value Function Loss: 0.00555

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02903
Policy Update Magnitude: 0.23656
Value Function Update Magnitude: 0.32796

Collected Steps per Second: 22,308.45152
Overall Steps per Second: 10,645.25238

Timestep Collection Time: 2.24211
Timestep Consumption Time: 2.45651
PPO Batch Consumption Time: 0.28028
Total Iteration Time: 4.69862

Cumulative Model Updates: 370,996
Cumulative Timesteps: 3,094,128,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.64615
Policy Entropy: 3.99176
Value Function Loss: 0.00504

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02244
Policy Update Magnitude: 0.22273
Value Function Update Magnitude: 0.30725

Collected Steps per Second: 22,294.33001
Overall Steps per Second: 10,537.43489

Timestep Collection Time: 2.24272
Timestep Consumption Time: 2.50227
PPO Batch Consumption Time: 0.29351
Total Iteration Time: 4.74499

Cumulative Model Updates: 371,002
Cumulative Timesteps: 3,094,178,862

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3094178862...
Checkpoint 3094178862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.71358
Policy Entropy: 3.99190
Value Function Loss: 0.00558

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.22440
Value Function Update Magnitude: 0.31692

Collected Steps per Second: 23,189.96439
Overall Steps per Second: 10,738.65337

Timestep Collection Time: 2.15654
Timestep Consumption Time: 2.50047
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.65701

Cumulative Model Updates: 371,008
Cumulative Timesteps: 3,094,228,872

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.66524
Policy Entropy: 3.96926
Value Function Loss: 0.00602

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02623
Policy Update Magnitude: 0.22956
Value Function Update Magnitude: 0.33031

Collected Steps per Second: 22,673.29057
Overall Steps per Second: 10,747.67463

Timestep Collection Time: 2.20603
Timestep Consumption Time: 2.44781
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.65384

Cumulative Model Updates: 371,014
Cumulative Timesteps: 3,094,278,890

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3094278890...
Checkpoint 3094278890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.49951
Policy Entropy: 3.97486
Value Function Loss: 0.00601

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02565
Policy Update Magnitude: 0.23219
Value Function Update Magnitude: 0.33658

Collected Steps per Second: 22,356.25305
Overall Steps per Second: 10,676.96670

Timestep Collection Time: 2.23705
Timestep Consumption Time: 2.44705
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.68410

Cumulative Model Updates: 371,020
Cumulative Timesteps: 3,094,328,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.32632
Policy Entropy: 3.94870
Value Function Loss: 0.00599

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02582
Policy Update Magnitude: 0.23858
Value Function Update Magnitude: 0.34296

Collected Steps per Second: 23,232.50555
Overall Steps per Second: 10,846.77445

Timestep Collection Time: 2.15293
Timestep Consumption Time: 2.45839
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.61132

Cumulative Model Updates: 371,026
Cumulative Timesteps: 3,094,378,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3094378920...
Checkpoint 3094378920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.84167
Policy Entropy: 3.91908
Value Function Loss: 0.00687

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02431
Policy Update Magnitude: 0.24929
Value Function Update Magnitude: 0.35348

Collected Steps per Second: 22,123.37890
Overall Steps per Second: 10,616.03154

Timestep Collection Time: 2.26005
Timestep Consumption Time: 2.44981
PPO Batch Consumption Time: 0.28092
Total Iteration Time: 4.70986

Cumulative Model Updates: 371,032
Cumulative Timesteps: 3,094,428,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.35124
Policy Entropy: 3.92119
Value Function Loss: 0.00671

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02507
Policy Update Magnitude: 0.25699
Value Function Update Magnitude: 0.36404

Collected Steps per Second: 22,676.14305
Overall Steps per Second: 10,932.71352

Timestep Collection Time: 2.20567
Timestep Consumption Time: 2.36923
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.57489

Cumulative Model Updates: 371,038
Cumulative Timesteps: 3,094,478,936

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3094478936...
Checkpoint 3094478936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.15842
Policy Entropy: 3.94843
Value Function Loss: 0.00696

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.25778
Value Function Update Magnitude: 0.35995

Collected Steps per Second: 22,345.62472
Overall Steps per Second: 10,654.76517

Timestep Collection Time: 2.23766
Timestep Consumption Time: 2.45526
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.69292

Cumulative Model Updates: 371,044
Cumulative Timesteps: 3,094,528,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.66835
Policy Entropy: 3.99579
Value Function Loss: 0.00609

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01950
Policy Update Magnitude: 0.23921
Value Function Update Magnitude: 0.34831

Collected Steps per Second: 22,399.54060
Overall Steps per Second: 10,559.03910

Timestep Collection Time: 2.23246
Timestep Consumption Time: 2.50339
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.73585

Cumulative Model Updates: 371,050
Cumulative Timesteps: 3,094,578,944

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3094578944...
Checkpoint 3094578944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.81682
Policy Entropy: 3.96531
Value Function Loss: 0.00661

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02253
Policy Update Magnitude: 0.23418
Value Function Update Magnitude: 0.33764

Collected Steps per Second: 22,229.23384
Overall Steps per Second: 10,708.43805

Timestep Collection Time: 2.25055
Timestep Consumption Time: 2.42128
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.67183

Cumulative Model Updates: 371,056
Cumulative Timesteps: 3,094,628,972

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.55848
Policy Entropy: 3.94632
Value Function Loss: 0.00632

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02732
Policy Update Magnitude: 0.24491
Value Function Update Magnitude: 0.33602

Collected Steps per Second: 22,600.61538
Overall Steps per Second: 10,703.50506

Timestep Collection Time: 2.21286
Timestep Consumption Time: 2.45963
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.67249

Cumulative Model Updates: 371,062
Cumulative Timesteps: 3,094,678,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3094678984...
Checkpoint 3094678984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.25637
Policy Entropy: 3.97188
Value Function Loss: 0.00640

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.24818
Value Function Update Magnitude: 0.32106

Collected Steps per Second: 22,377.20682
Overall Steps per Second: 10,720.94450

Timestep Collection Time: 2.23477
Timestep Consumption Time: 2.42974
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.66451

Cumulative Model Updates: 371,068
Cumulative Timesteps: 3,094,728,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.75545
Policy Entropy: 4.04431
Value Function Loss: 0.00616

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02357
Policy Update Magnitude: 0.22713
Value Function Update Magnitude: 0.31073

Collected Steps per Second: 23,278.10897
Overall Steps per Second: 10,837.02845

Timestep Collection Time: 2.14794
Timestep Consumption Time: 2.46587
PPO Batch Consumption Time: 0.28070
Total Iteration Time: 4.61381

Cumulative Model Updates: 371,074
Cumulative Timesteps: 3,094,778,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3094778992...
Checkpoint 3094778992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.29698
Policy Entropy: 4.03321
Value Function Loss: 0.00666

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02121
Policy Update Magnitude: 0.22504
Value Function Update Magnitude: 0.30354

Collected Steps per Second: 22,562.77556
Overall Steps per Second: 10,670.14912

Timestep Collection Time: 2.21622
Timestep Consumption Time: 2.47013
PPO Batch Consumption Time: 0.28045
Total Iteration Time: 4.68635

Cumulative Model Updates: 371,080
Cumulative Timesteps: 3,094,828,996

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.50469
Policy Entropy: 3.99093
Value Function Loss: 0.00709

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02390
Policy Update Magnitude: 0.23707
Value Function Update Magnitude: 0.31390

Collected Steps per Second: 22,533.49341
Overall Steps per Second: 10,868.84405

Timestep Collection Time: 2.22025
Timestep Consumption Time: 2.38281
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.60307

Cumulative Model Updates: 371,086
Cumulative Timesteps: 3,094,879,026

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3094879026...
Checkpoint 3094879026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.08262
Policy Entropy: 3.92503
Value Function Loss: 0.00779

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02815
Policy Update Magnitude: 0.25785
Value Function Update Magnitude: 0.33472

Collected Steps per Second: 22,353.34895
Overall Steps per Second: 10,667.76792

Timestep Collection Time: 2.23680
Timestep Consumption Time: 2.45021
PPO Batch Consumption Time: 0.28050
Total Iteration Time: 4.68702

Cumulative Model Updates: 371,092
Cumulative Timesteps: 3,094,929,026

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.92086
Policy Entropy: 3.98444
Value Function Loss: 0.00645

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02653
Policy Update Magnitude: 0.24959
Value Function Update Magnitude: 0.34887

Collected Steps per Second: 22,544.64831
Overall Steps per Second: 10,639.29387

Timestep Collection Time: 2.21889
Timestep Consumption Time: 2.48293
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.70182

Cumulative Model Updates: 371,098
Cumulative Timesteps: 3,094,979,050

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3094979050...
Checkpoint 3094979050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.22292
Policy Entropy: 3.99466
Value Function Loss: 0.00616

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02324
Policy Update Magnitude: 0.23988
Value Function Update Magnitude: 0.33414

Collected Steps per Second: 22,334.49216
Overall Steps per Second: 10,858.30955

Timestep Collection Time: 2.23905
Timestep Consumption Time: 2.36646
PPO Batch Consumption Time: 0.27996
Total Iteration Time: 4.60551

Cumulative Model Updates: 371,104
Cumulative Timesteps: 3,095,029,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.44045
Policy Entropy: 3.99374
Value Function Loss: 0.00588

Mean KL Divergence: 0.00264
SB3 Clip Fraction: 0.01930
Policy Update Magnitude: 0.24718
Value Function Update Magnitude: 0.31415

Collected Steps per Second: 22,561.62315
Overall Steps per Second: 10,552.15551

Timestep Collection Time: 2.21748
Timestep Consumption Time: 2.52373
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.74121

Cumulative Model Updates: 371,110
Cumulative Timesteps: 3,095,079,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3095079088...
Checkpoint 3095079088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.77905
Policy Entropy: 3.95673
Value Function Loss: 0.00631

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02465
Policy Update Magnitude: 0.24721
Value Function Update Magnitude: 0.32164

Collected Steps per Second: 22,300.15168
Overall Steps per Second: 10,664.94058

Timestep Collection Time: 2.24285
Timestep Consumption Time: 2.44690
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.68976

Cumulative Model Updates: 371,116
Cumulative Timesteps: 3,095,129,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.17123
Policy Entropy: 3.90725
Value Function Loss: 0.00733

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02681
Policy Update Magnitude: 0.25627
Value Function Update Magnitude: 0.33889

Collected Steps per Second: 22,506.74383
Overall Steps per Second: 10,856.86035

Timestep Collection Time: 2.22218
Timestep Consumption Time: 2.38449
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.60667

Cumulative Model Updates: 371,122
Cumulative Timesteps: 3,095,179,118

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3095179118...
Checkpoint 3095179118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.13274
Policy Entropy: 3.95115
Value Function Loss: 0.00677

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.03193
Policy Update Magnitude: 0.25807
Value Function Update Magnitude: 0.36234

Collected Steps per Second: 22,439.96697
Overall Steps per Second: 10,699.97403

Timestep Collection Time: 2.22959
Timestep Consumption Time: 2.44631
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.67590

Cumulative Model Updates: 371,128
Cumulative Timesteps: 3,095,229,150

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.98913
Policy Entropy: 3.90527
Value Function Loss: 0.00648

Mean KL Divergence: 0.00737
SB3 Clip Fraction: 0.04150
Policy Update Magnitude: 0.26204
Value Function Update Magnitude: 0.35849

Collected Steps per Second: 22,098.00101
Overall Steps per Second: 10,512.75809

Timestep Collection Time: 2.26265
Timestep Consumption Time: 2.49348
PPO Batch Consumption Time: 0.29383
Total Iteration Time: 4.75613

Cumulative Model Updates: 371,134
Cumulative Timesteps: 3,095,279,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3095279150...
Checkpoint 3095279150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.71138
Policy Entropy: 3.93197
Value Function Loss: 0.00570

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.04583
Policy Update Magnitude: 0.25644
Value Function Update Magnitude: 0.34763

Collected Steps per Second: 23,039.36183
Overall Steps per Second: 10,681.37061

Timestep Collection Time: 2.17020
Timestep Consumption Time: 2.51085
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.68105

Cumulative Model Updates: 371,140
Cumulative Timesteps: 3,095,329,150

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.21499
Policy Entropy: 3.91140
Value Function Loss: 0.00672

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.03995
Policy Update Magnitude: 0.25149
Value Function Update Magnitude: 0.33918

Collected Steps per Second: 22,217.00157
Overall Steps per Second: 10,477.22077

Timestep Collection Time: 2.25089
Timestep Consumption Time: 2.52213
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.77302

Cumulative Model Updates: 371,146
Cumulative Timesteps: 3,095,379,158

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3095379158...
Checkpoint 3095379158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.16313
Policy Entropy: 3.98097
Value Function Loss: 0.00624

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.24678
Value Function Update Magnitude: 0.33941

Collected Steps per Second: 22,315.60629
Overall Steps per Second: 10,841.85417

Timestep Collection Time: 2.24085
Timestep Consumption Time: 2.37146
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.61231

Cumulative Model Updates: 371,152
Cumulative Timesteps: 3,095,429,164

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.40702
Policy Entropy: 4.01037
Value Function Loss: 0.00700

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.24224
Value Function Update Magnitude: 0.32515

Collected Steps per Second: 22,701.90639
Overall Steps per Second: 10,550.82185

Timestep Collection Time: 2.20272
Timestep Consumption Time: 2.53681
PPO Batch Consumption Time: 0.29466
Total Iteration Time: 4.73954

Cumulative Model Updates: 371,158
Cumulative Timesteps: 3,095,479,170

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3095479170...
Checkpoint 3095479170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.60964
Policy Entropy: 4.02860
Value Function Loss: 0.00561

Mean KL Divergence: 0.00317
SB3 Clip Fraction: 0.02435
Policy Update Magnitude: 0.23872
Value Function Update Magnitude: 0.31587

Collected Steps per Second: 22,127.96513
Overall Steps per Second: 10,639.82073

Timestep Collection Time: 2.26058
Timestep Consumption Time: 2.44082
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.70140

Cumulative Model Updates: 371,164
Cumulative Timesteps: 3,095,529,192

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.49170
Policy Entropy: 4.01647
Value Function Loss: 0.00605

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02802
Policy Update Magnitude: 0.23659
Value Function Update Magnitude: 0.32352

Collected Steps per Second: 22,544.98368
Overall Steps per Second: 10,841.45076

Timestep Collection Time: 2.21814
Timestep Consumption Time: 2.39452
PPO Batch Consumption Time: 0.28132
Total Iteration Time: 4.61267

Cumulative Model Updates: 371,170
Cumulative Timesteps: 3,095,579,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3095579200...
Checkpoint 3095579200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.68005
Policy Entropy: 4.00679
Value Function Loss: 0.00598

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02546
Policy Update Magnitude: 0.23680
Value Function Update Magnitude: 0.33815

Collected Steps per Second: 22,019.13002
Overall Steps per Second: 10,469.09738

Timestep Collection Time: 2.27212
Timestep Consumption Time: 2.50671
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.77883

Cumulative Model Updates: 371,176
Cumulative Timesteps: 3,095,629,230

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.81961
Policy Entropy: 3.99928
Value Function Loss: 0.00576

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02755
Policy Update Magnitude: 0.24014
Value Function Update Magnitude: 0.34944

Collected Steps per Second: 22,617.83332
Overall Steps per Second: 10,727.70431

Timestep Collection Time: 2.21135
Timestep Consumption Time: 2.45097
PPO Batch Consumption Time: 0.29415
Total Iteration Time: 4.66232

Cumulative Model Updates: 371,182
Cumulative Timesteps: 3,095,679,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3095679246...
Checkpoint 3095679246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.17357
Policy Entropy: 3.98199
Value Function Loss: 0.00640

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.25071
Value Function Update Magnitude: 0.33396

Collected Steps per Second: 22,344.91349
Overall Steps per Second: 10,595.15197

Timestep Collection Time: 2.23890
Timestep Consumption Time: 2.48288
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.72178

Cumulative Model Updates: 371,188
Cumulative Timesteps: 3,095,729,274

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.61534
Policy Entropy: 3.96842
Value Function Loss: 0.00627

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02321
Policy Update Magnitude: 0.24362
Value Function Update Magnitude: 0.34508

Collected Steps per Second: 22,571.22104
Overall Steps per Second: 10,547.08751

Timestep Collection Time: 2.21583
Timestep Consumption Time: 2.52614
PPO Batch Consumption Time: 0.29424
Total Iteration Time: 4.74197

Cumulative Model Updates: 371,194
Cumulative Timesteps: 3,095,779,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3095779288...
Checkpoint 3095779288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.10337
Policy Entropy: 3.93204
Value Function Loss: 0.00685

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02413
Policy Update Magnitude: 0.25069
Value Function Update Magnitude: 0.36153

Collected Steps per Second: 22,627.76463
Overall Steps per Second: 10,824.26279

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.41064
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.62128

Cumulative Model Updates: 371,200
Cumulative Timesteps: 3,095,829,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.19321
Policy Entropy: 3.90255
Value Function Loss: 0.00715

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02821
Policy Update Magnitude: 0.25456
Value Function Update Magnitude: 0.35046

Collected Steps per Second: 22,662.06269
Overall Steps per Second: 10,699.90061

Timestep Collection Time: 2.20783
Timestep Consumption Time: 2.46829
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.67612

Cumulative Model Updates: 371,206
Cumulative Timesteps: 3,095,879,344

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3095879344...
Checkpoint 3095879344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.92410
Policy Entropy: 3.87709
Value Function Loss: 0.00719

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02883
Policy Update Magnitude: 0.26474
Value Function Update Magnitude: 0.35566

Collected Steps per Second: 22,168.51528
Overall Steps per Second: 10,638.87121

Timestep Collection Time: 2.25644
Timestep Consumption Time: 2.44537
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.70181

Cumulative Model Updates: 371,212
Cumulative Timesteps: 3,095,929,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.65734
Policy Entropy: 3.86300
Value Function Loss: 0.00743

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.03332
Policy Update Magnitude: 0.28021
Value Function Update Magnitude: 0.37212

Collected Steps per Second: 22,299.89099
Overall Steps per Second: 10,824.34496

Timestep Collection Time: 2.24234
Timestep Consumption Time: 2.37724
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.61959

Cumulative Model Updates: 371,218
Cumulative Timesteps: 3,095,979,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3095979370...
Checkpoint 3095979370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.07564
Policy Entropy: 3.87898
Value Function Loss: 0.00700

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.03678
Policy Update Magnitude: 0.29119
Value Function Update Magnitude: 0.37981

Collected Steps per Second: 22,445.65793
Overall Steps per Second: 10,712.96687

Timestep Collection Time: 2.22903
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.67023

Cumulative Model Updates: 371,224
Cumulative Timesteps: 3,096,029,402

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.37147
Policy Entropy: 3.89963
Value Function Loss: 0.00761

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.04613
Policy Update Magnitude: 0.28892
Value Function Update Magnitude: 0.37360

Collected Steps per Second: 22,539.79714
Overall Steps per Second: 10,655.66238

Timestep Collection Time: 2.21919
Timestep Consumption Time: 2.47503
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.69422

Cumulative Model Updates: 371,230
Cumulative Timesteps: 3,096,079,422

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3096079422...
Checkpoint 3096079422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.12516
Policy Entropy: 3.95706
Value Function Loss: 0.00691

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.04065
Policy Update Magnitude: 0.27407
Value Function Update Magnitude: 0.34336

Collected Steps per Second: 22,412.64386
Overall Steps per Second: 10,874.09448

Timestep Collection Time: 2.23160
Timestep Consumption Time: 2.36796
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.59956

Cumulative Model Updates: 371,236
Cumulative Timesteps: 3,096,129,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.78370
Policy Entropy: 3.98320
Value Function Loss: 0.00726

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.04059
Policy Update Magnitude: 0.25707
Value Function Update Magnitude: 0.31540

Collected Steps per Second: 22,689.28516
Overall Steps per Second: 10,567.50003

Timestep Collection Time: 2.20377
Timestep Consumption Time: 2.52791
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.73168

Cumulative Model Updates: 371,242
Cumulative Timesteps: 3,096,179,440

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3096179440...
Checkpoint 3096179440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.63526
Policy Entropy: 4.01087
Value Function Loss: 0.00659

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.03131
Policy Update Magnitude: 0.23710
Value Function Update Magnitude: 0.29510

Collected Steps per Second: 22,233.76026
Overall Steps per Second: 10,546.43111

Timestep Collection Time: 2.24937
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.74208

Cumulative Model Updates: 371,248
Cumulative Timesteps: 3,096,229,452

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.82590
Policy Entropy: 3.93616
Value Function Loss: 0.00782

Mean KL Divergence: 0.00389
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.23905
Value Function Update Magnitude: 0.30526

Collected Steps per Second: 22,741.68772
Overall Steps per Second: 10,930.17178

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.37693
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.57651

Cumulative Model Updates: 371,254
Cumulative Timesteps: 3,096,279,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3096279474...
Checkpoint 3096279474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.64149
Policy Entropy: 3.90301
Value Function Loss: 0.00736

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02752
Policy Update Magnitude: 0.24998
Value Function Update Magnitude: 0.30889

Collected Steps per Second: 22,380.11063
Overall Steps per Second: 10,639.23269

Timestep Collection Time: 2.23484
Timestep Consumption Time: 2.46625
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.70109

Cumulative Model Updates: 371,260
Cumulative Timesteps: 3,096,329,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.74833
Policy Entropy: 3.89429
Value Function Loss: 0.00743

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02758
Policy Update Magnitude: 0.25275
Value Function Update Magnitude: 0.30985

Collected Steps per Second: 22,634.51391
Overall Steps per Second: 10,665.38094

Timestep Collection Time: 2.21025
Timestep Consumption Time: 2.48044
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.69069

Cumulative Model Updates: 371,266
Cumulative Timesteps: 3,096,379,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3096379518...
Checkpoint 3096379518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.97497
Policy Entropy: 3.92385
Value Function Loss: 0.00595

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.24615
Value Function Update Magnitude: 0.31194

Collected Steps per Second: 22,489.48329
Overall Steps per Second: 10,926.52235

Timestep Collection Time: 2.22415
Timestep Consumption Time: 2.35370
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.57785

Cumulative Model Updates: 371,272
Cumulative Timesteps: 3,096,429,538

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.14151
Policy Entropy: 3.98932
Value Function Loss: 0.00511

Mean KL Divergence: 0.00291
SB3 Clip Fraction: 0.02214
Policy Update Magnitude: 0.23138
Value Function Update Magnitude: 0.30933

Collected Steps per Second: 22,595.01442
Overall Steps per Second: 10,584.77911

Timestep Collection Time: 2.21438
Timestep Consumption Time: 2.51259
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.72698

Cumulative Model Updates: 371,278
Cumulative Timesteps: 3,096,479,572

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3096479572...
Checkpoint 3096479572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.70380
Policy Entropy: 3.95733
Value Function Loss: 0.00465

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02833
Policy Update Magnitude: 0.22440
Value Function Update Magnitude: 0.29875

Collected Steps per Second: 22,088.73084
Overall Steps per Second: 10,520.73783

Timestep Collection Time: 2.26487
Timestep Consumption Time: 2.49031
PPO Batch Consumption Time: 0.29491
Total Iteration Time: 4.75518

Cumulative Model Updates: 371,284
Cumulative Timesteps: 3,096,529,600

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.80206
Policy Entropy: 3.91719
Value Function Loss: 0.00603

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02839
Policy Update Magnitude: 0.23698
Value Function Update Magnitude: 0.30545

Collected Steps per Second: 23,082.09897
Overall Steps per Second: 10,843.50204

Timestep Collection Time: 2.16670
Timestep Consumption Time: 2.44546
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.61216

Cumulative Model Updates: 371,290
Cumulative Timesteps: 3,096,579,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3096579612...
Checkpoint 3096579612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.05320
Policy Entropy: 3.90024
Value Function Loss: 0.00710

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.03240
Policy Update Magnitude: 0.25699
Value Function Update Magnitude: 0.33228

Collected Steps per Second: 22,114.46123
Overall Steps per Second: 10,596.34321

Timestep Collection Time: 2.26268
Timestep Consumption Time: 2.45951
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.72220

Cumulative Model Updates: 371,296
Cumulative Timesteps: 3,096,629,650

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.44158
Policy Entropy: 3.94340
Value Function Loss: 0.00700

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.03142
Policy Update Magnitude: 0.25380
Value Function Update Magnitude: 0.34166

Collected Steps per Second: 22,798.57473
Overall Steps per Second: 10,696.84995

Timestep Collection Time: 2.19400
Timestep Consumption Time: 2.48215
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.67614

Cumulative Model Updates: 371,302
Cumulative Timesteps: 3,096,679,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3096679670...
Checkpoint 3096679670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.81206
Policy Entropy: 3.99616
Value Function Loss: 0.00576

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02874
Policy Update Magnitude: 0.23745
Value Function Update Magnitude: 0.32110

Collected Steps per Second: 22,890.13850
Overall Steps per Second: 10,849.05030

Timestep Collection Time: 2.18557
Timestep Consumption Time: 2.42571
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.61128

Cumulative Model Updates: 371,308
Cumulative Timesteps: 3,096,729,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.50715
Policy Entropy: 3.95679
Value Function Loss: 0.00607

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02832
Policy Update Magnitude: 0.23886
Value Function Update Magnitude: 0.29913

Collected Steps per Second: 22,609.81270
Overall Steps per Second: 10,525.52914

Timestep Collection Time: 2.21267
Timestep Consumption Time: 2.54035
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.75302

Cumulative Model Updates: 371,314
Cumulative Timesteps: 3,096,779,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3096779726...
Checkpoint 3096779726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.16974
Policy Entropy: 3.93897
Value Function Loss: 0.00645

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.03109
Policy Update Magnitude: 0.23720
Value Function Update Magnitude: 0.30448

Collected Steps per Second: 22,146.90723
Overall Steps per Second: 10,689.47681

Timestep Collection Time: 2.25801
Timestep Consumption Time: 2.42023
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.67825

Cumulative Model Updates: 371,320
Cumulative Timesteps: 3,096,829,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.57714
Policy Entropy: 3.93246
Value Function Loss: 0.00713

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02420
Policy Update Magnitude: 0.24246
Value Function Update Magnitude: 0.32736

Collected Steps per Second: 23,107.10936
Overall Steps per Second: 10,843.24610

Timestep Collection Time: 2.16479
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.61319

Cumulative Model Updates: 371,326
Cumulative Timesteps: 3,096,879,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3096879756...
Checkpoint 3096879756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.36081
Policy Entropy: 3.95572
Value Function Loss: 0.00658

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.24406
Value Function Update Magnitude: 0.32879

Collected Steps per Second: 22,002.96116
Overall Steps per Second: 10,599.01699

Timestep Collection Time: 2.27269
Timestep Consumption Time: 2.44529
PPO Batch Consumption Time: 0.28038
Total Iteration Time: 4.71798

Cumulative Model Updates: 371,332
Cumulative Timesteps: 3,096,929,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.82636
Policy Entropy: 3.97821
Value Function Loss: 0.00613

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.24356
Value Function Update Magnitude: 0.31595

Collected Steps per Second: 22,643.26449
Overall Steps per Second: 10,913.28196

Timestep Collection Time: 2.20860
Timestep Consumption Time: 2.37389
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.58249

Cumulative Model Updates: 371,338
Cumulative Timesteps: 3,096,979,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3096979772...
Checkpoint 3096979772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.65188
Policy Entropy: 3.99473
Value Function Loss: 0.00633

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02442
Policy Update Magnitude: 0.24278
Value Function Update Magnitude: 0.31503

Collected Steps per Second: 22,353.36670
Overall Steps per Second: 10,659.47351

Timestep Collection Time: 2.23752
Timestep Consumption Time: 2.45465
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.69216

Cumulative Model Updates: 371,344
Cumulative Timesteps: 3,097,029,788

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.68022
Policy Entropy: 3.95375
Value Function Loss: 0.00650

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02177
Policy Update Magnitude: 0.24318
Value Function Update Magnitude: 0.31862

Collected Steps per Second: 22,459.98949
Overall Steps per Second: 10,593.87355

Timestep Collection Time: 2.22672
Timestep Consumption Time: 2.49413
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.72084

Cumulative Model Updates: 371,350
Cumulative Timesteps: 3,097,079,800

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3097079800...
Checkpoint 3097079800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.32454
Policy Entropy: 3.91060
Value Function Loss: 0.00725

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.25419
Value Function Update Magnitude: 0.34590

Collected Steps per Second: 22,159.89303
Overall Steps per Second: 10,698.21329

Timestep Collection Time: 2.25687
Timestep Consumption Time: 2.41793
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.67480

Cumulative Model Updates: 371,356
Cumulative Timesteps: 3,097,129,812

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.23805
Policy Entropy: 3.91629
Value Function Loss: 0.00668

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03028
Policy Update Magnitude: 0.25672
Value Function Update Magnitude: 0.36693

Collected Steps per Second: 22,815.99441
Overall Steps per Second: 10,745.26268

Timestep Collection Time: 2.19215
Timestep Consumption Time: 2.46256
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.65470

Cumulative Model Updates: 371,362
Cumulative Timesteps: 3,097,179,828

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3097179828...
Checkpoint 3097179828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.09794
Policy Entropy: 3.96582
Value Function Loss: 0.00575

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02628
Policy Update Magnitude: 0.25449
Value Function Update Magnitude: 0.35251

Collected Steps per Second: 21,886.06801
Overall Steps per Second: 10,591.83767

Timestep Collection Time: 2.28547
Timestep Consumption Time: 2.43703
PPO Batch Consumption Time: 0.28143
Total Iteration Time: 4.72250

Cumulative Model Updates: 371,368
Cumulative Timesteps: 3,097,229,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.69004
Policy Entropy: 3.96829
Value Function Loss: 0.00573

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.24533
Value Function Update Magnitude: 0.32515

Collected Steps per Second: 22,584.31022
Overall Steps per Second: 10,916.60410

Timestep Collection Time: 2.21490
Timestep Consumption Time: 2.36729
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.58219

Cumulative Model Updates: 371,374
Cumulative Timesteps: 3,097,279,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3097279870...
Checkpoint 3097279870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.06108
Policy Entropy: 3.96640
Value Function Loss: 0.00584

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.24531
Value Function Update Magnitude: 0.32701

Collected Steps per Second: 22,413.73818
Overall Steps per Second: 10,645.45265

Timestep Collection Time: 2.23193
Timestep Consumption Time: 2.46735
PPO Batch Consumption Time: 0.28002
Total Iteration Time: 4.69928

Cumulative Model Updates: 371,380
Cumulative Timesteps: 3,097,329,896

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.31452
Policy Entropy: 3.98783
Value Function Loss: 0.00585

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02446
Policy Update Magnitude: 0.24410
Value Function Update Magnitude: 0.33247

Collected Steps per Second: 22,555.50305
Overall Steps per Second: 10,627.98806

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.48890
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.70663

Cumulative Model Updates: 371,386
Cumulative Timesteps: 3,097,379,918

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3097379918...
Checkpoint 3097379918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.82863
Policy Entropy: 3.96751
Value Function Loss: 0.00661

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02654
Policy Update Magnitude: 0.24989
Value Function Update Magnitude: 0.34603

Collected Steps per Second: 23,094.16890
Overall Steps per Second: 10,874.46236

Timestep Collection Time: 2.16574
Timestep Consumption Time: 2.43366
PPO Batch Consumption Time: 0.27980
Total Iteration Time: 4.59940

Cumulative Model Updates: 371,392
Cumulative Timesteps: 3,097,429,934

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.44832
Policy Entropy: 3.94730
Value Function Loss: 0.00726

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.02982
Policy Update Magnitude: 0.26337
Value Function Update Magnitude: 0.36877

Collected Steps per Second: 22,385.41102
Overall Steps per Second: 10,582.48670

Timestep Collection Time: 2.23485
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.72743

Cumulative Model Updates: 371,398
Cumulative Timesteps: 3,097,479,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3097479962...
Checkpoint 3097479962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.20734
Policy Entropy: 3.93263
Value Function Loss: 0.00703

Mean KL Divergence: 0.00407
SB3 Clip Fraction: 0.02969
Policy Update Magnitude: 0.26530
Value Function Update Magnitude: 0.38199

Collected Steps per Second: 22,087.08416
Overall Steps per Second: 10,675.05360

Timestep Collection Time: 2.26440
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.68513

Cumulative Model Updates: 371,404
Cumulative Timesteps: 3,097,529,976

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.01841
Policy Entropy: 3.99685
Value Function Loss: 0.00627

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.25474
Value Function Update Magnitude: 0.35816

Collected Steps per Second: 23,465.43670
Overall Steps per Second: 10,800.35677

Timestep Collection Time: 2.13079
Timestep Consumption Time: 2.49868
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.62948

Cumulative Model Updates: 371,410
Cumulative Timesteps: 3,097,579,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3097579976...
Checkpoint 3097579976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.59126
Policy Entropy: 3.99918
Value Function Loss: 0.00614

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02594
Policy Update Magnitude: 0.23709
Value Function Update Magnitude: 0.33225

Collected Steps per Second: 22,446.40212
Overall Steps per Second: 10,702.93723

Timestep Collection Time: 2.22904
Timestep Consumption Time: 2.44575
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.67479

Cumulative Model Updates: 371,416
Cumulative Timesteps: 3,097,630,010

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.88334
Policy Entropy: 3.95843
Value Function Loss: 0.00648

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02600
Policy Update Magnitude: 0.24151
Value Function Update Magnitude: 0.32613

Collected Steps per Second: 22,276.28669
Overall Steps per Second: 10,544.58587

Timestep Collection Time: 2.24580
Timestep Consumption Time: 2.49863
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.74443

Cumulative Model Updates: 371,422
Cumulative Timesteps: 3,097,680,038

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3097680038...
Checkpoint 3097680038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.00106
Policy Entropy: 3.90879
Value Function Loss: 0.00737

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.25384
Value Function Update Magnitude: 0.33461

Collected Steps per Second: 23,156.90493
Overall Steps per Second: 10,767.40078

Timestep Collection Time: 2.15970
Timestep Consumption Time: 2.48506
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.64476

Cumulative Model Updates: 371,428
Cumulative Timesteps: 3,097,730,050

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.12710
Policy Entropy: 3.94719
Value Function Loss: 0.00695

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.25910
Value Function Update Magnitude: 0.34310

Collected Steps per Second: 22,878.02979
Overall Steps per Second: 10,707.91017

Timestep Collection Time: 2.18559
Timestep Consumption Time: 2.48404
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.66963

Cumulative Model Updates: 371,434
Cumulative Timesteps: 3,097,780,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3097780052...
Checkpoint 3097780052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.97004
Policy Entropy: 3.96201
Value Function Loss: 0.00639

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.25231
Value Function Update Magnitude: 0.34733

Collected Steps per Second: 22,551.95918
Overall Steps per Second: 10,619.96481

Timestep Collection Time: 2.21808
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.71019

Cumulative Model Updates: 371,440
Cumulative Timesteps: 3,097,830,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.40393
Policy Entropy: 3.95640
Value Function Loss: 0.00620

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02436
Policy Update Magnitude: 0.24786
Value Function Update Magnitude: 0.33977

Collected Steps per Second: 23,438.24847
Overall Steps per Second: 10,948.79044

Timestep Collection Time: 2.13352
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.56726

Cumulative Model Updates: 371,446
Cumulative Timesteps: 3,097,880,080

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3097880080...
Checkpoint 3097880080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.12358
Policy Entropy: 3.88881
Value Function Loss: 0.00737

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02695
Policy Update Magnitude: 0.26585
Value Function Update Magnitude: 0.35111

Collected Steps per Second: 22,214.53413
Overall Steps per Second: 10,640.78297

Timestep Collection Time: 2.25168
Timestep Consumption Time: 2.44910
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.70078

Cumulative Model Updates: 371,452
Cumulative Timesteps: 3,097,930,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.52643
Policy Entropy: 3.89907
Value Function Loss: 0.00743

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02945
Policy Update Magnitude: 0.27112
Value Function Update Magnitude: 0.35385

Collected Steps per Second: 22,487.08874
Overall Steps per Second: 10,850.38363

Timestep Collection Time: 2.22385
Timestep Consumption Time: 2.38502
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.60887

Cumulative Model Updates: 371,458
Cumulative Timesteps: 3,097,980,108

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3097980108...
Checkpoint 3097980108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.93172
Policy Entropy: 3.89486
Value Function Loss: 0.00802

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.03351
Policy Update Magnitude: 0.27568
Value Function Update Magnitude: 0.34956

Collected Steps per Second: 22,466.81497
Overall Steps per Second: 10,710.69130

Timestep Collection Time: 2.22684
Timestep Consumption Time: 2.44419
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.67103

Cumulative Model Updates: 371,464
Cumulative Timesteps: 3,098,030,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.14347
Policy Entropy: 3.93532
Value Function Loss: 0.00661

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.03415
Policy Update Magnitude: 0.27261
Value Function Update Magnitude: 0.34996

Collected Steps per Second: 22,536.89166
Overall Steps per Second: 10,587.97937

Timestep Collection Time: 2.21947
Timestep Consumption Time: 2.50475
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.72423

Cumulative Model Updates: 371,470
Cumulative Timesteps: 3,098,080,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3098080158...
Checkpoint 3098080158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.94384
Policy Entropy: 3.93690
Value Function Loss: 0.00613

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.03474
Policy Update Magnitude: 0.26102
Value Function Update Magnitude: 0.33152

Collected Steps per Second: 22,422.91423
Overall Steps per Second: 10,872.83639

Timestep Collection Time: 2.22995
Timestep Consumption Time: 2.36885
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.59880

Cumulative Model Updates: 371,476
Cumulative Timesteps: 3,098,130,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.58465
Policy Entropy: 3.99896
Value Function Loss: 0.00601

Mean KL Divergence: 0.00570
SB3 Clip Fraction: 0.03146
Policy Update Magnitude: 0.23838
Value Function Update Magnitude: 0.30959

Collected Steps per Second: 22,693.76476
Overall Steps per Second: 10,577.01379

Timestep Collection Time: 2.20395
Timestep Consumption Time: 2.52479
PPO Batch Consumption Time: 0.29359
Total Iteration Time: 4.72874

Cumulative Model Updates: 371,482
Cumulative Timesteps: 3,098,180,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3098180176...
Checkpoint 3098180176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.12282
Policy Entropy: 3.95907
Value Function Loss: 0.00629

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.02584
Policy Update Magnitude: 0.23670
Value Function Update Magnitude: 0.30609

Collected Steps per Second: 22,188.52275
Overall Steps per Second: 10,603.38988

Timestep Collection Time: 2.25378
Timestep Consumption Time: 2.46245
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.71623

Cumulative Model Updates: 371,488
Cumulative Timesteps: 3,098,230,184

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.75744
Policy Entropy: 3.96492
Value Function Loss: 0.00618

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02791
Policy Update Magnitude: 0.23866
Value Function Update Magnitude: 0.31151

Collected Steps per Second: 22,652.60922
Overall Steps per Second: 10,908.54694

Timestep Collection Time: 2.20769
Timestep Consumption Time: 2.37679
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.58448

Cumulative Model Updates: 371,494
Cumulative Timesteps: 3,098,280,194

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3098280194...
Checkpoint 3098280194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.13619
Policy Entropy: 3.97153
Value Function Loss: 0.00543

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02851
Policy Update Magnitude: 0.23378
Value Function Update Magnitude: 0.31549

Collected Steps per Second: 21,933.36943
Overall Steps per Second: 10,555.98238

Timestep Collection Time: 2.28091
Timestep Consumption Time: 2.45839
PPO Batch Consumption Time: 0.28090
Total Iteration Time: 4.73930

Cumulative Model Updates: 371,500
Cumulative Timesteps: 3,098,330,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.65641
Policy Entropy: 3.97142
Value Function Loss: 0.00642

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.23471
Value Function Update Magnitude: 0.30326

Collected Steps per Second: 22,168.98069
Overall Steps per Second: 10,517.88788

Timestep Collection Time: 2.25567
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.75438

Cumulative Model Updates: 371,506
Cumulative Timesteps: 3,098,380,228

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3098380228...
Checkpoint 3098380228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.23929
Policy Entropy: 3.96943
Value Function Loss: 0.00644

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02084
Policy Update Magnitude: 0.24468
Value Function Update Magnitude: 0.30865

Collected Steps per Second: 22,955.98120
Overall Steps per Second: 10,672.48468

Timestep Collection Time: 2.18000
Timestep Consumption Time: 2.50907
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.68907

Cumulative Model Updates: 371,512
Cumulative Timesteps: 3,098,430,272

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.01965
Policy Entropy: 3.92766
Value Function Loss: 0.00646

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02277
Policy Update Magnitude: 0.24405
Value Function Update Magnitude: 0.33396

Collected Steps per Second: 22,526.01584
Overall Steps per Second: 10,566.28110

Timestep Collection Time: 2.22045
Timestep Consumption Time: 2.51328
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.73374

Cumulative Model Updates: 371,518
Cumulative Timesteps: 3,098,480,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3098480290...
Checkpoint 3098480290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.45234
Policy Entropy: 3.96898
Value Function Loss: 0.00574

Mean KL Divergence: 0.00259
SB3 Clip Fraction: 0.01975
Policy Update Magnitude: 0.24423
Value Function Update Magnitude: 0.33931

Collected Steps per Second: 22,245.10370
Overall Steps per Second: 10,715.49345

Timestep Collection Time: 2.24849
Timestep Consumption Time: 2.41933
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.66782

Cumulative Model Updates: 371,524
Cumulative Timesteps: 3,098,530,308

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.00431
Policy Entropy: 3.96928
Value Function Loss: 0.00611

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02308
Policy Update Magnitude: 0.24062
Value Function Update Magnitude: 0.34681

Collected Steps per Second: 22,900.65326
Overall Steps per Second: 10,711.28423

Timestep Collection Time: 2.18404
Timestep Consumption Time: 2.48543
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.66947

Cumulative Model Updates: 371,530
Cumulative Timesteps: 3,098,580,324

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3098580324...
Checkpoint 3098580324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.38688
Policy Entropy: 3.99198
Value Function Loss: 0.00624

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01974
Policy Update Magnitude: 0.24288
Value Function Update Magnitude: 0.33169

Collected Steps per Second: 22,261.27736
Overall Steps per Second: 10,720.50569

Timestep Collection Time: 2.24668
Timestep Consumption Time: 2.41858
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.66526

Cumulative Model Updates: 371,536
Cumulative Timesteps: 3,098,630,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.72392
Policy Entropy: 3.97242
Value Function Loss: 0.00663

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02384
Policy Update Magnitude: 0.25052
Value Function Update Magnitude: 0.31384

Collected Steps per Second: 22,659.15867
Overall Steps per Second: 10,857.61484

Timestep Collection Time: 2.20776
Timestep Consumption Time: 2.39970
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.60746

Cumulative Model Updates: 371,542
Cumulative Timesteps: 3,098,680,364

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3098680364...
Checkpoint 3098680364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.75643
Policy Entropy: 3.97578
Value Function Loss: 0.00630

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.24857
Value Function Update Magnitude: 0.30231

Collected Steps per Second: 22,598.30219
Overall Steps per Second: 10,658.11482

Timestep Collection Time: 2.21264
Timestep Consumption Time: 2.47880
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.69145

Cumulative Model Updates: 371,548
Cumulative Timesteps: 3,098,730,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.87626
Policy Entropy: 3.96005
Value Function Loss: 0.00681

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.24758
Value Function Update Magnitude: 0.29742

Collected Steps per Second: 22,393.31497
Overall Steps per Second: 10,822.02366

Timestep Collection Time: 2.23415
Timestep Consumption Time: 2.38883
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.62298

Cumulative Model Updates: 371,554
Cumulative Timesteps: 3,098,780,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3098780396...
Checkpoint 3098780396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.77150
Policy Entropy: 3.97006
Value Function Loss: 0.00633

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.02571
Policy Update Magnitude: 0.24033
Value Function Update Magnitude: 0.30380

Collected Steps per Second: 22,582.97277
Overall Steps per Second: 10,727.68007

Timestep Collection Time: 2.21521
Timestep Consumption Time: 2.44805
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.66326

Cumulative Model Updates: 371,560
Cumulative Timesteps: 3,098,830,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.15491
Policy Entropy: 3.96749
Value Function Loss: 0.00661

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02535
Policy Update Magnitude: 0.24865
Value Function Update Magnitude: 0.31465

Collected Steps per Second: 22,822.22743
Overall Steps per Second: 10,664.81686

Timestep Collection Time: 2.19181
Timestep Consumption Time: 2.49857
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.69038

Cumulative Model Updates: 371,566
Cumulative Timesteps: 3,098,880,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3098880444...
Checkpoint 3098880444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.68657
Policy Entropy: 3.92652
Value Function Loss: 0.00655

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02579
Policy Update Magnitude: 0.25108
Value Function Update Magnitude: 0.32085

Collected Steps per Second: 22,475.05725
Overall Steps per Second: 10,879.30221

Timestep Collection Time: 2.22496
Timestep Consumption Time: 2.37148
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.59643

Cumulative Model Updates: 371,572
Cumulative Timesteps: 3,098,930,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.41193
Policy Entropy: 3.91321
Value Function Loss: 0.00660

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02572
Policy Update Magnitude: 0.25081
Value Function Update Magnitude: 0.31795

Collected Steps per Second: 22,658.67937
Overall Steps per Second: 10,626.70297

Timestep Collection Time: 2.20807
Timestep Consumption Time: 2.50007
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.70814

Cumulative Model Updates: 371,578
Cumulative Timesteps: 3,098,980,482

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3098980482...
Checkpoint 3098980482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.25373
Policy Entropy: 3.87523
Value Function Loss: 0.00687

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03209
Policy Update Magnitude: 0.25054
Value Function Update Magnitude: 0.31663

Collected Steps per Second: 22,328.30528
Overall Steps per Second: 10,659.00668

Timestep Collection Time: 2.24003
Timestep Consumption Time: 2.45234
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.69237

Cumulative Model Updates: 371,584
Cumulative Timesteps: 3,099,030,498

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.75140
Policy Entropy: 3.92600
Value Function Loss: 0.00618

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.03701
Policy Update Magnitude: 0.24562
Value Function Update Magnitude: 0.32353

Collected Steps per Second: 22,481.68749
Overall Steps per Second: 10,738.73576

Timestep Collection Time: 2.22412
Timestep Consumption Time: 2.43211
PPO Batch Consumption Time: 0.29298
Total Iteration Time: 4.65623

Cumulative Model Updates: 371,590
Cumulative Timesteps: 3,099,080,500

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3099080500...
Checkpoint 3099080500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.62120
Policy Entropy: 3.96011
Value Function Loss: 0.00506

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.03708
Policy Update Magnitude: 0.24149
Value Function Update Magnitude: 0.31584

Collected Steps per Second: 22,523.91196
Overall Steps per Second: 10,645.31644

Timestep Collection Time: 2.22075
Timestep Consumption Time: 2.47803
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.69878

Cumulative Model Updates: 371,596
Cumulative Timesteps: 3,099,130,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.45093
Policy Entropy: 3.97556
Value Function Loss: 0.00494

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.03096
Policy Update Magnitude: 0.23790
Value Function Update Magnitude: 0.30742

Collected Steps per Second: 22,544.24423
Overall Steps per Second: 10,800.00775

Timestep Collection Time: 2.21910
Timestep Consumption Time: 2.41312
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.63222

Cumulative Model Updates: 371,602
Cumulative Timesteps: 3,099,180,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3099180548...
Checkpoint 3099180548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.73934
Policy Entropy: 3.95388
Value Function Loss: 0.00513

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.23739
Value Function Update Magnitude: 0.31717

Collected Steps per Second: 22,436.86794
Overall Steps per Second: 10,743.01532

Timestep Collection Time: 2.22954
Timestep Consumption Time: 2.42688
PPO Batch Consumption Time: 0.29334
Total Iteration Time: 4.65642

Cumulative Model Updates: 371,608
Cumulative Timesteps: 3,099,230,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.88007
Policy Entropy: 3.96659
Value Function Loss: 0.00518

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02796
Policy Update Magnitude: 0.24138
Value Function Update Magnitude: 0.31823

Collected Steps per Second: 23,072.59849
Overall Steps per Second: 10,862.26431

Timestep Collection Time: 2.16846
Timestep Consumption Time: 2.43758
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.60604

Cumulative Model Updates: 371,614
Cumulative Timesteps: 3,099,280,604

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3099280604...
Checkpoint 3099280604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.83403
Policy Entropy: 3.97699
Value Function Loss: 0.00582

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02262
Policy Update Magnitude: 0.23856
Value Function Update Magnitude: 0.30117

Collected Steps per Second: 22,190.58673
Overall Steps per Second: 10,681.18109

Timestep Collection Time: 2.25429
Timestep Consumption Time: 2.42909
PPO Batch Consumption Time: 0.28323
Total Iteration Time: 4.68338

Cumulative Model Updates: 371,620
Cumulative Timesteps: 3,099,330,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54296
Policy Entropy: 4.00711
Value Function Loss: 0.00579

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02098
Policy Update Magnitude: 0.23226
Value Function Update Magnitude: 0.29242

Collected Steps per Second: 22,705.40513
Overall Steps per Second: 10,905.49729

Timestep Collection Time: 2.20282
Timestep Consumption Time: 2.38349
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.58631

Cumulative Model Updates: 371,626
Cumulative Timesteps: 3,099,380,644

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3099380644...
Checkpoint 3099380644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.17305
Policy Entropy: 3.98628
Value Function Loss: 0.00581

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.01845
Policy Update Magnitude: 0.23389
Value Function Update Magnitude: 0.29409

Collected Steps per Second: 22,667.78314
Overall Steps per Second: 10,652.58631

Timestep Collection Time: 2.20719
Timestep Consumption Time: 2.48951
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.69670

Cumulative Model Updates: 371,632
Cumulative Timesteps: 3,099,430,676

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.15631
Policy Entropy: 4.00607
Value Function Loss: 0.00548

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.02286
Policy Update Magnitude: 0.23465
Value Function Update Magnitude: 0.29701

Collected Steps per Second: 22,581.30914
Overall Steps per Second: 11,004.57473

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.33056
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.54593

Cumulative Model Updates: 371,638
Cumulative Timesteps: 3,099,480,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3099480702...
Checkpoint 3099480702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.39842
Policy Entropy: 3.97378
Value Function Loss: 0.00584

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.02146
Policy Update Magnitude: 0.24338
Value Function Update Magnitude: 0.31301

Collected Steps per Second: 22,576.58096
Overall Steps per Second: 10,618.70336

Timestep Collection Time: 2.21557
Timestep Consumption Time: 2.49499
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.71056

Cumulative Model Updates: 371,644
Cumulative Timesteps: 3,099,530,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.17585
Policy Entropy: 3.98047
Value Function Loss: 0.00650

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02344
Policy Update Magnitude: 0.24452
Value Function Update Magnitude: 0.33130

Collected Steps per Second: 22,660.21929
Overall Steps per Second: 10,787.90613

Timestep Collection Time: 2.20669
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.63519

Cumulative Model Updates: 371,650
Cumulative Timesteps: 3,099,580,726

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3099580726...
Checkpoint 3099580726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.56156
Policy Entropy: 3.94845
Value Function Loss: 0.00733

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.25223
Value Function Update Magnitude: 0.34894

Collected Steps per Second: 22,272.55469
Overall Steps per Second: 10,671.15513

Timestep Collection Time: 2.24635
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.29494
Total Iteration Time: 4.68853

Cumulative Model Updates: 371,656
Cumulative Timesteps: 3,099,630,758

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.75231
Policy Entropy: 3.96274
Value Function Loss: 0.00653

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02694
Policy Update Magnitude: 0.25538
Value Function Update Magnitude: 0.34703

Collected Steps per Second: 22,512.93323
Overall Steps per Second: 10,555.98232

Timestep Collection Time: 2.22095
Timestep Consumption Time: 2.51570
PPO Batch Consumption Time: 0.29511
Total Iteration Time: 4.73665

Cumulative Model Updates: 371,662
Cumulative Timesteps: 3,099,680,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3099680758...
Checkpoint 3099680758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.27513
Policy Entropy: 3.93161
Value Function Loss: 0.00656

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02996
Policy Update Magnitude: 0.25203
Value Function Update Magnitude: 0.34166

Collected Steps per Second: 22,361.68824
Overall Steps per Second: 10,562.24263

Timestep Collection Time: 2.23704
Timestep Consumption Time: 2.49907
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.73612

Cumulative Model Updates: 371,668
Cumulative Timesteps: 3,099,730,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.04148
Policy Entropy: 3.92160
Value Function Loss: 0.00639

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02589
Policy Update Magnitude: 0.24909
Value Function Update Magnitude: 0.34309

Collected Steps per Second: 22,094.03069
Overall Steps per Second: 10,678.59754

Timestep Collection Time: 2.26305
Timestep Consumption Time: 2.41921
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.68226

Cumulative Model Updates: 371,674
Cumulative Timesteps: 3,099,780,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3099780782...
Checkpoint 3099780782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.36589
Policy Entropy: 3.93405
Value Function Loss: 0.00643

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.25739
Value Function Update Magnitude: 0.34700

Collected Steps per Second: 22,545.51324
Overall Steps per Second: 10,632.07142

Timestep Collection Time: 2.21809
Timestep Consumption Time: 2.48541
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.70350

Cumulative Model Updates: 371,680
Cumulative Timesteps: 3,099,830,790

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.52959
Policy Entropy: 3.94678
Value Function Loss: 0.00716

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02891
Policy Update Magnitude: 0.26206
Value Function Update Magnitude: 0.34057

Collected Steps per Second: 22,823.87983
Overall Steps per Second: 10,703.12478

Timestep Collection Time: 2.19191
Timestep Consumption Time: 2.48223
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.67415

Cumulative Model Updates: 371,686
Cumulative Timesteps: 3,099,880,818

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3099880818...
Checkpoint 3099880818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.74006
Policy Entropy: 3.96581
Value Function Loss: 0.00737

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.03106
Policy Update Magnitude: 0.25642
Value Function Update Magnitude: 0.34373

Collected Steps per Second: 22,456.67490
Overall Steps per Second: 10,757.84083

Timestep Collection Time: 2.22651
Timestep Consumption Time: 2.42126
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.64777

Cumulative Model Updates: 371,692
Cumulative Timesteps: 3,099,930,818

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.51475
Policy Entropy: 3.94925
Value Function Loss: 0.00696

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.03111
Policy Update Magnitude: 0.25939
Value Function Update Magnitude: 0.34241

Collected Steps per Second: 23,237.79332
Overall Steps per Second: 10,813.51768

Timestep Collection Time: 2.15270
Timestep Consumption Time: 2.47336
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.62606

Cumulative Model Updates: 371,698
Cumulative Timesteps: 3,099,980,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3099980842...
Checkpoint 3099980842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.35321
Policy Entropy: 3.94018
Value Function Loss: 0.00677

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.03174
Policy Update Magnitude: 0.26779
Value Function Update Magnitude: 0.32795

Collected Steps per Second: 22,574.07864
Overall Steps per Second: 10,691.73558

Timestep Collection Time: 2.21564
Timestep Consumption Time: 2.46237
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.67801

Cumulative Model Updates: 371,704
Cumulative Timesteps: 3,100,030,858

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.77402
Policy Entropy: 3.97055
Value Function Loss: 0.00629

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.26399
Value Function Update Magnitude: 0.33299

Collected Steps per Second: 23,031.94028
Overall Steps per Second: 10,816.71732

Timestep Collection Time: 2.17090
Timestep Consumption Time: 2.45158
PPO Batch Consumption Time: 0.29378
Total Iteration Time: 4.62247

Cumulative Model Updates: 371,710
Cumulative Timesteps: 3,100,080,858

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3100080858...
Checkpoint 3100080858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92.47887
Policy Entropy: 3.95061
Value Function Loss: 0.00643

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02505
Policy Update Magnitude: 0.25310
Value Function Update Magnitude: 0.33666

Collected Steps per Second: 22,031.77501
Overall Steps per Second: 10,640.30906

Timestep Collection Time: 2.27054
Timestep Consumption Time: 2.43083
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.70137

Cumulative Model Updates: 371,716
Cumulative Timesteps: 3,100,130,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.34023
Policy Entropy: 3.96186
Value Function Loss: 0.00661

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.25388
Value Function Update Magnitude: 0.32927

Collected Steps per Second: 22,612.55060
Overall Steps per Second: 10,660.55959

Timestep Collection Time: 2.21222
Timestep Consumption Time: 2.48021
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.69244

Cumulative Model Updates: 371,722
Cumulative Timesteps: 3,100,180,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3100180906...
Checkpoint 3100180906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.63859
Policy Entropy: 3.97871
Value Function Loss: 0.00579

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02713
Policy Update Magnitude: 0.26283
Value Function Update Magnitude: 0.32405

Collected Steps per Second: 23,516.94994
Overall Steps per Second: 10,898.66800

Timestep Collection Time: 2.12621
Timestep Consumption Time: 2.46169
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.58790

Cumulative Model Updates: 371,728
Cumulative Timesteps: 3,100,230,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.44466
Policy Entropy: 3.98545
Value Function Loss: 0.00558

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02294
Policy Update Magnitude: 0.24704
Value Function Update Magnitude: 0.32117

Collected Steps per Second: 22,755.10015
Overall Steps per Second: 10,701.75816

Timestep Collection Time: 2.19731
Timestep Consumption Time: 2.47482
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.67213

Cumulative Model Updates: 371,734
Cumulative Timesteps: 3,100,280,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3100280908...
Checkpoint 3100280908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.35671
Policy Entropy: 3.98944
Value Function Loss: 0.00596

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.02269
Policy Update Magnitude: 0.23853
Value Function Update Magnitude: 0.31244

Collected Steps per Second: 22,274.55044
Overall Steps per Second: 10,655.43266

Timestep Collection Time: 2.24561
Timestep Consumption Time: 2.44871
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.69432

Cumulative Model Updates: 371,740
Cumulative Timesteps: 3,100,330,928

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.83129
Policy Entropy: 3.94188
Value Function Loss: 0.00686

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02351
Policy Update Magnitude: 0.24761
Value Function Update Magnitude: 0.31732

Collected Steps per Second: 23,457.11262
Overall Steps per Second: 10,844.92123

Timestep Collection Time: 2.13232
Timestep Consumption Time: 2.47980
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.61211

Cumulative Model Updates: 371,746
Cumulative Timesteps: 3,100,380,946

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3100380946...
Checkpoint 3100380946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.61261
Policy Entropy: 3.99115
Value Function Loss: 0.00666

Mean KL Divergence: 0.00263
SB3 Clip Fraction: 0.02246
Policy Update Magnitude: 0.24847
Value Function Update Magnitude: 0.32965

Collected Steps per Second: 22,760.17510
Overall Steps per Second: 10,831.47538

Timestep Collection Time: 2.19700
Timestep Consumption Time: 2.41955
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.61655

Cumulative Model Updates: 371,752
Cumulative Timesteps: 3,100,430,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.10053
Policy Entropy: 3.98849
Value Function Loss: 0.00665

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02334
Policy Update Magnitude: 0.24166
Value Function Update Magnitude: 0.32880

Collected Steps per Second: 22,728.37699
Overall Steps per Second: 10,720.70029

Timestep Collection Time: 2.20016
Timestep Consumption Time: 2.46428
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.66443

Cumulative Model Updates: 371,758
Cumulative Timesteps: 3,100,480,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3100480956...
Checkpoint 3100480956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.26885
Policy Entropy: 3.98889
Value Function Loss: 0.00648

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.24198
Value Function Update Magnitude: 0.32434

Collected Steps per Second: 23,290.29077
Overall Steps per Second: 10,888.34480

Timestep Collection Time: 2.14725
Timestep Consumption Time: 2.44574
PPO Batch Consumption Time: 0.28308
Total Iteration Time: 4.59298

Cumulative Model Updates: 371,764
Cumulative Timesteps: 3,100,530,966

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.29588
Policy Entropy: 3.94562
Value Function Loss: 0.00695

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.03106
Policy Update Magnitude: 0.25263
Value Function Update Magnitude: 0.31210

Collected Steps per Second: 22,727.36258
Overall Steps per Second: 10,712.38174

Timestep Collection Time: 2.20061
Timestep Consumption Time: 2.46820
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.66880

Cumulative Model Updates: 371,770
Cumulative Timesteps: 3,100,580,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3100580980...
Checkpoint 3100580980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.39969
Policy Entropy: 3.94430
Value Function Loss: 0.00720

Mean KL Divergence: 0.00433
SB3 Clip Fraction: 0.03127
Policy Update Magnitude: 0.25602
Value Function Update Magnitude: 0.32062

Collected Steps per Second: 22,151.44210
Overall Steps per Second: 10,596.97777

Timestep Collection Time: 2.25854
Timestep Consumption Time: 2.46261
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.72116

Cumulative Model Updates: 371,776
Cumulative Timesteps: 3,100,631,010

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.94900
Policy Entropy: 3.96108
Value Function Loss: 0.00644

Mean KL Divergence: 0.00427
SB3 Clip Fraction: 0.02914
Policy Update Magnitude: 0.25184
Value Function Update Magnitude: 0.34584

Collected Steps per Second: 23,529.92645
Overall Steps per Second: 10,811.88128

Timestep Collection Time: 2.12580
Timestep Consumption Time: 2.50059
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.62639

Cumulative Model Updates: 371,782
Cumulative Timesteps: 3,100,681,030

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3100681030...
Checkpoint 3100681030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.58978
Policy Entropy: 3.95215
Value Function Loss: 0.00669

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.02740
Policy Update Magnitude: 0.25906
Value Function Update Magnitude: 0.35667

Collected Steps per Second: 22,273.00703
Overall Steps per Second: 10,537.85331

Timestep Collection Time: 2.24595
Timestep Consumption Time: 2.50113
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.74708

Cumulative Model Updates: 371,788
Cumulative Timesteps: 3,100,731,054

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.26966
Policy Entropy: 3.95450
Value Function Loss: 0.00675

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02786
Policy Update Magnitude: 0.26327
Value Function Update Magnitude: 0.35695

Collected Steps per Second: 22,441.09381
Overall Steps per Second: 10,656.00597

Timestep Collection Time: 2.22850
Timestep Consumption Time: 2.46463
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.69313

Cumulative Model Updates: 371,794
Cumulative Timesteps: 3,100,781,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3100781064...
Checkpoint 3100781064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.37953
Policy Entropy: 3.90326
Value Function Loss: 0.00751

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.03033
Policy Update Magnitude: 0.26617
Value Function Update Magnitude: 0.35949

Collected Steps per Second: 23,179.29855
Overall Steps per Second: 10,896.70464

Timestep Collection Time: 2.15710
Timestep Consumption Time: 2.43145
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.58854

Cumulative Model Updates: 371,800
Cumulative Timesteps: 3,100,831,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.72699
Policy Entropy: 3.90989
Value Function Loss: 0.00700

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02593
Policy Update Magnitude: 0.27292
Value Function Update Magnitude: 0.37055

Collected Steps per Second: 22,628.57686
Overall Steps per Second: 10,660.58793

Timestep Collection Time: 2.21030
Timestep Consumption Time: 2.48137
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.69167

Cumulative Model Updates: 371,806
Cumulative Timesteps: 3,100,881,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3100881080...
Checkpoint 3100881080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.06813
Policy Entropy: 3.92304
Value Function Loss: 0.00586

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02991
Policy Update Magnitude: 0.26484
Value Function Update Magnitude: 0.36408

Collected Steps per Second: 22,213.77055
Overall Steps per Second: 10,882.02678

Timestep Collection Time: 2.25176
Timestep Consumption Time: 2.34481
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.59657

Cumulative Model Updates: 371,812
Cumulative Timesteps: 3,100,931,100

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.36133
Policy Entropy: 3.98795
Value Function Loss: 0.00561

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.25255
Value Function Update Magnitude: 0.33154

Collected Steps per Second: 22,712.67669
Overall Steps per Second: 10,686.72222

Timestep Collection Time: 2.20203
Timestep Consumption Time: 2.47798
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.68001

Cumulative Model Updates: 371,818
Cumulative Timesteps: 3,100,981,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3100981114...
Checkpoint 3100981114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.61462
Policy Entropy: 3.98784
Value Function Loss: 0.00550

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02374
Policy Update Magnitude: 0.24255
Value Function Update Magnitude: 0.31240

Collected Steps per Second: 22,632.72148
Overall Steps per Second: 10,863.34764

Timestep Collection Time: 2.20946
Timestep Consumption Time: 2.39373
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.60319

Cumulative Model Updates: 371,824
Cumulative Timesteps: 3,101,031,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.84121
Policy Entropy: 3.93523
Value Function Loss: 0.00672

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02647
Policy Update Magnitude: 0.24480
Value Function Update Magnitude: 0.31832

Collected Steps per Second: 23,378.84805
Overall Steps per Second: 10,936.17469

Timestep Collection Time: 2.13894
Timestep Consumption Time: 2.43359
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.57253

Cumulative Model Updates: 371,830
Cumulative Timesteps: 3,101,081,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3101081126...
Checkpoint 3101081126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.54352
Policy Entropy: 3.89916
Value Function Loss: 0.00717

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02918
Policy Update Magnitude: 0.25121
Value Function Update Magnitude: 0.32146

Collected Steps per Second: 21,306.81213
Overall Steps per Second: 10,214.39779

Timestep Collection Time: 2.34732
Timestep Consumption Time: 2.54910
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.89642

Cumulative Model Updates: 371,836
Cumulative Timesteps: 3,101,131,140

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.68675
Policy Entropy: 3.91707
Value Function Loss: 0.00745

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02951
Policy Update Magnitude: 0.25715
Value Function Update Magnitude: 0.32372

Collected Steps per Second: 22,750.55605
Overall Steps per Second: 10,855.83893

Timestep Collection Time: 2.19880
Timestep Consumption Time: 2.40922
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.60803

Cumulative Model Updates: 371,842
Cumulative Timesteps: 3,101,181,164

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3101181164...
Checkpoint 3101181164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.88288
Policy Entropy: 3.94092
Value Function Loss: 0.00740

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.03124
Policy Update Magnitude: 0.26739
Value Function Update Magnitude: 0.33533

Collected Steps per Second: 23,135.78081
Overall Steps per Second: 10,702.20752

Timestep Collection Time: 2.16202
Timestep Consumption Time: 2.51178
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.67380

Cumulative Model Updates: 371,848
Cumulative Timesteps: 3,101,231,184

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.88010
Policy Entropy: 3.94116
Value Function Loss: 0.00688

Mean KL Divergence: 0.00428
SB3 Clip Fraction: 0.02706
Policy Update Magnitude: 0.26597
Value Function Update Magnitude: 0.34220

Collected Steps per Second: 22,426.58501
Overall Steps per Second: 10,514.64767

Timestep Collection Time: 2.23048
Timestep Consumption Time: 2.52689
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.75736

Cumulative Model Updates: 371,854
Cumulative Timesteps: 3,101,281,206

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3101281206...
Checkpoint 3101281206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.13304
Policy Entropy: 3.94834
Value Function Loss: 0.00720

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02323
Policy Update Magnitude: 0.26265
Value Function Update Magnitude: 0.34688

Collected Steps per Second: 22,198.81529
Overall Steps per Second: 10,666.68646

Timestep Collection Time: 2.25327
Timestep Consumption Time: 2.43609
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.68937

Cumulative Model Updates: 371,860
Cumulative Timesteps: 3,101,331,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.56826
Policy Entropy: 3.97352
Value Function Loss: 0.00599

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02433
Policy Update Magnitude: 0.26031
Value Function Update Magnitude: 0.34967

Collected Steps per Second: 22,073.00674
Overall Steps per Second: 10,452.11957

Timestep Collection Time: 2.26630
Timestep Consumption Time: 2.51972
PPO Batch Consumption Time: 0.29395
Total Iteration Time: 4.78601

Cumulative Model Updates: 371,866
Cumulative Timesteps: 3,101,381,250

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3101381250...
Checkpoint 3101381250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.21343
Policy Entropy: 3.98303
Value Function Loss: 0.00600

Mean KL Divergence: 0.00320
SB3 Clip Fraction: 0.02513
Policy Update Magnitude: 0.25606
Value Function Update Magnitude: 0.35008

Collected Steps per Second: 22,012.77798
Overall Steps per Second: 10,558.94649

Timestep Collection Time: 2.27141
Timestep Consumption Time: 2.46391
PPO Batch Consumption Time: 0.28751
Total Iteration Time: 4.73532

Cumulative Model Updates: 371,872
Cumulative Timesteps: 3,101,431,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.25276
Policy Entropy: 3.97134
Value Function Loss: 0.00529

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02542
Policy Update Magnitude: 0.25660
Value Function Update Magnitude: 0.34261

Collected Steps per Second: 22,658.35712
Overall Steps per Second: 10,897.82920

Timestep Collection Time: 2.20784
Timestep Consumption Time: 2.38262
PPO Batch Consumption Time: 0.28108
Total Iteration Time: 4.59046

Cumulative Model Updates: 371,878
Cumulative Timesteps: 3,101,481,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3101481276...
Checkpoint 3101481276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.16384
Policy Entropy: 3.94419
Value Function Loss: 0.00705

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.03017
Policy Update Magnitude: 0.25632
Value Function Update Magnitude: 0.33390

Collected Steps per Second: 22,119.99860
Overall Steps per Second: 10,613.39665

Timestep Collection Time: 2.26112
Timestep Consumption Time: 2.45141
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.71253

Cumulative Model Updates: 371,884
Cumulative Timesteps: 3,101,531,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.24236
Policy Entropy: 3.96591
Value Function Loss: 0.00674

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.03117
Policy Update Magnitude: 0.26026
Value Function Update Magnitude: 0.34125

Collected Steps per Second: 22,616.00538
Overall Steps per Second: 10,618.97224

Timestep Collection Time: 2.21144
Timestep Consumption Time: 2.49843
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.70987

Cumulative Model Updates: 371,890
Cumulative Timesteps: 3,101,581,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3101581306...
Checkpoint 3101581306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.98229
Policy Entropy: 4.00852
Value Function Loss: 0.00652

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.02760
Policy Update Magnitude: 0.24760
Value Function Update Magnitude: 0.33023

Collected Steps per Second: 22,128.97503
Overall Steps per Second: 10,725.28938

Timestep Collection Time: 2.25975
Timestep Consumption Time: 2.40269
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.66244

Cumulative Model Updates: 371,896
Cumulative Timesteps: 3,101,631,312

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.40438
Policy Entropy: 4.03741
Value Function Loss: 0.00579

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.23600
Value Function Update Magnitude: 0.31651

Collected Steps per Second: 23,080.10942
Overall Steps per Second: 10,684.05243

Timestep Collection Time: 2.16645
Timestep Consumption Time: 2.51361
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.68006

Cumulative Model Updates: 371,902
Cumulative Timesteps: 3,101,681,314

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3101681314...
Checkpoint 3101681314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.63465
Policy Entropy: 4.03516
Value Function Loss: 0.00557

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02676
Policy Update Magnitude: 0.23815
Value Function Update Magnitude: 0.31328

Collected Steps per Second: 22,111.78124
Overall Steps per Second: 10,661.19834

Timestep Collection Time: 2.26142
Timestep Consumption Time: 2.42886
PPO Batch Consumption Time: 0.27962
Total Iteration Time: 4.69028

Cumulative Model Updates: 371,908
Cumulative Timesteps: 3,101,731,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.28919
Policy Entropy: 4.01905
Value Function Loss: 0.00578

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02459
Policy Update Magnitude: 0.23542
Value Function Update Magnitude: 0.30951

Collected Steps per Second: 23,893.07198
Overall Steps per Second: 10,938.67478

Timestep Collection Time: 2.09375
Timestep Consumption Time: 2.47957
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.57331

Cumulative Model Updates: 371,914
Cumulative Timesteps: 3,101,781,344

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3101781344...
Checkpoint 3101781344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.06008
Policy Entropy: 3.97946
Value Function Loss: 0.00595

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02619
Policy Update Magnitude: 0.23981
Value Function Update Magnitude: 0.31124

Collected Steps per Second: 22,785.98702
Overall Steps per Second: 10,614.45225

Timestep Collection Time: 2.19565
Timestep Consumption Time: 2.51774
PPO Batch Consumption Time: 0.29307
Total Iteration Time: 4.71339

Cumulative Model Updates: 371,920
Cumulative Timesteps: 3,101,831,374

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.13985
Policy Entropy: 3.98968
Value Function Loss: 0.00676

Mean KL Divergence: 0.00324
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.24139
Value Function Update Magnitude: 0.31703

Collected Steps per Second: 22,549.48358
Overall Steps per Second: 10,890.47542

Timestep Collection Time: 2.21850
Timestep Consumption Time: 2.37506
PPO Batch Consumption Time: 0.28056
Total Iteration Time: 4.59356

Cumulative Model Updates: 371,926
Cumulative Timesteps: 3,101,881,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3101881400...
Checkpoint 3101881400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.39210
Policy Entropy: 3.97374
Value Function Loss: 0.00626

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02252
Policy Update Magnitude: 0.24384
Value Function Update Magnitude: 0.32012

Collected Steps per Second: 22,619.77636
Overall Steps per Second: 10,654.96193

Timestep Collection Time: 2.21143
Timestep Consumption Time: 2.48329
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.69471

Cumulative Model Updates: 371,932
Cumulative Timesteps: 3,101,931,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.38048
Policy Entropy: 4.01806
Value Function Loss: 0.00553

Mean KL Divergence: 0.00278
SB3 Clip Fraction: 0.02096
Policy Update Magnitude: 0.23457
Value Function Update Magnitude: 0.31801

Collected Steps per Second: 22,645.11025
Overall Steps per Second: 10,691.10700

Timestep Collection Time: 2.20851
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.67791

Cumulative Model Updates: 371,938
Cumulative Timesteps: 3,101,981,434

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3101981434...
Checkpoint 3101981434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.94231
Policy Entropy: 3.96418
Value Function Loss: 0.00649

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02116
Policy Update Magnitude: 0.24222
Value Function Update Magnitude: 0.32415

Collected Steps per Second: 23,136.98081
Overall Steps per Second: 10,958.10667

Timestep Collection Time: 2.16156
Timestep Consumption Time: 2.40237
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.56393

Cumulative Model Updates: 371,944
Cumulative Timesteps: 3,102,031,446

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.17826
Policy Entropy: 3.94943
Value Function Loss: 0.00661

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02074
Policy Update Magnitude: 0.25078
Value Function Update Magnitude: 0.33530

Collected Steps per Second: 22,744.91963
Overall Steps per Second: 10,761.42471

Timestep Collection Time: 2.19856
Timestep Consumption Time: 2.44823
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.64678

Cumulative Model Updates: 371,950
Cumulative Timesteps: 3,102,081,452

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3102081452...
Checkpoint 3102081452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.48248
Policy Entropy: 3.90366
Value Function Loss: 0.00715

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02532
Policy Update Magnitude: 0.25598
Value Function Update Magnitude: 0.34242

Collected Steps per Second: 22,036.48116
Overall Steps per Second: 10,623.18291

Timestep Collection Time: 2.27005
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.28067
Total Iteration Time: 4.70895

Cumulative Model Updates: 371,956
Cumulative Timesteps: 3,102,131,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.55955
Policy Entropy: 3.91285
Value Function Loss: 0.00618

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02794
Policy Update Magnitude: 0.26160
Value Function Update Magnitude: 0.33133

Collected Steps per Second: 23,689.47599
Overall Steps per Second: 11,006.53220

Timestep Collection Time: 2.11073
Timestep Consumption Time: 2.43221
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.54294

Cumulative Model Updates: 371,962
Cumulative Timesteps: 3,102,181,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3102181478...
Checkpoint 3102181478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.10072
Policy Entropy: 3.95798
Value Function Loss: 0.00591

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02719
Policy Update Magnitude: 0.24982
Value Function Update Magnitude: 0.31781

Collected Steps per Second: 22,421.63722
Overall Steps per Second: 10,631.10051

Timestep Collection Time: 2.23115
Timestep Consumption Time: 2.47448
PPO Batch Consumption Time: 0.28405
Total Iteration Time: 4.70563

Cumulative Model Updates: 371,968
Cumulative Timesteps: 3,102,231,504

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.13504
Policy Entropy: 3.97521
Value Function Loss: 0.00642

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02597
Policy Update Magnitude: 0.24896
Value Function Update Magnitude: 0.30129

Collected Steps per Second: 22,645.93209
Overall Steps per Second: 10,820.92035

Timestep Collection Time: 2.20870
Timestep Consumption Time: 2.41365
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.62234

Cumulative Model Updates: 371,974
Cumulative Timesteps: 3,102,281,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3102281522...
Checkpoint 3102281522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.02964
Policy Entropy: 4.00772
Value Function Loss: 0.00652

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.24383
Value Function Update Magnitude: 0.30146

Collected Steps per Second: 23,387.80843
Overall Steps per Second: 10,745.25807

Timestep Collection Time: 2.13915
Timestep Consumption Time: 2.51686
PPO Batch Consumption Time: 0.29336
Total Iteration Time: 4.65601

Cumulative Model Updates: 371,980
Cumulative Timesteps: 3,102,331,552

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.01895
Policy Entropy: 3.99080
Value Function Loss: 0.00659

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02356
Policy Update Magnitude: 0.24652
Value Function Update Magnitude: 0.30517

Collected Steps per Second: 23,145.21640
Overall Steps per Second: 10,868.00268

Timestep Collection Time: 2.16105
Timestep Consumption Time: 2.44127
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.60232

Cumulative Model Updates: 371,986
Cumulative Timesteps: 3,102,381,570

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3102381570...
Checkpoint 3102381570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.41233
Policy Entropy: 3.98049
Value Function Loss: 0.00695

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02575
Policy Update Magnitude: 0.24935
Value Function Update Magnitude: 0.30355

Collected Steps per Second: 22,744.81714
Overall Steps per Second: 10,880.20791

Timestep Collection Time: 2.19909
Timestep Consumption Time: 2.39806
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.59715

Cumulative Model Updates: 371,992
Cumulative Timesteps: 3,102,431,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.72544
Policy Entropy: 3.96632
Value Function Loss: 0.00723

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02923
Policy Update Magnitude: 0.25386
Value Function Update Magnitude: 0.32035

Collected Steps per Second: 22,959.81706
Overall Steps per Second: 10,728.05264

Timestep Collection Time: 2.17772
Timestep Consumption Time: 2.48296
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.66068

Cumulative Model Updates: 371,998
Cumulative Timesteps: 3,102,481,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3102481588...
Checkpoint 3102481588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.79552
Policy Entropy: 3.96645
Value Function Loss: 0.00705

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02631
Policy Update Magnitude: 0.25751
Value Function Update Magnitude: 0.34035

Collected Steps per Second: 22,536.36522
Overall Steps per Second: 10,670.73408

Timestep Collection Time: 2.21944
Timestep Consumption Time: 2.46796
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.68740

Cumulative Model Updates: 372,004
Cumulative Timesteps: 3,102,531,606

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.22264
Policy Entropy: 3.97277
Value Function Loss: 0.00633

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.25306
Value Function Update Magnitude: 0.34258

Collected Steps per Second: 22,647.42801
Overall Steps per Second: 10,899.18351

Timestep Collection Time: 2.20846
Timestep Consumption Time: 2.38050
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.58897

Cumulative Model Updates: 372,010
Cumulative Timesteps: 3,102,581,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3102581622...
Checkpoint 3102581622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.59238
Policy Entropy: 3.98552
Value Function Loss: 0.00569

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02659
Policy Update Magnitude: 0.24569
Value Function Update Magnitude: 0.34870

Collected Steps per Second: 22,355.97823
Overall Steps per Second: 10,627.88548

Timestep Collection Time: 2.23824
Timestep Consumption Time: 2.46994
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.70818

Cumulative Model Updates: 372,016
Cumulative Timesteps: 3,102,631,660

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.92178
Policy Entropy: 3.99666
Value Function Loss: 0.00530

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02831
Policy Update Magnitude: 0.24145
Value Function Update Magnitude: 0.34180

Collected Steps per Second: 22,582.62375
Overall Steps per Second: 10,805.06713

Timestep Collection Time: 2.21533
Timestep Consumption Time: 2.41472
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.63005

Cumulative Model Updates: 372,022
Cumulative Timesteps: 3,102,681,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3102681688...
Checkpoint 3102681688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.76363
Policy Entropy: 3.98556
Value Function Loss: 0.00549

Mean KL Divergence: 0.00341
SB3 Clip Fraction: 0.02685
Policy Update Magnitude: 0.23713
Value Function Update Magnitude: 0.32002

Collected Steps per Second: 22,904.93645
Overall Steps per Second: 10,725.54841

Timestep Collection Time: 2.18320
Timestep Consumption Time: 2.47913
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.66233

Cumulative Model Updates: 372,028
Cumulative Timesteps: 3,102,731,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.96786
Policy Entropy: 3.97280
Value Function Loss: 0.00589

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02956
Policy Update Magnitude: 0.24306
Value Function Update Magnitude: 0.31171

Collected Steps per Second: 22,872.10513
Overall Steps per Second: 10,792.08124

Timestep Collection Time: 2.18668
Timestep Consumption Time: 2.44764
PPO Batch Consumption Time: 0.27987
Total Iteration Time: 4.63432

Cumulative Model Updates: 372,034
Cumulative Timesteps: 3,102,781,708

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3102781708...
Checkpoint 3102781708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.37771
Policy Entropy: 3.96632
Value Function Loss: 0.00653

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.02734
Policy Update Magnitude: 0.24563
Value Function Update Magnitude: 0.32605

Collected Steps per Second: 22,155.13252
Overall Steps per Second: 10,759.91542

Timestep Collection Time: 2.25781
Timestep Consumption Time: 2.39111
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.64892

Cumulative Model Updates: 372,040
Cumulative Timesteps: 3,102,831,730

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.56861
Policy Entropy: 3.94953
Value Function Loss: 0.00702

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02710
Policy Update Magnitude: 0.25222
Value Function Update Magnitude: 0.34077

Collected Steps per Second: 22,884.30237
Overall Steps per Second: 10,670.77551

Timestep Collection Time: 2.18569
Timestep Consumption Time: 2.50169
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.68738

Cumulative Model Updates: 372,046
Cumulative Timesteps: 3,102,881,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3102881748...
Checkpoint 3102881748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.54599
Policy Entropy: 3.95095
Value Function Loss: 0.00662

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02611
Policy Update Magnitude: 0.25082
Value Function Update Magnitude: 0.34786

Collected Steps per Second: 22,313.14381
Overall Steps per Second: 10,500.10442

Timestep Collection Time: 2.24191
Timestep Consumption Time: 2.52224
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.76414

Cumulative Model Updates: 372,052
Cumulative Timesteps: 3,102,931,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.90687
Policy Entropy: 3.97437
Value Function Loss: 0.00551

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02417
Policy Update Magnitude: 0.24242
Value Function Update Magnitude: 0.33503

Collected Steps per Second: 22,164.91916
Overall Steps per Second: 10,802.70254

Timestep Collection Time: 2.25600
Timestep Consumption Time: 2.37284
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.62884

Cumulative Model Updates: 372,058
Cumulative Timesteps: 3,102,981,776

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3102981776...
Checkpoint 3102981776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.02200
Policy Entropy: 3.98125
Value Function Loss: 0.00554

Mean KL Divergence: 0.00267
SB3 Clip Fraction: 0.02074
Policy Update Magnitude: 0.23236
Value Function Update Magnitude: 0.30924

Collected Steps per Second: 22,351.45874
Overall Steps per Second: 10,673.96234

Timestep Collection Time: 2.23726
Timestep Consumption Time: 2.44760
PPO Batch Consumption Time: 0.27978
Total Iteration Time: 4.68486

Cumulative Model Updates: 372,064
Cumulative Timesteps: 3,103,031,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.72517
Policy Entropy: 3.97330
Value Function Loss: 0.00559

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02010
Policy Update Magnitude: 0.23696
Value Function Update Magnitude: 0.31464

Collected Steps per Second: 22,556.28821
Overall Steps per Second: 10,662.33498

Timestep Collection Time: 2.21685
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.68978

Cumulative Model Updates: 372,070
Cumulative Timesteps: 3,103,081,786

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3103081786...
Checkpoint 3103081786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.59400
Policy Entropy: 3.96287
Value Function Loss: 0.00535

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02683
Policy Update Magnitude: 0.23491
Value Function Update Magnitude: 0.32570

Collected Steps per Second: 22,437.72186
Overall Steps per Second: 10,848.78193

Timestep Collection Time: 2.22884
Timestep Consumption Time: 2.38090
PPO Batch Consumption Time: 0.28094
Total Iteration Time: 4.60973

Cumulative Model Updates: 372,076
Cumulative Timesteps: 3,103,131,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.12475
Policy Entropy: 3.98768
Value Function Loss: 0.00507

Mean KL Divergence: 0.00313
SB3 Clip Fraction: 0.02484
Policy Update Magnitude: 0.23752
Value Function Update Magnitude: 0.30788

Collected Steps per Second: 22,579.99893
Overall Steps per Second: 10,553.36360

Timestep Collection Time: 2.21532
Timestep Consumption Time: 2.52459
PPO Batch Consumption Time: 0.29332
Total Iteration Time: 4.73991

Cumulative Model Updates: 372,082
Cumulative Timesteps: 3,103,181,818

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3103181818...
Checkpoint 3103181818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.44715
Policy Entropy: 4.03364
Value Function Loss: 0.00470

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02444
Policy Update Magnitude: 0.23195
Value Function Update Magnitude: 0.28934

Collected Steps per Second: 22,011.40874
Overall Steps per Second: 10,678.08463

Timestep Collection Time: 2.27273
Timestep Consumption Time: 2.41219
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.68492

Cumulative Model Updates: 372,088
Cumulative Timesteps: 3,103,231,844

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.60502
Policy Entropy: 4.02468
Value Function Loss: 0.00532

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02756
Policy Update Magnitude: 0.23770
Value Function Update Magnitude: 0.29350

Collected Steps per Second: 23,420.91397
Overall Steps per Second: 10,815.57457

Timestep Collection Time: 2.13484
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.62296

Cumulative Model Updates: 372,094
Cumulative Timesteps: 3,103,281,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3103281844...
Checkpoint 3103281844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.47260
Policy Entropy: 4.00047
Value Function Loss: 0.00659

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.03171
Policy Update Magnitude: 0.25948
Value Function Update Magnitude: 0.31432

Collected Steps per Second: 22,080.69927
Overall Steps per Second: 10,615.21648

Timestep Collection Time: 2.26614
Timestep Consumption Time: 2.44766
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.71380

Cumulative Model Updates: 372,100
Cumulative Timesteps: 3,103,331,882

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.91741
Policy Entropy: 3.93345
Value Function Loss: 0.00756

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.03414
Policy Update Magnitude: 0.27525
Value Function Update Magnitude: 0.35496

Collected Steps per Second: 22,260.77072
Overall Steps per Second: 10,537.02124

Timestep Collection Time: 2.24646
Timestep Consumption Time: 2.49947
PPO Batch Consumption Time: 0.29360
Total Iteration Time: 4.74593

Cumulative Model Updates: 372,106
Cumulative Timesteps: 3,103,381,890

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3103381890...
Checkpoint 3103381890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.88860
Policy Entropy: 3.92072
Value Function Loss: 0.00727

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.03826
Policy Update Magnitude: 0.27256
Value Function Update Magnitude: 0.37094

Collected Steps per Second: 23,088.59058
Overall Steps per Second: 10,702.42094

Timestep Collection Time: 2.16644
Timestep Consumption Time: 2.50727
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 4.67371

Cumulative Model Updates: 372,112
Cumulative Timesteps: 3,103,431,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.94426
Policy Entropy: 3.89071
Value Function Loss: 0.00726

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.03495
Policy Update Magnitude: 0.26833
Value Function Update Magnitude: 0.35372

Collected Steps per Second: 22,539.09736
Overall Steps per Second: 10,569.07183

Timestep Collection Time: 2.21925
Timestep Consumption Time: 2.51342
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.73268

Cumulative Model Updates: 372,118
Cumulative Timesteps: 3,103,481,930

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3103481930...
Checkpoint 3103481930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2.63376
Policy Entropy: 3.91110
Value Function Loss: 0.00769

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.03609
Policy Update Magnitude: 0.27430
Value Function Update Magnitude: 0.35119

Collected Steps per Second: 22,209.98204
Overall Steps per Second: 10,851.35743

Timestep Collection Time: 2.25160
Timestep Consumption Time: 2.35686
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.60846

Cumulative Model Updates: 372,124
Cumulative Timesteps: 3,103,531,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.05807
Policy Entropy: 3.92519
Value Function Loss: 0.00698

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.03451
Policy Update Magnitude: 0.26752
Value Function Update Magnitude: 0.34942

Collected Steps per Second: 22,547.96005
Overall Steps per Second: 10,567.34344

Timestep Collection Time: 2.21856
Timestep Consumption Time: 2.51527
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.73383

Cumulative Model Updates: 372,130
Cumulative Timesteps: 3,103,581,962

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3103581962...
Checkpoint 3103581962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.78117
Policy Entropy: 3.99511
Value Function Loss: 0.00577

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.24849
Value Function Update Magnitude: 0.32895

Collected Steps per Second: 22,063.11816
Overall Steps per Second: 10,590.34402

Timestep Collection Time: 2.26668
Timestep Consumption Time: 2.45555
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.72223

Cumulative Model Updates: 372,136
Cumulative Timesteps: 3,103,631,972

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43.21642
Policy Entropy: 4.01798
Value Function Loss: 0.00507

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02495
Policy Update Magnitude: 0.23450
Value Function Update Magnitude: 0.30377

Collected Steps per Second: 23,449.74467
Overall Steps per Second: 10,906.54417

Timestep Collection Time: 2.13282
Timestep Consumption Time: 2.45287
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.58569

Cumulative Model Updates: 372,142
Cumulative Timesteps: 3,103,681,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3103681986...
Checkpoint 3103681986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.14041
Policy Entropy: 3.99967
Value Function Loss: 0.00494

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02134
Policy Update Magnitude: 0.22654
Value Function Update Magnitude: 0.30321

Collected Steps per Second: 22,162.75625
Overall Steps per Second: 10,632.59836

Timestep Collection Time: 2.25694
Timestep Consumption Time: 2.44746
PPO Batch Consumption Time: 0.28006
Total Iteration Time: 4.70440

Cumulative Model Updates: 372,148
Cumulative Timesteps: 3,103,732,006

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.79999
Policy Entropy: 3.97701
Value Function Loss: 0.00549

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02173
Policy Update Magnitude: 0.23022
Value Function Update Magnitude: 0.31360

Collected Steps per Second: 22,445.07520
Overall Steps per Second: 10,869.70697

Timestep Collection Time: 2.22811
Timestep Consumption Time: 2.37275
PPO Batch Consumption Time: 0.28049
Total Iteration Time: 4.60086

Cumulative Model Updates: 372,154
Cumulative Timesteps: 3,103,782,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3103782016...
Checkpoint 3103782016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.48058
Policy Entropy: 3.98382
Value Function Loss: 0.00559

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.02151
Policy Update Magnitude: 0.23465
Value Function Update Magnitude: 0.33675

Collected Steps per Second: 22,426.53594
Overall Steps per Second: 10,731.85706

Timestep Collection Time: 2.22950
Timestep Consumption Time: 2.42952
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.65903

Cumulative Model Updates: 372,160
Cumulative Timesteps: 3,103,832,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.29183
Policy Entropy: 3.98773
Value Function Loss: 0.00651

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.25670
Value Function Update Magnitude: 0.34847

Collected Steps per Second: 22,448.74461
Overall Steps per Second: 10,545.85190

Timestep Collection Time: 2.22774
Timestep Consumption Time: 2.51441
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.74215

Cumulative Model Updates: 372,166
Cumulative Timesteps: 3,103,882,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3103882026...
Checkpoint 3103882026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.12318
Policy Entropy: 3.96644
Value Function Loss: 0.00711

Mean KL Divergence: 0.00403
SB3 Clip Fraction: 0.02951
Policy Update Magnitude: 0.26532
Value Function Update Magnitude: 0.34957

Collected Steps per Second: 22,250.82738
Overall Steps per Second: 10,718.22153

Timestep Collection Time: 2.24855
Timestep Consumption Time: 2.41939
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.66794

Cumulative Model Updates: 372,172
Cumulative Timesteps: 3,103,932,058

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.03935
Policy Entropy: 3.92644
Value Function Loss: 0.00724

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.03081
Policy Update Magnitude: 0.26403
Value Function Update Magnitude: 0.36017

Collected Steps per Second: 22,581.35623
Overall Steps per Second: 10,698.44695

Timestep Collection Time: 2.21475
Timestep Consumption Time: 2.45995
PPO Batch Consumption Time: 0.27969
Total Iteration Time: 4.67470

Cumulative Model Updates: 372,178
Cumulative Timesteps: 3,103,982,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3103982070...
Checkpoint 3103982070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.28982
Policy Entropy: 3.95281
Value Function Loss: 0.00675

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03044
Policy Update Magnitude: 0.25760
Value Function Update Magnitude: 0.36889

Collected Steps per Second: 22,290.97819
Overall Steps per Second: 10,660.24767

Timestep Collection Time: 2.24414
Timestep Consumption Time: 2.44844
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.69257

Cumulative Model Updates: 372,184
Cumulative Timesteps: 3,104,032,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.32810
Policy Entropy: 3.98029
Value Function Loss: 0.00617

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 0.25242
Value Function Update Magnitude: 0.35572

Collected Steps per Second: 22,609.40410
Overall Steps per Second: 10,923.59655

Timestep Collection Time: 2.21182
Timestep Consumption Time: 2.36616
PPO Batch Consumption Time: 0.27902
Total Iteration Time: 4.57798

Cumulative Model Updates: 372,190
Cumulative Timesteps: 3,104,082,102

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3104082102...
Checkpoint 3104082102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.45022
Policy Entropy: 4.02103
Value Function Loss: 0.00623

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02855
Policy Update Magnitude: 0.24947
Value Function Update Magnitude: 0.33926

Collected Steps per Second: 22,316.17614
Overall Steps per Second: 10,613.08184

Timestep Collection Time: 2.24089
Timestep Consumption Time: 2.47104
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.71192

Cumulative Model Updates: 372,196
Cumulative Timesteps: 3,104,132,110

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.41052
Policy Entropy: 4.02433
Value Function Loss: 0.00591

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.02910
Policy Update Magnitude: 0.24712
Value Function Update Magnitude: 0.33721

Collected Steps per Second: 22,568.69475
Overall Steps per Second: 10,661.90637

Timestep Collection Time: 2.21688
Timestep Consumption Time: 2.47572
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.69259

Cumulative Model Updates: 372,202
Cumulative Timesteps: 3,104,182,142

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3104182142...
Checkpoint 3104182142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.08430
Policy Entropy: 4.03381
Value Function Loss: 0.00503

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.02835
Policy Update Magnitude: 0.23093
Value Function Update Magnitude: 0.30962

Collected Steps per Second: 23,107.01987
Overall Steps per Second: 10,854.58449

Timestep Collection Time: 2.16402
Timestep Consumption Time: 2.44270
PPO Batch Consumption Time: 0.28024
Total Iteration Time: 4.60672

Cumulative Model Updates: 372,208
Cumulative Timesteps: 3,104,232,146

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.01273
Policy Entropy: 4.03038
Value Function Loss: 0.00544

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.23139
Value Function Update Magnitude: 0.29249

Collected Steps per Second: 22,222.95099
Overall Steps per Second: 10,464.05828

Timestep Collection Time: 2.25038
Timestep Consumption Time: 2.52884
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.77922

Cumulative Model Updates: 372,214
Cumulative Timesteps: 3,104,282,156

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3104282156...
Checkpoint 3104282156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.11874
Policy Entropy: 4.01768
Value Function Loss: 0.00535

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01971
Policy Update Magnitude: 0.23339
Value Function Update Magnitude: 0.31545

Collected Steps per Second: 22,190.07499
Overall Steps per Second: 10,668.02636

Timestep Collection Time: 2.25497
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.69046

Cumulative Model Updates: 372,220
Cumulative Timesteps: 3,104,332,194

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.61947
Policy Entropy: 4.00995
Value Function Loss: 0.00562

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02222
Policy Update Magnitude: 0.23734
Value Function Update Magnitude: 0.31346

Collected Steps per Second: 22,371.32064
Overall Steps per Second: 10,513.36807

Timestep Collection Time: 2.23670
Timestep Consumption Time: 2.52276
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.75946

Cumulative Model Updates: 372,226
Cumulative Timesteps: 3,104,382,232

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3104382232...
Checkpoint 3104382232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.31256
Policy Entropy: 3.99104
Value Function Loss: 0.00568

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02320
Policy Update Magnitude: 0.23541
Value Function Update Magnitude: 0.31170

Collected Steps per Second: 22,265.33413
Overall Steps per Second: 10,589.58830

Timestep Collection Time: 2.24609
Timestep Consumption Time: 2.47647
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.72256

Cumulative Model Updates: 372,232
Cumulative Timesteps: 3,104,432,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.07065
Policy Entropy: 4.00293
Value Function Loss: 0.00591

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.01949
Policy Update Magnitude: 0.23521
Value Function Update Magnitude: 0.32212

Collected Steps per Second: 22,594.90161
Overall Steps per Second: 10,892.04081

Timestep Collection Time: 2.21351
Timestep Consumption Time: 2.37829
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.59179

Cumulative Model Updates: 372,238
Cumulative Timesteps: 3,104,482,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3104482256...
Checkpoint 3104482256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.18211
Policy Entropy: 3.99623
Value Function Loss: 0.00626

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02191
Policy Update Magnitude: 0.23358
Value Function Update Magnitude: 0.33030

Collected Steps per Second: 22,389.14936
Overall Steps per Second: 10,698.68501

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.44113
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.67515

Cumulative Model Updates: 372,244
Cumulative Timesteps: 3,104,532,274

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.30134
Policy Entropy: 4.00138
Value Function Loss: 0.00626

Mean KL Divergence: 0.00285
SB3 Clip Fraction: 0.02053
Policy Update Magnitude: 0.23443
Value Function Update Magnitude: 0.33187

Collected Steps per Second: 22,668.99404
Overall Steps per Second: 10,783.05515

Timestep Collection Time: 2.20707
Timestep Consumption Time: 2.43280
PPO Batch Consumption Time: 0.28033
Total Iteration Time: 4.63987

Cumulative Model Updates: 372,250
Cumulative Timesteps: 3,104,582,306

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3104582306...
Checkpoint 3104582306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.92446
Policy Entropy: 3.99719
Value Function Loss: 0.00585

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02478
Policy Update Magnitude: 0.23844
Value Function Update Magnitude: 0.31715

Collected Steps per Second: 21,965.01179
Overall Steps per Second: 10,785.37046

Timestep Collection Time: 2.27717
Timestep Consumption Time: 2.36041
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.63758

Cumulative Model Updates: 372,256
Cumulative Timesteps: 3,104,632,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.42314
Policy Entropy: 4.00051
Value Function Loss: 0.00580

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02354
Policy Update Magnitude: 0.24377
Value Function Update Magnitude: 0.31089

Collected Steps per Second: 22,831.30246
Overall Steps per Second: 10,758.66763

Timestep Collection Time: 2.19050
Timestep Consumption Time: 2.45803
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.64853

Cumulative Model Updates: 372,262
Cumulative Timesteps: 3,104,682,336

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3104682336...
Checkpoint 3104682336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.53079
Policy Entropy: 4.03773
Value Function Loss: 0.00536

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02084
Policy Update Magnitude: 0.23975
Value Function Update Magnitude: 0.31728

Collected Steps per Second: 22,036.86045
Overall Steps per Second: 10,654.83831

Timestep Collection Time: 2.27029
Timestep Consumption Time: 2.42523
PPO Batch Consumption Time: 0.28073
Total Iteration Time: 4.69552

Cumulative Model Updates: 372,268
Cumulative Timesteps: 3,104,732,366

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.54656
Policy Entropy: 3.97820
Value Function Loss: 0.00621

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02235
Policy Update Magnitude: 0.23782
Value Function Update Magnitude: 0.31858

Collected Steps per Second: 22,352.75359
Overall Steps per Second: 10,751.23265

Timestep Collection Time: 2.23713
Timestep Consumption Time: 2.41406
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.65119

Cumulative Model Updates: 372,274
Cumulative Timesteps: 3,104,782,372

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3104782372...
Checkpoint 3104782372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.18137
Policy Entropy: 3.97828
Value Function Loss: 0.00638

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.02858
Policy Update Magnitude: 0.24701
Value Function Update Magnitude: 0.32876

Collected Steps per Second: 22,125.67427
Overall Steps per Second: 10,477.77107

Timestep Collection Time: 2.26027
Timestep Consumption Time: 2.51269
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.77296

Cumulative Model Updates: 372,280
Cumulative Timesteps: 3,104,832,382

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.95954
Policy Entropy: 3.95348
Value Function Loss: 0.00695

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.03522
Policy Update Magnitude: 0.25017
Value Function Update Magnitude: 0.33463

Collected Steps per Second: 22,581.18619
Overall Steps per Second: 10,767.38853

Timestep Collection Time: 2.21441
Timestep Consumption Time: 2.42961
PPO Batch Consumption Time: 0.28068
Total Iteration Time: 4.64402

Cumulative Model Updates: 372,286
Cumulative Timesteps: 3,104,882,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3104882386...
Checkpoint 3104882386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69.92308
Policy Entropy: 3.99218
Value Function Loss: 0.00629

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.03811
Policy Update Magnitude: 0.24682
Value Function Update Magnitude: 0.35190

Collected Steps per Second: 22,712.37547
Overall Steps per Second: 10,758.98924

Timestep Collection Time: 2.20144
Timestep Consumption Time: 2.44583
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.64728

Cumulative Model Updates: 372,292
Cumulative Timesteps: 3,104,932,386

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.90829
Policy Entropy: 3.98136
Value Function Loss: 0.00579

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.03364
Policy Update Magnitude: 0.24350
Value Function Update Magnitude: 0.34073

Collected Steps per Second: 22,524.27027
Overall Steps per Second: 10,561.04707

Timestep Collection Time: 2.22036
Timestep Consumption Time: 2.51515
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.73552

Cumulative Model Updates: 372,298
Cumulative Timesteps: 3,104,982,398

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3104982398...
Checkpoint 3104982398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.77174
Policy Entropy: 3.96620
Value Function Loss: 0.00609

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.23908
Value Function Update Magnitude: 0.33350

Collected Steps per Second: 22,212.39151
Overall Steps per Second: 10,520.45955

Timestep Collection Time: 2.25100
Timestep Consumption Time: 2.50165
PPO Batch Consumption Time: 0.29473
Total Iteration Time: 4.75264

Cumulative Model Updates: 372,304
Cumulative Timesteps: 3,105,032,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.70773
Policy Entropy: 3.98324
Value Function Loss: 0.00595

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02403
Policy Update Magnitude: 0.24412
Value Function Update Magnitude: 0.33021

Collected Steps per Second: 23,349.72532
Overall Steps per Second: 10,866.58648

Timestep Collection Time: 2.14212
Timestep Consumption Time: 2.46079
PPO Batch Consumption Time: 0.28085
Total Iteration Time: 4.60292

Cumulative Model Updates: 372,310
Cumulative Timesteps: 3,105,082,416

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3105082416...
Checkpoint 3105082416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50.39059
Policy Entropy: 3.99733
Value Function Loss: 0.00640

Mean KL Divergence: 0.00312
SB3 Clip Fraction: 0.02352
Policy Update Magnitude: 0.25114
Value Function Update Magnitude: 0.33406

Collected Steps per Second: 22,180.83318
Overall Steps per Second: 10,637.81519

Timestep Collection Time: 2.25465
Timestep Consumption Time: 2.44650
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.70115

Cumulative Model Updates: 372,316
Cumulative Timesteps: 3,105,132,426

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.81262
Policy Entropy: 4.01393
Value Function Loss: 0.00643

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02562
Policy Update Magnitude: 0.24801
Value Function Update Magnitude: 0.33836

Collected Steps per Second: 22,817.63745
Overall Steps per Second: 10,752.91679

Timestep Collection Time: 2.19208
Timestep Consumption Time: 2.45950
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.65158

Cumulative Model Updates: 372,322
Cumulative Timesteps: 3,105,182,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3105182444...
Checkpoint 3105182444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.10558
Policy Entropy: 4.00100
Value Function Loss: 0.00687

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.24912
Value Function Update Magnitude: 0.32496

Collected Steps per Second: 23,090.88596
Overall Steps per Second: 10,851.52560

Timestep Collection Time: 2.16596
Timestep Consumption Time: 2.44297
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.60894

Cumulative Model Updates: 372,328
Cumulative Timesteps: 3,105,232,458

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.04017
Policy Entropy: 3.96754
Value Function Loss: 0.00779

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.03254
Policy Update Magnitude: 0.25678
Value Function Update Magnitude: 0.32641

Collected Steps per Second: 23,024.35517
Overall Steps per Second: 10,836.88347

Timestep Collection Time: 2.17205
Timestep Consumption Time: 2.44275
PPO Batch Consumption Time: 0.27940
Total Iteration Time: 4.61480

Cumulative Model Updates: 372,334
Cumulative Timesteps: 3,105,282,468

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3105282468...
Checkpoint 3105282468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.94871
Policy Entropy: 3.97575
Value Function Loss: 0.00685

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.03762
Policy Update Magnitude: 0.26162
Value Function Update Magnitude: 0.32828

Collected Steps per Second: 22,302.54361
Overall Steps per Second: 10,701.67381

Timestep Collection Time: 2.24208
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.67254

Cumulative Model Updates: 372,340
Cumulative Timesteps: 3,105,332,472

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.27392
Policy Entropy: 3.96281
Value Function Loss: 0.00647

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.03633
Policy Update Magnitude: 0.25270
Value Function Update Magnitude: 0.32035

Collected Steps per Second: 22,892.21209
Overall Steps per Second: 10,844.33411

Timestep Collection Time: 2.18494
Timestep Consumption Time: 2.42743
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.61236

Cumulative Model Updates: 372,346
Cumulative Timesteps: 3,105,382,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3105382490...
Checkpoint 3105382490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.46231
Policy Entropy: 3.93986
Value Function Loss: 0.00640

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.03557
Policy Update Magnitude: 0.25872
Value Function Update Magnitude: 0.32301

Collected Steps per Second: 22,103.93615
Overall Steps per Second: 10,704.97343

Timestep Collection Time: 2.26231
Timestep Consumption Time: 2.40897
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.67129

Cumulative Model Updates: 372,352
Cumulative Timesteps: 3,105,432,496

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.97846
Policy Entropy: 3.93592
Value Function Loss: 0.00652

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.03533
Policy Update Magnitude: 0.25268
Value Function Update Magnitude: 0.33452

Collected Steps per Second: 23,355.39884
Overall Steps per Second: 10,916.83665

Timestep Collection Time: 2.14203
Timestep Consumption Time: 2.44061
PPO Batch Consumption Time: 0.27993
Total Iteration Time: 4.58265

Cumulative Model Updates: 372,358
Cumulative Timesteps: 3,105,482,524

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3105482524...
Checkpoint 3105482524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.02350
Policy Entropy: 3.95531
Value Function Loss: 0.00605

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.24849
Value Function Update Magnitude: 0.33810

Collected Steps per Second: 22,320.82892
Overall Steps per Second: 10,640.18798

Timestep Collection Time: 2.24087
Timestep Consumption Time: 2.45999
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.70086

Cumulative Model Updates: 372,364
Cumulative Timesteps: 3,105,532,542

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.09545
Policy Entropy: 3.99158
Value Function Loss: 0.00614

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.24456
Value Function Update Magnitude: 0.33463

Collected Steps per Second: 22,607.98646
Overall Steps per Second: 10,699.97782

Timestep Collection Time: 2.21170
Timestep Consumption Time: 2.46140
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.67309

Cumulative Model Updates: 372,370
Cumulative Timesteps: 3,105,582,544

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3105582544...
Checkpoint 3105582544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.66847
Policy Entropy: 3.95829
Value Function Loss: 0.00735

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02860
Policy Update Magnitude: 0.25606
Value Function Update Magnitude: 0.33446

Collected Steps per Second: 22,950.05253
Overall Steps per Second: 10,902.98175

Timestep Collection Time: 2.17969
Timestep Consumption Time: 2.40841
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.58810

Cumulative Model Updates: 372,376
Cumulative Timesteps: 3,105,632,568

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.36695
Policy Entropy: 3.94819
Value Function Loss: 0.00768

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02754
Policy Update Magnitude: 0.26122
Value Function Update Magnitude: 0.34318

Collected Steps per Second: 22,607.73660
Overall Steps per Second: 10,655.61360

Timestep Collection Time: 2.21234
Timestep Consumption Time: 2.48152
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.69386

Cumulative Model Updates: 372,382
Cumulative Timesteps: 3,105,682,584

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3105682584...
Checkpoint 3105682584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.29386
Policy Entropy: 3.95073
Value Function Loss: 0.00725

Mean KL Divergence: 0.00393
SB3 Clip Fraction: 0.03014
Policy Update Magnitude: 0.25588
Value Function Update Magnitude: 0.34392

Collected Steps per Second: 22,255.62306
Overall Steps per Second: 10,655.59821

Timestep Collection Time: 2.24698
Timestep Consumption Time: 2.44614
PPO Batch Consumption Time: 0.28648
Total Iteration Time: 4.69312

Cumulative Model Updates: 372,388
Cumulative Timesteps: 3,105,732,592

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.53105
Policy Entropy: 3.96764
Value Function Loss: 0.00684

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.25795
Value Function Update Magnitude: 0.33797

Collected Steps per Second: 23,054.96605
Overall Steps per Second: 10,738.78858

Timestep Collection Time: 2.16882
Timestep Consumption Time: 2.48739
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.65620

Cumulative Model Updates: 372,394
Cumulative Timesteps: 3,105,782,594

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3105782594...
Checkpoint 3105782594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.75354
Policy Entropy: 3.97889
Value Function Loss: 0.00535

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.02884
Policy Update Magnitude: 0.25099
Value Function Update Magnitude: 0.32914

Collected Steps per Second: 22,081.16528
Overall Steps per Second: 10,579.36204

Timestep Collection Time: 2.26455
Timestep Consumption Time: 2.46201
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.72656

Cumulative Model Updates: 372,400
Cumulative Timesteps: 3,105,832,598

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.52607
Policy Entropy: 3.97121
Value Function Loss: 0.00532

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02810
Policy Update Magnitude: 0.24652
Value Function Update Magnitude: 0.31358

Collected Steps per Second: 22,542.31451
Overall Steps per Second: 10,799.63542

Timestep Collection Time: 2.21823
Timestep Consumption Time: 2.41193
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.63016

Cumulative Model Updates: 372,406
Cumulative Timesteps: 3,105,882,602

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3105882602...
Checkpoint 3105882602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.75233
Policy Entropy: 3.97849
Value Function Loss: 0.00496

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02539
Policy Update Magnitude: 0.23633
Value Function Update Magnitude: 0.29236

Collected Steps per Second: 23,414.57059
Overall Steps per Second: 10,715.23899

Timestep Collection Time: 2.13662
Timestep Consumption Time: 2.53225
PPO Batch Consumption Time: 0.29465
Total Iteration Time: 4.66886

Cumulative Model Updates: 372,412
Cumulative Timesteps: 3,105,932,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.32167
Policy Entropy: 3.96001
Value Function Loss: 0.00609

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02453
Policy Update Magnitude: 0.23966
Value Function Update Magnitude: 0.29779

Collected Steps per Second: 22,645.66428
Overall Steps per Second: 10,570.23416

Timestep Collection Time: 2.20810
Timestep Consumption Time: 2.52254
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.73064

Cumulative Model Updates: 372,418
Cumulative Timesteps: 3,105,982,634

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3105982634...
Checkpoint 3105982634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.06491
Policy Entropy: 3.98443
Value Function Loss: 0.00574

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02241
Policy Update Magnitude: 0.24223
Value Function Update Magnitude: 0.31689

Collected Steps per Second: 22,401.44714
Overall Steps per Second: 10,791.52104

Timestep Collection Time: 2.23271
Timestep Consumption Time: 2.40204
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.63475

Cumulative Model Updates: 372,424
Cumulative Timesteps: 3,106,032,650

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.73975
Policy Entropy: 3.98913
Value Function Loss: 0.00586

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.24226
Value Function Update Magnitude: 0.30930

Collected Steps per Second: 22,631.18785
Overall Steps per Second: 10,656.18289

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.48317
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.69286

Cumulative Model Updates: 372,430
Cumulative Timesteps: 3,106,082,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3106082658...
Checkpoint 3106082658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.43337
Policy Entropy: 4.01082
Value Function Loss: 0.00542

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.23863
Value Function Update Magnitude: 0.31780

Collected Steps per Second: 22,024.99185
Overall Steps per Second: 10,607.03083

Timestep Collection Time: 2.27015
Timestep Consumption Time: 2.44371
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.71385

Cumulative Model Updates: 372,436
Cumulative Timesteps: 3,106,132,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.67295
Policy Entropy: 3.98832
Value Function Loss: 0.00585

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.24210
Value Function Update Magnitude: 0.33536

Collected Steps per Second: 22,593.41211
Overall Steps per Second: 10,894.18124

Timestep Collection Time: 2.21436
Timestep Consumption Time: 2.37800
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.59236

Cumulative Model Updates: 372,442
Cumulative Timesteps: 3,106,182,688

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3106182688...
Checkpoint 3106182688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.31830
Policy Entropy: 3.99959
Value Function Loss: 0.00562

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02553
Policy Update Magnitude: 0.24848
Value Function Update Magnitude: 0.33366

Collected Steps per Second: 22,444.44314
Overall Steps per Second: 10,729.99119

Timestep Collection Time: 2.22870
Timestep Consumption Time: 2.43318
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.66189

Cumulative Model Updates: 372,448
Cumulative Timesteps: 3,106,232,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.55423
Policy Entropy: 3.98232
Value Function Loss: 0.00638

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02547
Policy Update Magnitude: 0.24543
Value Function Update Magnitude: 0.32496

Collected Steps per Second: 22,687.65008
Overall Steps per Second: 10,791.33291

Timestep Collection Time: 2.20455
Timestep Consumption Time: 2.43028
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.63483

Cumulative Model Updates: 372,454
Cumulative Timesteps: 3,106,282,726

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3106282726...
Checkpoint 3106282726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.28601
Policy Entropy: 3.98101
Value Function Loss: 0.00593

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02112
Policy Update Magnitude: 0.25419
Value Function Update Magnitude: 0.32882

Collected Steps per Second: 22,749.33057
Overall Steps per Second: 10,694.88224

Timestep Collection Time: 2.19804
Timestep Consumption Time: 2.47746
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.67551

Cumulative Model Updates: 372,460
Cumulative Timesteps: 3,106,332,730

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.18992
Policy Entropy: 3.94310
Value Function Loss: 0.00717

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02813
Policy Update Magnitude: 0.25541
Value Function Update Magnitude: 0.34588

Collected Steps per Second: 22,469.05069
Overall Steps per Second: 10,529.25775

Timestep Collection Time: 2.22564
Timestep Consumption Time: 2.52379
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.74943

Cumulative Model Updates: 372,466
Cumulative Timesteps: 3,106,382,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3106382738...
Checkpoint 3106382738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.88082
Policy Entropy: 3.95794
Value Function Loss: 0.00708

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.03014
Policy Update Magnitude: 0.26562
Value Function Update Magnitude: 0.36031

Collected Steps per Second: 22,261.99221
Overall Steps per Second: 10,695.39899

Timestep Collection Time: 2.24625
Timestep Consumption Time: 2.42922
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.67547

Cumulative Model Updates: 372,472
Cumulative Timesteps: 3,106,432,744

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.62285
Policy Entropy: 3.96884
Value Function Loss: 0.00738

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.03041
Policy Update Magnitude: 0.26837
Value Function Update Magnitude: 0.36463

Collected Steps per Second: 22,896.07938
Overall Steps per Second: 10,801.13842

Timestep Collection Time: 2.18448
Timestep Consumption Time: 2.44614
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.63062

Cumulative Model Updates: 372,478
Cumulative Timesteps: 3,106,482,760

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3106482760...
Checkpoint 3106482760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.70805
Policy Entropy: 3.95669
Value Function Loss: 0.00724

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.03357
Policy Update Magnitude: 0.26376
Value Function Update Magnitude: 0.35564

Collected Steps per Second: 22,126.70409
Overall Steps per Second: 10,635.11613

Timestep Collection Time: 2.26098
Timestep Consumption Time: 2.44306
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.70404

Cumulative Model Updates: 372,484
Cumulative Timesteps: 3,106,532,788

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.14923
Policy Entropy: 3.95728
Value Function Loss: 0.00760

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.03234
Policy Update Magnitude: 0.26893
Value Function Update Magnitude: 0.34271

Collected Steps per Second: 23,165.27690
Overall Steps per Second: 10,930.44512

Timestep Collection Time: 2.15849
Timestep Consumption Time: 2.41607
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.57456

Cumulative Model Updates: 372,490
Cumulative Timesteps: 3,106,582,790

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3106582790...
Checkpoint 3106582790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.46941
Policy Entropy: 3.91640
Value Function Loss: 0.00809

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.03880
Policy Update Magnitude: 0.26579
Value Function Update Magnitude: 0.35478

Collected Steps per Second: 22,403.08401
Overall Steps per Second: 10,682.47506

Timestep Collection Time: 2.23210
Timestep Consumption Time: 2.44902
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.68112

Cumulative Model Updates: 372,496
Cumulative Timesteps: 3,106,632,796

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.66436
Policy Entropy: 3.93391
Value Function Loss: 0.00749

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.04805
Policy Update Magnitude: 0.31036
Value Function Update Magnitude: 0.37013

Collected Steps per Second: 22,793.68985
Overall Steps per Second: 10,820.68894

Timestep Collection Time: 2.19368
Timestep Consumption Time: 2.42729
PPO Batch Consumption Time: 0.28181
Total Iteration Time: 4.62096

Cumulative Model Updates: 372,502
Cumulative Timesteps: 3,106,682,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3106682798...
Checkpoint 3106682798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.08577
Policy Entropy: 3.90579
Value Function Loss: 0.00764

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.05211
Policy Update Magnitude: 0.27204
Value Function Update Magnitude: 0.36687

Collected Steps per Second: 22,826.54653
Overall Steps per Second: 10,675.73320

Timestep Collection Time: 2.19201
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.68689

Cumulative Model Updates: 372,508
Cumulative Timesteps: 3,106,732,834

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.20087
Policy Entropy: 3.94413
Value Function Loss: 0.00711

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.03896
Policy Update Magnitude: 0.26727
Value Function Update Magnitude: 0.35299

Collected Steps per Second: 22,424.92110
Overall Steps per Second: 10,513.55352

Timestep Collection Time: 2.23064
Timestep Consumption Time: 2.52722
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.75786

Cumulative Model Updates: 372,514
Cumulative Timesteps: 3,106,782,856

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3106782856...
Checkpoint 3106782856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.39227
Policy Entropy: 3.92139
Value Function Loss: 0.00805

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.02902
Policy Update Magnitude: 0.26765
Value Function Update Magnitude: 0.35753

Collected Steps per Second: 22,136.14900
Overall Steps per Second: 10,642.82900

Timestep Collection Time: 2.25965
Timestep Consumption Time: 2.44023
PPO Batch Consumption Time: 0.28246
Total Iteration Time: 4.69988

Cumulative Model Updates: 372,520
Cumulative Timesteps: 3,106,832,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.79639
Policy Entropy: 3.98783
Value Function Loss: 0.00620

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.02901
Policy Update Magnitude: 0.26372
Value Function Update Magnitude: 0.36663

Collected Steps per Second: 23,787.63954
Overall Steps per Second: 10,884.36168

Timestep Collection Time: 2.10218
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.59430

Cumulative Model Updates: 372,526
Cumulative Timesteps: 3,106,882,882

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3106882882...
Checkpoint 3106882882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.52936
Policy Entropy: 3.96993
Value Function Loss: 0.00633

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02599
Policy Update Magnitude: 0.25420
Value Function Update Magnitude: 0.34965

Collected Steps per Second: 22,682.11935
Overall Steps per Second: 10,661.99636

Timestep Collection Time: 2.20526
Timestep Consumption Time: 2.48617
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.69143

Cumulative Model Updates: 372,532
Cumulative Timesteps: 3,106,932,902

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.62529
Policy Entropy: 3.99608
Value Function Loss: 0.00554

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.24708
Value Function Update Magnitude: 0.32782

Collected Steps per Second: 22,926.29607
Overall Steps per Second: 10,926.35939

Timestep Collection Time: 2.18143
Timestep Consumption Time: 2.39576
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.57719

Cumulative Model Updates: 372,538
Cumulative Timesteps: 3,106,982,914

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3106982914...
Checkpoint 3106982914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.53174
Policy Entropy: 3.95543
Value Function Loss: 0.00591

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02494
Policy Update Magnitude: 0.24830
Value Function Update Magnitude: 0.32354

Collected Steps per Second: 22,438.50377
Overall Steps per Second: 10,618.15146

Timestep Collection Time: 2.22867
Timestep Consumption Time: 2.48100
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.70967

Cumulative Model Updates: 372,544
Cumulative Timesteps: 3,107,032,922

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42.47682
Policy Entropy: 3.96510
Value Function Loss: 0.00547

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02557
Policy Update Magnitude: 0.24279
Value Function Update Magnitude: 0.31116

Collected Steps per Second: 22,939.12952
Overall Steps per Second: 10,901.14925

Timestep Collection Time: 2.18012
Timestep Consumption Time: 2.40747
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.58759

Cumulative Model Updates: 372,550
Cumulative Timesteps: 3,107,082,932

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3107082932...
Checkpoint 3107082932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.98780
Policy Entropy: 3.96405
Value Function Loss: 0.00617

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02682
Policy Update Magnitude: 0.23720
Value Function Update Magnitude: 0.30847

Collected Steps per Second: 22,226.61350
Overall Steps per Second: 10,700.62633

Timestep Collection Time: 2.24992
Timestep Consumption Time: 2.42346
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.67337

Cumulative Model Updates: 372,556
Cumulative Timesteps: 3,107,132,940

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.35366
Policy Entropy: 3.97508
Value Function Loss: 0.00686

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.24108
Value Function Update Magnitude: 0.33105

Collected Steps per Second: 22,803.84394
Overall Steps per Second: 10,836.85994

Timestep Collection Time: 2.19270
Timestep Consumption Time: 2.42137
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.61407

Cumulative Model Updates: 372,562
Cumulative Timesteps: 3,107,182,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3107182942...
Checkpoint 3107182942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.69314
Policy Entropy: 3.98292
Value Function Loss: 0.00695

Mean KL Divergence: 0.00350
SB3 Clip Fraction: 0.02638
Policy Update Magnitude: 0.24797
Value Function Update Magnitude: 0.33868

Collected Steps per Second: 22,268.32522
Overall Steps per Second: 10,716.07842

Timestep Collection Time: 2.24642
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.66813

Cumulative Model Updates: 372,568
Cumulative Timesteps: 3,107,232,966

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.03115
Policy Entropy: 3.98271
Value Function Loss: 0.00692

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02270
Policy Update Magnitude: 0.23810
Value Function Update Magnitude: 0.34489

Collected Steps per Second: 22,919.77593
Overall Steps per Second: 10,656.39538

Timestep Collection Time: 2.18152
Timestep Consumption Time: 2.51050
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.69202

Cumulative Model Updates: 372,574
Cumulative Timesteps: 3,107,282,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3107282966...
Checkpoint 3107282966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.84341
Policy Entropy: 3.99471
Value Function Loss: 0.00718

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02350
Policy Update Magnitude: 0.24066
Value Function Update Magnitude: 0.34816

Collected Steps per Second: 22,424.36307
Overall Steps per Second: 10,508.76958

Timestep Collection Time: 2.22999
Timestep Consumption Time: 2.52852
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.75850

Cumulative Model Updates: 372,580
Cumulative Timesteps: 3,107,332,972

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.06616
Policy Entropy: 3.99069
Value Function Loss: 0.00798

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.24749
Value Function Update Magnitude: 0.35411

Collected Steps per Second: 22,555.82845
Overall Steps per Second: 10,836.55562

Timestep Collection Time: 2.21743
Timestep Consumption Time: 2.39806
PPO Batch Consumption Time: 0.28346
Total Iteration Time: 4.61549

Cumulative Model Updates: 372,586
Cumulative Timesteps: 3,107,382,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3107382988...
Checkpoint 3107382988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.53060
Policy Entropy: 3.96244
Value Function Loss: 0.00827

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.25531
Value Function Update Magnitude: 0.37762

Collected Steps per Second: 22,389.81214
Overall Steps per Second: 10,611.77291

Timestep Collection Time: 2.23441
Timestep Consumption Time: 2.47998
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.71439

Cumulative Model Updates: 372,592
Cumulative Timesteps: 3,107,433,016

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.76729
Policy Entropy: 3.93096
Value Function Loss: 0.00816

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02818
Policy Update Magnitude: 0.26409
Value Function Update Magnitude: 0.39700

Collected Steps per Second: 22,316.45300
Overall Steps per Second: 10,550.62214

Timestep Collection Time: 2.24175
Timestep Consumption Time: 2.49996
PPO Batch Consumption Time: 0.29355
Total Iteration Time: 4.74171

Cumulative Model Updates: 372,598
Cumulative Timesteps: 3,107,483,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3107483044...
Checkpoint 3107483044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.71275
Policy Entropy: 3.95323
Value Function Loss: 0.00703

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.02709
Policy Update Magnitude: 0.26635
Value Function Update Magnitude: 0.39403

Collected Steps per Second: 22,282.17733
Overall Steps per Second: 10,707.58472

Timestep Collection Time: 2.24475
Timestep Consumption Time: 2.42651
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.67127

Cumulative Model Updates: 372,604
Cumulative Timesteps: 3,107,533,062

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.57233
Policy Entropy: 3.98596
Value Function Loss: 0.00640

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02643
Policy Update Magnitude: 0.25073
Value Function Update Magnitude: 0.36057

Collected Steps per Second: 22,704.01887
Overall Steps per Second: 10,733.66267

Timestep Collection Time: 2.20296
Timestep Consumption Time: 2.45677
PPO Batch Consumption Time: 0.28011
Total Iteration Time: 4.65973

Cumulative Model Updates: 372,610
Cumulative Timesteps: 3,107,583,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3107583078...
Checkpoint 3107583078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.35570
Policy Entropy: 4.00011
Value Function Loss: 0.00636

Mean KL Divergence: 0.00302
SB3 Clip Fraction: 0.02295
Policy Update Magnitude: 0.24023
Value Function Update Magnitude: 0.33034

Collected Steps per Second: 22,214.79054
Overall Steps per Second: 10,758.15937

Timestep Collection Time: 2.25102
Timestep Consumption Time: 2.39717
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.64819

Cumulative Model Updates: 372,616
Cumulative Timesteps: 3,107,633,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.25830
Policy Entropy: 3.97747
Value Function Loss: 0.00650

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02552
Policy Update Magnitude: 0.24032
Value Function Update Magnitude: 0.32129

Collected Steps per Second: 22,472.32386
Overall Steps per Second: 10,889.05351

Timestep Collection Time: 2.22683
Timestep Consumption Time: 2.36880
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.59562

Cumulative Model Updates: 372,622
Cumulative Timesteps: 3,107,683,126

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 3107683126...
Checkpoint 3107683126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.45567
Policy Entropy: 3.99663
Value Function Loss: 0.00573

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02492
Policy Update Magnitude: 0.24388
Value Function Update Magnitude: 0.31791

Collected Steps per Second: 22,370.15224
Overall Steps per Second: 10,586.14594

Timestep Collection Time: 2.23637
Timestep Consumption Time: 2.48943
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.72580

Cumulative Model Updates: 372,628
Cumulative Timesteps: 3,107,733,154

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.77760
Policy Entropy: 4.00990
Value Function Loss: 0.00582

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02668
Policy Update Magnitude: 0.24314
Value Function Update Magnitude: 0.30983

Collected Steps per Second: 22,546.98366
Overall Steps per Second: 10,619.59742

Timestep Collection Time: 2.21928
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.71185

Cumulative Model Updates: 372,634
Cumulative Timesteps: 3,107,783,192

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 3107783192...
Checkpoint 3107783192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.21473
Policy Entropy: 4.01002
Value Function Loss: 0.00566

Mean KL Divergence: 0.00331
SB3 Clip Fraction: 0.02512
Policy Update Magnitude: 0.24131
Value Function Update Magnitude: 0.29588

Collected Steps per Second: 23,336.20177
Overall Steps per Second: 10,913.02954

Timestep Collection Time: 2.14379
Timestep Consumption Time: 2.44045
PPO Batch Consumption Time: 0.28031
Total Iteration Time: 4.58424

Cumulative Model Updates: 372,640
Cumulative Timesteps: 3,107,833,220

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.77100
Policy Entropy: 3.99663
Value Function Loss: 0.00618

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02641
Policy Update Magnitude: 0.23595
Value Function Update Magnitude: 0.30353

Collected Steps per Second: 22,461.91679
Overall Steps per Second: 10,543.60971

Timestep Collection Time: 2.22688
Timestep Consumption Time: 2.51723
PPO Batch Consumption Time: 0.29369
Total Iteration Time: 4.74411

Cumulative Model Updates: 372,646
Cumulative Timesteps: 3,107,883,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3107883240...
Checkpoint 3107883240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.61831
Policy Entropy: 3.98590
Value Function Loss: 0.00617

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02504
Policy Update Magnitude: 0.23622
Value Function Update Magnitude: 0.30287

Collected Steps per Second: 22,099.01012
Overall Steps per Second: 10,583.47281

Timestep Collection Time: 2.26354
Timestep Consumption Time: 2.46289
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.72643

Cumulative Model Updates: 372,652
Cumulative Timesteps: 3,107,933,262

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.35399
Policy Entropy: 3.96810
Value Function Loss: 0.00697

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02960
Policy Update Magnitude: 0.24969
Value Function Update Magnitude: 0.30315

Collected Steps per Second: 23,409.65440
Overall Steps per Second: 10,902.90324

Timestep Collection Time: 2.13681
Timestep Consumption Time: 2.45114
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.58795

Cumulative Model Updates: 372,658
Cumulative Timesteps: 3,107,983,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3107983284...
Checkpoint 3107983284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.89273
Policy Entropy: 3.95977
Value Function Loss: 0.00660

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02939
Policy Update Magnitude: 0.24844
Value Function Update Magnitude: 0.32537

Collected Steps per Second: 22,220.28508
Overall Steps per Second: 10,646.33257

Timestep Collection Time: 2.25074
Timestep Consumption Time: 2.44684
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.69758

Cumulative Model Updates: 372,664
Cumulative Timesteps: 3,108,033,296

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.14917
Policy Entropy: 3.96688
Value Function Loss: 0.00664

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02672
Policy Update Magnitude: 0.24746
Value Function Update Magnitude: 0.32130

Collected Steps per Second: 22,602.32717
Overall Steps per Second: 10,896.75113

Timestep Collection Time: 2.21340
Timestep Consumption Time: 2.37769
PPO Batch Consumption Time: 0.28125
Total Iteration Time: 4.59109

Cumulative Model Updates: 372,670
Cumulative Timesteps: 3,108,083,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3108083324...
Checkpoint 3108083324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.08605
Policy Entropy: 3.98668
Value Function Loss: 0.00589

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02481
Policy Update Magnitude: 0.23793
Value Function Update Magnitude: 0.30607

Collected Steps per Second: 22,021.58018
Overall Steps per Second: 10,595.48871

Timestep Collection Time: 2.27141
Timestep Consumption Time: 2.44947
PPO Batch Consumption Time: 0.28053
Total Iteration Time: 4.72088

Cumulative Model Updates: 372,676
Cumulative Timesteps: 3,108,133,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.30896
Policy Entropy: 3.99777
Value Function Loss: 0.00610

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02265
Policy Update Magnitude: 0.23205
Value Function Update Magnitude: 0.30245

Collected Steps per Second: 22,642.09932
Overall Steps per Second: 10,640.25025

Timestep Collection Time: 2.20828
Timestep Consumption Time: 2.49086
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.69914

Cumulative Model Updates: 372,682
Cumulative Timesteps: 3,108,183,344

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3108183344...
Checkpoint 3108183344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.77346
Policy Entropy: 4.00825
Value Function Loss: 0.00580

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02139
Policy Update Magnitude: 0.22632
Value Function Update Magnitude: 0.29845

Collected Steps per Second: 21,908.79380
Overall Steps per Second: 10,586.77795

Timestep Collection Time: 2.28237
Timestep Consumption Time: 2.44088
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.72325

Cumulative Model Updates: 372,688
Cumulative Timesteps: 3,108,233,348

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.72616
Policy Entropy: 3.99698
Value Function Loss: 0.00628

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01737
Policy Update Magnitude: 0.22043
Value Function Update Magnitude: 0.30236

Collected Steps per Second: 22,755.60409
Overall Steps per Second: 10,608.51101

Timestep Collection Time: 2.19761
Timestep Consumption Time: 2.51634
PPO Batch Consumption Time: 0.28917
Total Iteration Time: 4.71395

Cumulative Model Updates: 372,694
Cumulative Timesteps: 3,108,283,356

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3108283356...
Checkpoint 3108283356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54.32960
Policy Entropy: 3.97835
Value Function Loss: 0.00630

Mean KL Divergence: 0.00230
SB3 Clip Fraction: 0.01848
Policy Update Magnitude: 0.22437
Value Function Update Magnitude: 0.31490

Collected Steps per Second: 22,240.85408
Overall Steps per Second: 10,594.16954

Timestep Collection Time: 2.24919
Timestep Consumption Time: 2.47265
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.72184

Cumulative Model Updates: 372,700
Cumulative Timesteps: 3,108,333,380

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.62315
Policy Entropy: 3.94907
Value Function Loss: 0.00660

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.02059
Policy Update Magnitude: 0.23582
Value Function Update Magnitude: 0.33269

Collected Steps per Second: 23,383.09044
Overall Steps per Second: 10,773.23886

Timestep Collection Time: 2.13847
Timestep Consumption Time: 2.50303
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.64150

Cumulative Model Updates: 372,706
Cumulative Timesteps: 3,108,383,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3108383384...
Checkpoint 3108383384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.25932
Policy Entropy: 3.95327
Value Function Loss: 0.00710

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02360
Policy Update Magnitude: 0.24069
Value Function Update Magnitude: 0.32626

Collected Steps per Second: 22,323.77163
Overall Steps per Second: 10,618.64385

Timestep Collection Time: 2.24066
Timestep Consumption Time: 2.46992
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.71058

Cumulative Model Updates: 372,712
Cumulative Timesteps: 3,108,433,404

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.09107
Policy Entropy: 3.93712
Value Function Loss: 0.00680

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02200
Policy Update Magnitude: 0.24198
Value Function Update Magnitude: 0.32216

Collected Steps per Second: 22,448.22277
Overall Steps per Second: 10,613.28086

Timestep Collection Time: 2.22762
Timestep Consumption Time: 2.48403
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.71164

Cumulative Model Updates: 372,718
Cumulative Timesteps: 3,108,483,410

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3108483410...
Checkpoint 3108483410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.35139
Policy Entropy: 3.92030
Value Function Loss: 0.00683

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02226
Policy Update Magnitude: 0.24126
Value Function Update Magnitude: 0.33116

Collected Steps per Second: 22,361.26360
Overall Steps per Second: 10,877.53290

Timestep Collection Time: 2.23690
Timestep Consumption Time: 2.36157
PPO Batch Consumption Time: 0.28069
Total Iteration Time: 4.59847

Cumulative Model Updates: 372,724
Cumulative Timesteps: 3,108,533,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.10778
Policy Entropy: 3.93263
Value Function Loss: 0.00708

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02511
Policy Update Magnitude: 0.24684
Value Function Update Magnitude: 0.35277

Collected Steps per Second: 22,697.26141
Overall Steps per Second: 10,585.83071

Timestep Collection Time: 2.20379
Timestep Consumption Time: 2.52139
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.72518

Cumulative Model Updates: 372,730
Cumulative Timesteps: 3,108,583,450

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3108583450...
Checkpoint 3108583450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.19478
Policy Entropy: 3.95835
Value Function Loss: 0.00675

Mean KL Divergence: 0.00355
SB3 Clip Fraction: 0.02739
Policy Update Magnitude: 0.24961
Value Function Update Magnitude: 0.36059

Collected Steps per Second: 22,333.61747
Overall Steps per Second: 10,566.98472

Timestep Collection Time: 2.23985
Timestep Consumption Time: 2.49414
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.73399

Cumulative Model Updates: 372,736
Cumulative Timesteps: 3,108,633,474

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.15472
Policy Entropy: 3.99096
Value Function Loss: 0.00638

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.24260
Value Function Update Magnitude: 0.33931

Collected Steps per Second: 23,459.73230
Overall Steps per Second: 10,883.27527

Timestep Collection Time: 2.13242
Timestep Consumption Time: 2.46417
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.59659

Cumulative Model Updates: 372,742
Cumulative Timesteps: 3,108,683,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3108683500...
Checkpoint 3108683500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.85041
Policy Entropy: 3.99607
Value Function Loss: 0.00535

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02795
Policy Update Magnitude: 0.23678
Value Function Update Magnitude: 0.32202

Collected Steps per Second: 22,243.45080
Overall Steps per Second: 10,617.57621

Timestep Collection Time: 2.24812
Timestep Consumption Time: 2.46162
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.70974

Cumulative Model Updates: 372,748
Cumulative Timesteps: 3,108,733,506

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.73808
Policy Entropy: 3.97616
Value Function Loss: 0.00585

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.02913
Policy Update Magnitude: 0.25705
Value Function Update Magnitude: 0.32363

Collected Steps per Second: 22,427.06026
Overall Steps per Second: 10,886.90511

Timestep Collection Time: 2.23016
Timestep Consumption Time: 2.36398
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.59414

Cumulative Model Updates: 372,754
Cumulative Timesteps: 3,108,783,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3108783522...
Checkpoint 3108783522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.68062
Policy Entropy: 3.98864
Value Function Loss: 0.00631

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.03214
Policy Update Magnitude: 0.24971
Value Function Update Magnitude: 0.33442

Collected Steps per Second: 22,457.59287
Overall Steps per Second: 10,715.43101

Timestep Collection Time: 2.22722
Timestep Consumption Time: 2.44063
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.66785

Cumulative Model Updates: 372,760
Cumulative Timesteps: 3,108,833,540

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9.13211
Policy Entropy: 3.99286
Value Function Loss: 0.00680

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.02668
Policy Update Magnitude: 0.24424
Value Function Update Magnitude: 0.34499

Collected Steps per Second: 22,693.50646
Overall Steps per Second: 10,652.38010

Timestep Collection Time: 2.20345
Timestep Consumption Time: 2.49071
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.69416

Cumulative Model Updates: 372,766
Cumulative Timesteps: 3,108,883,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3108883544...
Checkpoint 3108883544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.01889
Policy Entropy: 3.99888
Value Function Loss: 0.00711

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02265
Policy Update Magnitude: 0.24900
Value Function Update Magnitude: 0.34329

Collected Steps per Second: 22,510.46802
Overall Steps per Second: 10,875.19135

Timestep Collection Time: 2.22208
Timestep Consumption Time: 2.37738
PPO Batch Consumption Time: 0.28128
Total Iteration Time: 4.59946

Cumulative Model Updates: 372,772
Cumulative Timesteps: 3,108,933,564

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.03240
Policy Entropy: 3.99171
Value Function Loss: 0.00705

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02488
Policy Update Magnitude: 0.24752
Value Function Update Magnitude: 0.34167

Collected Steps per Second: 22,493.16799
Overall Steps per Second: 10,510.96294

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.53536
PPO Batch Consumption Time: 0.29448
Total Iteration Time: 4.75941

Cumulative Model Updates: 372,778
Cumulative Timesteps: 3,108,983,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3108983590...
Checkpoint 3108983590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.02259
Policy Entropy: 3.95936
Value Function Loss: 0.00767

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.24673
Value Function Update Magnitude: 0.34841

Collected Steps per Second: 22,322.43491
Overall Steps per Second: 10,651.27902

Timestep Collection Time: 2.24026
Timestep Consumption Time: 2.45477
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.69502

Cumulative Model Updates: 372,784
Cumulative Timesteps: 3,109,033,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.06344
Policy Entropy: 3.95883
Value Function Loss: 0.00724

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02917
Policy Update Magnitude: 0.24667
Value Function Update Magnitude: 0.34129

Collected Steps per Second: 22,397.84499
Overall Steps per Second: 10,837.44111

Timestep Collection Time: 2.23271
Timestep Consumption Time: 2.38166
PPO Batch Consumption Time: 0.28099
Total Iteration Time: 4.61437

Cumulative Model Updates: 372,790
Cumulative Timesteps: 3,109,083,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3109083606...
Checkpoint 3109083606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25.84489
Policy Entropy: 3.93162
Value Function Loss: 0.00735

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02820
Policy Update Magnitude: 0.23807
Value Function Update Magnitude: 0.33762

Collected Steps per Second: 22,199.95679
Overall Steps per Second: 10,638.14608

Timestep Collection Time: 2.25352
Timestep Consumption Time: 2.44918
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.70270

Cumulative Model Updates: 372,796
Cumulative Timesteps: 3,109,133,634

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.26559
Policy Entropy: 3.95121
Value Function Loss: 0.00714

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.24165
Value Function Update Magnitude: 0.34408

Collected Steps per Second: 22,032.83477
Overall Steps per Second: 10,529.29987

Timestep Collection Time: 2.26970
Timestep Consumption Time: 2.47971
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.74941

Cumulative Model Updates: 372,802
Cumulative Timesteps: 3,109,183,642

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3109183642...
Checkpoint 3109183642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.44890
Policy Entropy: 3.95585
Value Function Loss: 0.00659

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.03249
Policy Update Magnitude: 0.24535
Value Function Update Magnitude: 0.35189

Collected Steps per Second: 23,101.15693
Overall Steps per Second: 10,762.72088

Timestep Collection Time: 2.16569
Timestep Consumption Time: 2.48276
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.64845

Cumulative Model Updates: 372,808
Cumulative Timesteps: 3,109,233,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.62346
Policy Entropy: 3.98697
Value Function Loss: 0.00582

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.02897
Policy Update Magnitude: 0.24410
Value Function Update Magnitude: 0.34074

Collected Steps per Second: 22,799.45424
Overall Steps per Second: 10,731.72057

Timestep Collection Time: 2.19365
Timestep Consumption Time: 2.46674
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.66039

Cumulative Model Updates: 372,814
Cumulative Timesteps: 3,109,283,686

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3109283686...
Checkpoint 3109283686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.63434
Policy Entropy: 3.99335
Value Function Loss: 0.00545

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.03108
Policy Update Magnitude: 0.23519
Value Function Update Magnitude: 0.31872

Collected Steps per Second: 21,744.53823
Overall Steps per Second: 10,414.18569

Timestep Collection Time: 2.30062
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.29410
Total Iteration Time: 4.80364

Cumulative Model Updates: 372,820
Cumulative Timesteps: 3,109,333,712

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.14252
Policy Entropy: 3.99277
Value Function Loss: 0.00638

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.02967
Policy Update Magnitude: 0.23234
Value Function Update Magnitude: 0.32093

Collected Steps per Second: 23,397.22201
Overall Steps per Second: 10,881.88185

Timestep Collection Time: 2.13803
Timestep Consumption Time: 2.45897
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.59700

Cumulative Model Updates: 372,826
Cumulative Timesteps: 3,109,383,736

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3109383736...
Checkpoint 3109383736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.63681
Policy Entropy: 4.02963
Value Function Loss: 0.00615

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02555
Policy Update Magnitude: 0.22920
Value Function Update Magnitude: 0.32688

Collected Steps per Second: 22,388.26486
Overall Steps per Second: 10,713.38131

Timestep Collection Time: 2.23340
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.66725

Cumulative Model Updates: 372,832
Cumulative Timesteps: 3,109,433,738

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.91633
Policy Entropy: 4.04120
Value Function Loss: 0.00566

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.22320
Value Function Update Magnitude: 0.32350

Collected Steps per Second: 22,517.15946
Overall Steps per Second: 10,906.08635

Timestep Collection Time: 2.22115
Timestep Consumption Time: 2.36473
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.58588

Cumulative Model Updates: 372,838
Cumulative Timesteps: 3,109,483,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3109483752...
Checkpoint 3109483752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.65628
Policy Entropy: 4.04021
Value Function Loss: 0.00617

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.01961
Policy Update Magnitude: 0.22757
Value Function Update Magnitude: 0.30563

Collected Steps per Second: 22,349.97765
Overall Steps per Second: 10,592.49408

Timestep Collection Time: 2.23839
Timestep Consumption Time: 2.48458
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.72297

Cumulative Model Updates: 372,844
Cumulative Timesteps: 3,109,533,780

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.09594
Policy Entropy: 3.99160
Value Function Loss: 0.00718

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02115
Policy Update Magnitude: 0.23786
Value Function Update Magnitude: 0.30915

Collected Steps per Second: 22,548.18682
Overall Steps per Second: 10,524.63103

Timestep Collection Time: 2.21756
Timestep Consumption Time: 2.53339
PPO Batch Consumption Time: 0.29364
Total Iteration Time: 4.75095

Cumulative Model Updates: 372,850
Cumulative Timesteps: 3,109,583,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3109583782...
Checkpoint 3109583782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53.81671
Policy Entropy: 3.93485
Value Function Loss: 0.00762

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02322
Policy Update Magnitude: 0.25508
Value Function Update Magnitude: 0.33356

Collected Steps per Second: 22,102.66392
Overall Steps per Second: 10,640.85090

Timestep Collection Time: 2.26326
Timestep Consumption Time: 2.43787
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 4.70113

Cumulative Model Updates: 372,856
Cumulative Timesteps: 3,109,633,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.91101
Policy Entropy: 3.94278
Value Function Loss: 0.00704

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02770
Policy Update Magnitude: 0.25908
Value Function Update Magnitude: 0.32936

Collected Steps per Second: 22,566.05455
Overall Steps per Second: 10,614.60854

Timestep Collection Time: 2.21660
Timestep Consumption Time: 2.49577
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.71237

Cumulative Model Updates: 372,862
Cumulative Timesteps: 3,109,683,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3109683826...
Checkpoint 3109683826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.19521
Policy Entropy: 3.94835
Value Function Loss: 0.00682

Mean KL Divergence: 0.00388
SB3 Clip Fraction: 0.02772
Policy Update Magnitude: 0.24770
Value Function Update Magnitude: 0.32242

Collected Steps per Second: 22,159.19093
Overall Steps per Second: 10,532.45845

Timestep Collection Time: 2.25757
Timestep Consumption Time: 2.49212
PPO Batch Consumption Time: 0.29341
Total Iteration Time: 4.74970

Cumulative Model Updates: 372,868
Cumulative Timesteps: 3,109,733,852

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75.37667
Policy Entropy: 3.96874
Value Function Loss: 0.00679

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02641
Policy Update Magnitude: 0.24011
Value Function Update Magnitude: 0.31988

Collected Steps per Second: 22,488.28366
Overall Steps per Second: 10,847.25556

Timestep Collection Time: 2.22365
Timestep Consumption Time: 2.38637
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.61001

Cumulative Model Updates: 372,874
Cumulative Timesteps: 3,109,783,858

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3109783858...
Checkpoint 3109783858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.08963
Policy Entropy: 3.94662
Value Function Loss: 0.00728

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02868
Policy Update Magnitude: 0.24957
Value Function Update Magnitude: 0.32140

Collected Steps per Second: 22,469.38405
Overall Steps per Second: 10,627.34213

Timestep Collection Time: 2.22578
Timestep Consumption Time: 2.48019
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.70597

Cumulative Model Updates: 372,880
Cumulative Timesteps: 3,109,833,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.16263
Policy Entropy: 3.93248
Value Function Loss: 0.00800

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.03238
Policy Update Magnitude: 0.26006
Value Function Update Magnitude: 0.35001

Collected Steps per Second: 22,599.03128
Overall Steps per Second: 10,656.29582

Timestep Collection Time: 2.21470
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.69675

Cumulative Model Updates: 372,886
Cumulative Timesteps: 3,109,883,920

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 3109883920...
Checkpoint 3109883920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.12477
Policy Entropy: 3.95533
Value Function Loss: 0.00740

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.03596
Policy Update Magnitude: 0.25433
Value Function Update Magnitude: 0.37010

Collected Steps per Second: 21,965.48862
Overall Steps per Second: 10,667.60291

Timestep Collection Time: 2.27630
Timestep Consumption Time: 2.41079
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.68709

Cumulative Model Updates: 372,892
Cumulative Timesteps: 3,109,933,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.75890
Policy Entropy: 3.95812
Value Function Loss: 0.00774

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.03468
Policy Update Magnitude: 0.25280
Value Function Update Magnitude: 0.36915

Collected Steps per Second: 22,662.36032
Overall Steps per Second: 10,681.92919

Timestep Collection Time: 2.20763
Timestep Consumption Time: 2.47599
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.68361

Cumulative Model Updates: 372,898
Cumulative Timesteps: 3,109,983,950

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3109983950...
Checkpoint 3109983950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.91139
Policy Entropy: 3.96515
Value Function Loss: 0.00761

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.03220
Policy Update Magnitude: 0.25613
Value Function Update Magnitude: 0.37375

Collected Steps per Second: 22,153.99725
Overall Steps per Second: 10,587.29003

Timestep Collection Time: 2.25792
Timestep Consumption Time: 2.46680
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.72472

Cumulative Model Updates: 372,904
Cumulative Timesteps: 3,110,033,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.22253
Policy Entropy: 3.94197
Value Function Loss: 0.00780

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.03323
Policy Update Magnitude: 0.26987
Value Function Update Magnitude: 0.36718

Collected Steps per Second: 23,373.90273
Overall Steps per Second: 10,907.05461

Timestep Collection Time: 2.14025
Timestep Consumption Time: 2.44632
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.58657

Cumulative Model Updates: 372,910
Cumulative Timesteps: 3,110,083,998

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3110083998...
Checkpoint 3110083998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.06940
Policy Entropy: 3.93430
Value Function Loss: 0.00722

Mean KL Divergence: 0.00417
SB3 Clip Fraction: 0.03005
Policy Update Magnitude: 0.27222
Value Function Update Magnitude: 0.35426

Collected Steps per Second: 22,410.48106
Overall Steps per Second: 10,734.05651

Timestep Collection Time: 2.23208
Timestep Consumption Time: 2.42804
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.66012

Cumulative Model Updates: 372,916
Cumulative Timesteps: 3,110,134,020

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.22123
Policy Entropy: 3.96580
Value Function Loss: 0.00657

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.02798
Policy Update Magnitude: 0.25709
Value Function Update Magnitude: 0.33688

Collected Steps per Second: 23,110.68274
Overall Steps per Second: 10,920.30953

Timestep Collection Time: 2.16428
Timestep Consumption Time: 2.41599
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.58027

Cumulative Model Updates: 372,922
Cumulative Timesteps: 3,110,184,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3110184038...
Checkpoint 3110184038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.96338
Policy Entropy: 4.01398
Value Function Loss: 0.00607

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02375
Policy Update Magnitude: 0.23820
Value Function Update Magnitude: 0.31012

Collected Steps per Second: 23,128.43234
Overall Steps per Second: 10,696.44776

Timestep Collection Time: 2.16279
Timestep Consumption Time: 2.51371
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.67651

Cumulative Model Updates: 372,928
Cumulative Timesteps: 3,110,234,060

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.28840
Policy Entropy: 4.04871
Value Function Loss: 0.00588

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02187
Policy Update Magnitude: 0.23058
Value Function Update Magnitude: 0.29363

Collected Steps per Second: 22,701.51165
Overall Steps per Second: 10,782.76145

Timestep Collection Time: 2.20382
Timestep Consumption Time: 2.43600
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.63981

Cumulative Model Updates: 372,934
Cumulative Timesteps: 3,110,284,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3110284090...
Checkpoint 3110284090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.75522
Policy Entropy: 4.01487
Value Function Loss: 0.00644

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02016
Policy Update Magnitude: 0.23504
Value Function Update Magnitude: 0.30998

Collected Steps per Second: 22,584.48733
Overall Steps per Second: 10,836.30602

Timestep Collection Time: 2.21515
Timestep Consumption Time: 2.40155
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.61670

Cumulative Model Updates: 372,940
Cumulative Timesteps: 3,110,334,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.54744
Policy Entropy: 3.97188
Value Function Loss: 0.00721

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02677
Policy Update Magnitude: 0.24804
Value Function Update Magnitude: 0.34198

Collected Steps per Second: 23,072.98158
Overall Steps per Second: 10,753.44169

Timestep Collection Time: 2.16747
Timestep Consumption Time: 2.48313
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.65060

Cumulative Model Updates: 372,946
Cumulative Timesteps: 3,110,384,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3110384128...
Checkpoint 3110384128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.21416
Policy Entropy: 3.91462
Value Function Loss: 0.00750

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.25223
Value Function Update Magnitude: 0.34932

Collected Steps per Second: 22,190.44369
Overall Steps per Second: 10,632.23575

Timestep Collection Time: 2.25358
Timestep Consumption Time: 2.44985
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.70343

Cumulative Model Updates: 372,952
Cumulative Timesteps: 3,110,434,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.13187
Policy Entropy: 3.91529
Value Function Loss: 0.00774

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.03082
Policy Update Magnitude: 0.26374
Value Function Update Magnitude: 0.36376

Collected Steps per Second: 23,346.00934
Overall Steps per Second: 10,888.60535

Timestep Collection Time: 2.14289
Timestep Consumption Time: 2.45163
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.59453

Cumulative Model Updates: 372,958
Cumulative Timesteps: 3,110,484,164

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3110484164...
Checkpoint 3110484164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.30636
Policy Entropy: 3.90988
Value Function Loss: 0.00759

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.03679
Policy Update Magnitude: 0.26573
Value Function Update Magnitude: 0.36887

Collected Steps per Second: 22,291.95788
Overall Steps per Second: 10,666.36185

Timestep Collection Time: 2.24368
Timestep Consumption Time: 2.44545
PPO Batch Consumption Time: 0.28021
Total Iteration Time: 4.68913

Cumulative Model Updates: 372,964
Cumulative Timesteps: 3,110,534,180

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.73454
Policy Entropy: 3.92836
Value Function Loss: 0.00786

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.03411
Policy Update Magnitude: 0.26552
Value Function Update Magnitude: 0.38675

Collected Steps per Second: 22,456.26436
Overall Steps per Second: 10,562.17123

Timestep Collection Time: 2.22726
Timestep Consumption Time: 2.50813
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.73539

Cumulative Model Updates: 372,970
Cumulative Timesteps: 3,110,584,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3110584196...
Checkpoint 3110584196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.47277
Policy Entropy: 3.90217
Value Function Loss: 0.00704

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.03488
Policy Update Magnitude: 0.26902
Value Function Update Magnitude: 0.40165

Collected Steps per Second: 23,231.21775
Overall Steps per Second: 10,901.86451

Timestep Collection Time: 2.15253
Timestep Consumption Time: 2.43439
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.58692

Cumulative Model Updates: 372,976
Cumulative Timesteps: 3,110,634,202

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.88676
Policy Entropy: 3.91730
Value Function Loss: 0.00614

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.03558
Policy Update Magnitude: 0.26265
Value Function Update Magnitude: 0.38262

Collected Steps per Second: 22,488.46075
Overall Steps per Second: 10,562.58207

Timestep Collection Time: 2.22443
Timestep Consumption Time: 2.51153
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.73596

Cumulative Model Updates: 372,982
Cumulative Timesteps: 3,110,684,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3110684226...
Checkpoint 3110684226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.93005
Policy Entropy: 3.95348
Value Function Loss: 0.00523

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.03676
Policy Update Magnitude: 0.24282
Value Function Update Magnitude: 0.34571

Collected Steps per Second: 22,167.20686
Overall Steps per Second: 10,678.28507

Timestep Collection Time: 2.25585
Timestep Consumption Time: 2.42711
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.68296

Cumulative Model Updates: 372,988
Cumulative Timesteps: 3,110,734,232

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55.67629
Policy Entropy: 3.97608
Value Function Loss: 0.00554

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.03335
Policy Update Magnitude: 0.23546
Value Function Update Magnitude: 0.31822

Collected Steps per Second: 23,209.87343
Overall Steps per Second: 10,835.26636

Timestep Collection Time: 2.15486
Timestep Consumption Time: 2.46099
PPO Batch Consumption Time: 0.28037
Total Iteration Time: 4.61585

Cumulative Model Updates: 372,994
Cumulative Timesteps: 3,110,784,246

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3110784246...
Checkpoint 3110784246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.01758
Policy Entropy: 3.95372
Value Function Loss: 0.00562

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.03339
Policy Update Magnitude: 0.22944
Value Function Update Magnitude: 0.30938

Collected Steps per Second: 22,498.96036
Overall Steps per Second: 10,696.41463

Timestep Collection Time: 2.22241
Timestep Consumption Time: 2.45224
PPO Batch Consumption Time: 0.27981
Total Iteration Time: 4.67465

Cumulative Model Updates: 373,000
Cumulative Timesteps: 3,110,834,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.88381
Policy Entropy: 3.92541
Value Function Loss: 0.00607

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02688
Policy Update Magnitude: 0.22980
Value Function Update Magnitude: 0.31504

Collected Steps per Second: 22,406.31437
Overall Steps per Second: 10,842.70554

Timestep Collection Time: 2.23267
Timestep Consumption Time: 2.38112
PPO Batch Consumption Time: 0.28017
Total Iteration Time: 4.61379

Cumulative Model Updates: 373,006
Cumulative Timesteps: 3,110,884,274

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3110884274...
Checkpoint 3110884274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.64321
Policy Entropy: 3.95043
Value Function Loss: 0.00579

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02487
Policy Update Magnitude: 0.23333
Value Function Update Magnitude: 0.32298

Collected Steps per Second: 22,284.27399
Overall Steps per Second: 10,644.04383

Timestep Collection Time: 2.24418
Timestep Consumption Time: 2.45422
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.69840

Cumulative Model Updates: 373,012
Cumulative Timesteps: 3,110,934,284

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.09656
Policy Entropy: 3.97532
Value Function Loss: 0.00586

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02697
Policy Update Magnitude: 0.23548
Value Function Update Magnitude: 0.32086

Collected Steps per Second: 22,261.66743
Overall Steps per Second: 10,494.30236

Timestep Collection Time: 2.24790
Timestep Consumption Time: 2.52059
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 4.76849

Cumulative Model Updates: 373,018
Cumulative Timesteps: 3,110,984,326

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 3110984326...
Checkpoint 3110984326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.41693
Policy Entropy: 3.99051
Value Function Loss: 0.00665

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.24113
Value Function Update Magnitude: 0.33183

Collected Steps per Second: 22,398.04669
Overall Steps per Second: 10,721.55076

Timestep Collection Time: 2.23261
Timestep Consumption Time: 2.43146
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.66406

Cumulative Model Updates: 373,024
Cumulative Timesteps: 3,111,034,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60.85313
Policy Entropy: 3.97399
Value Function Loss: 0.00700

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02790
Policy Update Magnitude: 0.24333
Value Function Update Magnitude: 0.33463

Collected Steps per Second: 22,661.49122
Overall Steps per Second: 10,746.38646

Timestep Collection Time: 2.20665
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.28003
Total Iteration Time: 4.65329

Cumulative Model Updates: 373,030
Cumulative Timesteps: 3,111,084,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3111084338...
Checkpoint 3111084338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6.20753
Policy Entropy: 3.95346
Value Function Loss: 0.00662

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.02693
Policy Update Magnitude: 0.24350
Value Function Update Magnitude: 0.33207

Collected Steps per Second: 22,193.57701
Overall Steps per Second: 10,715.89235

Timestep Collection Time: 2.25363
Timestep Consumption Time: 2.41384
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.66746

Cumulative Model Updates: 373,036
Cumulative Timesteps: 3,111,134,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.07590
Policy Entropy: 3.97145
Value Function Loss: 0.00670

Mean KL Divergence: 0.00307
SB3 Clip Fraction: 0.02233
Policy Update Magnitude: 0.24269
Value Function Update Magnitude: 0.31932

Collected Steps per Second: 22,590.84815
Overall Steps per Second: 10,881.19065

Timestep Collection Time: 2.21399
Timestep Consumption Time: 2.38256
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.59656

Cumulative Model Updates: 373,042
Cumulative Timesteps: 3,111,184,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3111184370...
Checkpoint 3111184370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.87125
Policy Entropy: 3.99594
Value Function Loss: 0.00647

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.02699
Policy Update Magnitude: 0.23915
Value Function Update Magnitude: 0.32171

Collected Steps per Second: 22,237.31351
Overall Steps per Second: 10,630.52391

Timestep Collection Time: 2.24883
Timestep Consumption Time: 2.45536
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.70419

Cumulative Model Updates: 373,048
Cumulative Timesteps: 3,111,234,378

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.18057
Policy Entropy: 4.01377
Value Function Loss: 0.00652

Mean KL Divergence: 0.00351
SB3 Clip Fraction: 0.02766
Policy Update Magnitude: 0.23601
Value Function Update Magnitude: 0.32414

Collected Steps per Second: 22,436.78484
Overall Steps per Second: 10,888.88657

Timestep Collection Time: 2.22920
Timestep Consumption Time: 2.36411
PPO Batch Consumption Time: 0.27923
Total Iteration Time: 4.59331

Cumulative Model Updates: 373,054
Cumulative Timesteps: 3,111,284,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3111284394...
Checkpoint 3111284394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.61323
Policy Entropy: 3.99815
Value Function Loss: 0.00647

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02528
Policy Update Magnitude: 0.23513
Value Function Update Magnitude: 0.31369

Collected Steps per Second: 22,103.80659
Overall Steps per Second: 10,646.53570

Timestep Collection Time: 2.26314
Timestep Consumption Time: 2.43548
PPO Batch Consumption Time: 0.27945
Total Iteration Time: 4.69862

Cumulative Model Updates: 373,060
Cumulative Timesteps: 3,111,334,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20.93588
Policy Entropy: 3.98919
Value Function Loss: 0.00674

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02834
Policy Update Magnitude: 0.23509
Value Function Update Magnitude: 0.31535

Collected Steps per Second: 22,574.40537
Overall Steps per Second: 10,514.81905

Timestep Collection Time: 2.21632
Timestep Consumption Time: 2.54192
PPO Batch Consumption Time: 0.29365
Total Iteration Time: 4.75824

Cumulative Model Updates: 373,066
Cumulative Timesteps: 3,111,384,450

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3111384450...
Checkpoint 3111384450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.41975
Policy Entropy: 3.97684
Value Function Loss: 0.00621

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02468
Policy Update Magnitude: 0.23761
Value Function Update Magnitude: 0.32191

Collected Steps per Second: 22,211.48568
Overall Steps per Second: 10,626.91373

Timestep Collection Time: 2.25109
Timestep Consumption Time: 2.45395
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.70503

Cumulative Model Updates: 373,072
Cumulative Timesteps: 3,111,434,450

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.58207
Policy Entropy: 3.97246
Value Function Loss: 0.00661

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02869
Policy Update Magnitude: 0.23532
Value Function Update Magnitude: 0.32772

Collected Steps per Second: 22,153.27474
Overall Steps per Second: 10,486.79938

Timestep Collection Time: 2.25772
Timestep Consumption Time: 2.51170
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.76942

Cumulative Model Updates: 373,078
Cumulative Timesteps: 3,111,484,466

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3111484466...
Checkpoint 3111484466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72.44852
Policy Entropy: 3.96091
Value Function Loss: 0.00667

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02516
Policy Update Magnitude: 0.24272
Value Function Update Magnitude: 0.33931

Collected Steps per Second: 22,049.56920
Overall Steps per Second: 10,676.46008

Timestep Collection Time: 2.26762
Timestep Consumption Time: 2.41558
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.68320

Cumulative Model Updates: 373,084
Cumulative Timesteps: 3,111,534,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.84822
Policy Entropy: 3.91219
Value Function Loss: 0.00788

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.26424
Value Function Update Magnitude: 0.34980

Collected Steps per Second: 23,269.49967
Overall Steps per Second: 10,823.78672

Timestep Collection Time: 2.14874
Timestep Consumption Time: 2.47072
PPO Batch Consumption Time: 0.28157
Total Iteration Time: 4.61946

Cumulative Model Updates: 373,090
Cumulative Timesteps: 3,111,584,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3111584466...
Checkpoint 3111584466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.76107
Policy Entropy: 3.91079
Value Function Loss: 0.00827

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.03292
Policy Update Magnitude: 0.26864
Value Function Update Magnitude: 0.35467

Collected Steps per Second: 22,262.96799
Overall Steps per Second: 10,549.72222

Timestep Collection Time: 2.24705
Timestep Consumption Time: 2.49488
PPO Batch Consumption Time: 0.27961
Total Iteration Time: 4.74193

Cumulative Model Updates: 373,096
Cumulative Timesteps: 3,111,634,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.58150
Policy Entropy: 3.89753
Value Function Loss: 0.00820

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.03343
Policy Update Magnitude: 0.27039
Value Function Update Magnitude: 0.35962

Collected Steps per Second: 22,226.63086
Overall Steps per Second: 10,664.03622

Timestep Collection Time: 2.25063
Timestep Consumption Time: 2.44027
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.69091

Cumulative Model Updates: 373,102
Cumulative Timesteps: 3,111,684,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3111684516...
Checkpoint 3111684516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12.38830
Policy Entropy: 3.92930
Value Function Loss: 0.00701

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.03172
Policy Update Magnitude: 0.25719
Value Function Update Magnitude: 0.34768

Collected Steps per Second: 22,434.41288
Overall Steps per Second: 10,561.66736

Timestep Collection Time: 2.22872
Timestep Consumption Time: 2.50538
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.73410

Cumulative Model Updates: 373,108
Cumulative Timesteps: 3,111,734,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.81115
Policy Entropy: 3.92201
Value Function Loss: 0.00689

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.03430
Policy Update Magnitude: 0.24460
Value Function Update Magnitude: 0.33325

Collected Steps per Second: 22,422.80225
Overall Steps per Second: 10,472.01998

Timestep Collection Time: 2.23059
Timestep Consumption Time: 2.54557
PPO Batch Consumption Time: 0.29417
Total Iteration Time: 4.77616

Cumulative Model Updates: 373,114
Cumulative Timesteps: 3,111,784,532

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3111784532...
Checkpoint 3111784532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.79756
Policy Entropy: 3.94547
Value Function Loss: 0.00710

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03150
Policy Update Magnitude: 0.24708
Value Function Update Magnitude: 0.34101

Collected Steps per Second: 22,203.57324
Overall Steps per Second: 10,662.53968

Timestep Collection Time: 2.25261
Timestep Consumption Time: 2.43820
PPO Batch Consumption Time: 0.29380
Total Iteration Time: 4.69081

Cumulative Model Updates: 373,120
Cumulative Timesteps: 3,111,834,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.54115
Policy Entropy: 3.93865
Value Function Loss: 0.00727

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.03112
Policy Update Magnitude: 0.25401
Value Function Update Magnitude: 0.35511

Collected Steps per Second: 22,450.31657
Overall Steps per Second: 10,576.87099

Timestep Collection Time: 2.22830
Timestep Consumption Time: 2.50146
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.72975

Cumulative Model Updates: 373,126
Cumulative Timesteps: 3,111,884,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3111884574...
Checkpoint 3111884574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.53158
Policy Entropy: 3.93534
Value Function Loss: 0.00696

Mean KL Divergence: 0.00408
SB3 Clip Fraction: 0.02960
Policy Update Magnitude: 0.25131
Value Function Update Magnitude: 0.33916

Collected Steps per Second: 22,350.96985
Overall Steps per Second: 10,581.92997

Timestep Collection Time: 2.23749
Timestep Consumption Time: 2.48849
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.72598

Cumulative Model Updates: 373,132
Cumulative Timesteps: 3,111,934,584

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.67217
Policy Entropy: 3.94588
Value Function Loss: 0.00642

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02736
Policy Update Magnitude: 0.24420
Value Function Update Magnitude: 0.30718

Collected Steps per Second: 23,258.36476
Overall Steps per Second: 10,794.07534

Timestep Collection Time: 2.15071
Timestep Consumption Time: 2.48350
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.63421

Cumulative Model Updates: 373,138
Cumulative Timesteps: 3,111,984,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3111984606...
Checkpoint 3111984606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.68609
Policy Entropy: 3.94777
Value Function Loss: 0.00606

Mean KL Divergence: 0.00386
SB3 Clip Fraction: 0.02928
Policy Update Magnitude: 0.23913
Value Function Update Magnitude: 0.30079

Collected Steps per Second: 22,469.34054
Overall Steps per Second: 10,670.33357

Timestep Collection Time: 2.22570
Timestep Consumption Time: 2.46113
PPO Batch Consumption Time: 0.28082
Total Iteration Time: 4.68683

Cumulative Model Updates: 373,144
Cumulative Timesteps: 3,112,034,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.50756
Policy Entropy: 3.97208
Value Function Loss: 0.00624

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02797
Policy Update Magnitude: 0.23535
Value Function Update Magnitude: 0.31495

Collected Steps per Second: 22,459.55623
Overall Steps per Second: 10,600.10626

Timestep Collection Time: 2.22720
Timestep Consumption Time: 2.49181
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.71901

Cumulative Model Updates: 373,150
Cumulative Timesteps: 3,112,084,638

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3112084638...
Checkpoint 3112084638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.25753
Policy Entropy: 3.97333
Value Function Loss: 0.00552

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.02472
Policy Update Magnitude: 0.23035
Value Function Update Magnitude: 0.31727

Collected Steps per Second: 23,223.48145
Overall Steps per Second: 10,896.69066

Timestep Collection Time: 2.15342
Timestep Consumption Time: 2.43604
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.58947

Cumulative Model Updates: 373,156
Cumulative Timesteps: 3,112,134,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.13733
Policy Entropy: 3.97883
Value Function Loss: 0.00585

Mean KL Divergence: 0.00254
SB3 Clip Fraction: 0.01967
Policy Update Magnitude: 0.23186
Value Function Update Magnitude: 0.31421

Collected Steps per Second: 22,238.00643
Overall Steps per Second: 10,549.98227

Timestep Collection Time: 2.24894
Timestep Consumption Time: 2.49154
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.74048

Cumulative Model Updates: 373,162
Cumulative Timesteps: 3,112,184,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3112184660...
Checkpoint 3112184660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.62697
Policy Entropy: 3.94606
Value Function Loss: 0.00645

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02558
Policy Update Magnitude: 0.23720
Value Function Update Magnitude: 0.33302

Collected Steps per Second: 22,282.85607
Overall Steps per Second: 10,617.86856

Timestep Collection Time: 2.24513
Timestep Consumption Time: 2.46655
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.71168

Cumulative Model Updates: 373,168
Cumulative Timesteps: 3,112,234,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.90045
Policy Entropy: 3.93303
Value Function Loss: 0.00685

Mean KL Divergence: 0.00382
SB3 Clip Fraction: 0.02664
Policy Update Magnitude: 0.24365
Value Function Update Magnitude: 0.34606

Collected Steps per Second: 23,194.17463
Overall Steps per Second: 10,846.92109

Timestep Collection Time: 2.15571
Timestep Consumption Time: 2.45389
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.60960

Cumulative Model Updates: 373,174
Cumulative Timesteps: 3,112,284,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3112284688...
Checkpoint 3112284688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.51563
Policy Entropy: 3.98827
Value Function Loss: 0.00571

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02387
Policy Update Magnitude: 0.24653
Value Function Update Magnitude: 0.34853

Collected Steps per Second: 22,357.65615
Overall Steps per Second: 10,664.04538

Timestep Collection Time: 2.23673
Timestep Consumption Time: 2.45267
PPO Batch Consumption Time: 0.28072
Total Iteration Time: 4.68940

Cumulative Model Updates: 373,180
Cumulative Timesteps: 3,112,334,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39.90324
Policy Entropy: 3.98087
Value Function Loss: 0.00605

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02429
Policy Update Magnitude: 0.23296
Value Function Update Magnitude: 0.31557

Collected Steps per Second: 22,080.38016
Overall Steps per Second: 10,482.92983

Timestep Collection Time: 2.26473
Timestep Consumption Time: 2.50551
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.77023

Cumulative Model Updates: 373,186
Cumulative Timesteps: 3,112,384,702

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3112384702...
Checkpoint 3112384702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.06682
Policy Entropy: 3.96320
Value Function Loss: 0.00611

Mean KL Divergence: 0.00361
SB3 Clip Fraction: 0.02637
Policy Update Magnitude: 0.23650
Value Function Update Magnitude: 0.30621

Collected Steps per Second: 23,272.52060
Overall Steps per Second: 10,711.76512

Timestep Collection Time: 2.14940
Timestep Consumption Time: 2.52042
PPO Batch Consumption Time: 0.29401
Total Iteration Time: 4.66982

Cumulative Model Updates: 373,192
Cumulative Timesteps: 3,112,434,724

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.60967
Policy Entropy: 3.94884
Value Function Loss: 0.00632

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.24049
Value Function Update Magnitude: 0.31437

Collected Steps per Second: 22,575.31309
Overall Steps per Second: 10,638.06656

Timestep Collection Time: 2.21490
Timestep Consumption Time: 2.48539
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.70029

Cumulative Model Updates: 373,198
Cumulative Timesteps: 3,112,484,726

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3112484726...
Checkpoint 3112484726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.10222
Policy Entropy: 3.98673
Value Function Loss: 0.00576

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.23573
Value Function Update Magnitude: 0.31860

Collected Steps per Second: 22,615.14598
Overall Steps per Second: 10,796.14806

Timestep Collection Time: 2.21241
Timestep Consumption Time: 2.42202
PPO Batch Consumption Time: 0.27985
Total Iteration Time: 4.63443

Cumulative Model Updates: 373,204
Cumulative Timesteps: 3,112,534,760

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.34502
Policy Entropy: 4.01908
Value Function Loss: 0.00582

Mean KL Divergence: 0.00310
SB3 Clip Fraction: 0.02289
Policy Update Magnitude: 0.24585
Value Function Update Magnitude: 0.31364

Collected Steps per Second: 23,120.11822
Overall Steps per Second: 10,726.36337

Timestep Collection Time: 2.16262
Timestep Consumption Time: 2.49879
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.66141

Cumulative Model Updates: 373,210
Cumulative Timesteps: 3,112,584,760

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3112584760...
Checkpoint 3112584760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.59537
Policy Entropy: 3.98338
Value Function Loss: 0.00697

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02460
Policy Update Magnitude: 0.24502
Value Function Update Magnitude: 0.32255

Collected Steps per Second: 22,374.47794
Overall Steps per Second: 10,577.90022

Timestep Collection Time: 2.23549
Timestep Consumption Time: 2.49304
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.72854

Cumulative Model Updates: 373,216
Cumulative Timesteps: 3,112,634,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.61706
Policy Entropy: 3.99243
Value Function Loss: 0.00690

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02702
Policy Update Magnitude: 0.24731
Value Function Update Magnitude: 0.33143

Collected Steps per Second: 22,444.81017
Overall Steps per Second: 10,786.14190

Timestep Collection Time: 2.22920
Timestep Consumption Time: 2.40953
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.63873

Cumulative Model Updates: 373,222
Cumulative Timesteps: 3,112,684,812

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 3112684812...
Checkpoint 3112684812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.22750
Policy Entropy: 4.00672
Value Function Loss: 0.00633

Mean KL Divergence: 0.00406
SB3 Clip Fraction: 0.02929
Policy Update Magnitude: 0.24044
Value Function Update Magnitude: 0.32977

Collected Steps per Second: 22,538.68512
Overall Steps per Second: 10,639.36489

Timestep Collection Time: 2.21859
Timestep Consumption Time: 2.48132
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.69990

Cumulative Model Updates: 373,228
Cumulative Timesteps: 3,112,734,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.71906
Policy Entropy: 4.00819
Value Function Loss: 0.00565

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02590
Policy Update Magnitude: 0.23493
Value Function Update Magnitude: 0.31608

Collected Steps per Second: 22,709.89864
Overall Steps per Second: 10,800.10423

Timestep Collection Time: 2.20195
Timestep Consumption Time: 2.42819
PPO Batch Consumption Time: 0.28012
Total Iteration Time: 4.63014

Cumulative Model Updates: 373,234
Cumulative Timesteps: 3,112,784,822

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3112784822...
Checkpoint 3112784822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.11611
Policy Entropy: 4.01057
Value Function Loss: 0.00526

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02905
Policy Update Magnitude: 0.22538
Value Function Update Magnitude: 0.30295

Collected Steps per Second: 22,436.61877
Overall Steps per Second: 10,718.88372

Timestep Collection Time: 2.22877
Timestep Consumption Time: 2.43646
PPO Batch Consumption Time: 0.29269
Total Iteration Time: 4.66522

Cumulative Model Updates: 373,240
Cumulative Timesteps: 3,112,834,828

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.82174
Policy Entropy: 4.01247
Value Function Loss: 0.00549

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.04000
Policy Update Magnitude: 0.25317
Value Function Update Magnitude: 0.29668

Collected Steps per Second: 22,431.29636
Overall Steps per Second: 10,539.98023

Timestep Collection Time: 2.22983
Timestep Consumption Time: 2.51572
PPO Batch Consumption Time: 0.29291
Total Iteration Time: 4.74555

Cumulative Model Updates: 373,246
Cumulative Timesteps: 3,112,884,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3112884846...
Checkpoint 3112884846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68.27575
Policy Entropy: 4.03756
Value Function Loss: 0.00536

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.05269
Policy Update Magnitude: 0.23093
Value Function Update Magnitude: 0.28673

Collected Steps per Second: 22,386.03265
Overall Steps per Second: 10,622.67958

Timestep Collection Time: 2.23470
Timestep Consumption Time: 2.47466
PPO Batch Consumption Time: 0.29386
Total Iteration Time: 4.70936

Cumulative Model Updates: 373,252
Cumulative Timesteps: 3,112,934,872

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.41526
Policy Entropy: 4.06151
Value Function Loss: 0.00507

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.04536
Policy Update Magnitude: 0.21511
Value Function Update Magnitude: 0.29260

Collected Steps per Second: 22,340.35177
Overall Steps per Second: 10,840.52787

Timestep Collection Time: 2.23837
Timestep Consumption Time: 2.37450
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.61287

Cumulative Model Updates: 373,258
Cumulative Timesteps: 3,112,984,878

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3112984878...
Checkpoint 3112984878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17.89905
Policy Entropy: 4.04540
Value Function Loss: 0.00528

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.03574
Policy Update Magnitude: 0.21688
Value Function Update Magnitude: 0.29616

Collected Steps per Second: 22,496.69113
Overall Steps per Second: 10,727.89961

Timestep Collection Time: 2.22379
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.66335

Cumulative Model Updates: 373,264
Cumulative Timesteps: 3,113,034,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.06794
Policy Entropy: 4.06099
Value Function Loss: 0.00558

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02879
Policy Update Magnitude: 0.23152
Value Function Update Magnitude: 0.29367

Collected Steps per Second: 22,282.63836
Overall Steps per Second: 10,846.12716

Timestep Collection Time: 2.24462
Timestep Consumption Time: 2.36680
PPO Batch Consumption Time: 0.27995
Total Iteration Time: 4.61142

Cumulative Model Updates: 373,270
Cumulative Timesteps: 3,113,084,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3113084922...
Checkpoint 3113084922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21.24081
Policy Entropy: 4.04665
Value Function Loss: 0.00517

Mean KL Divergence: 0.00322
SB3 Clip Fraction: 0.02243
Policy Update Magnitude: 0.22461
Value Function Update Magnitude: 0.29997

Collected Steps per Second: 22,237.25551
Overall Steps per Second: 10,706.83750

Timestep Collection Time: 2.24938
Timestep Consumption Time: 2.42240
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.67178

Cumulative Model Updates: 373,276
Cumulative Timesteps: 3,113,134,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.90643
Policy Entropy: 4.04211
Value Function Loss: 0.00508

Mean KL Divergence: 0.00290
SB3 Clip Fraction: 0.02032
Policy Update Magnitude: 0.22206
Value Function Update Magnitude: 0.29073

Collected Steps per Second: 22,679.77775
Overall Steps per Second: 10,759.73777

Timestep Collection Time: 2.20540
Timestep Consumption Time: 2.44323
PPO Batch Consumption Time: 0.28004
Total Iteration Time: 4.64863

Cumulative Model Updates: 373,282
Cumulative Timesteps: 3,113,184,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3113184960...
Checkpoint 3113184960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.28434
Policy Entropy: 4.00288
Value Function Loss: 0.00624

Mean KL Divergence: 0.00323
SB3 Clip Fraction: 0.02257
Policy Update Magnitude: 0.23328
Value Function Update Magnitude: 0.28663

Collected Steps per Second: 22,226.02397
Overall Steps per Second: 10,745.52753

Timestep Collection Time: 2.25043
Timestep Consumption Time: 2.40435
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.65477

Cumulative Model Updates: 373,288
Cumulative Timesteps: 3,113,234,978

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8.82077
Policy Entropy: 4.03111
Value Function Loss: 0.00675

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02089
Policy Update Magnitude: 0.24005
Value Function Update Magnitude: 0.30463

Collected Steps per Second: 22,440.81504
Overall Steps per Second: 10,540.39479

Timestep Collection Time: 2.22897
Timestep Consumption Time: 2.51658
PPO Batch Consumption Time: 0.29285
Total Iteration Time: 4.74555

Cumulative Model Updates: 373,294
Cumulative Timesteps: 3,113,284,998

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3113284998...
Checkpoint 3113284998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.51878
Policy Entropy: 4.02719
Value Function Loss: 0.00606

Mean KL Divergence: 0.00326
SB3 Clip Fraction: 0.02311
Policy Update Magnitude: 0.22473
Value Function Update Magnitude: 0.31555

Collected Steps per Second: 22,223.02387
Overall Steps per Second: 10,563.31916

Timestep Collection Time: 2.25091
Timestep Consumption Time: 2.48453
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.73544

Cumulative Model Updates: 373,300
Cumulative Timesteps: 3,113,335,020

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.44778
Policy Entropy: 4.04950
Value Function Loss: 0.00534

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02236
Policy Update Magnitude: 0.21944
Value Function Update Magnitude: 0.31385

Collected Steps per Second: 23,583.83570
Overall Steps per Second: 10,958.37965

Timestep Collection Time: 2.12052
Timestep Consumption Time: 2.44311
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.56363

Cumulative Model Updates: 373,306
Cumulative Timesteps: 3,113,385,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3113385030...
Checkpoint 3113385030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.73062
Policy Entropy: 3.97724
Value Function Loss: 0.00549

Mean KL Divergence: 0.00301
SB3 Clip Fraction: 0.02273
Policy Update Magnitude: 0.22301
Value Function Update Magnitude: 0.31472

Collected Steps per Second: 22,037.81362
Overall Steps per Second: 10,566.14993

Timestep Collection Time: 2.27001
Timestep Consumption Time: 2.46455
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.73455

Cumulative Model Updates: 373,312
Cumulative Timesteps: 3,113,435,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.55237
Policy Entropy: 3.95964
Value Function Loss: 0.00606

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.24168
Value Function Update Magnitude: 0.33080

Collected Steps per Second: 22,230.99229
Overall Steps per Second: 10,704.24266

Timestep Collection Time: 2.25109
Timestep Consumption Time: 2.42406
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.67516

Cumulative Model Updates: 373,318
Cumulative Timesteps: 3,113,485,100

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 3113485100...
Checkpoint 3113485100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.77667
Policy Entropy: 3.88631
Value Function Loss: 0.00601

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.02630
Policy Update Magnitude: 0.25424
Value Function Update Magnitude: 0.33330

Collected Steps per Second: 22,572.11512
Overall Steps per Second: 10,628.56960

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.49127
PPO Batch Consumption Time: 0.28886
Total Iteration Time: 4.70825

Cumulative Model Updates: 373,324
Cumulative Timesteps: 3,113,535,142

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.14162
Policy Entropy: 3.92662
Value Function Loss: 0.00589

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02642
Policy Update Magnitude: 0.24770
Value Function Update Magnitude: 0.31514

Collected Steps per Second: 22,479.01004
Overall Steps per Second: 10,677.72989

Timestep Collection Time: 2.22474
Timestep Consumption Time: 2.45884
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.68358

Cumulative Model Updates: 373,330
Cumulative Timesteps: 3,113,585,152

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3113585152...
Checkpoint 3113585152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.05010
Policy Entropy: 3.92723
Value Function Loss: 0.00616

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.02540
Policy Update Magnitude: 0.24258
Value Function Update Magnitude: 0.30037

Collected Steps per Second: 22,302.50633
Overall Steps per Second: 10,650.86388

Timestep Collection Time: 2.24226
Timestep Consumption Time: 2.45295
PPO Batch Consumption Time: 0.29297
Total Iteration Time: 4.69521

Cumulative Model Updates: 373,336
Cumulative Timesteps: 3,113,635,160

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.59555
Policy Entropy: 3.94732
Value Function Loss: 0.00615

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02338
Policy Update Magnitude: 0.24471
Value Function Update Magnitude: 0.30488

Collected Steps per Second: 22,457.07401
Overall Steps per Second: 10,506.51105

Timestep Collection Time: 2.22718
Timestep Consumption Time: 2.53329
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.76048

Cumulative Model Updates: 373,342
Cumulative Timesteps: 3,113,685,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3113685176...
Checkpoint 3113685176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.33223
Policy Entropy: 3.94138
Value Function Loss: 0.00683

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02348
Policy Update Magnitude: 0.25481
Value Function Update Magnitude: 0.31436

Collected Steps per Second: 22,402.75203
Overall Steps per Second: 10,617.54677

Timestep Collection Time: 2.23312
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.71182

Cumulative Model Updates: 373,348
Cumulative Timesteps: 3,113,735,204

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6.64096
Policy Entropy: 3.94797
Value Function Loss: 0.00735

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02512
Policy Update Magnitude: 0.25538
Value Function Update Magnitude: 0.31551

Collected Steps per Second: 22,366.37079
Overall Steps per Second: 10,841.56042

Timestep Collection Time: 2.23675
Timestep Consumption Time: 2.37771
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.61446

Cumulative Model Updates: 373,354
Cumulative Timesteps: 3,113,785,232

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3113785232...
Checkpoint 3113785232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.13121
Policy Entropy: 3.96307
Value Function Loss: 0.00723

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02829
Policy Update Magnitude: 0.24695
Value Function Update Magnitude: 0.30768

Collected Steps per Second: 22,304.83570
Overall Steps per Second: 10,649.30343

Timestep Collection Time: 2.24211
Timestep Consumption Time: 2.45397
PPO Batch Consumption Time: 0.28084
Total Iteration Time: 4.69608

Cumulative Model Updates: 373,360
Cumulative Timesteps: 3,113,835,242

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.77636
Policy Entropy: 3.96153
Value Function Loss: 0.00702

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.02690
Policy Update Magnitude: 0.23702
Value Function Update Magnitude: 0.29672

Collected Steps per Second: 22,560.72022
Overall Steps per Second: 10,597.19799

Timestep Collection Time: 2.21731
Timestep Consumption Time: 2.50319
PPO Batch Consumption Time: 0.29293
Total Iteration Time: 4.72049

Cumulative Model Updates: 373,366
Cumulative Timesteps: 3,113,885,266

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3113885266...
Checkpoint 3113885266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.28858
Policy Entropy: 3.95434
Value Function Loss: 0.00660

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02686
Policy Update Magnitude: 0.23072
Value Function Update Magnitude: 0.29869

Collected Steps per Second: 22,279.09979
Overall Steps per Second: 10,749.93859

Timestep Collection Time: 2.24470
Timestep Consumption Time: 2.40741
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.65212

Cumulative Model Updates: 373,372
Cumulative Timesteps: 3,113,935,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.86718
Policy Entropy: 3.95705
Value Function Loss: 0.00681

Mean KL Divergence: 0.00288
SB3 Clip Fraction: 0.02223
Policy Update Magnitude: 0.23752
Value Function Update Magnitude: 0.32347

Collected Steps per Second: 22,743.50454
Overall Steps per Second: 10,765.90888

Timestep Collection Time: 2.20036
Timestep Consumption Time: 2.44801
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.64838

Cumulative Model Updates: 373,378
Cumulative Timesteps: 3,113,985,320

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 3113985320...
Checkpoint 3113985320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.16573
Policy Entropy: 3.95706
Value Function Loss: 0.00640

Mean KL Divergence: 0.00364
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.24940
Value Function Update Magnitude: 0.34317

Collected Steps per Second: 22,430.90580
Overall Steps per Second: 10,596.36694

Timestep Collection Time: 2.22969
Timestep Consumption Time: 2.49023
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.71992

Cumulative Model Updates: 373,384
Cumulative Timesteps: 3,114,035,334

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.98117
Policy Entropy: 3.97227
Value Function Loss: 0.00668

Mean KL Divergence: 0.00460
SB3 Clip Fraction: 0.02913
Policy Update Magnitude: 0.24607
Value Function Update Magnitude: 0.34851

Collected Steps per Second: 23,136.08986
Overall Steps per Second: 10,861.19451

Timestep Collection Time: 2.16234
Timestep Consumption Time: 2.44379
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60612

Cumulative Model Updates: 373,390
Cumulative Timesteps: 3,114,085,362

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3114085362...
Checkpoint 3114085362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.76475
Policy Entropy: 4.01147
Value Function Loss: 0.00590

Mean KL Divergence: 0.00384
SB3 Clip Fraction: 0.02578
Policy Update Magnitude: 0.24236
Value Function Update Magnitude: 0.35166

Collected Steps per Second: 22,314.64380
Overall Steps per Second: 10,718.01735

Timestep Collection Time: 2.24077
Timestep Consumption Time: 2.42446
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.66523

Cumulative Model Updates: 373,396
Cumulative Timesteps: 3,114,135,364

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.94710
Policy Entropy: 3.97720
Value Function Loss: 0.00614

Mean KL Divergence: 0.00362
SB3 Clip Fraction: 0.02576
Policy Update Magnitude: 0.24047
Value Function Update Magnitude: 0.34782

Collected Steps per Second: 22,526.73056
Overall Steps per Second: 10,761.97680

Timestep Collection Time: 2.21959
Timestep Consumption Time: 2.42640
PPO Batch Consumption Time: 0.28066
Total Iteration Time: 4.64599

Cumulative Model Updates: 373,402
Cumulative Timesteps: 3,114,185,364

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3114185364...
Checkpoint 3114185364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.68954
Policy Entropy: 3.98483
Value Function Loss: 0.00635

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.02290
Policy Update Magnitude: 0.24640
Value Function Update Magnitude: 0.32748

Collected Steps per Second: 23,051.35383
Overall Steps per Second: 10,756.32935

Timestep Collection Time: 2.16976
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.64991

Cumulative Model Updates: 373,408
Cumulative Timesteps: 3,114,235,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.05867
Policy Entropy: 3.96108
Value Function Loss: 0.00686

Mean KL Divergence: 0.00336
SB3 Clip Fraction: 0.02423
Policy Update Magnitude: 0.24822
Value Function Update Magnitude: 0.32783

Collected Steps per Second: 22,464.39322
Overall Steps per Second: 10,548.50787

Timestep Collection Time: 2.22779
Timestep Consumption Time: 2.51658
PPO Batch Consumption Time: 0.29388
Total Iteration Time: 4.74437

Cumulative Model Updates: 373,414
Cumulative Timesteps: 3,114,285,426

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 3114285426...
Checkpoint 3114285426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.14079
Policy Entropy: 4.01746
Value Function Loss: 0.00677

Mean KL Divergence: 0.00334
SB3 Clip Fraction: 0.02392
Policy Update Magnitude: 0.23966
Value Function Update Magnitude: 0.33195

Collected Steps per Second: 22,295.26306
Overall Steps per Second: 10,542.30931

Timestep Collection Time: 2.24362
Timestep Consumption Time: 2.50127
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.74488

Cumulative Model Updates: 373,420
Cumulative Timesteps: 3,114,335,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.74155
Policy Entropy: 4.04397
Value Function Loss: 0.00573

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02347
Policy Update Magnitude: 0.22554
Value Function Update Magnitude: 0.31555

Collected Steps per Second: 22,059.27140
Overall Steps per Second: 10,504.91939

Timestep Collection Time: 2.26726
Timestep Consumption Time: 2.49375
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.76101

Cumulative Model Updates: 373,426
Cumulative Timesteps: 3,114,385,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3114385462...
Checkpoint 3114385462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.37756
Policy Entropy: 4.04326
Value Function Loss: 0.00605

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02519
Policy Update Magnitude: 0.22818
Value Function Update Magnitude: 0.31260

Collected Steps per Second: 21,833.42626
Overall Steps per Second: 10,528.51357

Timestep Collection Time: 2.29043
Timestep Consumption Time: 2.45934
PPO Batch Consumption Time: 0.27998
Total Iteration Time: 4.74977

Cumulative Model Updates: 373,432
Cumulative Timesteps: 3,114,435,470

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.08154
Policy Entropy: 4.01954
Value Function Loss: 0.00623

Mean KL Divergence: 0.00305
SB3 Clip Fraction: 0.02102
Policy Update Magnitude: 0.24653
Value Function Update Magnitude: 0.32124

Collected Steps per Second: 22,266.58025
Overall Steps per Second: 10,722.96246

Timestep Collection Time: 2.24597
Timestep Consumption Time: 2.41786
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.66382

Cumulative Model Updates: 373,438
Cumulative Timesteps: 3,114,485,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3114485480...
Checkpoint 3114485480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35.46851
Policy Entropy: 3.98769
Value Function Loss: 0.00696

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02261
Policy Update Magnitude: 0.25092
Value Function Update Magnitude: 0.33626

Collected Steps per Second: 22,342.11566
Overall Steps per Second: 10,552.91666

Timestep Collection Time: 2.23828
Timestep Consumption Time: 2.50050
PPO Batch Consumption Time: 0.29367
Total Iteration Time: 4.73878

Cumulative Model Updates: 373,444
Cumulative Timesteps: 3,114,535,488

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.98084
Policy Entropy: 4.01802
Value Function Loss: 0.00622

Mean KL Divergence: 0.00293
SB3 Clip Fraction: 0.02229
Policy Update Magnitude: 0.24160
Value Function Update Magnitude: 0.34680

Collected Steps per Second: 22,592.01359
Overall Steps per Second: 10,763.53136

Timestep Collection Time: 2.21326
Timestep Consumption Time: 2.43224
PPO Batch Consumption Time: 0.28009
Total Iteration Time: 4.64550

Cumulative Model Updates: 373,450
Cumulative Timesteps: 3,114,585,490

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3114585490...
Checkpoint 3114585490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.87112
Policy Entropy: 4.02420
Value Function Loss: 0.00671

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02094
Policy Update Magnitude: 0.23843
Value Function Update Magnitude: 0.33761

Collected Steps per Second: 22,262.07585
Overall Steps per Second: 10,660.13223

Timestep Collection Time: 2.24633
Timestep Consumption Time: 2.44479
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.69112

Cumulative Model Updates: 373,456
Cumulative Timesteps: 3,114,635,498

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14.12535
Policy Entropy: 4.01244
Value Function Loss: 0.00640

Mean KL Divergence: 0.00279
SB3 Clip Fraction: 0.02030
Policy Update Magnitude: 0.23632
Value Function Update Magnitude: 0.33297

Collected Steps per Second: 22,659.28712
Overall Steps per Second: 10,582.63238

Timestep Collection Time: 2.20722
Timestep Consumption Time: 2.51883
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.72605

Cumulative Model Updates: 373,462
Cumulative Timesteps: 3,114,685,512

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3114685512...
Checkpoint 3114685512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.45149
Policy Entropy: 3.98486
Value Function Loss: 0.00667

Mean KL Divergence: 0.00339
SB3 Clip Fraction: 0.02461
Policy Update Magnitude: 0.23569
Value Function Update Magnitude: 0.32369

Collected Steps per Second: 22,420.04521
Overall Steps per Second: 10,612.32023

Timestep Collection Time: 2.23086
Timestep Consumption Time: 2.48215
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.71301

Cumulative Model Updates: 373,468
Cumulative Timesteps: 3,114,735,528

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.39387
Policy Entropy: 4.00485
Value Function Loss: 0.00570

Mean KL Divergence: 0.00309
SB3 Clip Fraction: 0.02369
Policy Update Magnitude: 0.23054
Value Function Update Magnitude: 0.32281

Collected Steps per Second: 22,665.06023
Overall Steps per Second: 10,835.16099

Timestep Collection Time: 2.20604
Timestep Consumption Time: 2.40857
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.61461

Cumulative Model Updates: 373,474
Cumulative Timesteps: 3,114,785,528

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3114785528...
Checkpoint 3114785528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.18497
Policy Entropy: 4.01118
Value Function Loss: 0.00572

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.23041
Value Function Update Magnitude: 0.30996

Collected Steps per Second: 22,378.97978
Overall Steps per Second: 10,619.28422

Timestep Collection Time: 2.23504
Timestep Consumption Time: 2.47507
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.71011

Cumulative Model Updates: 373,480
Cumulative Timesteps: 3,114,835,546

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7.23155
Policy Entropy: 3.98770
Value Function Loss: 0.00593

Mean KL Divergence: 0.00314
SB3 Clip Fraction: 0.02368
Policy Update Magnitude: 0.23409
Value Function Update Magnitude: 0.31397

Collected Steps per Second: 22,378.62959
Overall Steps per Second: 10,562.69613

Timestep Collection Time: 2.23561
Timestep Consumption Time: 2.50087
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.73648

Cumulative Model Updates: 373,486
Cumulative Timesteps: 3,114,885,576

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3114885576...
Checkpoint 3114885576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.87478
Policy Entropy: 3.94076
Value Function Loss: 0.00643

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.02862
Policy Update Magnitude: 0.24507
Value Function Update Magnitude: 0.32346

Collected Steps per Second: 23,117.70257
Overall Steps per Second: 10,731.25991

Timestep Collection Time: 2.16423
Timestep Consumption Time: 2.49804
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.66227

Cumulative Model Updates: 373,492
Cumulative Timesteps: 3,114,935,608

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.35694
Policy Entropy: 3.91556
Value Function Loss: 0.00671

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.02909
Policy Update Magnitude: 0.25028
Value Function Update Magnitude: 0.31530

Collected Steps per Second: 22,571.23564
Overall Steps per Second: 10,713.69389

Timestep Collection Time: 2.21618
Timestep Consumption Time: 2.45279
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.66898

Cumulative Model Updates: 373,498
Cumulative Timesteps: 3,114,985,630

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3114985630...
Checkpoint 3114985630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.15307
Policy Entropy: 3.89666
Value Function Loss: 0.00797

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.02972
Policy Update Magnitude: 0.26606
Value Function Update Magnitude: 0.32773

Collected Steps per Second: 22,367.43500
Overall Steps per Second: 10,708.38660

Timestep Collection Time: 2.23620
Timestep Consumption Time: 2.43472
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 4.67092

Cumulative Model Updates: 373,504
Cumulative Timesteps: 3,115,035,648

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38.11665
Policy Entropy: 3.92336
Value Function Loss: 0.00716

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.03120
Policy Update Magnitude: 0.26349
Value Function Update Magnitude: 0.34898

Collected Steps per Second: 22,546.09342
Overall Steps per Second: 10,586.51051

Timestep Collection Time: 2.21777
Timestep Consumption Time: 2.50541
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.72318

Cumulative Model Updates: 373,510
Cumulative Timesteps: 3,115,085,650

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3115085650...
Checkpoint 3115085650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.04984
Policy Entropy: 3.97119
Value Function Loss: 0.00658

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.02922
Policy Update Magnitude: 0.25968
Value Function Update Magnitude: 0.35277

Collected Steps per Second: 22,413.12427
Overall Steps per Second: 10,659.46907

Timestep Collection Time: 2.23137
Timestep Consumption Time: 2.46042
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.69179

Cumulative Model Updates: 373,516
Cumulative Timesteps: 3,115,135,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.67501
Policy Entropy: 3.98432
Value Function Loss: 0.00594

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02447
Policy Update Magnitude: 0.24249
Value Function Update Magnitude: 0.33283

Collected Steps per Second: 22,559.48516
Overall Steps per Second: 10,757.49654

Timestep Collection Time: 2.21663
Timestep Consumption Time: 2.43185
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.64848

Cumulative Model Updates: 373,522
Cumulative Timesteps: 3,115,185,668

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3115185668...
Checkpoint 3115185668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5.67257
Policy Entropy: 3.96819
Value Function Loss: 0.00739

Mean KL Divergence: 0.00296
SB3 Clip Fraction: 0.02491
Policy Update Magnitude: 0.25485
Value Function Update Magnitude: 0.32847

Collected Steps per Second: 22,328.55107
Overall Steps per Second: 10,566.30064

Timestep Collection Time: 2.23982
Timestep Consumption Time: 2.49334
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.73316

Cumulative Model Updates: 373,528
Cumulative Timesteps: 3,115,235,680

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.92648
Policy Entropy: 3.97796
Value Function Loss: 0.00762

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02564
Policy Update Magnitude: 0.25597
Value Function Update Magnitude: 0.33350

Collected Steps per Second: 22,205.05709
Overall Steps per Second: 10,552.28491

Timestep Collection Time: 2.25237
Timestep Consumption Time: 2.48727
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.73964

Cumulative Model Updates: 373,534
Cumulative Timesteps: 3,115,285,694

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3115285694...
Checkpoint 3115285694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.85408
Policy Entropy: 3.97718
Value Function Loss: 0.00747

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.02957
Policy Update Magnitude: 0.25876
Value Function Update Magnitude: 0.33584

Collected Steps per Second: 23,003.67170
Overall Steps per Second: 10,564.99458

Timestep Collection Time: 2.17365
Timestep Consumption Time: 2.55915
PPO Batch Consumption Time: 0.30165
Total Iteration Time: 4.73280

Cumulative Model Updates: 373,540
Cumulative Timesteps: 3,115,335,696

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.62133
Policy Entropy: 3.96589
Value Function Loss: 0.00726

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.02761
Policy Update Magnitude: 0.26857
Value Function Update Magnitude: 0.32861

Collected Steps per Second: 21,234.04702
Overall Steps per Second: 10,367.96704

Timestep Collection Time: 2.35490
Timestep Consumption Time: 2.46803
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.82293

Cumulative Model Updates: 373,546
Cumulative Timesteps: 3,115,385,700

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3115385700...
Checkpoint 3115385700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9.96931
Policy Entropy: 3.94792
Value Function Loss: 0.00714

Mean KL Divergence: 0.00399
SB3 Clip Fraction: 0.02908
Policy Update Magnitude: 0.26376
Value Function Update Magnitude: 0.34029

Collected Steps per Second: 22,271.45605
Overall Steps per Second: 10,685.64125

Timestep Collection Time: 2.24548
Timestep Consumption Time: 2.43464
PPO Batch Consumption Time: 0.28041
Total Iteration Time: 4.68011

Cumulative Model Updates: 373,552
Cumulative Timesteps: 3,115,435,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.12018
Policy Entropy: 3.97018
Value Function Loss: 0.00700

Mean KL Divergence: 0.00385
SB3 Clip Fraction: 0.02778
Policy Update Magnitude: 0.24942
Value Function Update Magnitude: 0.33563

Collected Steps per Second: 23,024.30018
Overall Steps per Second: 10,663.70797

Timestep Collection Time: 2.17301
Timestep Consumption Time: 2.51879
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.69180

Cumulative Model Updates: 373,558
Cumulative Timesteps: 3,115,485,742

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3115485742...
Checkpoint 3115485742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.19894
Policy Entropy: 4.00071
Value Function Loss: 0.00627

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02486
Policy Update Magnitude: 0.23828
Value Function Update Magnitude: 0.30994

Collected Steps per Second: 22,599.72576
Overall Steps per Second: 10,622.55441

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.49535
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.70847

Cumulative Model Updates: 373,564
Cumulative Timesteps: 3,115,535,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10.75802
Policy Entropy: 4.03465
Value Function Loss: 0.00561

Mean KL Divergence: 0.00292
SB3 Clip Fraction: 0.02217
Policy Update Magnitude: 0.22927
Value Function Update Magnitude: 0.30184

Collected Steps per Second: 22,558.58236
Overall Steps per Second: 10,756.58752

Timestep Collection Time: 2.21716
Timestep Consumption Time: 2.43264
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.64980

Cumulative Model Updates: 373,570
Cumulative Timesteps: 3,115,585,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3115585774...
Checkpoint 3115585774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.18654
Policy Entropy: 4.02384
Value Function Loss: 0.00609

Mean KL Divergence: 0.00321
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.22750
Value Function Update Magnitude: 0.29711

Collected Steps per Second: 22,389.91498
Overall Steps per Second: 10,700.65538

Timestep Collection Time: 2.23324
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.67280

Cumulative Model Updates: 373,576
Cumulative Timesteps: 3,115,635,776

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.59445
Policy Entropy: 4.01315
Value Function Loss: 0.00691

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02448
Policy Update Magnitude: 0.23484
Value Function Update Magnitude: 0.32048

Collected Steps per Second: 22,217.02645
Overall Steps per Second: 10,472.05121

Timestep Collection Time: 2.25098
Timestep Consumption Time: 2.52459
PPO Batch Consumption Time: 0.29296
Total Iteration Time: 4.77557

Cumulative Model Updates: 373,582
Cumulative Timesteps: 3,115,685,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3115685786...
Checkpoint 3115685786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.26630
Policy Entropy: 3.97002
Value Function Loss: 0.00700

Mean KL Divergence: 0.00357
SB3 Clip Fraction: 0.02421
Policy Update Magnitude: 0.24393
Value Function Update Magnitude: 0.34025

Collected Steps per Second: 22,446.29432
Overall Steps per Second: 10,760.39709

Timestep Collection Time: 2.22879
Timestep Consumption Time: 2.42048
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.64927

Cumulative Model Updates: 373,588
Cumulative Timesteps: 3,115,735,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.62760
Policy Entropy: 3.96483
Value Function Loss: 0.00653

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.02627
Policy Update Magnitude: 0.24997
Value Function Update Magnitude: 0.33499

Collected Steps per Second: 22,727.00218
Overall Steps per Second: 10,731.94619

Timestep Collection Time: 2.20091
Timestep Consumption Time: 2.45994
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.66085

Cumulative Model Updates: 373,594
Cumulative Timesteps: 3,115,785,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3115785834...
Checkpoint 3115785834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8.28238
Policy Entropy: 3.92754
Value Function Loss: 0.00678

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02531
Policy Update Magnitude: 0.25121
Value Function Update Magnitude: 0.33413

Collected Steps per Second: 22,216.07354
Overall Steps per Second: 10,644.89465

Timestep Collection Time: 2.25197
Timestep Consumption Time: 2.44793
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.69991

Cumulative Model Updates: 373,600
Cumulative Timesteps: 3,115,835,864

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5.81525
Policy Entropy: 3.96169
Value Function Loss: 0.00605

Mean KL Divergence: 0.00352
SB3 Clip Fraction: 0.02738
Policy Update Magnitude: 0.24934
Value Function Update Magnitude: 0.34503

Collected Steps per Second: 22,282.58853
Overall Steps per Second: 10,834.46379

Timestep Collection Time: 2.24507
Timestep Consumption Time: 2.37223
PPO Batch Consumption Time: 0.28015
Total Iteration Time: 4.61730

Cumulative Model Updates: 373,606
Cumulative Timesteps: 3,115,885,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3115885890...
Checkpoint 3115885890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.45594
Policy Entropy: 4.00739
Value Function Loss: 0.00599

Mean KL Divergence: 0.00354
SB3 Clip Fraction: 0.02661
Policy Update Magnitude: 0.23983
Value Function Update Magnitude: 0.33095

Collected Steps per Second: 22,419.43503
Overall Steps per Second: 10,695.45615

Timestep Collection Time: 2.23074
Timestep Consumption Time: 2.44526
PPO Batch Consumption Time: 0.28043
Total Iteration Time: 4.67600

Cumulative Model Updates: 373,612
Cumulative Timesteps: 3,115,935,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.89321
Policy Entropy: 4.03877
Value Function Loss: 0.00637

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02449
Policy Update Magnitude: 0.23138
Value Function Update Magnitude: 0.32620

Collected Steps per Second: 22,404.37460
Overall Steps per Second: 10,872.39445

Timestep Collection Time: 2.23260
Timestep Consumption Time: 2.36804
PPO Batch Consumption Time: 0.28036
Total Iteration Time: 4.60064

Cumulative Model Updates: 373,618
Cumulative Timesteps: 3,115,985,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3115985922...
Checkpoint 3115985922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.46886
Policy Entropy: 4.04794
Value Function Loss: 0.00628

Mean KL Divergence: 0.00300
SB3 Clip Fraction: 0.02363
Policy Update Magnitude: 0.23701
Value Function Update Magnitude: 0.34677

Collected Steps per Second: 22,259.01900
Overall Steps per Second: 10,663.59725

Timestep Collection Time: 2.24736
Timestep Consumption Time: 2.44374
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.69110

Cumulative Model Updates: 373,624
Cumulative Timesteps: 3,116,035,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.23335
Policy Entropy: 3.99960
Value Function Loss: 0.00669

Mean KL Divergence: 0.00349
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.24390
Value Function Update Magnitude: 0.35511

Collected Steps per Second: 22,251.83499
Overall Steps per Second: 10,545.97272

Timestep Collection Time: 2.24790
Timestep Consumption Time: 2.49514
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.74304

Cumulative Model Updates: 373,630
Cumulative Timesteps: 3,116,085,966

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3116085966...
Checkpoint 3116085966 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14.13883
Policy Entropy: 4.01508
Value Function Loss: 0.00622

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02379
Policy Update Magnitude: 0.24268
Value Function Update Magnitude: 0.35222

Collected Steps per Second: 22,039.41556
Overall Steps per Second: 10,659.22829

Timestep Collection Time: 2.26866
Timestep Consumption Time: 2.42211
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.69077

Cumulative Model Updates: 373,636
Cumulative Timesteps: 3,116,135,966

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.25881
Policy Entropy: 4.01065
Value Function Loss: 0.00574

Mean KL Divergence: 0.00295
SB3 Clip Fraction: 0.02328
Policy Update Magnitude: 0.24181
Value Function Update Magnitude: 0.35723

Collected Steps per Second: 22,430.62211
Overall Steps per Second: 10,540.43580

Timestep Collection Time: 2.22972
Timestep Consumption Time: 2.51525
PPO Batch Consumption Time: 0.29381
Total Iteration Time: 4.74497

Cumulative Model Updates: 373,642
Cumulative Timesteps: 3,116,185,980

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3116185980...
Checkpoint 3116185980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37.00877
Policy Entropy: 3.98716
Value Function Loss: 0.00550

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.02079
Policy Update Magnitude: 0.23795
Value Function Update Magnitude: 0.33695

Collected Steps per Second: 20,486.91130
Overall Steps per Second: 10,378.60105

Timestep Collection Time: 2.44127
Timestep Consumption Time: 2.37769
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.81895

Cumulative Model Updates: 373,648
Cumulative Timesteps: 3,116,235,994

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.95254
Policy Entropy: 3.95883
Value Function Loss: 0.00630

Mean KL Divergence: 0.00306
SB3 Clip Fraction: 0.02332
Policy Update Magnitude: 0.23280
Value Function Update Magnitude: 0.32763

Collected Steps per Second: 21,730.11810
Overall Steps per Second: 10,615.48452

Timestep Collection Time: 2.30095
Timestep Consumption Time: 2.40915
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.71010

Cumulative Model Updates: 373,654
Cumulative Timesteps: 3,116,285,994

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3116285994...
Checkpoint 3116285994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.07611
Policy Entropy: 3.93063
Value Function Loss: 0.00681

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.02353
Policy Update Magnitude: 0.23696
Value Function Update Magnitude: 0.34652

Collected Steps per Second: 22,098.93779
Overall Steps per Second: 10,650.15134

Timestep Collection Time: 2.26319
Timestep Consumption Time: 2.43290
PPO Batch Consumption Time: 0.28097
Total Iteration Time: 4.69608

Cumulative Model Updates: 373,660
Cumulative Timesteps: 3,116,336,008

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.49610
Policy Entropy: 3.94309
Value Function Loss: 0.00756

Mean KL Divergence: 0.00344
SB3 Clip Fraction: 0.02662
Policy Update Magnitude: 0.24836
Value Function Update Magnitude: 0.36488

Collected Steps per Second: 22,653.02762
Overall Steps per Second: 10,702.82536

Timestep Collection Time: 2.20783
Timestep Consumption Time: 2.46514
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.67297

Cumulative Model Updates: 373,666
Cumulative Timesteps: 3,116,386,022

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3116386022...
Checkpoint 3116386022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.93902
Policy Entropy: 3.93387
Value Function Loss: 0.00667

Mean KL Divergence: 0.00340
SB3 Clip Fraction: 0.02624
Policy Update Magnitude: 0.24783
Value Function Update Magnitude: 0.37091

Collected Steps per Second: 23,326.06324
Overall Steps per Second: 10,883.26531

Timestep Collection Time: 2.14413
Timestep Consumption Time: 2.45137
PPO Batch Consumption Time: 0.28078
Total Iteration Time: 4.59550

Cumulative Model Updates: 373,672
Cumulative Timesteps: 3,116,436,036

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.96492
Policy Entropy: 3.92496
Value Function Loss: 0.00620

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.02912
Policy Update Magnitude: 0.24636
Value Function Update Magnitude: 0.36325

Collected Steps per Second: 22,387.14442
Overall Steps per Second: 10,521.43565

Timestep Collection Time: 2.23405
Timestep Consumption Time: 2.51948
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.75353

Cumulative Model Updates: 373,678
Cumulative Timesteps: 3,116,486,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3116486050...
Checkpoint 3116486050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.12368
Policy Entropy: 3.94723
Value Function Loss: 0.00535

Mean KL Divergence: 0.00401
SB3 Clip Fraction: 0.03121
Policy Update Magnitude: 0.24026
Value Function Update Magnitude: 0.33251

Collected Steps per Second: 22,602.29641
Overall Steps per Second: 10,635.76520

Timestep Collection Time: 2.21216
Timestep Consumption Time: 2.48895
PPO Batch Consumption Time: 0.29382
Total Iteration Time: 4.70112

Cumulative Model Updates: 373,684
Cumulative Timesteps: 3,116,536,050

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.06782
Policy Entropy: 3.94334
Value Function Loss: 0.00605

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02747
Policy Update Magnitude: 0.25009
Value Function Update Magnitude: 0.30927

Collected Steps per Second: 22,607.71550
Overall Steps per Second: 10,804.18299

Timestep Collection Time: 2.21225
Timestep Consumption Time: 2.41688
PPO Batch Consumption Time: 0.28632
Total Iteration Time: 4.62913

Cumulative Model Updates: 373,690
Cumulative Timesteps: 3,116,586,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3116586064...
Checkpoint 3116586064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15.11578
Policy Entropy: 3.98521
Value Function Loss: 0.00653

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.02811
Policy Update Magnitude: 0.25696
Value Function Update Magnitude: 0.31966

Collected Steps per Second: 22,891.33171
Overall Steps per Second: 10,674.63570

Timestep Collection Time: 2.18511
Timestep Consumption Time: 2.50077
PPO Batch Consumption Time: 0.28874
Total Iteration Time: 4.68587

Cumulative Model Updates: 373,696
Cumulative Timesteps: 3,116,636,084

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21.98659
Policy Entropy: 3.96632
Value Function Loss: 0.00736

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02670
Policy Update Magnitude: 0.25649
Value Function Update Magnitude: 0.33983

Collected Steps per Second: 22,549.25435
Overall Steps per Second: 10,655.73149

Timestep Collection Time: 2.21772
Timestep Consumption Time: 2.47534
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69306

Cumulative Model Updates: 373,702
Cumulative Timesteps: 3,116,686,092

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 3116686092...
Checkpoint 3116686092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.58506
Policy Entropy: 3.99504
Value Function Loss: 0.00660

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02272
Policy Update Magnitude: 0.25372
Value Function Update Magnitude: 0.34625

Collected Steps per Second: 22,381.14118
Overall Steps per Second: 10,914.30103

Timestep Collection Time: 2.23519
Timestep Consumption Time: 2.34834
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.58353

Cumulative Model Updates: 373,708
Cumulative Timesteps: 3,116,736,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.90735
Policy Entropy: 3.98806
Value Function Loss: 0.00619

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.02416
Policy Update Magnitude: 0.25477
Value Function Update Magnitude: 0.34848

Collected Steps per Second: 22,238.72037
Overall Steps per Second: 10,450.35713

Timestep Collection Time: 2.24968
Timestep Consumption Time: 2.53772
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 4.78740

Cumulative Model Updates: 373,714
Cumulative Timesteps: 3,116,786,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3116786148...
Checkpoint 3116786148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.58529
Policy Entropy: 4.00463
Value Function Loss: 0.00578

Mean KL Divergence: 0.00366
SB3 Clip Fraction: 0.02357
Policy Update Magnitude: 0.24400
Value Function Update Magnitude: 0.33763

Collected Steps per Second: 22,236.50717
Overall Steps per Second: 10,680.03489

Timestep Collection Time: 2.24945
Timestep Consumption Time: 2.43405
PPO Batch Consumption Time: 0.29457
Total Iteration Time: 4.68351

Cumulative Model Updates: 373,720
Cumulative Timesteps: 3,116,836,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.98988
Policy Entropy: 4.01431
Value Function Loss: 0.00539

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02466
Policy Update Magnitude: 0.22968
Value Function Update Magnitude: 0.32219

Collected Steps per Second: 22,580.85706
Overall Steps per Second: 10,564.24352

Timestep Collection Time: 2.21497
Timestep Consumption Time: 2.51949
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.73446

Cumulative Model Updates: 373,726
Cumulative Timesteps: 3,116,886,184

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3116886184...
Checkpoint 3116886184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.57081
Policy Entropy: 4.02855
Value Function Loss: 0.00517

Mean KL Divergence: 0.00319
SB3 Clip Fraction: 0.02561
Policy Update Magnitude: 0.22735
Value Function Update Magnitude: 0.30188

Collected Steps per Second: 22,438.91122
Overall Steps per Second: 10,533.37652

Timestep Collection Time: 2.22854
Timestep Consumption Time: 2.51885
PPO Batch Consumption Time: 0.29349
Total Iteration Time: 4.74739

Cumulative Model Updates: 373,732
Cumulative Timesteps: 3,116,936,190

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.00871
Policy Entropy: 4.04701
Value Function Loss: 0.00538

Mean KL Divergence: 0.00297
SB3 Clip Fraction: 0.02296
Policy Update Magnitude: 0.21871
Value Function Update Magnitude: 0.28641

Collected Steps per Second: 20,971.60646
Overall Steps per Second: 10,304.60735

Timestep Collection Time: 2.38551
Timestep Consumption Time: 2.46940
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.85492

Cumulative Model Updates: 373,738
Cumulative Timesteps: 3,116,986,218

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3116986218...
Checkpoint 3116986218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40.14294
Policy Entropy: 4.03734
Value Function Loss: 0.00715

Mean KL Divergence: 0.00303
SB3 Clip Fraction: 0.02299
Policy Update Magnitude: 0.22165
Value Function Update Magnitude: 0.30443

Collected Steps per Second: 19,869.72420
Overall Steps per Second: 9,715.24693

Timestep Collection Time: 2.51740
Timestep Consumption Time: 2.63121
PPO Batch Consumption Time: 0.31526
Total Iteration Time: 5.14861

Cumulative Model Updates: 373,744
Cumulative Timesteps: 3,117,036,238

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.34525
Policy Entropy: 3.99625
Value Function Loss: 0.00703

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02158
Policy Update Magnitude: 0.24436
Value Function Update Magnitude: 0.35193

Collected Steps per Second: 21,227.92890
Overall Steps per Second: 10,130.09401

Timestep Collection Time: 2.35614
Timestep Consumption Time: 2.58123
PPO Batch Consumption Time: 0.29821
Total Iteration Time: 4.93737

Cumulative Model Updates: 373,750
Cumulative Timesteps: 3,117,086,254

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3117086254...
Checkpoint 3117086254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.44939
Policy Entropy: 3.97826
Value Function Loss: 0.00614

Mean KL Divergence: 0.00347
SB3 Clip Fraction: 0.02543
Policy Update Magnitude: 0.24316
Value Function Update Magnitude: 0.36331

Collected Steps per Second: 20,430.78786
Overall Steps per Second: 9,892.71765

Timestep Collection Time: 2.44758
Timestep Consumption Time: 2.60725
PPO Batch Consumption Time: 0.32336
Total Iteration Time: 5.05483

Cumulative Model Updates: 373,756
Cumulative Timesteps: 3,117,136,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.77169
Policy Entropy: 3.96329
Value Function Loss: 0.00567

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.02678
Policy Update Magnitude: 0.24114
Value Function Update Magnitude: 0.34228

Collected Steps per Second: 20,655.72193
Overall Steps per Second: 9,684.50348

Timestep Collection Time: 2.42190
Timestep Consumption Time: 2.74368
PPO Batch Consumption Time: 0.32628
Total Iteration Time: 5.16557

Cumulative Model Updates: 373,762
Cumulative Timesteps: 3,117,186,286

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3117186286...
Checkpoint 3117186286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41.84631
Policy Entropy: 3.99542
Value Function Loss: 0.00567

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.02415
Policy Update Magnitude: 0.23645
Value Function Update Magnitude: 0.31704

Collected Steps per Second: 21,417.15134
Overall Steps per Second: 10,197.84018

Timestep Collection Time: 2.33467
Timestep Consumption Time: 2.56852
PPO Batch Consumption Time: 0.30083
Total Iteration Time: 4.90320

Cumulative Model Updates: 373,768
Cumulative Timesteps: 3,117,236,288

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.93937
Policy Entropy: 3.98642
Value Function Loss: 0.00592

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02408
Policy Update Magnitude: 0.23683
Value Function Update Magnitude: 0.31731

Collected Steps per Second: 21,122.42583
Overall Steps per Second: 10,293.91089

Timestep Collection Time: 2.36819
Timestep Consumption Time: 2.49118
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.85938

Cumulative Model Updates: 373,774
Cumulative Timesteps: 3,117,286,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 3117286310...
Checkpoint 3117286310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.14738
Policy Entropy: 3.98950
Value Function Loss: 0.00642

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.02033
Policy Update Magnitude: 0.24231
Value Function Update Magnitude: 0.32918

Collected Steps per Second: 22,078.34266
Overall Steps per Second: 9,731.94246

Timestep Collection Time: 2.26493
Timestep Consumption Time: 2.87340
PPO Batch Consumption Time: 0.33724
Total Iteration Time: 5.13834

Cumulative Model Updates: 373,780
Cumulative Timesteps: 3,117,336,316

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.18755
Policy Entropy: 3.97066
Value Function Loss: 0.00724

Mean KL Divergence: 0.00289
SB3 Clip Fraction: 0.02265
Policy Update Magnitude: 0.24825
Value Function Update Magnitude: 0.33959

Collected Steps per Second: 20,401.76025
Overall Steps per Second: 9,514.64162

Timestep Collection Time: 2.45165
Timestep Consumption Time: 2.80530
PPO Batch Consumption Time: 0.34040
Total Iteration Time: 5.25695

Cumulative Model Updates: 373,786
Cumulative Timesteps: 3,117,386,334

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3117386334...
Checkpoint 3117386334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.83558
Policy Entropy: 3.92280
Value Function Loss: 0.00724

Mean KL Divergence: 0.00342
SB3 Clip Fraction: 0.02537
Policy Update Magnitude: 0.26227
Value Function Update Magnitude: 0.35446

Collected Steps per Second: 21,034.59958
Overall Steps per Second: 9,627.18083

Timestep Collection Time: 2.37846
Timestep Consumption Time: 2.81828
PPO Batch Consumption Time: 0.33639
Total Iteration Time: 5.19674

Cumulative Model Updates: 373,792
Cumulative Timesteps: 3,117,436,364

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.28102
Policy Entropy: 3.94354
Value Function Loss: 0.00736

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.02823
Policy Update Magnitude: 0.26946
Value Function Update Magnitude: 0.36296

Collected Steps per Second: 19,414.03199
Overall Steps per Second: 9,861.05193

Timestep Collection Time: 2.57566
Timestep Consumption Time: 2.49520
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 5.07086

Cumulative Model Updates: 373,798
Cumulative Timesteps: 3,117,486,368

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3117486368...
Checkpoint 3117486368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.79368
Policy Entropy: 3.94643
Value Function Loss: 0.00717

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.02817
Policy Update Magnitude: 0.25847
Value Function Update Magnitude: 0.34627

Collected Steps per Second: 21,749.11427
Overall Steps per Second: 10,171.45245

Timestep Collection Time: 2.29959
Timestep Consumption Time: 2.61751
PPO Batch Consumption Time: 0.31533
Total Iteration Time: 4.91710

Cumulative Model Updates: 373,804
Cumulative Timesteps: 3,117,536,382

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30.05269
Policy Entropy: 3.97634
Value Function Loss: 0.00680

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02595
Policy Update Magnitude: 0.24946
Value Function Update Magnitude: 0.34108

Collected Steps per Second: 20,681.86990
Overall Steps per Second: 10,093.54234

Timestep Collection Time: 2.41845
Timestep Consumption Time: 2.53700
PPO Batch Consumption Time: 0.29371
Total Iteration Time: 4.95545

Cumulative Model Updates: 373,810
Cumulative Timesteps: 3,117,586,400

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3117586400...
Checkpoint 3117586400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.12185
Policy Entropy: 3.94090
Value Function Loss: 0.00715

Mean KL Divergence: 0.00358
SB3 Clip Fraction: 0.02692
Policy Update Magnitude: 0.26078
Value Function Update Magnitude: 0.35555

Collected Steps per Second: 16,271.07173
Overall Steps per Second: 8,575.22738

Timestep Collection Time: 3.07343
Timestep Consumption Time: 2.75825
PPO Batch Consumption Time: 0.31326
Total Iteration Time: 5.83168

Cumulative Model Updates: 373,816
Cumulative Timesteps: 3,117,636,408

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.97484
Policy Entropy: 3.97285
Value Function Loss: 0.00729

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.02914
Policy Update Magnitude: 0.25746
Value Function Update Magnitude: 0.35893

Collected Steps per Second: 19,257.09707
Overall Steps per Second: 9,922.98642

Timestep Collection Time: 2.59655
Timestep Consumption Time: 2.44246
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 5.03901

Cumulative Model Updates: 373,822
Cumulative Timesteps: 3,117,686,410

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3117686410...
Checkpoint 3117686410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.84996
Policy Entropy: 3.97217
Value Function Loss: 0.00721

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.02810
Policy Update Magnitude: 0.24871
Value Function Update Magnitude: 0.35034

Collected Steps per Second: 21,508.48287
Overall Steps per Second: 10,402.48793

Timestep Collection Time: 2.32532
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.80789

Cumulative Model Updates: 373,828
Cumulative Timesteps: 3,117,736,424

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.89394
Policy Entropy: 3.99486
Value Function Loss: 0.00653

Mean KL Divergence: 0.00286
SB3 Clip Fraction: 0.02206
Policy Update Magnitude: 0.24505
Value Function Update Magnitude: 0.33642

Collected Steps per Second: 22,005.19176
Overall Steps per Second: 10,684.32337

Timestep Collection Time: 2.27337
Timestep Consumption Time: 2.40881
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.68219

Cumulative Model Updates: 373,834
Cumulative Timesteps: 3,117,786,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3117786450...
Checkpoint 3117786450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.56382
Policy Entropy: 3.99666
Value Function Loss: 0.00588

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02735
Policy Update Magnitude: 0.23534
Value Function Update Magnitude: 0.33369

Collected Steps per Second: 20,274.40263
Overall Steps per Second: 9,609.87287

Timestep Collection Time: 2.46636
Timestep Consumption Time: 2.73704
PPO Batch Consumption Time: 0.31852
Total Iteration Time: 5.20340

Cumulative Model Updates: 373,840
Cumulative Timesteps: 3,117,836,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.04103
Policy Entropy: 4.02715
Value Function Loss: 0.00571

Mean KL Divergence: 0.00316
SB3 Clip Fraction: 0.02184
Policy Update Magnitude: 0.23273
Value Function Update Magnitude: 0.31749

Collected Steps per Second: 20,076.94544
Overall Steps per Second: 9,649.99767

Timestep Collection Time: 2.49171
Timestep Consumption Time: 2.69233
PPO Batch Consumption Time: 0.29999
Total Iteration Time: 5.18404

Cumulative Model Updates: 373,846
Cumulative Timesteps: 3,117,886,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3117886480...
Checkpoint 3117886480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.42358
Policy Entropy: 4.06293
Value Function Loss: 0.00569

Mean KL Divergence: 0.00226
SB3 Clip Fraction: 0.01862
Policy Update Magnitude: 0.22638
Value Function Update Magnitude: 0.30546

Collected Steps per Second: 20,768.21210
Overall Steps per Second: 10,280.12308

Timestep Collection Time: 2.40849
Timestep Consumption Time: 2.45721
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.86570

Cumulative Model Updates: 373,852
Cumulative Timesteps: 3,117,936,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.87732
Policy Entropy: 4.02357
Value Function Loss: 0.00590

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.02128
Policy Update Magnitude: 0.22564
Value Function Update Magnitude: 0.30855

Collected Steps per Second: 21,351.90451
Overall Steps per Second: 9,999.94162

Timestep Collection Time: 2.34255
Timestep Consumption Time: 2.65927
PPO Batch Consumption Time: 0.31487
Total Iteration Time: 5.00183

Cumulative Model Updates: 373,858
Cumulative Timesteps: 3,117,986,518

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3117986518...
Checkpoint 3117986518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.31311
Policy Entropy: 4.01498
Value Function Loss: 0.00559

Mean KL Divergence: 0.00335
SB3 Clip Fraction: 0.02563
Policy Update Magnitude: 0.23562
Value Function Update Magnitude: 0.31822

Collected Steps per Second: 20,619.14903
Overall Steps per Second: 9,595.36820

Timestep Collection Time: 2.42619
Timestep Consumption Time: 2.78737
PPO Batch Consumption Time: 0.32871
Total Iteration Time: 5.21356

Cumulative Model Updates: 373,864
Cumulative Timesteps: 3,118,036,544

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48.81767
Policy Entropy: 4.00800
Value Function Loss: 0.00520

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.02804
Policy Update Magnitude: 0.24269
Value Function Update Magnitude: 0.31920

Collected Steps per Second: 15,953.24363
Overall Steps per Second: 8,615.38568

Timestep Collection Time: 3.13441
Timestep Consumption Time: 2.66963
PPO Batch Consumption Time: 0.31720
Total Iteration Time: 5.80403

Cumulative Model Updates: 373,870
Cumulative Timesteps: 3,118,086,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3118086548...
Checkpoint 3118086548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.96883
Policy Entropy: 4.04060
Value Function Loss: 0.00487

Mean KL Divergence: 0.00395
SB3 Clip Fraction: 0.02887
Policy Update Magnitude: 0.23756
Value Function Update Magnitude: 0.31623

Collected Steps per Second: 19,727.73890
Overall Steps per Second: 9,800.55800

Timestep Collection Time: 2.53460
Timestep Consumption Time: 2.56735
PPO Batch Consumption Time: 0.30042
Total Iteration Time: 5.10195

Cumulative Model Updates: 373,876
Cumulative Timesteps: 3,118,136,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.72897
Policy Entropy: 4.00633
Value Function Loss: 0.00524

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.02849
Policy Update Magnitude: 0.23197
Value Function Update Magnitude: 0.28650

Collected Steps per Second: 18,994.23379
Overall Steps per Second: 9,286.43563

Timestep Collection Time: 2.63311
Timestep Consumption Time: 2.75259
PPO Batch Consumption Time: 0.32046
Total Iteration Time: 5.38570

Cumulative Model Updates: 373,882
Cumulative Timesteps: 3,118,186,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 3118186564...
Checkpoint 3118186564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.97762
Policy Entropy: 3.98731
Value Function Loss: 0.00657

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.02992
Policy Update Magnitude: 0.23181
Value Function Update Magnitude: 0.30284

Collected Steps per Second: 19,475.50214
Overall Steps per Second: 9,452.46949

Timestep Collection Time: 2.56733
Timestep Consumption Time: 2.72230
PPO Batch Consumption Time: 0.32997
Total Iteration Time: 5.28962

Cumulative Model Updates: 373,888
Cumulative Timesteps: 3,118,236,564

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54.52075
Policy Entropy: 3.97962
Value Function Loss: 0.00658

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.03251
Policy Update Magnitude: 0.24284
Value Function Update Magnitude: 0.34320

Collected Steps per Second: 21,064.09920
Overall Steps per Second: 10,104.75685

Timestep Collection Time: 2.37447
Timestep Consumption Time: 2.57528
PPO Batch Consumption Time: 0.29694
Total Iteration Time: 4.94975

Cumulative Model Updates: 373,894
Cumulative Timesteps: 3,118,286,580

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3118286580...
Checkpoint 3118286580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45.97847
Policy Entropy: 3.97591
Value Function Loss: 0.00683

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.03187
Policy Update Magnitude: 0.24777
Value Function Update Magnitude: 0.34495

Collected Steps per Second: 19,790.38852
Overall Steps per Second: 9,860.26968

Timestep Collection Time: 2.52759
Timestep Consumption Time: 2.54550
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 5.07309

Cumulative Model Updates: 373,900
Cumulative Timesteps: 3,118,336,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11.09107
Policy Entropy: 3.96789
Value Function Loss: 0.00591

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.03185
Policy Update Magnitude: 0.24429
Value Function Update Magnitude: 0.33706

Collected Steps per Second: 22,058.84039
Overall Steps per Second: 10,473.07828

Timestep Collection Time: 2.26784
Timestep Consumption Time: 2.50878
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.77663

Cumulative Model Updates: 373,906
Cumulative Timesteps: 3,118,386,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3118386628...
Checkpoint 3118386628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.71225
Policy Entropy: 3.92420
Value Function Loss: 0.00651

Mean KL Divergence: 0.00423
SB3 Clip Fraction: 0.03211
Policy Update Magnitude: 0.24928
Value Function Update Magnitude: 0.32508

Collected Steps per Second: 22,184.59295
Overall Steps per Second: 10,505.21785

Timestep Collection Time: 2.25463
Timestep Consumption Time: 2.50663
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.76125

Cumulative Model Updates: 373,912
Cumulative Timesteps: 3,118,436,646

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.17167
Policy Entropy: 3.95447
Value Function Loss: 0.00674

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.02832
Policy Update Magnitude: 0.25321
Value Function Update Magnitude: 0.32367

Collected Steps per Second: 22,487.78281
Overall Steps per Second: 10,706.33349

Timestep Collection Time: 2.22387
Timestep Consumption Time: 2.44719
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.67107

Cumulative Model Updates: 373,918
Cumulative Timesteps: 3,118,486,656

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 3118486656...
Checkpoint 3118486656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.15687
Policy Entropy: 3.92268
Value Function Loss: 0.00737

Mean KL Divergence: 0.00426
SB3 Clip Fraction: 0.02641
Policy Update Magnitude: 0.25294
Value Function Update Magnitude: 0.31764

Collected Steps per Second: 21,797.94747
Overall Steps per Second: 10,649.26005

Timestep Collection Time: 2.29389
Timestep Consumption Time: 2.40146
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.69535

Cumulative Model Updates: 373,924
Cumulative Timesteps: 3,118,536,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.97466
Policy Entropy: 3.93209
Value Function Loss: 0.00695

Mean KL Divergence: 0.00345
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.25897
Value Function Update Magnitude: 0.32418

Collected Steps per Second: 21,800.59781
Overall Steps per Second: 10,439.75768

Timestep Collection Time: 2.29535
Timestep Consumption Time: 2.49786
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.79321

Cumulative Model Updates: 373,930
Cumulative Timesteps: 3,118,586,698

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 3118586698...
Checkpoint 3118586698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36.65848
Policy Entropy: 3.93236
Value Function Loss: 0.00558

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.02749
Policy Update Magnitude: 0.24809
Value Function Update Magnitude: 0.33236

Collected Steps per Second: 19,781.69090
Overall Steps per Second: 9,750.34998

Timestep Collection Time: 2.52779
Timestep Consumption Time: 2.60064
PPO Batch Consumption Time: 0.29910
Total Iteration Time: 5.12843

Cumulative Model Updates: 373,936
Cumulative Timesteps: 3,118,636,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.62185
Policy Entropy: 3.93604
Value Function Loss: 0.00656

Mean KL Divergence: 0.00338
SB3 Clip Fraction: 0.02656
Policy Update Magnitude: 0.24811
Value Function Update Magnitude: 0.31383

Collected Steps per Second: 21,202.63096
Overall Steps per Second: 10,437.42791

Timestep Collection Time: 2.35952
Timestep Consumption Time: 2.43362
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.79313

Cumulative Model Updates: 373,942
Cumulative Timesteps: 3,118,686,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 3118686730...
Checkpoint 3118686730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26.62476
Policy Entropy: 3.92654
Value Function Loss: 0.00703

Mean KL Divergence: 0.00353
SB3 Clip Fraction: 0.02687
Policy Update Magnitude: 0.25586
Value Function Update Magnitude: 0.32593

Collected Steps per Second: 20,826.11361
Overall Steps per Second: 9,909.71123

Timestep Collection Time: 2.40170
Timestep Consumption Time: 2.64568
PPO Batch Consumption Time: 0.30401
Total Iteration Time: 5.04737

Cumulative Model Updates: 373,948
Cumulative Timesteps: 3,118,736,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.67555
Policy Entropy: 3.93366
Value Function Loss: 0.00770

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.03308
Policy Update Magnitude: 0.27009
Value Function Update Magnitude: 0.34209

Collected Steps per Second: 22,276.05126
Overall Steps per Second: 10,396.07547

Timestep Collection Time: 2.24600
Timestep Consumption Time: 2.56659
PPO Batch Consumption Time: 0.30248
Total Iteration Time: 4.81259

Cumulative Model Updates: 373,954
Cumulative Timesteps: 3,118,786,780

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3118786780...
Checkpoint 3118786780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7.01297
Policy Entropy: 3.99948
Value Function Loss: 0.00635

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.03405
Policy Update Magnitude: 0.25985
Value Function Update Magnitude: 0.32923

Collected Steps per Second: 22,491.06885
Overall Steps per Second: 10,726.14878

Timestep Collection Time: 2.22435
Timestep Consumption Time: 2.43977
PPO Batch Consumption Time: 0.27922
Total Iteration Time: 4.66412

Cumulative Model Updates: 373,960
Cumulative Timesteps: 3,118,836,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46.88367
Policy Entropy: 4.02877
Value Function Loss: 0.00591

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.02835
Policy Update Magnitude: 0.22981
Value Function Update Magnitude: 0.31564

Collected Steps per Second: 21,729.07701
Overall Steps per Second: 10,476.96415

Timestep Collection Time: 2.30162
Timestep Consumption Time: 2.47190
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.77352

Cumulative Model Updates: 373,966
Cumulative Timesteps: 3,118,886,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 3118886820...
Checkpoint 3118886820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.48711
Policy Entropy: 3.99468
Value Function Loss: 0.00571

Mean KL Divergence: 0.00409
SB3 Clip Fraction: 0.03109
Policy Update Magnitude: 0.23272
Value Function Update Magnitude: 0.31526

Collected Steps per Second: 21,267.87391
Overall Steps per Second: 10,254.31858

Timestep Collection Time: 2.35237
Timestep Consumption Time: 2.52655
PPO Batch Consumption Time: 0.29937
Total Iteration Time: 4.87892

Cumulative Model Updates: 373,972
Cumulative Timesteps: 3,118,936,850

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35.21008
Policy Entropy: 3.95363
Value Function Loss: 0.00682

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.03372
Policy Update Magnitude: 0.24936
Value Function Update Magnitude: 0.33497

Collected Steps per Second: 21,337.60125
Overall Steps per Second: 10,577.49604

Timestep Collection Time: 2.34356
Timestep Consumption Time: 2.38402
PPO Batch Consumption Time: 0.28022
Total Iteration Time: 4.72758

Cumulative Model Updates: 373,978
Cumulative Timesteps: 3,118,986,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3118986856...
Checkpoint 3118986856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.81152
Policy Entropy: 3.91671
Value Function Loss: 0.00687

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.03272
Policy Update Magnitude: 0.26507
Value Function Update Magnitude: 0.35565

Collected Steps per Second: 22,199.22271
Overall Steps per Second: 10,338.04758

Timestep Collection Time: 2.25251
Timestep Consumption Time: 2.58438
PPO Batch Consumption Time: 0.30436
Total Iteration Time: 4.83689

Cumulative Model Updates: 373,984
Cumulative Timesteps: 3,119,036,860

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.84925
Policy Entropy: 3.93605
Value Function Loss: 0.00688

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.03001
Policy Update Magnitude: 0.27673
Value Function Update Magnitude: 0.35528

Collected Steps per Second: 21,637.99595
Overall Steps per Second: 10,271.65238

Timestep Collection Time: 2.31093
Timestep Consumption Time: 2.55722
PPO Batch Consumption Time: 0.29529
Total Iteration Time: 4.86816

Cumulative Model Updates: 373,990
Cumulative Timesteps: 3,119,086,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3119086864...
Checkpoint 3119086864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.64907
Policy Entropy: 3.91994
Value Function Loss: 0.00701

Mean KL Divergence: 0.00452
SB3 Clip Fraction: 0.03161
Policy Update Magnitude: 0.27704
Value Function Update Magnitude: 0.35283

Collected Steps per Second: 18,114.92745
Overall Steps per Second: 9,657.44480

Timestep Collection Time: 2.76049
Timestep Consumption Time: 2.41749
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 5.17797

Cumulative Model Updates: 373,996
Cumulative Timesteps: 3,119,136,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12.73785
Policy Entropy: 3.97345
Value Function Loss: 0.00682

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.03054
Policy Update Magnitude: 0.26399
Value Function Update Magnitude: 0.34360

Collected Steps per Second: 20,454.21422
Overall Steps per Second: 10,066.84476

Timestep Collection Time: 2.44605
Timestep Consumption Time: 2.52393
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.96998

Cumulative Model Updates: 374,002
Cumulative Timesteps: 3,119,186,902

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 3119186902...
Checkpoint 3119186902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.81612
Policy Entropy: 3.98228
Value Function Loss: 0.00663

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.03184
Policy Update Magnitude: 0.25926
Value Function Update Magnitude: 0.34418

Collected Steps per Second: 19,991.61987
Overall Steps per Second: 9,950.00117

Timestep Collection Time: 2.50235
Timestep Consumption Time: 2.52539
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 5.02774

Cumulative Model Updates: 374,008
Cumulative Timesteps: 3,119,236,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28.74044
Policy Entropy: 4.03965
Value Function Loss: 0.00605

Mean KL Divergence: 0.00311
SB3 Clip Fraction: 0.02258
Policy Update Magnitude: 0.24853
Value Function Update Magnitude: 0.32456

Collected Steps per Second: 20,888.50021
Overall Steps per Second: 9,882.60186

Timestep Collection Time: 2.39395
Timestep Consumption Time: 2.66605
PPO Batch Consumption Time: 0.30390
Total Iteration Time: 5.06000

Cumulative Model Updates: 374,014
Cumulative Timesteps: 3,119,286,934

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 3119286934...
Checkpoint 3119286934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.12414
Policy Entropy: 4.01361
Value Function Loss: 0.00626

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.02807
Policy Update Magnitude: 0.24199
Value Function Update Magnitude: 0.32189

Collected Steps per Second: 18,656.86394
Overall Steps per Second: 9,439.13569

Timestep Collection Time: 2.68105
Timestep Consumption Time: 2.61816
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 5.29921

Cumulative Model Updates: 374,020
Cumulative Timesteps: 3,119,336,954

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3119336954...
Checkpoint 3119336954 saved!
