Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03353
Policy Entropy: 0.70863
Value Function Loss: 0.03968

Mean KL Divergence: 0.00000
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.01925
Value Function Update Magnitude: 0.02318

Collected Steps per Second: 14,948.54461
Overall Steps per Second: 10,842.95438

Timestep Collection Time: 3.34521
Timestep Consumption Time: 1.26663
PPO Batch Consumption Time: 0.32820
Total Iteration Time: 4.61184

Cumulative Model Updates: 73
Cumulative Timesteps: 1,300,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04229
Policy Entropy: 0.70516
Value Function Loss: 0.03490

Mean KL Divergence: 0.00009
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.01986
Value Function Update Magnitude: 0.02215

Collected Steps per Second: 16,457.77888
Overall Steps per Second: 12,185.66641

Timestep Collection Time: 3.03844
Timestep Consumption Time: 1.06523
PPO Batch Consumption Time: 0.34102
Total Iteration Time: 4.10367

Cumulative Model Updates: 74
Cumulative Timesteps: 1,350,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1350662...
Checkpoint 1350662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.03488
Policy Entropy: 0.69775
Value Function Loss: 0.02921

Mean KL Divergence: 0.00113
SB3 Clip Fraction: 0.00169
Policy Update Magnitude: 0.06042
Value Function Update Magnitude: 0.06214

Collected Steps per Second: 17,685.11341
Overall Steps per Second: 11,210.90857

Timestep Collection Time: 2.82837
Timestep Consumption Time: 1.63336
PPO Batch Consumption Time: 0.31893
Total Iteration Time: 4.46173

Cumulative Model Updates: 77
Cumulative Timesteps: 1,400,682

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00203
Policy Entropy: 0.68643
Value Function Loss: 0.03190

Mean KL Divergence: 0.00343
SB3 Clip Fraction: 0.02767
Policy Update Magnitude: 0.05659
Value Function Update Magnitude: 0.05497

Collected Steps per Second: 21,308.10221
Overall Steps per Second: 12,135.26324

Timestep Collection Time: 2.34690
Timestep Consumption Time: 1.77398
PPO Batch Consumption Time: 0.32433
Total Iteration Time: 4.12088

Cumulative Model Updates: 80
Cumulative Timesteps: 1,450,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1450690...
Checkpoint 1450690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05272
Policy Entropy: 0.67835
Value Function Loss: 0.03342

Mean KL Divergence: 0.00380
SB3 Clip Fraction: 0.04295
Policy Update Magnitude: 0.05017
Value Function Update Magnitude: 0.05253

Collected Steps per Second: 16,800.66630
Overall Steps per Second: 10,571.44548

Timestep Collection Time: 2.97679
Timestep Consumption Time: 1.75407
PPO Batch Consumption Time: 0.32861
Total Iteration Time: 4.73086

Cumulative Model Updates: 83
Cumulative Timesteps: 1,500,702

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.03066
Policy Entropy: 0.67605
Value Function Loss: 0.04731

Mean KL Divergence: 0.00177
SB3 Clip Fraction: 0.00845
Policy Update Magnitude: 0.05212
Value Function Update Magnitude: 0.05601

Collected Steps per Second: 21,412.69802
Overall Steps per Second: 12,632.62929

Timestep Collection Time: 2.33684
Timestep Consumption Time: 1.62417
PPO Batch Consumption Time: 0.32898
Total Iteration Time: 3.96101

Cumulative Model Updates: 86
Cumulative Timesteps: 1,550,740

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1550740...
Checkpoint 1550740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01279
Policy Entropy: 0.67412
Value Function Loss: 0.04103

Mean KL Divergence: 0.00163
SB3 Clip Fraction: 0.00582
Policy Update Magnitude: 0.05472
Value Function Update Magnitude: 0.05756

Collected Steps per Second: 19,424.89829
Overall Steps per Second: 11,653.73291

Timestep Collection Time: 2.57546
Timestep Consumption Time: 1.71742
PPO Batch Consumption Time: 0.32652
Total Iteration Time: 4.29287

Cumulative Model Updates: 89
Cumulative Timesteps: 1,600,768

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.05476
Policy Entropy: 0.67178
Value Function Loss: 0.05555

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.02120
Policy Update Magnitude: 0.05447
Value Function Update Magnitude: 0.05782

Collected Steps per Second: 20,322.12592
Overall Steps per Second: 11,964.62104

Timestep Collection Time: 2.46293
Timestep Consumption Time: 1.72040
PPO Batch Consumption Time: 0.32588
Total Iteration Time: 4.18333

Cumulative Model Updates: 92
Cumulative Timesteps: 1,650,820

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1650820...
Checkpoint 1650820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01270
Policy Entropy: 0.66611
Value Function Loss: 0.05190

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01853
Policy Update Magnitude: 0.05640
Value Function Update Magnitude: 0.05638

Collected Steps per Second: 20,388.89168
Overall Steps per Second: 11,952.16830

Timestep Collection Time: 2.45418
Timestep Consumption Time: 1.73234
PPO Batch Consumption Time: 0.32487
Total Iteration Time: 4.18652

Cumulative Model Updates: 95
Cumulative Timesteps: 1,700,858

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01369
Policy Entropy: 0.65804
Value Function Loss: 0.05196

Mean KL Divergence: 0.00202
SB3 Clip Fraction: 0.00920
Policy Update Magnitude: 0.05998
Value Function Update Magnitude: 0.05996

Collected Steps per Second: 20,574.87653
Overall Steps per Second: 12,013.74303

Timestep Collection Time: 2.43112
Timestep Consumption Time: 1.73244
PPO Batch Consumption Time: 0.32321
Total Iteration Time: 4.16357

Cumulative Model Updates: 98
Cumulative Timesteps: 1,750,878

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1750878...
Checkpoint 1750878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01332
Policy Entropy: 0.65207
Value Function Loss: 0.06125

Mean KL Divergence: 0.00244
SB3 Clip Fraction: 0.01620
Policy Update Magnitude: 0.06248
Value Function Update Magnitude: 0.06767

Collected Steps per Second: 21,676.02446
Overall Steps per Second: 12,810.83981

Timestep Collection Time: 2.30799
Timestep Consumption Time: 1.59714
PPO Batch Consumption Time: 0.31750
Total Iteration Time: 3.90513

Cumulative Model Updates: 101
Cumulative Timesteps: 1,800,906

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02781
Policy Entropy: 0.64934
Value Function Loss: 0.07702

Mean KL Divergence: 0.00359
SB3 Clip Fraction: 0.03299
Policy Update Magnitude: 0.06522
Value Function Update Magnitude: 0.08581

Collected Steps per Second: 20,448.60983
Overall Steps per Second: 12,002.16933

Timestep Collection Time: 2.44525
Timestep Consumption Time: 1.72083
PPO Batch Consumption Time: 0.32220
Total Iteration Time: 4.16608

Cumulative Model Updates: 104
Cumulative Timesteps: 1,850,908

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1850908...
Checkpoint 1850908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.02903
Policy Entropy: 0.65132
Value Function Loss: 0.09366

Mean KL Divergence: 0.00371
SB3 Clip Fraction: 0.03886
Policy Update Magnitude: 0.06842
Value Function Update Magnitude: 0.10695

Collected Steps per Second: 21,584.48003
Overall Steps per Second: 12,546.77224

Timestep Collection Time: 2.31704
Timestep Consumption Time: 1.66901
PPO Batch Consumption Time: 0.32255
Total Iteration Time: 3.98605

Cumulative Model Updates: 107
Cumulative Timesteps: 1,900,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.04179
Policy Entropy: 0.65401
Value Function Loss: 0.08222

Mean KL Divergence: 0.00299
SB3 Clip Fraction: 0.02231
Policy Update Magnitude: 0.07574
Value Function Update Magnitude: 0.09700

Collected Steps per Second: 22,779.37224
Overall Steps per Second: 12,856.59688

Timestep Collection Time: 2.19506
Timestep Consumption Time: 1.69415
PPO Batch Consumption Time: 0.32183
Total Iteration Time: 3.88921

Cumulative Model Updates: 110
Cumulative Timesteps: 1,950,922

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1950922...
Checkpoint 1950922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: -0.05179
Policy Entropy: 0.65150
Value Function Loss: 0.07971

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.05187
Policy Update Magnitude: 0.07262
Value Function Update Magnitude: 0.07111

Collected Steps per Second: 21,941.62795
Overall Steps per Second: 12,543.24495

Timestep Collection Time: 2.28023
Timestep Consumption Time: 1.70853
PPO Batch Consumption Time: 0.32498
Total Iteration Time: 3.98876

Cumulative Model Updates: 113
Cumulative Timesteps: 2,000,954

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.10350
Policy Entropy: 0.64296
Value Function Loss: 0.07362

Mean KL Divergence: 0.00280
SB3 Clip Fraction: 0.02117
Policy Update Magnitude: 0.07287
Value Function Update Magnitude: 0.06781

Collected Steps per Second: 21,694.93019
Overall Steps per Second: 12,791.95469

Timestep Collection Time: 2.30625
Timestep Consumption Time: 1.60511
PPO Batch Consumption Time: 0.32284
Total Iteration Time: 3.91136

Cumulative Model Updates: 116
Cumulative Timesteps: 2,050,988

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 2050988...
Checkpoint 2050988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.01462
Policy Entropy: 0.63582
Value Function Loss: 0.07134

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.02983
Policy Update Magnitude: 0.07042
Value Function Update Magnitude: 0.06513

Collected Steps per Second: 22,113.76588
Overall Steps per Second: 12,593.54723

Timestep Collection Time: 2.26221
Timestep Consumption Time: 1.71014
PPO Batch Consumption Time: 0.32491
Total Iteration Time: 3.97235

Cumulative Model Updates: 119
Cumulative Timesteps: 2,101,014

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: -0.00412
Policy Entropy: 0.63244
Value Function Loss: 0.07562

Mean KL Divergence: 0.00282
SB3 Clip Fraction: 0.02281
Policy Update Magnitude: 0.07414
Value Function Update Magnitude: 0.06480

Collected Steps per Second: 21,633.66444
Overall Steps per Second: 12,532.70755

Timestep Collection Time: 2.31121
Timestep Consumption Time: 1.67835
PPO Batch Consumption Time: 0.32287
Total Iteration Time: 3.98956

Cumulative Model Updates: 122
Cumulative Timesteps: 2,151,014

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2151014...
Checkpoint 2151014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00346
Policy Entropy: 0.63434
Value Function Loss: 0.06848

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.01494
Policy Update Magnitude: 0.07365
Value Function Update Magnitude: 0.06363

Collected Steps per Second: 22,992.93572
Overall Steps per Second: 12,816.76847

Timestep Collection Time: 2.17484
Timestep Consumption Time: 1.72677
PPO Batch Consumption Time: 0.32352
Total Iteration Time: 3.90161

Cumulative Model Updates: 125
Cumulative Timesteps: 2,201,020

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 0.00391
Policy Entropy: 0.63751
Value Function Loss: 0.06405

Mean KL Divergence: 0.00211
SB3 Clip Fraction: 0.01429
Policy Update Magnitude: 0.07344
Value Function Update Magnitude: 0.05296

Collected Steps per Second: 19,007.26859
Overall Steps per Second: 11,477.35038

Timestep Collection Time: 2.63194
Timestep Consumption Time: 1.72673
PPO Batch Consumption Time: 0.31714
Total Iteration Time: 4.35867

Cumulative Model Updates: 128
Cumulative Timesteps: 2,251,046

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 2251046...
Checkpoint 2251046 saved!
