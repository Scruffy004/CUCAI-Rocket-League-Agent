Created new wandb run! xc9gp3ls
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.47544
Policy Entropy: 4.49941
Value Function Loss: nan

Mean KL Divergence: 0.00001
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.59232
Value Function Update Magnitude: 0.66806

Collected Steps per Second: 18,312.71533
Overall Steps per Second: 11,537.42894

Timestep Collection Time: 2.73176
Timestep Consumption Time: 1.60421
PPO Batch Consumption Time: 0.38039
Total Iteration Time: 4.33597

Cumulative Model Updates: 2
Cumulative Timesteps: 50,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.21951
Policy Entropy: 4.49911
Value Function Loss: 46.12292

Mean KL Divergence: 0.00021
SB3 Clip Fraction: 0.00000
Policy Update Magnitude: 0.78678
Value Function Update Magnitude: 1.08685

Collected Steps per Second: 20,079.15807
Overall Steps per Second: 10,481.83104

Timestep Collection Time: 2.49273
Timestep Consumption Time: 2.28239
PPO Batch Consumption Time: 0.34319
Total Iteration Time: 4.77512

Cumulative Model Updates: 6
Cumulative Timesteps: 100,078

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 100078...
Checkpoint 100078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74.28025
Policy Entropy: 4.49483
Value Function Loss: 28.71606

Mean KL Divergence: 0.00327
SB3 Clip Fraction: 0.01097
Policy Update Magnitude: 0.84303
Value Function Update Magnitude: 0.82723

Collected Steps per Second: 18,238.93826
Overall Steps per Second: 9,049.63442

Timestep Collection Time: 2.74248
Timestep Consumption Time: 2.78481
PPO Batch Consumption Time: 0.31145
Total Iteration Time: 5.52730

Cumulative Model Updates: 12
Cumulative Timesteps: 150,098

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.87231
Policy Entropy: 4.48952
Value Function Loss: 1.90317

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.03239
Policy Update Magnitude: 0.56772
Value Function Update Magnitude: 0.83372

Collected Steps per Second: 18,655.65859
Overall Steps per Second: 9,291.58933

Timestep Collection Time: 2.68080
Timestep Consumption Time: 2.70171
PPO Batch Consumption Time: 0.29538
Total Iteration Time: 5.38250

Cumulative Model Updates: 18
Cumulative Timesteps: 200,110

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 200110...
Checkpoint 200110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71.20783
Policy Entropy: 4.49154
Value Function Loss: 1.41448

Mean KL Divergence: 0.00198
SB3 Clip Fraction: 0.00006
Policy Update Magnitude: 0.41960
Value Function Update Magnitude: 0.52633

Collected Steps per Second: 19,914.58657
Overall Steps per Second: 9,818.55949

Timestep Collection Time: 2.51082
Timestep Consumption Time: 2.58178
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 5.09260

Cumulative Model Updates: 24
Cumulative Timesteps: 250,112

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.87735
Policy Entropy: 4.49164
Value Function Loss: 1.41361

Mean KL Divergence: 0.00158
SB3 Clip Fraction: 0.00475
Policy Update Magnitude: 0.35779
Value Function Update Magnitude: 0.41586

Collected Steps per Second: 19,787.58951
Overall Steps per Second: 9,559.83336

Timestep Collection Time: 2.52694
Timestep Consumption Time: 2.70349
PPO Batch Consumption Time: 0.29982
Total Iteration Time: 5.23043

Cumulative Model Updates: 30
Cumulative Timesteps: 300,114

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 300114...
Checkpoint 300114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.64045
Policy Entropy: 4.48874
Value Function Loss: 1.10166

Mean KL Divergence: 0.00164
SB3 Clip Fraction: 0.00338
Policy Update Magnitude: 0.35065
Value Function Update Magnitude: 0.48911

Collected Steps per Second: 20,323.27827
Overall Steps per Second: 9,688.64544

Timestep Collection Time: 2.46122
Timestep Consumption Time: 2.70153
PPO Batch Consumption Time: 0.30720
Total Iteration Time: 5.16274

Cumulative Model Updates: 36
Cumulative Timesteps: 350,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68.99208
Policy Entropy: 4.48408
Value Function Loss: 0.95877

Mean KL Divergence: 0.00225
SB3 Clip Fraction: 0.01197
Policy Update Magnitude: 0.33751
Value Function Update Magnitude: 0.49455

Collected Steps per Second: 20,913.34772
Overall Steps per Second: 9,902.64922

Timestep Collection Time: 2.39225
Timestep Consumption Time: 2.65993
PPO Batch Consumption Time: 0.29456
Total Iteration Time: 5.05218

Cumulative Model Updates: 42
Cumulative Timesteps: 400,164

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 400164...
Checkpoint 400164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.06594
Policy Entropy: 4.48693
Value Function Loss: 0.93642

Mean KL Divergence: 0.00140
SB3 Clip Fraction: 0.00096
Policy Update Magnitude: 0.35482
Value Function Update Magnitude: 0.67371

Collected Steps per Second: 20,529.76078
Overall Steps per Second: 9,765.19626

Timestep Collection Time: 2.43559
Timestep Consumption Time: 2.68484
PPO Batch Consumption Time: 0.29842
Total Iteration Time: 5.12043

Cumulative Model Updates: 48
Cumulative Timesteps: 450,166

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.50718
Policy Entropy: 4.48868
Value Function Loss: 0.76691

Mean KL Divergence: 0.00154
SB3 Clip Fraction: 0.00103
Policy Update Magnitude: 0.36816
Value Function Update Magnitude: 0.90479

Collected Steps per Second: 19,943.22588
Overall Steps per Second: 9,793.28402

Timestep Collection Time: 2.50822
Timestep Consumption Time: 2.59957
PPO Batch Consumption Time: 0.29519
Total Iteration Time: 5.10779

Cumulative Model Updates: 54
Cumulative Timesteps: 500,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 500188...
Checkpoint 500188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.13552
Policy Entropy: 4.48741
Value Function Loss: 0.72843

Mean KL Divergence: 0.00192
SB3 Clip Fraction: 0.00865
Policy Update Magnitude: 0.37596
Value Function Update Magnitude: 0.82622

Collected Steps per Second: 20,695.90316
Overall Steps per Second: 9,826.41404

Timestep Collection Time: 2.41623
Timestep Consumption Time: 2.67271
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 5.08894

Cumulative Model Updates: 60
Cumulative Timesteps: 550,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.12233
Policy Entropy: 4.48309
Value Function Loss: 0.76027

Mean KL Divergence: 0.00215
SB3 Clip Fraction: 0.00852
Policy Update Magnitude: 0.37457
Value Function Update Magnitude: 0.72894

Collected Steps per Second: 19,986.33048
Overall Steps per Second: 9,705.02074

Timestep Collection Time: 2.50221
Timestep Consumption Time: 2.65079
PPO Batch Consumption Time: 0.29533
Total Iteration Time: 5.15300

Cumulative Model Updates: 66
Cumulative Timesteps: 600,204

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 600204...
Checkpoint 600204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.27408
Policy Entropy: 4.48498
Value Function Loss: 0.79521

Mean KL Divergence: 0.00179
SB3 Clip Fraction: 0.00339
Policy Update Magnitude: 0.38432
Value Function Update Magnitude: 0.68482

Collected Steps per Second: 21,240.62289
Overall Steps per Second: 9,859.64735

Timestep Collection Time: 2.35520
Timestep Consumption Time: 2.71861
PPO Batch Consumption Time: 0.30627
Total Iteration Time: 5.07381

Cumulative Model Updates: 72
Cumulative Timesteps: 650,230

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.40811
Policy Entropy: 4.48514
Value Function Loss: 0.83825

Mean KL Divergence: 0.00188
SB3 Clip Fraction: 0.00588
Policy Update Magnitude: 0.38546
Value Function Update Magnitude: 0.61740

Collected Steps per Second: 19,948.34067
Overall Steps per Second: 9,461.98366

Timestep Collection Time: 2.50828
Timestep Consumption Time: 2.77983
PPO Batch Consumption Time: 0.31026
Total Iteration Time: 5.28811

Cumulative Model Updates: 78
Cumulative Timesteps: 700,266

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 700266...
Checkpoint 700266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.66436
Policy Entropy: 4.48420
Value Function Loss: 0.85329

Mean KL Divergence: 0.00175
SB3 Clip Fraction: 0.00287
Policy Update Magnitude: 0.40861
Value Function Update Magnitude: 0.60334

Collected Steps per Second: 20,916.97348
Overall Steps per Second: 9,969.90187

Timestep Collection Time: 2.39050
Timestep Consumption Time: 2.62480
PPO Batch Consumption Time: 0.29669
Total Iteration Time: 5.01530

Cumulative Model Updates: 84
Cumulative Timesteps: 750,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.90510
Policy Entropy: 4.48529
Value Function Loss: 0.82606

Mean KL Divergence: 0.00182
SB3 Clip Fraction: 0.00475
Policy Update Magnitude: 0.42079
Value Function Update Magnitude: 0.61056

Collected Steps per Second: 19,598.01380
Overall Steps per Second: 9,312.65368

Timestep Collection Time: 2.55159
Timestep Consumption Time: 2.81810
PPO Batch Consumption Time: 0.31469
Total Iteration Time: 5.36968

Cumulative Model Updates: 90
Cumulative Timesteps: 800,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 800274...
Checkpoint 800274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47.33738
Policy Entropy: 4.48159
Value Function Loss: 0.81691

Mean KL Divergence: 0.00260
SB3 Clip Fraction: 0.01532
Policy Update Magnitude: 0.42218
Value Function Update Magnitude: 0.55382

Collected Steps per Second: 20,613.73324
Overall Steps per Second: 9,635.07041

Timestep Collection Time: 2.42586
Timestep Consumption Time: 2.76414
PPO Batch Consumption Time: 0.31588
Total Iteration Time: 5.19000

Cumulative Model Updates: 96
Cumulative Timesteps: 850,280

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.47301
Policy Entropy: 4.47446
Value Function Loss: 0.86061

Mean KL Divergence: 0.00318
SB3 Clip Fraction: 0.00950
Policy Update Magnitude: 0.40619
Value Function Update Magnitude: 0.42251

Collected Steps per Second: 20,571.83446
Overall Steps per Second: 9,622.25102

Timestep Collection Time: 2.43051
Timestep Consumption Time: 2.76578
PPO Batch Consumption Time: 0.31075
Total Iteration Time: 5.19629

Cumulative Model Updates: 102
Cumulative Timesteps: 900,280

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 900280...
Checkpoint 900280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.18208
Policy Entropy: 4.47600
Value Function Loss: 0.89011

Mean KL Divergence: 0.00236
SB3 Clip Fraction: 0.00896
Policy Update Magnitude: 0.40742
Value Function Update Magnitude: 0.36624

Collected Steps per Second: 20,694.94573
Overall Steps per Second: 9,766.25005

Timestep Collection Time: 2.41615
Timestep Consumption Time: 2.70373
PPO Batch Consumption Time: 0.29553
Total Iteration Time: 5.11988

Cumulative Model Updates: 108
Cumulative Timesteps: 950,282

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.94441
Policy Entropy: 4.47674
Value Function Loss: 0.96729

Mean KL Divergence: 0.00200
SB3 Clip Fraction: 0.00969
Policy Update Magnitude: 0.42907
Value Function Update Magnitude: 0.34465

Collected Steps per Second: 20,419.94726
Overall Steps per Second: 9,731.56822

Timestep Collection Time: 2.45006
Timestep Consumption Time: 2.69095
PPO Batch Consumption Time: 0.31445
Total Iteration Time: 5.14100

Cumulative Model Updates: 114
Cumulative Timesteps: 1,000,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1000312...
Checkpoint 1000312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44.58820
Policy Entropy: 4.47084
Value Function Loss: 1.04631

Mean KL Divergence: 0.00277
SB3 Clip Fraction: 0.01944
Policy Update Magnitude: 0.43261
Value Function Update Magnitude: 0.31945

Collected Steps per Second: 20,592.72646
Overall Steps per Second: 9,785.58261

Timestep Collection Time: 2.42862
Timestep Consumption Time: 2.68216
PPO Batch Consumption Time: 0.29617
Total Iteration Time: 5.11078

Cumulative Model Updates: 120
Cumulative Timesteps: 1,050,324

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.33961
Policy Entropy: 4.47358
Value Function Loss: 1.08246

Mean KL Divergence: 0.00223
SB3 Clip Fraction: 0.01087
Policy Update Magnitude: 0.42089
Value Function Update Magnitude: 0.29264

Collected Steps per Second: 20,381.34123
Overall Steps per Second: 9,649.14854

Timestep Collection Time: 2.45450
Timestep Consumption Time: 2.73000
PPO Batch Consumption Time: 0.30841
Total Iteration Time: 5.18450

Cumulative Model Updates: 126
Cumulative Timesteps: 1,100,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1100350...
Checkpoint 1100350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.34066
Policy Entropy: 4.46578
Value Function Loss: 1.12335

Mean KL Divergence: 0.00234
SB3 Clip Fraction: 0.00848
Policy Update Magnitude: 0.44640
Value Function Update Magnitude: 0.26821

Collected Steps per Second: 21,314.71062
Overall Steps per Second: 9,752.55139

Timestep Collection Time: 2.34627
Timestep Consumption Time: 2.78162
PPO Batch Consumption Time: 0.31271
Total Iteration Time: 5.12789

Cumulative Model Updates: 132
Cumulative Timesteps: 1,150,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.28916
Policy Entropy: 4.46160
Value Function Loss: 1.12211

Mean KL Divergence: 0.00274
SB3 Clip Fraction: 0.01415
Policy Update Magnitude: 0.47839
Value Function Update Magnitude: 0.26632

Collected Steps per Second: 20,202.38094
Overall Steps per Second: 9,732.00363

Timestep Collection Time: 2.47525
Timestep Consumption Time: 2.66305
PPO Batch Consumption Time: 0.29398
Total Iteration Time: 5.13830

Cumulative Model Updates: 138
Cumulative Timesteps: 1,200,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1200366...
Checkpoint 1200366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39.86534
Policy Entropy: 4.45448
Value Function Loss: 1.19854

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.02728
Policy Update Magnitude: 0.47236
Value Function Update Magnitude: 0.26169

Collected Steps per Second: 20,601.00247
Overall Steps per Second: 9,751.05204

Timestep Collection Time: 2.42794
Timestep Consumption Time: 2.70156
PPO Batch Consumption Time: 0.31398
Total Iteration Time: 5.12950

Cumulative Model Updates: 144
Cumulative Timesteps: 1,250,384

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.96805
Policy Entropy: 4.47332
Value Function Loss: 1.25874

Mean KL Divergence: 0.00298
SB3 Clip Fraction: 0.01001
Policy Update Magnitude: 0.48864
Value Function Update Magnitude: 0.28612

Collected Steps per Second: 20,361.67867
Overall Steps per Second: 9,668.08085

Timestep Collection Time: 2.45677
Timestep Consumption Time: 2.71737
PPO Batch Consumption Time: 0.30378
Total Iteration Time: 5.17414

Cumulative Model Updates: 150
Cumulative Timesteps: 1,300,408

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1300408...
Checkpoint 1300408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.47258
Policy Entropy: 4.46283
Value Function Loss: 1.21829

Mean KL Divergence: 0.00258
SB3 Clip Fraction: 0.01469
Policy Update Magnitude: 0.48466
Value Function Update Magnitude: 0.28406

Collected Steps per Second: 20,514.69108
Overall Steps per Second: 9,712.20829

Timestep Collection Time: 2.43777
Timestep Consumption Time: 2.71142
PPO Batch Consumption Time: 0.30025
Total Iteration Time: 5.14919

Cumulative Model Updates: 156
Cumulative Timesteps: 1,350,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56.84217
Policy Entropy: 4.47244
Value Function Loss: 1.25649

Mean KL Divergence: 0.00220
SB3 Clip Fraction: 0.00553
Policy Update Magnitude: 0.49993
Value Function Update Magnitude: 0.38786

Collected Steps per Second: 20,839.86758
Overall Steps per Second: 9,734.66128

Timestep Collection Time: 2.39954
Timestep Consumption Time: 2.73737
PPO Batch Consumption Time: 0.30240
Total Iteration Time: 5.13690

Cumulative Model Updates: 162
Cumulative Timesteps: 1,400,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1400424...
Checkpoint 1400424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.84030
Policy Entropy: 4.46768
Value Function Loss: 1.22194

Mean KL Divergence: 0.00217
SB3 Clip Fraction: 0.00697
Policy Update Magnitude: 0.53679
Value Function Update Magnitude: 0.33078

Collected Steps per Second: 20,221.01686
Overall Steps per Second: 9,565.07629

Timestep Collection Time: 2.47327
Timestep Consumption Time: 2.75534
PPO Batch Consumption Time: 0.30984
Total Iteration Time: 5.22860

Cumulative Model Updates: 168
Cumulative Timesteps: 1,450,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29.41040
Policy Entropy: 4.46806
Value Function Loss: 1.29799

Mean KL Divergence: 0.00250
SB3 Clip Fraction: 0.01053
Policy Update Magnitude: 0.60295
Value Function Update Magnitude: 0.27585

Collected Steps per Second: 20,472.58715
Overall Steps per Second: 9,936.70427

Timestep Collection Time: 2.44288
Timestep Consumption Time: 2.59018
PPO Batch Consumption Time: 0.29482
Total Iteration Time: 5.03306

Cumulative Model Updates: 174
Cumulative Timesteps: 1,500,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1500448...
Checkpoint 1500448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.29476
Policy Entropy: 4.46405
Value Function Loss: 1.32013

Mean KL Divergence: 0.00308
SB3 Clip Fraction: 0.01883
Policy Update Magnitude: 0.59658
Value Function Update Magnitude: 0.24787

Collected Steps per Second: 20,211.89391
Overall Steps per Second: 9,559.00156

Timestep Collection Time: 2.47448
Timestep Consumption Time: 2.75765
PPO Batch Consumption Time: 0.31088
Total Iteration Time: 5.23214

Cumulative Model Updates: 180
Cumulative Timesteps: 1,550,462

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66.51637
Policy Entropy: 4.46112
Value Function Loss: 1.31434

Mean KL Divergence: 0.00283
SB3 Clip Fraction: 0.01625
Policy Update Magnitude: 0.61377
Value Function Update Magnitude: 0.24856

Collected Steps per Second: 20,484.30612
Overall Steps per Second: 9,815.71719

Timestep Collection Time: 2.44109
Timestep Consumption Time: 2.65319
PPO Batch Consumption Time: 0.29998
Total Iteration Time: 5.09428

Cumulative Model Updates: 186
Cumulative Timesteps: 1,600,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1600466...
Checkpoint 1600466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.98475
Policy Entropy: 4.46340
Value Function Loss: 1.30374

Mean KL Divergence: 0.00276
SB3 Clip Fraction: 0.01850
Policy Update Magnitude: 0.63741
Value Function Update Magnitude: 0.24790

Collected Steps per Second: 20,633.70652
Overall Steps per Second: 9,758.59100

Timestep Collection Time: 2.42322
Timestep Consumption Time: 2.70047
PPO Batch Consumption Time: 0.30279
Total Iteration Time: 5.12369

Cumulative Model Updates: 192
Cumulative Timesteps: 1,650,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61.32423
Policy Entropy: 4.46075
Value Function Loss: 1.29316

Mean KL Divergence: 0.00281
SB3 Clip Fraction: 0.01547
Policy Update Magnitude: 0.63831
Value Function Update Magnitude: 0.25356

Collected Steps per Second: 20,898.56039
Overall Steps per Second: 9,885.02635

Timestep Collection Time: 2.39375
Timestep Consumption Time: 2.66703
PPO Batch Consumption Time: 0.29479
Total Iteration Time: 5.06079

Cumulative Model Updates: 198
Cumulative Timesteps: 1,700,492

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1700492...
Checkpoint 1700492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.67436
Policy Entropy: 4.46312
Value Function Loss: 1.35933

Mean KL Divergence: 0.00266
SB3 Clip Fraction: 0.01314
Policy Update Magnitude: 0.65099
Value Function Update Magnitude: 0.24613

Collected Steps per Second: 20,176.20840
Overall Steps per Second: 9,734.99401

Timestep Collection Time: 2.47886
Timestep Consumption Time: 2.65869
PPO Batch Consumption Time: 0.30516
Total Iteration Time: 5.13755

Cumulative Model Updates: 204
Cumulative Timesteps: 1,750,506

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50.00855
Policy Entropy: 4.45627
Value Function Loss: 1.38847

Mean KL Divergence: 0.00284
SB3 Clip Fraction: 0.01909
Policy Update Magnitude: 0.69210
Value Function Update Magnitude: 0.37140

Collected Steps per Second: 20,692.07323
Overall Steps per Second: 9,643.26941

Timestep Collection Time: 2.41716
Timestep Consumption Time: 2.76947
PPO Batch Consumption Time: 0.31633
Total Iteration Time: 5.18662

Cumulative Model Updates: 210
Cumulative Timesteps: 1,800,522

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1800522...
Checkpoint 1800522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49.74481
Policy Entropy: 4.46234
Value Function Loss: 1.41405

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.01843
Policy Update Magnitude: 0.68816
Value Function Update Magnitude: 0.30133

Collected Steps per Second: 20,057.01847
Overall Steps per Second: 9,615.45987

Timestep Collection Time: 2.49319
Timestep Consumption Time: 2.70739
PPO Batch Consumption Time: 0.30616
Total Iteration Time: 5.20058

Cumulative Model Updates: 216
Cumulative Timesteps: 1,850,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90.73101
Policy Entropy: 4.46039
Value Function Loss: 1.39572

Mean KL Divergence: 0.00330
SB3 Clip Fraction: 0.03189
Policy Update Magnitude: 0.67810
Value Function Update Magnitude: 0.29164

Collected Steps per Second: 21,644.79495
Overall Steps per Second: 9,821.41497

Timestep Collection Time: 2.31067
Timestep Consumption Time: 2.78167
PPO Batch Consumption Time: 0.31424
Total Iteration Time: 5.09234

Cumulative Model Updates: 222
Cumulative Timesteps: 1,900,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1900542...
Checkpoint 1900542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56.84298
Policy Entropy: 4.46964
Value Function Loss: 1.41488

Mean KL Divergence: 0.00272
SB3 Clip Fraction: 0.01452
Policy Update Magnitude: 0.69779
Value Function Update Magnitude: 0.25341

Collected Steps per Second: 20,119.98626
Overall Steps per Second: 9,436.72939

Timestep Collection Time: 2.48618
Timestep Consumption Time: 2.81459
PPO Batch Consumption Time: 0.31837
Total Iteration Time: 5.30078

Cumulative Model Updates: 228
Cumulative Timesteps: 1,950,564

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44.31383
Policy Entropy: 4.45309
Value Function Loss: 1.42242

Mean KL Divergence: 0.00365
SB3 Clip Fraction: 0.03221
Policy Update Magnitude: 0.69802
Value Function Update Magnitude: 0.32625

Collected Steps per Second: 19,901.47449
Overall Steps per Second: 9,687.63178

Timestep Collection Time: 2.51358
Timestep Consumption Time: 2.65011
PPO Batch Consumption Time: 0.29823
Total Iteration Time: 5.16370

Cumulative Model Updates: 234
Cumulative Timesteps: 2,000,588

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 2000588...
Checkpoint 2000588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.36409
Policy Entropy: 4.45973
Value Function Loss: 1.44912

Mean KL Divergence: 0.00363
SB3 Clip Fraction: 0.02744
Policy Update Magnitude: 0.70422
Value Function Update Magnitude: 0.37898

Collected Steps per Second: 20,724.86579
Overall Steps per Second: 9,818.13626

Timestep Collection Time: 2.41420
Timestep Consumption Time: 2.68188
PPO Batch Consumption Time: 0.29558
Total Iteration Time: 5.09608

Cumulative Model Updates: 240
Cumulative Timesteps: 2,050,622

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116.44720
Policy Entropy: 4.46244
Value Function Loss: 1.42297

Mean KL Divergence: 0.00348
SB3 Clip Fraction: 0.02679
Policy Update Magnitude: 0.69395
Value Function Update Magnitude: 0.34969

Collected Steps per Second: 20,781.03575
Overall Steps per Second: 9,597.72849

Timestep Collection Time: 2.40825
Timestep Consumption Time: 2.80611
PPO Batch Consumption Time: 0.31969
Total Iteration Time: 5.21436

Cumulative Model Updates: 246
Cumulative Timesteps: 2,100,668

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 2100668...
Checkpoint 2100668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.77157
Policy Entropy: 4.45441
Value Function Loss: 1.73329

Mean KL Divergence: 0.00304
SB3 Clip Fraction: 0.01919
Policy Update Magnitude: 0.68454
Value Function Update Magnitude: 0.28405

Collected Steps per Second: 19,879.95802
Overall Steps per Second: 9,766.17542

Timestep Collection Time: 2.51630
Timestep Consumption Time: 2.60587
PPO Batch Consumption Time: 0.29958
Total Iteration Time: 5.12217

Cumulative Model Updates: 252
Cumulative Timesteps: 2,150,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69.51640
Policy Entropy: 4.45001
Value Function Loss: 1.93753

Mean KL Divergence: 0.00402
SB3 Clip Fraction: 0.03818
Policy Update Magnitude: 0.70828
Value Function Update Magnitude: 0.21218

Collected Steps per Second: 20,944.22845
Overall Steps per Second: 9,742.06240

Timestep Collection Time: 2.38872
Timestep Consumption Time: 2.74674
PPO Batch Consumption Time: 0.31018
Total Iteration Time: 5.13546

Cumulative Model Updates: 258
Cumulative Timesteps: 2,200,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 2200722...
Checkpoint 2200722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.13914
Policy Entropy: 4.44711
Value Function Loss: 1.80721

Mean KL Divergence: 0.00328
SB3 Clip Fraction: 0.02419
Policy Update Magnitude: 0.73376
Value Function Update Magnitude: 0.15292

Collected Steps per Second: 19,720.33347
Overall Steps per Second: 9,453.53667

Timestep Collection Time: 2.53667
Timestep Consumption Time: 2.75489
PPO Batch Consumption Time: 0.31510
Total Iteration Time: 5.29156

Cumulative Model Updates: 264
Cumulative Timesteps: 2,250,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.22075
Policy Entropy: 4.44509
Value Function Loss: 1.97005

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03270
Policy Update Magnitude: 0.74852
Value Function Update Magnitude: 0.17014

Collected Steps per Second: 21,433.10596
Overall Steps per Second: 9,988.04243

Timestep Collection Time: 2.33368
Timestep Consumption Time: 2.67411
PPO Batch Consumption Time: 0.29672
Total Iteration Time: 5.00779

Cumulative Model Updates: 270
Cumulative Timesteps: 2,300,764

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2300764...
Checkpoint 2300764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60.70885
Policy Entropy: 4.43692
Value Function Loss: 1.55935

Mean KL Divergence: 0.00390
SB3 Clip Fraction: 0.03829
Policy Update Magnitude: 0.72440
Value Function Update Magnitude: 0.13600

Collected Steps per Second: 19,834.81875
Overall Steps per Second: 9,489.04749

Timestep Collection Time: 2.52203
Timestep Consumption Time: 2.74973
PPO Batch Consumption Time: 0.30804
Total Iteration Time: 5.27176

Cumulative Model Updates: 276
Cumulative Timesteps: 2,350,788

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49.99406
Policy Entropy: 4.43878
Value Function Loss: 1.68125

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.02878
Policy Update Magnitude: 0.72882
Value Function Update Magnitude: 0.15708

Collected Steps per Second: 20,648.32469
Overall Steps per Second: 9,885.71490

Timestep Collection Time: 2.42189
Timestep Consumption Time: 2.63672
PPO Batch Consumption Time: 0.30323
Total Iteration Time: 5.05861

Cumulative Model Updates: 282
Cumulative Timesteps: 2,400,796

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 2400796...
Checkpoint 2400796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61.54093
Policy Entropy: 4.43538
Value Function Loss: 1.59837

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03200
Policy Update Magnitude: 0.74912
Value Function Update Magnitude: 0.17452

Collected Steps per Second: 20,513.73905
Overall Steps per Second: 9,601.27641

Timestep Collection Time: 2.43866
Timestep Consumption Time: 2.77169
PPO Batch Consumption Time: 0.31566
Total Iteration Time: 5.21035

Cumulative Model Updates: 288
Cumulative Timesteps: 2,450,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96.70111
Policy Entropy: 4.43381
Value Function Loss: 1.65237

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04298
Policy Update Magnitude: 0.73758
Value Function Update Magnitude: 0.22019

Collected Steps per Second: 20,684.44497
Overall Steps per Second: 9,601.69666

Timestep Collection Time: 2.41728
Timestep Consumption Time: 2.79014
PPO Batch Consumption Time: 0.31999
Total Iteration Time: 5.20741

Cumulative Model Updates: 294
Cumulative Timesteps: 2,500,822

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 2500822...
Checkpoint 2500822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96.11578
Policy Entropy: 4.42979
Value Function Loss: 1.67354

Mean KL Divergence: 0.00458
SB3 Clip Fraction: 0.04798
Policy Update Magnitude: 0.71606
Value Function Update Magnitude: 0.26712

Collected Steps per Second: 20,451.12762
Overall Steps per Second: 9,761.43248

Timestep Collection Time: 2.44593
Timestep Consumption Time: 2.67852
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 5.12445

Cumulative Model Updates: 300
Cumulative Timesteps: 2,550,844

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70.99318
Policy Entropy: 4.42775
Value Function Loss: 1.55142

Mean KL Divergence: 0.00404
SB3 Clip Fraction: 0.03889
Policy Update Magnitude: 0.72849
Value Function Update Magnitude: 0.23454

Collected Steps per Second: 20,847.37210
Overall Steps per Second: 9,757.89380

Timestep Collection Time: 2.39886
Timestep Consumption Time: 2.72622
PPO Batch Consumption Time: 0.30460
Total Iteration Time: 5.12508

Cumulative Model Updates: 306
Cumulative Timesteps: 2,600,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2600854...
Checkpoint 2600854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55.98254
Policy Entropy: 4.42444
Value Function Loss: 1.47017

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04462
Policy Update Magnitude: 0.70861
Value Function Update Magnitude: 0.22797

Collected Steps per Second: 20,198.46137
Overall Steps per Second: 9,774.67129

Timestep Collection Time: 2.47613
Timestep Consumption Time: 2.64056
PPO Batch Consumption Time: 0.29514
Total Iteration Time: 5.11669

Cumulative Model Updates: 312
Cumulative Timesteps: 2,650,868

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58.94388
Policy Entropy: 4.41590
Value Function Loss: 1.57308

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04398
Policy Update Magnitude: 0.70865
Value Function Update Magnitude: 0.19625

Collected Steps per Second: 21,293.65172
Overall Steps per Second: 9,847.07363

Timestep Collection Time: 2.34859
Timestep Consumption Time: 2.73008
PPO Batch Consumption Time: 0.30593
Total Iteration Time: 5.07867

Cumulative Model Updates: 318
Cumulative Timesteps: 2,700,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 2700878...
Checkpoint 2700878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.68049
Policy Entropy: 4.41609
Value Function Loss: 1.74726

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.03724
Policy Update Magnitude: 0.73659
Value Function Update Magnitude: 0.24692

Collected Steps per Second: 20,791.86162
Overall Steps per Second: 9,699.74595

Timestep Collection Time: 2.40671
Timestep Consumption Time: 2.75219
PPO Batch Consumption Time: 0.31258
Total Iteration Time: 5.15890

Cumulative Model Updates: 324
Cumulative Timesteps: 2,750,918

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77.06115
Policy Entropy: 4.40436
Value Function Loss: 1.69723

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04366
Policy Update Magnitude: 0.76135
Value Function Update Magnitude: 0.18939

Collected Steps per Second: 20,533.23753
Overall Steps per Second: 9,923.14888

Timestep Collection Time: 2.43517
Timestep Consumption Time: 2.60375
PPO Batch Consumption Time: 0.29650
Total Iteration Time: 5.03892

Cumulative Model Updates: 330
Cumulative Timesteps: 2,800,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 2800920...
Checkpoint 2800920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48.65881
Policy Entropy: 4.40312
Value Function Loss: 1.76562

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.04916
Policy Update Magnitude: 0.72429
Value Function Update Magnitude: 0.17603

Collected Steps per Second: 20,548.74769
Overall Steps per Second: 9,837.66031

Timestep Collection Time: 2.43421
Timestep Consumption Time: 2.65033
PPO Batch Consumption Time: 0.29452
Total Iteration Time: 5.08454

Cumulative Model Updates: 336
Cumulative Timesteps: 2,850,940

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.47959
Policy Entropy: 4.39599
Value Function Loss: 1.68346

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.04746
Policy Update Magnitude: 0.72663
Value Function Update Magnitude: 0.21406

Collected Steps per Second: 19,966.16793
Overall Steps per Second: 9,642.50813

Timestep Collection Time: 2.50514
Timestep Consumption Time: 2.68210
PPO Batch Consumption Time: 0.29771
Total Iteration Time: 5.18724

Cumulative Model Updates: 342
Cumulative Timesteps: 2,900,958

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 2900958...
Checkpoint 2900958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.32431
Policy Entropy: 4.39564
Value Function Loss: 1.74315

Mean KL Divergence: 0.00398
SB3 Clip Fraction: 0.03726
Policy Update Magnitude: 0.72432
Value Function Update Magnitude: 0.31453

Collected Steps per Second: 21,155.11353
Overall Steps per Second: 9,928.08195

Timestep Collection Time: 2.36406
Timestep Consumption Time: 2.67337
PPO Batch Consumption Time: 0.29528
Total Iteration Time: 5.03743

Cumulative Model Updates: 348
Cumulative Timesteps: 2,950,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57.34045
Policy Entropy: 4.39242
Value Function Loss: 1.70042

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04397
Policy Update Magnitude: 0.72232
Value Function Update Magnitude: 0.25248

Collected Steps per Second: 20,647.10410
Overall Steps per Second: 9,550.11185

Timestep Collection Time: 2.42310
Timestep Consumption Time: 2.81558
PPO Batch Consumption Time: 0.31780
Total Iteration Time: 5.23868

Cumulative Model Updates: 354
Cumulative Timesteps: 3,001,000

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 3001000...
Checkpoint 3001000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.42636
Policy Entropy: 4.39243
Value Function Loss: 1.42689

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.03325
Policy Update Magnitude: 0.73500
Value Function Update Magnitude: 0.25501

Collected Steps per Second: 20,598.75923
Overall Steps per Second: 9,886.01945

Timestep Collection Time: 2.42830
Timestep Consumption Time: 2.63137
PPO Batch Consumption Time: 0.29552
Total Iteration Time: 5.05967

Cumulative Model Updates: 360
Cumulative Timesteps: 3,051,020

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52.80229
Policy Entropy: 4.39558
Value Function Loss: 1.62672

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05165
Policy Update Magnitude: 0.68834
Value Function Update Magnitude: 0.33022

Collected Steps per Second: 20,887.43136
Overall Steps per Second: 9,798.87938

Timestep Collection Time: 2.39388
Timestep Consumption Time: 2.70895
PPO Batch Consumption Time: 0.30195
Total Iteration Time: 5.10283

Cumulative Model Updates: 366
Cumulative Timesteps: 3,101,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 3101022...
Checkpoint 3101022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.83305
Policy Entropy: 4.38927
Value Function Loss: 1.66934

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.03977
Policy Update Magnitude: 0.70225
Value Function Update Magnitude: 0.24217

Collected Steps per Second: 20,966.65335
Overall Steps per Second: 9,971.36855

Timestep Collection Time: 2.38560
Timestep Consumption Time: 2.63056
PPO Batch Consumption Time: 0.29522
Total Iteration Time: 5.01616

Cumulative Model Updates: 372
Cumulative Timesteps: 3,151,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.59354
Policy Entropy: 4.37979
Value Function Loss: 1.58656

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04327
Policy Update Magnitude: 0.72216
Value Function Update Magnitude: 0.30602

Collected Steps per Second: 20,284.48829
Overall Steps per Second: 9,672.98748

Timestep Collection Time: 2.46513
Timestep Consumption Time: 2.70431
PPO Batch Consumption Time: 0.31691
Total Iteration Time: 5.16945

Cumulative Model Updates: 378
Cumulative Timesteps: 3,201,044

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3201044...
Checkpoint 3201044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58.82247
Policy Entropy: 4.38413
Value Function Loss: 1.52593

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05255
Policy Update Magnitude: 0.68580
Value Function Update Magnitude: 0.30800

Collected Steps per Second: 21,274.46152
Overall Steps per Second: 9,820.14832

Timestep Collection Time: 2.35174
Timestep Consumption Time: 2.74309
PPO Batch Consumption Time: 0.31038
Total Iteration Time: 5.09483

Cumulative Model Updates: 384
Cumulative Timesteps: 3,251,076

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.39945
Policy Entropy: 4.37409
Value Function Loss: 1.57974

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.04991
Policy Update Magnitude: 0.67770
Value Function Update Magnitude: 0.25506

Collected Steps per Second: 21,311.99225
Overall Steps per Second: 10,092.94872

Timestep Collection Time: 2.34685
Timestep Consumption Time: 2.60869
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.95554

Cumulative Model Updates: 390
Cumulative Timesteps: 3,301,092

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 3301092...
Checkpoint 3301092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.94477
Policy Entropy: 4.36968
Value Function Loss: 1.54808

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04604
Policy Update Magnitude: 0.70147
Value Function Update Magnitude: 0.24653

Collected Steps per Second: 22,193.21977
Overall Steps per Second: 10,255.51693

Timestep Collection Time: 2.25429
Timestep Consumption Time: 2.62406
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.87835

Cumulative Model Updates: 396
Cumulative Timesteps: 3,351,122

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.11903
Policy Entropy: 4.37063
Value Function Loss: 1.58284

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04001
Policy Update Magnitude: 0.71182
Value Function Update Magnitude: 0.25017

Collected Steps per Second: 21,500.15152
Overall Steps per Second: 9,944.87795

Timestep Collection Time: 2.32677
Timestep Consumption Time: 2.70355
PPO Batch Consumption Time: 0.30469
Total Iteration Time: 5.03033

Cumulative Model Updates: 402
Cumulative Timesteps: 3,401,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 3401148...
Checkpoint 3401148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.90329
Policy Entropy: 4.37667
Value Function Loss: 1.47743

Mean KL Divergence: 0.00411
SB3 Clip Fraction: 0.03920
Policy Update Magnitude: 0.71794
Value Function Update Magnitude: 0.26522

Collected Steps per Second: 21,344.12053
Overall Steps per Second: 10,108.69056

Timestep Collection Time: 2.34322
Timestep Consumption Time: 2.60440
PPO Batch Consumption Time: 0.29993
Total Iteration Time: 4.94762

Cumulative Model Updates: 408
Cumulative Timesteps: 3,451,162

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.58828
Policy Entropy: 4.36546
Value Function Loss: 1.53704

Mean KL Divergence: 0.00418
SB3 Clip Fraction: 0.04370
Policy Update Magnitude: 0.72943
Value Function Update Magnitude: 0.26344

Collected Steps per Second: 19,482.74109
Overall Steps per Second: 9,229.60452

Timestep Collection Time: 2.56658
Timestep Consumption Time: 2.85120
PPO Batch Consumption Time: 0.32305
Total Iteration Time: 5.41778

Cumulative Model Updates: 414
Cumulative Timesteps: 3,501,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 3501166...
Checkpoint 3501166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63.04751
Policy Entropy: 4.36545
Value Function Loss: 1.55644

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04455
Policy Update Magnitude: 0.74052
Value Function Update Magnitude: 0.24922

Collected Steps per Second: 19,913.06486
Overall Steps per Second: 9,586.39883

Timestep Collection Time: 2.51192
Timestep Consumption Time: 2.70589
PPO Batch Consumption Time: 0.30787
Total Iteration Time: 5.21781

Cumulative Model Updates: 420
Cumulative Timesteps: 3,551,186

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79.51531
Policy Entropy: 4.36270
Value Function Loss: 1.57325

Mean KL Divergence: 0.00462
SB3 Clip Fraction: 0.05071
Policy Update Magnitude: 0.74715
Value Function Update Magnitude: 0.26345

Collected Steps per Second: 21,641.94604
Overall Steps per Second: 10,094.34228

Timestep Collection Time: 2.31116
Timestep Consumption Time: 2.64389
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.95505

Cumulative Model Updates: 426
Cumulative Timesteps: 3,601,204

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 3601204...
Checkpoint 3601204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.85613
Policy Entropy: 4.36024
Value Function Loss: 1.71227

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05009
Policy Update Magnitude: 0.76861
Value Function Update Magnitude: 0.33363

Collected Steps per Second: 20,570.33152
Overall Steps per Second: 9,777.34738

Timestep Collection Time: 2.43146
Timestep Consumption Time: 2.68403
PPO Batch Consumption Time: 0.30044
Total Iteration Time: 5.11550

Cumulative Model Updates: 432
Cumulative Timesteps: 3,651,220

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.71950
Policy Entropy: 4.36361
Value Function Loss: 1.56183

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05199
Policy Update Magnitude: 0.75577
Value Function Update Magnitude: 0.24682

Collected Steps per Second: 20,769.09938
Overall Steps per Second: 9,959.15223

Timestep Collection Time: 2.40858
Timestep Consumption Time: 2.61434
PPO Batch Consumption Time: 0.29946
Total Iteration Time: 5.02292

Cumulative Model Updates: 438
Cumulative Timesteps: 3,701,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 3701244...
Checkpoint 3701244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57.43420
Policy Entropy: 4.36048
Value Function Loss: 1.61188

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06071
Policy Update Magnitude: 0.74808
Value Function Update Magnitude: 0.22676

Collected Steps per Second: 20,654.20883
Overall Steps per Second: 9,861.07005

Timestep Collection Time: 2.42110
Timestep Consumption Time: 2.64995
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 5.07105

Cumulative Model Updates: 444
Cumulative Timesteps: 3,751,250

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.32098
Policy Entropy: 4.36254
Value Function Loss: 1.69213

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04072
Policy Update Magnitude: 0.75030
Value Function Update Magnitude: 0.28512

Collected Steps per Second: 20,832.55156
Overall Steps per Second: 9,923.34149

Timestep Collection Time: 2.40105
Timestep Consumption Time: 2.63959
PPO Batch Consumption Time: 0.29726
Total Iteration Time: 5.04064

Cumulative Model Updates: 450
Cumulative Timesteps: 3,801,270

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 3801270...
Checkpoint 3801270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.53167
Policy Entropy: 4.35881
Value Function Loss: 1.50593

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.04797
Policy Update Magnitude: 0.74719
Value Function Update Magnitude: 0.27222

Collected Steps per Second: 20,364.57582
Overall Steps per Second: 9,973.38411

Timestep Collection Time: 2.45652
Timestep Consumption Time: 2.55943
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 5.01595

Cumulative Model Updates: 456
Cumulative Timesteps: 3,851,296

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91.88915
Policy Entropy: 4.35582
Value Function Loss: 1.45051

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04408
Policy Update Magnitude: 0.73263
Value Function Update Magnitude: 0.30093

Collected Steps per Second: 20,927.78303
Overall Steps per Second: 9,872.50743

Timestep Collection Time: 2.38917
Timestep Consumption Time: 2.67540
PPO Batch Consumption Time: 0.29636
Total Iteration Time: 5.06457

Cumulative Model Updates: 462
Cumulative Timesteps: 3,901,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 3901296...
Checkpoint 3901296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59.10262
Policy Entropy: 4.35086
Value Function Loss: 1.52595

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04283
Policy Update Magnitude: 0.72878
Value Function Update Magnitude: 0.24240

Collected Steps per Second: 20,577.48170
Overall Steps per Second: 9,921.06581

Timestep Collection Time: 2.43101
Timestep Consumption Time: 2.61119
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 5.04220

Cumulative Model Updates: 468
Cumulative Timesteps: 3,951,320

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53.79845
Policy Entropy: 4.34926
Value Function Loss: 1.47438

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04788
Policy Update Magnitude: 0.73151
Value Function Update Magnitude: 0.22918

Collected Steps per Second: 21,457.53733
Overall Steps per Second: 10,076.09872

Timestep Collection Time: 2.33112
Timestep Consumption Time: 2.63311
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.96422

Cumulative Model Updates: 474
Cumulative Timesteps: 4,001,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 4001340...
Checkpoint 4001340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81.73852
Policy Entropy: 4.34586
Value Function Loss: 1.50322

Mean KL Divergence: 0.00442
SB3 Clip Fraction: 0.04519
Policy Update Magnitude: 0.73205
Value Function Update Magnitude: 0.27902

Collected Steps per Second: 20,630.64635
Overall Steps per Second: 9,806.44532

Timestep Collection Time: 2.42484
Timestep Consumption Time: 2.67650
PPO Batch Consumption Time: 0.29928
Total Iteration Time: 5.10134

Cumulative Model Updates: 480
Cumulative Timesteps: 4,051,366

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130.92301
Policy Entropy: 4.34875
Value Function Loss: 1.48519

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05117
Policy Update Magnitude: 0.72133
Value Function Update Magnitude: 0.24720

Collected Steps per Second: 20,126.61351
Overall Steps per Second: 9,742.24656

Timestep Collection Time: 2.48487
Timestep Consumption Time: 2.64865
PPO Batch Consumption Time: 0.30627
Total Iteration Time: 5.13352

Cumulative Model Updates: 486
Cumulative Timesteps: 4,101,378

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 4101378...
Checkpoint 4101378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.38828
Policy Entropy: 4.33977
Value Function Loss: 1.45780

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05741
Policy Update Magnitude: 0.71411
Value Function Update Magnitude: 0.23712

Collected Steps per Second: 20,855.97575
Overall Steps per Second: 9,766.97012

Timestep Collection Time: 2.39797
Timestep Consumption Time: 2.72255
PPO Batch Consumption Time: 0.30831
Total Iteration Time: 5.12052

Cumulative Model Updates: 492
Cumulative Timesteps: 4,151,390

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.33818
Policy Entropy: 4.34423
Value Function Loss: 1.44871

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05199
Policy Update Magnitude: 0.70043
Value Function Update Magnitude: 0.24899

Collected Steps per Second: 20,594.75169
Overall Steps per Second: 9,924.49341

Timestep Collection Time: 2.42858
Timestep Consumption Time: 2.61107
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 5.03965

Cumulative Model Updates: 498
Cumulative Timesteps: 4,201,406

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 4201406...
Checkpoint 4201406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65.31615
Policy Entropy: 4.33810
Value Function Loss: 1.34589

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04335
Policy Update Magnitude: 0.68635
Value Function Update Magnitude: 0.25320

Collected Steps per Second: 21,072.76473
Overall Steps per Second: 9,848.19250

Timestep Collection Time: 2.37377
Timestep Consumption Time: 2.70553
PPO Batch Consumption Time: 0.30311
Total Iteration Time: 5.07931

Cumulative Model Updates: 504
Cumulative Timesteps: 4,251,428

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94.89683
Policy Entropy: 4.33650
Value Function Loss: 1.36125

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04327
Policy Update Magnitude: 0.69053
Value Function Update Magnitude: 0.25495

Collected Steps per Second: 20,710.20745
Overall Steps per Second: 9,813.87918

Timestep Collection Time: 2.41436
Timestep Consumption Time: 2.68066
PPO Batch Consumption Time: 0.30196
Total Iteration Time: 5.09503

Cumulative Model Updates: 510
Cumulative Timesteps: 4,301,430

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 4301430...
Checkpoint 4301430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.80017
Policy Entropy: 4.33292
Value Function Loss: 1.36212

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05533
Policy Update Magnitude: 0.69387
Value Function Update Magnitude: 0.33061

Collected Steps per Second: 20,836.99398
Overall Steps per Second: 10,099.90235

Timestep Collection Time: 2.39996
Timestep Consumption Time: 2.55137
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.95134

Cumulative Model Updates: 516
Cumulative Timesteps: 4,351,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146.14837
Policy Entropy: 4.33997
Value Function Loss: 1.64820

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05670
Policy Update Magnitude: 0.69038
Value Function Update Magnitude: 0.29666

Collected Steps per Second: 20,589.80298
Overall Steps per Second: 9,775.95207

Timestep Collection Time: 2.43052
Timestep Consumption Time: 2.68857
PPO Batch Consumption Time: 0.29966
Total Iteration Time: 5.11909

Cumulative Model Updates: 522
Cumulative Timesteps: 4,401,482

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 4401482...
Checkpoint 4401482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105.09691
Policy Entropy: 4.33612
Value Function Loss: 1.68244

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05682
Policy Update Magnitude: 0.69121
Value Function Update Magnitude: 0.27274

Collected Steps per Second: 20,651.35490
Overall Steps per Second: 9,886.51790

Timestep Collection Time: 2.42231
Timestep Consumption Time: 2.63751
PPO Batch Consumption Time: 0.29639
Total Iteration Time: 5.05982

Cumulative Model Updates: 528
Cumulative Timesteps: 4,451,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105.97803
Policy Entropy: 4.33364
Value Function Loss: 1.72844

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05072
Policy Update Magnitude: 0.70018
Value Function Update Magnitude: 0.24157

Collected Steps per Second: 20,943.32579
Overall Steps per Second: 9,721.31769

Timestep Collection Time: 2.38778
Timestep Consumption Time: 2.75638
PPO Batch Consumption Time: 0.30749
Total Iteration Time: 5.14416

Cumulative Model Updates: 534
Cumulative Timesteps: 4,501,514

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 4501514...
Checkpoint 4501514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.79602
Policy Entropy: 4.32645
Value Function Loss: 1.73229

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05506
Policy Update Magnitude: 0.69682
Value Function Update Magnitude: 0.19581

Collected Steps per Second: 20,835.08958
Overall Steps per Second: 9,842.88106

Timestep Collection Time: 2.40095
Timestep Consumption Time: 2.68130
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 5.08225

Cumulative Model Updates: 540
Cumulative Timesteps: 4,551,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74.74058
Policy Entropy: 4.32933
Value Function Loss: 1.77424

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05878
Policy Update Magnitude: 0.70615
Value Function Update Magnitude: 0.17890

Collected Steps per Second: 20,339.20119
Overall Steps per Second: 9,923.32573

Timestep Collection Time: 2.45841
Timestep Consumption Time: 2.58043
PPO Batch Consumption Time: 0.29562
Total Iteration Time: 5.03883

Cumulative Model Updates: 546
Cumulative Timesteps: 4,601,540

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 4601540...
Checkpoint 4601540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.97004
Policy Entropy: 4.32746
Value Function Loss: 1.79281

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05577
Policy Update Magnitude: 0.71597
Value Function Update Magnitude: 0.17149

Collected Steps per Second: 20,774.26949
Overall Steps per Second: 9,939.76226

Timestep Collection Time: 2.40682
Timestep Consumption Time: 2.62348
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 5.03030

Cumulative Model Updates: 552
Cumulative Timesteps: 4,651,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.33245
Policy Entropy: 4.32570
Value Function Loss: 1.79603

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05799
Policy Update Magnitude: 0.73352
Value Function Update Magnitude: 0.17729

Collected Steps per Second: 20,225.57108
Overall Steps per Second: 9,580.61923

Timestep Collection Time: 2.47330
Timestep Consumption Time: 2.74807
PPO Batch Consumption Time: 0.31063
Total Iteration Time: 5.22137

Cumulative Model Updates: 558
Cumulative Timesteps: 4,701,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 4701564...
Checkpoint 4701564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.73314
Policy Entropy: 4.33288
Value Function Loss: 1.79700

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06584
Policy Update Magnitude: 0.70037
Value Function Update Magnitude: 0.18771

Collected Steps per Second: 21,505.74629
Overall Steps per Second: 10,080.93333

Timestep Collection Time: 2.32524
Timestep Consumption Time: 2.63521
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.96045

Cumulative Model Updates: 564
Cumulative Timesteps: 4,751,570

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92.79689
Policy Entropy: 4.32597
Value Function Loss: 1.80084

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05395
Policy Update Magnitude: 0.69622
Value Function Update Magnitude: 0.16661

Collected Steps per Second: 20,329.70802
Overall Steps per Second: 9,630.28637

Timestep Collection Time: 2.45945
Timestep Consumption Time: 2.73250
PPO Batch Consumption Time: 0.30335
Total Iteration Time: 5.19195

Cumulative Model Updates: 570
Cumulative Timesteps: 4,801,570

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 4801570...
Checkpoint 4801570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82.65153
Policy Entropy: 4.32189
Value Function Loss: 1.85821

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05951
Policy Update Magnitude: 0.72404
Value Function Update Magnitude: 0.18801

Collected Steps per Second: 20,492.88040
Overall Steps per Second: 9,796.73364

Timestep Collection Time: 2.44085
Timestep Consumption Time: 2.66494
PPO Batch Consumption Time: 0.31108
Total Iteration Time: 5.10578

Cumulative Model Updates: 576
Cumulative Timesteps: 4,851,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78.26633
Policy Entropy: 4.32120
Value Function Loss: 1.82259

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06431
Policy Update Magnitude: 0.71210
Value Function Update Magnitude: 0.23280

Collected Steps per Second: 20,642.74229
Overall Steps per Second: 9,640.25137

Timestep Collection Time: 2.42361
Timestep Consumption Time: 2.76609
PPO Batch Consumption Time: 0.31059
Total Iteration Time: 5.18970

Cumulative Model Updates: 582
Cumulative Timesteps: 4,901,620

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 4901620...
Checkpoint 4901620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.79524
Policy Entropy: 4.31356
Value Function Loss: 1.74592

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07239
Policy Update Magnitude: 0.69075
Value Function Update Magnitude: 0.21635

Collected Steps per Second: 20,603.24934
Overall Steps per Second: 9,910.20876

Timestep Collection Time: 2.42845
Timestep Consumption Time: 2.62028
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 5.04873

Cumulative Model Updates: 588
Cumulative Timesteps: 4,951,654

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.16490
Policy Entropy: 4.31029
Value Function Loss: 1.69721

Mean KL Divergence: 0.00505
SB3 Clip Fraction: 0.05524
Policy Update Magnitude: 0.69362
Value Function Update Magnitude: 0.18577

Collected Steps per Second: 20,425.80038
Overall Steps per Second: 9,575.03017

Timestep Collection Time: 2.44857
Timestep Consumption Time: 2.77481
PPO Batch Consumption Time: 0.31348
Total Iteration Time: 5.22338

Cumulative Model Updates: 594
Cumulative Timesteps: 5,001,668

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 5001668...
Checkpoint 5001668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78.40044
Policy Entropy: 4.30153
Value Function Loss: 1.72827

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.05989
Policy Update Magnitude: 0.68945
Value Function Update Magnitude: 0.15949

Collected Steps per Second: 20,773.71949
Overall Steps per Second: 9,916.47654

Timestep Collection Time: 2.40737
Timestep Consumption Time: 2.63575
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 5.04312

Cumulative Model Updates: 600
Cumulative Timesteps: 5,051,678

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97.20135
Policy Entropy: 4.30043
Value Function Loss: 1.78298

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05581
Policy Update Magnitude: 0.69306
Value Function Update Magnitude: 0.14944

Collected Steps per Second: 20,319.14084
Overall Steps per Second: 9,952.30154

Timestep Collection Time: 2.46152
Timestep Consumption Time: 2.56405
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 5.02557

Cumulative Model Updates: 606
Cumulative Timesteps: 5,101,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 5101694...
Checkpoint 5101694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112.02967
Policy Entropy: 4.29996
Value Function Loss: 1.79080

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05986
Policy Update Magnitude: 0.68856
Value Function Update Magnitude: 0.16619

Collected Steps per Second: 20,708.37832
Overall Steps per Second: 9,863.66323

Timestep Collection Time: 2.41670
Timestep Consumption Time: 2.65707
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 5.07377

Cumulative Model Updates: 612
Cumulative Timesteps: 5,151,740

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.90000
Policy Entropy: 4.29364
Value Function Loss: 1.80974

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06364
Policy Update Magnitude: 0.69010
Value Function Update Magnitude: 0.19298

Collected Steps per Second: 20,402.08109
Overall Steps per Second: 9,638.07792

Timestep Collection Time: 2.45112
Timestep Consumption Time: 2.73746
PPO Batch Consumption Time: 0.31369
Total Iteration Time: 5.18859

Cumulative Model Updates: 618
Cumulative Timesteps: 5,201,748

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 5201748...
Checkpoint 5201748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79.72002
Policy Entropy: 4.29122
Value Function Loss: 1.81842

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07362
Policy Update Magnitude: 0.68895
Value Function Update Magnitude: 0.21079

Collected Steps per Second: 21,118.90146
Overall Steps per Second: 9,777.98565

Timestep Collection Time: 2.36812
Timestep Consumption Time: 2.74664
PPO Batch Consumption Time: 0.30969
Total Iteration Time: 5.11475

Cumulative Model Updates: 624
Cumulative Timesteps: 5,251,760

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.03532
Policy Entropy: 4.29251
Value Function Loss: 1.81233

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.06949
Policy Update Magnitude: 0.67142
Value Function Update Magnitude: 0.21302

Collected Steps per Second: 20,429.57756
Overall Steps per Second: 9,680.87739

Timestep Collection Time: 2.44773
Timestep Consumption Time: 2.71772
PPO Batch Consumption Time: 0.30317
Total Iteration Time: 5.16544

Cumulative Model Updates: 630
Cumulative Timesteps: 5,301,766

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 5301766...
Checkpoint 5301766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128.14352
Policy Entropy: 4.28597
Value Function Loss: 1.75833

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.05785
Policy Update Magnitude: 0.66265
Value Function Update Magnitude: 0.20675

Collected Steps per Second: 20,577.07125
Overall Steps per Second: 9,790.44322

Timestep Collection Time: 2.43086
Timestep Consumption Time: 2.67820
PPO Batch Consumption Time: 0.30037
Total Iteration Time: 5.10906

Cumulative Model Updates: 636
Cumulative Timesteps: 5,351,786

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.80791
Policy Entropy: 4.28661
Value Function Loss: 1.69555

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05192
Policy Update Magnitude: 0.66307
Value Function Update Magnitude: 0.22900

Collected Steps per Second: 21,127.46745
Overall Steps per Second: 10,045.16508

Timestep Collection Time: 2.36706
Timestep Consumption Time: 2.61145
PPO Batch Consumption Time: 0.29027
Total Iteration Time: 4.97851

Cumulative Model Updates: 642
Cumulative Timesteps: 5,401,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 5401796...
Checkpoint 5401796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.91613
Policy Entropy: 4.28307
Value Function Loss: 1.70962

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.05788
Policy Update Magnitude: 0.66988
Value Function Update Magnitude: 0.20578

Collected Steps per Second: 20,719.17994
Overall Steps per Second: 9,885.89465

Timestep Collection Time: 2.41448
Timestep Consumption Time: 2.64586
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 5.06034

Cumulative Model Updates: 648
Cumulative Timesteps: 5,451,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83.92555
Policy Entropy: 4.28833
Value Function Loss: 1.71477

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.67158
Value Function Update Magnitude: 0.19352

Collected Steps per Second: 20,709.57094
Overall Steps per Second: 10,046.35708

Timestep Collection Time: 2.41483
Timestep Consumption Time: 2.56310
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.97792

Cumulative Model Updates: 654
Cumulative Timesteps: 5,501,832

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 5501832...
Checkpoint 5501832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95.23087
Policy Entropy: 4.28015
Value Function Loss: 1.79151

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06085
Policy Update Magnitude: 0.66828
Value Function Update Magnitude: 0.20853

Collected Steps per Second: 20,793.26143
Overall Steps per Second: 9,675.67963

Timestep Collection Time: 2.40578
Timestep Consumption Time: 2.76430
PPO Batch Consumption Time: 0.31182
Total Iteration Time: 5.17008

Cumulative Model Updates: 660
Cumulative Timesteps: 5,551,856

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.56146
Policy Entropy: 4.27774
Value Function Loss: 1.79860

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05675
Policy Update Magnitude: 0.67690
Value Function Update Magnitude: 0.24375

Collected Steps per Second: 18,434.07797
Overall Steps per Second: 9,390.09978

Timestep Collection Time: 2.71291
Timestep Consumption Time: 2.61291
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 5.32582

Cumulative Model Updates: 666
Cumulative Timesteps: 5,601,866

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 5601866...
Checkpoint 5601866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.07834
Policy Entropy: 4.26514
Value Function Loss: 1.75894

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.07038
Policy Update Magnitude: 0.66149
Value Function Update Magnitude: 0.25193

Collected Steps per Second: 22,076.88433
Overall Steps per Second: 10,122.10894

Timestep Collection Time: 2.26527
Timestep Consumption Time: 2.67540
PPO Batch Consumption Time: 0.29391
Total Iteration Time: 4.94067

Cumulative Model Updates: 672
Cumulative Timesteps: 5,651,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89.61101
Policy Entropy: 4.26946
Value Function Loss: 1.71310

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06557
Policy Update Magnitude: 0.64997
Value Function Update Magnitude: 0.20988

Collected Steps per Second: 21,222.92072
Overall Steps per Second: 10,039.45365

Timestep Collection Time: 2.35594
Timestep Consumption Time: 2.62441
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.98035

Cumulative Model Updates: 678
Cumulative Timesteps: 5,701,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 5701876...
Checkpoint 5701876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84.38934
Policy Entropy: 4.26043
Value Function Loss: 1.75614

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06230
Policy Update Magnitude: 0.64683
Value Function Update Magnitude: 0.17715

Collected Steps per Second: 21,244.26935
Overall Steps per Second: 10,198.73631

Timestep Collection Time: 2.35471
Timestep Consumption Time: 2.55022
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.90492

Cumulative Model Updates: 684
Cumulative Timesteps: 5,751,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71.92631
Policy Entropy: 4.27171
Value Function Loss: 1.78477

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05465
Policy Update Magnitude: 0.66311
Value Function Update Magnitude: 0.18997

Collected Steps per Second: 21,489.50997
Overall Steps per Second: 10,104.33339

Timestep Collection Time: 2.32737
Timestep Consumption Time: 2.62239
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.94976

Cumulative Model Updates: 690
Cumulative Timesteps: 5,801,914

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 5801914...
Checkpoint 5801914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80.44708
Policy Entropy: 4.26773
Value Function Loss: 1.78533

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04748
Policy Update Magnitude: 0.66995
Value Function Update Magnitude: 0.19563

Collected Steps per Second: 21,366.69155
Overall Steps per Second: 10,147.14558

Timestep Collection Time: 2.34065
Timestep Consumption Time: 2.58802
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.92868

Cumulative Model Updates: 696
Cumulative Timesteps: 5,851,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.36299
Policy Entropy: 4.27023
Value Function Loss: 1.72394

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05058
Policy Update Magnitude: 0.67452
Value Function Update Magnitude: 0.22529

Collected Steps per Second: 21,563.12902
Overall Steps per Second: 10,146.97147

Timestep Collection Time: 2.32016
Timestep Consumption Time: 2.61037
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.93054

Cumulative Model Updates: 702
Cumulative Timesteps: 5,901,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 5901956...
Checkpoint 5901956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76.92280
Policy Entropy: 4.26473
Value Function Loss: 1.70309

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05633
Policy Update Magnitude: 0.67786
Value Function Update Magnitude: 0.20577

Collected Steps per Second: 21,180.05614
Overall Steps per Second: 9,855.65993

Timestep Collection Time: 2.36137
Timestep Consumption Time: 2.71328
PPO Batch Consumption Time: 0.30503
Total Iteration Time: 5.07465

Cumulative Model Updates: 708
Cumulative Timesteps: 5,951,970

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82.33137
Policy Entropy: 4.26039
Value Function Loss: 1.75642

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07392
Policy Update Magnitude: 0.66313
Value Function Update Magnitude: 0.17795

Collected Steps per Second: 21,446.68672
Overall Steps per Second: 10,275.84822

Timestep Collection Time: 2.33146
Timestep Consumption Time: 2.53452
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.86597

Cumulative Model Updates: 714
Cumulative Timesteps: 6,001,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 6001972...
Checkpoint 6001972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99.77732
Policy Entropy: 4.25324
Value Function Loss: 1.81632

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07723
Policy Update Magnitude: 0.65979
Value Function Update Magnitude: 0.18533

Collected Steps per Second: 21,115.74014
Overall Steps per Second: 9,838.08067

Timestep Collection Time: 2.36942
Timestep Consumption Time: 2.71613
PPO Batch Consumption Time: 0.30509
Total Iteration Time: 5.08554

Cumulative Model Updates: 720
Cumulative Timesteps: 6,052,004

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95.23845
Policy Entropy: 4.25021
Value Function Loss: 1.86800

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07282
Policy Update Magnitude: 0.65143
Value Function Update Magnitude: 0.17335

Collected Steps per Second: 21,237.21129
Overall Steps per Second: 9,855.85997

Timestep Collection Time: 2.35502
Timestep Consumption Time: 2.71953
PPO Batch Consumption Time: 0.30494
Total Iteration Time: 5.07454

Cumulative Model Updates: 726
Cumulative Timesteps: 6,102,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 6102018...
Checkpoint 6102018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70.44595
Policy Entropy: 4.24373
Value Function Loss: 1.83629

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.66536
Value Function Update Magnitude: 0.16528

Collected Steps per Second: 20,414.41757
Overall Steps per Second: 9,507.23528

Timestep Collection Time: 2.45121
Timestep Consumption Time: 2.81215
PPO Batch Consumption Time: 0.32309
Total Iteration Time: 5.26336

Cumulative Model Updates: 732
Cumulative Timesteps: 6,152,058

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109.88679
Policy Entropy: 4.24737
Value Function Loss: 1.82998

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07357
Policy Update Magnitude: 0.67027
Value Function Update Magnitude: 0.15440

Collected Steps per Second: 19,550.58890
Overall Steps per Second: 9,210.23734

Timestep Collection Time: 2.55900
Timestep Consumption Time: 2.87300
PPO Batch Consumption Time: 0.32862
Total Iteration Time: 5.43200

Cumulative Model Updates: 738
Cumulative Timesteps: 6,202,088

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 6202088...
Checkpoint 6202088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.97438
Policy Entropy: 4.25150
Value Function Loss: 1.80980

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07654
Policy Update Magnitude: 0.65702
Value Function Update Magnitude: 0.15956

Collected Steps per Second: 20,310.56390
Overall Steps per Second: 9,723.05294

Timestep Collection Time: 2.46315
Timestep Consumption Time: 2.68215
PPO Batch Consumption Time: 0.31332
Total Iteration Time: 5.14530

Cumulative Model Updates: 744
Cumulative Timesteps: 6,252,116

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.31379
Policy Entropy: 4.25199
Value Function Loss: 1.85867

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.64273
Value Function Update Magnitude: 0.19707

Collected Steps per Second: 20,376.46142
Overall Steps per Second: 9,429.29075

Timestep Collection Time: 2.45470
Timestep Consumption Time: 2.84984
PPO Batch Consumption Time: 0.32240
Total Iteration Time: 5.30453

Cumulative Model Updates: 750
Cumulative Timesteps: 6,302,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 6302134...
Checkpoint 6302134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.17679
Policy Entropy: 4.24794
Value Function Loss: 1.82879

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07234
Policy Update Magnitude: 0.65996
Value Function Update Magnitude: 0.20993

Collected Steps per Second: 20,243.94639
Overall Steps per Second: 9,646.36792

Timestep Collection Time: 2.47096
Timestep Consumption Time: 2.71462
PPO Batch Consumption Time: 0.30964
Total Iteration Time: 5.18558

Cumulative Model Updates: 756
Cumulative Timesteps: 6,352,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 128.17994
Policy Entropy: 4.24126
Value Function Loss: 1.81553

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06235
Policy Update Magnitude: 0.67062
Value Function Update Magnitude: 0.19753

Collected Steps per Second: 20,979.85805
Overall Steps per Second: 9,869.92032

Timestep Collection Time: 2.38343
Timestep Consumption Time: 2.68287
PPO Batch Consumption Time: 0.29646
Total Iteration Time: 5.06630

Cumulative Model Updates: 762
Cumulative Timesteps: 6,402,160

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 6402160...
Checkpoint 6402160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.78097
Policy Entropy: 4.22497
Value Function Loss: 1.79218

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06848
Policy Update Magnitude: 0.66968
Value Function Update Magnitude: 0.19187

Collected Steps per Second: 20,881.74005
Overall Steps per Second: 9,965.69421

Timestep Collection Time: 2.39645
Timestep Consumption Time: 2.62498
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 5.02143

Cumulative Model Updates: 768
Cumulative Timesteps: 6,452,202

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72.92212
Policy Entropy: 4.21549
Value Function Loss: 1.80673

Mean KL Divergence: 0.00517
SB3 Clip Fraction: 0.06001
Policy Update Magnitude: 0.67050
Value Function Update Magnitude: 0.19010

Collected Steps per Second: 21,060.15675
Overall Steps per Second: 9,967.03067

Timestep Collection Time: 2.37463
Timestep Consumption Time: 2.64292
PPO Batch Consumption Time: 0.30648
Total Iteration Time: 5.01754

Cumulative Model Updates: 774
Cumulative Timesteps: 6,502,212

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 6502212...
Checkpoint 6502212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.77380
Policy Entropy: 4.19548
Value Function Loss: 1.83020

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.67878
Value Function Update Magnitude: 0.19189

Collected Steps per Second: 21,322.75264
Overall Steps per Second: 9,873.59648

Timestep Collection Time: 2.34510
Timestep Consumption Time: 2.71932
PPO Batch Consumption Time: 0.30903
Total Iteration Time: 5.06442

Cumulative Model Updates: 780
Cumulative Timesteps: 6,552,216

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80.80074
Policy Entropy: 4.20079
Value Function Loss: 1.82646

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07172
Policy Update Magnitude: 0.67632
Value Function Update Magnitude: 0.18481

Collected Steps per Second: 21,246.73062
Overall Steps per Second: 9,891.13638

Timestep Collection Time: 2.35377
Timestep Consumption Time: 2.70227
PPO Batch Consumption Time: 0.30820
Total Iteration Time: 5.05604

Cumulative Model Updates: 786
Cumulative Timesteps: 6,602,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 6602226...
Checkpoint 6602226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73.18637
Policy Entropy: 4.20396
Value Function Loss: 1.84513

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06972
Policy Update Magnitude: 0.66711
Value Function Update Magnitude: 0.19037

Collected Steps per Second: 18,198.68983
Overall Steps per Second: 9,447.98339

Timestep Collection Time: 2.74910
Timestep Consumption Time: 2.54621
PPO Batch Consumption Time: 0.28958
Total Iteration Time: 5.29531

Cumulative Model Updates: 792
Cumulative Timesteps: 6,652,256

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120.46709
Policy Entropy: 4.20563
Value Function Loss: 1.88953

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07080
Policy Update Magnitude: 0.66400
Value Function Update Magnitude: 0.18869

Collected Steps per Second: 19,966.93543
Overall Steps per Second: 9,705.53357

Timestep Collection Time: 2.50564
Timestep Consumption Time: 2.64915
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 5.15479

Cumulative Model Updates: 798
Cumulative Timesteps: 6,702,286

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 6702286...
Checkpoint 6702286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89.48444
Policy Entropy: 4.19867
Value Function Loss: 1.88202

Mean KL Divergence: 0.00564
SB3 Clip Fraction: 0.06651
Policy Update Magnitude: 0.67591
Value Function Update Magnitude: 0.18526

Collected Steps per Second: 20,852.56685
Overall Steps per Second: 9,972.26609

Timestep Collection Time: 2.39827
Timestep Consumption Time: 2.61664
PPO Batch Consumption Time: 0.30338
Total Iteration Time: 5.01491

Cumulative Model Updates: 804
Cumulative Timesteps: 6,752,296

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.56867
Policy Entropy: 4.19351
Value Function Loss: 1.86013

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06559
Policy Update Magnitude: 0.67933
Value Function Update Magnitude: 0.17847

Collected Steps per Second: 21,006.54580
Overall Steps per Second: 9,918.99527

Timestep Collection Time: 2.38069
Timestep Consumption Time: 2.66115
PPO Batch Consumption Time: 0.29867
Total Iteration Time: 5.04184

Cumulative Model Updates: 810
Cumulative Timesteps: 6,802,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 6802306...
Checkpoint 6802306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.33888
Policy Entropy: 4.18649
Value Function Loss: 1.79417

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07477
Policy Update Magnitude: 0.67752
Value Function Update Magnitude: 0.19798

Collected Steps per Second: 20,690.26931
Overall Steps per Second: 9,749.73561

Timestep Collection Time: 2.41775
Timestep Consumption Time: 2.71305
PPO Batch Consumption Time: 0.31051
Total Iteration Time: 5.13081

Cumulative Model Updates: 816
Cumulative Timesteps: 6,852,330

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 6852330...
Checkpoint 6852330 saved!
