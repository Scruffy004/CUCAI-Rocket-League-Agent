Checkpoint loaded!
Learner successfully initialized!
Press (p) to pause (c) to checkpoint, (q) to checkpoint and quit (after next iteration)

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.38199
Policy Entropy: 3.95867
Value Function Loss: 0.16024

Mean KL Divergence: 0.00178
SB3 Clip Fraction: 0.02167
Policy Update Magnitude: 0.26384
Value Function Update Magnitude: 0.22343

Collected Steps per Second: 7,130.51665
Overall Steps per Second: 4,035.49264

Timestep Collection Time: 7.01240
Timestep Consumption Time: 5.37816
PPO Batch Consumption Time: 2.15266
Total Iteration Time: 12.39056

Cumulative Model Updates: 171,110
Cumulative Timesteps: 1,426,916,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.90794
Policy Entropy: 3.80924
Value Function Loss: 0.12634

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.11992
Policy Update Magnitude: 0.34491
Value Function Update Magnitude: 0.28541

Collected Steps per Second: 21,512.76841
Overall Steps per Second: 13,362.49672

Timestep Collection Time: 2.32420
Timestep Consumption Time: 1.41761
PPO Batch Consumption Time: 0.33723
Total Iteration Time: 3.74182

Cumulative Model Updates: 171,112
Cumulative Timesteps: 1,426,966,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1426966252...
Checkpoint 1426966252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.98419
Policy Entropy: 3.78895
Value Function Loss: 0.09809

Mean KL Divergence: 0.02302
SB3 Clip Fraction: 0.22757
Policy Update Magnitude: 0.60528
Value Function Update Magnitude: 0.60397

Collected Steps per Second: 22,402.10456
Overall Steps per Second: 11,861.69061

Timestep Collection Time: 2.23256
Timestep Consumption Time: 1.98387
PPO Batch Consumption Time: 0.29668
Total Iteration Time: 4.21643

Cumulative Model Updates: 171,116
Cumulative Timesteps: 1,427,016,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,670.49581
Policy Entropy: 3.62833
Value Function Loss: 0.08045

Mean KL Divergence: 0.03155
SB3 Clip Fraction: 0.29781
Policy Update Magnitude: 0.77887
Value Function Update Magnitude: 0.87503

Collected Steps per Second: 21,659.07248
Overall Steps per Second: 10,614.72200

Timestep Collection Time: 2.30979
Timestep Consumption Time: 2.40328
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.71308

Cumulative Model Updates: 171,122
Cumulative Timesteps: 1,427,066,294

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1427066294...
Checkpoint 1427066294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,827.20881
Policy Entropy: 3.60692
Value Function Loss: 0.10385

Mean KL Divergence: 0.01868
SB3 Clip Fraction: 0.21152
Policy Update Magnitude: 0.80749
Value Function Update Magnitude: 0.69349

Collected Steps per Second: 21,020.12703
Overall Steps per Second: 10,568.13518

Timestep Collection Time: 2.37991
Timestep Consumption Time: 2.35375
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.73366

Cumulative Model Updates: 171,128
Cumulative Timesteps: 1,427,116,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,109.82675
Policy Entropy: 3.53312
Value Function Loss: 0.13416

Mean KL Divergence: 0.01708
SB3 Clip Fraction: 0.19830
Policy Update Magnitude: 0.89483
Value Function Update Magnitude: 0.60073

Collected Steps per Second: 21,278.76510
Overall Steps per Second: 10,565.44596

Timestep Collection Time: 2.34995
Timestep Consumption Time: 2.38284
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.73279

Cumulative Model Updates: 171,134
Cumulative Timesteps: 1,427,166,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1427166324...
Checkpoint 1427166324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,064.15603
Policy Entropy: 3.54205
Value Function Loss: 0.15789

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.17546
Policy Update Magnitude: 0.90398
Value Function Update Magnitude: 0.45868

Collected Steps per Second: 21,408.05850
Overall Steps per Second: 10,518.76016

Timestep Collection Time: 2.33678
Timestep Consumption Time: 2.41910
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.75588

Cumulative Model Updates: 171,140
Cumulative Timesteps: 1,427,216,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,644.78256
Policy Entropy: 3.57495
Value Function Loss: 0.13957

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.17821
Policy Update Magnitude: 0.87678
Value Function Update Magnitude: 0.38986

Collected Steps per Second: 21,774.84873
Overall Steps per Second: 10,530.47012

Timestep Collection Time: 2.29659
Timestep Consumption Time: 2.45229
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.74889

Cumulative Model Updates: 171,146
Cumulative Timesteps: 1,427,266,358

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1427266358...
Checkpoint 1427266358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,419.04485
Policy Entropy: 3.56757
Value Function Loss: 0.13676

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.16166
Policy Update Magnitude: 0.78861
Value Function Update Magnitude: 0.36180

Collected Steps per Second: 21,359.11411
Overall Steps per Second: 10,533.46868

Timestep Collection Time: 2.34204
Timestep Consumption Time: 2.40701
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.74905

Cumulative Model Updates: 171,152
Cumulative Timesteps: 1,427,316,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,231.61864
Policy Entropy: 3.59712
Value Function Loss: 0.12023

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15442
Policy Update Magnitude: 0.72571
Value Function Update Magnitude: 0.35013

Collected Steps per Second: 21,771.41821
Overall Steps per Second: 10,533.11778

Timestep Collection Time: 2.29815
Timestep Consumption Time: 2.45201
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.75016

Cumulative Model Updates: 171,158
Cumulative Timesteps: 1,427,366,416

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1427366416...
Checkpoint 1427366416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,093.14473
Policy Entropy: 3.59271
Value Function Loss: 0.10824

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.17801
Policy Update Magnitude: 0.66225
Value Function Update Magnitude: 0.46898

Collected Steps per Second: 21,620.87927
Overall Steps per Second: 10,545.98728

Timestep Collection Time: 2.31258
Timestep Consumption Time: 2.42856
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.74114

Cumulative Model Updates: 171,164
Cumulative Timesteps: 1,427,416,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,340.42683
Policy Entropy: 3.62553
Value Function Loss: 0.09525

Mean KL Divergence: 0.01211
SB3 Clip Fraction: 0.15482
Policy Update Magnitude: 0.61938
Value Function Update Magnitude: 0.45209

Collected Steps per Second: 22,039.44525
Overall Steps per Second: 10,616.85083

Timestep Collection Time: 2.26975
Timestep Consumption Time: 2.44201
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.71176

Cumulative Model Updates: 171,170
Cumulative Timesteps: 1,427,466,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1427466440...
Checkpoint 1427466440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,321.11959
Policy Entropy: 3.64225
Value Function Loss: 0.07716

Mean KL Divergence: 0.01415
SB3 Clip Fraction: 0.16914
Policy Update Magnitude: 0.62328
Value Function Update Magnitude: 0.39085

Collected Steps per Second: 22,346.11216
Overall Steps per Second: 10,645.44280

Timestep Collection Time: 2.23851
Timestep Consumption Time: 2.46040
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.69891

Cumulative Model Updates: 171,176
Cumulative Timesteps: 1,427,516,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,198.81602
Policy Entropy: 3.60721
Value Function Loss: 0.09607

Mean KL Divergence: 0.02139
SB3 Clip Fraction: 0.22712
Policy Update Magnitude: 0.66345
Value Function Update Magnitude: 0.37379

Collected Steps per Second: 22,270.11859
Overall Steps per Second: 10,539.95616

Timestep Collection Time: 2.24624
Timestep Consumption Time: 2.49989
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.74613

Cumulative Model Updates: 171,182
Cumulative Timesteps: 1,427,566,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1427566486...
Checkpoint 1427566486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,232.91447
Policy Entropy: 3.61396
Value Function Loss: 0.11686

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.17539
Policy Update Magnitude: 0.70345
Value Function Update Magnitude: 0.45986

Collected Steps per Second: 22,253.23973
Overall Steps per Second: 10,436.28861

Timestep Collection Time: 2.24776
Timestep Consumption Time: 2.54513
PPO Batch Consumption Time: 0.30001
Total Iteration Time: 4.79289

Cumulative Model Updates: 171,188
Cumulative Timesteps: 1,427,616,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,857.33015
Policy Entropy: 3.62926
Value Function Loss: 0.14044

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.14974
Policy Update Magnitude: 0.76748
Value Function Update Magnitude: 0.44391

Collected Steps per Second: 21,444.18174
Overall Steps per Second: 10,462.50278

Timestep Collection Time: 2.33266
Timestep Consumption Time: 2.44841
PPO Batch Consumption Time: 0.28023
Total Iteration Time: 4.78107

Cumulative Model Updates: 171,194
Cumulative Timesteps: 1,427,666,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1427666528...
Checkpoint 1427666528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,651.20165
Policy Entropy: 3.66192
Value Function Loss: 0.12791

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.86248
Value Function Update Magnitude: 0.36434

Collected Steps per Second: 22,364.04081
Overall Steps per Second: 10,713.29436

Timestep Collection Time: 2.23627
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.66822

Cumulative Model Updates: 171,200
Cumulative Timesteps: 1,427,716,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,164.68105
Policy Entropy: 3.68259
Value Function Loss: 0.10565

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.77500
Value Function Update Magnitude: 0.35115

Collected Steps per Second: 22,193.25577
Overall Steps per Second: 10,478.18901

Timestep Collection Time: 2.25510
Timestep Consumption Time: 2.52130
PPO Batch Consumption Time: 0.29506
Total Iteration Time: 4.77640

Cumulative Model Updates: 171,206
Cumulative Timesteps: 1,427,766,588

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1427766588...
Checkpoint 1427766588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,277.15485
Policy Entropy: 3.67986
Value Function Loss: 0.07804

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.65410
Value Function Update Magnitude: 0.38773

Collected Steps per Second: 22,256.67457
Overall Steps per Second: 10,571.17340

Timestep Collection Time: 2.24652
Timestep Consumption Time: 2.48333
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.72984

Cumulative Model Updates: 171,212
Cumulative Timesteps: 1,427,816,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,121.95876
Policy Entropy: 3.69944
Value Function Loss: 0.05220

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.56943
Value Function Update Magnitude: 0.41302

Collected Steps per Second: 21,664.64266
Overall Steps per Second: 10,541.95563

Timestep Collection Time: 2.30846
Timestep Consumption Time: 2.43563
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.74409

Cumulative Model Updates: 171,218
Cumulative Timesteps: 1,427,866,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1427866600...
Checkpoint 1427866600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,121.95876
Policy Entropy: 3.69275
Value Function Loss: 0.03739

Mean KL Divergence: 0.00792
SB3 Clip Fraction: 0.10203
Policy Update Magnitude: 0.56115
Value Function Update Magnitude: 0.45320

Collected Steps per Second: 21,914.53376
Overall Steps per Second: 10,633.43694

Timestep Collection Time: 2.28250
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.70403

Cumulative Model Updates: 171,224
Cumulative Timesteps: 1,427,916,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,121.95876
Policy Entropy: 3.69722
Value Function Loss: 0.03256

Mean KL Divergence: 0.01155
SB3 Clip Fraction: 0.14112
Policy Update Magnitude: 0.52338
Value Function Update Magnitude: 0.45875

Collected Steps per Second: 22,135.15639
Overall Steps per Second: 10,457.66859

Timestep Collection Time: 2.26021
Timestep Consumption Time: 2.52384
PPO Batch Consumption Time: 0.29326
Total Iteration Time: 4.78405

Cumulative Model Updates: 171,230
Cumulative Timesteps: 1,427,966,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1427966650...
Checkpoint 1427966650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,121.95876
Policy Entropy: 3.68528
Value Function Loss: 0.02686

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15324
Policy Update Magnitude: 0.41087
Value Function Update Magnitude: 0.32287

Collected Steps per Second: 21,408.46951
Overall Steps per Second: 10,628.73700

Timestep Collection Time: 2.33702
Timestep Consumption Time: 2.37022
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.70724

Cumulative Model Updates: 171,236
Cumulative Timesteps: 1,428,016,682

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,121.95876
Policy Entropy: 3.68262
Value Function Loss: 0.03494

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.19205
Policy Update Magnitude: 0.33704
Value Function Update Magnitude: 0.30028

Collected Steps per Second: 22,096.44838
Overall Steps per Second: 10,751.06656

Timestep Collection Time: 2.26290
Timestep Consumption Time: 2.38799
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.65089

Cumulative Model Updates: 171,242
Cumulative Timesteps: 1,428,066,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1428066684...
Checkpoint 1428066684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.66612
Value Function Loss: 0.03769

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.32065
Value Function Update Magnitude: 0.36608

Collected Steps per Second: 21,896.49488
Overall Steps per Second: 10,647.70850

Timestep Collection Time: 2.28466
Timestep Consumption Time: 2.41363
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.69829

Cumulative Model Updates: 171,248
Cumulative Timesteps: 1,428,116,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.66920
Value Function Loss: 0.03455

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.14539
Policy Update Magnitude: 0.35679
Value Function Update Magnitude: 0.36138

Collected Steps per Second: 22,079.43760
Overall Steps per Second: 10,545.99571

Timestep Collection Time: 2.26573
Timestep Consumption Time: 2.47787
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.74360

Cumulative Model Updates: 171,254
Cumulative Timesteps: 1,428,166,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1428166736...
Checkpoint 1428166736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.66299
Value Function Loss: 0.03038

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15745
Policy Update Magnitude: 0.35262
Value Function Update Magnitude: 0.35758

Collected Steps per Second: 22,418.27634
Overall Steps per Second: 10,600.28039

Timestep Collection Time: 2.23157
Timestep Consumption Time: 2.48793
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.71950

Cumulative Model Updates: 171,260
Cumulative Timesteps: 1,428,216,764

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.66327
Value Function Loss: 0.03387

Mean KL Divergence: 0.01442
SB3 Clip Fraction: 0.18555
Policy Update Magnitude: 0.35617
Value Function Update Magnitude: 0.47759

Collected Steps per Second: 21,466.38930
Overall Steps per Second: 10,314.64194

Timestep Collection Time: 2.33025
Timestep Consumption Time: 2.51936
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.84961

Cumulative Model Updates: 171,266
Cumulative Timesteps: 1,428,266,786

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1428266786...
Checkpoint 1428266786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.65215
Value Function Loss: 0.03952

Mean KL Divergence: 0.01446
SB3 Clip Fraction: 0.16873
Policy Update Magnitude: 0.49666
Value Function Update Magnitude: 0.52052

Collected Steps per Second: 21,947.29506
Overall Steps per Second: 10,431.86507

Timestep Collection Time: 2.27828
Timestep Consumption Time: 2.51492
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.79320

Cumulative Model Updates: 171,272
Cumulative Timesteps: 1,428,316,788

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.63169
Value Function Loss: 0.03949

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16122
Policy Update Magnitude: 0.48639
Value Function Update Magnitude: 0.49816

Collected Steps per Second: 20,666.07037
Overall Steps per Second: 10,171.02409

Timestep Collection Time: 2.41962
Timestep Consumption Time: 2.49670
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.91632

Cumulative Model Updates: 171,278
Cumulative Timesteps: 1,428,366,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1428366792...
Checkpoint 1428366792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.64904
Value Function Loss: 0.03349

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.18504
Policy Update Magnitude: 0.47774
Value Function Update Magnitude: 0.49650

Collected Steps per Second: 21,612.70574
Overall Steps per Second: 10,409.77391

Timestep Collection Time: 2.31521
Timestep Consumption Time: 2.49162
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.80683

Cumulative Model Updates: 171,284
Cumulative Timesteps: 1,428,416,830

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.66066
Value Function Loss: 0.02550

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.46167
Value Function Update Magnitude: 0.48885

Collected Steps per Second: 21,940.23800
Overall Steps per Second: 10,082.85840

Timestep Collection Time: 2.28029
Timestep Consumption Time: 2.68160
PPO Batch Consumption Time: 0.31777
Total Iteration Time: 4.96189

Cumulative Model Updates: 171,290
Cumulative Timesteps: 1,428,466,860

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1428466860...
Checkpoint 1428466860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.69332
Value Function Loss: 0.02254

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.41030
Value Function Update Magnitude: 0.41560

Collected Steps per Second: 21,127.15238
Overall Steps per Second: 10,229.04051

Timestep Collection Time: 2.36710
Timestep Consumption Time: 2.52193
PPO Batch Consumption Time: 0.28983
Total Iteration Time: 4.88902

Cumulative Model Updates: 171,296
Cumulative Timesteps: 1,428,516,870

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.68816
Value Function Loss: 0.02494

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15815
Policy Update Magnitude: 0.34296
Value Function Update Magnitude: 0.30389

Collected Steps per Second: 20,831.91201
Overall Steps per Second: 10,256.81093

Timestep Collection Time: 2.40093
Timestep Consumption Time: 2.47544
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.87637

Cumulative Model Updates: 171,302
Cumulative Timesteps: 1,428,566,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1428566886...
Checkpoint 1428566886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.68907
Value Function Loss: 0.02230

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.17531
Policy Update Magnitude: 0.27639
Value Function Update Magnitude: 0.24040

Collected Steps per Second: 19,828.68703
Overall Steps per Second: 9,981.49122

Timestep Collection Time: 2.52281
Timestep Consumption Time: 2.48887
PPO Batch Consumption Time: 0.29863
Total Iteration Time: 5.01168

Cumulative Model Updates: 171,308
Cumulative Timesteps: 1,428,616,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.66737
Value Function Loss: 0.02450

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.15763
Policy Update Magnitude: 0.27917
Value Function Update Magnitude: 0.27016

Collected Steps per Second: 18,527.79032
Overall Steps per Second: 9,684.46876

Timestep Collection Time: 2.69994
Timestep Consumption Time: 2.46544
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 5.16538

Cumulative Model Updates: 171,314
Cumulative Timesteps: 1,428,666,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1428666934...
Checkpoint 1428666934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.65888
Value Function Loss: 0.02540

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16044
Policy Update Magnitude: 0.29166
Value Function Update Magnitude: 0.36607

Collected Steps per Second: 21,998.18634
Overall Steps per Second: 10,484.04983

Timestep Collection Time: 2.27319
Timestep Consumption Time: 2.49653
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.76972

Cumulative Model Updates: 171,320
Cumulative Timesteps: 1,428,716,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,721.49178
Policy Entropy: 3.64419
Value Function Loss: 0.03085

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.16714
Policy Update Magnitude: 0.41750
Value Function Update Magnitude: 0.51760

Collected Steps per Second: 21,330.11869
Overall Steps per Second: 10,222.79592

Timestep Collection Time: 2.34626
Timestep Consumption Time: 2.54927
PPO Batch Consumption Time: 0.29894
Total Iteration Time: 4.89553

Cumulative Model Updates: 171,326
Cumulative Timesteps: 1,428,766,986

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1428766986...
Checkpoint 1428766986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,335.47465
Policy Entropy: 3.64188
Value Function Loss: 0.03367

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08900
Policy Update Magnitude: 0.50108
Value Function Update Magnitude: 0.49980

Collected Steps per Second: 20,467.62901
Overall Steps per Second: 10,131.42021

Timestep Collection Time: 2.44366
Timestep Consumption Time: 2.49306
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.93672

Cumulative Model Updates: 171,332
Cumulative Timesteps: 1,428,817,002

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,335.47465
Policy Entropy: 3.64967
Value Function Loss: 0.03970

Mean KL Divergence: 0.00686
SB3 Clip Fraction: 0.08051
Policy Update Magnitude: 0.60873
Value Function Update Magnitude: 0.45647

Collected Steps per Second: 21,935.51625
Overall Steps per Second: 10,125.30203

Timestep Collection Time: 2.27941
Timestep Consumption Time: 2.65872
PPO Batch Consumption Time: 0.29921
Total Iteration Time: 4.93812

Cumulative Model Updates: 171,338
Cumulative Timesteps: 1,428,867,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1428867002...
Checkpoint 1428867002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,335.47465
Policy Entropy: 3.63726
Value Function Loss: 0.04288

Mean KL Divergence: 0.01632
SB3 Clip Fraction: 0.20283
Policy Update Magnitude: 0.55299
Value Function Update Magnitude: 0.53351

Collected Steps per Second: 21,173.35604
Overall Steps per Second: 10,125.05301

Timestep Collection Time: 2.36288
Timestep Consumption Time: 2.57833
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.94121

Cumulative Model Updates: 171,344
Cumulative Timesteps: 1,428,917,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,947.29207
Policy Entropy: 3.65988
Value Function Loss: 0.04357

Mean KL Divergence: 0.01726
SB3 Clip Fraction: 0.20421
Policy Update Magnitude: 0.49700
Value Function Update Magnitude: 0.49424

Collected Steps per Second: 20,779.91234
Overall Steps per Second: 10,059.53534

Timestep Collection Time: 2.40675
Timestep Consumption Time: 2.56485
PPO Batch Consumption Time: 0.29886
Total Iteration Time: 4.97160

Cumulative Model Updates: 171,350
Cumulative Timesteps: 1,428,967,044

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1428967044...
Checkpoint 1428967044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,285.14029
Policy Entropy: 3.65112
Value Function Loss: 0.04930

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15424
Policy Update Magnitude: 0.52922
Value Function Update Magnitude: 0.55999

Collected Steps per Second: 21,981.08591
Overall Steps per Second: 10,449.49851

Timestep Collection Time: 2.27532
Timestep Consumption Time: 2.51094
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.78626

Cumulative Model Updates: 171,356
Cumulative Timesteps: 1,429,017,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,270.64925
Policy Entropy: 3.64312
Value Function Loss: 0.05255

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16759
Policy Update Magnitude: 0.58857
Value Function Update Magnitude: 0.54635

Collected Steps per Second: 21,947.15715
Overall Steps per Second: 10,388.41643

Timestep Collection Time: 2.27856
Timestep Consumption Time: 2.53526
PPO Batch Consumption Time: 0.29287
Total Iteration Time: 4.81382

Cumulative Model Updates: 171,362
Cumulative Timesteps: 1,429,067,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1429067066...
Checkpoint 1429067066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,270.64925
Policy Entropy: 3.63301
Value Function Loss: 0.05558

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16057
Policy Update Magnitude: 0.53407
Value Function Update Magnitude: 0.45673

Collected Steps per Second: 21,942.70735
Overall Steps per Second: 10,482.48474

Timestep Collection Time: 2.27966
Timestep Consumption Time: 2.49230
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.77196

Cumulative Model Updates: 171,368
Cumulative Timesteps: 1,429,117,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,270.64925
Policy Entropy: 3.65870
Value Function Loss: 0.04483

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14540
Policy Update Magnitude: 0.42507
Value Function Update Magnitude: 0.35538

Collected Steps per Second: 21,793.64743
Overall Steps per Second: 10,572.00997

Timestep Collection Time: 2.29434
Timestep Consumption Time: 2.43532
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.72966

Cumulative Model Updates: 171,374
Cumulative Timesteps: 1,429,167,090

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1429167090...
Checkpoint 1429167090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,270.64925
Policy Entropy: 3.65708
Value Function Loss: 0.03658

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.37085
Value Function Update Magnitude: 0.39606

Collected Steps per Second: 21,526.32890
Overall Steps per Second: 10,519.50307

Timestep Collection Time: 2.32302
Timestep Consumption Time: 2.43063
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.75365

Cumulative Model Updates: 171,380
Cumulative Timesteps: 1,429,217,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,270.64925
Policy Entropy: 3.64858
Value Function Loss: 0.03888

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.42356
Value Function Update Magnitude: 0.38739

Collected Steps per Second: 21,819.19228
Overall Steps per Second: 10,581.08314

Timestep Collection Time: 2.29239
Timestep Consumption Time: 2.43473
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.72712

Cumulative Model Updates: 171,386
Cumulative Timesteps: 1,429,267,114

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1429267114...
Checkpoint 1429267114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,270.64925
Policy Entropy: 3.65573
Value Function Loss: 0.03603

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14076
Policy Update Magnitude: 0.46751
Value Function Update Magnitude: 0.44043

Collected Steps per Second: 21,150.21755
Overall Steps per Second: 10,461.40324

Timestep Collection Time: 2.36423
Timestep Consumption Time: 2.41562
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.77986

Cumulative Model Updates: 171,392
Cumulative Timesteps: 1,429,317,118

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,270.64925
Policy Entropy: 3.63952
Value Function Loss: 0.03786

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.15668
Policy Update Magnitude: 0.44318
Value Function Update Magnitude: 0.47222

Collected Steps per Second: 22,546.89181
Overall Steps per Second: 10,645.58816

Timestep Collection Time: 2.21840
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.69847

Cumulative Model Updates: 171,398
Cumulative Timesteps: 1,429,367,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1429367136...
Checkpoint 1429367136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,270.64925
Policy Entropy: 3.65516
Value Function Loss: 0.03019

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.15376
Policy Update Magnitude: 0.37817
Value Function Update Magnitude: 0.40215

Collected Steps per Second: 22,095.71011
Overall Steps per Second: 10,492.48116

Timestep Collection Time: 2.26352
Timestep Consumption Time: 2.50314
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.76665

Cumulative Model Updates: 171,404
Cumulative Timesteps: 1,429,417,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,876.88902
Policy Entropy: 3.65435
Value Function Loss: 0.03166

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.32507
Value Function Update Magnitude: 0.41538

Collected Steps per Second: 22,814.00043
Overall Steps per Second: 10,822.06936

Timestep Collection Time: 2.19207
Timestep Consumption Time: 2.42904
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.62111

Cumulative Model Updates: 171,410
Cumulative Timesteps: 1,429,467,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1429467160...
Checkpoint 1429467160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,314.31481
Policy Entropy: 3.70012
Value Function Loss: 0.02719

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11884
Policy Update Magnitude: 0.32583
Value Function Update Magnitude: 0.47038

Collected Steps per Second: 21,859.17643
Overall Steps per Second: 10,275.80911

Timestep Collection Time: 2.28883
Timestep Consumption Time: 2.58008
PPO Batch Consumption Time: 0.30442
Total Iteration Time: 4.86891

Cumulative Model Updates: 171,416
Cumulative Timesteps: 1,429,517,192

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,314.31481
Policy Entropy: 3.68874
Value Function Loss: 0.02918

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.31869
Value Function Update Magnitude: 0.53561

Collected Steps per Second: 21,100.31306
Overall Steps per Second: 10,229.86724

Timestep Collection Time: 2.37020
Timestep Consumption Time: 2.51862
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.88882

Cumulative Model Updates: 171,422
Cumulative Timesteps: 1,429,567,204

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1429567204...
Checkpoint 1429567204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,314.31481
Policy Entropy: 3.68312
Value Function Loss: 0.02584

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.29259
Value Function Update Magnitude: 0.43497

Collected Steps per Second: 21,780.72942
Overall Steps per Second: 10,362.36135

Timestep Collection Time: 2.29662
Timestep Consumption Time: 2.53066
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.82728

Cumulative Model Updates: 171,428
Cumulative Timesteps: 1,429,617,226

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,314.31481
Policy Entropy: 3.67292
Value Function Loss: 0.02452

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13474
Policy Update Magnitude: 0.25744
Value Function Update Magnitude: 0.33540

Collected Steps per Second: 21,897.70350
Overall Steps per Second: 10,539.98514

Timestep Collection Time: 2.28453
Timestep Consumption Time: 2.46177
PPO Batch Consumption Time: 0.28039
Total Iteration Time: 4.74631

Cumulative Model Updates: 171,434
Cumulative Timesteps: 1,429,667,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1429667252...
Checkpoint 1429667252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,314.31481
Policy Entropy: 3.66980
Value Function Loss: 0.02145

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.25456
Value Function Update Magnitude: 0.25190

Collected Steps per Second: 21,104.83379
Overall Steps per Second: 10,394.07439

Timestep Collection Time: 2.36941
Timestep Consumption Time: 2.44160
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.81101

Cumulative Model Updates: 171,440
Cumulative Timesteps: 1,429,717,258

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.67985
Value Function Loss: 0.02364

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.26570
Value Function Update Magnitude: 0.27021

Collected Steps per Second: 21,644.53833
Overall Steps per Second: 10,747.62359

Timestep Collection Time: 2.31088
Timestep Consumption Time: 2.34298
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.65387

Cumulative Model Updates: 171,446
Cumulative Timesteps: 1,429,767,276

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1429767276...
Checkpoint 1429767276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.66040
Value Function Loss: 0.02641

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.29653
Value Function Update Magnitude: 0.37669

Collected Steps per Second: 22,105.08131
Overall Steps per Second: 10,565.32697

Timestep Collection Time: 2.26219
Timestep Consumption Time: 2.47083
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.73303

Cumulative Model Updates: 171,452
Cumulative Timesteps: 1,429,817,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.66255
Value Function Loss: 0.03002

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.36413
Value Function Update Magnitude: 0.46784

Collected Steps per Second: 22,398.79111
Overall Steps per Second: 10,612.72315

Timestep Collection Time: 2.23253
Timestep Consumption Time: 2.47936
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.71189

Cumulative Model Updates: 171,458
Cumulative Timesteps: 1,429,867,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1429867288...
Checkpoint 1429867288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.65697
Value Function Loss: 0.03072

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13475
Policy Update Magnitude: 0.41786
Value Function Update Magnitude: 0.48193

Collected Steps per Second: 22,511.15883
Overall Steps per Second: 10,625.32718

Timestep Collection Time: 2.22219
Timestep Consumption Time: 2.48581
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.70800

Cumulative Model Updates: 171,464
Cumulative Timesteps: 1,429,917,312

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.66973
Value Function Loss: 0.02709

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.37805
Value Function Update Magnitude: 0.49809

Collected Steps per Second: 22,895.45430
Overall Steps per Second: 10,785.73504

Timestep Collection Time: 2.18480
Timestep Consumption Time: 2.45299
PPO Batch Consumption Time: 0.28025
Total Iteration Time: 4.63779

Cumulative Model Updates: 171,470
Cumulative Timesteps: 1,429,967,334

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1429967334...
Checkpoint 1429967334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.69054
Value Function Loss: 0.02351

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.31295
Value Function Update Magnitude: 0.41917

Collected Steps per Second: 22,380.14367
Overall Steps per Second: 10,704.42367

Timestep Collection Time: 2.23484
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.67246

Cumulative Model Updates: 171,476
Cumulative Timesteps: 1,430,017,350

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.68302
Value Function Loss: 0.02232

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.26933
Value Function Update Magnitude: 0.29109

Collected Steps per Second: 22,877.00991
Overall Steps per Second: 10,813.58547

Timestep Collection Time: 2.18665
Timestep Consumption Time: 2.43938
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.62603

Cumulative Model Updates: 171,482
Cumulative Timesteps: 1,430,067,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1430067374...
Checkpoint 1430067374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.68156
Value Function Loss: 0.02171

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12397
Policy Update Magnitude: 0.25078
Value Function Update Magnitude: 0.25945

Collected Steps per Second: 22,000.36378
Overall Steps per Second: 10,622.38911

Timestep Collection Time: 2.27278
Timestep Consumption Time: 2.43445
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.70723

Cumulative Model Updates: 171,488
Cumulative Timesteps: 1,430,117,376

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.65682
Value Function Loss: 0.02668

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.25859
Value Function Update Magnitude: 0.30448

Collected Steps per Second: 22,567.74927
Overall Steps per Second: 10,408.15704

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.58920
PPO Batch Consumption Time: 0.30416
Total Iteration Time: 4.80546

Cumulative Model Updates: 171,494
Cumulative Timesteps: 1,430,167,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1430167392...
Checkpoint 1430167392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.66720
Value Function Loss: 0.02645

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.28998
Value Function Update Magnitude: 0.35715

Collected Steps per Second: 22,588.79598
Overall Steps per Second: 10,598.27062

Timestep Collection Time: 2.21411
Timestep Consumption Time: 2.50497
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.71907

Cumulative Model Updates: 171,500
Cumulative Timesteps: 1,430,217,406

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.65287
Value Function Loss: 0.02884

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.29596
Value Function Update Magnitude: 0.36681

Collected Steps per Second: 22,568.20569
Overall Steps per Second: 10,610.24654

Timestep Collection Time: 2.21675
Timestep Consumption Time: 2.49832
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.71506

Cumulative Model Updates: 171,506
Cumulative Timesteps: 1,430,267,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1430267434...
Checkpoint 1430267434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.67615
Value Function Loss: 0.02598

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.30076
Value Function Update Magnitude: 0.31563

Collected Steps per Second: 22,070.23383
Overall Steps per Second: 10,665.79196

Timestep Collection Time: 2.26595
Timestep Consumption Time: 2.42287
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.68882

Cumulative Model Updates: 171,512
Cumulative Timesteps: 1,430,317,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,093.19452
Policy Entropy: 3.65940
Value Function Loss: 0.03033

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.33394
Value Function Update Magnitude: 0.36660

Collected Steps per Second: 22,761.91462
Overall Steps per Second: 10,789.86429

Timestep Collection Time: 2.19683
Timestep Consumption Time: 2.43752
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.63435

Cumulative Model Updates: 171,518
Cumulative Timesteps: 1,430,367,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1430367448...
Checkpoint 1430367448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237,535.75136
Policy Entropy: 3.66598
Value Function Loss: 0.03258

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.12050
Policy Update Magnitude: 0.39085
Value Function Update Magnitude: 0.52271

Collected Steps per Second: 21,990.90694
Overall Steps per Second: 10,625.12490

Timestep Collection Time: 2.27439
Timestep Consumption Time: 2.43294
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.70733

Cumulative Model Updates: 171,524
Cumulative Timesteps: 1,430,417,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,831.08506
Policy Entropy: 3.66002
Value Function Loss: 0.03572

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.44512
Value Function Update Magnitude: 0.52358

Collected Steps per Second: 21,909.40221
Overall Steps per Second: 10,599.83922

Timestep Collection Time: 2.28304
Timestep Consumption Time: 2.43590
PPO Batch Consumption Time: 0.29320
Total Iteration Time: 4.71894

Cumulative Model Updates: 171,530
Cumulative Timesteps: 1,430,467,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1430467484...
Checkpoint 1430467484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,353.26309
Policy Entropy: 3.68121
Value Function Loss: 0.03247

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.43539
Value Function Update Magnitude: 0.53571

Collected Steps per Second: 21,531.08050
Overall Steps per Second: 10,606.01633

Timestep Collection Time: 2.32287
Timestep Consumption Time: 2.39275
PPO Batch Consumption Time: 0.28399
Total Iteration Time: 4.71563

Cumulative Model Updates: 171,536
Cumulative Timesteps: 1,430,517,498

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,353.26309
Policy Entropy: 3.67931
Value Function Loss: 0.02712

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.40430
Value Function Update Magnitude: 0.53077

Collected Steps per Second: 21,810.84989
Overall Steps per Second: 10,633.32858

Timestep Collection Time: 2.29363
Timestep Consumption Time: 2.41101
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.70464

Cumulative Model Updates: 171,542
Cumulative Timesteps: 1,430,567,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1430567524...
Checkpoint 1430567524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,353.26309
Policy Entropy: 3.67021
Value Function Loss: 0.02211

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.35078
Value Function Update Magnitude: 0.42608

Collected Steps per Second: 22,189.56859
Overall Steps per Second: 10,547.28826

Timestep Collection Time: 2.25457
Timestep Consumption Time: 2.48864
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.74321

Cumulative Model Updates: 171,548
Cumulative Timesteps: 1,430,617,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,880.05232
Policy Entropy: 3.67112
Value Function Loss: 0.02420

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.31595
Value Function Update Magnitude: 0.36361

Collected Steps per Second: 22,794.07666
Overall Steps per Second: 10,869.51631

Timestep Collection Time: 2.19390
Timestep Consumption Time: 2.40685
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.60076

Cumulative Model Updates: 171,554
Cumulative Timesteps: 1,430,667,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1430667560...
Checkpoint 1430667560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.66553
Value Function Loss: 0.02621

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.31982
Value Function Update Magnitude: 0.39476

Collected Steps per Second: 22,326.46436
Overall Steps per Second: 10,654.54804

Timestep Collection Time: 2.24066
Timestep Consumption Time: 2.45461
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.69527

Cumulative Model Updates: 171,560
Cumulative Timesteps: 1,430,717,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.67092
Value Function Loss: 0.02820

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.33587
Value Function Update Magnitude: 0.42294

Collected Steps per Second: 22,882.44844
Overall Steps per Second: 10,791.06035

Timestep Collection Time: 2.18630
Timestep Consumption Time: 2.44976
PPO Batch Consumption Time: 0.27937
Total Iteration Time: 4.63606

Cumulative Model Updates: 171,566
Cumulative Timesteps: 1,430,767,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1430767614...
Checkpoint 1430767614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.68366
Value Function Loss: 0.02384

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12808
Policy Update Magnitude: 0.32282
Value Function Update Magnitude: 0.44598

Collected Steps per Second: 21,777.79261
Overall Steps per Second: 10,372.27358

Timestep Collection Time: 2.29766
Timestep Consumption Time: 2.52655
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.82421

Cumulative Model Updates: 171,572
Cumulative Timesteps: 1,430,817,652

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.67985
Value Function Loss: 0.02248

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.34486
Value Function Update Magnitude: 0.37716

Collected Steps per Second: 22,640.76292
Overall Steps per Second: 10,633.80239

Timestep Collection Time: 2.20902
Timestep Consumption Time: 2.49428
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.70330

Cumulative Model Updates: 171,578
Cumulative Timesteps: 1,430,867,666

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1430867666...
Checkpoint 1430867666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.67270
Value Function Loss: 0.02224

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12854
Policy Update Magnitude: 0.37084
Value Function Update Magnitude: 0.34950

Collected Steps per Second: 22,349.57955
Overall Steps per Second: 10,586.06064

Timestep Collection Time: 2.23754
Timestep Consumption Time: 2.48641
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.72395

Cumulative Model Updates: 171,584
Cumulative Timesteps: 1,430,917,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.67545
Value Function Loss: 0.02162

Mean KL Divergence: 0.00540
SB3 Clip Fraction: 0.06394
Policy Update Magnitude: 0.41691
Value Function Update Magnitude: 0.41670

Collected Steps per Second: 22,876.37374
Overall Steps per Second: 10,815.28598

Timestep Collection Time: 2.18767
Timestep Consumption Time: 2.43967
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.62734

Cumulative Model Updates: 171,590
Cumulative Timesteps: 1,430,967,720

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1430967720...
Checkpoint 1430967720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.69345
Value Function Loss: 0.01963

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06504
Policy Update Magnitude: 0.41606
Value Function Update Magnitude: 0.36070

Collected Steps per Second: 21,876.84394
Overall Steps per Second: 10,607.89903

Timestep Collection Time: 2.28671
Timestep Consumption Time: 2.42921
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.71592

Cumulative Model Updates: 171,596
Cumulative Timesteps: 1,431,017,746

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.70137
Value Function Loss: 0.01913

Mean KL Divergence: 0.00492
SB3 Clip Fraction: 0.05513
Policy Update Magnitude: 0.41528
Value Function Update Magnitude: 0.32270

Collected Steps per Second: 22,289.42180
Overall Steps per Second: 10,858.14910

Timestep Collection Time: 2.24429
Timestep Consumption Time: 2.36275
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.60705

Cumulative Model Updates: 171,602
Cumulative Timesteps: 1,431,067,770

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1431067770...
Checkpoint 1431067770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.68498
Value Function Loss: 0.02042

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06248
Policy Update Magnitude: 0.45347
Value Function Update Magnitude: 0.35047

Collected Steps per Second: 21,265.78069
Overall Steps per Second: 10,334.22975

Timestep Collection Time: 2.35251
Timestep Consumption Time: 2.48849
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.84100

Cumulative Model Updates: 171,608
Cumulative Timesteps: 1,431,117,798

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.66655
Value Function Loss: 0.02634

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.47094
Value Function Update Magnitude: 0.31998

Collected Steps per Second: 22,751.41887
Overall Steps per Second: 10,812.30383

Timestep Collection Time: 2.19854
Timestep Consumption Time: 2.42767
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.62621

Cumulative Model Updates: 171,614
Cumulative Timesteps: 1,431,167,818

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1431167818...
Checkpoint 1431167818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.67024
Value Function Loss: 0.02523

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12091
Policy Update Magnitude: 0.43047
Value Function Update Magnitude: 0.41986

Collected Steps per Second: 21,673.86154
Overall Steps per Second: 10,622.07933

Timestep Collection Time: 2.30831
Timestep Consumption Time: 2.40169
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.71000

Cumulative Model Updates: 171,620
Cumulative Timesteps: 1,431,217,848

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,676.36379
Policy Entropy: 3.68121
Value Function Loss: 0.02486

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.43407
Value Function Update Magnitude: 0.38553

Collected Steps per Second: 22,618.41790
Overall Steps per Second: 10,625.06380

Timestep Collection Time: 2.21112
Timestep Consumption Time: 2.49587
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.70698

Cumulative Model Updates: 171,626
Cumulative Timesteps: 1,431,267,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1431267860...
Checkpoint 1431267860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 459,880.76817
Policy Entropy: 3.69946
Value Function Loss: 0.02690

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.17721
Policy Update Magnitude: 0.38090
Value Function Update Magnitude: 0.56578

Collected Steps per Second: 21,871.02168
Overall Steps per Second: 10,526.49019

Timestep Collection Time: 2.28622
Timestep Consumption Time: 2.46389
PPO Batch Consumption Time: 0.28309
Total Iteration Time: 4.75011

Cumulative Model Updates: 171,632
Cumulative Timesteps: 1,431,317,862

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372,504.87486
Policy Entropy: 3.69197
Value Function Loss: 0.03046

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10367
Policy Update Magnitude: 0.52342
Value Function Update Magnitude: 0.70491

Collected Steps per Second: 22,888.89232
Overall Steps per Second: 10,816.20411

Timestep Collection Time: 2.18525
Timestep Consumption Time: 2.43911
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.62436

Cumulative Model Updates: 171,638
Cumulative Timesteps: 1,431,367,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1431367880...
Checkpoint 1431367880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372,504.87486
Policy Entropy: 3.69988
Value Function Loss: 0.02911

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.57967
Value Function Update Magnitude: 0.72707

Collected Steps per Second: 22,371.06638
Overall Steps per Second: 10,691.67723

Timestep Collection Time: 2.23512
Timestep Consumption Time: 2.44160
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.67672

Cumulative Model Updates: 171,644
Cumulative Timesteps: 1,431,417,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372,504.87486
Policy Entropy: 3.68827
Value Function Loss: 0.02359

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10053
Policy Update Magnitude: 0.51448
Value Function Update Magnitude: 0.66193

Collected Steps per Second: 22,530.41338
Overall Steps per Second: 10,570.26821

Timestep Collection Time: 2.21976
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.73138

Cumulative Model Updates: 171,650
Cumulative Timesteps: 1,431,467,894

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1431467894...
Checkpoint 1431467894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 372,504.87486
Policy Entropy: 3.69292
Value Function Loss: 0.02224

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.16147
Policy Update Magnitude: 0.40266
Value Function Update Magnitude: 0.45749

Collected Steps per Second: 22,370.85920
Overall Steps per Second: 10,534.05812

Timestep Collection Time: 2.23514
Timestep Consumption Time: 2.51156
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.74670

Cumulative Model Updates: 171,656
Cumulative Timesteps: 1,431,517,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 372,504.87486
Policy Entropy: 3.65947
Value Function Loss: 0.03013

Mean KL Divergence: 0.01269
SB3 Clip Fraction: 0.16560
Policy Update Magnitude: 0.35118
Value Function Update Magnitude: 0.39328

Collected Steps per Second: 22,761.57829
Overall Steps per Second: 10,659.91025

Timestep Collection Time: 2.19756
Timestep Consumption Time: 2.49478
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.69235

Cumulative Model Updates: 171,662
Cumulative Timesteps: 1,431,567,916

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1431567916...
Checkpoint 1431567916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319,834.57758
Policy Entropy: 3.67371
Value Function Loss: 0.03376

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.42321
Value Function Update Magnitude: 0.55485

Collected Steps per Second: 22,381.96152
Overall Steps per Second: 10,529.91437

Timestep Collection Time: 2.23421
Timestep Consumption Time: 2.51474
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.74895

Cumulative Model Updates: 171,668
Cumulative Timesteps: 1,431,617,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319,834.57758
Policy Entropy: 3.66465
Value Function Loss: 0.03853

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14730
Policy Update Magnitude: 0.44022
Value Function Update Magnitude: 0.51794

Collected Steps per Second: 22,499.01531
Overall Steps per Second: 10,754.35864

Timestep Collection Time: 2.22330
Timestep Consumption Time: 2.42803
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.65132

Cumulative Model Updates: 171,674
Cumulative Timesteps: 1,431,667,944

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1431667944...
Checkpoint 1431667944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319,834.57758
Policy Entropy: 3.68963
Value Function Loss: 0.03300

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.40587
Value Function Update Magnitude: 0.46145

Collected Steps per Second: 21,714.76300
Overall Steps per Second: 10,434.43875

Timestep Collection Time: 2.30350
Timestep Consumption Time: 2.49024
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.79374

Cumulative Model Updates: 171,680
Cumulative Timesteps: 1,431,717,964

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319,834.57758
Policy Entropy: 3.66701
Value Function Loss: 0.03333

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.38748
Value Function Update Magnitude: 0.45303

Collected Steps per Second: 22,976.44345
Overall Steps per Second: 10,738.63035

Timestep Collection Time: 2.17701
Timestep Consumption Time: 2.48094
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.65795

Cumulative Model Updates: 171,686
Cumulative Timesteps: 1,431,767,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1431767984...
Checkpoint 1431767984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 319,834.57758
Policy Entropy: 3.67260
Value Function Loss: 0.03346

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.43921
Value Function Update Magnitude: 0.54804

Collected Steps per Second: 21,001.73983
Overall Steps per Second: 10,385.02764

Timestep Collection Time: 2.38190
Timestep Consumption Time: 2.43504
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.81693

Cumulative Model Updates: 171,692
Cumulative Timesteps: 1,431,818,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319,834.57758
Policy Entropy: 3.66301
Value Function Loss: 0.04013

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.51105
Value Function Update Magnitude: 0.59390

Collected Steps per Second: 21,891.54845
Overall Steps per Second: 10,750.75219

Timestep Collection Time: 2.28545
Timestep Consumption Time: 2.36837
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.65381

Cumulative Model Updates: 171,698
Cumulative Timesteps: 1,431,868,040

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1431868040...
Checkpoint 1431868040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410,942.56241
Policy Entropy: 3.67573
Value Function Loss: 0.04028

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.49757
Value Function Update Magnitude: 0.56681

Collected Steps per Second: 21,749.05990
Overall Steps per Second: 10,648.00371

Timestep Collection Time: 2.29904
Timestep Consumption Time: 2.39686
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.69590

Cumulative Model Updates: 171,704
Cumulative Timesteps: 1,431,918,042

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 410,942.56241
Policy Entropy: 3.67533
Value Function Loss: 0.03750

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13798
Policy Update Magnitude: 0.47027
Value Function Update Magnitude: 0.58398

Collected Steps per Second: 22,736.99315
Overall Steps per Second: 10,819.00139

Timestep Collection Time: 2.20108
Timestep Consumption Time: 2.42467
PPO Batch Consumption Time: 0.27946
Total Iteration Time: 4.62575

Cumulative Model Updates: 171,710
Cumulative Timesteps: 1,431,968,088

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1431968088...
Checkpoint 1431968088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 502,058.75977
Policy Entropy: 3.68144
Value Function Loss: 0.03120

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13464
Policy Update Magnitude: 0.43194
Value Function Update Magnitude: 0.56119

Collected Steps per Second: 22,349.69562
Overall Steps per Second: 10,685.29186

Timestep Collection Time: 2.23806
Timestep Consumption Time: 2.44314
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.68120

Cumulative Model Updates: 171,716
Cumulative Timesteps: 1,432,018,108

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 502,058.75977
Policy Entropy: 3.67571
Value Function Loss: 0.02961

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.42137
Value Function Update Magnitude: 0.65711

Collected Steps per Second: 22,966.57097
Overall Steps per Second: 10,853.41371

Timestep Collection Time: 2.17804
Timestep Consumption Time: 2.43084
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.60887

Cumulative Model Updates: 171,722
Cumulative Timesteps: 1,432,068,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1432068130...
Checkpoint 1432068130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 881,868.01454
Policy Entropy: 3.67341
Value Function Loss: 0.03364

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.44802
Value Function Update Magnitude: 0.76735

Collected Steps per Second: 22,192.23996
Overall Steps per Second: 10,657.34226

Timestep Collection Time: 2.25385
Timestep Consumption Time: 2.43944
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.69329

Cumulative Model Updates: 171,728
Cumulative Timesteps: 1,432,118,148

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,066.46076
Policy Entropy: 3.67307
Value Function Loss: 0.03102

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13747
Policy Update Magnitude: 0.47048
Value Function Update Magnitude: 0.89162

Collected Steps per Second: 22,809.68772
Overall Steps per Second: 10,689.58192

Timestep Collection Time: 2.19231
Timestep Consumption Time: 2.48570
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.67801

Cumulative Model Updates: 171,734
Cumulative Timesteps: 1,432,168,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1432168154...
Checkpoint 1432168154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,066.46076
Policy Entropy: 3.67558
Value Function Loss: 0.03081

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.42355
Value Function Update Magnitude: 0.77202

Collected Steps per Second: 22,671.66657
Overall Steps per Second: 10,792.45595

Timestep Collection Time: 2.20663
Timestep Consumption Time: 2.42883
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.63546

Cumulative Model Updates: 171,740
Cumulative Timesteps: 1,432,218,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,066.46076
Policy Entropy: 3.69180
Value Function Loss: 0.02935

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.42141
Value Function Update Magnitude: 0.65033

Collected Steps per Second: 22,739.23889
Overall Steps per Second: 10,596.17737

Timestep Collection Time: 2.19919
Timestep Consumption Time: 2.52024
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.71944

Cumulative Model Updates: 171,746
Cumulative Timesteps: 1,432,268,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1432268190...
Checkpoint 1432268190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 476,193.45908
Policy Entropy: 3.69495
Value Function Loss: 0.02772

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12996
Policy Update Magnitude: 0.42929
Value Function Update Magnitude: 0.62218

Collected Steps per Second: 22,407.05043
Overall Steps per Second: 10,635.80260

Timestep Collection Time: 2.23251
Timestep Consumption Time: 2.47085
PPO Batch Consumption Time: 0.28525
Total Iteration Time: 4.70336

Cumulative Model Updates: 171,752
Cumulative Timesteps: 1,432,318,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782,853.05677
Policy Entropy: 3.69738
Value Function Loss: 0.02944

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.44430
Value Function Update Magnitude: 0.70913

Collected Steps per Second: 22,197.56221
Overall Steps per Second: 10,823.47361

Timestep Collection Time: 2.25268
Timestep Consumption Time: 2.36728
PPO Batch Consumption Time: 0.27994
Total Iteration Time: 4.61996

Cumulative Model Updates: 171,758
Cumulative Timesteps: 1,432,368,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1432368218...
Checkpoint 1432368218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782,853.05677
Policy Entropy: 3.68524
Value Function Loss: 0.03057

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.45473
Value Function Update Magnitude: 0.66469

Collected Steps per Second: 21,735.82105
Overall Steps per Second: 10,675.37948

Timestep Collection Time: 2.30044
Timestep Consumption Time: 2.38342
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.68386

Cumulative Model Updates: 171,764
Cumulative Timesteps: 1,432,418,220

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782,853.05677
Policy Entropy: 3.66727
Value Function Loss: 0.03045

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.43253
Value Function Update Magnitude: 0.53055

Collected Steps per Second: 22,089.25506
Overall Steps per Second: 10,526.50233

Timestep Collection Time: 2.26427
Timestep Consumption Time: 2.48717
PPO Batch Consumption Time: 0.29379
Total Iteration Time: 4.75144

Cumulative Model Updates: 171,770
Cumulative Timesteps: 1,432,468,236

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1432468236...
Checkpoint 1432468236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782,853.05677
Policy Entropy: 3.66250
Value Function Loss: 0.02667

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13171
Policy Update Magnitude: 0.37458
Value Function Update Magnitude: 0.42908

Collected Steps per Second: 20,944.29168
Overall Steps per Second: 10,183.56422

Timestep Collection Time: 2.38748
Timestep Consumption Time: 2.52279
PPO Batch Consumption Time: 0.29968
Total Iteration Time: 4.91027

Cumulative Model Updates: 171,776
Cumulative Timesteps: 1,432,518,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782,853.05677
Policy Entropy: 3.66691
Value Function Loss: 0.02469

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.32387
Value Function Update Magnitude: 0.33018

Collected Steps per Second: 21,542.57367
Overall Steps per Second: 10,547.97675

Timestep Collection Time: 2.32229
Timestep Consumption Time: 2.42061
PPO Batch Consumption Time: 0.29444
Total Iteration Time: 4.74290

Cumulative Model Updates: 171,782
Cumulative Timesteps: 1,432,568,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1432568268...
Checkpoint 1432568268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061,373.47112
Policy Entropy: 3.67394
Value Function Loss: 0.02462

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13348
Policy Update Magnitude: 0.29512
Value Function Update Magnitude: 0.32628

Collected Steps per Second: 21,305.82194
Overall Steps per Second: 10,316.03302

Timestep Collection Time: 2.34903
Timestep Consumption Time: 2.50245
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.85148

Cumulative Model Updates: 171,788
Cumulative Timesteps: 1,432,618,316

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061,373.47112
Policy Entropy: 3.68301
Value Function Loss: 0.02510

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.29901
Value Function Update Magnitude: 0.40313

Collected Steps per Second: 21,101.39887
Overall Steps per Second: 10,208.84794

Timestep Collection Time: 2.37074
Timestep Consumption Time: 2.52952
PPO Batch Consumption Time: 0.28113
Total Iteration Time: 4.90026

Cumulative Model Updates: 171,794
Cumulative Timesteps: 1,432,668,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1432668342...
Checkpoint 1432668342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061,373.47112
Policy Entropy: 3.68063
Value Function Loss: 0.02414

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.13094
Policy Update Magnitude: 0.30288
Value Function Update Magnitude: 0.49357

Collected Steps per Second: 20,779.77379
Overall Steps per Second: 9,978.00967

Timestep Collection Time: 2.40667
Timestep Consumption Time: 2.60535
PPO Batch Consumption Time: 0.30291
Total Iteration Time: 5.01202

Cumulative Model Updates: 171,800
Cumulative Timesteps: 1,432,718,352

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070,444.80154
Policy Entropy: 3.67452
Value Function Loss: 0.02878

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12416
Policy Update Magnitude: 0.33671
Value Function Update Magnitude: 0.52034

Collected Steps per Second: 22,615.60901
Overall Steps per Second: 10,727.95045

Timestep Collection Time: 2.21210
Timestep Consumption Time: 2.45123
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.66333

Cumulative Model Updates: 171,806
Cumulative Timesteps: 1,432,768,380

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1432768380...
Checkpoint 1432768380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.25910
Policy Entropy: 3.68239
Value Function Loss: 0.03126

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.38310
Value Function Update Magnitude: 0.56984

Collected Steps per Second: 21,810.75690
Overall Steps per Second: 10,189.89962

Timestep Collection Time: 2.29272
Timestep Consumption Time: 2.61469
PPO Batch Consumption Time: 0.31081
Total Iteration Time: 4.90741

Cumulative Model Updates: 171,812
Cumulative Timesteps: 1,432,818,386

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.25910
Policy Entropy: 3.68611
Value Function Loss: 0.03227

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13033
Policy Update Magnitude: 0.47991
Value Function Update Magnitude: 0.49342

Collected Steps per Second: 19,364.78743
Overall Steps per Second: 9,792.73909

Timestep Collection Time: 2.58273
Timestep Consumption Time: 2.52452
PPO Batch Consumption Time: 0.29404
Total Iteration Time: 5.10725

Cumulative Model Updates: 171,818
Cumulative Timesteps: 1,432,868,400

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1432868400...
Checkpoint 1432868400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.25910
Policy Entropy: 3.68573
Value Function Loss: 0.03082

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12957
Policy Update Magnitude: 0.44681
Value Function Update Magnitude: 0.50674

Collected Steps per Second: 21,839.28212
Overall Steps per Second: 10,466.02179

Timestep Collection Time: 2.28964
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.77775

Cumulative Model Updates: 171,824
Cumulative Timesteps: 1,432,918,404

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.25910
Policy Entropy: 3.68060
Value Function Loss: 0.02884

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.38834
Value Function Update Magnitude: 0.55257

Collected Steps per Second: 20,880.93823
Overall Steps per Second: 10,325.01347

Timestep Collection Time: 2.39462
Timestep Consumption Time: 2.44818
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.84280

Cumulative Model Updates: 171,830
Cumulative Timesteps: 1,432,968,406

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1432968406...
Checkpoint 1432968406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.25910
Policy Entropy: 3.66180
Value Function Loss: 0.02868

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.37869
Value Function Update Magnitude: 0.56355

Collected Steps per Second: 17,583.53675
Overall Steps per Second: 9,324.16703

Timestep Collection Time: 2.84357
Timestep Consumption Time: 2.51884
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 5.36241

Cumulative Model Updates: 171,836
Cumulative Timesteps: 1,433,018,406

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.25910
Policy Entropy: 3.66928
Value Function Loss: 0.02490

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.34317
Value Function Update Magnitude: 0.43623

Collected Steps per Second: 22,737.06977
Overall Steps per Second: 10,807.92782

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.42835
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.62845

Cumulative Model Updates: 171,842
Cumulative Timesteps: 1,433,068,430

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1433068430...
Checkpoint 1433068430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.25910
Policy Entropy: 3.67620
Value Function Loss: 0.02308

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.30490
Value Function Update Magnitude: 0.31718

Collected Steps per Second: 21,183.87112
Overall Steps per Second: 10,333.21200

Timestep Collection Time: 2.36142
Timestep Consumption Time: 2.47967
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.84109

Cumulative Model Updates: 171,848
Cumulative Timesteps: 1,433,118,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.25910
Policy Entropy: 3.68359
Value Function Loss: 0.02179

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12790
Policy Update Magnitude: 0.27270
Value Function Update Magnitude: 0.26994

Collected Steps per Second: 21,559.21519
Overall Steps per Second: 10,359.28991

Timestep Collection Time: 2.32059
Timestep Consumption Time: 2.50890
PPO Batch Consumption Time: 0.30028
Total Iteration Time: 4.82948

Cumulative Model Updates: 171,854
Cumulative Timesteps: 1,433,168,484

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1433168484...
Checkpoint 1433168484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.25910
Policy Entropy: 3.67253
Value Function Loss: 0.02228

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13102
Policy Update Magnitude: 0.27292
Value Function Update Magnitude: 0.27849

Collected Steps per Second: 20,801.89808
Overall Steps per Second: 10,225.68395

Timestep Collection Time: 2.40488
Timestep Consumption Time: 2.48731
PPO Batch Consumption Time: 0.30196
Total Iteration Time: 4.89219

Cumulative Model Updates: 171,860
Cumulative Timesteps: 1,433,218,510

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,327.25910
Policy Entropy: 3.65546
Value Function Loss: 0.02571

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.28044
Value Function Update Magnitude: 0.33819

Collected Steps per Second: 21,409.53464
Overall Steps per Second: 10,317.80459

Timestep Collection Time: 2.33672
Timestep Consumption Time: 2.51199
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.84871

Cumulative Model Updates: 171,866
Cumulative Timesteps: 1,433,268,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1433268538...
Checkpoint 1433268538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924,641.97893
Policy Entropy: 3.67221
Value Function Loss: 0.02638

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.31628
Value Function Update Magnitude: 0.39291

Collected Steps per Second: 21,714.81685
Overall Steps per Second: 10,322.80621

Timestep Collection Time: 2.30386
Timestep Consumption Time: 2.54249
PPO Batch Consumption Time: 0.29900
Total Iteration Time: 4.84636

Cumulative Model Updates: 171,872
Cumulative Timesteps: 1,433,318,566

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 924,641.97893
Policy Entropy: 3.65654
Value Function Loss: 0.02814

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.34211
Value Function Update Magnitude: 0.47257

Collected Steps per Second: 21,536.17574
Overall Steps per Second: 10,511.55919

Timestep Collection Time: 2.32298
Timestep Consumption Time: 2.43636
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.75933

Cumulative Model Updates: 171,878
Cumulative Timesteps: 1,433,368,594

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1433368594...
Checkpoint 1433368594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 924,641.97893
Policy Entropy: 3.66649
Value Function Loss: 0.02606

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.36142
Value Function Update Magnitude: 0.47337

Collected Steps per Second: 19,826.67257
Overall Steps per Second: 9,644.95793

Timestep Collection Time: 2.52317
Timestep Consumption Time: 2.66358
PPO Batch Consumption Time: 0.29513
Total Iteration Time: 5.18675

Cumulative Model Updates: 171,884
Cumulative Timesteps: 1,433,418,620

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228,121.72413
Policy Entropy: 3.65081
Value Function Loss: 0.03496

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.40655
Value Function Update Magnitude: 0.46543

Collected Steps per Second: 21,487.54827
Overall Steps per Second: 10,108.28244

Timestep Collection Time: 2.32749
Timestep Consumption Time: 2.62014
PPO Batch Consumption Time: 0.29560
Total Iteration Time: 4.94763

Cumulative Model Updates: 171,890
Cumulative Timesteps: 1,433,468,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1433468632...
Checkpoint 1433468632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228,121.72413
Policy Entropy: 3.66258
Value Function Loss: 0.03206

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13022
Policy Update Magnitude: 0.46042
Value Function Update Magnitude: 0.54882

Collected Steps per Second: 20,168.56000
Overall Steps per Second: 10,273.18199

Timestep Collection Time: 2.48020
Timestep Consumption Time: 2.38899
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.86918

Cumulative Model Updates: 171,896
Cumulative Timesteps: 1,433,518,654

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228,121.72413
Policy Entropy: 3.66023
Value Function Loss: 0.03253

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.45766
Value Function Update Magnitude: 0.66643

Collected Steps per Second: 20,280.28586
Overall Steps per Second: 9,784.83576

Timestep Collection Time: 2.46555
Timestep Consumption Time: 2.64461
PPO Batch Consumption Time: 0.29288
Total Iteration Time: 5.11015

Cumulative Model Updates: 171,902
Cumulative Timesteps: 1,433,568,656

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1433568656...
Checkpoint 1433568656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228,121.72413
Policy Entropy: 3.66740
Value Function Loss: 0.02648

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.43442
Value Function Update Magnitude: 0.63567

Collected Steps per Second: 21,980.12342
Overall Steps per Second: 10,176.06306

Timestep Collection Time: 2.27578
Timestep Consumption Time: 2.63987
PPO Batch Consumption Time: 0.31304
Total Iteration Time: 4.91565

Cumulative Model Updates: 171,908
Cumulative Timesteps: 1,433,618,678

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228,121.72413
Policy Entropy: 3.66133
Value Function Loss: 0.02468

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.39481
Value Function Update Magnitude: 0.58952

Collected Steps per Second: 21,214.14981
Overall Steps per Second: 10,498.90119

Timestep Collection Time: 2.35795
Timestep Consumption Time: 2.40654
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.76450

Cumulative Model Updates: 171,914
Cumulative Timesteps: 1,433,668,700

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1433668700...
Checkpoint 1433668700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,228,121.72413
Policy Entropy: 3.67242
Value Function Loss: 0.02392

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.40681
Value Function Update Magnitude: 0.51930

Collected Steps per Second: 22,051.83835
Overall Steps per Second: 10,489.11732

Timestep Collection Time: 2.26856
Timestep Consumption Time: 2.50076
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.76932

Cumulative Model Updates: 171,920
Cumulative Timesteps: 1,433,718,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551,741.30491
Policy Entropy: 3.66847
Value Function Loss: 0.03080

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.12291
Policy Update Magnitude: 0.42820
Value Function Update Magnitude: 0.51016

Collected Steps per Second: 18,679.07127
Overall Steps per Second: 9,642.48735

Timestep Collection Time: 2.67722
Timestep Consumption Time: 2.50899
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 5.18621

Cumulative Model Updates: 171,926
Cumulative Timesteps: 1,433,768,734

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1433768734...
Checkpoint 1433768734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551,741.30491
Policy Entropy: 3.68937
Value Function Loss: 0.02926

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12238
Policy Update Magnitude: 0.46142
Value Function Update Magnitude: 0.55692

Collected Steps per Second: 18,872.86206
Overall Steps per Second: 9,672.73881

Timestep Collection Time: 2.65047
Timestep Consumption Time: 2.52097
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 5.17144

Cumulative Model Updates: 171,932
Cumulative Timesteps: 1,433,818,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551,741.30491
Policy Entropy: 3.68850
Value Function Loss: 0.03180

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.45967
Value Function Update Magnitude: 0.54823

Collected Steps per Second: 20,893.73512
Overall Steps per Second: 10,184.91285

Timestep Collection Time: 2.39421
Timestep Consumption Time: 2.51737
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.91158

Cumulative Model Updates: 171,938
Cumulative Timesteps: 1,433,868,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1433868780...
Checkpoint 1433868780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551,741.30491
Policy Entropy: 3.69329
Value Function Loss: 0.02571

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.45154
Value Function Update Magnitude: 0.44969

Collected Steps per Second: 20,505.54238
Overall Steps per Second: 9,746.27610

Timestep Collection Time: 2.43934
Timestep Consumption Time: 2.69288
PPO Batch Consumption Time: 0.30795
Total Iteration Time: 5.13222

Cumulative Model Updates: 171,944
Cumulative Timesteps: 1,433,918,800

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,551,741.30491
Policy Entropy: 3.67232
Value Function Loss: 0.03547

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12269
Policy Update Magnitude: 0.45811
Value Function Update Magnitude: 0.41479

Collected Steps per Second: 19,289.26329
Overall Steps per Second: 9,787.52555

Timestep Collection Time: 2.59336
Timestep Consumption Time: 2.51764
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 5.11100

Cumulative Model Updates: 171,950
Cumulative Timesteps: 1,433,968,824

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1433968824...
Checkpoint 1433968824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,517,652.91022
Policy Entropy: 3.67990
Value Function Loss: 0.03864

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.54334
Value Function Update Magnitude: 0.51126

Collected Steps per Second: 20,868.99361
Overall Steps per Second: 10,597.20376

Timestep Collection Time: 2.39628
Timestep Consumption Time: 2.32270
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.71898

Cumulative Model Updates: 171,956
Cumulative Timesteps: 1,434,018,832

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.66425
Value Function Loss: 0.04469

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.51652
Value Function Update Magnitude: 0.57358

Collected Steps per Second: 20,131.29642
Overall Steps per Second: 10,125.98179

Timestep Collection Time: 2.48538
Timestep Consumption Time: 2.45577
PPO Batch Consumption Time: 0.29438
Total Iteration Time: 4.94115

Cumulative Model Updates: 171,962
Cumulative Timesteps: 1,434,068,866

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1434068866...
Checkpoint 1434068866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.68099
Value Function Loss: 0.03996

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.48115
Value Function Update Magnitude: 0.50543

Collected Steps per Second: 20,062.84754
Overall Steps per Second: 10,073.50009

Timestep Collection Time: 2.49267
Timestep Consumption Time: 2.47184
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.96451

Cumulative Model Updates: 171,968
Cumulative Timesteps: 1,434,118,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.67170
Value Function Loss: 0.03815

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.42429
Value Function Update Magnitude: 0.42303

Collected Steps per Second: 21,468.40453
Overall Steps per Second: 10,422.72593

Timestep Collection Time: 2.32994
Timestep Consumption Time: 2.46919
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.79913

Cumulative Model Updates: 171,974
Cumulative Timesteps: 1,434,168,896

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1434168896...
Checkpoint 1434168896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.69307
Value Function Loss: 0.03027

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.38602
Value Function Update Magnitude: 0.39511

Collected Steps per Second: 19,056.60364
Overall Steps per Second: 9,568.69359

Timestep Collection Time: 2.62502
Timestep Consumption Time: 2.60286
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 5.22788

Cumulative Model Updates: 171,980
Cumulative Timesteps: 1,434,218,920

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.69093
Value Function Loss: 0.03138

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.39621
Value Function Update Magnitude: 0.36066

Collected Steps per Second: 21,653.87486
Overall Steps per Second: 10,436.03622

Timestep Collection Time: 2.31016
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.79339

Cumulative Model Updates: 171,986
Cumulative Timesteps: 1,434,268,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1434268944...
Checkpoint 1434268944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.69241
Value Function Loss: 0.02689

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.41858
Value Function Update Magnitude: 0.40850

Collected Steps per Second: 21,789.26950
Overall Steps per Second: 10,166.72796

Timestep Collection Time: 2.29544
Timestep Consumption Time: 2.62414
PPO Batch Consumption Time: 0.30936
Total Iteration Time: 4.91958

Cumulative Model Updates: 171,992
Cumulative Timesteps: 1,434,318,960

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.68788
Value Function Loss: 0.02734

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.39273
Value Function Update Magnitude: 0.41876

Collected Steps per Second: 22,354.07418
Overall Steps per Second: 10,460.15503

Timestep Collection Time: 2.23798
Timestep Consumption Time: 2.54474
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 4.78272

Cumulative Model Updates: 171,998
Cumulative Timesteps: 1,434,368,988

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1434368988...
Checkpoint 1434368988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.68663
Value Function Loss: 0.02295

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.34576
Value Function Update Magnitude: 0.32461

Collected Steps per Second: 20,831.96645
Overall Steps per Second: 10,148.60498

Timestep Collection Time: 2.40054
Timestep Consumption Time: 2.52703
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.92757

Cumulative Model Updates: 172,004
Cumulative Timesteps: 1,434,418,996

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.66443
Value Function Loss: 0.02847

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.34426
Value Function Update Magnitude: 0.40358

Collected Steps per Second: 22,077.83011
Overall Steps per Second: 10,518.89951

Timestep Collection Time: 2.26644
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.75696

Cumulative Model Updates: 172,010
Cumulative Timesteps: 1,434,469,034

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1434469034...
Checkpoint 1434469034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.65885
Value Function Loss: 0.02982

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13634
Policy Update Magnitude: 0.40415
Value Function Update Magnitude: 0.42266

Collected Steps per Second: 20,320.96663
Overall Steps per Second: 10,132.41126

Timestep Collection Time: 2.46160
Timestep Consumption Time: 2.47524
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.93683

Cumulative Model Updates: 172,016
Cumulative Timesteps: 1,434,519,056

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.65502
Value Function Loss: 0.03480

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.41231
Value Function Update Magnitude: 0.43044

Collected Steps per Second: 21,422.65449
Overall Steps per Second: 10,253.80589

Timestep Collection Time: 2.33398
Timestep Consumption Time: 2.54226
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.87624

Cumulative Model Updates: 172,022
Cumulative Timesteps: 1,434,569,056

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1434569056...
Checkpoint 1434569056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.66673
Value Function Loss: 0.03258

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.39171
Value Function Update Magnitude: 0.35991

Collected Steps per Second: 20,994.12409
Overall Steps per Second: 10,128.69093

Timestep Collection Time: 2.38181
Timestep Consumption Time: 2.55506
PPO Batch Consumption Time: 0.29474
Total Iteration Time: 4.93687

Cumulative Model Updates: 172,028
Cumulative Timesteps: 1,434,619,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.67511
Value Function Loss: 0.02600

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13012
Policy Update Magnitude: 0.36501
Value Function Update Magnitude: 0.32545

Collected Steps per Second: 18,650.52417
Overall Steps per Second: 9,706.92936

Timestep Collection Time: 2.68089
Timestep Consumption Time: 2.47007
PPO Batch Consumption Time: 0.27625
Total Iteration Time: 5.15096

Cumulative Model Updates: 172,034
Cumulative Timesteps: 1,434,669,060

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1434669060...
Checkpoint 1434669060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.68648
Value Function Loss: 0.02542

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13100
Policy Update Magnitude: 0.32983
Value Function Update Magnitude: 0.25462

Collected Steps per Second: 21,908.73550
Overall Steps per Second: 10,538.68469

Timestep Collection Time: 2.28292
Timestep Consumption Time: 2.46302
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.74594

Cumulative Model Updates: 172,040
Cumulative Timesteps: 1,434,719,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.69322
Value Function Loss: 0.02141

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13050
Policy Update Magnitude: 0.30640
Value Function Update Magnitude: 0.19189

Collected Steps per Second: 21,216.54838
Overall Steps per Second: 10,286.21561

Timestep Collection Time: 2.35693
Timestep Consumption Time: 2.50452
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.86146

Cumulative Model Updates: 172,046
Cumulative Timesteps: 1,434,769,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1434769082...
Checkpoint 1434769082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.68585
Value Function Loss: 0.02247

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.30940
Value Function Update Magnitude: 0.20939

Collected Steps per Second: 20,972.69918
Overall Steps per Second: 10,360.72443

Timestep Collection Time: 2.38491
Timestep Consumption Time: 2.44274
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.82765

Cumulative Model Updates: 172,052
Cumulative Timesteps: 1,434,819,100

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.65620
Value Function Loss: 0.02648

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13405
Policy Update Magnitude: 0.34487
Value Function Update Magnitude: 0.29565

Collected Steps per Second: 21,253.26430
Overall Steps per Second: 10,222.90211

Timestep Collection Time: 2.35296
Timestep Consumption Time: 2.53881
PPO Batch Consumption Time: 0.30969
Total Iteration Time: 4.89176

Cumulative Model Updates: 172,058
Cumulative Timesteps: 1,434,869,108

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1434869108...
Checkpoint 1434869108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,229,306.75856
Policy Entropy: 3.65957
Value Function Loss: 0.02955

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.38604
Value Function Update Magnitude: 0.37397

Collected Steps per Second: 21,209.51319
Overall Steps per Second: 10,393.23800

Timestep Collection Time: 2.35753
Timestep Consumption Time: 2.45349
PPO Batch Consumption Time: 0.28485
Total Iteration Time: 4.81101

Cumulative Model Updates: 172,064
Cumulative Timesteps: 1,434,919,110

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782,782.94927
Policy Entropy: 3.66712
Value Function Loss: 0.03459

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13116
Policy Update Magnitude: 0.41838
Value Function Update Magnitude: 0.35797

Collected Steps per Second: 22,781.33768
Overall Steps per Second: 10,693.09395

Timestep Collection Time: 2.19610
Timestep Consumption Time: 2.48262
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.67872

Cumulative Model Updates: 172,070
Cumulative Timesteps: 1,434,969,140

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1434969140...
Checkpoint 1434969140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,951.72336
Policy Entropy: 3.66866
Value Function Loss: 0.03397

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.46785
Value Function Update Magnitude: 0.47589

Collected Steps per Second: 22,188.85546
Overall Steps per Second: 10,371.43562

Timestep Collection Time: 2.25347
Timestep Consumption Time: 2.56765
PPO Batch Consumption Time: 0.30623
Total Iteration Time: 4.82113

Cumulative Model Updates: 172,076
Cumulative Timesteps: 1,435,019,142

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,111.86819
Policy Entropy: 3.67322
Value Function Loss: 0.03630

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.50111
Value Function Update Magnitude: 0.54125

Collected Steps per Second: 22,449.14659
Overall Steps per Second: 10,335.44846

Timestep Collection Time: 2.22779
Timestep Consumption Time: 2.61109
PPO Batch Consumption Time: 0.30314
Total Iteration Time: 4.83888

Cumulative Model Updates: 172,082
Cumulative Timesteps: 1,435,069,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1435069154...
Checkpoint 1435069154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,209.23644
Policy Entropy: 3.68264
Value Function Loss: 0.03462

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.50727
Value Function Update Magnitude: 0.54574

Collected Steps per Second: 22,319.62649
Overall Steps per Second: 10,519.39790

Timestep Collection Time: 2.24072
Timestep Consumption Time: 2.51355
PPO Batch Consumption Time: 0.29347
Total Iteration Time: 4.75426

Cumulative Model Updates: 172,088
Cumulative Timesteps: 1,435,119,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224,184.35999
Policy Entropy: 3.68766
Value Function Loss: 0.03653

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.51981
Value Function Update Magnitude: 0.56573

Collected Steps per Second: 21,686.74709
Overall Steps per Second: 10,408.57778

Timestep Collection Time: 2.30620
Timestep Consumption Time: 2.49887
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.80508

Cumulative Model Updates: 172,094
Cumulative Timesteps: 1,435,169,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1435169180...
Checkpoint 1435169180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,595.16255
Policy Entropy: 3.68932
Value Function Loss: 0.03033

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.55128
Value Function Update Magnitude: 0.63029

Collected Steps per Second: 21,916.68610
Overall Steps per Second: 10,558.66598

Timestep Collection Time: 2.28237
Timestep Consumption Time: 2.45516
PPO Batch Consumption Time: 0.27908
Total Iteration Time: 4.73753

Cumulative Model Updates: 172,100
Cumulative Timesteps: 1,435,219,202

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,595.16255
Policy Entropy: 3.67193
Value Function Loss: 0.03104

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.51175
Value Function Update Magnitude: 0.60992

Collected Steps per Second: 22,740.45736
Overall Steps per Second: 10,665.62959

Timestep Collection Time: 2.20022
Timestep Consumption Time: 2.49092
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.69114

Cumulative Model Updates: 172,106
Cumulative Timesteps: 1,435,269,236

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1435269236...
Checkpoint 1435269236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,595.16255
Policy Entropy: 3.68501
Value Function Loss: 0.02706

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11482
Policy Update Magnitude: 0.46423
Value Function Update Magnitude: 0.51091

Collected Steps per Second: 22,343.74291
Overall Steps per Second: 10,565.15851

Timestep Collection Time: 2.23991
Timestep Consumption Time: 2.49717
PPO Batch Consumption Time: 0.29335
Total Iteration Time: 4.73708

Cumulative Model Updates: 172,112
Cumulative Timesteps: 1,435,319,284

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,595.16255
Policy Entropy: 3.67406
Value Function Loss: 0.02597

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12514
Policy Update Magnitude: 0.38475
Value Function Update Magnitude: 0.40128

Collected Steps per Second: 22,208.90235
Overall Steps per Second: 10,828.26199

Timestep Collection Time: 2.25144
Timestep Consumption Time: 2.36629
PPO Batch Consumption Time: 0.27968
Total Iteration Time: 4.61773

Cumulative Model Updates: 172,118
Cumulative Timesteps: 1,435,369,286

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1435369286...
Checkpoint 1435369286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,595.16255
Policy Entropy: 3.66597
Value Function Loss: 0.02742

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.37085
Value Function Update Magnitude: 0.34374

Collected Steps per Second: 21,691.36829
Overall Steps per Second: 10,616.73917

Timestep Collection Time: 2.30645
Timestep Consumption Time: 2.40592
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.71237

Cumulative Model Updates: 172,124
Cumulative Timesteps: 1,435,419,316

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,595.16255
Policy Entropy: 3.66788
Value Function Loss: 0.02802

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14192
Policy Update Magnitude: 0.39635
Value Function Update Magnitude: 0.46575

Collected Steps per Second: 22,006.61897
Overall Steps per Second: 10,502.75490

Timestep Collection Time: 2.27204
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.76066

Cumulative Model Updates: 172,130
Cumulative Timesteps: 1,435,469,316

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1435469316...
Checkpoint 1435469316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,595.16255
Policy Entropy: 3.66536
Value Function Loss: 0.03047

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14033
Policy Update Magnitude: 0.41970
Value Function Update Magnitude: 0.47145

Collected Steps per Second: 22,375.63437
Overall Steps per Second: 10,646.56018

Timestep Collection Time: 2.23466
Timestep Consumption Time: 2.46188
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.69654

Cumulative Model Updates: 172,136
Cumulative Timesteps: 1,435,519,318

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,504.54163
Policy Entropy: 3.67915
Value Function Loss: 0.03131

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14403
Policy Update Magnitude: 0.43174
Value Function Update Magnitude: 0.48139

Collected Steps per Second: 22,636.34049
Overall Steps per Second: 10,794.57437

Timestep Collection Time: 2.20884
Timestep Consumption Time: 2.42312
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.63196

Cumulative Model Updates: 172,142
Cumulative Timesteps: 1,435,569,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1435569318...
Checkpoint 1435569318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321,504.54163
Policy Entropy: 3.67168
Value Function Loss: 0.02869

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14990
Policy Update Magnitude: 0.40007
Value Function Update Magnitude: 0.56259

Collected Steps per Second: 22,192.92658
Overall Steps per Second: 10,655.37703

Timestep Collection Time: 2.25441
Timestep Consumption Time: 2.44106
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.69547

Cumulative Model Updates: 172,148
Cumulative Timesteps: 1,435,619,350

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,504.54163
Policy Entropy: 3.67920
Value Function Loss: 0.02466

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14081
Policy Update Magnitude: 0.37966
Value Function Update Magnitude: 0.52423

Collected Steps per Second: 22,642.07918
Overall Steps per Second: 10,461.77700

Timestep Collection Time: 2.20951
Timestep Consumption Time: 2.57246
PPO Batch Consumption Time: 0.30009
Total Iteration Time: 4.78198

Cumulative Model Updates: 172,154
Cumulative Timesteps: 1,435,669,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1435669378...
Checkpoint 1435669378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321,504.54163
Policy Entropy: 3.67264
Value Function Loss: 0.02120

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.35737
Value Function Update Magnitude: 0.37676

Collected Steps per Second: 22,259.47172
Overall Steps per Second: 10,525.89786

Timestep Collection Time: 2.24623
Timestep Consumption Time: 2.50395
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.75019

Cumulative Model Updates: 172,160
Cumulative Timesteps: 1,435,719,378

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,504.54163
Policy Entropy: 3.68535
Value Function Loss: 0.01875

Mean KL Divergence: 0.00780
SB3 Clip Fraction: 0.09713
Policy Update Magnitude: 0.34975
Value Function Update Magnitude: 0.26895

Collected Steps per Second: 22,524.52372
Overall Steps per Second: 10,656.70359

Timestep Collection Time: 2.22051
Timestep Consumption Time: 2.47287
PPO Batch Consumption Time: 0.28378
Total Iteration Time: 4.69338

Cumulative Model Updates: 172,166
Cumulative Timesteps: 1,435,769,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1435769394...
Checkpoint 1435769394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321,504.54163
Policy Entropy: 3.68739
Value Function Loss: 0.01655

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.16459
Policy Update Magnitude: 0.32264
Value Function Update Magnitude: 0.22618

Collected Steps per Second: 22,185.06726
Overall Steps per Second: 10,643.70954

Timestep Collection Time: 2.25494
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.70005

Cumulative Model Updates: 172,172
Cumulative Timesteps: 1,435,819,420

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,504.54163
Policy Entropy: 3.68333
Value Function Loss: 0.01735

Mean KL Divergence: 0.01795
SB3 Clip Fraction: 0.21642
Policy Update Magnitude: 0.25528
Value Function Update Magnitude: 0.19551

Collected Steps per Second: 22,507.93850
Overall Steps per Second: 10,611.41695

Timestep Collection Time: 2.22322
Timestep Consumption Time: 2.49246
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.71568

Cumulative Model Updates: 172,178
Cumulative Timesteps: 1,435,869,460

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1435869460...
Checkpoint 1435869460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321,504.54163
Policy Entropy: 3.66191
Value Function Loss: 0.02267

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.17376
Policy Update Magnitude: 0.27060
Value Function Update Magnitude: 0.26016

Collected Steps per Second: 22,350.81148
Overall Steps per Second: 10,540.14381

Timestep Collection Time: 2.23777
Timestep Consumption Time: 2.50752
PPO Batch Consumption Time: 0.29278
Total Iteration Time: 4.74529

Cumulative Model Updates: 172,184
Cumulative Timesteps: 1,435,919,476

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,504.54163
Policy Entropy: 3.64237
Value Function Loss: 0.03548

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.15652
Policy Update Magnitude: 0.41676
Value Function Update Magnitude: 0.31731

Collected Steps per Second: 22,699.49846
Overall Steps per Second: 10,673.40737

Timestep Collection Time: 2.20340
Timestep Consumption Time: 2.48264
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.68604

Cumulative Model Updates: 172,190
Cumulative Timesteps: 1,435,969,492

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1435969492...
Checkpoint 1435969492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 692,321.91445
Policy Entropy: 3.64494
Value Function Loss: 0.04623

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15016
Policy Update Magnitude: 0.56068
Value Function Update Magnitude: 0.32124

Collected Steps per Second: 22,111.23868
Overall Steps per Second: 10,412.87759

Timestep Collection Time: 2.26202
Timestep Consumption Time: 2.54127
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.80328

Cumulative Model Updates: 172,196
Cumulative Timesteps: 1,436,019,508

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,425.81627
Policy Entropy: 3.66190
Value Function Loss: 0.05270

Mean KL Divergence: 0.01414
SB3 Clip Fraction: 0.17263
Policy Update Magnitude: 0.64397
Value Function Update Magnitude: 0.36919

Collected Steps per Second: 22,094.53311
Overall Steps per Second: 10,667.01298

Timestep Collection Time: 2.26327
Timestep Consumption Time: 2.42464
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.68791

Cumulative Model Updates: 172,202
Cumulative Timesteps: 1,436,069,514

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1436069514...
Checkpoint 1436069514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,425.81627
Policy Entropy: 3.68905
Value Function Loss: 0.04342

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.18801
Policy Update Magnitude: 0.70307
Value Function Update Magnitude: 0.33525

Collected Steps per Second: 21,687.78161
Overall Steps per Second: 10,593.43479

Timestep Collection Time: 2.30664
Timestep Consumption Time: 2.41571
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.72236

Cumulative Model Updates: 172,208
Cumulative Timesteps: 1,436,119,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 522,142.44836
Policy Entropy: 3.71563
Value Function Loss: 0.03941

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13681
Policy Update Magnitude: 0.67314
Value Function Update Magnitude: 0.40073

Collected Steps per Second: 22,232.60435
Overall Steps per Second: 10,785.73450

Timestep Collection Time: 2.24895
Timestep Consumption Time: 2.38680
PPO Batch Consumption Time: 0.28293
Total Iteration Time: 4.63575

Cumulative Model Updates: 172,214
Cumulative Timesteps: 1,436,169,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1436169540...
Checkpoint 1436169540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946,978.47802
Policy Entropy: 3.72354
Value Function Loss: 0.04202

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11816
Policy Update Magnitude: 0.74950
Value Function Update Magnitude: 0.50100

Collected Steps per Second: 21,693.22424
Overall Steps per Second: 10,580.09148

Timestep Collection Time: 2.30579
Timestep Consumption Time: 2.42196
PPO Batch Consumption Time: 0.27915
Total Iteration Time: 4.72775

Cumulative Model Updates: 172,220
Cumulative Timesteps: 1,436,219,560

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946,978.47802
Policy Entropy: 3.70867
Value Function Loss: 0.04109

Mean KL Divergence: 0.01324
SB3 Clip Fraction: 0.16325
Policy Update Magnitude: 0.79523
Value Function Update Magnitude: 0.60465

Collected Steps per Second: 22,496.93990
Overall Steps per Second: 10,617.56050

Timestep Collection Time: 2.22297
Timestep Consumption Time: 2.48715
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.71012

Cumulative Model Updates: 172,226
Cumulative Timesteps: 1,436,269,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1436269570...
Checkpoint 1436269570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946,978.47802
Policy Entropy: 3.67353
Value Function Loss: 0.03788

Mean KL Divergence: 0.01406
SB3 Clip Fraction: 0.17154
Policy Update Magnitude: 0.61680
Value Function Update Magnitude: 0.57664

Collected Steps per Second: 22,049.67560
Overall Steps per Second: 10,537.89952

Timestep Collection Time: 2.26851
Timestep Consumption Time: 2.47816
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.74668

Cumulative Model Updates: 172,232
Cumulative Timesteps: 1,436,319,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946,978.47802
Policy Entropy: 3.64753
Value Function Loss: 0.02930

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15158
Policy Update Magnitude: 0.45431
Value Function Update Magnitude: 0.45961

Collected Steps per Second: 22,396.97628
Overall Steps per Second: 10,497.57736

Timestep Collection Time: 2.23280
Timestep Consumption Time: 2.53096
PPO Batch Consumption Time: 0.29816
Total Iteration Time: 4.76377

Cumulative Model Updates: 172,238
Cumulative Timesteps: 1,436,369,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1436369598...
Checkpoint 1436369598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946,978.47802
Policy Entropy: 3.63887
Value Function Loss: 0.03131

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.38092
Value Function Update Magnitude: 0.37007

Collected Steps per Second: 21,948.38033
Overall Steps per Second: 10,564.12142

Timestep Collection Time: 2.27917
Timestep Consumption Time: 2.45611
PPO Batch Consumption Time: 0.27953
Total Iteration Time: 4.73527

Cumulative Model Updates: 172,244
Cumulative Timesteps: 1,436,419,622

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 946,978.47802
Policy Entropy: 3.65439
Value Function Loss: 0.02940

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14398
Policy Update Magnitude: 0.36408
Value Function Update Magnitude: 0.27874

Collected Steps per Second: 22,797.89628
Overall Steps per Second: 10,679.99461

Timestep Collection Time: 2.19345
Timestep Consumption Time: 2.48876
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.68221

Cumulative Model Updates: 172,250
Cumulative Timesteps: 1,436,469,628

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1436469628...
Checkpoint 1436469628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 946,978.47802
Policy Entropy: 3.64912
Value Function Loss: 0.03305

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.35995
Value Function Update Magnitude: 0.23373

Collected Steps per Second: 22,583.42657
Overall Steps per Second: 10,811.25121

Timestep Collection Time: 2.21401
Timestep Consumption Time: 2.41080
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.62481

Cumulative Model Updates: 172,256
Cumulative Timesteps: 1,436,519,628

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811,971.70859
Policy Entropy: 3.65457
Value Function Loss: 0.03311

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14509
Policy Update Magnitude: 0.44414
Value Function Update Magnitude: 0.35606

Collected Steps per Second: 22,512.46002
Overall Steps per Second: 10,585.12827

Timestep Collection Time: 2.22215
Timestep Consumption Time: 2.50392
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.72606

Cumulative Model Updates: 172,262
Cumulative Timesteps: 1,436,569,654

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1436569654...
Checkpoint 1436569654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.63843
Value Function Loss: 0.04101

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.49382
Value Function Update Magnitude: 0.57082

Collected Steps per Second: 21,558.13884
Overall Steps per Second: 10,569.79678

Timestep Collection Time: 2.32024
Timestep Consumption Time: 2.41211
PPO Batch Consumption Time: 0.28590
Total Iteration Time: 4.73235

Cumulative Model Updates: 172,268
Cumulative Timesteps: 1,436,619,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.65466
Value Function Loss: 0.03877

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.52387
Value Function Update Magnitude: 0.57747

Collected Steps per Second: 22,181.83409
Overall Steps per Second: 10,850.33537

Timestep Collection Time: 2.25446
Timestep Consumption Time: 2.35443
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.60889

Cumulative Model Updates: 172,274
Cumulative Timesteps: 1,436,669,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1436669682...
Checkpoint 1436669682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.65751
Value Function Loss: 0.03655

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13401
Policy Update Magnitude: 0.50568
Value Function Update Magnitude: 0.52248

Collected Steps per Second: 21,649.74260
Overall Steps per Second: 10,463.21508

Timestep Collection Time: 2.30987
Timestep Consumption Time: 2.46954
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.77941

Cumulative Model Updates: 172,280
Cumulative Timesteps: 1,436,719,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.67221
Value Function Loss: 0.03123

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12835
Policy Update Magnitude: 0.47629
Value Function Update Magnitude: 0.51179

Collected Steps per Second: 22,958.54045
Overall Steps per Second: 10,695.15378

Timestep Collection Time: 2.17854
Timestep Consumption Time: 2.49797
PPO Batch Consumption Time: 0.29321
Total Iteration Time: 4.67651

Cumulative Model Updates: 172,286
Cumulative Timesteps: 1,436,769,706

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1436769706...
Checkpoint 1436769706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.68838
Value Function Loss: 0.02847

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.45817
Value Function Update Magnitude: 0.48292

Collected Steps per Second: 22,066.39548
Overall Steps per Second: 10,729.45770

Timestep Collection Time: 2.26698
Timestep Consumption Time: 2.39533
PPO Batch Consumption Time: 0.27653
Total Iteration Time: 4.66230

Cumulative Model Updates: 172,292
Cumulative Timesteps: 1,436,819,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.68132
Value Function Loss: 0.02649

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.40903
Value Function Update Magnitude: 0.40790

Collected Steps per Second: 22,840.94764
Overall Steps per Second: 10,808.68322

Timestep Collection Time: 2.19028
Timestep Consumption Time: 2.43822
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.62850

Cumulative Model Updates: 172,298
Cumulative Timesteps: 1,436,869,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1436869758...
Checkpoint 1436869758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.68697
Value Function Loss: 0.02314

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.36213
Value Function Update Magnitude: 0.33997

Collected Steps per Second: 22,423.76002
Overall Steps per Second: 10,718.96639

Timestep Collection Time: 2.23076
Timestep Consumption Time: 2.43592
PPO Batch Consumption Time: 0.27678
Total Iteration Time: 4.66668

Cumulative Model Updates: 172,304
Cumulative Timesteps: 1,436,919,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.66548
Value Function Loss: 0.02299

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14227
Policy Update Magnitude: 0.35658
Value Function Update Magnitude: 0.29521

Collected Steps per Second: 22,732.84256
Overall Steps per Second: 10,782.60043

Timestep Collection Time: 2.20016
Timestep Consumption Time: 2.43842
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.63858

Cumulative Model Updates: 172,310
Cumulative Timesteps: 1,436,969,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1436969796...
Checkpoint 1436969796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.67493
Value Function Loss: 0.02316

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.38859
Value Function Update Magnitude: 0.29244

Collected Steps per Second: 21,812.00399
Overall Steps per Second: 10,430.86958

Timestep Collection Time: 2.29277
Timestep Consumption Time: 2.50165
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.79442

Cumulative Model Updates: 172,316
Cumulative Timesteps: 1,437,019,806

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.66545
Value Function Loss: 0.02589

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.17541
Policy Update Magnitude: 0.41020
Value Function Update Magnitude: 0.38421

Collected Steps per Second: 22,524.13313
Overall Steps per Second: 10,724.79782

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.44313
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.66377

Cumulative Model Updates: 172,322
Cumulative Timesteps: 1,437,069,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1437069824...
Checkpoint 1437069824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 532,758.60330
Policy Entropy: 3.66311
Value Function Loss: 0.02831

Mean KL Divergence: 0.01912
SB3 Clip Fraction: 0.22603
Policy Update Magnitude: 0.39199
Value Function Update Magnitude: 0.39550

Collected Steps per Second: 22,145.77720
Overall Steps per Second: 10,622.19594

Timestep Collection Time: 2.25966
Timestep Consumption Time: 2.45142
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.71108

Cumulative Model Updates: 172,328
Cumulative Timesteps: 1,437,119,866

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.67095
Value Function Loss: 0.03182

Mean KL Divergence: 0.01325
SB3 Clip Fraction: 0.17236
Policy Update Magnitude: 0.40740
Value Function Update Magnitude: 0.46636

Collected Steps per Second: 22,864.66139
Overall Steps per Second: 10,698.96368

Timestep Collection Time: 2.18827
Timestep Consumption Time: 2.48826
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.67653

Cumulative Model Updates: 172,334
Cumulative Timesteps: 1,437,169,900

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1437169900...
Checkpoint 1437169900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.66854
Value Function Loss: 0.03315

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13635
Policy Update Magnitude: 0.41804
Value Function Update Magnitude: 0.44912

Collected Steps per Second: 22,372.57825
Overall Steps per Second: 10,536.87268

Timestep Collection Time: 2.23604
Timestep Consumption Time: 2.51167
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.74771

Cumulative Model Updates: 172,340
Cumulative Timesteps: 1,437,219,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.66751
Value Function Loss: 0.03271

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14857
Policy Update Magnitude: 0.41916
Value Function Update Magnitude: 0.40704

Collected Steps per Second: 22,757.80308
Overall Steps per Second: 10,777.90094

Timestep Collection Time: 2.19766
Timestep Consumption Time: 2.44276
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.64042

Cumulative Model Updates: 172,346
Cumulative Timesteps: 1,437,269,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1437269940...
Checkpoint 1437269940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.67543
Value Function Loss: 0.02998

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.39493
Value Function Update Magnitude: 0.33476

Collected Steps per Second: 21,452.64896
Overall Steps per Second: 10,663.78285

Timestep Collection Time: 2.33137
Timestep Consumption Time: 2.35871
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.69008

Cumulative Model Updates: 172,352
Cumulative Timesteps: 1,437,319,954

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.67167
Value Function Loss: 0.02725

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15962
Policy Update Magnitude: 0.35508
Value Function Update Magnitude: 0.26642

Collected Steps per Second: 22,134.80645
Overall Steps per Second: 10,834.63609

Timestep Collection Time: 2.25970
Timestep Consumption Time: 2.35679
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.61649

Cumulative Model Updates: 172,358
Cumulative Timesteps: 1,437,369,972

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1437369972...
Checkpoint 1437369972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.67349
Value Function Loss: 0.02656

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.35676
Value Function Update Magnitude: 0.36089

Collected Steps per Second: 21,502.44543
Overall Steps per Second: 10,395.29408

Timestep Collection Time: 2.32597
Timestep Consumption Time: 2.48525
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.81122

Cumulative Model Updates: 172,364
Cumulative Timesteps: 1,437,419,986

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.68787
Value Function Loss: 0.02373

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.14365
Policy Update Magnitude: 0.44027
Value Function Update Magnitude: 0.48099

Collected Steps per Second: 22,979.62984
Overall Steps per Second: 10,830.59000

Timestep Collection Time: 2.17715
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.61932

Cumulative Model Updates: 172,370
Cumulative Timesteps: 1,437,470,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1437470016...
Checkpoint 1437470016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.67628
Value Function Loss: 0.02585

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15074
Policy Update Magnitude: 0.36985
Value Function Update Magnitude: 0.36106

Collected Steps per Second: 22,397.15371
Overall Steps per Second: 10,643.41685

Timestep Collection Time: 2.23314
Timestep Consumption Time: 2.46610
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.69924

Cumulative Model Updates: 172,376
Cumulative Timesteps: 1,437,520,032

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.69113
Value Function Loss: 0.02564

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.16566
Policy Update Magnitude: 0.37182
Value Function Update Magnitude: 0.27153

Collected Steps per Second: 22,748.70789
Overall Steps per Second: 10,784.37385

Timestep Collection Time: 2.19828
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.63708

Cumulative Model Updates: 172,382
Cumulative Timesteps: 1,437,570,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1437570040...
Checkpoint 1437570040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.67001
Value Function Loss: 0.02992

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15892
Policy Update Magnitude: 0.49135
Value Function Update Magnitude: 0.33579

Collected Steps per Second: 22,040.73351
Overall Steps per Second: 10,658.51502

Timestep Collection Time: 2.26998
Timestep Consumption Time: 2.42411
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.69409

Cumulative Model Updates: 172,388
Cumulative Timesteps: 1,437,620,072

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 563,853.05556
Policy Entropy: 3.65388
Value Function Loss: 0.04038

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15354
Policy Update Magnitude: 0.58541
Value Function Update Magnitude: 0.37260

Collected Steps per Second: 22,613.35159
Overall Steps per Second: 10,413.39553

Timestep Collection Time: 2.21268
Timestep Consumption Time: 2.59229
PPO Batch Consumption Time: 0.30526
Total Iteration Time: 4.80496

Cumulative Model Updates: 172,394
Cumulative Timesteps: 1,437,670,108

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1437670108...
Checkpoint 1437670108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,420,427.83909
Policy Entropy: 3.64856
Value Function Loss: 0.05338

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13927
Policy Update Magnitude: 0.58931
Value Function Update Magnitude: 0.38491

Collected Steps per Second: 21,604.73926
Overall Steps per Second: 10,363.08501

Timestep Collection Time: 2.31542
Timestep Consumption Time: 2.51172
PPO Batch Consumption Time: 0.29282
Total Iteration Time: 4.82713

Cumulative Model Updates: 172,400
Cumulative Timesteps: 1,437,720,132

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846,891.73124
Policy Entropy: 3.65149
Value Function Loss: 0.05629

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.15210
Policy Update Magnitude: 0.61805
Value Function Update Magnitude: 0.39805

Collected Steps per Second: 22,401.83256
Overall Steps per Second: 10,541.30055

Timestep Collection Time: 2.23303
Timestep Consumption Time: 2.51249
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.74552

Cumulative Model Updates: 172,406
Cumulative Timesteps: 1,437,770,156

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1437770156...
Checkpoint 1437770156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 627,630.21175
Policy Entropy: 3.67749
Value Function Loss: 0.05403

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14843
Policy Update Magnitude: 0.59342
Value Function Update Magnitude: 0.40685

Collected Steps per Second: 21,967.89544
Overall Steps per Second: 10,514.28064

Timestep Collection Time: 2.27669
Timestep Consumption Time: 2.48008
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.75677

Cumulative Model Updates: 172,412
Cumulative Timesteps: 1,437,820,170

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 677,856.54010
Policy Entropy: 3.66786
Value Function Loss: 0.05392

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.57678
Value Function Update Magnitude: 0.41182

Collected Steps per Second: 22,408.54007
Overall Steps per Second: 10,541.14505

Timestep Collection Time: 2.23290
Timestep Consumption Time: 2.51383
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.74673

Cumulative Model Updates: 172,418
Cumulative Timesteps: 1,437,870,206

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1437870206...
Checkpoint 1437870206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291,802.48193
Policy Entropy: 3.66505
Value Function Loss: 0.05304

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14473
Policy Update Magnitude: 0.60301
Value Function Update Magnitude: 0.43382

Collected Steps per Second: 22,065.31196
Overall Steps per Second: 10,577.73938

Timestep Collection Time: 2.26682
Timestep Consumption Time: 2.46179
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.72861

Cumulative Model Updates: 172,424
Cumulative Timesteps: 1,437,920,224

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300,617.97426
Policy Entropy: 3.65448
Value Function Loss: 0.05361

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14777
Policy Update Magnitude: 0.61607
Value Function Update Magnitude: 0.42943

Collected Steps per Second: 22,713.74256
Overall Steps per Second: 10,599.64053

Timestep Collection Time: 2.20131
Timestep Consumption Time: 2.51583
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.71714

Cumulative Model Updates: 172,430
Cumulative Timesteps: 1,437,970,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1437970224...
Checkpoint 1437970224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,617.97426
Policy Entropy: 3.68226
Value Function Loss: 0.04016

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13572
Policy Update Magnitude: 0.56363
Value Function Update Magnitude: 0.40127

Collected Steps per Second: 21,916.24126
Overall Steps per Second: 10,455.52267

Timestep Collection Time: 2.28205
Timestep Consumption Time: 2.50145
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.78350

Cumulative Model Updates: 172,436
Cumulative Timesteps: 1,438,020,238

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 300,617.97426
Policy Entropy: 3.68880
Value Function Loss: 0.03510

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13822
Policy Update Magnitude: 0.50992
Value Function Update Magnitude: 0.42980

Collected Steps per Second: 22,518.33887
Overall Steps per Second: 10,558.45253

Timestep Collection Time: 2.22068
Timestep Consumption Time: 2.51543
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.73611

Cumulative Model Updates: 172,442
Cumulative Timesteps: 1,438,070,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1438070244...
Checkpoint 1438070244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,617.97426
Policy Entropy: 3.69224
Value Function Loss: 0.03258

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.49598
Value Function Update Magnitude: 0.49217

Collected Steps per Second: 21,588.49629
Overall Steps per Second: 10,459.61533

Timestep Collection Time: 2.31827
Timestep Consumption Time: 2.46661
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.78488

Cumulative Model Updates: 172,448
Cumulative Timesteps: 1,438,120,292

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,235,334.12863
Policy Entropy: 3.66601
Value Function Loss: 0.03993

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.14585
Policy Update Magnitude: 0.53778
Value Function Update Magnitude: 0.49240

Collected Steps per Second: 21,983.83038
Overall Steps per Second: 10,518.17831

Timestep Collection Time: 2.27522
Timestep Consumption Time: 2.48017
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.75539

Cumulative Model Updates: 172,454
Cumulative Timesteps: 1,438,170,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1438170310...
Checkpoint 1438170310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810,508.44805
Policy Entropy: 3.66913
Value Function Loss: 0.03956

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14902
Policy Update Magnitude: 0.50149
Value Function Update Magnitude: 0.47429

Collected Steps per Second: 22,230.35891
Overall Steps per Second: 10,645.78332

Timestep Collection Time: 2.25017
Timestep Consumption Time: 2.44860
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.69876

Cumulative Model Updates: 172,460
Cumulative Timesteps: 1,438,220,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810,508.44805
Policy Entropy: 3.68230
Value Function Loss: 0.03437

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.43351
Value Function Update Magnitude: 0.50683

Collected Steps per Second: 22,091.38392
Overall Steps per Second: 10,701.65453

Timestep Collection Time: 2.26432
Timestep Consumption Time: 2.40991
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.67423

Cumulative Model Updates: 172,466
Cumulative Timesteps: 1,438,270,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1438270354...
Checkpoint 1438270354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810,508.44805
Policy Entropy: 3.68608
Value Function Loss: 0.02574

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.35099
Value Function Update Magnitude: 0.46391

Collected Steps per Second: 22,007.84395
Overall Steps per Second: 10,624.57135

Timestep Collection Time: 2.27401
Timestep Consumption Time: 2.43639
PPO Batch Consumption Time: 0.29204
Total Iteration Time: 4.71040

Cumulative Model Updates: 172,472
Cumulative Timesteps: 1,438,320,400

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810,508.44805
Policy Entropy: 3.69499
Value Function Loss: 0.02388

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.33933
Value Function Update Magnitude: 0.46707

Collected Steps per Second: 22,138.79392
Overall Steps per Second: 10,594.80764

Timestep Collection Time: 2.25929
Timestep Consumption Time: 2.46170
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.72099

Cumulative Model Updates: 172,478
Cumulative Timesteps: 1,438,370,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1438370418...
Checkpoint 1438370418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708,545.47631
Policy Entropy: 3.68619
Value Function Loss: 0.02811

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.39134
Value Function Update Magnitude: 0.64222

Collected Steps per Second: 22,122.60087
Overall Steps per Second: 10,695.47539

Timestep Collection Time: 2.26040
Timestep Consumption Time: 2.41503
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.67543

Cumulative Model Updates: 172,484
Cumulative Timesteps: 1,438,420,424

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 573,926.30123
Policy Entropy: 3.69209
Value Function Loss: 0.03149

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.45189
Value Function Update Magnitude: 0.72167

Collected Steps per Second: 22,932.40321
Overall Steps per Second: 10,912.26534

Timestep Collection Time: 2.18041
Timestep Consumption Time: 2.40178
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.58218

Cumulative Model Updates: 172,490
Cumulative Timesteps: 1,438,470,426

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1438470426...
Checkpoint 1438470426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 573,926.30123
Policy Entropy: 3.68971
Value Function Loss: 0.02951

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.44233
Value Function Update Magnitude: 0.66545

Collected Steps per Second: 22,338.45615
Overall Steps per Second: 10,684.51329

Timestep Collection Time: 2.23928
Timestep Consumption Time: 2.44245
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.68173

Cumulative Model Updates: 172,496
Cumulative Timesteps: 1,438,520,448

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,347,907.17449
Policy Entropy: 3.67093
Value Function Loss: 0.03509

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.45639
Value Function Update Magnitude: 0.54861

Collected Steps per Second: 22,575.57287
Overall Steps per Second: 10,585.36264

Timestep Collection Time: 2.21602
Timestep Consumption Time: 2.51013
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.72615

Cumulative Model Updates: 172,502
Cumulative Timesteps: 1,438,570,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1438570476...
Checkpoint 1438570476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,065,230.20734
Policy Entropy: 3.66626
Value Function Loss: 0.03910

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.47096
Value Function Update Magnitude: 0.50281

Collected Steps per Second: 22,031.24036
Overall Steps per Second: 10,426.71504

Timestep Collection Time: 2.26969
Timestep Consumption Time: 2.52607
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.79576

Cumulative Model Updates: 172,508
Cumulative Timesteps: 1,438,620,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,256,306.70063
Policy Entropy: 3.66223
Value Function Loss: 0.04231

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.47310
Value Function Update Magnitude: 0.55588

Collected Steps per Second: 22,628.76694
Overall Steps per Second: 10,600.91707

Timestep Collection Time: 2.21046
Timestep Consumption Time: 2.50800
PPO Batch Consumption Time: 0.29328
Total Iteration Time: 4.71846

Cumulative Model Updates: 172,514
Cumulative Timesteps: 1,438,670,500

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1438670500...
Checkpoint 1438670500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,153.00620
Policy Entropy: 3.66688
Value Function Loss: 0.04404

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.51206
Value Function Update Magnitude: 0.71399

Collected Steps per Second: 22,123.96527
Overall Steps per Second: 10,600.24457

Timestep Collection Time: 2.25999
Timestep Consumption Time: 2.45688
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.71687

Cumulative Model Updates: 172,520
Cumulative Timesteps: 1,438,720,500

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,887.69449
Policy Entropy: 3.65870
Value Function Loss: 0.04981

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14184
Policy Update Magnitude: 0.52893
Value Function Update Magnitude: 0.80163

Collected Steps per Second: 22,395.03708
Overall Steps per Second: 10,556.45316

Timestep Collection Time: 2.23398
Timestep Consumption Time: 2.50530
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.73928

Cumulative Model Updates: 172,526
Cumulative Timesteps: 1,438,770,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1438770530...
Checkpoint 1438770530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,887.69449
Policy Entropy: 3.67046
Value Function Loss: 0.04311

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13691
Policy Update Magnitude: 0.52403
Value Function Update Magnitude: 0.65878

Collected Steps per Second: 21,297.85377
Overall Steps per Second: 10,648.15521

Timestep Collection Time: 2.34925
Timestep Consumption Time: 2.34959
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.69884

Cumulative Model Updates: 172,532
Cumulative Timesteps: 1,438,820,564

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,887.69449
Policy Entropy: 3.67100
Value Function Loss: 0.03161

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14292
Policy Update Magnitude: 0.46114
Value Function Update Magnitude: 0.51894

Collected Steps per Second: 21,729.73882
Overall Steps per Second: 10,605.60435

Timestep Collection Time: 2.30201
Timestep Consumption Time: 2.41456
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.71656

Cumulative Model Updates: 172,538
Cumulative Timesteps: 1,438,870,586

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1438870586...
Checkpoint 1438870586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,887.69449
Policy Entropy: 3.67224
Value Function Loss: 0.02214

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.37037
Value Function Update Magnitude: 0.42374

Collected Steps per Second: 21,737.33314
Overall Steps per Second: 10,640.88636

Timestep Collection Time: 2.30056
Timestep Consumption Time: 2.39905
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.69961

Cumulative Model Updates: 172,544
Cumulative Timesteps: 1,438,920,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,887.69449
Policy Entropy: 3.64893
Value Function Loss: 0.02372

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.33695
Value Function Update Magnitude: 0.37620

Collected Steps per Second: 22,136.53492
Overall Steps per Second: 10,730.74559

Timestep Collection Time: 2.25997
Timestep Consumption Time: 2.40214
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.66212

Cumulative Model Updates: 172,550
Cumulative Timesteps: 1,438,970,622

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1438970622...
Checkpoint 1438970622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 555,375.51120
Policy Entropy: 3.64680
Value Function Loss: 0.02626

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.33916
Value Function Update Magnitude: 0.35757

Collected Steps per Second: 22,111.73719
Overall Steps per Second: 10,443.46681

Timestep Collection Time: 2.26269
Timestep Consumption Time: 2.52806
PPO Batch Consumption Time: 0.29749
Total Iteration Time: 4.79075

Cumulative Model Updates: 172,556
Cumulative Timesteps: 1,439,020,654

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 685,120.54927
Policy Entropy: 3.65546
Value Function Loss: 0.03043

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.34714
Value Function Update Magnitude: 0.46888

Collected Steps per Second: 22,936.36894
Overall Steps per Second: 10,631.53205

Timestep Collection Time: 2.18021
Timestep Consumption Time: 2.52335
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.70356

Cumulative Model Updates: 172,562
Cumulative Timesteps: 1,439,070,660

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1439070660...
Checkpoint 1439070660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 449,513.93435
Policy Entropy: 3.66738
Value Function Loss: 0.02858

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13234
Policy Update Magnitude: 0.34599
Value Function Update Magnitude: 0.54950

Collected Steps per Second: 22,364.47533
Overall Steps per Second: 10,618.02396

Timestep Collection Time: 2.23703
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.71180

Cumulative Model Updates: 172,568
Cumulative Timesteps: 1,439,120,690

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 449,513.93435
Policy Entropy: 3.67041
Value Function Loss: 0.02710

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12591
Policy Update Magnitude: 0.32480
Value Function Update Magnitude: 0.44534

Collected Steps per Second: 22,627.86992
Overall Steps per Second: 10,583.94187

Timestep Collection Time: 2.21073
Timestep Consumption Time: 2.51568
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.72641

Cumulative Model Updates: 172,574
Cumulative Timesteps: 1,439,170,714

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1439170714...
Checkpoint 1439170714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,409,568.57996
Policy Entropy: 3.65780
Value Function Loss: 0.02974

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.31855
Value Function Update Magnitude: 0.38847

Collected Steps per Second: 22,376.77989
Overall Steps per Second: 10,559.95429

Timestep Collection Time: 2.23580
Timestep Consumption Time: 2.50191
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.73771

Cumulative Model Updates: 172,580
Cumulative Timesteps: 1,439,220,744

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 749,106.71409
Policy Entropy: 3.64973
Value Function Loss: 0.03120

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.32742
Value Function Update Magnitude: 0.43311

Collected Steps per Second: 23,099.38549
Overall Steps per Second: 10,873.97451

Timestep Collection Time: 2.16577
Timestep Consumption Time: 2.43494
PPO Batch Consumption Time: 0.27918
Total Iteration Time: 4.60071

Cumulative Model Updates: 172,586
Cumulative Timesteps: 1,439,270,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1439270772...
Checkpoint 1439270772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 878,373.10981
Policy Entropy: 3.65733
Value Function Loss: 0.03154

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13261
Policy Update Magnitude: 0.36732
Value Function Update Magnitude: 0.57493

Collected Steps per Second: 22,426.96448
Overall Steps per Second: 10,685.19388

Timestep Collection Time: 2.23151
Timestep Consumption Time: 2.45217
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.68368

Cumulative Model Updates: 172,592
Cumulative Timesteps: 1,439,320,818

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 791,365.21120
Policy Entropy: 3.66685
Value Function Loss: 0.03089

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13326
Policy Update Magnitude: 0.36410
Value Function Update Magnitude: 0.55343

Collected Steps per Second: 22,192.65490
Overall Steps per Second: 10,831.31220

Timestep Collection Time: 2.25309
Timestep Consumption Time: 2.36334
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.61643

Cumulative Model Updates: 172,598
Cumulative Timesteps: 1,439,370,820

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1439370820...
Checkpoint 1439370820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689,951.31784
Policy Entropy: 3.67130
Value Function Loss: 0.03415

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.37394
Value Function Update Magnitude: 0.57258

Collected Steps per Second: 21,414.92195
Overall Steps per Second: 10,661.12284

Timestep Collection Time: 2.33557
Timestep Consumption Time: 2.35587
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.69144

Cumulative Model Updates: 172,604
Cumulative Timesteps: 1,439,420,836

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,087.05302
Policy Entropy: 3.65708
Value Function Loss: 0.04495

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.43701
Value Function Update Magnitude: 0.74137

Collected Steps per Second: 22,395.86081
Overall Steps per Second: 10,873.62084

Timestep Collection Time: 2.23256
Timestep Consumption Time: 2.36573
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.59828

Cumulative Model Updates: 172,610
Cumulative Timesteps: 1,439,470,836

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1439470836...
Checkpoint 1439470836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,194.63015
Policy Entropy: 3.68902
Value Function Loss: 0.05206

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.49310
Value Function Update Magnitude: 0.83554

Collected Steps per Second: 21,448.99813
Overall Steps per Second: 10,415.73964

Timestep Collection Time: 2.33214
Timestep Consumption Time: 2.47040
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.80254

Cumulative Model Updates: 172,616
Cumulative Timesteps: 1,439,520,858

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,815.21303
Policy Entropy: 3.70869
Value Function Loss: 0.04798

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.53337
Value Function Update Magnitude: 0.80594

Collected Steps per Second: 22,793.28251
Overall Steps per Second: 10,758.34088

Timestep Collection Time: 2.19468
Timestep Consumption Time: 2.45511
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.64979

Cumulative Model Updates: 172,622
Cumulative Timesteps: 1,439,570,882

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1439570882...
Checkpoint 1439570882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,321.84765
Policy Entropy: 3.71057
Value Function Loss: 0.03826

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.49935
Value Function Update Magnitude: 0.93178

Collected Steps per Second: 22,096.45033
Overall Steps per Second: 10,602.31416

Timestep Collection Time: 2.26290
Timestep Consumption Time: 2.45324
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.71614

Cumulative Model Updates: 172,628
Cumulative Timesteps: 1,439,620,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 448,385.05865
Policy Entropy: 3.69473
Value Function Loss: 0.03265

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.44336
Value Function Update Magnitude: 0.89341

Collected Steps per Second: 22,502.85729
Overall Steps per Second: 10,599.92044

Timestep Collection Time: 2.22256
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.71834

Cumulative Model Updates: 172,634
Cumulative Timesteps: 1,439,670,898

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1439670898...
Checkpoint 1439670898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238,292.93150
Policy Entropy: 3.68637
Value Function Loss: 0.03202

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.43537
Value Function Update Magnitude: 0.89869

Collected Steps per Second: 22,502.30365
Overall Steps per Second: 10,606.64512

Timestep Collection Time: 2.22386
Timestep Consumption Time: 2.49412
PPO Batch Consumption Time: 0.29309
Total Iteration Time: 4.71799

Cumulative Model Updates: 172,640
Cumulative Timesteps: 1,439,720,940

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 238,292.93150
Policy Entropy: 3.68227
Value Function Loss: 0.03047

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13861
Policy Update Magnitude: 0.45573
Value Function Update Magnitude: 0.82115

Collected Steps per Second: 22,372.44422
Overall Steps per Second: 10,722.18471

Timestep Collection Time: 2.23596
Timestep Consumption Time: 2.42950
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.66547

Cumulative Model Updates: 172,646
Cumulative Timesteps: 1,439,770,964

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1439770964...
Checkpoint 1439770964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,958.59669
Policy Entropy: 3.67666
Value Function Loss: 0.02752

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14346
Policy Update Magnitude: 0.44030
Value Function Update Magnitude: 0.79466

Collected Steps per Second: 21,894.63642
Overall Steps per Second: 10,452.78282

Timestep Collection Time: 2.28421
Timestep Consumption Time: 2.50035
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.78456

Cumulative Model Updates: 172,652
Cumulative Timesteps: 1,439,820,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,028.84609
Policy Entropy: 3.69056
Value Function Loss: 0.02911

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.46169
Value Function Update Magnitude: 0.83621

Collected Steps per Second: 23,109.05755
Overall Steps per Second: 10,777.53557

Timestep Collection Time: 2.16461
Timestep Consumption Time: 2.47671
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.64132

Cumulative Model Updates: 172,658
Cumulative Timesteps: 1,439,870,998

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1439870998...
Checkpoint 1439870998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 418,084.26210
Policy Entropy: 3.69884
Value Function Loss: 0.03574

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.49369
Value Function Update Magnitude: 0.97199

Collected Steps per Second: 22,504.57344
Overall Steps per Second: 10,633.78987

Timestep Collection Time: 2.22213
Timestep Consumption Time: 2.48062
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.70274

Cumulative Model Updates: 172,664
Cumulative Timesteps: 1,439,921,006

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,486.97080
Policy Entropy: 3.68762
Value Function Loss: 0.04569

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.51231
Value Function Update Magnitude: 0.89838

Collected Steps per Second: 22,214.83060
Overall Steps per Second: 10,824.70578

Timestep Collection Time: 2.25120
Timestep Consumption Time: 2.36879
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.61999

Cumulative Model Updates: 172,670
Cumulative Timesteps: 1,439,971,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1439971016...
Checkpoint 1439971016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 223,958.54000
Policy Entropy: 3.69098
Value Function Loss: 0.04242

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.54246
Value Function Update Magnitude: 0.70166

Collected Steps per Second: 21,670.44141
Overall Steps per Second: 10,755.84642

Timestep Collection Time: 2.30766
Timestep Consumption Time: 2.34172
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.64938

Cumulative Model Updates: 172,676
Cumulative Timesteps: 1,440,021,024

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,781.21414
Policy Entropy: 3.67337
Value Function Loss: 0.03991

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.54149
Value Function Update Magnitude: 0.56021

Collected Steps per Second: 22,064.69234
Overall Steps per Second: 10,814.21832

Timestep Collection Time: 2.26697
Timestep Consumption Time: 2.35842
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.62539

Cumulative Model Updates: 172,682
Cumulative Timesteps: 1,440,071,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1440071044...
Checkpoint 1440071044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,781.21414
Policy Entropy: 3.68527
Value Function Loss: 0.03402

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.50304
Value Function Update Magnitude: 0.46045

Collected Steps per Second: 21,532.29994
Overall Steps per Second: 10,601.92324

Timestep Collection Time: 2.32302
Timestep Consumption Time: 2.39499
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.71801

Cumulative Model Updates: 172,688
Cumulative Timesteps: 1,440,121,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,781.21414
Policy Entropy: 3.67295
Value Function Loss: 0.03486

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.47874
Value Function Update Magnitude: 0.39118

Collected Steps per Second: 22,568.76519
Overall Steps per Second: 10,663.28639

Timestep Collection Time: 2.21598
Timestep Consumption Time: 2.47413
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.69011

Cumulative Model Updates: 172,694
Cumulative Timesteps: 1,440,171,076

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1440171076...
Checkpoint 1440171076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,781.21414
Policy Entropy: 3.68600
Value Function Loss: 0.02910

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.45274
Value Function Update Magnitude: 0.41365

Collected Steps per Second: 21,909.92255
Overall Steps per Second: 10,487.72053

Timestep Collection Time: 2.28234
Timestep Consumption Time: 2.48571
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.76805

Cumulative Model Updates: 172,700
Cumulative Timesteps: 1,440,221,082

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,781.21414
Policy Entropy: 3.68043
Value Function Loss: 0.02628

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14497
Policy Update Magnitude: 0.43719
Value Function Update Magnitude: 0.44486

Collected Steps per Second: 22,814.42102
Overall Steps per Second: 10,673.42720

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.28861
Total Iteration Time: 4.68697

Cumulative Model Updates: 172,706
Cumulative Timesteps: 1,440,271,108

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1440271108...
Checkpoint 1440271108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,781.21414
Policy Entropy: 3.69212
Value Function Loss: 0.02271

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.40377
Value Function Update Magnitude: 0.39671

Collected Steps per Second: 22,508.15279
Overall Steps per Second: 10,538.33437

Timestep Collection Time: 2.22142
Timestep Consumption Time: 2.52317
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.74458

Cumulative Model Updates: 172,712
Cumulative Timesteps: 1,440,321,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 883,317.75107
Policy Entropy: 3.66813
Value Function Loss: 0.02807

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14049
Policy Update Magnitude: 0.45993
Value Function Update Magnitude: 0.52951

Collected Steps per Second: 22,360.05028
Overall Steps per Second: 10,718.84549

Timestep Collection Time: 2.23667
Timestep Consumption Time: 2.42913
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.66580

Cumulative Model Updates: 172,718
Cumulative Timesteps: 1,440,371,120

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1440371120...
Checkpoint 1440371120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 679,953.58958
Policy Entropy: 3.66866
Value Function Loss: 0.03304

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14476
Policy Update Magnitude: 0.47631
Value Function Update Magnitude: 0.74508

Collected Steps per Second: 22,157.99222
Overall Steps per Second: 10,637.97263

Timestep Collection Time: 2.25661
Timestep Consumption Time: 2.44372
PPO Batch Consumption Time: 0.27964
Total Iteration Time: 4.70033

Cumulative Model Updates: 172,724
Cumulative Timesteps: 1,440,421,122

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 640,153.33667
Policy Entropy: 3.66551
Value Function Loss: 0.03728

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.48638
Value Function Update Magnitude: 0.67910

Collected Steps per Second: 22,544.52794
Overall Steps per Second: 10,586.29725

Timestep Collection Time: 2.21925
Timestep Consumption Time: 2.50686
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.72611

Cumulative Model Updates: 172,730
Cumulative Timesteps: 1,440,471,154

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1440471154...
Checkpoint 1440471154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 640,153.33667
Policy Entropy: 3.67100
Value Function Loss: 0.03041

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.50211
Value Function Update Magnitude: 0.63261

Collected Steps per Second: 22,134.48487
Overall Steps per Second: 10,610.00419

Timestep Collection Time: 2.26000
Timestep Consumption Time: 2.45479
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.71480

Cumulative Model Updates: 172,736
Cumulative Timesteps: 1,440,521,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 381,384.38158
Policy Entropy: 3.67021
Value Function Loss: 0.04134

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.48464
Value Function Update Magnitude: 0.58498

Collected Steps per Second: 22,129.43254
Overall Steps per Second: 10,809.27342

Timestep Collection Time: 2.26043
Timestep Consumption Time: 2.36726
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.62769

Cumulative Model Updates: 172,742
Cumulative Timesteps: 1,440,571,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1440571200...
Checkpoint 1440571200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 643,351.47781
Policy Entropy: 3.68485
Value Function Loss: 0.05082

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.51072
Value Function Update Magnitude: 0.62942

Collected Steps per Second: 21,394.37725
Overall Steps per Second: 10,654.42869

Timestep Collection Time: 2.33893
Timestep Consumption Time: 2.35771
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.69664

Cumulative Model Updates: 172,748
Cumulative Timesteps: 1,440,621,240

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323,379.56970
Policy Entropy: 3.68192
Value Function Loss: 0.05845

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13783
Policy Update Magnitude: 0.60314
Value Function Update Magnitude: 0.64180

Collected Steps per Second: 22,019.04511
Overall Steps per Second: 10,664.93842

Timestep Collection Time: 2.27194
Timestep Consumption Time: 2.41876
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.69070

Cumulative Model Updates: 172,754
Cumulative Timesteps: 1,440,671,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1440671266...
Checkpoint 1440671266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,833.37574
Policy Entropy: 3.71005
Value Function Loss: 0.04516

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.63832
Value Function Update Magnitude: 0.76447

Collected Steps per Second: 21,562.15512
Overall Steps per Second: 10,529.96427

Timestep Collection Time: 2.31943
Timestep Consumption Time: 2.43006
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 4.74949

Cumulative Model Updates: 172,760
Cumulative Timesteps: 1,440,721,278

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266,996.78829
Policy Entropy: 3.68047
Value Function Loss: 0.04161

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.73620
Value Function Update Magnitude: 0.72232

Collected Steps per Second: 21,860.61344
Overall Steps per Second: 10,448.50493

Timestep Collection Time: 2.28822
Timestep Consumption Time: 2.49925
PPO Batch Consumption Time: 0.29348
Total Iteration Time: 4.78748

Cumulative Model Updates: 172,766
Cumulative Timesteps: 1,440,771,300

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1440771300...
Checkpoint 1440771300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 154,102.39221
Policy Entropy: 3.68096
Value Function Loss: 0.04392

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.17414
Policy Update Magnitude: 0.66924
Value Function Update Magnitude: 0.61498

Collected Steps per Second: 22,300.45086
Overall Steps per Second: 10,620.13388

Timestep Collection Time: 2.24345
Timestep Consumption Time: 2.46741
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.71086

Cumulative Model Updates: 172,772
Cumulative Timesteps: 1,440,821,330

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,608.42418
Policy Entropy: 3.65103
Value Function Loss: 0.05223

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.17683
Policy Update Magnitude: 0.65580
Value Function Update Magnitude: 0.52810

Collected Steps per Second: 22,655.20363
Overall Steps per Second: 10,822.79950

Timestep Collection Time: 2.20823
Timestep Consumption Time: 2.41423
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.62246

Cumulative Model Updates: 172,778
Cumulative Timesteps: 1,440,871,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1440871358...
Checkpoint 1440871358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,861.79002
Policy Entropy: 3.65046
Value Function Loss: 0.05824

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16308
Policy Update Magnitude: 0.68640
Value Function Update Magnitude: 0.52452

Collected Steps per Second: 22,218.36151
Overall Steps per Second: 10,658.90187

Timestep Collection Time: 2.25174
Timestep Consumption Time: 2.44199
PPO Batch Consumption Time: 0.27956
Total Iteration Time: 4.69373

Cumulative Model Updates: 172,784
Cumulative Timesteps: 1,440,921,388

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,861.79002
Policy Entropy: 3.64877
Value Function Loss: 0.06119

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14553
Policy Update Magnitude: 0.74773
Value Function Update Magnitude: 0.46984

Collected Steps per Second: 22,355.46885
Overall Steps per Second: 10,336.68994

Timestep Collection Time: 2.23730
Timestep Consumption Time: 2.60138
PPO Batch Consumption Time: 0.30673
Total Iteration Time: 4.83869

Cumulative Model Updates: 172,790
Cumulative Timesteps: 1,440,971,404

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1440971404...
Checkpoint 1440971404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210,086.98573
Policy Entropy: 3.65089
Value Function Loss: 0.05748

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.15695
Policy Update Magnitude: 0.72971
Value Function Update Magnitude: 0.38338

Collected Steps per Second: 22,102.81876
Overall Steps per Second: 10,445.37486

Timestep Collection Time: 2.26288
Timestep Consumption Time: 2.52546
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.78834

Cumulative Model Updates: 172,796
Cumulative Timesteps: 1,441,021,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,086.98573
Policy Entropy: 3.67677
Value Function Loss: 0.04241

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.69996
Value Function Update Magnitude: 0.35057

Collected Steps per Second: 22,717.74052
Overall Steps per Second: 10,764.20149

Timestep Collection Time: 2.20163
Timestep Consumption Time: 2.44489
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.64651

Cumulative Model Updates: 172,802
Cumulative Timesteps: 1,441,071,436

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1441071436...
Checkpoint 1441071436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210,086.98573
Policy Entropy: 3.70791
Value Function Loss: 0.02639

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.17851
Policy Update Magnitude: 0.58172
Value Function Update Magnitude: 0.40759

Collected Steps per Second: 22,048.52474
Overall Steps per Second: 10,628.33344

Timestep Collection Time: 2.26854
Timestep Consumption Time: 2.43756
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.70610

Cumulative Model Updates: 172,808
Cumulative Timesteps: 1,441,121,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,086.98573
Policy Entropy: 3.68879
Value Function Loss: 0.02847

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12002
Policy Update Magnitude: 0.54312
Value Function Update Magnitude: 0.44597

Collected Steps per Second: 22,627.23761
Overall Steps per Second: 10,585.90397

Timestep Collection Time: 2.21061
Timestep Consumption Time: 2.51454
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.72515

Cumulative Model Updates: 172,814
Cumulative Timesteps: 1,441,171,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1441171474...
Checkpoint 1441171474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210,086.98573
Policy Entropy: 3.69180
Value Function Loss: 0.03066

Mean KL Divergence: 0.01453
SB3 Clip Fraction: 0.17687
Policy Update Magnitude: 0.62875
Value Function Update Magnitude: 0.62453

Collected Steps per Second: 22,210.17923
Overall Steps per Second: 10,555.49361

Timestep Collection Time: 2.25230
Timestep Consumption Time: 2.48684
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.73914

Cumulative Model Updates: 172,820
Cumulative Timesteps: 1,441,221,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,086.98573
Policy Entropy: 3.67824
Value Function Loss: 0.03447

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.17054
Policy Update Magnitude: 0.59586
Value Function Update Magnitude: 0.59448

Collected Steps per Second: 22,811.46180
Overall Steps per Second: 10,704.37442

Timestep Collection Time: 2.19214
Timestep Consumption Time: 2.47940
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.67155

Cumulative Model Updates: 172,826
Cumulative Timesteps: 1,441,271,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1441271504...
Checkpoint 1441271504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,861.80339
Policy Entropy: 3.70467
Value Function Loss: 0.03362

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15520
Policy Update Magnitude: 0.48776
Value Function Update Magnitude: 0.57347

Collected Steps per Second: 21,782.12613
Overall Steps per Second: 10,650.12454

Timestep Collection Time: 2.29629
Timestep Consumption Time: 2.40018
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.69647

Cumulative Model Updates: 172,832
Cumulative Timesteps: 1,441,321,522

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,311.25042
Policy Entropy: 3.69987
Value Function Loss: 0.02923

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.45462
Value Function Update Magnitude: 0.57182

Collected Steps per Second: 22,383.91166
Overall Steps per Second: 10,725.81780

Timestep Collection Time: 2.23428
Timestep Consumption Time: 2.42848
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.66277

Cumulative Model Updates: 172,838
Cumulative Timesteps: 1,441,371,534

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1441371534...
Checkpoint 1441371534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,311.25042
Policy Entropy: 3.68468
Value Function Loss: 0.02670

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16642
Policy Update Magnitude: 0.40887
Value Function Update Magnitude: 0.49853

Collected Steps per Second: 21,515.15408
Overall Steps per Second: 10,555.40572

Timestep Collection Time: 2.32413
Timestep Consumption Time: 2.41316
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.73729

Cumulative Model Updates: 172,844
Cumulative Timesteps: 1,441,421,538

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,311.25042
Policy Entropy: 3.67426
Value Function Loss: 0.02704

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.17436
Policy Update Magnitude: 0.42275
Value Function Update Magnitude: 0.47430

Collected Steps per Second: 21,869.80827
Overall Steps per Second: 10,502.86553

Timestep Collection Time: 2.28717
Timestep Consumption Time: 2.47534
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.76251

Cumulative Model Updates: 172,850
Cumulative Timesteps: 1,441,471,558

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1441471558...
Checkpoint 1441471558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,311.25042
Policy Entropy: 3.68590
Value Function Loss: 0.02876

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14147
Policy Update Magnitude: 0.38664
Value Function Update Magnitude: 0.46327

Collected Steps per Second: 22,260.49489
Overall Steps per Second: 10,646.28997

Timestep Collection Time: 2.24622
Timestep Consumption Time: 2.45044
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.69666

Cumulative Model Updates: 172,856
Cumulative Timesteps: 1,441,521,560

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,311.25042
Policy Entropy: 3.67721
Value Function Loss: 0.03727

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.39822
Value Function Update Magnitude: 0.36697

Collected Steps per Second: 22,767.85070
Overall Steps per Second: 10,658.13550

Timestep Collection Time: 2.19740
Timestep Consumption Time: 2.49667
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.69407

Cumulative Model Updates: 172,862
Cumulative Timesteps: 1,441,571,590

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1441571590...
Checkpoint 1441571590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,907.12908
Policy Entropy: 3.70969
Value Function Loss: 0.03770

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.50683
Value Function Update Magnitude: 0.44361

Collected Steps per Second: 22,287.80728
Overall Steps per Second: 10,481.06263

Timestep Collection Time: 2.24401
Timestep Consumption Time: 2.52784
PPO Batch Consumption Time: 0.29595
Total Iteration Time: 4.77184

Cumulative Model Updates: 172,868
Cumulative Timesteps: 1,441,621,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,936.90585
Policy Entropy: 3.66766
Value Function Loss: 0.04825

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14358
Policy Update Magnitude: 0.57723
Value Function Update Magnitude: 0.50431

Collected Steps per Second: 22,709.09044
Overall Steps per Second: 10,603.12681

Timestep Collection Time: 2.20282
Timestep Consumption Time: 2.51504
PPO Batch Consumption Time: 0.29266
Total Iteration Time: 4.71785

Cumulative Model Updates: 172,874
Cumulative Timesteps: 1,441,671,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1441671628...
Checkpoint 1441671628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,936.90585
Policy Entropy: 3.68727
Value Function Loss: 0.03961

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.60678
Value Function Update Magnitude: 0.65348

Collected Steps per Second: 22,447.14963
Overall Steps per Second: 10,582.92504

Timestep Collection Time: 2.22754
Timestep Consumption Time: 2.49724
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.72478

Cumulative Model Updates: 172,880
Cumulative Timesteps: 1,441,721,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,576.51355
Policy Entropy: 3.64597
Value Function Loss: 0.04807

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.55608
Value Function Update Magnitude: 0.62379

Collected Steps per Second: 22,817.00323
Overall Steps per Second: 10,756.33847

Timestep Collection Time: 2.19144
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.64861

Cumulative Model Updates: 172,886
Cumulative Timesteps: 1,441,771,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1441771632...
Checkpoint 1441771632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,576.51355
Policy Entropy: 3.68535
Value Function Loss: 0.03786

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.53544
Value Function Update Magnitude: 0.50963

Collected Steps per Second: 22,182.44518
Overall Steps per Second: 10,672.37248

Timestep Collection Time: 2.25485
Timestep Consumption Time: 2.43183
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.68668

Cumulative Model Updates: 172,892
Cumulative Timesteps: 1,441,821,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,576.51355
Policy Entropy: 3.65878
Value Function Loss: 0.03643

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.46563
Value Function Update Magnitude: 0.56683

Collected Steps per Second: 22,179.57314
Overall Steps per Second: 10,829.14717

Timestep Collection Time: 2.25541
Timestep Consumption Time: 2.36398
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.61938

Cumulative Model Updates: 172,898
Cumulative Timesteps: 1,441,871,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1441871674...
Checkpoint 1441871674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,576.51355
Policy Entropy: 3.69096
Value Function Loss: 0.02673

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.37937
Value Function Update Magnitude: 0.43938

Collected Steps per Second: 21,673.87851
Overall Steps per Second: 10,750.18502

Timestep Collection Time: 2.30748
Timestep Consumption Time: 2.34472
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.65220

Cumulative Model Updates: 172,904
Cumulative Timesteps: 1,441,921,686

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 422,283.28050
Policy Entropy: 3.67812
Value Function Loss: 0.02700

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.37751
Value Function Update Magnitude: 0.37414

Collected Steps per Second: 22,289.66269
Overall Steps per Second: 10,731.30216

Timestep Collection Time: 2.24445
Timestep Consumption Time: 2.41743
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.66188

Cumulative Model Updates: 172,910
Cumulative Timesteps: 1,441,971,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1441971714...
Checkpoint 1441971714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277,068.05263
Policy Entropy: 3.69893
Value Function Loss: 0.02388

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.41794
Value Function Update Magnitude: 0.44469

Collected Steps per Second: 22,074.30494
Overall Steps per Second: 10,681.37484

Timestep Collection Time: 2.26562
Timestep Consumption Time: 2.41655
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.68217

Cumulative Model Updates: 172,916
Cumulative Timesteps: 1,442,021,726

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277,068.05263
Policy Entropy: 3.67595
Value Function Loss: 0.02807

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.49139
Value Function Update Magnitude: 0.60680

Collected Steps per Second: 22,766.82870
Overall Steps per Second: 10,752.59965

Timestep Collection Time: 2.19723
Timestep Consumption Time: 2.45504
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.65227

Cumulative Model Updates: 172,922
Cumulative Timesteps: 1,442,071,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1442071750...
Checkpoint 1442071750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373,127.31884
Policy Entropy: 3.68011
Value Function Loss: 0.02915

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.54004
Value Function Update Magnitude: 0.77472

Collected Steps per Second: 22,157.31972
Overall Steps per Second: 10,506.98910

Timestep Collection Time: 2.25840
Timestep Consumption Time: 2.50415
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.76254

Cumulative Model Updates: 172,928
Cumulative Timesteps: 1,442,121,790

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373,127.31884
Policy Entropy: 3.66962
Value Function Loss: 0.02685

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14690
Policy Update Magnitude: 0.52887
Value Function Update Magnitude: 0.74949

Collected Steps per Second: 22,971.98547
Overall Steps per Second: 10,851.01652

Timestep Collection Time: 2.17761
Timestep Consumption Time: 2.43247
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.61007

Cumulative Model Updates: 172,934
Cumulative Timesteps: 1,442,171,814

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1442171814...
Checkpoint 1442171814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373,127.31884
Policy Entropy: 3.65987
Value Function Loss: 0.03228

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.17933
Policy Update Magnitude: 0.50815
Value Function Update Magnitude: 0.65452

Collected Steps per Second: 21,956.13251
Overall Steps per Second: 10,595.23734

Timestep Collection Time: 2.27818
Timestep Consumption Time: 2.44281
PPO Batch Consumption Time: 0.27894
Total Iteration Time: 4.72099

Cumulative Model Updates: 172,940
Cumulative Timesteps: 1,442,221,834

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,760.50666
Policy Entropy: 3.64772
Value Function Loss: 0.04479

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.15812
Policy Update Magnitude: 0.58131
Value Function Update Magnitude: 0.61399

Collected Steps per Second: 22,600.40000
Overall Steps per Second: 10,612.95841

Timestep Collection Time: 2.21270
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.71198

Cumulative Model Updates: 172,946
Cumulative Timesteps: 1,442,271,842

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1442271842...
Checkpoint 1442271842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,125.98996
Policy Entropy: 3.64426
Value Function Loss: 0.06341

Mean KL Divergence: 0.01236
SB3 Clip Fraction: 0.15109
Policy Update Magnitude: 0.69209
Value Function Update Magnitude: 0.48742

Collected Steps per Second: 21,981.15434
Overall Steps per Second: 10,501.21913

Timestep Collection Time: 2.27613
Timestep Consumption Time: 2.48827
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.76440

Cumulative Model Updates: 172,952
Cumulative Timesteps: 1,442,321,874

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,513.13431
Policy Entropy: 3.66160
Value Function Loss: 0.06223

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.18294
Policy Update Magnitude: 0.66886
Value Function Update Magnitude: 0.43794

Collected Steps per Second: 22,452.95403
Overall Steps per Second: 10,574.14330

Timestep Collection Time: 2.22786
Timestep Consumption Time: 2.50274
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.73060

Cumulative Model Updates: 172,958
Cumulative Timesteps: 1,442,371,896

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1442371896...
Checkpoint 1442371896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,513.13431
Policy Entropy: 3.68195
Value Function Loss: 0.05682

Mean KL Divergence: 0.01716
SB3 Clip Fraction: 0.19946
Policy Update Magnitude: 0.71250
Value Function Update Magnitude: 0.44752

Collected Steps per Second: 21,447.21259
Overall Steps per Second: 10,511.80021

Timestep Collection Time: 2.33205
Timestep Consumption Time: 2.42603
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.75808

Cumulative Model Updates: 172,964
Cumulative Timesteps: 1,442,421,912

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,878.30541
Policy Entropy: 3.66600
Value Function Loss: 0.04876

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.18592
Policy Update Magnitude: 0.65751
Value Function Update Magnitude: 0.53836

Collected Steps per Second: 22,001.40942
Overall Steps per Second: 10,680.78721

Timestep Collection Time: 2.27313
Timestep Consumption Time: 2.40930
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.68243

Cumulative Model Updates: 172,970
Cumulative Timesteps: 1,442,471,924

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1442471924...
Checkpoint 1442471924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,878.30541
Policy Entropy: 3.67699
Value Function Loss: 0.04898

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15144
Policy Update Magnitude: 0.73842
Value Function Update Magnitude: 0.50245

Collected Steps per Second: 21,647.64643
Overall Steps per Second: 10,436.76795

Timestep Collection Time: 2.30981
Timestep Consumption Time: 2.48113
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.79095

Cumulative Model Updates: 172,976
Cumulative Timesteps: 1,442,521,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,878.30541
Policy Entropy: 3.71439
Value Function Loss: 0.03721

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.11578
Policy Update Magnitude: 0.69369
Value Function Update Magnitude: 0.39215

Collected Steps per Second: 22,684.92255
Overall Steps per Second: 10,818.22220

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.41840
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.62313

Cumulative Model Updates: 172,982
Cumulative Timesteps: 1,442,571,940

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1442571940...
Checkpoint 1442571940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 529,546.23136
Policy Entropy: 3.71132
Value Function Loss: 0.03037

Mean KL Divergence: 0.00796
SB3 Clip Fraction: 0.09901
Policy Update Magnitude: 0.62668
Value Function Update Magnitude: 0.42542

Collected Steps per Second: 21,959.35417
Overall Steps per Second: 10,659.84587

Timestep Collection Time: 2.27812
Timestep Consumption Time: 2.41482
PPO Batch Consumption Time: 0.27954
Total Iteration Time: 4.69294

Cumulative Model Updates: 172,988
Cumulative Timesteps: 1,442,621,966

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232,316.65875
Policy Entropy: 3.70765
Value Function Loss: 0.03125

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.64991
Value Function Update Magnitude: 0.68119

Collected Steps per Second: 22,942.26551
Overall Steps per Second: 10,720.99633

Timestep Collection Time: 2.18017
Timestep Consumption Time: 2.48526
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.66542

Cumulative Model Updates: 172,994
Cumulative Timesteps: 1,442,671,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1442671984...
Checkpoint 1442671984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,625.87138
Policy Entropy: 3.70297
Value Function Loss: 0.03196

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10523
Policy Update Magnitude: 0.64244
Value Function Update Magnitude: 0.77432

Collected Steps per Second: 22,581.70050
Overall Steps per Second: 10,621.15874

Timestep Collection Time: 2.21454
Timestep Consumption Time: 2.49380
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.70834

Cumulative Model Updates: 173,000
Cumulative Timesteps: 1,442,721,992

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,056.85755
Policy Entropy: 3.70882
Value Function Loss: 0.03064

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.49343
Value Function Update Magnitude: 0.68311

Collected Steps per Second: 22,705.48695
Overall Steps per Second: 10,732.19398

Timestep Collection Time: 2.20317
Timestep Consumption Time: 2.45795
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.66112

Cumulative Model Updates: 173,006
Cumulative Timesteps: 1,442,772,016

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1442772016...
Checkpoint 1442772016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,056.85755
Policy Entropy: 3.70606
Value Function Loss: 0.02445

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14360
Policy Update Magnitude: 0.41258
Value Function Update Magnitude: 0.58985

Collected Steps per Second: 22,259.27601
Overall Steps per Second: 10,617.98837

Timestep Collection Time: 2.24670
Timestep Consumption Time: 2.46323
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.70993

Cumulative Model Updates: 173,012
Cumulative Timesteps: 1,442,822,026

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,056.85755
Policy Entropy: 3.68420
Value Function Loss: 0.02506

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.40319
Value Function Update Magnitude: 0.55677

Collected Steps per Second: 23,009.88084
Overall Steps per Second: 10,862.59795

Timestep Collection Time: 2.17376
Timestep Consumption Time: 2.43085
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.60461

Cumulative Model Updates: 173,018
Cumulative Timesteps: 1,442,872,044

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1442872044...
Checkpoint 1442872044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,056.85755
Policy Entropy: 3.68283
Value Function Loss: 0.02270

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.39796
Value Function Update Magnitude: 0.53201

Collected Steps per Second: 22,254.04225
Overall Steps per Second: 10,710.43134

Timestep Collection Time: 2.24687
Timestep Consumption Time: 2.42166
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.66853

Cumulative Model Updates: 173,024
Cumulative Timesteps: 1,442,922,046

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,056.85755
Policy Entropy: 3.67430
Value Function Loss: 0.02496

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.36426
Value Function Update Magnitude: 0.43863

Collected Steps per Second: 21,940.20270
Overall Steps per Second: 10,584.63841

Timestep Collection Time: 2.27938
Timestep Consumption Time: 2.44539
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.72477

Cumulative Model Updates: 173,030
Cumulative Timesteps: 1,442,972,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1442972056...
Checkpoint 1442972056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207,413.88377
Policy Entropy: 3.68372
Value Function Loss: 0.02757

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.37577
Value Function Update Magnitude: 0.39653

Collected Steps per Second: 21,276.44639
Overall Steps per Second: 10,527.88839

Timestep Collection Time: 2.35058
Timestep Consumption Time: 2.39985
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.75043

Cumulative Model Updates: 173,036
Cumulative Timesteps: 1,443,022,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,092.41574
Policy Entropy: 3.67850
Value Function Loss: 0.02971

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.43176
Value Function Update Magnitude: 0.49337

Collected Steps per Second: 22,024.64452
Overall Steps per Second: 10,517.31607

Timestep Collection Time: 2.27018
Timestep Consumption Time: 2.48388
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.75406

Cumulative Model Updates: 173,042
Cumulative Timesteps: 1,443,072,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1443072068...
Checkpoint 1443072068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 136,092.41574
Policy Entropy: 3.69203
Value Function Loss: 0.02640

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.46600
Value Function Update Magnitude: 0.55830

Collected Steps per Second: 22,481.34736
Overall Steps per Second: 10,623.09497

Timestep Collection Time: 2.22451
Timestep Consumption Time: 2.48316
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 4.70767

Cumulative Model Updates: 173,048
Cumulative Timesteps: 1,443,122,078

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,009,481.78691
Policy Entropy: 3.68286
Value Function Loss: 0.02661

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.49236
Value Function Update Magnitude: 0.61484

Collected Steps per Second: 22,650.70080
Overall Steps per Second: 10,801.63854

Timestep Collection Time: 2.20814
Timestep Consumption Time: 2.42226
PPO Batch Consumption Time: 0.28016
Total Iteration Time: 4.63041

Cumulative Model Updates: 173,054
Cumulative Timesteps: 1,443,172,094

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1443172094...
Checkpoint 1443172094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 938,354.35396
Policy Entropy: 3.67337
Value Function Loss: 0.03573

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.53875
Value Function Update Magnitude: 0.55252

Collected Steps per Second: 22,426.14947
Overall Steps per Second: 10,730.14193

Timestep Collection Time: 2.23061
Timestep Consumption Time: 2.43140
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.66201

Cumulative Model Updates: 173,060
Cumulative Timesteps: 1,443,222,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 862,593.46606
Policy Entropy: 3.65356
Value Function Loss: 0.04442

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.59347
Value Function Update Magnitude: 0.58396

Collected Steps per Second: 22,520.48383
Overall Steps per Second: 10,633.89795

Timestep Collection Time: 2.22056
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.70270

Cumulative Model Updates: 173,066
Cumulative Timesteps: 1,443,272,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1443272126...
Checkpoint 1443272126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 925,861.47041
Policy Entropy: 3.65326
Value Function Loss: 0.04388

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14244
Policy Update Magnitude: 0.58912
Value Function Update Magnitude: 0.62324

Collected Steps per Second: 22,177.09479
Overall Steps per Second: 10,527.09603

Timestep Collection Time: 2.25485
Timestep Consumption Time: 2.49537
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.75022

Cumulative Model Updates: 173,072
Cumulative Timesteps: 1,443,322,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322,845.90014
Policy Entropy: 3.65173
Value Function Loss: 0.04205

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.54243
Value Function Update Magnitude: 0.52149

Collected Steps per Second: 22,877.37657
Overall Steps per Second: 10,847.63744

Timestep Collection Time: 2.18679
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.61188

Cumulative Model Updates: 173,078
Cumulative Timesteps: 1,443,372,160

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1443372160...
Checkpoint 1443372160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261,508.49623
Policy Entropy: 3.66296
Value Function Loss: 0.03928

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.50583
Value Function Update Magnitude: 0.42857

Collected Steps per Second: 22,390.03704
Overall Steps per Second: 10,551.37475

Timestep Collection Time: 2.23314
Timestep Consumption Time: 2.50558
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.73872

Cumulative Model Updates: 173,084
Cumulative Timesteps: 1,443,422,160

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261,508.49623
Policy Entropy: 3.66394
Value Function Loss: 0.03553

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.49303
Value Function Update Magnitude: 0.40617

Collected Steps per Second: 22,312.55520
Overall Steps per Second: 10,545.81931

Timestep Collection Time: 2.24161
Timestep Consumption Time: 2.50112
PPO Batch Consumption Time: 0.29354
Total Iteration Time: 4.74273

Cumulative Model Updates: 173,090
Cumulative Timesteps: 1,443,472,176

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1443472176...
Checkpoint 1443472176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 261,508.49623
Policy Entropy: 3.65842
Value Function Loss: 0.03343

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.46385
Value Function Update Magnitude: 0.37941

Collected Steps per Second: 21,430.79325
Overall Steps per Second: 10,586.00878

Timestep Collection Time: 2.33496
Timestep Consumption Time: 2.39204
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.72699

Cumulative Model Updates: 173,096
Cumulative Timesteps: 1,443,522,216

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 261,508.49623
Policy Entropy: 3.66874
Value Function Loss: 0.02792

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.43913
Value Function Update Magnitude: 0.34668

Collected Steps per Second: 21,836.73609
Overall Steps per Second: 10,637.99206

Timestep Collection Time: 2.29118
Timestep Consumption Time: 2.41196
PPO Batch Consumption Time: 0.28787
Total Iteration Time: 4.70314

Cumulative Model Updates: 173,102
Cumulative Timesteps: 1,443,572,248

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1443572248...
Checkpoint 1443572248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,364.92322
Policy Entropy: 3.65290
Value Function Loss: 0.03107

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13209
Policy Update Magnitude: 0.43366
Value Function Update Magnitude: 0.37894

Collected Steps per Second: 21,487.06337
Overall Steps per Second: 10,253.58142

Timestep Collection Time: 2.32810
Timestep Consumption Time: 2.55059
PPO Batch Consumption Time: 0.30234
Total Iteration Time: 4.87869

Cumulative Model Updates: 173,108
Cumulative Timesteps: 1,443,622,272

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,364.92322
Policy Entropy: 3.65435
Value Function Loss: 0.02993

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13122
Policy Update Magnitude: 0.42026
Value Function Update Magnitude: 0.34052

Collected Steps per Second: 22,193.86812
Overall Steps per Second: 10,653.47405

Timestep Collection Time: 2.25396
Timestep Consumption Time: 2.44160
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.69556

Cumulative Model Updates: 173,114
Cumulative Timesteps: 1,443,672,296

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1443672296...
Checkpoint 1443672296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,364.92322
Policy Entropy: 3.64988
Value Function Loss: 0.03017

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.39860
Value Function Update Magnitude: 0.30234

Collected Steps per Second: 22,229.90334
Overall Steps per Second: 10,638.67445

Timestep Collection Time: 2.24967
Timestep Consumption Time: 2.45110
PPO Batch Consumption Time: 0.28492
Total Iteration Time: 4.70077

Cumulative Model Updates: 173,120
Cumulative Timesteps: 1,443,722,306

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 468,364.92322
Policy Entropy: 3.65135
Value Function Loss: 0.03075

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.40281
Value Function Update Magnitude: 0.30964

Collected Steps per Second: 22,487.45479
Overall Steps per Second: 10,563.43621

Timestep Collection Time: 2.22382
Timestep Consumption Time: 2.51025
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.73407

Cumulative Model Updates: 173,126
Cumulative Timesteps: 1,443,772,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1443772314...
Checkpoint 1443772314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 468,364.92322
Policy Entropy: 3.65580
Value Function Loss: 0.03284

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13625
Policy Update Magnitude: 0.43630
Value Function Update Magnitude: 0.33768

Collected Steps per Second: 22,449.78663
Overall Steps per Second: 10,530.64684

Timestep Collection Time: 2.22835
Timestep Consumption Time: 2.52216
PPO Batch Consumption Time: 0.29418
Total Iteration Time: 4.75052

Cumulative Model Updates: 173,132
Cumulative Timesteps: 1,443,822,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,377.82325
Policy Entropy: 3.65036
Value Function Loss: 0.04089

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.49029
Value Function Update Magnitude: 0.34724

Collected Steps per Second: 22,547.56771
Overall Steps per Second: 10,604.66701

Timestep Collection Time: 2.21833
Timestep Consumption Time: 2.49827
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.71660

Cumulative Model Updates: 173,138
Cumulative Timesteps: 1,443,872,358

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1443872358...
Checkpoint 1443872358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,061.62546
Policy Entropy: 3.67264
Value Function Loss: 0.04066

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.53092
Value Function Update Magnitude: 0.44391

Collected Steps per Second: 22,398.96878
Overall Steps per Second: 10,564.27915

Timestep Collection Time: 2.23332
Timestep Consumption Time: 2.50189
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.73520

Cumulative Model Updates: 173,144
Cumulative Timesteps: 1,443,922,382

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,947.97206
Policy Entropy: 3.67252
Value Function Loss: 0.04013

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.52977
Value Function Update Magnitude: 0.57020

Collected Steps per Second: 22,611.15838
Overall Steps per Second: 10,749.74276

Timestep Collection Time: 2.21183
Timestep Consumption Time: 2.44056
PPO Batch Consumption Time: 0.27928
Total Iteration Time: 4.65239

Cumulative Model Updates: 173,150
Cumulative Timesteps: 1,443,972,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1443972394...
Checkpoint 1443972394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,348.21254
Policy Entropy: 3.68155
Value Function Loss: 0.03253

Mean KL Divergence: 0.00750
SB3 Clip Fraction: 0.09638
Policy Update Magnitude: 0.59319
Value Function Update Magnitude: 0.70546

Collected Steps per Second: 21,991.50234
Overall Steps per Second: 10,628.78086

Timestep Collection Time: 2.27470
Timestep Consumption Time: 2.43177
PPO Batch Consumption Time: 0.27893
Total Iteration Time: 4.70647

Cumulative Model Updates: 173,156
Cumulative Timesteps: 1,444,022,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,907.39781
Policy Entropy: 3.68923
Value Function Loss: 0.02887

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09333
Policy Update Magnitude: 0.69417
Value Function Update Magnitude: 0.77660

Collected Steps per Second: 22,735.37937
Overall Steps per Second: 10,657.51565

Timestep Collection Time: 2.19966
Timestep Consumption Time: 2.49281
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.69246

Cumulative Model Updates: 173,162
Cumulative Timesteps: 1,444,072,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1444072428...
Checkpoint 1444072428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,907.39781
Policy Entropy: 3.69981
Value Function Loss: 0.02409

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08848
Policy Update Magnitude: 0.67911
Value Function Update Magnitude: 0.76984

Collected Steps per Second: 21,575.83213
Overall Steps per Second: 10,527.66301

Timestep Collection Time: 2.31796
Timestep Consumption Time: 2.43257
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.75053

Cumulative Model Updates: 173,168
Cumulative Timesteps: 1,444,122,440

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,907.39781
Policy Entropy: 3.69189
Value Function Loss: 0.02744

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13922
Policy Update Magnitude: 0.56723
Value Function Update Magnitude: 0.73077

Collected Steps per Second: 21,629.19996
Overall Steps per Second: 10,573.31028

Timestep Collection Time: 2.31271
Timestep Consumption Time: 2.41826
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.73097

Cumulative Model Updates: 173,174
Cumulative Timesteps: 1,444,172,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1444172462...
Checkpoint 1444172462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 542,272.44898
Policy Entropy: 3.68033
Value Function Loss: 0.03200

Mean KL Divergence: 0.01422
SB3 Clip Fraction: 0.18035
Policy Update Magnitude: 0.47448
Value Function Update Magnitude: 0.69565

Collected Steps per Second: 21,483.63984
Overall Steps per Second: 10,513.15711

Timestep Collection Time: 2.32838
Timestep Consumption Time: 2.42966
PPO Batch Consumption Time: 0.29205
Total Iteration Time: 4.75804

Cumulative Model Updates: 173,180
Cumulative Timesteps: 1,444,222,484

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189,087.17887
Policy Entropy: 3.68934
Value Function Loss: 0.03347

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.50749
Value Function Update Magnitude: 0.78571

Collected Steps per Second: 22,038.86474
Overall Steps per Second: 10,346.17730

Timestep Collection Time: 2.26872
Timestep Consumption Time: 2.56398
PPO Batch Consumption Time: 0.30397
Total Iteration Time: 4.83270

Cumulative Model Updates: 173,186
Cumulative Timesteps: 1,444,272,484

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1444272484...
Checkpoint 1444272484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,616.97067
Policy Entropy: 3.69330
Value Function Loss: 0.04114

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.16326
Policy Update Magnitude: 0.57803
Value Function Update Magnitude: 0.82588

Collected Steps per Second: 21,508.90432
Overall Steps per Second: 10,270.95262

Timestep Collection Time: 2.32611
Timestep Consumption Time: 2.54511
PPO Batch Consumption Time: 0.29934
Total Iteration Time: 4.87121

Cumulative Model Updates: 173,192
Cumulative Timesteps: 1,444,322,516

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,396.02555
Policy Entropy: 3.70814
Value Function Loss: 0.03992

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.61693
Value Function Update Magnitude: 0.96156

Collected Steps per Second: 22,875.96274
Overall Steps per Second: 10,892.71898

Timestep Collection Time: 2.18614
Timestep Consumption Time: 2.40500
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.59114

Cumulative Model Updates: 173,198
Cumulative Timesteps: 1,444,372,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1444372526...
Checkpoint 1444372526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284,600.35393
Policy Entropy: 3.66092
Value Function Loss: 0.04937

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13674
Policy Update Magnitude: 0.63236
Value Function Update Magnitude: 0.87952

Collected Steps per Second: 22,112.98158
Overall Steps per Second: 10,645.12633

Timestep Collection Time: 2.26121
Timestep Consumption Time: 2.43597
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.69717

Cumulative Model Updates: 173,204
Cumulative Timesteps: 1,444,422,528

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,240.96592
Policy Entropy: 3.68256
Value Function Loss: 0.04278

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14736
Policy Update Magnitude: 0.57652
Value Function Update Magnitude: 0.69443

Collected Steps per Second: 22,739.33567
Overall Steps per Second: 10,641.73079

Timestep Collection Time: 2.19945
Timestep Consumption Time: 2.50035
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.69980

Cumulative Model Updates: 173,210
Cumulative Timesteps: 1,444,472,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1444472542...
Checkpoint 1444472542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,240.96592
Policy Entropy: 3.65128
Value Function Loss: 0.04006

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.52123
Value Function Update Magnitude: 0.58641

Collected Steps per Second: 22,419.95753
Overall Steps per Second: 10,529.86301

Timestep Collection Time: 2.23051
Timestep Consumption Time: 2.51865
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.74916

Cumulative Model Updates: 173,216
Cumulative Timesteps: 1,444,522,550

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,240.96592
Policy Entropy: 3.67091
Value Function Loss: 0.03139

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.50936
Value Function Update Magnitude: 0.57437

Collected Steps per Second: 22,879.85787
Overall Steps per Second: 10,829.12283

Timestep Collection Time: 2.18559
Timestep Consumption Time: 2.43214
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.61773

Cumulative Model Updates: 173,222
Cumulative Timesteps: 1,444,572,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1444572556...
Checkpoint 1444572556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,240.96592
Policy Entropy: 3.66316
Value Function Loss: 0.03287

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.47685
Value Function Update Magnitude: 0.61794

Collected Steps per Second: 22,310.04189
Overall Steps per Second: 10,653.32243

Timestep Collection Time: 2.24240
Timestep Consumption Time: 2.45360
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.69600

Cumulative Model Updates: 173,228
Cumulative Timesteps: 1,444,622,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,680.60580
Policy Entropy: 3.67448
Value Function Loss: 0.03259

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13101
Policy Update Magnitude: 0.43851
Value Function Update Magnitude: 0.51800

Collected Steps per Second: 22,959.79823
Overall Steps per Second: 10,712.40881

Timestep Collection Time: 2.17885
Timestep Consumption Time: 2.49106
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.66991

Cumulative Model Updates: 173,234
Cumulative Timesteps: 1,444,672,610

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1444672610...
Checkpoint 1444672610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,680.60580
Policy Entropy: 3.65986
Value Function Loss: 0.03403

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.40956
Value Function Update Magnitude: 0.44299

Collected Steps per Second: 22,644.83916
Overall Steps per Second: 10,656.48353

Timestep Collection Time: 2.20880
Timestep Consumption Time: 2.48486
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.69367

Cumulative Model Updates: 173,240
Cumulative Timesteps: 1,444,722,628

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 505,628.24037
Policy Entropy: 3.65602
Value Function Loss: 0.03750

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.41223
Value Function Update Magnitude: 0.55578

Collected Steps per Second: 22,914.99916
Overall Steps per Second: 10,677.34549

Timestep Collection Time: 2.18302
Timestep Consumption Time: 2.50204
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.68506

Cumulative Model Updates: 173,246
Cumulative Timesteps: 1,444,772,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1444772652...
Checkpoint 1444772652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 761,506.16842
Policy Entropy: 3.67720
Value Function Loss: 0.04210

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14044
Policy Update Magnitude: 0.43330
Value Function Update Magnitude: 0.60698

Collected Steps per Second: 22,426.64094
Overall Steps per Second: 10,694.66473

Timestep Collection Time: 2.22976
Timestep Consumption Time: 2.44603
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.67579

Cumulative Model Updates: 173,252
Cumulative Timesteps: 1,444,822,658

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,213.56551
Policy Entropy: 3.70334
Value Function Loss: 0.04442

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13891
Policy Update Magnitude: 0.44513
Value Function Update Magnitude: 0.68626

Collected Steps per Second: 22,949.37111
Overall Steps per Second: 10,819.15121

Timestep Collection Time: 2.18080
Timestep Consumption Time: 2.44507
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.62587

Cumulative Model Updates: 173,258
Cumulative Timesteps: 1,444,872,706

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1444872706...
Checkpoint 1444872706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,403.20749
Policy Entropy: 3.71138
Value Function Loss: 0.04493

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.47946
Value Function Update Magnitude: 0.69042

Collected Steps per Second: 22,150.78222
Overall Steps per Second: 10,668.64539

Timestep Collection Time: 2.25753
Timestep Consumption Time: 2.42967
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.68719

Cumulative Model Updates: 173,264
Cumulative Timesteps: 1,444,922,712

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,164.52378
Policy Entropy: 3.70099
Value Function Loss: 0.03821

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.47269
Value Function Update Magnitude: 0.65258

Collected Steps per Second: 22,593.19807
Overall Steps per Second: 10,540.51799

Timestep Collection Time: 2.21368
Timestep Consumption Time: 2.53125
PPO Batch Consumption Time: 0.29730
Total Iteration Time: 4.74493

Cumulative Model Updates: 173,270
Cumulative Timesteps: 1,444,972,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1444972726...
Checkpoint 1444972726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294,036.76911
Policy Entropy: 3.67363
Value Function Loss: 0.04125

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13403
Policy Update Magnitude: 0.47384
Value Function Update Magnitude: 0.58718

Collected Steps per Second: 22,330.56912
Overall Steps per Second: 10,578.82803

Timestep Collection Time: 2.24007
Timestep Consumption Time: 2.48843
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.72850

Cumulative Model Updates: 173,276
Cumulative Timesteps: 1,445,022,748

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,540.50461
Policy Entropy: 3.68885
Value Function Loss: 0.03905

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.51468
Value Function Update Magnitude: 0.56718

Collected Steps per Second: 22,610.14092
Overall Steps per Second: 10,570.37975

Timestep Collection Time: 2.21219
Timestep Consumption Time: 2.51971
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.73190

Cumulative Model Updates: 173,282
Cumulative Timesteps: 1,445,072,766

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1445072766...
Checkpoint 1445072766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781,359.89659
Policy Entropy: 3.67270
Value Function Loss: 0.04734

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.56370
Value Function Update Magnitude: 0.70697

Collected Steps per Second: 22,428.83910
Overall Steps per Second: 10,505.07181

Timestep Collection Time: 2.22945
Timestep Consumption Time: 2.53054
PPO Batch Consumption Time: 0.29396
Total Iteration Time: 4.75999

Cumulative Model Updates: 173,288
Cumulative Timesteps: 1,445,122,770

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627,556.81225
Policy Entropy: 3.66497
Value Function Loss: 0.05415

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.18767
Policy Update Magnitude: 0.64991
Value Function Update Magnitude: 0.66272

Collected Steps per Second: 22,482.39744
Overall Steps per Second: 10,558.29993

Timestep Collection Time: 2.22441
Timestep Consumption Time: 2.51215
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.73656

Cumulative Model Updates: 173,294
Cumulative Timesteps: 1,445,172,780

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1445172780...
Checkpoint 1445172780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 530,800.83247
Policy Entropy: 3.62049
Value Function Loss: 0.10157

Mean KL Divergence: 0.01683
SB3 Clip Fraction: 0.19434
Policy Update Magnitude: 0.71825
Value Function Update Magnitude: 0.64041

Collected Steps per Second: 22,130.37696
Overall Steps per Second: 10,505.86423

Timestep Collection Time: 2.25943
Timestep Consumption Time: 2.50001
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.75944

Cumulative Model Updates: 173,300
Cumulative Timesteps: 1,445,222,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,929.51249
Policy Entropy: 3.64003
Value Function Loss: 0.10615

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.17473
Policy Update Magnitude: 0.81936
Value Function Update Magnitude: 0.57322

Collected Steps per Second: 22,460.72920
Overall Steps per Second: 10,641.46291

Timestep Collection Time: 2.22691
Timestep Consumption Time: 2.47338
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.70029

Cumulative Model Updates: 173,306
Cumulative Timesteps: 1,445,272,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1445272800...
Checkpoint 1445272800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 792,995.87582
Policy Entropy: 3.64874
Value Function Loss: 0.11233

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.16745
Policy Update Magnitude: 0.99528
Value Function Update Magnitude: 0.62050

Collected Steps per Second: 22,271.63953
Overall Steps per Second: 10,495.00246

Timestep Collection Time: 2.24501
Timestep Consumption Time: 2.51916
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.76417

Cumulative Model Updates: 173,312
Cumulative Timesteps: 1,445,322,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,932.65131
Policy Entropy: 3.67183
Value Function Loss: 0.09804

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.16147
Policy Update Magnitude: 0.87918
Value Function Update Magnitude: 0.53944

Collected Steps per Second: 22,493.68630
Overall Steps per Second: 10,580.44726

Timestep Collection Time: 2.22302
Timestep Consumption Time: 2.50305
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.72608

Cumulative Model Updates: 173,318
Cumulative Timesteps: 1,445,372,804

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1445372804...
Checkpoint 1445372804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,534.39390
Policy Entropy: 3.67610
Value Function Loss: 0.08020

Mean KL Divergence: 0.01298
SB3 Clip Fraction: 0.16479
Policy Update Magnitude: 0.82963
Value Function Update Magnitude: 0.52813

Collected Steps per Second: 22,489.64578
Overall Steps per Second: 10,594.47349

Timestep Collection Time: 2.22405
Timestep Consumption Time: 2.49710
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.72114

Cumulative Model Updates: 173,324
Cumulative Timesteps: 1,445,422,822

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,534.39390
Policy Entropy: 3.68105
Value Function Loss: 0.06178

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.17697
Policy Update Magnitude: 0.85215
Value Function Update Magnitude: 0.53264

Collected Steps per Second: 22,726.79158
Overall Steps per Second: 10,760.07870

Timestep Collection Time: 2.20119
Timestep Consumption Time: 2.44803
PPO Batch Consumption Time: 0.27935
Total Iteration Time: 4.64922

Cumulative Model Updates: 173,330
Cumulative Timesteps: 1,445,472,848

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1445472848...
Checkpoint 1445472848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,534.39390
Policy Entropy: 3.69950
Value Function Loss: 0.04549

Mean KL Divergence: 0.01875
SB3 Clip Fraction: 0.22198
Policy Update Magnitude: 0.74451
Value Function Update Magnitude: 0.53987

Collected Steps per Second: 22,315.06829
Overall Steps per Second: 10,670.52254

Timestep Collection Time: 2.24082
Timestep Consumption Time: 2.44536
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.68618

Cumulative Model Updates: 173,336
Cumulative Timesteps: 1,445,522,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,534.39390
Policy Entropy: 3.69932
Value Function Loss: 0.03916

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.18962
Policy Update Magnitude: 0.65643
Value Function Update Magnitude: 0.63909

Collected Steps per Second: 22,952.13268
Overall Steps per Second: 10,823.49478

Timestep Collection Time: 2.17845
Timestep Consumption Time: 2.44113
PPO Batch Consumption Time: 0.27910
Total Iteration Time: 4.61958

Cumulative Model Updates: 173,342
Cumulative Timesteps: 1,445,572,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1445572852...
Checkpoint 1445572852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,972.37551
Policy Entropy: 3.70809
Value Function Loss: 0.04821

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.19319
Policy Update Magnitude: 0.58978
Value Function Update Magnitude: 0.55062

Collected Steps per Second: 21,275.87619
Overall Steps per Second: 10,668.76592

Timestep Collection Time: 2.35074
Timestep Consumption Time: 2.33715
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.68789

Cumulative Model Updates: 173,348
Cumulative Timesteps: 1,445,622,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,186.41957
Policy Entropy: 3.71649
Value Function Loss: 0.04493

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11235
Policy Update Magnitude: 0.64933
Value Function Update Magnitude: 0.45558

Collected Steps per Second: 21,787.25160
Overall Steps per Second: 10,601.91697

Timestep Collection Time: 2.29565
Timestep Consumption Time: 2.42198
PPO Batch Consumption Time: 0.29319
Total Iteration Time: 4.71764

Cumulative Model Updates: 173,354
Cumulative Timesteps: 1,445,672,882

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1445672882...
Checkpoint 1445672882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,415.51559
Policy Entropy: 3.70319
Value Function Loss: 0.03675

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.23689
Policy Update Magnitude: 0.59235
Value Function Update Magnitude: 0.53854

Collected Steps per Second: 21,673.78376
Overall Steps per Second: 10,635.31580

Timestep Collection Time: 2.30703
Timestep Consumption Time: 2.39448
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.70151

Cumulative Model Updates: 173,360
Cumulative Timesteps: 1,445,722,884

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 442,668.29896
Policy Entropy: 3.65483
Value Function Loss: 0.04834

Mean KL Divergence: 0.02491
SB3 Clip Fraction: 0.26075
Policy Update Magnitude: 0.44949
Value Function Update Magnitude: 0.50551

Collected Steps per Second: 23,402.49669
Overall Steps per Second: 10,848.47158

Timestep Collection Time: 2.13670
Timestep Consumption Time: 2.47262
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.60931

Cumulative Model Updates: 173,366
Cumulative Timesteps: 1,445,772,888

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1445772888...
Checkpoint 1445772888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330,944.99738
Policy Entropy: 3.62408
Value Function Loss: 0.06213

Mean KL Divergence: 0.01668
SB3 Clip Fraction: 0.20547
Policy Update Magnitude: 0.55312
Value Function Update Magnitude: 0.51530

Collected Steps per Second: 21,960.75084
Overall Steps per Second: 10,584.15052

Timestep Collection Time: 2.27770
Timestep Consumption Time: 2.44823
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.72593

Cumulative Model Updates: 173,372
Cumulative Timesteps: 1,445,822,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,606.39910
Policy Entropy: 3.64044
Value Function Loss: 0.06404

Mean KL Divergence: 0.02073
SB3 Clip Fraction: 0.25015
Policy Update Magnitude: 0.60693
Value Function Update Magnitude: 0.57719

Collected Steps per Second: 22,648.43136
Overall Steps per Second: 10,615.99937

Timestep Collection Time: 2.20889
Timestep Consumption Time: 2.50362
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.71251

Cumulative Model Updates: 173,378
Cumulative Timesteps: 1,445,872,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1445872936...
Checkpoint 1445872936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,637.97616
Policy Entropy: 3.67802
Value Function Loss: 0.05569

Mean KL Divergence: 0.01747
SB3 Clip Fraction: 0.21563
Policy Update Magnitude: 0.56600
Value Function Update Magnitude: 0.49541

Collected Steps per Second: 22,291.43328
Overall Steps per Second: 10,549.98356

Timestep Collection Time: 2.24328
Timestep Consumption Time: 2.49663
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.73991

Cumulative Model Updates: 173,384
Cumulative Timesteps: 1,445,922,942

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,979.07553
Policy Entropy: 3.70355
Value Function Loss: 0.04137

Mean KL Divergence: 0.02066
SB3 Clip Fraction: 0.23301
Policy Update Magnitude: 0.56266
Value Function Update Magnitude: 0.51224

Collected Steps per Second: 22,817.98303
Overall Steps per Second: 10,806.77529

Timestep Collection Time: 2.19152
Timestep Consumption Time: 2.43577
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.62728

Cumulative Model Updates: 173,390
Cumulative Timesteps: 1,445,972,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1445972948...
Checkpoint 1445972948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,979.07553
Policy Entropy: 3.67950
Value Function Loss: 0.03981

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.21497
Policy Update Magnitude: 0.53256
Value Function Update Magnitude: 0.45859

Collected Steps per Second: 22,067.18392
Overall Steps per Second: 10,623.92870

Timestep Collection Time: 2.26717
Timestep Consumption Time: 2.44201
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.70918

Cumulative Model Updates: 173,396
Cumulative Timesteps: 1,446,022,978

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,689.57401
Policy Entropy: 3.68731
Value Function Loss: 0.03702

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.13832
Policy Update Magnitude: 0.55176
Value Function Update Magnitude: 0.40225

Collected Steps per Second: 22,466.20088
Overall Steps per Second: 10,553.47740

Timestep Collection Time: 2.22663
Timestep Consumption Time: 2.51342
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.74005

Cumulative Model Updates: 173,402
Cumulative Timesteps: 1,446,073,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1446073002...
Checkpoint 1446073002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 245,103.95628
Policy Entropy: 3.68677
Value Function Loss: 0.03648

Mean KL Divergence: 0.00784
SB3 Clip Fraction: 0.09974
Policy Update Magnitude: 0.61098
Value Function Update Magnitude: 0.43144

Collected Steps per Second: 22,246.50851
Overall Steps per Second: 10,709.71101

Timestep Collection Time: 2.24763
Timestep Consumption Time: 2.42121
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.66885

Cumulative Model Updates: 173,408
Cumulative Timesteps: 1,446,123,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 270,586.98082
Policy Entropy: 3.68709
Value Function Loss: 0.04222

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13410
Policy Update Magnitude: 0.67742
Value Function Update Magnitude: 0.55827

Collected Steps per Second: 22,727.57638
Overall Steps per Second: 10,784.20365

Timestep Collection Time: 2.20050
Timestep Consumption Time: 2.43703
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.63752

Cumulative Model Updates: 173,414
Cumulative Timesteps: 1,446,173,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1446173016...
Checkpoint 1446173016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 94,374.66016
Policy Entropy: 3.68965
Value Function Loss: 0.04810

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.17637
Policy Update Magnitude: 0.59632
Value Function Update Magnitude: 0.56235

Collected Steps per Second: 21,357.26440
Overall Steps per Second: 10,631.60042

Timestep Collection Time: 2.34112
Timestep Consumption Time: 2.36184
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.70296

Cumulative Model Updates: 173,420
Cumulative Timesteps: 1,446,223,016

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,578.50748
Policy Entropy: 3.67297
Value Function Loss: 0.06119

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10503
Policy Update Magnitude: 0.71510
Value Function Update Magnitude: 0.47639

Collected Steps per Second: 21,932.30521
Overall Steps per Second: 10,494.93271

Timestep Collection Time: 2.27992
Timestep Consumption Time: 2.48466
PPO Batch Consumption Time: 0.29913
Total Iteration Time: 4.76459

Cumulative Model Updates: 173,426
Cumulative Timesteps: 1,446,273,020

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1446273020...
Checkpoint 1446273020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,302.74348
Policy Entropy: 3.69751
Value Function Loss: 0.05589

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09709
Policy Update Magnitude: 0.91203
Value Function Update Magnitude: 0.44923

Collected Steps per Second: 21,487.63718
Overall Steps per Second: 10,707.72890

Timestep Collection Time: 2.32776
Timestep Consumption Time: 2.34345
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.67121

Cumulative Model Updates: 173,432
Cumulative Timesteps: 1,446,323,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251,859.81800
Policy Entropy: 3.69069
Value Function Loss: 0.04850

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.17080
Policy Update Magnitude: 0.76266
Value Function Update Magnitude: 0.51343

Collected Steps per Second: 22,385.65929
Overall Steps per Second: 10,749.96074

Timestep Collection Time: 2.23438
Timestep Consumption Time: 2.41848
PPO Batch Consumption Time: 0.27903
Total Iteration Time: 4.65285

Cumulative Model Updates: 173,438
Cumulative Timesteps: 1,446,373,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1446373056...
Checkpoint 1446373056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,957.81222
Policy Entropy: 3.66719
Value Function Loss: 0.06226

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.18411
Policy Update Magnitude: 0.69384
Value Function Update Magnitude: 0.59185

Collected Steps per Second: 21,822.22851
Overall Steps per Second: 10,638.18542

Timestep Collection Time: 2.29197
Timestep Consumption Time: 2.40958
PPO Batch Consumption Time: 0.27905
Total Iteration Time: 4.70155

Cumulative Model Updates: 173,444
Cumulative Timesteps: 1,446,423,072

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,648.26481
Policy Entropy: 3.66327
Value Function Loss: 0.09100

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.76625
Value Function Update Magnitude: 0.51032

Collected Steps per Second: 21,968.55097
Overall Steps per Second: 10,559.08170

Timestep Collection Time: 2.27716
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.28577
Total Iteration Time: 4.73772

Cumulative Model Updates: 173,450
Cumulative Timesteps: 1,446,473,098

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1446473098...
Checkpoint 1446473098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,792.13936
Policy Entropy: 3.69252
Value Function Loss: 0.10340

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.18354
Policy Update Magnitude: 0.99412
Value Function Update Magnitude: 0.43563

Collected Steps per Second: 21,525.73178
Overall Steps per Second: 10,565.48452

Timestep Collection Time: 2.32354
Timestep Consumption Time: 2.41036
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.73391

Cumulative Model Updates: 173,456
Cumulative Timesteps: 1,446,523,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,166.20100
Policy Entropy: 3.71112
Value Function Loss: 0.09940

Mean KL Divergence: 0.01601
SB3 Clip Fraction: 0.17756
Policy Update Magnitude: 0.87695
Value Function Update Magnitude: 0.53156

Collected Steps per Second: 22,321.95153
Overall Steps per Second: 10,520.30567

Timestep Collection Time: 2.24084
Timestep Consumption Time: 2.51377
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.75461

Cumulative Model Updates: 173,462
Cumulative Timesteps: 1,446,573,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1446573134...
Checkpoint 1446573134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,629.33181
Policy Entropy: 3.70868
Value Function Loss: 0.10372

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.16406
Policy Update Magnitude: 0.80998
Value Function Update Magnitude: 0.49771

Collected Steps per Second: 21,902.90448
Overall Steps per Second: 10,568.05236

Timestep Collection Time: 2.28381
Timestep Consumption Time: 2.44952
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.73332

Cumulative Model Updates: 173,468
Cumulative Timesteps: 1,446,623,156

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,339.23715
Policy Entropy: 3.70994
Value Function Loss: 0.10152

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.11602
Policy Update Magnitude: 0.99519
Value Function Update Magnitude: 0.49050

Collected Steps per Second: 22,433.43832
Overall Steps per Second: 10,601.37824

Timestep Collection Time: 2.22980
Timestep Consumption Time: 2.48865
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.71844

Cumulative Model Updates: 173,474
Cumulative Timesteps: 1,446,673,178

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1446673178...
Checkpoint 1446673178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,865.17539
Policy Entropy: 3.73620
Value Function Loss: 0.09084

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 1.11535
Value Function Update Magnitude: 0.58661

Collected Steps per Second: 21,941.52585
Overall Steps per Second: 10,630.02877

Timestep Collection Time: 2.27951
Timestep Consumption Time: 2.42565
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.70516

Cumulative Model Updates: 173,480
Cumulative Timesteps: 1,446,723,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,779.22981
Policy Entropy: 3.76139
Value Function Loss: 0.08235

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.16421
Policy Update Magnitude: 0.84229
Value Function Update Magnitude: 0.55503

Collected Steps per Second: 22,388.17857
Overall Steps per Second: 10,568.24274

Timestep Collection Time: 2.23502
Timestep Consumption Time: 2.49973
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.73475

Cumulative Model Updates: 173,486
Cumulative Timesteps: 1,446,773,232

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1446773232...
Checkpoint 1446773232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,788.19993
Policy Entropy: 3.73859
Value Function Loss: 0.07261

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15504
Policy Update Magnitude: 0.65918
Value Function Update Magnitude: 0.55896

Collected Steps per Second: 22,263.27808
Overall Steps per Second: 10,485.57740

Timestep Collection Time: 2.24675
Timestep Consumption Time: 2.52361
PPO Batch Consumption Time: 0.29392
Total Iteration Time: 4.77036

Cumulative Model Updates: 173,492
Cumulative Timesteps: 1,446,823,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,920.11134
Policy Entropy: 3.72112
Value Function Loss: 0.07082

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.60161
Value Function Update Magnitude: 0.50942

Collected Steps per Second: 22,369.13837
Overall Steps per Second: 10,563.74277

Timestep Collection Time: 2.23585
Timestep Consumption Time: 2.49865
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.73450

Cumulative Model Updates: 173,498
Cumulative Timesteps: 1,446,873,266

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1446873266...
Checkpoint 1446873266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,326.05136
Policy Entropy: 3.74310
Value Function Loss: 0.06156

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12287
Policy Update Magnitude: 0.60780
Value Function Update Magnitude: 0.60279

Collected Steps per Second: 22,235.28303
Overall Steps per Second: 10,369.17403

Timestep Collection Time: 2.24931
Timestep Consumption Time: 2.57403
PPO Batch Consumption Time: 0.30260
Total Iteration Time: 4.82334

Cumulative Model Updates: 173,504
Cumulative Timesteps: 1,446,923,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,196.55684
Policy Entropy: 3.74328
Value Function Loss: 0.05907

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.57210
Value Function Update Magnitude: 0.52995

Collected Steps per Second: 22,774.20770
Overall Steps per Second: 10,622.25802

Timestep Collection Time: 2.19661
Timestep Consumption Time: 2.51294
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.70954

Cumulative Model Updates: 173,510
Cumulative Timesteps: 1,446,973,306

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1446973306...
Checkpoint 1446973306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,614.18112
Policy Entropy: 3.73828
Value Function Loss: 0.05756

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.56452
Value Function Update Magnitude: 0.57816

Collected Steps per Second: 22,021.19938
Overall Steps per Second: 10,610.57043

Timestep Collection Time: 2.27154
Timestep Consumption Time: 2.44282
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.71436

Cumulative Model Updates: 173,516
Cumulative Timesteps: 1,447,023,328

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,602.47969
Policy Entropy: 3.73652
Value Function Loss: 0.06611

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13338
Policy Update Magnitude: 0.54648
Value Function Update Magnitude: 0.58491

Collected Steps per Second: 22,632.30489
Overall Steps per Second: 10,585.48884

Timestep Collection Time: 2.20941
Timestep Consumption Time: 2.51442
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.72383

Cumulative Model Updates: 173,522
Cumulative Timesteps: 1,447,073,332

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1447073332...
Checkpoint 1447073332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,718.85077
Policy Entropy: 3.74161
Value Function Loss: 0.06158

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12530
Policy Update Magnitude: 0.53390
Value Function Update Magnitude: 0.59074

Collected Steps per Second: 22,406.42715
Overall Steps per Second: 10,553.45689

Timestep Collection Time: 2.23168
Timestep Consumption Time: 2.50648
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.73816

Cumulative Model Updates: 173,528
Cumulative Timesteps: 1,447,123,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.54058
Policy Entropy: 3.71939
Value Function Loss: 0.05347

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.48619
Value Function Update Magnitude: 0.62026

Collected Steps per Second: 22,773.12873
Overall Steps per Second: 10,677.03830

Timestep Collection Time: 2.19566
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.68313

Cumulative Model Updates: 173,534
Cumulative Timesteps: 1,447,173,338

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1447173338...
Checkpoint 1447173338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,776.51408
Policy Entropy: 3.72111
Value Function Loss: 0.04747

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.46388
Value Function Update Magnitude: 0.63458

Collected Steps per Second: 22,329.40236
Overall Steps per Second: 10,571.44473

Timestep Collection Time: 2.23920
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.72972

Cumulative Model Updates: 173,540
Cumulative Timesteps: 1,447,223,338

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,995.20415
Policy Entropy: 3.70997
Value Function Loss: 0.04798

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.46014
Value Function Update Magnitude: 0.59311

Collected Steps per Second: 23,157.24271
Overall Steps per Second: 10,776.32814

Timestep Collection Time: 2.15941
Timestep Consumption Time: 2.48095
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.64036

Cumulative Model Updates: 173,546
Cumulative Timesteps: 1,447,273,344

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1447273344...
Checkpoint 1447273344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,031.06345
Policy Entropy: 3.75534
Value Function Loss: 0.04521

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.43015
Value Function Update Magnitude: 0.68076

Collected Steps per Second: 22,565.29747
Overall Steps per Second: 10,650.38799

Timestep Collection Time: 2.21677
Timestep Consumption Time: 2.47996
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.69673

Cumulative Model Updates: 173,552
Cumulative Timesteps: 1,447,323,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,715.53575
Policy Entropy: 3.75913
Value Function Loss: 0.03843

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.39369
Value Function Update Magnitude: 0.72550

Collected Steps per Second: 22,406.69902
Overall Steps per Second: 10,871.20313

Timestep Collection Time: 2.23192
Timestep Consumption Time: 2.36830
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60023

Cumulative Model Updates: 173,558
Cumulative Timesteps: 1,447,373,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1447373376...
Checkpoint 1447373376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,591.49595
Policy Entropy: 3.77145
Value Function Loss: 0.03241

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12227
Policy Update Magnitude: 0.34325
Value Function Update Magnitude: 0.70583

Collected Steps per Second: 21,677.33245
Overall Steps per Second: 10,632.09087

Timestep Collection Time: 2.30794
Timestep Consumption Time: 2.39762
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.70557

Cumulative Model Updates: 173,564
Cumulative Timesteps: 1,447,423,406

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,658.05494
Policy Entropy: 3.74924
Value Function Loss: 0.03381

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12956
Policy Update Magnitude: 0.36878
Value Function Update Magnitude: 0.78201

Collected Steps per Second: 22,088.57284
Overall Steps per Second: 10,739.64385

Timestep Collection Time: 2.26407
Timestep Consumption Time: 2.39251
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.65658

Cumulative Model Updates: 173,570
Cumulative Timesteps: 1,447,473,416

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1447473416...
Checkpoint 1447473416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,449.12333
Policy Entropy: 3.73355
Value Function Loss: 0.03577

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13317
Policy Update Magnitude: 0.37929
Value Function Update Magnitude: 0.80191

Collected Steps per Second: 21,696.59662
Overall Steps per Second: 10,448.27400

Timestep Collection Time: 2.30451
Timestep Consumption Time: 2.48097
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.78548

Cumulative Model Updates: 173,576
Cumulative Timesteps: 1,447,523,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,449.12333
Policy Entropy: 3.70002
Value Function Loss: 0.03627

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.39790
Value Function Update Magnitude: 0.71770

Collected Steps per Second: 22,873.73507
Overall Steps per Second: 10,793.88826

Timestep Collection Time: 2.18705
Timestep Consumption Time: 2.44761
PPO Batch Consumption Time: 0.28539
Total Iteration Time: 4.63466

Cumulative Model Updates: 173,582
Cumulative Timesteps: 1,447,573,442

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1447573442...
Checkpoint 1447573442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,449.12333
Policy Entropy: 3.69470
Value Function Loss: 0.03048

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.40495
Value Function Update Magnitude: 0.56721

Collected Steps per Second: 21,855.64596
Overall Steps per Second: 10,470.43055

Timestep Collection Time: 2.28893
Timestep Consumption Time: 2.48891
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.77784

Cumulative Model Updates: 173,588
Cumulative Timesteps: 1,447,623,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,449.12333
Policy Entropy: 3.69318
Value Function Loss: 0.02969

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.36244
Value Function Update Magnitude: 0.40462

Collected Steps per Second: 22,772.17184
Overall Steps per Second: 10,675.39434

Timestep Collection Time: 2.19654
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.68554

Cumulative Model Updates: 173,594
Cumulative Timesteps: 1,447,673,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1447673488...
Checkpoint 1447673488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,449.12333
Policy Entropy: 3.69073
Value Function Loss: 0.02923

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13029
Policy Update Magnitude: 0.35074
Value Function Update Magnitude: 0.34340

Collected Steps per Second: 22,401.34338
Overall Steps per Second: 10,616.16579

Timestep Collection Time: 2.23246
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.71074

Cumulative Model Updates: 173,600
Cumulative Timesteps: 1,447,723,498

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,449.12333
Policy Entropy: 3.69250
Value Function Loss: 0.02961

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.37141
Value Function Update Magnitude: 0.39358

Collected Steps per Second: 22,931.81809
Overall Steps per Second: 10,683.64112

Timestep Collection Time: 2.18142
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.68230

Cumulative Model Updates: 173,606
Cumulative Timesteps: 1,447,773,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1447773522...
Checkpoint 1447773522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,449.12333
Policy Entropy: 3.70065
Value Function Loss: 0.02400

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.37338
Value Function Update Magnitude: 0.45744

Collected Steps per Second: 22,520.66075
Overall Steps per Second: 10,643.87666

Timestep Collection Time: 2.22107
Timestep Consumption Time: 2.47834
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.69942

Cumulative Model Updates: 173,612
Cumulative Timesteps: 1,447,823,542

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,449.12333
Policy Entropy: 3.69530
Value Function Loss: 0.02088

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.34900
Value Function Update Magnitude: 0.43220

Collected Steps per Second: 22,983.52989
Overall Steps per Second: 10,708.47015

Timestep Collection Time: 2.17695
Timestep Consumption Time: 2.49543
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67238

Cumulative Model Updates: 173,618
Cumulative Timesteps: 1,447,873,576

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1447873576...
Checkpoint 1447873576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,719.34840
Policy Entropy: 3.69625
Value Function Loss: 0.02304

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.32669
Value Function Update Magnitude: 0.43983

Collected Steps per Second: 22,386.71576
Overall Steps per Second: 10,627.64590

Timestep Collection Time: 2.23391
Timestep Consumption Time: 2.47174
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.70565

Cumulative Model Updates: 173,624
Cumulative Timesteps: 1,447,923,586

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,719.34840
Policy Entropy: 3.70331
Value Function Loss: 0.02262

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.33542
Value Function Update Magnitude: 0.46410

Collected Steps per Second: 23,231.94290
Overall Steps per Second: 10,878.22787

Timestep Collection Time: 2.15255
Timestep Consumption Time: 2.44452
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59707

Cumulative Model Updates: 173,630
Cumulative Timesteps: 1,447,973,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1447973594...
Checkpoint 1447973594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,719.34840
Policy Entropy: 3.69391
Value Function Loss: 0.02276

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.31920
Value Function Update Magnitude: 0.42665

Collected Steps per Second: 22,258.43231
Overall Steps per Second: 10,661.54453

Timestep Collection Time: 2.24652
Timestep Consumption Time: 2.44361
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.69013

Cumulative Model Updates: 173,636
Cumulative Timesteps: 1,448,023,598

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,719.34840
Policy Entropy: 3.68288
Value Function Loss: 0.02231

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.33008
Value Function Update Magnitude: 0.43744

Collected Steps per Second: 22,794.56084
Overall Steps per Second: 10,812.04563

Timestep Collection Time: 2.19430
Timestep Consumption Time: 2.43184
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.62614

Cumulative Model Updates: 173,642
Cumulative Timesteps: 1,448,073,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1448073616...
Checkpoint 1448073616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,719.34840
Policy Entropy: 3.67938
Value Function Loss: 0.02775

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.35971
Value Function Update Magnitude: 0.36675

Collected Steps per Second: 21,664.34268
Overall Steps per Second: 10,732.11748

Timestep Collection Time: 2.30868
Timestep Consumption Time: 2.35173
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.66040

Cumulative Model Updates: 173,648
Cumulative Timesteps: 1,448,123,632

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,719.34840
Policy Entropy: 3.68475
Value Function Loss: 0.02633

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.36820
Value Function Update Magnitude: 0.36558

Collected Steps per Second: 22,081.55058
Overall Steps per Second: 10,843.92315

Timestep Collection Time: 2.26515
Timestep Consumption Time: 2.34739
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61254

Cumulative Model Updates: 173,654
Cumulative Timesteps: 1,448,173,650

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1448173650...
Checkpoint 1448173650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,719.34840
Policy Entropy: 3.67661
Value Function Loss: 0.02672

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.34860
Value Function Update Magnitude: 0.37110

Collected Steps per Second: 21,822.44278
Overall Steps per Second: 10,643.14992

Timestep Collection Time: 2.29159
Timestep Consumption Time: 2.40702
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.69861

Cumulative Model Updates: 173,660
Cumulative Timesteps: 1,448,223,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,719.34840
Policy Entropy: 3.67514
Value Function Loss: 0.02573

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.35556
Value Function Update Magnitude: 0.39092

Collected Steps per Second: 22,128.79954
Overall Steps per Second: 10,562.22606

Timestep Collection Time: 2.25986
Timestep Consumption Time: 2.47475
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.73461

Cumulative Model Updates: 173,666
Cumulative Timesteps: 1,448,273,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1448273666...
Checkpoint 1448273666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,496.31637
Policy Entropy: 3.67187
Value Function Loss: 0.02758

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.37388
Value Function Update Magnitude: 0.46899

Collected Steps per Second: 22,170.70861
Overall Steps per Second: 10,637.90630

Timestep Collection Time: 2.25649
Timestep Consumption Time: 2.44631
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.70281

Cumulative Model Updates: 173,672
Cumulative Timesteps: 1,448,323,694

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251,496.31637
Policy Entropy: 3.68521
Value Function Loss: 0.02589

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.38443
Value Function Update Magnitude: 0.44246

Collected Steps per Second: 22,922.98336
Overall Steps per Second: 10,813.75998

Timestep Collection Time: 2.18165
Timestep Consumption Time: 2.44301
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.62466

Cumulative Model Updates: 173,678
Cumulative Timesteps: 1,448,373,704

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1448373704...
Checkpoint 1448373704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,496.31637
Policy Entropy: 3.67834
Value Function Loss: 0.02788

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.35087
Value Function Update Magnitude: 0.41915

Collected Steps per Second: 22,063.73011
Overall Steps per Second: 10,617.05495

Timestep Collection Time: 2.26616
Timestep Consumption Time: 2.44324
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.70940

Cumulative Model Updates: 173,684
Cumulative Timesteps: 1,448,423,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251,496.31637
Policy Entropy: 3.68708
Value Function Loss: 0.02570

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.34679
Value Function Update Magnitude: 0.39583

Collected Steps per Second: 23,034.89799
Overall Steps per Second: 10,715.42991

Timestep Collection Time: 2.17218
Timestep Consumption Time: 2.49735
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.66953

Cumulative Model Updates: 173,690
Cumulative Timesteps: 1,448,473,740

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1448473740...
Checkpoint 1448473740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 251,496.31637
Policy Entropy: 3.67293
Value Function Loss: 0.03056

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.40440
Value Function Update Magnitude: 0.46029

Collected Steps per Second: 22,347.40015
Overall Steps per Second: 10,541.58661

Timestep Collection Time: 2.23802
Timestep Consumption Time: 2.50642
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.74445

Cumulative Model Updates: 173,696
Cumulative Timesteps: 1,448,523,754

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251,496.31637
Policy Entropy: 3.65937
Value Function Loss: 0.03214

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.41551
Value Function Update Magnitude: 0.52059

Collected Steps per Second: 23,000.81165
Overall Steps per Second: 10,828.80876

Timestep Collection Time: 2.17558
Timestep Consumption Time: 2.44543
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.62101

Cumulative Model Updates: 173,702
Cumulative Timesteps: 1,448,573,794

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1448573794...
Checkpoint 1448573794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264,602.28949
Policy Entropy: 3.65985
Value Function Loss: 0.03614

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.43658
Value Function Update Magnitude: 0.55331

Collected Steps per Second: 22,285.34130
Overall Steps per Second: 10,703.62522

Timestep Collection Time: 2.24444
Timestep Consumption Time: 2.42856
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.67300

Cumulative Model Updates: 173,708
Cumulative Timesteps: 1,448,623,812

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,602.28949
Policy Entropy: 3.66812
Value Function Loss: 0.03056

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.42639
Value Function Update Magnitude: 0.50378

Collected Steps per Second: 22,642.14690
Overall Steps per Second: 10,602.07176

Timestep Collection Time: 2.21039
Timestep Consumption Time: 2.51020
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.72059

Cumulative Model Updates: 173,714
Cumulative Timesteps: 1,448,673,860

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1448673860...
Checkpoint 1448673860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,045.28263
Policy Entropy: 3.66413
Value Function Loss: 0.03076

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.39980
Value Function Update Magnitude: 0.48032

Collected Steps per Second: 22,476.01411
Overall Steps per Second: 10,623.47918

Timestep Collection Time: 2.22584
Timestep Consumption Time: 2.48335
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.70919

Cumulative Model Updates: 173,720
Cumulative Timesteps: 1,448,723,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363,045.28263
Policy Entropy: 3.66985
Value Function Loss: 0.02505

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.38034
Value Function Update Magnitude: 0.45617

Collected Steps per Second: 22,766.30812
Overall Steps per Second: 10,741.93205

Timestep Collection Time: 2.19649
Timestep Consumption Time: 2.45872
PPO Batch Consumption Time: 0.28338
Total Iteration Time: 4.65521

Cumulative Model Updates: 173,726
Cumulative Timesteps: 1,448,773,894

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1448773894...
Checkpoint 1448773894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,045.28263
Policy Entropy: 3.66155
Value Function Loss: 0.02740

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.37121
Value Function Update Magnitude: 0.45783

Collected Steps per Second: 22,597.35870
Overall Steps per Second: 10,630.70921

Timestep Collection Time: 2.21300
Timestep Consumption Time: 2.49111
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.70411

Cumulative Model Updates: 173,732
Cumulative Timesteps: 1,448,823,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363,045.28263
Policy Entropy: 3.67224
Value Function Loss: 0.02346

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.35844
Value Function Update Magnitude: 0.39735

Collected Steps per Second: 22,909.54417
Overall Steps per Second: 10,854.51446

Timestep Collection Time: 2.18311
Timestep Consumption Time: 2.42456
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.60767

Cumulative Model Updates: 173,738
Cumulative Timesteps: 1,448,873,916

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1448873916...
Checkpoint 1448873916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,045.28263
Policy Entropy: 3.67067
Value Function Loss: 0.02270

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12546
Policy Update Magnitude: 0.32701
Value Function Update Magnitude: 0.37430

Collected Steps per Second: 21,545.42808
Overall Steps per Second: 10,507.13490

Timestep Collection Time: 2.32151
Timestep Consumption Time: 2.43887
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.76038

Cumulative Model Updates: 173,744
Cumulative Timesteps: 1,448,923,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363,045.28263
Policy Entropy: 3.68232
Value Function Loss: 0.02062

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.12018
Policy Update Magnitude: 0.29488
Value Function Update Magnitude: 0.29210

Collected Steps per Second: 21,794.26172
Overall Steps per Second: 10,686.69929

Timestep Collection Time: 2.29437
Timestep Consumption Time: 2.38472
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.67909

Cumulative Model Updates: 173,750
Cumulative Timesteps: 1,448,973,938

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1448973938...
Checkpoint 1448973938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,045.28263
Policy Entropy: 3.67087
Value Function Loss: 0.02176

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.30069
Value Function Update Magnitude: 0.29547

Collected Steps per Second: 21,869.79773
Overall Steps per Second: 10,653.25333

Timestep Collection Time: 2.28662
Timestep Consumption Time: 2.40753
PPO Batch Consumption Time: 0.27678
Total Iteration Time: 4.69415

Cumulative Model Updates: 173,756
Cumulative Timesteps: 1,449,023,946

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363,045.28263
Policy Entropy: 3.65665
Value Function Loss: 0.02405

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.12195
Policy Update Magnitude: 0.32368
Value Function Update Magnitude: 0.41526

Collected Steps per Second: 22,415.63881
Overall Steps per Second: 10,786.60899

Timestep Collection Time: 2.23192
Timestep Consumption Time: 2.40623
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.63816

Cumulative Model Updates: 173,762
Cumulative Timesteps: 1,449,073,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1449073976...
Checkpoint 1449073976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 363,045.28263
Policy Entropy: 3.65053
Value Function Loss: 0.02350

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.34846
Value Function Update Magnitude: 0.46474

Collected Steps per Second: 22,164.50462
Overall Steps per Second: 10,736.77098

Timestep Collection Time: 2.25658
Timestep Consumption Time: 2.40180
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.65838

Cumulative Model Updates: 173,768
Cumulative Timesteps: 1,449,123,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391,133.66081
Policy Entropy: 3.65187
Value Function Loss: 0.02750

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12527
Policy Update Magnitude: 0.36073
Value Function Update Magnitude: 0.37102

Collected Steps per Second: 22,935.30858
Overall Steps per Second: 10,811.96261

Timestep Collection Time: 2.18048
Timestep Consumption Time: 2.44495
PPO Batch Consumption Time: 0.27966
Total Iteration Time: 4.62543

Cumulative Model Updates: 173,774
Cumulative Timesteps: 1,449,174,002

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1449174002...
Checkpoint 1449174002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205,088.57482
Policy Entropy: 3.67121
Value Function Loss: 0.03423

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.39644
Value Function Update Magnitude: 0.42498

Collected Steps per Second: 22,202.58231
Overall Steps per Second: 10,646.49771

Timestep Collection Time: 2.25199
Timestep Consumption Time: 2.44439
PPO Batch Consumption Time: 0.27926
Total Iteration Time: 4.69638

Cumulative Model Updates: 173,780
Cumulative Timesteps: 1,449,224,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,009.53087
Policy Entropy: 3.68126
Value Function Loss: 0.03712

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.43280
Value Function Update Magnitude: 0.53642

Collected Steps per Second: 23,043.98847
Overall Steps per Second: 10,732.23791

Timestep Collection Time: 2.17141
Timestep Consumption Time: 2.49099
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.66240

Cumulative Model Updates: 173,786
Cumulative Timesteps: 1,449,274,040

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1449274040...
Checkpoint 1449274040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,506.79525
Policy Entropy: 3.66823
Value Function Loss: 0.04038

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.42318
Value Function Update Magnitude: 0.55226

Collected Steps per Second: 22,348.43884
Overall Steps per Second: 10,576.88546

Timestep Collection Time: 2.23774
Timestep Consumption Time: 2.49049
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.72824

Cumulative Model Updates: 173,792
Cumulative Timesteps: 1,449,324,050

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,506.79525
Policy Entropy: 3.66220
Value Function Loss: 0.03189

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13311
Policy Update Magnitude: 0.40938
Value Function Update Magnitude: 0.54385

Collected Steps per Second: 23,216.21609
Overall Steps per Second: 10,736.78160

Timestep Collection Time: 2.15539
Timestep Consumption Time: 2.50522
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.66061

Cumulative Model Updates: 173,798
Cumulative Timesteps: 1,449,374,090

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1449374090...
Checkpoint 1449374090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 427,586.22095
Policy Entropy: 3.65259
Value Function Loss: 0.02850

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.38618
Value Function Update Magnitude: 0.61170

Collected Steps per Second: 22,382.62171
Overall Steps per Second: 10,731.94339

Timestep Collection Time: 2.23414
Timestep Consumption Time: 2.42540
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.65955

Cumulative Model Updates: 173,804
Cumulative Timesteps: 1,449,424,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,247.20492
Policy Entropy: 3.67711
Value Function Loss: 0.02374

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.36714
Value Function Update Magnitude: 0.58552

Collected Steps per Second: 23,058.33421
Overall Steps per Second: 10,837.33232

Timestep Collection Time: 2.16945
Timestep Consumption Time: 2.44644
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.61590

Cumulative Model Updates: 173,810
Cumulative Timesteps: 1,449,474,120

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1449474120...
Checkpoint 1449474120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460,344.73736
Policy Entropy: 3.67836
Value Function Loss: 0.02907

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.37224
Value Function Update Magnitude: 0.58327

Collected Steps per Second: 22,572.25992
Overall Steps per Second: 10,654.67736

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.47796
PPO Batch Consumption Time: 0.28643
Total Iteration Time: 4.69334

Cumulative Model Updates: 173,816
Cumulative Timesteps: 1,449,524,126

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,017.24125
Policy Entropy: 3.69089
Value Function Loss: 0.02651

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.35631
Value Function Update Magnitude: 0.69692

Collected Steps per Second: 22,942.40362
Overall Steps per Second: 10,729.34222

Timestep Collection Time: 2.18077
Timestep Consumption Time: 2.48233
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.66310

Cumulative Model Updates: 173,822
Cumulative Timesteps: 1,449,574,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1449574158...
Checkpoint 1449574158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,240.96392
Policy Entropy: 3.68533
Value Function Loss: 0.03180

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.36776
Value Function Update Magnitude: 0.80245

Collected Steps per Second: 22,131.76380
Overall Steps per Second: 10,357.82895

Timestep Collection Time: 2.26046
Timestep Consumption Time: 2.56951
PPO Batch Consumption Time: 0.30228
Total Iteration Time: 4.82997

Cumulative Model Updates: 173,828
Cumulative Timesteps: 1,449,624,186

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,975.96997
Policy Entropy: 3.68486
Value Function Loss: 0.03095

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.41506
Value Function Update Magnitude: 0.86223

Collected Steps per Second: 22,690.50847
Overall Steps per Second: 10,673.91569

Timestep Collection Time: 2.20471
Timestep Consumption Time: 2.48204
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.68675

Cumulative Model Updates: 173,834
Cumulative Timesteps: 1,449,674,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1449674212...
Checkpoint 1449674212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,678.69768
Policy Entropy: 3.68523
Value Function Loss: 0.03418

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.45855
Value Function Update Magnitude: 0.79622

Collected Steps per Second: 22,217.73442
Overall Steps per Second: 10,532.35536

Timestep Collection Time: 2.25153
Timestep Consumption Time: 2.49802
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.74955

Cumulative Model Updates: 173,840
Cumulative Timesteps: 1,449,724,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316,417.76709
Policy Entropy: 3.66495
Value Function Loss: 0.04692

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.50887
Value Function Update Magnitude: 0.63431

Collected Steps per Second: 22,845.13959
Overall Steps per Second: 10,778.91326

Timestep Collection Time: 2.18874
Timestep Consumption Time: 2.45014
PPO Batch Consumption Time: 0.27925
Total Iteration Time: 4.63887

Cumulative Model Updates: 173,846
Cumulative Timesteps: 1,449,774,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1449774238...
Checkpoint 1449774238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,813.84648
Policy Entropy: 3.68991
Value Function Loss: 0.04414

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.58859
Value Function Update Magnitude: 0.70791

Collected Steps per Second: 22,063.96511
Overall Steps per Second: 10,626.72992

Timestep Collection Time: 2.26641
Timestep Consumption Time: 2.43927
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.70568

Cumulative Model Updates: 173,852
Cumulative Timesteps: 1,449,824,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171,138.80682
Policy Entropy: 3.67885
Value Function Loss: 0.04338

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13608
Policy Update Magnitude: 0.58226
Value Function Update Magnitude: 0.84029

Collected Steps per Second: 22,875.44991
Overall Steps per Second: 10,702.73733

Timestep Collection Time: 2.18645
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.67320

Cumulative Model Updates: 173,858
Cumulative Timesteps: 1,449,874,260

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1449874260...
Checkpoint 1449874260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.70019
Value Function Loss: 0.03293

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.57603
Value Function Update Magnitude: 1.00214

Collected Steps per Second: 22,220.97933
Overall Steps per Second: 10,545.83621

Timestep Collection Time: 2.25103
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.74310

Cumulative Model Updates: 173,864
Cumulative Timesteps: 1,449,924,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.67946
Value Function Loss: 0.03020

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.54642
Value Function Update Magnitude: 0.92110

Collected Steps per Second: 22,961.43170
Overall Steps per Second: 10,829.78990

Timestep Collection Time: 2.17878
Timestep Consumption Time: 2.44070
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.61948

Cumulative Model Updates: 173,870
Cumulative Timesteps: 1,449,974,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1449974308...
Checkpoint 1449974308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.67752
Value Function Loss: 0.02728

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.49588
Value Function Update Magnitude: 0.78621

Collected Steps per Second: 22,083.92368
Overall Steps per Second: 10,641.27088

Timestep Collection Time: 2.26563
Timestep Consumption Time: 2.43625
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.70188

Cumulative Model Updates: 173,876
Cumulative Timesteps: 1,450,024,342

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.65737
Value Function Loss: 0.02855

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13516
Policy Update Magnitude: 0.46488
Value Function Update Magnitude: 0.61546

Collected Steps per Second: 22,906.94142
Overall Steps per Second: 10,844.91336

Timestep Collection Time: 2.18379
Timestep Consumption Time: 2.42888
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.61267

Cumulative Model Updates: 173,882
Cumulative Timesteps: 1,450,074,366

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1450074366...
Checkpoint 1450074366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.65162
Value Function Loss: 0.02999

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.45274
Value Function Update Magnitude: 0.60008

Collected Steps per Second: 22,341.37862
Overall Steps per Second: 10,739.65243

Timestep Collection Time: 2.23818
Timestep Consumption Time: 2.41784
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.65602

Cumulative Model Updates: 173,888
Cumulative Timesteps: 1,450,124,370

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.65810
Value Function Loss: 0.03162

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12611
Policy Update Magnitude: 0.43840
Value Function Update Magnitude: 0.59655

Collected Steps per Second: 22,669.06095
Overall Steps per Second: 10,778.91068

Timestep Collection Time: 2.20609
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.27909
Total Iteration Time: 4.63962

Cumulative Model Updates: 173,894
Cumulative Timesteps: 1,450,174,380

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1450174380...
Checkpoint 1450174380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.66732
Value Function Loss: 0.02957

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.39820
Value Function Update Magnitude: 0.43719

Collected Steps per Second: 22,070.19312
Overall Steps per Second: 10,630.83193

Timestep Collection Time: 2.26559
Timestep Consumption Time: 2.43790
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.70349

Cumulative Model Updates: 173,900
Cumulative Timesteps: 1,450,224,382

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.66636
Value Function Loss: 0.02792

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12150
Policy Update Magnitude: 0.37159
Value Function Update Magnitude: 0.37954

Collected Steps per Second: 22,520.39324
Overall Steps per Second: 10,597.58997

Timestep Collection Time: 2.22128
Timestep Consumption Time: 2.49904
PPO Batch Consumption Time: 0.29609
Total Iteration Time: 4.72032

Cumulative Model Updates: 173,906
Cumulative Timesteps: 1,450,274,406

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1450274406...
Checkpoint 1450274406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.65645
Value Function Loss: 0.02812

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.39255
Value Function Update Magnitude: 0.35396

Collected Steps per Second: 22,179.72075
Overall Steps per Second: 10,574.33260

Timestep Collection Time: 2.25503
Timestep Consumption Time: 2.47491
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.72994

Cumulative Model Updates: 173,912
Cumulative Timesteps: 1,450,324,422

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.65020
Value Function Loss: 0.02977

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12792
Policy Update Magnitude: 0.42284
Value Function Update Magnitude: 0.42951

Collected Steps per Second: 21,589.37629
Overall Steps per Second: 10,429.19671

Timestep Collection Time: 2.31744
Timestep Consumption Time: 2.47987
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.79730

Cumulative Model Updates: 173,918
Cumulative Timesteps: 1,450,374,454

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1450374454...
Checkpoint 1450374454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.66816
Value Function Loss: 0.02598

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.41140
Value Function Update Magnitude: 0.50958

Collected Steps per Second: 21,473.59543
Overall Steps per Second: 10,650.45998

Timestep Collection Time: 2.32919
Timestep Consumption Time: 2.36695
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.69614

Cumulative Model Updates: 173,924
Cumulative Timesteps: 1,450,424,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.67433
Value Function Loss: 0.02341

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.37909
Value Function Update Magnitude: 0.49313

Collected Steps per Second: 22,072.39035
Overall Steps per Second: 10,730.21372

Timestep Collection Time: 2.26645
Timestep Consumption Time: 2.39571
PPO Batch Consumption Time: 0.28637
Total Iteration Time: 4.66216

Cumulative Model Updates: 173,930
Cumulative Timesteps: 1,450,474,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1450474496...
Checkpoint 1450474496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,629.71433
Policy Entropy: 3.68745
Value Function Loss: 0.02322

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11553
Policy Update Magnitude: 0.40050
Value Function Update Magnitude: 0.42204

Collected Steps per Second: 21,897.46096
Overall Steps per Second: 10,547.82252

Timestep Collection Time: 2.28428
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.74221

Cumulative Model Updates: 173,936
Cumulative Timesteps: 1,450,524,516

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280,223.73648
Policy Entropy: 3.68326
Value Function Loss: 0.02416

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12755
Policy Update Magnitude: 0.46404
Value Function Update Magnitude: 0.60837

Collected Steps per Second: 23,087.43440
Overall Steps per Second: 10,768.78727

Timestep Collection Time: 2.16785
Timestep Consumption Time: 2.47985
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.64769

Cumulative Model Updates: 173,942
Cumulative Timesteps: 1,450,574,566

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1450574566...
Checkpoint 1450574566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,645.80414
Policy Entropy: 3.69692
Value Function Loss: 0.02322

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14992
Policy Update Magnitude: 0.43346
Value Function Update Magnitude: 0.65511

Collected Steps per Second: 22,353.03589
Overall Steps per Second: 10,636.17313

Timestep Collection Time: 2.23826
Timestep Consumption Time: 2.46568
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.70395

Cumulative Model Updates: 173,948
Cumulative Timesteps: 1,450,624,598

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,645.80414
Policy Entropy: 3.68435
Value Function Loss: 0.02245

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14771
Policy Update Magnitude: 0.41923
Value Function Update Magnitude: 0.63164

Collected Steps per Second: 22,889.38147
Overall Steps per Second: 10,840.17982

Timestep Collection Time: 2.18521
Timestep Consumption Time: 2.42892
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.61413

Cumulative Model Updates: 173,954
Cumulative Timesteps: 1,450,674,616

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1450674616...
Checkpoint 1450674616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,645.80414
Policy Entropy: 3.67601
Value Function Loss: 0.02274

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11780
Policy Update Magnitude: 0.46621
Value Function Update Magnitude: 0.58171

Collected Steps per Second: 22,772.91635
Overall Steps per Second: 10,734.44707

Timestep Collection Time: 2.19577
Timestep Consumption Time: 2.46251
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.65827

Cumulative Model Updates: 173,960
Cumulative Timesteps: 1,450,724,620

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,645.80414
Policy Entropy: 3.65732
Value Function Loss: 0.02477

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12003
Policy Update Magnitude: 0.54621
Value Function Update Magnitude: 0.55837

Collected Steps per Second: 22,918.19242
Overall Steps per Second: 10,820.67133

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.44038
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.62319

Cumulative Model Updates: 173,966
Cumulative Timesteps: 1,450,774,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1450774646...
Checkpoint 1450774646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,645.80414
Policy Entropy: 3.65934
Value Function Loss: 0.02948

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.17693
Policy Update Magnitude: 0.57432
Value Function Update Magnitude: 0.49585

Collected Steps per Second: 22,555.36870
Overall Steps per Second: 10,689.41836

Timestep Collection Time: 2.21898
Timestep Consumption Time: 2.46322
PPO Batch Consumption Time: 0.27913
Total Iteration Time: 4.68220

Cumulative Model Updates: 173,972
Cumulative Timesteps: 1,450,824,696

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,902.51432
Policy Entropy: 3.65713
Value Function Loss: 0.04361

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14395
Policy Update Magnitude: 0.57845
Value Function Update Magnitude: 0.44818

Collected Steps per Second: 23,014.90147
Overall Steps per Second: 10,864.51723

Timestep Collection Time: 2.17311
Timestep Consumption Time: 2.43031
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.60343

Cumulative Model Updates: 173,978
Cumulative Timesteps: 1,450,874,710

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1450874710...
Checkpoint 1450874710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,957.81581
Policy Entropy: 3.66393
Value Function Loss: 0.04730

Mean KL Divergence: 0.01496
SB3 Clip Fraction: 0.18922
Policy Update Magnitude: 0.62670
Value Function Update Magnitude: 0.44200

Collected Steps per Second: 22,659.60356
Overall Steps per Second: 10,658.42721

Timestep Collection Time: 2.20666
Timestep Consumption Time: 2.48465
PPO Batch Consumption Time: 0.28481
Total Iteration Time: 4.69131

Cumulative Model Updates: 173,984
Cumulative Timesteps: 1,450,924,712

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427,964.98471
Policy Entropy: 3.66763
Value Function Loss: 0.06275

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.77965
Value Function Update Magnitude: 0.43254

Collected Steps per Second: 23,066.72953
Overall Steps per Second: 10,875.40889

Timestep Collection Time: 2.16849
Timestep Consumption Time: 2.43088
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.59937

Cumulative Model Updates: 173,990
Cumulative Timesteps: 1,450,974,732

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1450974732...
Checkpoint 1450974732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 651,099.54659
Policy Entropy: 3.67169
Value Function Loss: 0.05691

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16117
Policy Update Magnitude: 0.82279
Value Function Update Magnitude: 0.64393

Collected Steps per Second: 22,324.44775
Overall Steps per Second: 10,704.61656

Timestep Collection Time: 2.24014
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.67182

Cumulative Model Updates: 173,996
Cumulative Timesteps: 1,451,024,742

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255,142.26185
Policy Entropy: 3.67030
Value Function Loss: 0.05675

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.85495
Value Function Update Magnitude: 0.66417

Collected Steps per Second: 23,244.71817
Overall Steps per Second: 10,902.47986

Timestep Collection Time: 2.15146
Timestep Consumption Time: 2.43557
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.58703

Cumulative Model Updates: 174,002
Cumulative Timesteps: 1,451,074,752

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1451074752...
Checkpoint 1451074752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,649.49042
Policy Entropy: 3.69044
Value Function Loss: 0.05072

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.79667
Value Function Update Magnitude: 0.55464

Collected Steps per Second: 22,642.92828
Overall Steps per Second: 10,667.66418

Timestep Collection Time: 2.20961
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.69006

Cumulative Model Updates: 174,008
Cumulative Timesteps: 1,451,124,784

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,479.18528
Policy Entropy: 3.69728
Value Function Loss: 0.04784

Mean KL Divergence: 0.01502
SB3 Clip Fraction: 0.18513
Policy Update Magnitude: 0.66743
Value Function Update Magnitude: 0.67333

Collected Steps per Second: 23,270.65962
Overall Steps per Second: 10,893.41629

Timestep Collection Time: 2.14940
Timestep Consumption Time: 2.44218
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.59158

Cumulative Model Updates: 174,014
Cumulative Timesteps: 1,451,174,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1451174802...
Checkpoint 1451174802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,487.11025
Policy Entropy: 3.71111
Value Function Loss: 0.04115

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.17692
Policy Update Magnitude: 0.59550
Value Function Update Magnitude: 0.64304

Collected Steps per Second: 22,576.19669
Overall Steps per Second: 10,661.42185

Timestep Collection Time: 2.21570
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.69187

Cumulative Model Updates: 174,020
Cumulative Timesteps: 1,451,224,824

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 244,865.73877
Policy Entropy: 3.69219
Value Function Loss: 0.04416

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.17743
Policy Update Magnitude: 0.51465
Value Function Update Magnitude: 0.54533

Collected Steps per Second: 22,934.37287
Overall Steps per Second: 10,868.09873

Timestep Collection Time: 2.18118
Timestep Consumption Time: 2.42165
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.60283

Cumulative Model Updates: 174,026
Cumulative Timesteps: 1,451,274,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1451274848...
Checkpoint 1451274848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,136.32196
Policy Entropy: 3.68861
Value Function Loss: 0.03802

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.18699
Policy Update Magnitude: 0.43415
Value Function Update Magnitude: 0.39014

Collected Steps per Second: 22,402.98487
Overall Steps per Second: 10,760.09790

Timestep Collection Time: 2.23238
Timestep Consumption Time: 2.41553
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.64791

Cumulative Model Updates: 174,032
Cumulative Timesteps: 1,451,324,860

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,136.32196
Policy Entropy: 3.68654
Value Function Loss: 0.03371

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14807
Policy Update Magnitude: 0.39520
Value Function Update Magnitude: 0.31566

Collected Steps per Second: 23,247.58877
Overall Steps per Second: 10,815.29796

Timestep Collection Time: 2.15136
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28387
Total Iteration Time: 4.62438

Cumulative Model Updates: 174,038
Cumulative Timesteps: 1,451,374,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1451374874...
Checkpoint 1451374874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,136.32196
Policy Entropy: 3.67150
Value Function Loss: 0.04112

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.42411
Value Function Update Magnitude: 0.36488

Collected Steps per Second: 22,467.71882
Overall Steps per Second: 10,654.82536

Timestep Collection Time: 2.22666
Timestep Consumption Time: 2.46868
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.69534

Cumulative Model Updates: 174,044
Cumulative Timesteps: 1,451,424,902

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,040.65387
Policy Entropy: 3.65992
Value Function Loss: 0.04516

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.53679
Value Function Update Magnitude: 0.42955

Collected Steps per Second: 23,195.77539
Overall Steps per Second: 10,885.53096

Timestep Collection Time: 2.15582
Timestep Consumption Time: 2.43798
PPO Batch Consumption Time: 0.27916
Total Iteration Time: 4.59380

Cumulative Model Updates: 174,050
Cumulative Timesteps: 1,451,474,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1451474908...
Checkpoint 1451474908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,971.67758
Policy Entropy: 3.67756
Value Function Loss: 0.05308

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.58122
Value Function Update Magnitude: 0.44845

Collected Steps per Second: 22,630.93459
Overall Steps per Second: 10,676.87859

Timestep Collection Time: 2.21051
Timestep Consumption Time: 2.47494
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.68545

Cumulative Model Updates: 174,056
Cumulative Timesteps: 1,451,524,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,619.33145
Policy Entropy: 3.68296
Value Function Loss: 0.05783

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13749
Policy Update Magnitude: 0.57042
Value Function Update Magnitude: 0.48506

Collected Steps per Second: 22,739.11373
Overall Steps per Second: 10,646.20960

Timestep Collection Time: 2.20017
Timestep Consumption Time: 2.49915
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.69933

Cumulative Model Updates: 174,062
Cumulative Timesteps: 1,451,574,964

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1451574964...
Checkpoint 1451574964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,006.26701
Policy Entropy: 3.68568
Value Function Loss: 0.05468

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.55778
Value Function Update Magnitude: 0.59755

Collected Steps per Second: 22,557.42010
Overall Steps per Second: 10,606.56093

Timestep Collection Time: 2.21665
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.71425

Cumulative Model Updates: 174,068
Cumulative Timesteps: 1,451,624,966

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,099.94775
Policy Entropy: 3.67202
Value Function Loss: 0.05136

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.54915
Value Function Update Magnitude: 0.62486

Collected Steps per Second: 22,895.91230
Overall Steps per Second: 10,818.33669

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.43925
PPO Batch Consumption Time: 0.28118
Total Iteration Time: 4.62419

Cumulative Model Updates: 174,074
Cumulative Timesteps: 1,451,674,992

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1451674992...
Checkpoint 1451674992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,502.55033
Policy Entropy: 3.69158
Value Function Loss: 0.04430

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13438
Policy Update Magnitude: 0.54099
Value Function Update Magnitude: 0.66339

Collected Steps per Second: 22,547.05436
Overall Steps per Second: 10,641.90560

Timestep Collection Time: 2.21821
Timestep Consumption Time: 2.48152
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.69972

Cumulative Model Updates: 174,080
Cumulative Timesteps: 1,451,725,006

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,502.55033
Policy Entropy: 3.68258
Value Function Loss: 0.03576

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13463
Policy Update Magnitude: 0.49908
Value Function Update Magnitude: 0.57069

Collected Steps per Second: 23,237.32074
Overall Steps per Second: 10,953.31921

Timestep Collection Time: 2.15214
Timestep Consumption Time: 2.41360
PPO Batch Consumption Time: 0.27639
Total Iteration Time: 4.56574

Cumulative Model Updates: 174,086
Cumulative Timesteps: 1,451,775,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1451775016...
Checkpoint 1451775016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,502.55033
Policy Entropy: 3.68589
Value Function Loss: 0.02622

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13953
Policy Update Magnitude: 0.44778
Value Function Update Magnitude: 0.54304

Collected Steps per Second: 22,017.89437
Overall Steps per Second: 10,575.02977

Timestep Collection Time: 2.27170
Timestep Consumption Time: 2.45812
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.72982

Cumulative Model Updates: 174,092
Cumulative Timesteps: 1,451,825,034

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,502.55033
Policy Entropy: 3.68233
Value Function Loss: 0.02280

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.38330
Value Function Update Magnitude: 0.50205

Collected Steps per Second: 22,518.86403
Overall Steps per Second: 10,976.97803

Timestep Collection Time: 2.22178
Timestep Consumption Time: 2.33612
PPO Batch Consumption Time: 0.27566
Total Iteration Time: 4.55790

Cumulative Model Updates: 174,098
Cumulative Timesteps: 1,451,875,066

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1451875066...
Checkpoint 1451875066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,502.55033
Policy Entropy: 3.67749
Value Function Loss: 0.02048

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13343
Policy Update Magnitude: 0.33519
Value Function Update Magnitude: 0.43900

Collected Steps per Second: 22,175.46989
Overall Steps per Second: 10,734.22000

Timestep Collection Time: 2.25610
Timestep Consumption Time: 2.40470
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.66080

Cumulative Model Updates: 174,104
Cumulative Timesteps: 1,451,925,096

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 337,018.87568
Policy Entropy: 3.66838
Value Function Loss: 0.02377

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.35847
Value Function Update Magnitude: 0.44975

Collected Steps per Second: 22,163.73790
Overall Steps per Second: 10,797.15372

Timestep Collection Time: 2.25603
Timestep Consumption Time: 2.37501
PPO Batch Consumption Time: 0.28367
Total Iteration Time: 4.63104

Cumulative Model Updates: 174,110
Cumulative Timesteps: 1,451,975,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1451975098...
Checkpoint 1451975098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337,018.87568
Policy Entropy: 3.65755
Value Function Loss: 0.03163

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.44035
Value Function Update Magnitude: 0.50740

Collected Steps per Second: 21,965.81053
Overall Steps per Second: 10,572.09120

Timestep Collection Time: 2.27781
Timestep Consumption Time: 2.45484
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.73265

Cumulative Model Updates: 174,116
Cumulative Timesteps: 1,452,025,132

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 427,993.04192
Policy Entropy: 3.66848
Value Function Loss: 0.04248

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.50845
Value Function Update Magnitude: 0.47496

Collected Steps per Second: 23,029.95533
Overall Steps per Second: 10,928.39153

Timestep Collection Time: 2.17187
Timestep Consumption Time: 2.40502
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.57689

Cumulative Model Updates: 174,122
Cumulative Timesteps: 1,452,075,150

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1452075150...
Checkpoint 1452075150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,728.47979
Policy Entropy: 3.68078
Value Function Loss: 0.04538

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.56580
Value Function Update Magnitude: 0.57682

Collected Steps per Second: 22,840.57149
Overall Steps per Second: 10,714.96820

Timestep Collection Time: 2.18952
Timestep Consumption Time: 2.47778
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.66730

Cumulative Model Updates: 174,128
Cumulative Timesteps: 1,452,125,160

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,621.85034
Policy Entropy: 3.68626
Value Function Loss: 0.05246

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.60800
Value Function Update Magnitude: 0.66769

Collected Steps per Second: 23,129.86359
Overall Steps per Second: 10,848.36350

Timestep Collection Time: 2.16257
Timestep Consumption Time: 2.44826
PPO Batch Consumption Time: 0.27920
Total Iteration Time: 4.61083

Cumulative Model Updates: 174,134
Cumulative Timesteps: 1,452,175,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1452175180...
Checkpoint 1452175180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,581.38160
Policy Entropy: 3.70804
Value Function Loss: 0.05064

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.56864
Value Function Update Magnitude: 0.65781

Collected Steps per Second: 22,711.14072
Overall Steps per Second: 10,669.94746

Timestep Collection Time: 2.20200
Timestep Consumption Time: 2.48499
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.68700

Cumulative Model Updates: 174,140
Cumulative Timesteps: 1,452,225,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,942.20064
Policy Entropy: 3.69389
Value Function Loss: 0.05104

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13123
Policy Update Magnitude: 0.51446
Value Function Update Magnitude: 0.60680

Collected Steps per Second: 23,041.66791
Overall Steps per Second: 10,851.19344

Timestep Collection Time: 2.16998
Timestep Consumption Time: 2.43781
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.60779

Cumulative Model Updates: 174,146
Cumulative Timesteps: 1,452,275,190

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1452275190...
Checkpoint 1452275190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,942.20064
Policy Entropy: 3.69306
Value Function Loss: 0.03804

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.48423
Value Function Update Magnitude: 0.56325

Collected Steps per Second: 22,866.31619
Overall Steps per Second: 10,675.02963

Timestep Collection Time: 2.18671
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.68402

Cumulative Model Updates: 174,152
Cumulative Timesteps: 1,452,325,192

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,942.20064
Policy Entropy: 3.65848
Value Function Loss: 0.03290

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.40963
Value Function Update Magnitude: 0.51429

Collected Steps per Second: 23,178.96206
Overall Steps per Second: 10,864.61918

Timestep Collection Time: 2.15721
Timestep Consumption Time: 2.44506
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.60228

Cumulative Model Updates: 174,158
Cumulative Timesteps: 1,452,375,194

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1452375194...
Checkpoint 1452375194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,776.46586
Policy Entropy: 3.66480
Value Function Loss: 0.02653

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13517
Policy Update Magnitude: 0.36159
Value Function Update Magnitude: 0.36117

Collected Steps per Second: 22,688.01730
Overall Steps per Second: 10,683.57304

Timestep Collection Time: 2.20381
Timestep Consumption Time: 2.47628
PPO Batch Consumption Time: 0.28645
Total Iteration Time: 4.68008

Cumulative Model Updates: 174,164
Cumulative Timesteps: 1,452,425,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,776.46586
Policy Entropy: 3.65083
Value Function Loss: 0.02923

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13993
Policy Update Magnitude: 0.35408
Value Function Update Magnitude: 0.37992

Collected Steps per Second: 22,545.10441
Overall Steps per Second: 10,676.67609

Timestep Collection Time: 2.21795
Timestep Consumption Time: 2.46553
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.68348

Cumulative Model Updates: 174,170
Cumulative Timesteps: 1,452,475,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1452475198...
Checkpoint 1452475198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,776.46586
Policy Entropy: 3.65675
Value Function Loss: 0.02813

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13395
Policy Update Magnitude: 0.39377
Value Function Update Magnitude: 0.51723

Collected Steps per Second: 22,958.24132
Overall Steps per Second: 10,926.40195

Timestep Collection Time: 2.17865
Timestep Consumption Time: 2.39907
PPO Batch Consumption Time: 0.27610
Total Iteration Time: 4.57772

Cumulative Model Updates: 174,176
Cumulative Timesteps: 1,452,525,216

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,776.46586
Policy Entropy: 3.64542
Value Function Loss: 0.02774

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14378
Policy Update Magnitude: 0.42729
Value Function Update Magnitude: 0.60287

Collected Steps per Second: 23,113.16964
Overall Steps per Second: 10,859.72945

Timestep Collection Time: 2.16396
Timestep Consumption Time: 2.44168
PPO Batch Consumption Time: 0.28171
Total Iteration Time: 4.60564

Cumulative Model Updates: 174,182
Cumulative Timesteps: 1,452,575,232

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1452575232...
Checkpoint 1452575232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,776.46586
Policy Entropy: 3.66445
Value Function Loss: 0.02254

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.39257
Value Function Update Magnitude: 0.48873

Collected Steps per Second: 22,995.29967
Overall Steps per Second: 10,756.05123

Timestep Collection Time: 2.17436
Timestep Consumption Time: 2.47419
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.64855

Cumulative Model Updates: 174,188
Cumulative Timesteps: 1,452,625,232

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,776.46586
Policy Entropy: 3.66354
Value Function Loss: 0.02143

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.32422
Value Function Update Magnitude: 0.34451

Collected Steps per Second: 22,346.33677
Overall Steps per Second: 10,798.22348

Timestep Collection Time: 2.23867
Timestep Consumption Time: 2.39413
PPO Batch Consumption Time: 0.28391
Total Iteration Time: 4.63280

Cumulative Model Updates: 174,194
Cumulative Timesteps: 1,452,675,258

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1452675258...
Checkpoint 1452675258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,776.46586
Policy Entropy: 3.65982
Value Function Loss: 0.02712

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.33634
Value Function Update Magnitude: 0.35546

Collected Steps per Second: 22,116.87750
Overall Steps per Second: 10,691.47962

Timestep Collection Time: 2.26117
Timestep Consumption Time: 2.41639
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.67756

Cumulative Model Updates: 174,200
Cumulative Timesteps: 1,452,725,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,776.46586
Policy Entropy: 3.65440
Value Function Loss: 0.03393

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.44392
Value Function Update Magnitude: 0.49320

Collected Steps per Second: 22,297.60878
Overall Steps per Second: 10,746.73289

Timestep Collection Time: 2.24275
Timestep Consumption Time: 2.41057
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.65332

Cumulative Model Updates: 174,206
Cumulative Timesteps: 1,452,775,276

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1452775276...
Checkpoint 1452775276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 593,776.46586
Policy Entropy: 3.65224
Value Function Loss: 0.03260

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.47105
Value Function Update Magnitude: 0.53030

Collected Steps per Second: 22,606.74431
Overall Steps per Second: 10,730.90006

Timestep Collection Time: 2.21332
Timestep Consumption Time: 2.44947
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.66280

Cumulative Model Updates: 174,212
Cumulative Timesteps: 1,452,825,312

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 593,776.46586
Policy Entropy: 3.65246
Value Function Loss: 0.03102

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12990
Policy Update Magnitude: 0.45687
Value Function Update Magnitude: 0.54096

Collected Steps per Second: 22,997.39346
Overall Steps per Second: 10,915.49062

Timestep Collection Time: 2.17503
Timestep Consumption Time: 2.40745
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.58248

Cumulative Model Updates: 174,218
Cumulative Timesteps: 1,452,875,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1452875332...
Checkpoint 1452875332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,934.83582
Policy Entropy: 3.65573
Value Function Loss: 0.03131

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.45645
Value Function Update Magnitude: 0.51149

Collected Steps per Second: 22,675.79864
Overall Steps per Second: 10,649.21120

Timestep Collection Time: 2.20579
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.69687

Cumulative Model Updates: 174,224
Cumulative Timesteps: 1,452,925,350

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225,981.46852
Policy Entropy: 3.67105
Value Function Loss: 0.03146

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.48044
Value Function Update Magnitude: 0.60695

Collected Steps per Second: 23,031.88411
Overall Steps per Second: 10,878.78361

Timestep Collection Time: 2.17212
Timestep Consumption Time: 2.42656
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.59868

Cumulative Model Updates: 174,230
Cumulative Timesteps: 1,452,975,378

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1452975378...
Checkpoint 1452975378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 97,303.22124
Policy Entropy: 3.68511
Value Function Loss: 0.02926

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.46313
Value Function Update Magnitude: 0.57121

Collected Steps per Second: 22,640.76637
Overall Steps per Second: 10,653.41908

Timestep Collection Time: 2.20911
Timestep Consumption Time: 2.48572
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.69483

Cumulative Model Updates: 174,236
Cumulative Timesteps: 1,453,025,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,959.23316
Policy Entropy: 3.69937
Value Function Loss: 0.02478

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.41723
Value Function Update Magnitude: 0.58356

Collected Steps per Second: 23,077.81516
Overall Steps per Second: 10,884.82122

Timestep Collection Time: 2.16780
Timestep Consumption Time: 2.42833
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.59613

Cumulative Model Updates: 174,242
Cumulative Timesteps: 1,453,075,422

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1453075422...
Checkpoint 1453075422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,304.83918
Policy Entropy: 3.68854
Value Function Loss: 0.02470

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.37731
Value Function Update Magnitude: 0.59356

Collected Steps per Second: 22,677.80850
Overall Steps per Second: 10,716.62950

Timestep Collection Time: 2.20568
Timestep Consumption Time: 2.46183
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.66751

Cumulative Model Updates: 174,248
Cumulative Timesteps: 1,453,125,442

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,304.83918
Policy Entropy: 3.68324
Value Function Loss: 0.02086

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.34258
Value Function Update Magnitude: 0.56500

Collected Steps per Second: 22,857.28595
Overall Steps per Second: 10,856.88284

Timestep Collection Time: 2.18836
Timestep Consumption Time: 2.41885
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.60722

Cumulative Model Updates: 174,254
Cumulative Timesteps: 1,453,175,462

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1453175462...
Checkpoint 1453175462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,304.83918
Policy Entropy: 3.67321
Value Function Loss: 0.01884

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.31729
Value Function Update Magnitude: 0.48312

Collected Steps per Second: 22,293.90587
Overall Steps per Second: 10,721.84455

Timestep Collection Time: 2.24303
Timestep Consumption Time: 2.42090
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.66394

Cumulative Model Updates: 174,260
Cumulative Timesteps: 1,453,225,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,304.83918
Policy Entropy: 3.65644
Value Function Loss: 0.02161

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.35138
Value Function Update Magnitude: 0.50673

Collected Steps per Second: 22,335.39525
Overall Steps per Second: 10,913.06699

Timestep Collection Time: 2.23923
Timestep Consumption Time: 2.34372
PPO Batch Consumption Time: 0.27607
Total Iteration Time: 4.58295

Cumulative Model Updates: 174,266
Cumulative Timesteps: 1,453,275,482

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1453275482...
Checkpoint 1453275482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,293.13998
Policy Entropy: 3.65919
Value Function Loss: 0.02893

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.43983
Value Function Update Magnitude: 0.68823

Collected Steps per Second: 21,971.97100
Overall Steps per Second: 10,599.41217

Timestep Collection Time: 2.27590
Timestep Consumption Time: 2.44191
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.71781

Cumulative Model Updates: 174,272
Cumulative Timesteps: 1,453,325,488

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,293.13998
Policy Entropy: 3.63523
Value Function Loss: 0.03217

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13895
Policy Update Magnitude: 0.50141
Value Function Update Magnitude: 0.79069

Collected Steps per Second: 22,864.56436
Overall Steps per Second: 10,875.17696

Timestep Collection Time: 2.18793
Timestep Consumption Time: 2.41209
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.60002

Cumulative Model Updates: 174,278
Cumulative Timesteps: 1,453,375,514

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1453375514...
Checkpoint 1453375514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 431,333.96801
Policy Entropy: 3.64505
Value Function Loss: 0.03934

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.53587
Value Function Update Magnitude: 0.69782

Collected Steps per Second: 22,783.77082
Overall Steps per Second: 10,712.29184

Timestep Collection Time: 2.19621
Timestep Consumption Time: 2.47487
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.67108

Cumulative Model Updates: 174,284
Cumulative Timesteps: 1,453,425,552

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,003.05314
Policy Entropy: 3.65186
Value Function Loss: 0.03784

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.56003
Value Function Update Magnitude: 0.70649

Collected Steps per Second: 22,642.67045
Overall Steps per Second: 10,800.29914

Timestep Collection Time: 2.20822
Timestep Consumption Time: 2.42128
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.62950

Cumulative Model Updates: 174,290
Cumulative Timesteps: 1,453,475,552

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1453475552...
Checkpoint 1453475552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283,003.05314
Policy Entropy: 3.66015
Value Function Loss: 0.03448

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.55417
Value Function Update Magnitude: 0.79044

Collected Steps per Second: 23,042.27809
Overall Steps per Second: 10,700.70654

Timestep Collection Time: 2.17097
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.67483

Cumulative Model Updates: 174,296
Cumulative Timesteps: 1,453,525,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,003.05314
Policy Entropy: 3.66172
Value Function Loss: 0.03050

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.51613
Value Function Update Magnitude: 0.71325

Collected Steps per Second: 22,692.06712
Overall Steps per Second: 10,807.02659

Timestep Collection Time: 2.20368
Timestep Consumption Time: 2.42350
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.62717

Cumulative Model Updates: 174,302
Cumulative Timesteps: 1,453,575,582

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1453575582...
Checkpoint 1453575582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,858.84988
Policy Entropy: 3.64687
Value Function Loss: 0.03194

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12784
Policy Update Magnitude: 0.51832
Value Function Update Magnitude: 0.62035

Collected Steps per Second: 22,887.80687
Overall Steps per Second: 10,712.37279

Timestep Collection Time: 2.18553
Timestep Consumption Time: 2.48402
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.66955

Cumulative Model Updates: 174,308
Cumulative Timesteps: 1,453,625,604

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351,858.84988
Policy Entropy: 3.64659
Value Function Loss: 0.03405

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12962
Policy Update Magnitude: 0.51601
Value Function Update Magnitude: 0.60475

Collected Steps per Second: 22,757.37643
Overall Steps per Second: 10,842.50012

Timestep Collection Time: 2.19718
Timestep Consumption Time: 2.41449
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.61167

Cumulative Model Updates: 174,314
Cumulative Timesteps: 1,453,675,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1453675606...
Checkpoint 1453675606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,858.84988
Policy Entropy: 3.64033
Value Function Loss: 0.03322

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13449
Policy Update Magnitude: 0.48584
Value Function Update Magnitude: 0.51213

Collected Steps per Second: 22,819.61386
Overall Steps per Second: 10,749.25298

Timestep Collection Time: 2.19180
Timestep Consumption Time: 2.46118
PPO Batch Consumption Time: 0.28620
Total Iteration Time: 4.65297

Cumulative Model Updates: 174,320
Cumulative Timesteps: 1,453,725,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 351,858.84988
Policy Entropy: 3.64502
Value Function Loss: 0.03000

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.43605
Value Function Update Magnitude: 0.46185

Collected Steps per Second: 22,084.67112
Overall Steps per Second: 10,813.50334

Timestep Collection Time: 2.26537
Timestep Consumption Time: 2.36125
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.62662

Cumulative Model Updates: 174,326
Cumulative Timesteps: 1,453,775,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1453775652...
Checkpoint 1453775652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,945.93674
Policy Entropy: 3.65473
Value Function Loss: 0.03539

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.41772
Value Function Update Magnitude: 0.44906

Collected Steps per Second: 21,779.38347
Overall Steps per Second: 10,782.31889

Timestep Collection Time: 2.29667
Timestep Consumption Time: 2.34241
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.63908

Cumulative Model Updates: 174,332
Cumulative Timesteps: 1,453,825,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,184.54328
Policy Entropy: 3.64952
Value Function Loss: 0.03347

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13133
Policy Update Magnitude: 0.44905
Value Function Update Magnitude: 0.67363

Collected Steps per Second: 21,890.61511
Overall Steps per Second: 10,501.27539

Timestep Collection Time: 2.28491
Timestep Consumption Time: 2.47813
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.76304

Cumulative Model Updates: 174,338
Cumulative Timesteps: 1,453,875,690

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1453875690...
Checkpoint 1453875690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,184.54328
Policy Entropy: 3.65862
Value Function Loss: 0.02970

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.43209
Value Function Update Magnitude: 0.65708

Collected Steps per Second: 22,819.32891
Overall Steps per Second: 10,910.40981

Timestep Collection Time: 2.19130
Timestep Consumption Time: 2.39185
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.58315

Cumulative Model Updates: 174,344
Cumulative Timesteps: 1,453,925,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 152,184.54328
Policy Entropy: 3.64744
Value Function Loss: 0.02814

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.43306
Value Function Update Magnitude: 0.61923

Collected Steps per Second: 22,905.41038
Overall Steps per Second: 10,912.74459

Timestep Collection Time: 2.18411
Timestep Consumption Time: 2.40025
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.58436

Cumulative Model Updates: 174,350
Cumulative Timesteps: 1,453,975,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1453975722...
Checkpoint 1453975722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371,417.40713
Policy Entropy: 3.66901
Value Function Loss: 0.02808

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.44571
Value Function Update Magnitude: 0.64915

Collected Steps per Second: 22,744.67998
Overall Steps per Second: 10,661.54001

Timestep Collection Time: 2.19840
Timestep Consumption Time: 2.49154
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.68994

Cumulative Model Updates: 174,356
Cumulative Timesteps: 1,454,025,724

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,692.57335
Policy Entropy: 3.66810
Value Function Loss: 0.03190

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.45585
Value Function Update Magnitude: 0.59158

Collected Steps per Second: 23,051.88254
Overall Steps per Second: 10,878.42381

Timestep Collection Time: 2.17023
Timestep Consumption Time: 2.42859
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.59883

Cumulative Model Updates: 174,362
Cumulative Timesteps: 1,454,075,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1454075752...
Checkpoint 1454075752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 628,959.89509
Policy Entropy: 3.66989
Value Function Loss: 0.03051

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12102
Policy Update Magnitude: 0.44445
Value Function Update Magnitude: 0.70120

Collected Steps per Second: 22,557.23228
Overall Steps per Second: 10,791.85169

Timestep Collection Time: 2.21729
Timestep Consumption Time: 2.41731
PPO Batch Consumption Time: 0.27676
Total Iteration Time: 4.63461

Cumulative Model Updates: 174,368
Cumulative Timesteps: 1,454,125,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,623.54325
Policy Entropy: 3.65629
Value Function Loss: 0.03525

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13399
Policy Update Magnitude: 0.46294
Value Function Update Magnitude: 0.73240

Collected Steps per Second: 22,772.05840
Overall Steps per Second: 10,795.02736

Timestep Collection Time: 2.19576
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.63195

Cumulative Model Updates: 174,374
Cumulative Timesteps: 1,454,175,770

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1454175770...
Checkpoint 1454175770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,069.78829
Policy Entropy: 3.64838
Value Function Loss: 0.04129

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.49547
Value Function Update Magnitude: 0.67798

Collected Steps per Second: 22,335.12459
Overall Steps per Second: 10,721.04057

Timestep Collection Time: 2.23898
Timestep Consumption Time: 2.42549
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.66447

Cumulative Model Updates: 174,380
Cumulative Timesteps: 1,454,225,778

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,407.03354
Policy Entropy: 3.66301
Value Function Loss: 0.04131

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.52578
Value Function Update Magnitude: 0.59054

Collected Steps per Second: 22,887.61664
Overall Steps per Second: 10,835.35447

Timestep Collection Time: 2.18642
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.61840

Cumulative Model Updates: 174,386
Cumulative Timesteps: 1,454,275,820

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1454275820...
Checkpoint 1454275820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,407.03354
Policy Entropy: 3.66471
Value Function Loss: 0.03399

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.49786
Value Function Update Magnitude: 0.51766

Collected Steps per Second: 22,555.23471
Overall Steps per Second: 10,689.77611

Timestep Collection Time: 2.21740
Timestep Consumption Time: 2.46128
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.67868

Cumulative Model Updates: 174,392
Cumulative Timesteps: 1,454,325,834

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,806.50969
Policy Entropy: 3.68336
Value Function Loss: 0.02708

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12365
Policy Update Magnitude: 0.45568
Value Function Update Magnitude: 0.57897

Collected Steps per Second: 23,035.17700
Overall Steps per Second: 10,851.61769

Timestep Collection Time: 2.17146
Timestep Consumption Time: 2.43799
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.60945

Cumulative Model Updates: 174,398
Cumulative Timesteps: 1,454,375,854

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1454375854...
Checkpoint 1454375854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.66284
Value Function Loss: 0.02604

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.43077
Value Function Update Magnitude: 0.64349

Collected Steps per Second: 22,643.58924
Overall Steps per Second: 10,683.65044

Timestep Collection Time: 2.20848
Timestep Consumption Time: 2.47231
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.68080

Cumulative Model Updates: 174,404
Cumulative Timesteps: 1,454,425,862

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.66523
Value Function Loss: 0.02420

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.40790
Value Function Update Magnitude: 0.67623

Collected Steps per Second: 22,987.08053
Overall Steps per Second: 10,882.55857

Timestep Collection Time: 2.17592
Timestep Consumption Time: 2.42024
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.59616

Cumulative Model Updates: 174,410
Cumulative Timesteps: 1,454,475,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1454475880...
Checkpoint 1454475880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.65061
Value Function Loss: 0.02434

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13898
Policy Update Magnitude: 0.39654
Value Function Update Magnitude: 0.60832

Collected Steps per Second: 22,370.47995
Overall Steps per Second: 10,649.07367

Timestep Collection Time: 2.23536
Timestep Consumption Time: 2.46045
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.69581

Cumulative Model Updates: 174,416
Cumulative Timesteps: 1,454,525,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.65413
Value Function Loss: 0.02281

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13533
Policy Update Magnitude: 0.41329
Value Function Update Magnitude: 0.58225

Collected Steps per Second: 23,053.47349
Overall Steps per Second: 10,848.09498

Timestep Collection Time: 2.16956
Timestep Consumption Time: 2.44101
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.61058

Cumulative Model Updates: 174,422
Cumulative Timesteps: 1,454,575,902

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1454575902...
Checkpoint 1454575902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.65394
Value Function Loss: 0.02163

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.14095
Policy Update Magnitude: 0.40434
Value Function Update Magnitude: 0.55930

Collected Steps per Second: 22,895.16812
Overall Steps per Second: 10,700.07013

Timestep Collection Time: 2.18465
Timestep Consumption Time: 2.48990
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.67455

Cumulative Model Updates: 174,428
Cumulative Timesteps: 1,454,625,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.66797
Value Function Loss: 0.01989

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.39655
Value Function Update Magnitude: 0.55319

Collected Steps per Second: 22,713.42459
Overall Steps per Second: 10,697.32517

Timestep Collection Time: 2.20213
Timestep Consumption Time: 2.47361
PPO Batch Consumption Time: 0.28579
Total Iteration Time: 4.67575

Cumulative Model Updates: 174,434
Cumulative Timesteps: 1,454,675,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1454675938...
Checkpoint 1454675938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.67703
Value Function Loss: 0.01830

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13257
Policy Update Magnitude: 0.38318
Value Function Update Magnitude: 0.55036

Collected Steps per Second: 22,823.21262
Overall Steps per Second: 10,845.48480

Timestep Collection Time: 2.19321
Timestep Consumption Time: 2.42217
PPO Batch Consumption Time: 0.27691
Total Iteration Time: 4.61538

Cumulative Model Updates: 174,440
Cumulative Timesteps: 1,454,725,994

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.67601
Value Function Loss: 0.02009

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12118
Policy Update Magnitude: 0.37118
Value Function Update Magnitude: 0.45736

Collected Steps per Second: 23,001.22412
Overall Steps per Second: 10,871.07364

Timestep Collection Time: 2.17388
Timestep Consumption Time: 2.42566
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.59955

Cumulative Model Updates: 174,446
Cumulative Timesteps: 1,454,775,996

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1454775996...
Checkpoint 1454775996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.67302
Value Function Loss: 0.01944

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.35415
Value Function Update Magnitude: 0.36424

Collected Steps per Second: 22,294.12560
Overall Steps per Second: 10,764.22374

Timestep Collection Time: 2.24400
Timestep Consumption Time: 2.40362
PPO Batch Consumption Time: 0.27587
Total Iteration Time: 4.64762

Cumulative Model Updates: 174,452
Cumulative Timesteps: 1,454,826,024

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.64882
Value Function Loss: 0.02139

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12844
Policy Update Magnitude: 0.34490
Value Function Update Magnitude: 0.32197

Collected Steps per Second: 22,277.28043
Overall Steps per Second: 10,912.88157

Timestep Collection Time: 2.24498
Timestep Consumption Time: 2.33786
PPO Batch Consumption Time: 0.27594
Total Iteration Time: 4.58284

Cumulative Model Updates: 174,458
Cumulative Timesteps: 1,454,876,036

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1454876036...
Checkpoint 1454876036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.65491
Value Function Loss: 0.02020

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.33537
Value Function Update Magnitude: 0.31013

Collected Steps per Second: 22,243.51539
Overall Steps per Second: 10,756.27889

Timestep Collection Time: 2.24830
Timestep Consumption Time: 2.40108
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.64938

Cumulative Model Updates: 174,464
Cumulative Timesteps: 1,454,926,046

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,374.61689
Policy Entropy: 3.64400
Value Function Loss: 0.02445

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.35080
Value Function Update Magnitude: 0.28999

Collected Steps per Second: 22,570.36452
Overall Steps per Second: 10,760.80478

Timestep Collection Time: 2.21600
Timestep Consumption Time: 2.43198
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.64798

Cumulative Model Updates: 174,470
Cumulative Timesteps: 1,454,976,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1454976062...
Checkpoint 1454976062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 536,588.27310
Policy Entropy: 3.66087
Value Function Loss: 0.02463

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.40447
Value Function Update Magnitude: 0.35323

Collected Steps per Second: 22,935.63367
Overall Steps per Second: 10,784.85865

Timestep Collection Time: 2.18141
Timestep Consumption Time: 2.45769
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.63910

Cumulative Model Updates: 174,476
Cumulative Timesteps: 1,455,026,094

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536,588.27310
Policy Entropy: 3.65146
Value Function Loss: 0.02751

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.44788
Value Function Update Magnitude: 0.38923

Collected Steps per Second: 22,803.19389
Overall Steps per Second: 10,724.86165

Timestep Collection Time: 2.19268
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.66206

Cumulative Model Updates: 174,482
Cumulative Timesteps: 1,455,076,094

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1455076094...
Checkpoint 1455076094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,392.96388
Policy Entropy: 3.66559
Value Function Loss: 0.02639

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13628
Policy Update Magnitude: 0.44805
Value Function Update Magnitude: 0.42725

Collected Steps per Second: 22,912.44310
Overall Steps per Second: 10,687.92899

Timestep Collection Time: 2.18353
Timestep Consumption Time: 2.49745
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.68098

Cumulative Model Updates: 174,488
Cumulative Timesteps: 1,455,126,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,392.96388
Policy Entropy: 3.66148
Value Function Loss: 0.02703

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.44710
Value Function Update Magnitude: 0.47041

Collected Steps per Second: 23,055.08658
Overall Steps per Second: 10,886.79852

Timestep Collection Time: 2.16959
Timestep Consumption Time: 2.42497
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.59456

Cumulative Model Updates: 174,494
Cumulative Timesteps: 1,455,176,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1455176144...
Checkpoint 1455176144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,392.96388
Policy Entropy: 3.66699
Value Function Loss: 0.02949

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.43460
Value Function Update Magnitude: 0.49069

Collected Steps per Second: 22,833.64597
Overall Steps per Second: 10,671.64398

Timestep Collection Time: 2.19098
Timestep Consumption Time: 2.49696
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.68794

Cumulative Model Updates: 174,500
Cumulative Timesteps: 1,455,226,172

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,392.96388
Policy Entropy: 3.65339
Value Function Loss: 0.02858

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.42829
Value Function Update Magnitude: 0.40886

Collected Steps per Second: 22,951.64276
Overall Steps per Second: 10,835.05470

Timestep Collection Time: 2.17893
Timestep Consumption Time: 2.43665
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.61557

Cumulative Model Updates: 174,506
Cumulative Timesteps: 1,455,276,182

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1455276182...
Checkpoint 1455276182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,392.96388
Policy Entropy: 3.66863
Value Function Loss: 0.02744

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.41023
Value Function Update Magnitude: 0.31682

Collected Steps per Second: 22,565.06135
Overall Steps per Second: 10,714.20055

Timestep Collection Time: 2.21626
Timestep Consumption Time: 2.45138
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.66764

Cumulative Model Updates: 174,512
Cumulative Timesteps: 1,455,326,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488,392.96388
Policy Entropy: 3.67805
Value Function Loss: 0.02559

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.38230
Value Function Update Magnitude: 0.26760

Collected Steps per Second: 22,917.93645
Overall Steps per Second: 10,833.93268

Timestep Collection Time: 2.18196
Timestep Consumption Time: 2.43372
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.61568

Cumulative Model Updates: 174,518
Cumulative Timesteps: 1,455,376,198

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1455376198...
Checkpoint 1455376198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206,889.87727
Policy Entropy: 3.69365
Value Function Loss: 0.02725

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12802
Policy Update Magnitude: 0.41925
Value Function Update Magnitude: 0.33819

Collected Steps per Second: 23,112.42094
Overall Steps per Second: 10,729.78681

Timestep Collection Time: 2.16429
Timestep Consumption Time: 2.49768
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.66198

Cumulative Model Updates: 174,524
Cumulative Timesteps: 1,455,426,220

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,958.89096
Policy Entropy: 3.68700
Value Function Loss: 0.02806

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14052
Policy Update Magnitude: 0.46943
Value Function Update Magnitude: 0.42611

Collected Steps per Second: 22,937.12499
Overall Steps per Second: 10,861.60071

Timestep Collection Time: 2.18074
Timestep Consumption Time: 2.42447
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.60521

Cumulative Model Updates: 174,530
Cumulative Timesteps: 1,455,476,240

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1455476240...
Checkpoint 1455476240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.70698
Value Function Loss: 0.02618

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12948
Policy Update Magnitude: 0.43983
Value Function Update Magnitude: 0.55134

Collected Steps per Second: 22,693.24305
Overall Steps per Second: 10,671.87449

Timestep Collection Time: 2.20409
Timestep Consumption Time: 2.48281
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.68690

Cumulative Model Updates: 174,536
Cumulative Timesteps: 1,455,526,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.69196
Value Function Loss: 0.02503

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.40557
Value Function Update Magnitude: 0.55890

Collected Steps per Second: 22,871.86573
Overall Steps per Second: 10,798.31155

Timestep Collection Time: 2.18653
Timestep Consumption Time: 2.44475
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.63128

Cumulative Model Updates: 174,542
Cumulative Timesteps: 1,455,576,268

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1455576268...
Checkpoint 1455576268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.66991
Value Function Loss: 0.02558

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.41929
Value Function Update Magnitude: 0.46784

Collected Steps per Second: 22,589.73878
Overall Steps per Second: 10,803.23943

Timestep Collection Time: 2.21428
Timestep Consumption Time: 2.41581
PPO Batch Consumption Time: 0.27579
Total Iteration Time: 4.63009

Cumulative Model Updates: 174,548
Cumulative Timesteps: 1,455,626,288

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.65145
Value Function Loss: 0.02305

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.43420
Value Function Update Magnitude: 0.38117

Collected Steps per Second: 22,901.15967
Overall Steps per Second: 10,843.53404

Timestep Collection Time: 2.18426
Timestep Consumption Time: 2.42882
PPO Batch Consumption Time: 0.27932
Total Iteration Time: 4.61307

Cumulative Model Updates: 174,554
Cumulative Timesteps: 1,455,676,310

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1455676310...
Checkpoint 1455676310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.66531
Value Function Loss: 0.02051

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.40961
Value Function Update Magnitude: 0.35697

Collected Steps per Second: 22,723.71465
Overall Steps per Second: 10,663.35613

Timestep Collection Time: 2.20114
Timestep Consumption Time: 2.48951
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.69064

Cumulative Model Updates: 174,560
Cumulative Timesteps: 1,455,726,328

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.66850
Value Function Loss: 0.01838

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.41119
Value Function Update Magnitude: 0.41015

Collected Steps per Second: 22,932.58829
Overall Steps per Second: 10,875.28190

Timestep Collection Time: 2.18109
Timestep Consumption Time: 2.41815
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.59924

Cumulative Model Updates: 174,566
Cumulative Timesteps: 1,455,776,346

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1455776346...
Checkpoint 1455776346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.65513
Value Function Loss: 0.02036

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13213
Policy Update Magnitude: 0.40283
Value Function Update Magnitude: 0.46113

Collected Steps per Second: 21,937.34886
Overall Steps per Second: 10,640.96825

Timestep Collection Time: 2.28004
Timestep Consumption Time: 2.42047
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.70051

Cumulative Model Updates: 174,572
Cumulative Timesteps: 1,455,826,364

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.65896
Value Function Loss: 0.02025

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.39012
Value Function Update Magnitude: 0.42901

Collected Steps per Second: 22,136.47869
Overall Steps per Second: 10,862.45914

Timestep Collection Time: 2.25935
Timestep Consumption Time: 2.34495
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.60430

Cumulative Model Updates: 174,578
Cumulative Timesteps: 1,455,876,378

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1455876378...
Checkpoint 1455876378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.66828
Value Function Loss: 0.02064

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.35183
Value Function Update Magnitude: 0.38836

Collected Steps per Second: 22,126.87191
Overall Steps per Second: 10,759.72129

Timestep Collection Time: 2.26060
Timestep Consumption Time: 2.38822
PPO Batch Consumption Time: 0.27550
Total Iteration Time: 4.64882

Cumulative Model Updates: 174,584
Cumulative Timesteps: 1,455,926,398

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.67578
Value Function Loss: 0.01936

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12366
Policy Update Magnitude: 0.34432
Value Function Update Magnitude: 0.36177

Collected Steps per Second: 22,604.95214
Overall Steps per Second: 10,828.19668

Timestep Collection Time: 2.21341
Timestep Consumption Time: 2.40731
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.62071

Cumulative Model Updates: 174,590
Cumulative Timesteps: 1,455,976,432

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1455976432...
Checkpoint 1455976432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.65756
Value Function Loss: 0.02406

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.32066
Value Function Update Magnitude: 0.32925

Collected Steps per Second: 22,508.55532
Overall Steps per Second: 10,666.08928

Timestep Collection Time: 2.22271
Timestep Consumption Time: 2.46786
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.69057

Cumulative Model Updates: 174,596
Cumulative Timesteps: 1,456,026,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.65705
Value Function Loss: 0.02283

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11974
Policy Update Magnitude: 0.37550
Value Function Update Magnitude: 0.28454

Collected Steps per Second: 23,229.38378
Overall Steps per Second: 10,923.27494

Timestep Collection Time: 2.15443
Timestep Consumption Time: 2.42717
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.58159

Cumulative Model Updates: 174,602
Cumulative Timesteps: 1,456,076,508

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1456076508...
Checkpoint 1456076508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.64801
Value Function Loss: 0.02508

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13388
Policy Update Magnitude: 0.43760
Value Function Update Magnitude: 0.27462

Collected Steps per Second: 22,756.97866
Overall Steps per Second: 10,643.00963

Timestep Collection Time: 2.19783
Timestep Consumption Time: 2.50159
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.69942

Cumulative Model Updates: 174,608
Cumulative Timesteps: 1,456,126,524

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.66009
Value Function Loss: 0.02300

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.48906
Value Function Update Magnitude: 0.29518

Collected Steps per Second: 22,850.31822
Overall Steps per Second: 10,840.72877

Timestep Collection Time: 2.18938
Timestep Consumption Time: 2.42544
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.61482

Cumulative Model Updates: 174,614
Cumulative Timesteps: 1,456,176,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1456176552...
Checkpoint 1456176552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,079.87071
Policy Entropy: 3.67046
Value Function Loss: 0.02276

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08335
Policy Update Magnitude: 0.53767
Value Function Update Magnitude: 0.32427

Collected Steps per Second: 22,858.16750
Overall Steps per Second: 10,703.48736

Timestep Collection Time: 2.18836
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.28630
Total Iteration Time: 4.67343

Cumulative Model Updates: 174,620
Cumulative Timesteps: 1,456,226,574

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,858.80427
Policy Entropy: 3.69814
Value Function Loss: 0.02307

Mean KL Divergence: 0.00545
SB3 Clip Fraction: 0.06387
Policy Update Magnitude: 0.56706
Value Function Update Magnitude: 0.34819

Collected Steps per Second: 22,557.04567
Overall Steps per Second: 10,668.25835

Timestep Collection Time: 2.21767
Timestep Consumption Time: 2.47138
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.68905

Cumulative Model Updates: 174,626
Cumulative Timesteps: 1,456,276,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1456276598...
Checkpoint 1456276598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,584.28948
Policy Entropy: 3.71656
Value Function Loss: 0.02191

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.06867
Policy Update Magnitude: 0.55484
Value Function Update Magnitude: 0.43839

Collected Steps per Second: 23,120.01780
Overall Steps per Second: 10,885.29806

Timestep Collection Time: 2.16444
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.59721

Cumulative Model Updates: 174,632
Cumulative Timesteps: 1,456,326,640

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,584.28948
Policy Entropy: 3.71690
Value Function Loss: 0.02142

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09764
Policy Update Magnitude: 0.49086
Value Function Update Magnitude: 0.45692

Collected Steps per Second: 22,964.73540
Overall Steps per Second: 10,831.34188

Timestep Collection Time: 2.17725
Timestep Consumption Time: 2.43898
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.61623

Cumulative Model Updates: 174,638
Cumulative Timesteps: 1,456,376,640

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1456376640...
Checkpoint 1456376640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,584.28948
Policy Entropy: 3.70208
Value Function Loss: 0.01988

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.07941
Policy Update Magnitude: 0.48197
Value Function Update Magnitude: 0.38395

Collected Steps per Second: 22,513.80616
Overall Steps per Second: 10,786.92033

Timestep Collection Time: 2.22193
Timestep Consumption Time: 2.41554
PPO Batch Consumption Time: 0.27650
Total Iteration Time: 4.63747

Cumulative Model Updates: 174,644
Cumulative Timesteps: 1,456,426,664

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,584.28948
Policy Entropy: 3.67945
Value Function Loss: 0.02079

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08729
Policy Update Magnitude: 0.54587
Value Function Update Magnitude: 0.32058

Collected Steps per Second: 22,693.83253
Overall Steps per Second: 10,800.85133

Timestep Collection Time: 2.20359
Timestep Consumption Time: 2.42641
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.63001

Cumulative Model Updates: 174,650
Cumulative Timesteps: 1,456,476,672

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1456476672...
Checkpoint 1456476672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,584.28948
Policy Entropy: 3.69917
Value Function Loss: 0.01935

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07972
Policy Update Magnitude: 0.57925
Value Function Update Magnitude: 0.36888

Collected Steps per Second: 22,598.32900
Overall Steps per Second: 10,700.46461

Timestep Collection Time: 2.21370
Timestep Consumption Time: 2.46142
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.67512

Cumulative Model Updates: 174,656
Cumulative Timesteps: 1,456,526,698

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,584.28948
Policy Entropy: 3.69778
Value Function Loss: 0.01911

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07827
Policy Update Magnitude: 0.54263
Value Function Update Magnitude: 0.39350

Collected Steps per Second: 22,852.37306
Overall Steps per Second: 10,841.47840

Timestep Collection Time: 2.18997
Timestep Consumption Time: 2.42619
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.61616

Cumulative Model Updates: 174,662
Cumulative Timesteps: 1,456,576,744

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1456576744...
Checkpoint 1456576744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,584.28948
Policy Entropy: 3.71607
Value Function Loss: 0.01705

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06717
Policy Update Magnitude: 0.49073
Value Function Update Magnitude: 0.34728

Collected Steps per Second: 22,825.65484
Overall Steps per Second: 10,692.01458

Timestep Collection Time: 2.19069
Timestep Consumption Time: 2.48607
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.67676

Cumulative Model Updates: 174,668
Cumulative Timesteps: 1,456,626,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,584.28948
Policy Entropy: 3.71561
Value Function Loss: 0.01543

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.42287
Value Function Update Magnitude: 0.30687

Collected Steps per Second: 22,822.53771
Overall Steps per Second: 10,837.91761

Timestep Collection Time: 2.19204
Timestep Consumption Time: 2.42397
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.61602

Cumulative Model Updates: 174,674
Cumulative Timesteps: 1,456,676,776

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1456676776...
Checkpoint 1456676776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 454,453.56179
Policy Entropy: 3.69857
Value Function Loss: 0.03047

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.16309
Policy Update Magnitude: 0.45831
Value Function Update Magnitude: 0.39020

Collected Steps per Second: 22,557.45114
Overall Steps per Second: 10,728.94548

Timestep Collection Time: 2.21772
Timestep Consumption Time: 2.44500
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.66271

Cumulative Model Updates: 174,680
Cumulative Timesteps: 1,456,726,802

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.70165
Value Function Loss: 0.03300

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.19635
Policy Update Magnitude: 0.49494
Value Function Update Magnitude: 0.49578

Collected Steps per Second: 22,067.77329
Overall Steps per Second: 10,817.77703

Timestep Collection Time: 2.26756
Timestep Consumption Time: 2.35816
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.62572

Cumulative Model Updates: 174,686
Cumulative Timesteps: 1,456,776,842

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1456776842...
Checkpoint 1456776842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.68203
Value Function Loss: 0.03677

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.19069
Policy Update Magnitude: 0.45266
Value Function Update Magnitude: 0.45341

Collected Steps per Second: 21,890.13602
Overall Steps per Second: 10,670.03512

Timestep Collection Time: 2.28550
Timestep Consumption Time: 2.40333
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.68883

Cumulative Model Updates: 174,692
Cumulative Timesteps: 1,456,826,872

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.69197
Value Function Loss: 0.02766

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.14305
Policy Update Magnitude: 0.42744
Value Function Update Magnitude: 0.35366

Collected Steps per Second: 22,210.30463
Overall Steps per Second: 10,856.88798

Timestep Collection Time: 2.25139
Timestep Consumption Time: 2.35435
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.60574

Cumulative Model Updates: 174,698
Cumulative Timesteps: 1,456,876,876

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1456876876...
Checkpoint 1456876876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.69604
Value Function Loss: 0.02025

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04997
Policy Update Magnitude: 0.48384
Value Function Update Magnitude: 0.33256

Collected Steps per Second: 22,070.09830
Overall Steps per Second: 10,694.45661

Timestep Collection Time: 2.26723
Timestep Consumption Time: 2.41164
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.67887

Cumulative Model Updates: 174,704
Cumulative Timesteps: 1,456,926,914

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.70023
Value Function Loss: 0.01663

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05147
Policy Update Magnitude: 0.48312
Value Function Update Magnitude: 0.31928

Collected Steps per Second: 22,855.39383
Overall Steps per Second: 10,861.47507

Timestep Collection Time: 2.18767
Timestep Consumption Time: 2.41576
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.60343

Cumulative Model Updates: 174,710
Cumulative Timesteps: 1,456,976,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1456976914...
Checkpoint 1456976914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.68601
Value Function Loss: 0.01805

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07791
Policy Update Magnitude: 0.45683
Value Function Update Magnitude: 0.30947

Collected Steps per Second: 22,619.88285
Overall Steps per Second: 10,724.40237

Timestep Collection Time: 2.21098
Timestep Consumption Time: 2.45241
PPO Batch Consumption Time: 0.28286
Total Iteration Time: 4.66338

Cumulative Model Updates: 174,716
Cumulative Timesteps: 1,457,026,926

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.68522
Value Function Loss: 0.02011

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.43196
Value Function Update Magnitude: 0.36077

Collected Steps per Second: 22,567.24446
Overall Steps per Second: 10,672.42258

Timestep Collection Time: 2.21640
Timestep Consumption Time: 2.47026
PPO Batch Consumption Time: 0.28814
Total Iteration Time: 4.68666

Cumulative Model Updates: 174,722
Cumulative Timesteps: 1,457,076,944

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1457076944...
Checkpoint 1457076944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.68233
Value Function Loss: 0.02471

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.40441
Value Function Update Magnitude: 0.32075

Collected Steps per Second: 22,067.37475
Overall Steps per Second: 10,552.44777

Timestep Collection Time: 2.26688
Timestep Consumption Time: 2.47364
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.74051

Cumulative Model Updates: 174,728
Cumulative Timesteps: 1,457,126,968

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.70133
Value Function Loss: 0.02392

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.39134
Value Function Update Magnitude: 0.25118

Collected Steps per Second: 23,247.27006
Overall Steps per Second: 10,797.47800

Timestep Collection Time: 2.15113
Timestep Consumption Time: 2.48032
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.63145

Cumulative Model Updates: 174,734
Cumulative Timesteps: 1,457,176,976

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1457176976...
Checkpoint 1457176976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.69754
Value Function Loss: 0.02355

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14150
Policy Update Magnitude: 0.37417
Value Function Update Magnitude: 0.25564

Collected Steps per Second: 22,631.15400
Overall Steps per Second: 10,620.65741

Timestep Collection Time: 2.21005
Timestep Consumption Time: 2.49926
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.70931

Cumulative Model Updates: 174,740
Cumulative Timesteps: 1,457,226,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.68305
Value Function Loss: 0.02731

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.18056
Policy Update Magnitude: 0.39471
Value Function Update Magnitude: 0.26983

Collected Steps per Second: 22,933.76781
Overall Steps per Second: 10,882.60773

Timestep Collection Time: 2.18071
Timestep Consumption Time: 2.41488
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.59559

Cumulative Model Updates: 174,746
Cumulative Timesteps: 1,457,277,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1457277004...
Checkpoint 1457277004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.68832
Value Function Loss: 0.02764

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14682
Policy Update Magnitude: 0.39066
Value Function Update Magnitude: 0.25043

Collected Steps per Second: 21,950.00037
Overall Steps per Second: 10,686.76169

Timestep Collection Time: 2.27909
Timestep Consumption Time: 2.40203
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.68112

Cumulative Model Updates: 174,752
Cumulative Timesteps: 1,457,327,030

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,531.82213
Policy Entropy: 3.66737
Value Function Loss: 0.03371

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.43932
Value Function Update Magnitude: 0.29047

Collected Steps per Second: 22,189.40357
Overall Steps per Second: 10,858.23602

Timestep Collection Time: 2.25468
Timestep Consumption Time: 2.35288
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.60756

Cumulative Model Updates: 174,758
Cumulative Timesteps: 1,457,377,060

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1457377060...
Checkpoint 1457377060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 215,111.00390
Policy Entropy: 3.68416
Value Function Loss: 0.03459

Mean KL Divergence: 0.01134
SB3 Clip Fraction: 0.14340
Policy Update Magnitude: 0.56869
Value Function Update Magnitude: 0.28361

Collected Steps per Second: 21,908.38715
Overall Steps per Second: 10,655.78341

Timestep Collection Time: 2.28296
Timestep Consumption Time: 2.41083
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.69379

Cumulative Model Updates: 174,764
Cumulative Timesteps: 1,457,427,076

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,111.00390
Policy Entropy: 3.68924
Value Function Loss: 0.03236

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.20543
Policy Update Magnitude: 0.53869
Value Function Update Magnitude: 0.50532

Collected Steps per Second: 22,911.46419
Overall Steps per Second: 10,906.21376

Timestep Collection Time: 2.18354
Timestep Consumption Time: 2.40357
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.58711

Cumulative Model Updates: 174,770
Cumulative Timesteps: 1,457,477,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1457477104...
Checkpoint 1457477104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,624.03973
Policy Entropy: 3.70411
Value Function Loss: 0.02953

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.17432
Policy Update Magnitude: 0.50182
Value Function Update Magnitude: 0.60170

Collected Steps per Second: 22,530.53966
Overall Steps per Second: 10,668.54237

Timestep Collection Time: 2.22019
Timestep Consumption Time: 2.46855
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.68874

Cumulative Model Updates: 174,776
Cumulative Timesteps: 1,457,527,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 594,203.35358
Policy Entropy: 3.68796
Value Function Loss: 0.03075

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.15593
Policy Update Magnitude: 0.49202
Value Function Update Magnitude: 0.64174

Collected Steps per Second: 23,131.85500
Overall Steps per Second: 10,882.36347

Timestep Collection Time: 2.16178
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.59514

Cumulative Model Updates: 174,782
Cumulative Timesteps: 1,457,577,132

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1457577132...
Checkpoint 1457577132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 594,203.35358
Policy Entropy: 3.68449
Value Function Loss: 0.03140

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.50294
Value Function Update Magnitude: 0.62128

Collected Steps per Second: 22,618.55592
Overall Steps per Second: 10,645.23375

Timestep Collection Time: 2.21146
Timestep Consumption Time: 2.48736
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.69882

Cumulative Model Updates: 174,788
Cumulative Timesteps: 1,457,627,152

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 755,156.23355
Policy Entropy: 3.66811
Value Function Loss: 0.03663

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.51076
Value Function Update Magnitude: 0.49470

Collected Steps per Second: 22,854.97368
Overall Steps per Second: 10,841.82901

Timestep Collection Time: 2.18858
Timestep Consumption Time: 2.42503
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.61361

Cumulative Model Updates: 174,794
Cumulative Timesteps: 1,457,677,172

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1457677172...
Checkpoint 1457677172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 263,322.89987
Policy Entropy: 3.67062
Value Function Loss: 0.03689

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14359
Policy Update Magnitude: 0.52859
Value Function Update Magnitude: 0.42807

Collected Steps per Second: 22,696.92100
Overall Steps per Second: 10,755.09780

Timestep Collection Time: 2.20356
Timestep Consumption Time: 2.44670
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.65026

Cumulative Model Updates: 174,800
Cumulative Timesteps: 1,457,727,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,816.72731
Policy Entropy: 3.67910
Value Function Loss: 0.03692

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14431
Policy Update Magnitude: 0.49257
Value Function Update Magnitude: 0.43472

Collected Steps per Second: 23,026.84961
Overall Steps per Second: 10,863.49810

Timestep Collection Time: 2.17338
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.60680

Cumulative Model Updates: 174,806
Cumulative Timesteps: 1,457,777,232

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1457777232...
Checkpoint 1457777232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,539.01746
Policy Entropy: 3.69095
Value Function Loss: 0.03325

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.51080
Value Function Update Magnitude: 0.50930

Collected Steps per Second: 22,428.07385
Overall Steps per Second: 10,650.31201

Timestep Collection Time: 2.23113
Timestep Consumption Time: 2.46732
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.69845

Cumulative Model Updates: 174,812
Cumulative Timesteps: 1,457,827,272

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,539.01746
Policy Entropy: 3.68044
Value Function Loss: 0.02799

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07383
Policy Update Magnitude: 0.60232
Value Function Update Magnitude: 0.55183

Collected Steps per Second: 23,083.36799
Overall Steps per Second: 10,864.36721

Timestep Collection Time: 2.16641
Timestep Consumption Time: 2.43653
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.60294

Cumulative Model Updates: 174,818
Cumulative Timesteps: 1,457,877,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1457877280...
Checkpoint 1457877280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,539.01746
Policy Entropy: 3.67359
Value Function Loss: 0.02206

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.17919
Policy Update Magnitude: 0.52808
Value Function Update Magnitude: 0.50934

Collected Steps per Second: 22,520.79616
Overall Steps per Second: 10,713.60474

Timestep Collection Time: 2.22177
Timestep Consumption Time: 2.44855
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.67032

Cumulative Model Updates: 174,824
Cumulative Timesteps: 1,457,927,316

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,539.01746
Policy Entropy: 3.69136
Value Function Loss: 0.01726

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.38563
Value Function Update Magnitude: 0.43519

Collected Steps per Second: 22,780.89503
Overall Steps per Second: 10,844.17814

Timestep Collection Time: 2.19579
Timestep Consumption Time: 2.41701
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.61280

Cumulative Model Updates: 174,830
Cumulative Timesteps: 1,457,977,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1457977338...
Checkpoint 1457977338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,539.01746
Policy Entropy: 3.70690
Value Function Loss: 0.01638

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11476
Policy Update Magnitude: 0.33912
Value Function Update Magnitude: 0.39839

Collected Steps per Second: 22,609.58150
Overall Steps per Second: 10,673.22075

Timestep Collection Time: 2.21296
Timestep Consumption Time: 2.47485
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.68781

Cumulative Model Updates: 174,836
Cumulative Timesteps: 1,458,027,372

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,539.01746
Policy Entropy: 3.68556
Value Function Loss: 0.01752

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12429
Policy Update Magnitude: 0.33739
Value Function Update Magnitude: 0.39783

Collected Steps per Second: 22,850.56453
Overall Steps per Second: 10,715.00142

Timestep Collection Time: 2.18901
Timestep Consumption Time: 2.47922
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.66822

Cumulative Model Updates: 174,842
Cumulative Timesteps: 1,458,077,392

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1458077392...
Checkpoint 1458077392 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,539.01746
Policy Entropy: 3.67006
Value Function Loss: 0.01963

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.37604
Value Function Update Magnitude: 0.45564

Collected Steps per Second: 22,349.01573
Overall Steps per Second: 10,639.34656

Timestep Collection Time: 2.23885
Timestep Consumption Time: 2.46407
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.70292

Cumulative Model Updates: 174,848
Cumulative Timesteps: 1,458,127,428

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,539.01746
Policy Entropy: 3.64431
Value Function Loss: 0.02282

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.40046
Value Function Update Magnitude: 0.46597

Collected Steps per Second: 22,565.92436
Overall Steps per Second: 10,690.62200

Timestep Collection Time: 2.21635
Timestep Consumption Time: 2.46196
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.67831

Cumulative Model Updates: 174,854
Cumulative Timesteps: 1,458,177,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1458177442...
Checkpoint 1458177442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220,642.73300
Policy Entropy: 3.64957
Value Function Loss: 0.02782

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13855
Policy Update Magnitude: 0.42017
Value Function Update Magnitude: 0.56617

Collected Steps per Second: 22,593.77841
Overall Steps per Second: 10,610.17502

Timestep Collection Time: 2.21344
Timestep Consumption Time: 2.49996
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.71340

Cumulative Model Updates: 174,860
Cumulative Timesteps: 1,458,227,452

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,957.61282
Policy Entropy: 3.68237
Value Function Loss: 0.02828

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.44591
Value Function Update Magnitude: 0.64487

Collected Steps per Second: 23,153.17472
Overall Steps per Second: 10,871.94082

Timestep Collection Time: 2.16074
Timestep Consumption Time: 2.44083
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.60157

Cumulative Model Updates: 174,866
Cumulative Timesteps: 1,458,277,480

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1458277480...
Checkpoint 1458277480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,957.61282
Policy Entropy: 3.69341
Value Function Loss: 0.02917

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12240
Policy Update Magnitude: 0.47735
Value Function Update Magnitude: 0.67197

Collected Steps per Second: 21,998.77252
Overall Steps per Second: 10,691.91020

Timestep Collection Time: 2.27294
Timestep Consumption Time: 2.40367
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.67662

Cumulative Model Updates: 174,872
Cumulative Timesteps: 1,458,327,482

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,957.61282
Policy Entropy: 3.68571
Value Function Loss: 0.02584

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.46815
Value Function Update Magnitude: 0.56935

Collected Steps per Second: 22,260.08164
Overall Steps per Second: 10,841.17026

Timestep Collection Time: 2.24626
Timestep Consumption Time: 2.36597
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.61223

Cumulative Model Updates: 174,878
Cumulative Timesteps: 1,458,377,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1458377484...
Checkpoint 1458377484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,957.61282
Policy Entropy: 3.65815
Value Function Loss: 0.02598

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.42742
Value Function Update Magnitude: 0.52689

Collected Steps per Second: 21,831.28054
Overall Steps per Second: 10,656.01556

Timestep Collection Time: 2.29130
Timestep Consumption Time: 2.40295
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.69425

Cumulative Model Updates: 174,884
Cumulative Timesteps: 1,458,427,506

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 444,056.74128
Policy Entropy: 3.65206
Value Function Loss: 0.03163

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12889
Policy Update Magnitude: 0.46939
Value Function Update Magnitude: 0.49404

Collected Steps per Second: 23,057.28962
Overall Steps per Second: 10,931.70507

Timestep Collection Time: 2.16851
Timestep Consumption Time: 2.40534
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.57385

Cumulative Model Updates: 174,890
Cumulative Timesteps: 1,458,477,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1458477506...
Checkpoint 1458477506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 689,481.16357
Policy Entropy: 3.64674
Value Function Loss: 0.04060

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13589
Policy Update Magnitude: 0.49956
Value Function Update Magnitude: 0.54213

Collected Steps per Second: 22,484.05012
Overall Steps per Second: 10,665.73676

Timestep Collection Time: 2.22442
Timestep Consumption Time: 2.46480
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.68922

Cumulative Model Updates: 174,896
Cumulative Timesteps: 1,458,527,520

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 882,140.11839
Policy Entropy: 3.66084
Value Function Loss: 0.04418

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13988
Policy Update Magnitude: 0.49472
Value Function Update Magnitude: 0.54280

Collected Steps per Second: 23,100.54561
Overall Steps per Second: 10,888.77332

Timestep Collection Time: 2.16540
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.59391

Cumulative Model Updates: 174,902
Cumulative Timesteps: 1,458,577,542

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1458577542...
Checkpoint 1458577542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,778.59889
Policy Entropy: 3.66972
Value Function Loss: 0.04364

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.51524
Value Function Update Magnitude: 0.47205

Collected Steps per Second: 22,684.20922
Overall Steps per Second: 10,656.54594

Timestep Collection Time: 2.20541
Timestep Consumption Time: 2.48917
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.69458

Cumulative Model Updates: 174,908
Cumulative Timesteps: 1,458,627,570

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,778.59889
Policy Entropy: 3.65879
Value Function Loss: 0.03794

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12848
Policy Update Magnitude: 0.49088
Value Function Update Magnitude: 0.43967

Collected Steps per Second: 22,940.96218
Overall Steps per Second: 10,879.40336

Timestep Collection Time: 2.18012
Timestep Consumption Time: 2.41701
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.59713

Cumulative Model Updates: 174,914
Cumulative Timesteps: 1,458,677,584

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1458677584...
Checkpoint 1458677584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 456,055.29448
Policy Entropy: 3.67552
Value Function Loss: 0.03251

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.46064
Value Function Update Magnitude: 0.44582

Collected Steps per Second: 22,286.85550
Overall Steps per Second: 10,677.52113

Timestep Collection Time: 2.24518
Timestep Consumption Time: 2.44111
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.68629

Cumulative Model Updates: 174,920
Cumulative Timesteps: 1,458,727,622

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 369,401.56791
Policy Entropy: 3.68455
Value Function Loss: 0.02518

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14976
Policy Update Magnitude: 0.41672
Value Function Update Magnitude: 0.49021

Collected Steps per Second: 22,847.97547
Overall Steps per Second: 10,829.49163

Timestep Collection Time: 2.18838
Timestep Consumption Time: 2.42864
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.61702

Cumulative Model Updates: 174,926
Cumulative Timesteps: 1,458,777,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1458777622...
Checkpoint 1458777622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.69742
Value Function Loss: 0.02412

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10012
Policy Update Magnitude: 0.41079
Value Function Update Magnitude: 0.54081

Collected Steps per Second: 22,541.78048
Overall Steps per Second: 10,741.34228

Timestep Collection Time: 2.21846
Timestep Consumption Time: 2.43720
PPO Batch Consumption Time: 0.28226
Total Iteration Time: 4.65566

Cumulative Model Updates: 174,932
Cumulative Timesteps: 1,458,827,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.67865
Value Function Loss: 0.02154

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06432
Policy Update Magnitude: 0.47591
Value Function Update Magnitude: 0.53124

Collected Steps per Second: 22,467.99281
Overall Steps per Second: 10,953.02603

Timestep Collection Time: 2.22637
Timestep Consumption Time: 2.34059
PPO Batch Consumption Time: 0.27605
Total Iteration Time: 4.56696

Cumulative Model Updates: 174,938
Cumulative Timesteps: 1,458,877,652

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1458877652...
Checkpoint 1458877652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.68056
Value Function Loss: 0.01924

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06299
Policy Update Magnitude: 0.47035
Value Function Update Magnitude: 0.47123

Collected Steps per Second: 21,953.35903
Overall Steps per Second: 10,637.62871

Timestep Collection Time: 2.27792
Timestep Consumption Time: 2.42313
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.70105

Cumulative Model Updates: 174,944
Cumulative Timesteps: 1,458,927,660

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.67628
Value Function Loss: 0.01871

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06150
Policy Update Magnitude: 0.48414
Value Function Update Magnitude: 0.40331

Collected Steps per Second: 22,214.89413
Overall Steps per Second: 10,743.47806

Timestep Collection Time: 2.25191
Timestep Consumption Time: 2.40449
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.65641

Cumulative Model Updates: 174,950
Cumulative Timesteps: 1,458,977,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1458977686...
Checkpoint 1458977686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.67572
Value Function Loss: 0.02218

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09069
Policy Update Magnitude: 0.53444
Value Function Update Magnitude: 0.41198

Collected Steps per Second: 22,604.60381
Overall Steps per Second: 10,752.03645

Timestep Collection Time: 2.21229
Timestep Consumption Time: 2.43873
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.65103

Cumulative Model Updates: 174,956
Cumulative Timesteps: 1,459,027,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.67263
Value Function Loss: 0.02510

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14915
Policy Update Magnitude: 0.47033
Value Function Update Magnitude: 0.48053

Collected Steps per Second: 23,020.65073
Overall Steps per Second: 10,981.36177

Timestep Collection Time: 2.17370
Timestep Consumption Time: 2.38311
PPO Batch Consumption Time: 0.27578
Total Iteration Time: 4.55681

Cumulative Model Updates: 174,962
Cumulative Timesteps: 1,459,077,734

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1459077734...
Checkpoint 1459077734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.65993
Value Function Loss: 0.03131

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.16902
Policy Update Magnitude: 0.44990
Value Function Update Magnitude: 0.45669

Collected Steps per Second: 22,542.85089
Overall Steps per Second: 10,608.74786

Timestep Collection Time: 2.21853
Timestep Consumption Time: 2.49569
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.71422

Cumulative Model Updates: 174,968
Cumulative Timesteps: 1,459,127,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.65769
Value Function Loss: 0.02951

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15985
Policy Update Magnitude: 0.43925
Value Function Update Magnitude: 0.35496

Collected Steps per Second: 23,151.55762
Overall Steps per Second: 10,931.09520

Timestep Collection Time: 2.16037
Timestep Consumption Time: 2.41520
PPO Batch Consumption Time: 0.27602
Total Iteration Time: 4.57557

Cumulative Model Updates: 174,974
Cumulative Timesteps: 1,459,177,762

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1459177762...
Checkpoint 1459177762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.65496
Value Function Loss: 0.02635

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15833
Policy Update Magnitude: 0.40717
Value Function Update Magnitude: 0.31624

Collected Steps per Second: 22,890.15354
Overall Steps per Second: 10,719.12144

Timestep Collection Time: 2.18478
Timestep Consumption Time: 2.48071
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.66549

Cumulative Model Updates: 174,980
Cumulative Timesteps: 1,459,227,772

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.65817
Value Function Loss: 0.02408

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.37316
Value Function Update Magnitude: 0.34876

Collected Steps per Second: 22,882.61172
Overall Steps per Second: 10,772.78774

Timestep Collection Time: 2.18629
Timestep Consumption Time: 2.45763
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.64392

Cumulative Model Updates: 174,986
Cumulative Timesteps: 1,459,277,800

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1459277800...
Checkpoint 1459277800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.66199
Value Function Loss: 0.02366

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.37464
Value Function Update Magnitude: 0.39681

Collected Steps per Second: 22,625.30891
Overall Steps per Second: 10,623.14513

Timestep Collection Time: 2.21195
Timestep Consumption Time: 2.49909
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.71103

Cumulative Model Updates: 174,992
Cumulative Timesteps: 1,459,327,846

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.65661
Value Function Loss: 0.02319

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.34636
Value Function Update Magnitude: 0.42510

Collected Steps per Second: 22,810.66048
Overall Steps per Second: 10,819.47695

Timestep Collection Time: 2.19266
Timestep Consumption Time: 2.43012
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.62277

Cumulative Model Updates: 174,998
Cumulative Timesteps: 1,459,377,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1459377862...
Checkpoint 1459377862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.65824
Value Function Loss: 0.02050

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.31428
Value Function Update Magnitude: 0.35399

Collected Steps per Second: 22,729.27028
Overall Steps per Second: 10,735.69866

Timestep Collection Time: 2.20042
Timestep Consumption Time: 2.45824
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.65866

Cumulative Model Updates: 175,004
Cumulative Timesteps: 1,459,427,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.65254
Value Function Loss: 0.02041

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.29295
Value Function Update Magnitude: 0.27927

Collected Steps per Second: 23,097.32164
Overall Steps per Second: 10,910.74458

Timestep Collection Time: 2.16527
Timestep Consumption Time: 2.41847
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.58374

Cumulative Model Updates: 175,010
Cumulative Timesteps: 1,459,477,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1459477888...
Checkpoint 1459477888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.65179
Value Function Loss: 0.01989

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.28423
Value Function Update Magnitude: 0.27826

Collected Steps per Second: 22,885.28395
Overall Steps per Second: 10,703.03966

Timestep Collection Time: 2.18621
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.67456

Cumulative Model Updates: 175,016
Cumulative Timesteps: 1,459,527,920

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.65358
Value Function Loss: 0.02072

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13707
Policy Update Magnitude: 0.30235
Value Function Update Magnitude: 0.30465

Collected Steps per Second: 21,494.09437
Overall Steps per Second: 10,378.10863

Timestep Collection Time: 2.32724
Timestep Consumption Time: 2.49271
PPO Batch Consumption Time: 0.28480
Total Iteration Time: 4.81995

Cumulative Model Updates: 175,022
Cumulative Timesteps: 1,459,577,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1459577942...
Checkpoint 1459577942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 608,422.85903
Policy Entropy: 3.64948
Value Function Loss: 0.02154

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13114
Policy Update Magnitude: 0.32027
Value Function Update Magnitude: 0.27606

Collected Steps per Second: 21,818.53120
Overall Steps per Second: 10,621.71238

Timestep Collection Time: 2.29181
Timestep Consumption Time: 2.41590
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.70772

Cumulative Model Updates: 175,028
Cumulative Timesteps: 1,459,627,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,403,569.31867
Policy Entropy: 3.64654
Value Function Loss: 0.02508

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.35980
Value Function Update Magnitude: 0.33916

Collected Steps per Second: 22,124.29688
Overall Steps per Second: 10,741.79949

Timestep Collection Time: 2.26141
Timestep Consumption Time: 2.39629
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.65769

Cumulative Model Updates: 175,034
Cumulative Timesteps: 1,459,677,978

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1459677978...
Checkpoint 1459677978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 436,442.96482
Policy Entropy: 3.65337
Value Function Loss: 0.03300

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.43648
Value Function Update Magnitude: 0.43820

Collected Steps per Second: 21,976.96264
Overall Steps per Second: 10,830.29224

Timestep Collection Time: 2.27593
Timestep Consumption Time: 2.34241
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.61834

Cumulative Model Updates: 175,040
Cumulative Timesteps: 1,459,727,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,486.99351
Policy Entropy: 3.67794
Value Function Loss: 0.03813

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.49081
Value Function Update Magnitude: 0.53131

Collected Steps per Second: 22,206.81969
Overall Steps per Second: 10,714.64014

Timestep Collection Time: 2.25201
Timestep Consumption Time: 2.41543
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.66745

Cumulative Model Updates: 175,046
Cumulative Timesteps: 1,459,778,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1459778006...
Checkpoint 1459778006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,451.79392
Policy Entropy: 3.67075
Value Function Loss: 0.04641

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.51821
Value Function Update Magnitude: 0.56572

Collected Steps per Second: 22,218.47940
Overall Steps per Second: 10,626.29979

Timestep Collection Time: 2.25083
Timestep Consumption Time: 2.45542
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.70625

Cumulative Model Updates: 175,052
Cumulative Timesteps: 1,459,828,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,372,762.86187
Policy Entropy: 3.67594
Value Function Loss: 0.04626

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.53791
Value Function Update Magnitude: 0.67429

Collected Steps per Second: 23,140.66727
Overall Steps per Second: 10,796.32395

Timestep Collection Time: 2.16199
Timestep Consumption Time: 2.47199
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.63398

Cumulative Model Updates: 175,058
Cumulative Timesteps: 1,459,878,046

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1459878046...
Checkpoint 1459878046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,924.05667
Policy Entropy: 3.67956
Value Function Loss: 0.04822

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.55453
Value Function Update Magnitude: 0.71786

Collected Steps per Second: 22,499.81511
Overall Steps per Second: 10,672.08601

Timestep Collection Time: 2.22295
Timestep Consumption Time: 2.46367
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.68662

Cumulative Model Updates: 175,064
Cumulative Timesteps: 1,459,928,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,719.93919
Policy Entropy: 3.69910
Value Function Loss: 0.04072

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.58288
Value Function Update Magnitude: 0.76016

Collected Steps per Second: 23,299.78951
Overall Steps per Second: 10,769.05551

Timestep Collection Time: 2.14792
Timestep Consumption Time: 2.49929
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.64720

Cumulative Model Updates: 175,070
Cumulative Timesteps: 1,459,978,108

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1459978108...
Checkpoint 1459978108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,771.73579
Policy Entropy: 3.67959
Value Function Loss: 0.04223

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14061
Policy Update Magnitude: 0.56850
Value Function Update Magnitude: 0.64529

Collected Steps per Second: 22,642.96205
Overall Steps per Second: 10,642.21139

Timestep Collection Time: 2.20863
Timestep Consumption Time: 2.49058
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.69921

Cumulative Model Updates: 175,076
Cumulative Timesteps: 1,460,028,118

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,934.79611
Policy Entropy: 3.65458
Value Function Loss: 0.03693

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.51231
Value Function Update Magnitude: 0.53178

Collected Steps per Second: 23,188.44288
Overall Steps per Second: 10,913.10889

Timestep Collection Time: 2.15737
Timestep Consumption Time: 2.42666
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.58403

Cumulative Model Updates: 175,082
Cumulative Timesteps: 1,460,078,144

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1460078144...
Checkpoint 1460078144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,098.50780
Policy Entropy: 3.65313
Value Function Loss: 0.04563

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.14072
Policy Update Magnitude: 0.48549
Value Function Update Magnitude: 0.53066

Collected Steps per Second: 22,541.79109
Overall Steps per Second: 10,803.07773

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.41117
PPO Batch Consumption Time: 0.27603
Total Iteration Time: 4.63016

Cumulative Model Updates: 175,088
Cumulative Timesteps: 1,460,128,164

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,098.50780
Policy Entropy: 3.66574
Value Function Loss: 0.03011

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.45489
Value Function Update Magnitude: 0.58608

Collected Steps per Second: 22,942.51310
Overall Steps per Second: 10,886.29383

Timestep Collection Time: 2.17971
Timestep Consumption Time: 2.41396
PPO Batch Consumption Time: 0.27656
Total Iteration Time: 4.59367

Cumulative Model Updates: 175,094
Cumulative Timesteps: 1,460,178,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1460178172...
Checkpoint 1460178172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,090.65599
Policy Entropy: 3.66841
Value Function Loss: 0.03028

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.46105
Value Function Update Magnitude: 0.75869

Collected Steps per Second: 22,618.24694
Overall Steps per Second: 10,649.83033

Timestep Collection Time: 2.21255
Timestep Consumption Time: 2.48649
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.69904

Cumulative Model Updates: 175,100
Cumulative Timesteps: 1,460,228,216

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,090.65599
Policy Entropy: 3.65231
Value Function Loss: 0.03266

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.46735
Value Function Update Magnitude: 0.76254

Collected Steps per Second: 23,205.27810
Overall Steps per Second: 10,892.03877

Timestep Collection Time: 2.15546
Timestep Consumption Time: 2.43670
PPO Batch Consumption Time: 0.28201
Total Iteration Time: 4.59216

Cumulative Model Updates: 175,106
Cumulative Timesteps: 1,460,278,234

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1460278234...
Checkpoint 1460278234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,090.65599
Policy Entropy: 3.66042
Value Function Loss: 0.02872

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13890
Policy Update Magnitude: 0.48641
Value Function Update Magnitude: 0.67496

Collected Steps per Second: 22,662.12573
Overall Steps per Second: 10,665.84412

Timestep Collection Time: 2.20756
Timestep Consumption Time: 2.48293
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.69049

Cumulative Model Updates: 175,112
Cumulative Timesteps: 1,460,328,262

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093,981.78279
Policy Entropy: 3.66889
Value Function Loss: 0.03254

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.46422
Value Function Update Magnitude: 0.58725

Collected Steps per Second: 22,528.53093
Overall Steps per Second: 10,867.98886

Timestep Collection Time: 2.22136
Timestep Consumption Time: 2.38335
PPO Batch Consumption Time: 0.28318
Total Iteration Time: 4.60472

Cumulative Model Updates: 175,118
Cumulative Timesteps: 1,460,378,306

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1460378306...
Checkpoint 1460378306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093,981.78279
Policy Entropy: 3.68707
Value Function Loss: 0.02726

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13397
Policy Update Magnitude: 0.46064
Value Function Update Magnitude: 0.57983

Collected Steps per Second: 21,953.77829
Overall Steps per Second: 10,623.41908

Timestep Collection Time: 2.27815
Timestep Consumption Time: 2.42975
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.70790

Cumulative Model Updates: 175,124
Cumulative Timesteps: 1,460,428,320

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,093,981.78279
Policy Entropy: 3.66887
Value Function Loss: 0.02981

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.46956
Value Function Update Magnitude: 0.63986

Collected Steps per Second: 22,551.02208
Overall Steps per Second: 10,836.13572

Timestep Collection Time: 2.21941
Timestep Consumption Time: 2.39939
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.61881

Cumulative Model Updates: 175,130
Cumulative Timesteps: 1,460,478,370

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1460478370...
Checkpoint 1460478370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,552.72084
Policy Entropy: 3.66640
Value Function Loss: 0.03681

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13968
Policy Update Magnitude: 0.53504
Value Function Update Magnitude: 0.64373

Collected Steps per Second: 22,214.36803
Overall Steps per Second: 10,773.81510

Timestep Collection Time: 2.25188
Timestep Consumption Time: 2.39123
PPO Batch Consumption Time: 0.27611
Total Iteration Time: 4.64311

Cumulative Model Updates: 175,136
Cumulative Timesteps: 1,460,528,394

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,400.86995
Policy Entropy: 3.68253
Value Function Loss: 0.04337

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14554
Policy Update Magnitude: 0.56354
Value Function Update Magnitude: 0.76816

Collected Steps per Second: 23,235.11456
Overall Steps per Second: 10,862.86376

Timestep Collection Time: 2.15252
Timestep Consumption Time: 2.45161
PPO Batch Consumption Time: 0.28617
Total Iteration Time: 4.60413

Cumulative Model Updates: 175,142
Cumulative Timesteps: 1,460,578,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1460578408...
Checkpoint 1460578408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,648.83029
Policy Entropy: 3.70971
Value Function Loss: 0.03885

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.55542
Value Function Update Magnitude: 0.71128

Collected Steps per Second: 22,632.02186
Overall Steps per Second: 10,642.31498

Timestep Collection Time: 2.20952
Timestep Consumption Time: 2.48927
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.69879

Cumulative Model Updates: 175,148
Cumulative Timesteps: 1,460,628,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,648.83029
Policy Entropy: 3.70142
Value Function Loss: 0.03099

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.47068
Value Function Update Magnitude: 0.61926

Collected Steps per Second: 23,058.98436
Overall Steps per Second: 10,887.53379

Timestep Collection Time: 2.16957
Timestep Consumption Time: 2.42541
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.59498

Cumulative Model Updates: 175,154
Cumulative Timesteps: 1,460,678,442

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1460678442...
Checkpoint 1460678442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,648.83029
Policy Entropy: 3.67559
Value Function Loss: 0.02352

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.39416
Value Function Update Magnitude: 0.47936

Collected Steps per Second: 22,690.65191
Overall Steps per Second: 10,668.67051

Timestep Collection Time: 2.20373
Timestep Consumption Time: 2.48327
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.68699

Cumulative Model Updates: 175,160
Cumulative Timesteps: 1,460,728,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,648.83029
Policy Entropy: 3.66947
Value Function Loss: 0.02227

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.35408
Value Function Update Magnitude: 0.40370

Collected Steps per Second: 23,273.12548
Overall Steps per Second: 10,952.12479

Timestep Collection Time: 2.14926
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27678
Total Iteration Time: 4.56715

Cumulative Model Updates: 175,166
Cumulative Timesteps: 1,460,778,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1460778466...
Checkpoint 1460778466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,648.83029
Policy Entropy: 3.67536
Value Function Loss: 0.02426

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.34793
Value Function Update Magnitude: 0.39673

Collected Steps per Second: 22,342.64445
Overall Steps per Second: 10,605.34831

Timestep Collection Time: 2.23868
Timestep Consumption Time: 2.47762
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.71630

Cumulative Model Updates: 175,172
Cumulative Timesteps: 1,460,828,484

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,648.83029
Policy Entropy: 3.68067
Value Function Loss: 0.02250

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12798
Policy Update Magnitude: 0.39115
Value Function Update Magnitude: 0.54219

Collected Steps per Second: 23,323.55808
Overall Steps per Second: 10,971.54272

Timestep Collection Time: 2.14504
Timestep Consumption Time: 2.41494
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.55998

Cumulative Model Updates: 175,178
Cumulative Timesteps: 1,460,878,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1460878514...
Checkpoint 1460878514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,648.83029
Policy Entropy: 3.66824
Value Function Loss: 0.02441

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14043
Policy Update Magnitude: 0.43622
Value Function Update Magnitude: 0.61181

Collected Steps per Second: 22,817.37153
Overall Steps per Second: 10,663.32535

Timestep Collection Time: 2.19219
Timestep Consumption Time: 2.49866
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.69084

Cumulative Model Updates: 175,184
Cumulative Timesteps: 1,460,928,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297,858.67349
Policy Entropy: 3.68073
Value Function Loss: 0.02391

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.45180
Value Function Update Magnitude: 0.65493

Collected Steps per Second: 22,278.60767
Overall Steps per Second: 10,900.38282

Timestep Collection Time: 2.24502
Timestep Consumption Time: 2.34344
PPO Batch Consumption Time: 0.27596
Total Iteration Time: 4.58846

Cumulative Model Updates: 175,190
Cumulative Timesteps: 1,460,978,550

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1460978550...
Checkpoint 1460978550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,869.02322
Policy Entropy: 3.69163
Value Function Loss: 0.02470

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.47142
Value Function Update Magnitude: 0.69260

Collected Steps per Second: 21,671.04368
Overall Steps per Second: 10,558.87740

Timestep Collection Time: 2.30732
Timestep Consumption Time: 2.42822
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.73554

Cumulative Model Updates: 175,196
Cumulative Timesteps: 1,461,028,552

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,721.82518
Policy Entropy: 3.69817
Value Function Loss: 0.02644

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.45523
Value Function Update Magnitude: 0.64820

Collected Steps per Second: 22,188.79827
Overall Steps per Second: 10,889.29283

Timestep Collection Time: 2.25447
Timestep Consumption Time: 2.33940
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.59387

Cumulative Model Updates: 175,202
Cumulative Timesteps: 1,461,078,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1461078576...
Checkpoint 1461078576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,721.82518
Policy Entropy: 3.69332
Value Function Loss: 0.02476

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08986
Policy Update Magnitude: 0.48785
Value Function Update Magnitude: 0.58463

Collected Steps per Second: 21,970.92572
Overall Steps per Second: 10,729.03432

Timestep Collection Time: 2.27701
Timestep Consumption Time: 2.38585
PPO Batch Consumption Time: 0.27605
Total Iteration Time: 4.66286

Cumulative Model Updates: 175,208
Cumulative Timesteps: 1,461,128,604

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,721.82518
Policy Entropy: 3.66926
Value Function Loss: 0.02478

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09756
Policy Update Magnitude: 0.52540
Value Function Update Magnitude: 0.44642

Collected Steps per Second: 23,249.31864
Overall Steps per Second: 10,844.49852

Timestep Collection Time: 2.15146
Timestep Consumption Time: 2.46102
PPO Batch Consumption Time: 0.28644
Total Iteration Time: 4.61248

Cumulative Model Updates: 175,214
Cumulative Timesteps: 1,461,178,624

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1461178624...
Checkpoint 1461178624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,721.82518
Policy Entropy: 3.66582
Value Function Loss: 0.02515

Mean KL Divergence: 0.00630
SB3 Clip Fraction: 0.07543
Policy Update Magnitude: 0.60341
Value Function Update Magnitude: 0.43047

Collected Steps per Second: 22,528.90798
Overall Steps per Second: 10,611.11220

Timestep Collection Time: 2.22035
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.71411

Cumulative Model Updates: 175,220
Cumulative Timesteps: 1,461,228,646

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,721.82518
Policy Entropy: 3.67417
Value Function Loss: 0.02304

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08169
Policy Update Magnitude: 0.63014
Value Function Update Magnitude: 0.41889

Collected Steps per Second: 22,662.20185
Overall Steps per Second: 10,650.95183

Timestep Collection Time: 2.20641
Timestep Consumption Time: 2.48820
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.69460

Cumulative Model Updates: 175,226
Cumulative Timesteps: 1,461,278,648

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1461278648...
Checkpoint 1461278648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,721.82518
Policy Entropy: 3.69869
Value Function Loss: 0.01909

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07230
Policy Update Magnitude: 0.56513
Value Function Update Magnitude: 0.41328

Collected Steps per Second: 22,567.33564
Overall Steps per Second: 10,686.07971

Timestep Collection Time: 2.21772
Timestep Consumption Time: 2.46576
PPO Batch Consumption Time: 0.28819
Total Iteration Time: 4.68348

Cumulative Model Updates: 175,232
Cumulative Timesteps: 1,461,328,696

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,721.82518
Policy Entropy: 3.69629
Value Function Loss: 0.01711

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09631
Policy Update Magnitude: 0.47244
Value Function Update Magnitude: 0.42348

Collected Steps per Second: 23,252.96429
Overall Steps per Second: 10,776.85895

Timestep Collection Time: 2.15121
Timestep Consumption Time: 2.49040
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.64161

Cumulative Model Updates: 175,238
Cumulative Timesteps: 1,461,378,718

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1461378718...
Checkpoint 1461378718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,721.82518
Policy Entropy: 3.67827
Value Function Loss: 0.01722

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.16124
Policy Update Magnitude: 0.40112
Value Function Update Magnitude: 0.44689

Collected Steps per Second: 22,714.26316
Overall Steps per Second: 10,668.56724

Timestep Collection Time: 2.20188
Timestep Consumption Time: 2.48610
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.68798

Cumulative Model Updates: 175,244
Cumulative Timesteps: 1,461,428,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,721.82518
Policy Entropy: 3.67870
Value Function Loss: 0.01982

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10886
Policy Update Magnitude: 0.41425
Value Function Update Magnitude: 0.45838

Collected Steps per Second: 22,946.50713
Overall Steps per Second: 10,898.20368

Timestep Collection Time: 2.17977
Timestep Consumption Time: 2.40980
PPO Batch Consumption Time: 0.27575
Total Iteration Time: 4.58956

Cumulative Model Updates: 175,250
Cumulative Timesteps: 1,461,478,750

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1461478750...
Checkpoint 1461478750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,721.82518
Policy Entropy: 3.67239
Value Function Loss: 0.02115

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10722
Policy Update Magnitude: 0.47201
Value Function Update Magnitude: 0.43072

Collected Steps per Second: 21,870.92602
Overall Steps per Second: 10,625.34813

Timestep Collection Time: 2.28623
Timestep Consumption Time: 2.41968
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.70592

Cumulative Model Updates: 175,256
Cumulative Timesteps: 1,461,528,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,030.65664
Policy Entropy: 3.67903
Value Function Loss: 0.03377

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.52365
Value Function Update Magnitude: 0.36985

Collected Steps per Second: 22,617.19700
Overall Steps per Second: 10,870.46542

Timestep Collection Time: 2.21168
Timestep Consumption Time: 2.38996
PPO Batch Consumption Time: 0.28448
Total Iteration Time: 4.60164

Cumulative Model Updates: 175,262
Cumulative Timesteps: 1,461,578,774

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1461578774...
Checkpoint 1461578774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,486.64087
Policy Entropy: 3.68796
Value Function Loss: 0.03262

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.19013
Policy Update Magnitude: 0.50263
Value Function Update Magnitude: 0.45524

Collected Steps per Second: 21,886.36200
Overall Steps per Second: 10,664.81202

Timestep Collection Time: 2.28544
Timestep Consumption Time: 2.40475
PPO Batch Consumption Time: 0.27589
Total Iteration Time: 4.69019

Cumulative Model Updates: 175,268
Cumulative Timesteps: 1,461,628,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,486.64087
Policy Entropy: 3.69458
Value Function Loss: 0.03125

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.16774
Policy Update Magnitude: 0.43673
Value Function Update Magnitude: 0.47118

Collected Steps per Second: 23,166.58375
Overall Steps per Second: 10,901.28106

Timestep Collection Time: 2.15854
Timestep Consumption Time: 2.42863
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.58717

Cumulative Model Updates: 175,274
Cumulative Timesteps: 1,461,678,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1461678800...
Checkpoint 1461678800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,486.64087
Policy Entropy: 3.69894
Value Function Loss: 0.02474

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.42178
Value Function Update Magnitude: 0.53684

Collected Steps per Second: 22,602.77853
Overall Steps per Second: 10,703.53422

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.46061
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.67397

Cumulative Model Updates: 175,280
Cumulative Timesteps: 1,461,728,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 546,486.64087
Policy Entropy: 3.68159
Value Function Loss: 0.02408

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.37924
Value Function Update Magnitude: 0.60102

Collected Steps per Second: 23,225.43940
Overall Steps per Second: 10,792.44103

Timestep Collection Time: 2.15281
Timestep Consumption Time: 2.48006
PPO Batch Consumption Time: 0.28474
Total Iteration Time: 4.63287

Cumulative Model Updates: 175,286
Cumulative Timesteps: 1,461,778,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1461778828...
Checkpoint 1461778828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 546,486.64087
Policy Entropy: 3.67461
Value Function Loss: 0.02648

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.39790
Value Function Update Magnitude: 0.68621

Collected Steps per Second: 22,705.41734
Overall Steps per Second: 10,663.56960

Timestep Collection Time: 2.20291
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.69055

Cumulative Model Updates: 175,292
Cumulative Timesteps: 1,461,828,846

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 923,343.31592
Policy Entropy: 3.65978
Value Function Loss: 0.03320

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15162
Policy Update Magnitude: 0.46207
Value Function Update Magnitude: 0.67016

Collected Steps per Second: 22,938.81957
Overall Steps per Second: 10,867.98692

Timestep Collection Time: 2.18058
Timestep Consumption Time: 2.42193
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.60251

Cumulative Model Updates: 175,298
Cumulative Timesteps: 1,461,878,866

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1461878866...
Checkpoint 1461878866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,598.07501
Policy Entropy: 3.68989
Value Function Loss: 0.03419

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13818
Policy Update Magnitude: 0.50740
Value Function Update Magnitude: 0.65376

Collected Steps per Second: 22,409.47323
Overall Steps per Second: 10,707.30157

Timestep Collection Time: 2.23147
Timestep Consumption Time: 2.43880
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.67027

Cumulative Model Updates: 175,304
Cumulative Timesteps: 1,461,928,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,353.87636
Policy Entropy: 3.68839
Value Function Loss: 0.03433

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14322
Policy Update Magnitude: 0.49538
Value Function Update Magnitude: 0.67544

Collected Steps per Second: 22,828.77682
Overall Steps per Second: 10,820.74351

Timestep Collection Time: 2.19031
Timestep Consumption Time: 2.43063
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.62094

Cumulative Model Updates: 175,310
Cumulative Timesteps: 1,461,978,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1461978874...
Checkpoint 1461978874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,931.67186
Policy Entropy: 3.69736
Value Function Loss: 0.03132

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.49469
Value Function Update Magnitude: 0.67574

Collected Steps per Second: 22,532.19208
Overall Steps per Second: 10,674.79591

Timestep Collection Time: 2.21905
Timestep Consumption Time: 2.46488
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.68393

Cumulative Model Updates: 175,316
Cumulative Timesteps: 1,462,028,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,367.85353
Policy Entropy: 3.67362
Value Function Loss: 0.03545

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13579
Policy Update Magnitude: 0.50389
Value Function Update Magnitude: 0.75635

Collected Steps per Second: 22,991.48119
Overall Steps per Second: 10,862.55211

Timestep Collection Time: 2.17489
Timestep Consumption Time: 2.42845
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.60334

Cumulative Model Updates: 175,322
Cumulative Timesteps: 1,462,078,878

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1462078878...
Checkpoint 1462078878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,940.14037
Policy Entropy: 3.66828
Value Function Loss: 0.03755

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.57589
Value Function Update Magnitude: 0.87618

Collected Steps per Second: 22,419.23777
Overall Steps per Second: 10,706.63903

Timestep Collection Time: 2.23050
Timestep Consumption Time: 2.44006
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.67056

Cumulative Model Updates: 175,328
Cumulative Timesteps: 1,462,128,884

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,944.34544
Policy Entropy: 3.65868
Value Function Loss: 0.05062

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.58506
Value Function Update Magnitude: 0.82098

Collected Steps per Second: 22,932.75385
Overall Steps per Second: 10,825.27194

Timestep Collection Time: 2.18142
Timestep Consumption Time: 2.43980
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.62122

Cumulative Model Updates: 175,334
Cumulative Timesteps: 1,462,178,910

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1462178910...
Checkpoint 1462178910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,464.92065
Policy Entropy: 3.67082
Value Function Loss: 0.04976

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.59022
Value Function Update Magnitude: 0.76080

Collected Steps per Second: 22,704.44381
Overall Steps per Second: 10,706.14137

Timestep Collection Time: 2.20345
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.28470
Total Iteration Time: 4.67283

Cumulative Model Updates: 175,340
Cumulative Timesteps: 1,462,228,938

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,516.14814
Policy Entropy: 3.68428
Value Function Loss: 0.04866

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14089
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.71010

Collected Steps per Second: 22,899.74696
Overall Steps per Second: 10,863.14548

Timestep Collection Time: 2.18404
Timestep Consumption Time: 2.41997
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.60401

Cumulative Model Updates: 175,346
Cumulative Timesteps: 1,462,278,952

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1462278952...
Checkpoint 1462278952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 728,036.33140
Policy Entropy: 3.68954
Value Function Loss: 0.04500

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.53601
Value Function Update Magnitude: 0.68341

Collected Steps per Second: 22,792.37189
Overall Steps per Second: 10,672.23171

Timestep Collection Time: 2.19372
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.28727
Total Iteration Time: 4.68506

Cumulative Model Updates: 175,352
Cumulative Timesteps: 1,462,328,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,888.54354
Policy Entropy: 3.70142
Value Function Loss: 0.04168

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13549
Policy Update Magnitude: 0.51431
Value Function Update Magnitude: 0.63605

Collected Steps per Second: 22,832.08504
Overall Steps per Second: 10,839.19138

Timestep Collection Time: 2.19086
Timestep Consumption Time: 2.42406
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.61492

Cumulative Model Updates: 175,358
Cumulative Timesteps: 1,462,378,974

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1462378974...
Checkpoint 1462378974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,370.43707
Policy Entropy: 3.69107
Value Function Loss: 0.04127

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.52675
Value Function Update Magnitude: 0.84800

Collected Steps per Second: 22,455.64005
Overall Steps per Second: 10,772.60630

Timestep Collection Time: 2.22688
Timestep Consumption Time: 2.41508
PPO Batch Consumption Time: 0.27635
Total Iteration Time: 4.64196

Cumulative Model Updates: 175,364
Cumulative Timesteps: 1,462,428,980

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,370.43707
Policy Entropy: 3.68000
Value Function Loss: 0.03924

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14165
Policy Update Magnitude: 0.53000
Value Function Update Magnitude: 0.96299

Collected Steps per Second: 22,780.79918
Overall Steps per Second: 10,820.18748

Timestep Collection Time: 2.19501
Timestep Consumption Time: 2.42636
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.62136

Cumulative Model Updates: 175,370
Cumulative Timesteps: 1,462,478,984

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1462478984...
Checkpoint 1462478984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,370.43707
Policy Entropy: 3.64704
Value Function Loss: 0.03308

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14354
Policy Update Magnitude: 0.47740
Value Function Update Magnitude: 0.82672

Collected Steps per Second: 22,721.37706
Overall Steps per Second: 10,680.64823

Timestep Collection Time: 2.20154
Timestep Consumption Time: 2.48188
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.68342

Cumulative Model Updates: 175,376
Cumulative Timesteps: 1,462,529,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 713,716.09049
Policy Entropy: 3.62944
Value Function Loss: 0.03006

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13939
Policy Update Magnitude: 0.42941
Value Function Update Magnitude: 0.56755

Collected Steps per Second: 22,992.62870
Overall Steps per Second: 10,846.73719

Timestep Collection Time: 2.17565
Timestep Consumption Time: 2.43624
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.61189

Cumulative Model Updates: 175,382
Cumulative Timesteps: 1,462,579,030

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1462579030...
Checkpoint 1462579030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 713,716.09049
Policy Entropy: 3.65023
Value Function Loss: 0.02400

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.42948
Value Function Update Magnitude: 0.51791

Collected Steps per Second: 22,749.45891
Overall Steps per Second: 10,669.40797

Timestep Collection Time: 2.19865
Timestep Consumption Time: 2.48934
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.68798

Cumulative Model Updates: 175,388
Cumulative Timesteps: 1,462,629,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 758,786.85230
Policy Entropy: 3.64669
Value Function Loss: 0.02964

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13624
Policy Update Magnitude: 0.43443
Value Function Update Magnitude: 0.51928

Collected Steps per Second: 22,770.74896
Overall Steps per Second: 10,856.97638

Timestep Collection Time: 2.19598
Timestep Consumption Time: 2.40973
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.60570

Cumulative Model Updates: 175,394
Cumulative Timesteps: 1,462,679,052

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1462679052...
Checkpoint 1462679052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497,852.86674
Policy Entropy: 3.65630
Value Function Loss: 0.02866

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13322
Policy Update Magnitude: 0.44898
Value Function Update Magnitude: 0.50744

Collected Steps per Second: 22,457.26185
Overall Steps per Second: 10,815.02801

Timestep Collection Time: 2.22859
Timestep Consumption Time: 2.39905
PPO Batch Consumption Time: 0.27576
Total Iteration Time: 4.62763

Cumulative Model Updates: 175,400
Cumulative Timesteps: 1,462,729,100

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 815,532.08668
Policy Entropy: 3.63995
Value Function Loss: 0.04109

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.49566
Value Function Update Magnitude: 0.59675

Collected Steps per Second: 22,890.99648
Overall Steps per Second: 10,885.95006

Timestep Collection Time: 2.18514
Timestep Consumption Time: 2.40978
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.59491

Cumulative Model Updates: 175,406
Cumulative Timesteps: 1,462,779,120

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1462779120...
Checkpoint 1462779120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 163,946.62804
Policy Entropy: 3.65056
Value Function Loss: 0.04106

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.53814
Value Function Update Magnitude: 0.55626

Collected Steps per Second: 22,141.66567
Overall Steps per Second: 10,730.04668

Timestep Collection Time: 2.25909
Timestep Consumption Time: 2.40259
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.66168

Cumulative Model Updates: 175,412
Cumulative Timesteps: 1,462,829,140

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,160.62190
Policy Entropy: 3.66348
Value Function Loss: 0.04282

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.52791
Value Function Update Magnitude: 0.51598

Collected Steps per Second: 22,311.42271
Overall Steps per Second: 10,777.42814

Timestep Collection Time: 2.24154
Timestep Consumption Time: 2.39890
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.64044

Cumulative Model Updates: 175,418
Cumulative Timesteps: 1,462,879,152

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1462879152...
Checkpoint 1462879152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,940.84904
Policy Entropy: 3.67263
Value Function Loss: 0.03255

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13527
Policy Update Magnitude: 0.48027
Value Function Update Magnitude: 0.40692

Collected Steps per Second: 21,757.37939
Overall Steps per Second: 10,636.60737

Timestep Collection Time: 2.29936
Timestep Consumption Time: 2.40402
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.70338

Cumulative Model Updates: 175,424
Cumulative Timesteps: 1,462,929,180

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,154.92320
Policy Entropy: 3.66960
Value Function Loss: 0.02900

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14852
Policy Update Magnitude: 0.41584
Value Function Update Magnitude: 0.43037

Collected Steps per Second: 22,210.24595
Overall Steps per Second: 10,569.94790

Timestep Collection Time: 2.25130
Timestep Consumption Time: 2.47928
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.73058

Cumulative Model Updates: 175,430
Cumulative Timesteps: 1,462,979,182

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1462979182...
Checkpoint 1462979182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,154.92320
Policy Entropy: 3.66019
Value Function Loss: 0.02832

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14598
Policy Update Magnitude: 0.40391
Value Function Update Magnitude: 0.44326

Collected Steps per Second: 22,857.79043
Overall Steps per Second: 10,924.57498

Timestep Collection Time: 2.18840
Timestep Consumption Time: 2.39045
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.57885

Cumulative Model Updates: 175,436
Cumulative Timesteps: 1,463,029,204

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,154.92320
Policy Entropy: 3.66876
Value Function Loss: 0.02503

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14801
Policy Update Magnitude: 0.40823
Value Function Update Magnitude: 0.41233

Collected Steps per Second: 22,997.81753
Overall Steps per Second: 10,951.51698

Timestep Collection Time: 2.17621
Timestep Consumption Time: 2.39375
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.56996

Cumulative Model Updates: 175,442
Cumulative Timesteps: 1,463,079,252

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1463079252...
Checkpoint 1463079252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 886,013.00629
Policy Entropy: 3.67010
Value Function Loss: 0.02545

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.38208
Value Function Update Magnitude: 0.36935

Collected Steps per Second: 22,782.27782
Overall Steps per Second: 10,671.80791

Timestep Collection Time: 2.19513
Timestep Consumption Time: 2.49105
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.68618

Cumulative Model Updates: 175,448
Cumulative Timesteps: 1,463,129,262

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,944.99341
Policy Entropy: 3.69484
Value Function Loss: 0.02572

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14015
Policy Update Magnitude: 0.33263
Value Function Update Magnitude: 0.40943

Collected Steps per Second: 23,041.80790
Overall Steps per Second: 10,854.99619

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.43747
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.60857

Cumulative Model Updates: 175,454
Cumulative Timesteps: 1,463,179,288

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1463179288...
Checkpoint 1463179288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,267.26087
Policy Entropy: 3.67792
Value Function Loss: 0.03212

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14519
Policy Update Magnitude: 0.33292
Value Function Update Magnitude: 0.42352

Collected Steps per Second: 22,936.93992
Overall Steps per Second: 10,659.91543

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.51148
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.69216

Cumulative Model Updates: 175,460
Cumulative Timesteps: 1,463,229,306

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,261.53994
Policy Entropy: 3.67628
Value Function Loss: 0.03232

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14521
Policy Update Magnitude: 0.36019
Value Function Update Magnitude: 0.39106

Collected Steps per Second: 23,029.64889
Overall Steps per Second: 10,870.21412

Timestep Collection Time: 2.17190
Timestep Consumption Time: 2.42949
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.60138

Cumulative Model Updates: 175,466
Cumulative Timesteps: 1,463,279,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1463279324...
Checkpoint 1463279324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 603,388.33959
Policy Entropy: 3.66394
Value Function Loss: 0.03264

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.38903
Value Function Update Magnitude: 0.41477

Collected Steps per Second: 22,919.06266
Overall Steps per Second: 10,680.43507

Timestep Collection Time: 2.18229
Timestep Consumption Time: 2.50067
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.68296

Cumulative Model Updates: 175,472
Cumulative Timesteps: 1,463,329,340

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,880.27016
Policy Entropy: 3.69833
Value Function Loss: 0.02874

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.44305
Value Function Update Magnitude: 0.48572

Collected Steps per Second: 22,767.35565
Overall Steps per Second: 10,819.96597

Timestep Collection Time: 2.19709
Timestep Consumption Time: 2.42603
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.62312

Cumulative Model Updates: 175,478
Cumulative Timesteps: 1,463,379,362

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1463379362...
Checkpoint 1463379362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,880.27016
Policy Entropy: 3.69198
Value Function Loss: 0.02675

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13958
Policy Update Magnitude: 0.40662
Value Function Update Magnitude: 0.48479

Collected Steps per Second: 22,660.76561
Overall Steps per Second: 10,715.90055

Timestep Collection Time: 2.20663
Timestep Consumption Time: 2.45970
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.66634

Cumulative Model Updates: 175,484
Cumulative Timesteps: 1,463,429,366

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,880.27016
Policy Entropy: 3.70195
Value Function Loss: 0.02120

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13350
Policy Update Magnitude: 0.33703
Value Function Update Magnitude: 0.41296

Collected Steps per Second: 22,939.33996
Overall Steps per Second: 10,856.78556

Timestep Collection Time: 2.18010
Timestep Consumption Time: 2.42624
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.60634

Cumulative Model Updates: 175,490
Cumulative Timesteps: 1,463,479,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1463479376...
Checkpoint 1463479376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,880.27016
Policy Entropy: 3.67442
Value Function Loss: 0.02027

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.29015
Value Function Update Magnitude: 0.30091

Collected Steps per Second: 22,780.59716
Overall Steps per Second: 10,710.18783

Timestep Collection Time: 2.19599
Timestep Consumption Time: 2.47489
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.67088

Cumulative Model Updates: 175,496
Cumulative Timesteps: 1,463,529,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,880.27016
Policy Entropy: 3.67708
Value Function Loss: 0.01822

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.27188
Value Function Update Magnitude: 0.22562

Collected Steps per Second: 22,740.36134
Overall Steps per Second: 10,839.16736

Timestep Collection Time: 2.19900
Timestep Consumption Time: 2.41446
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.61345

Cumulative Model Updates: 175,502
Cumulative Timesteps: 1,463,579,408

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1463579408...
Checkpoint 1463579408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 395,880.27016
Policy Entropy: 3.66033
Value Function Loss: 0.02055

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.28018
Value Function Update Magnitude: 0.24958

Collected Steps per Second: 22,127.40118
Overall Steps per Second: 10,675.57338

Timestep Collection Time: 2.26009
Timestep Consumption Time: 2.42443
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.68453

Cumulative Model Updates: 175,508
Cumulative Timesteps: 1,463,629,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 395,880.27016
Policy Entropy: 3.67503
Value Function Loss: 0.02162

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.35940
Value Function Update Magnitude: 0.25687

Collected Steps per Second: 22,825.36629
Overall Steps per Second: 10,860.64819

Timestep Collection Time: 2.19195
Timestep Consumption Time: 2.41478
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.60672

Cumulative Model Updates: 175,514
Cumulative Timesteps: 1,463,679,450

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1463679450...
Checkpoint 1463679450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.67148
Value Function Loss: 0.02873

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.38155
Value Function Update Magnitude: 0.24584

Collected Steps per Second: 22,809.85542
Overall Steps per Second: 10,701.43997

Timestep Collection Time: 2.19221
Timestep Consumption Time: 2.48043
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.67264

Cumulative Model Updates: 175,520
Cumulative Timesteps: 1,463,729,454

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.67563
Value Function Loss: 0.02745

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.38203
Value Function Update Magnitude: 0.23830

Collected Steps per Second: 22,310.07327
Overall Steps per Second: 10,882.25087

Timestep Collection Time: 2.24231
Timestep Consumption Time: 2.35472
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.59703

Cumulative Model Updates: 175,526
Cumulative Timesteps: 1,463,779,480

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1463779480...
Checkpoint 1463779480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.66420
Value Function Loss: 0.02642

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14502
Policy Update Magnitude: 0.40229
Value Function Update Magnitude: 0.21146

Collected Steps per Second: 22,103.62493
Overall Steps per Second: 10,667.37908

Timestep Collection Time: 2.26316
Timestep Consumption Time: 2.42628
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.68944

Cumulative Model Updates: 175,532
Cumulative Timesteps: 1,463,829,504

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.66350
Value Function Loss: 0.02276

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12130
Policy Update Magnitude: 0.43357
Value Function Update Magnitude: 0.22454

Collected Steps per Second: 22,213.15939
Overall Steps per Second: 10,601.67471

Timestep Collection Time: 2.25218
Timestep Consumption Time: 2.46670
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.71888

Cumulative Model Updates: 175,538
Cumulative Timesteps: 1,463,879,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1463879532...
Checkpoint 1463879532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.66999
Value Function Loss: 0.02069

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.43396
Value Function Update Magnitude: 0.29202

Collected Steps per Second: 22,665.55871
Overall Steps per Second: 10,711.96854

Timestep Collection Time: 2.20670
Timestep Consumption Time: 2.46247
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.66917

Cumulative Model Updates: 175,544
Cumulative Timesteps: 1,463,929,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.66894
Value Function Loss: 0.02076

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.41849
Value Function Update Magnitude: 0.34250

Collected Steps per Second: 23,096.76762
Overall Steps per Second: 10,813.05473

Timestep Collection Time: 2.16576
Timestep Consumption Time: 2.46032
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.62607

Cumulative Model Updates: 175,550
Cumulative Timesteps: 1,463,979,570

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1463979570...
Checkpoint 1463979570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.67935
Value Function Loss: 0.01881

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14196
Policy Update Magnitude: 0.39824
Value Function Update Magnitude: 0.37364

Collected Steps per Second: 22,992.46748
Overall Steps per Second: 10,751.09365

Timestep Collection Time: 2.17541
Timestep Consumption Time: 2.47696
PPO Batch Consumption Time: 0.28738
Total Iteration Time: 4.65236

Cumulative Model Updates: 175,556
Cumulative Timesteps: 1,464,029,588

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.69267
Value Function Loss: 0.01689

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15642
Policy Update Magnitude: 0.36587
Value Function Update Magnitude: 0.35318

Collected Steps per Second: 22,924.28199
Overall Steps per Second: 10,718.75954

Timestep Collection Time: 2.18170
Timestep Consumption Time: 2.48432
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.66602

Cumulative Model Updates: 175,562
Cumulative Timesteps: 1,464,079,602

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1464079602...
Checkpoint 1464079602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.70634
Value Function Loss: 0.01511

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.14582
Policy Update Magnitude: 0.32362
Value Function Update Magnitude: 0.29515

Collected Steps per Second: 23,040.93546
Overall Steps per Second: 10,758.33346

Timestep Collection Time: 2.17083
Timestep Consumption Time: 2.47840
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.64923

Cumulative Model Updates: 175,568
Cumulative Timesteps: 1,464,129,620

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.68860
Value Function Loss: 0.01486

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13080
Policy Update Magnitude: 0.32828
Value Function Update Magnitude: 0.32305

Collected Steps per Second: 22,765.50965
Overall Steps per Second: 10,757.22905

Timestep Collection Time: 2.19701
Timestep Consumption Time: 2.45252
PPO Batch Consumption Time: 0.28201
Total Iteration Time: 4.64952

Cumulative Model Updates: 175,574
Cumulative Timesteps: 1,464,179,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1464179636...
Checkpoint 1464179636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.66998
Value Function Loss: 0.01637

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08505
Policy Update Magnitude: 0.45797
Value Function Update Magnitude: 0.40507

Collected Steps per Second: 22,797.99603
Overall Steps per Second: 10,637.68259

Timestep Collection Time: 2.19440
Timestep Consumption Time: 2.50850
PPO Batch Consumption Time: 0.29329
Total Iteration Time: 4.70290

Cumulative Model Updates: 175,580
Cumulative Timesteps: 1,464,229,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.66455
Value Function Loss: 0.01829

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09030
Policy Update Magnitude: 0.53458
Value Function Update Magnitude: 0.41808

Collected Steps per Second: 22,939.75927
Overall Steps per Second: 10,888.11477

Timestep Collection Time: 2.18093
Timestep Consumption Time: 2.41399
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.59492

Cumulative Model Updates: 175,586
Cumulative Timesteps: 1,464,279,694

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1464279694...
Checkpoint 1464279694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.67374
Value Function Loss: 0.01895

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10438
Policy Update Magnitude: 0.51222
Value Function Update Magnitude: 0.39244

Collected Steps per Second: 23,038.94487
Overall Steps per Second: 10,674.64567

Timestep Collection Time: 2.17137
Timestep Consumption Time: 2.51507
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.68643

Cumulative Model Updates: 175,592
Cumulative Timesteps: 1,464,329,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.67084
Value Function Loss: 0.02074

Mean KL Divergence: 0.01607
SB3 Clip Fraction: 0.19907
Policy Update Magnitude: 0.39932
Value Function Update Magnitude: 0.35961

Collected Steps per Second: 22,841.48263
Overall Steps per Second: 10,825.29918

Timestep Collection Time: 2.18935
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.61955

Cumulative Model Updates: 175,598
Cumulative Timesteps: 1,464,379,728

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1464379728...
Checkpoint 1464379728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,784.98766
Policy Entropy: 3.67063
Value Function Loss: 0.02143

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14838
Policy Update Magnitude: 0.35642
Value Function Update Magnitude: 0.38619

Collected Steps per Second: 22,578.69439
Overall Steps per Second: 10,785.25554

Timestep Collection Time: 2.21501
Timestep Consumption Time: 2.42206
PPO Batch Consumption Time: 0.27561
Total Iteration Time: 4.63707

Cumulative Model Updates: 175,604
Cumulative Timesteps: 1,464,429,740

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224,796.36471
Policy Entropy: 3.68268
Value Function Loss: 0.02365

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16101
Policy Update Magnitude: 0.45721
Value Function Update Magnitude: 0.50008

Collected Steps per Second: 22,877.35969
Overall Steps per Second: 10,815.81843

Timestep Collection Time: 2.18635
Timestep Consumption Time: 2.43817
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.62452

Cumulative Model Updates: 175,610
Cumulative Timesteps: 1,464,479,758

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1464479758...
Checkpoint 1464479758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 224,796.36471
Policy Entropy: 3.70024
Value Function Loss: 0.02053

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15949
Policy Update Magnitude: 0.43234
Value Function Update Magnitude: 0.58933

Collected Steps per Second: 22,972.14159
Overall Steps per Second: 10,694.04854

Timestep Collection Time: 2.17759
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.67774

Cumulative Model Updates: 175,616
Cumulative Timesteps: 1,464,529,782

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224,796.36471
Policy Entropy: 3.69648
Value Function Loss: 0.01905

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12981
Policy Update Magnitude: 0.36193
Value Function Update Magnitude: 0.51716

Collected Steps per Second: 22,707.65963
Overall Steps per Second: 10,810.93324

Timestep Collection Time: 2.20296
Timestep Consumption Time: 2.42421
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.62717

Cumulative Model Updates: 175,622
Cumulative Timesteps: 1,464,579,806

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1464579806...
Checkpoint 1464579806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,108.71876
Policy Entropy: 3.66097
Value Function Loss: 0.02082

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.33740
Value Function Update Magnitude: 0.47783

Collected Steps per Second: 22,771.12327
Overall Steps per Second: 10,711.87576

Timestep Collection Time: 2.19708
Timestep Consumption Time: 2.47344
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.67052

Cumulative Model Updates: 175,628
Cumulative Timesteps: 1,464,629,836

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,202.23787
Policy Entropy: 3.66658
Value Function Loss: 0.02444

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13416
Policy Update Magnitude: 0.37461
Value Function Update Magnitude: 0.56966

Collected Steps per Second: 22,210.19695
Overall Steps per Second: 10,892.29584

Timestep Collection Time: 2.25248
Timestep Consumption Time: 2.34049
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.59297

Cumulative Model Updates: 175,634
Cumulative Timesteps: 1,464,679,864

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1464679864...
Checkpoint 1464679864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,202.23787
Policy Entropy: 3.65313
Value Function Loss: 0.03189

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.44104
Value Function Update Magnitude: 0.51040

Collected Steps per Second: 22,086.92364
Overall Steps per Second: 10,656.95035

Timestep Collection Time: 2.26396
Timestep Consumption Time: 2.42819
PPO Batch Consumption Time: 0.29294
Total Iteration Time: 4.69215

Cumulative Model Updates: 175,640
Cumulative Timesteps: 1,464,729,868

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,202.23787
Policy Entropy: 3.66456
Value Function Loss: 0.02968

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.46885
Value Function Update Magnitude: 0.47809

Collected Steps per Second: 22,117.68619
Overall Steps per Second: 10,572.48188

Timestep Collection Time: 2.26100
Timestep Consumption Time: 2.46902
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.73002

Cumulative Model Updates: 175,646
Cumulative Timesteps: 1,464,779,876

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1464779876...
Checkpoint 1464779876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,202.23787
Policy Entropy: 3.64079
Value Function Loss: 0.03423

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14195
Policy Update Magnitude: 0.44523
Value Function Update Magnitude: 0.39783

Collected Steps per Second: 22,754.14927
Overall Steps per Second: 10,878.96546

Timestep Collection Time: 2.19793
Timestep Consumption Time: 2.39920
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.59713

Cumulative Model Updates: 175,652
Cumulative Timesteps: 1,464,829,888

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,202.23787
Policy Entropy: 3.65660
Value Function Loss: 0.03162

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14209
Policy Update Magnitude: 0.43657
Value Function Update Magnitude: 0.40380

Collected Steps per Second: 22,533.94261
Overall Steps per Second: 10,644.12492

Timestep Collection Time: 2.21950
Timestep Consumption Time: 2.47925
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.69874

Cumulative Model Updates: 175,658
Cumulative Timesteps: 1,464,879,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1464879902...
Checkpoint 1464879902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337,124.22095
Policy Entropy: 3.65232
Value Function Loss: 0.03914

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14211
Policy Update Magnitude: 0.47119
Value Function Update Magnitude: 0.33397

Collected Steps per Second: 22,685.35909
Overall Steps per Second: 10,661.06761

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.48679
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.69165

Cumulative Model Updates: 175,664
Cumulative Timesteps: 1,464,929,920

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,558.89463
Policy Entropy: 3.67145
Value Function Loss: 0.03554

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.52755
Value Function Update Magnitude: 0.35350

Collected Steps per Second: 22,707.23678
Overall Steps per Second: 10,783.97837

Timestep Collection Time: 2.20309
Timestep Consumption Time: 2.43583
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.63892

Cumulative Model Updates: 175,670
Cumulative Timesteps: 1,464,979,946

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1464979946...
Checkpoint 1464979946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,486.24952
Policy Entropy: 3.68599
Value Function Loss: 0.03247

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14442
Policy Update Magnitude: 0.50943
Value Function Update Magnitude: 0.47237

Collected Steps per Second: 22,475.62698
Overall Steps per Second: 10,645.89315

Timestep Collection Time: 2.22490
Timestep Consumption Time: 2.47231
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.69721

Cumulative Model Updates: 175,676
Cumulative Timesteps: 1,465,029,952

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,486.24952
Policy Entropy: 3.70201
Value Function Loss: 0.02290

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.45121
Value Function Update Magnitude: 0.51201

Collected Steps per Second: 23,047.45504
Overall Steps per Second: 10,877.27128

Timestep Collection Time: 2.17030
Timestep Consumption Time: 2.42828
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.59858

Cumulative Model Updates: 175,682
Cumulative Timesteps: 1,465,079,972

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1465079972...
Checkpoint 1465079972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,486.24952
Policy Entropy: 3.68631
Value Function Loss: 0.01954

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13402
Policy Update Magnitude: 0.39955
Value Function Update Magnitude: 0.45644

Collected Steps per Second: 22,303.13139
Overall Steps per Second: 10,745.36854

Timestep Collection Time: 2.24273
Timestep Consumption Time: 2.41229
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.65503

Cumulative Model Updates: 175,688
Cumulative Timesteps: 1,465,129,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,486.24952
Policy Entropy: 3.66874
Value Function Loss: 0.01849

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13546
Policy Update Magnitude: 0.38344
Value Function Update Magnitude: 0.39536

Collected Steps per Second: 23,121.09434
Overall Steps per Second: 10,898.62239

Timestep Collection Time: 2.16261
Timestep Consumption Time: 2.42531
PPO Batch Consumption Time: 0.27642
Total Iteration Time: 4.58792

Cumulative Model Updates: 175,694
Cumulative Timesteps: 1,465,179,994

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1465179994...
Checkpoint 1465179994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,757.22798
Policy Entropy: 3.65391
Value Function Loss: 0.02347

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.38323
Value Function Update Magnitude: 0.44169

Collected Steps per Second: 22,199.89177
Overall Steps per Second: 10,749.42171

Timestep Collection Time: 2.25352
Timestep Consumption Time: 2.40049
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.65402

Cumulative Model Updates: 175,700
Cumulative Timesteps: 1,465,230,022

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,757.22798
Policy Entropy: 3.65202
Value Function Loss: 0.02550

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.39955
Value Function Update Magnitude: 0.40248

Collected Steps per Second: 22,633.51224
Overall Steps per Second: 10,814.21957

Timestep Collection Time: 2.20964
Timestep Consumption Time: 2.41501
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.62465

Cumulative Model Updates: 175,706
Cumulative Timesteps: 1,465,280,034

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1465280034...
Checkpoint 1465280034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,757.22798
Policy Entropy: 3.64704
Value Function Loss: 0.03040

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.44498
Value Function Update Magnitude: 0.36312

Collected Steps per Second: 22,025.98360
Overall Steps per Second: 10,599.81141

Timestep Collection Time: 2.27086
Timestep Consumption Time: 2.44790
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.71876

Cumulative Model Updates: 175,712
Cumulative Timesteps: 1,465,330,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,757.22798
Policy Entropy: 3.65943
Value Function Loss: 0.03104

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12705
Policy Update Magnitude: 0.48283
Value Function Update Magnitude: 0.39082

Collected Steps per Second: 22,735.33473
Overall Steps per Second: 10,878.82315

Timestep Collection Time: 2.20028
Timestep Consumption Time: 2.39802
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.59829

Cumulative Model Updates: 175,718
Cumulative Timesteps: 1,465,380,076

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1465380076...
Checkpoint 1465380076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,757.22798
Policy Entropy: 3.66812
Value Function Loss: 0.03041

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.46679
Value Function Update Magnitude: 0.40987

Collected Steps per Second: 22,845.05626
Overall Steps per Second: 10,742.66938

Timestep Collection Time: 2.18953
Timestep Consumption Time: 2.46667
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.65620

Cumulative Model Updates: 175,724
Cumulative Timesteps: 1,465,430,096

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,691,948.91966
Policy Entropy: 3.66182
Value Function Loss: 0.03219

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.46417
Value Function Update Magnitude: 0.48007

Collected Steps per Second: 22,983.12591
Overall Steps per Second: 10,834.40096

Timestep Collection Time: 2.17586
Timestep Consumption Time: 2.43981
PPO Batch Consumption Time: 0.27949
Total Iteration Time: 4.61567

Cumulative Model Updates: 175,730
Cumulative Timesteps: 1,465,480,104

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1465480104...
Checkpoint 1465480104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.66320
Value Function Loss: 0.03056

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13260
Policy Update Magnitude: 0.47591
Value Function Update Magnitude: 0.44559

Collected Steps per Second: 22,811.98710
Overall Steps per Second: 10,681.09726

Timestep Collection Time: 2.19315
Timestep Consumption Time: 2.49083
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.68398

Cumulative Model Updates: 175,736
Cumulative Timesteps: 1,465,530,134

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.66846
Value Function Loss: 0.03094

Mean KL Divergence: 0.00775
SB3 Clip Fraction: 0.09718
Policy Update Magnitude: 0.59040
Value Function Update Magnitude: 0.45448

Collected Steps per Second: 23,003.48170
Overall Steps per Second: 10,915.43673

Timestep Collection Time: 2.17437
Timestep Consumption Time: 2.40795
PPO Batch Consumption Time: 0.27571
Total Iteration Time: 4.58232

Cumulative Model Updates: 175,742
Cumulative Timesteps: 1,465,580,152

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1465580152...
Checkpoint 1465580152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.67685
Value Function Loss: 0.02785

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11733
Policy Update Magnitude: 0.68324
Value Function Update Magnitude: 0.46028

Collected Steps per Second: 22,957.98591
Overall Steps per Second: 10,739.59844

Timestep Collection Time: 2.17902
Timestep Consumption Time: 2.47906
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.65809

Cumulative Model Updates: 175,748
Cumulative Timesteps: 1,465,630,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.67701
Value Function Loss: 0.02802

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.17545
Policy Update Magnitude: 0.61708
Value Function Update Magnitude: 0.42169

Collected Steps per Second: 22,901.53284
Overall Steps per Second: 10,764.41157

Timestep Collection Time: 2.18448
Timestep Consumption Time: 2.46305
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.64754

Cumulative Model Updates: 175,754
Cumulative Timesteps: 1,465,680,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1465680206...
Checkpoint 1465680206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.68738
Value Function Loss: 0.02636

Mean KL Divergence: 0.01218
SB3 Clip Fraction: 0.16058
Policy Update Magnitude: 0.49871
Value Function Update Magnitude: 0.32878

Collected Steps per Second: 22,829.56394
Overall Steps per Second: 10,667.03253

Timestep Collection Time: 2.19049
Timestep Consumption Time: 2.49760
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.68809

Cumulative Model Updates: 175,760
Cumulative Timesteps: 1,465,730,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.67783
Value Function Loss: 0.02481

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16735
Policy Update Magnitude: 0.48377
Value Function Update Magnitude: 0.30057

Collected Steps per Second: 22,649.97356
Overall Steps per Second: 10,805.49561

Timestep Collection Time: 2.20874
Timestep Consumption Time: 2.42112
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.62987

Cumulative Model Updates: 175,766
Cumulative Timesteps: 1,465,780,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1465780242...
Checkpoint 1465780242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.68994
Value Function Loss: 0.02134

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15030
Policy Update Magnitude: 0.45555
Value Function Update Magnitude: 0.30955

Collected Steps per Second: 22,261.79895
Overall Steps per Second: 10,735.69434

Timestep Collection Time: 2.24627
Timestep Consumption Time: 2.41165
PPO Batch Consumption Time: 0.27600
Total Iteration Time: 4.65792

Cumulative Model Updates: 175,772
Cumulative Timesteps: 1,465,830,248

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.69208
Value Function Loss: 0.01866

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14748
Policy Update Magnitude: 0.42270
Value Function Update Magnitude: 0.38912

Collected Steps per Second: 23,032.10510
Overall Steps per Second: 10,946.79390

Timestep Collection Time: 2.17097
Timestep Consumption Time: 2.39676
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.56773

Cumulative Model Updates: 175,778
Cumulative Timesteps: 1,465,880,250

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1465880250...
Checkpoint 1465880250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.70800
Value Function Loss: 0.01682

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.38573
Value Function Update Magnitude: 0.37818

Collected Steps per Second: 22,574.25621
Overall Steps per Second: 10,974.81464

Timestep Collection Time: 2.21491
Timestep Consumption Time: 2.34097
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.55589

Cumulative Model Updates: 175,784
Cumulative Timesteps: 1,465,930,250

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.71004
Value Function Loss: 0.01642

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13606
Policy Update Magnitude: 0.36674
Value Function Update Magnitude: 0.36643

Collected Steps per Second: 22,400.38054
Overall Steps per Second: 10,932.12766

Timestep Collection Time: 2.23344
Timestep Consumption Time: 2.34298
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.57642

Cumulative Model Updates: 175,790
Cumulative Timesteps: 1,465,980,280

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1465980280...
Checkpoint 1465980280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.71274
Value Function Loss: 0.01662

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11861
Policy Update Magnitude: 0.34405
Value Function Update Magnitude: 0.34623

Collected Steps per Second: 22,301.88455
Overall Steps per Second: 10,673.46906

Timestep Collection Time: 2.24322
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.28351
Total Iteration Time: 4.68714

Cumulative Model Updates: 175,796
Cumulative Timesteps: 1,466,030,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,370,479.06458
Policy Entropy: 3.68735
Value Function Loss: 0.01964

Mean KL Divergence: 0.01709
SB3 Clip Fraction: 0.20931
Policy Update Magnitude: 0.35547
Value Function Update Magnitude: 0.29575

Collected Steps per Second: 22,773.17875
Overall Steps per Second: 10,881.85789

Timestep Collection Time: 2.19574
Timestep Consumption Time: 2.39943
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.59517

Cumulative Model Updates: 175,802
Cumulative Timesteps: 1,466,080,312

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1466080312...
Checkpoint 1466080312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 751,521.41545
Policy Entropy: 3.63513
Value Function Loss: 0.06229

Mean KL Divergence: 0.02582
SB3 Clip Fraction: 0.25814
Policy Update Magnitude: 0.42919
Value Function Update Magnitude: 0.31991

Collected Steps per Second: 22,424.04319
Overall Steps per Second: 10,666.56838

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.45819
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.68829

Cumulative Model Updates: 175,808
Cumulative Timesteps: 1,466,130,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 391,484.74494
Policy Entropy: 3.61193
Value Function Loss: 0.10750

Mean KL Divergence: 0.02269
SB3 Clip Fraction: 0.22713
Policy Update Magnitude: 0.61113
Value Function Update Magnitude: 0.44694

Collected Steps per Second: 22,359.43610
Overall Steps per Second: 10,790.69356

Timestep Collection Time: 2.23628
Timestep Consumption Time: 2.39753
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.63381

Cumulative Model Updates: 175,814
Cumulative Timesteps: 1,466,180,322

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1466180322...
Checkpoint 1466180322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,672.53417
Policy Entropy: 3.64367
Value Function Loss: 0.15128

Mean KL Divergence: 0.02417
SB3 Clip Fraction: 0.21420
Policy Update Magnitude: 0.79947
Value Function Update Magnitude: 0.47459

Collected Steps per Second: 22,515.08508
Overall Steps per Second: 10,723.79943

Timestep Collection Time: 2.22153
Timestep Consumption Time: 2.44267
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.66421

Cumulative Model Updates: 175,820
Cumulative Timesteps: 1,466,230,340

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,708.97768
Policy Entropy: 3.77965
Value Function Loss: 0.13554

Mean KL Divergence: 0.01734
SB3 Clip Fraction: 0.17742
Policy Update Magnitude: 0.93697
Value Function Update Magnitude: 0.45063

Collected Steps per Second: 22,838.77737
Overall Steps per Second: 10,880.60493

Timestep Collection Time: 2.18970
Timestep Consumption Time: 2.40655
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.59625

Cumulative Model Updates: 175,826
Cumulative Timesteps: 1,466,280,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1466280350...
Checkpoint 1466280350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,636.73830
Policy Entropy: 3.84475
Value Function Loss: 0.11493

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.16252
Policy Update Magnitude: 0.99613
Value Function Update Magnitude: 0.57381

Collected Steps per Second: 22,336.39695
Overall Steps per Second: 10,730.96639

Timestep Collection Time: 2.23850
Timestep Consumption Time: 2.42091
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.65941

Cumulative Model Updates: 175,832
Cumulative Timesteps: 1,466,330,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.13550
Policy Entropy: 3.87252
Value Function Loss: 0.09950

Mean KL Divergence: 0.01720
SB3 Clip Fraction: 0.17289
Policy Update Magnitude: 1.14305
Value Function Update Magnitude: 0.66857

Collected Steps per Second: 22,869.78907
Overall Steps per Second: 10,864.82188

Timestep Collection Time: 2.18699
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.60348

Cumulative Model Updates: 175,838
Cumulative Timesteps: 1,466,380,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1466380366...
Checkpoint 1466380366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 309,320.34503
Policy Entropy: 3.89372
Value Function Loss: 0.09336

Mean KL Divergence: 0.01494
SB3 Clip Fraction: 0.16174
Policy Update Magnitude: 1.25902
Value Function Update Magnitude: 0.69490

Collected Steps per Second: 22,562.16608
Overall Steps per Second: 10,680.68649

Timestep Collection Time: 2.21654
Timestep Consumption Time: 2.46574
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.68228

Cumulative Model Updates: 175,844
Cumulative Timesteps: 1,466,430,376

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 595.02367
Policy Entropy: 3.94459
Value Function Loss: 0.07641

Mean KL Divergence: 0.01356
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 1.40708
Value Function Update Magnitude: 0.72364

Collected Steps per Second: 22,799.34895
Overall Steps per Second: 10,828.81519

Timestep Collection Time: 2.19313
Timestep Consumption Time: 2.42436
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.61749

Cumulative Model Updates: 175,850
Cumulative Timesteps: 1,466,480,378

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1466480378...
Checkpoint 1466480378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67.53543
Policy Entropy: 3.99524
Value Function Loss: 0.06282

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 1.44922
Value Function Update Magnitude: 0.77187

Collected Steps per Second: 22,412.14309
Overall Steps per Second: 10,683.28589

Timestep Collection Time: 2.23102
Timestep Consumption Time: 2.44937
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.68040

Cumulative Model Updates: 175,856
Cumulative Timesteps: 1,466,530,380

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,017.46015
Policy Entropy: 4.05096
Value Function Loss: 0.05633

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.11143
Policy Update Magnitude: 1.37676
Value Function Update Magnitude: 0.80884

Collected Steps per Second: 22,167.14410
Overall Steps per Second: 10,576.59282

Timestep Collection Time: 2.25667
Timestep Consumption Time: 2.47302
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.72969

Cumulative Model Updates: 175,862
Cumulative Timesteps: 1,466,580,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1466580404...
Checkpoint 1466580404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579.94307
Policy Entropy: 4.03151
Value Function Loss: 0.05756

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.10803
Policy Update Magnitude: 1.28734
Value Function Update Magnitude: 0.83995

Collected Steps per Second: 22,116.57761
Overall Steps per Second: 10,724.02749

Timestep Collection Time: 2.26192
Timestep Consumption Time: 2.40293
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.66485

Cumulative Model Updates: 175,868
Cumulative Timesteps: 1,466,630,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,524.91347
Policy Entropy: 3.98440
Value Function Loss: 0.06427

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.10070
Policy Update Magnitude: 1.24066
Value Function Update Magnitude: 0.77124

Collected Steps per Second: 22,294.49130
Overall Steps per Second: 10,708.66885

Timestep Collection Time: 2.24298
Timestep Consumption Time: 2.42670
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.66967

Cumulative Model Updates: 175,874
Cumulative Timesteps: 1,466,680,436

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1466680436...
Checkpoint 1466680436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,088.59539
Policy Entropy: 3.93621
Value Function Loss: 0.07078

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10960
Policy Update Magnitude: 1.15685
Value Function Update Magnitude: 0.77492

Collected Steps per Second: 22,390.67410
Overall Steps per Second: 10,652.46157

Timestep Collection Time: 2.23361
Timestep Consumption Time: 2.46127
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.69488

Cumulative Model Updates: 175,880
Cumulative Timesteps: 1,466,730,448

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,037.73888
Policy Entropy: 3.97379
Value Function Loss: 0.06995

Mean KL Divergence: 0.00713
SB3 Clip Fraction: 0.08889
Policy Update Magnitude: 1.06997
Value Function Update Magnitude: 0.76976

Collected Steps per Second: 22,857.64112
Overall Steps per Second: 10,846.09706

Timestep Collection Time: 2.18815
Timestep Consumption Time: 2.42328
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.61143

Cumulative Model Updates: 175,886
Cumulative Timesteps: 1,466,780,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1466780464...
Checkpoint 1466780464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62.83815
Policy Entropy: 4.02684
Value Function Loss: 0.06494

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07900
Policy Update Magnitude: 1.05471
Value Function Update Magnitude: 0.73052

Collected Steps per Second: 22,763.88586
Overall Steps per Second: 10,689.26685

Timestep Collection Time: 2.19699
Timestep Consumption Time: 2.48172
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.67871

Cumulative Model Updates: 175,892
Cumulative Timesteps: 1,466,830,476

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,796.40753
Policy Entropy: 4.03680
Value Function Loss: 0.06363

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07845
Policy Update Magnitude: 0.99930
Value Function Update Magnitude: 0.73655

Collected Steps per Second: 22,731.48598
Overall Steps per Second: 10,882.90588

Timestep Collection Time: 2.19977
Timestep Consumption Time: 2.39496
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.59473

Cumulative Model Updates: 175,898
Cumulative Timesteps: 1,466,880,480

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1466880480...
Checkpoint 1466880480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.01001
Policy Entropy: 4.01989
Value Function Loss: 0.06501

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09457
Policy Update Magnitude: 0.89679
Value Function Update Magnitude: 0.75695

Collected Steps per Second: 22,976.95006
Overall Steps per Second: 10,779.64054

Timestep Collection Time: 2.17836
Timestep Consumption Time: 2.46484
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.64320

Cumulative Model Updates: 175,904
Cumulative Timesteps: 1,466,930,532

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.59501
Policy Entropy: 3.95624
Value Function Loss: 0.06889

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.14077
Policy Update Magnitude: 0.68125
Value Function Update Magnitude: 0.72357

Collected Steps per Second: 22,909.97431
Overall Steps per Second: 10,780.45188

Timestep Collection Time: 2.18368
Timestep Consumption Time: 2.45694
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.64062

Cumulative Model Updates: 175,910
Cumulative Timesteps: 1,466,980,560

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1466980560...
Checkpoint 1466980560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,199.48346
Policy Entropy: 3.93018
Value Function Loss: 0.06655

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10870
Policy Update Magnitude: 0.52540
Value Function Update Magnitude: 0.60612

Collected Steps per Second: 22,575.51600
Overall Steps per Second: 10,644.73930

Timestep Collection Time: 2.21479
Timestep Consumption Time: 2.48237
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.69716

Cumulative Model Updates: 175,916
Cumulative Timesteps: 1,467,030,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,466.74961
Policy Entropy: 3.89547
Value Function Loss: 0.06252

Mean KL Divergence: 0.01780
SB3 Clip Fraction: 0.18394
Policy Update Magnitude: 0.50233
Value Function Update Magnitude: 0.64579

Collected Steps per Second: 22,994.35590
Overall Steps per Second: 10,916.45282

Timestep Collection Time: 2.17540
Timestep Consumption Time: 2.40685
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.58226

Cumulative Model Updates: 175,922
Cumulative Timesteps: 1,467,080,582

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1467080582...
Checkpoint 1467080582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83.34775
Policy Entropy: 3.88270
Value Function Loss: 0.06284

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.14779
Policy Update Magnitude: 0.50412
Value Function Update Magnitude: 0.59106

Collected Steps per Second: 22,414.95327
Overall Steps per Second: 10,661.98315

Timestep Collection Time: 2.23110
Timestep Consumption Time: 2.45940
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.69050

Cumulative Model Updates: 175,928
Cumulative Timesteps: 1,467,130,592

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,633.79159
Policy Entropy: 3.87643
Value Function Loss: 0.06092

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.56301
Value Function Update Magnitude: 0.60093

Collected Steps per Second: 22,667.60552
Overall Steps per Second: 10,828.81474

Timestep Collection Time: 2.20694
Timestep Consumption Time: 2.41277
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.61971

Cumulative Model Updates: 175,934
Cumulative Timesteps: 1,467,180,618

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1467180618...
Checkpoint 1467180618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,812.86212
Policy Entropy: 3.83873
Value Function Loss: 0.06149

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.44260
Value Function Update Magnitude: 0.64395

Collected Steps per Second: 22,555.08662
Overall Steps per Second: 10,693.93533

Timestep Collection Time: 2.21697
Timestep Consumption Time: 2.45895
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.67592

Cumulative Model Updates: 175,940
Cumulative Timesteps: 1,467,230,622

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,820.38719
Policy Entropy: 3.82143
Value Function Loss: 0.05580

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.16094
Policy Update Magnitude: 0.35047
Value Function Update Magnitude: 0.55449

Collected Steps per Second: 22,825.87468
Overall Steps per Second: 10,886.32922

Timestep Collection Time: 2.19155
Timestep Consumption Time: 2.40357
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.59512

Cumulative Model Updates: 175,946
Cumulative Timesteps: 1,467,280,646

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1467280646...
Checkpoint 1467280646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,548.37363
Policy Entropy: 3.77348
Value Function Loss: 0.05990

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.32617
Value Function Update Magnitude: 0.56823

Collected Steps per Second: 22,438.47527
Overall Steps per Second: 10,666.27574

Timestep Collection Time: 2.22832
Timestep Consumption Time: 2.45936
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.68767

Cumulative Model Updates: 175,952
Cumulative Timesteps: 1,467,330,646

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,243.57340
Policy Entropy: 3.75137
Value Function Loss: 0.05720

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14614
Policy Update Magnitude: 0.35496
Value Function Update Magnitude: 0.51029

Collected Steps per Second: 22,873.09722
Overall Steps per Second: 10,897.64057

Timestep Collection Time: 2.18624
Timestep Consumption Time: 2.40246
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.58870

Cumulative Model Updates: 175,958
Cumulative Timesteps: 1,467,380,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1467380652...
Checkpoint 1467380652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,171.49179
Policy Entropy: 3.72836
Value Function Loss: 0.06669

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13977
Policy Update Magnitude: 0.39752
Value Function Update Magnitude: 0.39381

Collected Steps per Second: 23,076.88475
Overall Steps per Second: 10,701.49541

Timestep Collection Time: 2.16762
Timestep Consumption Time: 2.50668
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.67430

Cumulative Model Updates: 175,964
Cumulative Timesteps: 1,467,430,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,863.67177
Policy Entropy: 3.76599
Value Function Loss: 0.05242

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14241
Policy Update Magnitude: 0.37426
Value Function Update Magnitude: 0.34659

Collected Steps per Second: 22,903.61356
Overall Steps per Second: 10,850.71860

Timestep Collection Time: 2.18332
Timestep Consumption Time: 2.42522
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.60854

Cumulative Model Updates: 175,970
Cumulative Timesteps: 1,467,480,680

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1467480680...
Checkpoint 1467480680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 668.73852
Policy Entropy: 3.74780
Value Function Loss: 0.04798

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14326
Policy Update Magnitude: 0.34620
Value Function Update Magnitude: 0.42342

Collected Steps per Second: 22,758.98093
Overall Steps per Second: 10,653.31051

Timestep Collection Time: 2.19702
Timestep Consumption Time: 2.49654
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.69356

Cumulative Model Updates: 175,976
Cumulative Timesteps: 1,467,530,682

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183.85180
Policy Entropy: 3.76633
Value Function Loss: 0.03803

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14625
Policy Update Magnitude: 0.32776
Value Function Update Magnitude: 0.38659

Collected Steps per Second: 22,391.94813
Overall Steps per Second: 10,600.34056

Timestep Collection Time: 2.23491
Timestep Consumption Time: 2.48607
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.72098

Cumulative Model Updates: 175,982
Cumulative Timesteps: 1,467,580,726

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1467580726...
Checkpoint 1467580726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183.85180
Policy Entropy: 3.73153
Value Function Loss: 0.03384

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.32405
Value Function Update Magnitude: 0.38828

Collected Steps per Second: 22,881.81205
Overall Steps per Second: 10,852.43200

Timestep Collection Time: 2.18628
Timestep Consumption Time: 2.42338
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.60966

Cumulative Model Updates: 175,988
Cumulative Timesteps: 1,467,630,752

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,147.14238
Policy Entropy: 3.74606
Value Function Loss: 0.02912

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14461
Policy Update Magnitude: 0.33750
Value Function Update Magnitude: 0.39383

Collected Steps per Second: 23,184.20818
Overall Steps per Second: 10,946.73110

Timestep Collection Time: 2.15664
Timestep Consumption Time: 2.41093
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.56757

Cumulative Model Updates: 175,994
Cumulative Timesteps: 1,467,680,752

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1467680752...
Checkpoint 1467680752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,789.38932
Policy Entropy: 3.71602
Value Function Loss: 0.03428

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.33780
Value Function Update Magnitude: 0.47676

Collected Steps per Second: 21,879.17661
Overall Steps per Second: 10,731.30476

Timestep Collection Time: 2.28647
Timestep Consumption Time: 2.37522
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.66169

Cumulative Model Updates: 176,000
Cumulative Timesteps: 1,467,730,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,956.76724
Policy Entropy: 3.73931
Value Function Loss: 0.03607

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.36425
Value Function Update Magnitude: 0.48738

Collected Steps per Second: 22,230.83347
Overall Steps per Second: 10,865.14464

Timestep Collection Time: 2.25003
Timestep Consumption Time: 2.35368
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.60371

Cumulative Model Updates: 176,006
Cumulative Timesteps: 1,467,780,798

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1467780798...
Checkpoint 1467780798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,681.39098
Policy Entropy: 3.73100
Value Function Loss: 0.04652

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.38029
Value Function Update Magnitude: 0.45780

Collected Steps per Second: 21,864.73902
Overall Steps per Second: 10,681.68066

Timestep Collection Time: 2.28697
Timestep Consumption Time: 2.39432
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.68129

Cumulative Model Updates: 176,012
Cumulative Timesteps: 1,467,830,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,514.63482
Policy Entropy: 3.76377
Value Function Loss: 0.04830

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.41484
Value Function Update Magnitude: 0.63007

Collected Steps per Second: 22,660.30063
Overall Steps per Second: 10,912.46895

Timestep Collection Time: 2.20774
Timestep Consumption Time: 2.37674
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.58448

Cumulative Model Updates: 176,018
Cumulative Timesteps: 1,467,880,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1467880830...
Checkpoint 1467880830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,234.57270
Policy Entropy: 3.77906
Value Function Loss: 0.05238

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.44900
Value Function Update Magnitude: 0.70108

Collected Steps per Second: 22,009.52878
Overall Steps per Second: 10,675.62456

Timestep Collection Time: 2.27211
Timestep Consumption Time: 2.41221
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.68432

Cumulative Model Updates: 176,024
Cumulative Timesteps: 1,467,930,838

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 769.23083
Policy Entropy: 3.78535
Value Function Loss: 0.04658

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12668
Policy Update Magnitude: 0.45237
Value Function Update Magnitude: 0.65913

Collected Steps per Second: 22,332.20098
Overall Steps per Second: 10,764.92986

Timestep Collection Time: 2.23973
Timestep Consumption Time: 2.40666
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.64638

Cumulative Model Updates: 176,030
Cumulative Timesteps: 1,467,980,856

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1467980856...
Checkpoint 1467980856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,384.83864
Policy Entropy: 3.75282
Value Function Loss: 0.04600

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.46508
Value Function Update Magnitude: 0.76991

Collected Steps per Second: 22,794.99356
Overall Steps per Second: 10,722.19213

Timestep Collection Time: 2.19460
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.66565

Cumulative Model Updates: 176,036
Cumulative Timesteps: 1,468,030,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,251.05043
Policy Entropy: 3.72696
Value Function Loss: 0.04059

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.45701
Value Function Update Magnitude: 0.82586

Collected Steps per Second: 23,172.69691
Overall Steps per Second: 10,976.39169

Timestep Collection Time: 2.15840
Timestep Consumption Time: 2.39829
PPO Batch Consumption Time: 0.27589
Total Iteration Time: 4.55669

Cumulative Model Updates: 176,042
Cumulative Timesteps: 1,468,080,898

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1468080898...
Checkpoint 1468080898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,625.18432
Policy Entropy: 3.70515
Value Function Loss: 0.03671

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.15275
Policy Update Magnitude: 0.41508
Value Function Update Magnitude: 0.72995

Collected Steps per Second: 22,712.53568
Overall Steps per Second: 10,675.72617

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.48319
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.68558

Cumulative Model Updates: 176,048
Cumulative Timesteps: 1,468,130,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,886.48192
Policy Entropy: 3.71002
Value Function Loss: 0.03261

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.14079
Policy Update Magnitude: 0.39068
Value Function Update Magnitude: 0.55651

Collected Steps per Second: 22,909.61130
Overall Steps per Second: 10,860.54871

Timestep Collection Time: 2.18389
Timestep Consumption Time: 2.42288
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.60677

Cumulative Model Updates: 176,054
Cumulative Timesteps: 1,468,180,952

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1468180952...
Checkpoint 1468180952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,886.48192
Policy Entropy: 3.68984
Value Function Loss: 0.02642

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14832
Policy Update Magnitude: 0.37536
Value Function Update Magnitude: 0.58901

Collected Steps per Second: 22,548.55660
Overall Steps per Second: 10,604.03219

Timestep Collection Time: 2.21868
Timestep Consumption Time: 2.49915
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.71783

Cumulative Model Updates: 176,060
Cumulative Timesteps: 1,468,230,980

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,886.48192
Policy Entropy: 3.68282
Value Function Loss: 0.02540

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13679
Policy Update Magnitude: 0.35034
Value Function Update Magnitude: 0.65309

Collected Steps per Second: 23,245.48968
Overall Steps per Second: 10,921.09740

Timestep Collection Time: 2.15207
Timestep Consumption Time: 2.42860
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.58068

Cumulative Model Updates: 176,066
Cumulative Timesteps: 1,468,281,006

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1468281006...
Checkpoint 1468281006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,886.48192
Policy Entropy: 3.66594
Value Function Loss: 0.02468

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13904
Policy Update Magnitude: 0.35625
Value Function Update Magnitude: 0.56427

Collected Steps per Second: 22,699.73637
Overall Steps per Second: 10,622.21627

Timestep Collection Time: 2.20329
Timestep Consumption Time: 2.50515
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.70843

Cumulative Model Updates: 176,072
Cumulative Timesteps: 1,468,331,020

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,886.48192
Policy Entropy: 3.65856
Value Function Loss: 0.02843

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.37254
Value Function Update Magnitude: 0.46951

Collected Steps per Second: 22,943.92118
Overall Steps per Second: 10,857.81752

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.42624
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.60590

Cumulative Model Updates: 176,078
Cumulative Timesteps: 1,468,381,030

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1468381030...
Checkpoint 1468381030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,886.48192
Policy Entropy: 3.67420
Value Function Loss: 0.02935

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13426
Policy Update Magnitude: 0.41508
Value Function Update Magnitude: 0.51917

Collected Steps per Second: 22,552.76611
Overall Steps per Second: 10,703.60029

Timestep Collection Time: 2.21818
Timestep Consumption Time: 2.45558
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.67375

Cumulative Model Updates: 176,084
Cumulative Timesteps: 1,468,431,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,099.24822
Policy Entropy: 3.67556
Value Function Loss: 0.03283

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13897
Policy Update Magnitude: 0.40902
Value Function Update Magnitude: 0.48542

Collected Steps per Second: 23,171.61168
Overall Steps per Second: 10,918.06965

Timestep Collection Time: 2.15790
Timestep Consumption Time: 2.42185
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.57975

Cumulative Model Updates: 176,090
Cumulative Timesteps: 1,468,481,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1468481058...
Checkpoint 1468481058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,821.52144
Policy Entropy: 3.70466
Value Function Loss: 0.03053

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.38572
Value Function Update Magnitude: 0.49137

Collected Steps per Second: 22,643.41372
Overall Steps per Second: 10,635.84456

Timestep Collection Time: 2.20912
Timestep Consumption Time: 2.49403
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.70315

Cumulative Model Updates: 176,096
Cumulative Timesteps: 1,468,531,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,194.13615
Policy Entropy: 3.68707
Value Function Loss: 0.03841

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12599
Policy Update Magnitude: 0.36758
Value Function Update Magnitude: 0.45183

Collected Steps per Second: 22,857.44254
Overall Steps per Second: 10,853.85056

Timestep Collection Time: 2.18896
Timestep Consumption Time: 2.42083
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.60979

Cumulative Model Updates: 176,102
Cumulative Timesteps: 1,468,581,114

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1468581114...
Checkpoint 1468581114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,838.57935
Policy Entropy: 3.70733
Value Function Loss: 0.03440

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.39533
Value Function Update Magnitude: 0.50833

Collected Steps per Second: 22,647.77481
Overall Steps per Second: 10,733.40254

Timestep Collection Time: 2.20861
Timestep Consumption Time: 2.45161
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.66022

Cumulative Model Updates: 176,108
Cumulative Timesteps: 1,468,631,134

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,878.21156
Policy Entropy: 3.69067
Value Function Loss: 0.03607

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.38035
Value Function Update Magnitude: 0.46843

Collected Steps per Second: 23,071.91603
Overall Steps per Second: 10,936.99629

Timestep Collection Time: 2.16818
Timestep Consumption Time: 2.40566
PPO Batch Consumption Time: 0.27590
Total Iteration Time: 4.57383

Cumulative Model Updates: 176,114
Cumulative Timesteps: 1,468,681,158

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1468681158...
Checkpoint 1468681158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,878.21156
Policy Entropy: 3.70454
Value Function Loss: 0.02667

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.35045
Value Function Update Magnitude: 0.40607

Collected Steps per Second: 21,962.07790
Overall Steps per Second: 10,646.49030

Timestep Collection Time: 2.27802
Timestep Consumption Time: 2.42118
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.69920

Cumulative Model Updates: 176,120
Cumulative Timesteps: 1,468,731,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,878.21156
Policy Entropy: 3.69024
Value Function Loss: 0.02467

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13307
Policy Update Magnitude: 0.34447
Value Function Update Magnitude: 0.36512

Collected Steps per Second: 22,599.18352
Overall Steps per Second: 10,875.69028

Timestep Collection Time: 2.21327
Timestep Consumption Time: 2.38580
PPO Batch Consumption Time: 0.28319
Total Iteration Time: 4.59906

Cumulative Model Updates: 176,126
Cumulative Timesteps: 1,468,781,206

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1468781206...
Checkpoint 1468781206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,878.21156
Policy Entropy: 3.68911
Value Function Loss: 0.02072

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.33716
Value Function Update Magnitude: 0.34020

Collected Steps per Second: 22,071.20623
Overall Steps per Second: 10,674.54506

Timestep Collection Time: 2.26603
Timestep Consumption Time: 2.41932
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.68535

Cumulative Model Updates: 176,132
Cumulative Timesteps: 1,468,831,220

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,878.21156
Policy Entropy: 3.68204
Value Function Loss: 0.02081

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13775
Policy Update Magnitude: 0.31846
Value Function Update Magnitude: 0.33036

Collected Steps per Second: 22,601.22734
Overall Steps per Second: 10,849.51767

Timestep Collection Time: 2.21360
Timestep Consumption Time: 2.39767
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.61126

Cumulative Model Updates: 176,138
Cumulative Timesteps: 1,468,881,250

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1468881250...
Checkpoint 1468881250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,878.21156
Policy Entropy: 3.68783
Value Function Loss: 0.01808

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.29136
Value Function Update Magnitude: 0.31779

Collected Steps per Second: 22,659.12431
Overall Steps per Second: 10,695.49097

Timestep Collection Time: 2.20838
Timestep Consumption Time: 2.47023
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.67861

Cumulative Model Updates: 176,144
Cumulative Timesteps: 1,468,931,290

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,878.21156
Policy Entropy: 3.69623
Value Function Loss: 0.01859

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.27111
Value Function Update Magnitude: 0.28825

Collected Steps per Second: 22,951.92951
Overall Steps per Second: 10,833.92353

Timestep Collection Time: 2.17873
Timestep Consumption Time: 2.43696
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.61569

Cumulative Model Updates: 176,150
Cumulative Timesteps: 1,468,981,296

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1468981296...
Checkpoint 1468981296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,878.21156
Policy Entropy: 3.68772
Value Function Loss: 0.01794

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.27904
Value Function Update Magnitude: 0.28026

Collected Steps per Second: 22,602.66670
Overall Steps per Second: 10,681.50606

Timestep Collection Time: 2.21248
Timestep Consumption Time: 2.46925
PPO Batch Consumption Time: 0.28486
Total Iteration Time: 4.68174

Cumulative Model Updates: 176,156
Cumulative Timesteps: 1,469,031,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,617.53649
Policy Entropy: 3.68475
Value Function Loss: 0.02292

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.30014
Value Function Update Magnitude: 0.32839

Collected Steps per Second: 22,967.37703
Overall Steps per Second: 10,867.42208

Timestep Collection Time: 2.17735
Timestep Consumption Time: 2.42429
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.60164

Cumulative Model Updates: 176,162
Cumulative Timesteps: 1,469,081,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1469081312...
Checkpoint 1469081312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,617.53649
Policy Entropy: 3.67036
Value Function Loss: 0.02381

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.32965
Value Function Update Magnitude: 0.43630

Collected Steps per Second: 22,826.18331
Overall Steps per Second: 10,714.72665

Timestep Collection Time: 2.19073
Timestep Consumption Time: 2.47630
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.66703

Cumulative Model Updates: 176,168
Cumulative Timesteps: 1,469,131,318

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,617.53649
Policy Entropy: 3.67843
Value Function Loss: 0.02432

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.34042
Value Function Update Magnitude: 0.46661

Collected Steps per Second: 23,346.67705
Overall Steps per Second: 10,958.21263

Timestep Collection Time: 2.14163
Timestep Consumption Time: 2.42116
PPO Batch Consumption Time: 0.27599
Total Iteration Time: 4.56279

Cumulative Model Updates: 176,174
Cumulative Timesteps: 1,469,181,318

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1469181318...
Checkpoint 1469181318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,617.53649
Policy Entropy: 3.67314
Value Function Loss: 0.02148

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13275
Policy Update Magnitude: 0.31363
Value Function Update Magnitude: 0.42610

Collected Steps per Second: 22,702.49033
Overall Steps per Second: 10,692.51313

Timestep Collection Time: 2.20363
Timestep Consumption Time: 2.47515
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.67879

Cumulative Model Updates: 176,180
Cumulative Timesteps: 1,469,231,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,617.53649
Policy Entropy: 3.67309
Value Function Loss: 0.02052

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.29716
Value Function Update Magnitude: 0.35468

Collected Steps per Second: 22,572.11747
Overall Steps per Second: 10,788.07894

Timestep Collection Time: 2.21574
Timestep Consumption Time: 2.42030
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.63604

Cumulative Model Updates: 176,186
Cumulative Timesteps: 1,469,281,360

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1469281360...
Checkpoint 1469281360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,617.53649
Policy Entropy: 3.67730
Value Function Loss: 0.01791

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.27527
Value Function Update Magnitude: 0.29657

Collected Steps per Second: 22,003.70720
Overall Steps per Second: 10,659.76417

Timestep Collection Time: 2.27325
Timestep Consumption Time: 2.41916
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69241

Cumulative Model Updates: 176,192
Cumulative Timesteps: 1,469,331,380

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292,733.23348
Policy Entropy: 3.67661
Value Function Loss: 0.02248

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.29698
Value Function Update Magnitude: 0.35669

Collected Steps per Second: 22,269.63032
Overall Steps per Second: 10,624.87453

Timestep Collection Time: 2.24683
Timestep Consumption Time: 2.46250
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.70933

Cumulative Model Updates: 176,198
Cumulative Timesteps: 1,469,381,416

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1469381416...
Checkpoint 1469381416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270,494.47590
Policy Entropy: 3.68402
Value Function Loss: 0.02534

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.37569
Value Function Update Magnitude: 0.47685

Collected Steps per Second: 22,591.50195
Overall Steps per Second: 10,846.50878

Timestep Collection Time: 2.21446
Timestep Consumption Time: 2.39790
PPO Batch Consumption Time: 0.27691
Total Iteration Time: 4.61236

Cumulative Model Updates: 176,204
Cumulative Timesteps: 1,469,431,444

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,105.46118
Policy Entropy: 3.65595
Value Function Loss: 0.03144

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13509
Policy Update Magnitude: 0.38706
Value Function Update Magnitude: 0.45048

Collected Steps per Second: 23,073.35310
Overall Steps per Second: 10,948.42325

Timestep Collection Time: 2.16787
Timestep Consumption Time: 2.40083
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.56869

Cumulative Model Updates: 176,210
Cumulative Timesteps: 1,469,481,464

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1469481464...
Checkpoint 1469481464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,105.46118
Policy Entropy: 3.66265
Value Function Loss: 0.03015

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.40198
Value Function Update Magnitude: 0.38173

Collected Steps per Second: 22,654.38873
Overall Steps per Second: 10,676.41036

Timestep Collection Time: 2.20796
Timestep Consumption Time: 2.47713
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.68510

Cumulative Model Updates: 176,216
Cumulative Timesteps: 1,469,531,484

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,390.44755
Policy Entropy: 3.66023
Value Function Loss: 0.03451

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.40545
Value Function Update Magnitude: 0.39960

Collected Steps per Second: 23,051.93330
Overall Steps per Second: 10,874.81240

Timestep Collection Time: 2.17006
Timestep Consumption Time: 2.42993
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.59999

Cumulative Model Updates: 176,222
Cumulative Timesteps: 1,469,581,508

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1469581508...
Checkpoint 1469581508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,877.80023
Policy Entropy: 3.70154
Value Function Loss: 0.02925

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13510
Policy Update Magnitude: 0.41489
Value Function Update Magnitude: 0.50887

Collected Steps per Second: 22,651.49552
Overall Steps per Second: 10,668.06650

Timestep Collection Time: 2.20851
Timestep Consumption Time: 2.48081
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.68932

Cumulative Model Updates: 176,228
Cumulative Timesteps: 1,469,631,534

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,117.85515
Policy Entropy: 3.70409
Value Function Loss: 0.02924

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13799
Policy Update Magnitude: 0.40893
Value Function Update Magnitude: 0.61254

Collected Steps per Second: 22,281.39153
Overall Steps per Second: 10,533.07122

Timestep Collection Time: 2.24429
Timestep Consumption Time: 2.50323
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.74752

Cumulative Model Updates: 176,234
Cumulative Timesteps: 1,469,681,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1469681540...
Checkpoint 1469681540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,117.85515
Policy Entropy: 3.71006
Value Function Loss: 0.02272

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.39199
Value Function Update Magnitude: 0.59532

Collected Steps per Second: 22,433.31948
Overall Steps per Second: 10,579.77300

Timestep Collection Time: 2.22945
Timestep Consumption Time: 2.49787
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.72732

Cumulative Model Updates: 176,240
Cumulative Timesteps: 1,469,731,554

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,117.85515
Policy Entropy: 3.68262
Value Function Loss: 0.02268

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.34605
Value Function Update Magnitude: 0.48349

Collected Steps per Second: 23,090.01719
Overall Steps per Second: 10,884.00717

Timestep Collection Time: 2.16656
Timestep Consumption Time: 2.42972
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.59629

Cumulative Model Updates: 176,246
Cumulative Timesteps: 1,469,781,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1469781580...
Checkpoint 1469781580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,117.85515
Policy Entropy: 3.68857
Value Function Loss: 0.01923

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.31912
Value Function Update Magnitude: 0.36194

Collected Steps per Second: 22,788.78938
Overall Steps per Second: 10,642.15310

Timestep Collection Time: 2.19468
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.69961

Cumulative Model Updates: 176,252
Cumulative Timesteps: 1,469,831,594

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,117.85515
Policy Entropy: 3.68406
Value Function Loss: 0.01925

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.30439
Value Function Update Magnitude: 0.32329

Collected Steps per Second: 23,218.71826
Overall Steps per Second: 10,922.69971

Timestep Collection Time: 2.15395
Timestep Consumption Time: 2.42477
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.57872

Cumulative Model Updates: 176,258
Cumulative Timesteps: 1,469,881,606

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1469881606...
Checkpoint 1469881606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,999.57209
Policy Entropy: 3.69332
Value Function Loss: 0.01872

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12810
Policy Update Magnitude: 0.33711
Value Function Update Magnitude: 0.32241

Collected Steps per Second: 22,896.24810
Overall Steps per Second: 10,706.60327

Timestep Collection Time: 2.18411
Timestep Consumption Time: 2.48665
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.67076

Cumulative Model Updates: 176,264
Cumulative Timesteps: 1,469,931,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,685.87156
Policy Entropy: 3.67899
Value Function Loss: 0.02777

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.39512
Value Function Update Magnitude: 0.47308

Collected Steps per Second: 22,993.49869
Overall Steps per Second: 10,885.53011

Timestep Collection Time: 2.17548
Timestep Consumption Time: 2.41979
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.59527

Cumulative Model Updates: 176,270
Cumulative Timesteps: 1,469,981,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1469981636...
Checkpoint 1469981636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,685.87156
Policy Entropy: 3.67989
Value Function Loss: 0.02670

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11104
Policy Update Magnitude: 0.49211
Value Function Update Magnitude: 0.49750

Collected Steps per Second: 22,616.15298
Overall Steps per Second: 10,636.83114

Timestep Collection Time: 2.21152
Timestep Consumption Time: 2.49064
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.70215

Cumulative Model Updates: 176,276
Cumulative Timesteps: 1,470,031,652

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,879.16182
Policy Entropy: 3.67634
Value Function Loss: 0.03796

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.51973
Value Function Update Magnitude: 0.54398

Collected Steps per Second: 22,897.79411
Overall Steps per Second: 10,841.14629

Timestep Collection Time: 2.18370
Timestep Consumption Time: 2.42854
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.61224

Cumulative Model Updates: 176,282
Cumulative Timesteps: 1,470,081,654

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1470081654...
Checkpoint 1470081654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,638.92650
Policy Entropy: 3.70971
Value Function Loss: 0.03867

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.15824
Policy Update Magnitude: 0.53150
Value Function Update Magnitude: 0.60581

Collected Steps per Second: 22,698.28366
Overall Steps per Second: 10,666.42871

Timestep Collection Time: 2.20334
Timestep Consumption Time: 2.48539
PPO Batch Consumption Time: 0.28923
Total Iteration Time: 4.68873

Cumulative Model Updates: 176,288
Cumulative Timesteps: 1,470,131,666

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,254.29872
Policy Entropy: 3.71121
Value Function Loss: 0.04605

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16738
Policy Update Magnitude: 0.47775
Value Function Update Magnitude: 0.52171

Collected Steps per Second: 23,363.00339
Overall Steps per Second: 10,962.17395

Timestep Collection Time: 2.14168
Timestep Consumption Time: 2.42275
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.56442

Cumulative Model Updates: 176,294
Cumulative Timesteps: 1,470,181,702

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1470181702...
Checkpoint 1470181702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,531.17688
Policy Entropy: 3.71334
Value Function Loss: 0.03891

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15212
Policy Update Magnitude: 0.43809
Value Function Update Magnitude: 0.43902

Collected Steps per Second: 22,681.58886
Overall Steps per Second: 10,649.62930

Timestep Collection Time: 2.20522
Timestep Consumption Time: 2.49146
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.69669

Cumulative Model Updates: 176,300
Cumulative Timesteps: 1,470,231,720

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,531.17688
Policy Entropy: 3.68471
Value Function Loss: 0.03109

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14159
Policy Update Magnitude: 0.39032
Value Function Update Magnitude: 0.42544

Collected Steps per Second: 23,079.96260
Overall Steps per Second: 10,908.19511

Timestep Collection Time: 2.16759
Timestep Consumption Time: 2.41868
PPO Batch Consumption Time: 0.27600
Total Iteration Time: 4.58628

Cumulative Model Updates: 176,306
Cumulative Timesteps: 1,470,281,748

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1470281748...
Checkpoint 1470281748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,531.17688
Policy Entropy: 3.68576
Value Function Loss: 0.02500

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12603
Policy Update Magnitude: 0.38371
Value Function Update Magnitude: 0.38313

Collected Steps per Second: 22,680.27925
Overall Steps per Second: 10,649.06863

Timestep Collection Time: 2.20553
Timestep Consumption Time: 2.49178
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.69731

Cumulative Model Updates: 176,312
Cumulative Timesteps: 1,470,331,770

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,468.46205
Policy Entropy: 3.69925
Value Function Loss: 0.02948

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.43025
Value Function Update Magnitude: 0.43302

Collected Steps per Second: 23,027.61103
Overall Steps per Second: 10,905.35059

Timestep Collection Time: 2.17191
Timestep Consumption Time: 2.41427
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.58619

Cumulative Model Updates: 176,318
Cumulative Timesteps: 1,470,381,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1470381784...
Checkpoint 1470381784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,386.32635
Policy Entropy: 3.70277
Value Function Loss: 0.03268

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.17104
Policy Update Magnitude: 0.48377
Value Function Update Magnitude: 0.61094

Collected Steps per Second: 22,491.02922
Overall Steps per Second: 10,574.29971

Timestep Collection Time: 2.22355
Timestep Consumption Time: 2.50584
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.72939

Cumulative Model Updates: 176,324
Cumulative Timesteps: 1,470,431,794

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,506.07794
Policy Entropy: 3.70892
Value Function Loss: 0.03823

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.49195
Value Function Update Magnitude: 0.61308

Collected Steps per Second: 22,997.07138
Overall Steps per Second: 10,887.03411

Timestep Collection Time: 2.17549
Timestep Consumption Time: 2.41988
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.59537

Cumulative Model Updates: 176,330
Cumulative Timesteps: 1,470,481,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1470481824...
Checkpoint 1470481824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,261.31074
Policy Entropy: 3.69347
Value Function Loss: 0.04197

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.15470
Policy Update Magnitude: 0.55700
Value Function Update Magnitude: 0.47808

Collected Steps per Second: 22,485.47169
Overall Steps per Second: 10,653.21269

Timestep Collection Time: 2.22473
Timestep Consumption Time: 2.47095
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.69567

Cumulative Model Updates: 176,336
Cumulative Timesteps: 1,470,531,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 263,825.58905
Policy Entropy: 3.66905
Value Function Loss: 0.05462

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.14651
Policy Update Magnitude: 0.63365
Value Function Update Magnitude: 0.40556

Collected Steps per Second: 23,007.98378
Overall Steps per Second: 10,859.00134

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.43171
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.60521

Cumulative Model Updates: 176,342
Cumulative Timesteps: 1,470,581,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1470581856...
Checkpoint 1470581856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,292.44776
Policy Entropy: 3.68015
Value Function Loss: 0.06121

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.17717
Policy Update Magnitude: 0.75656
Value Function Update Magnitude: 0.37228

Collected Steps per Second: 22,626.79088
Overall Steps per Second: 10,694.72582

Timestep Collection Time: 2.21012
Timestep Consumption Time: 2.46583
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.67595

Cumulative Model Updates: 176,348
Cumulative Timesteps: 1,470,631,864

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,436.48742
Policy Entropy: 3.69466
Value Function Loss: 0.05629

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.21370
Policy Update Magnitude: 0.65496
Value Function Update Magnitude: 0.44474

Collected Steps per Second: 22,929.19845
Overall Steps per Second: 10,880.45477

Timestep Collection Time: 2.18089
Timestep Consumption Time: 2.41506
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.59595

Cumulative Model Updates: 176,354
Cumulative Timesteps: 1,470,681,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1470681870...
Checkpoint 1470681870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.70285
Value Function Loss: 0.05246

Mean KL Divergence: 0.01465
SB3 Clip Fraction: 0.18021
Policy Update Magnitude: 0.62684
Value Function Update Magnitude: 0.49311

Collected Steps per Second: 22,473.88338
Overall Steps per Second: 10,680.32450

Timestep Collection Time: 2.22525
Timestep Consumption Time: 2.45719
PPO Batch Consumption Time: 0.28467
Total Iteration Time: 4.68244

Cumulative Model Updates: 176,360
Cumulative Timesteps: 1,470,731,880

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.70092
Value Function Loss: 0.04254

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.18967
Policy Update Magnitude: 0.61161
Value Function Update Magnitude: 0.55534

Collected Steps per Second: 22,928.72465
Overall Steps per Second: 10,844.58728

Timestep Collection Time: 2.18137
Timestep Consumption Time: 2.43070
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.61207

Cumulative Model Updates: 176,366
Cumulative Timesteps: 1,470,781,896

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1470781896...
Checkpoint 1470781896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.72261
Value Function Loss: 0.03364

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.18069
Policy Update Magnitude: 0.55897
Value Function Update Magnitude: 0.52197

Collected Steps per Second: 22,689.47131
Overall Steps per Second: 10,655.64585

Timestep Collection Time: 2.20428
Timestep Consumption Time: 2.48938
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.69366

Cumulative Model Updates: 176,372
Cumulative Timesteps: 1,470,831,910

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.73107
Value Function Loss: 0.02579

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.15178
Policy Update Magnitude: 0.40095
Value Function Update Magnitude: 0.40726

Collected Steps per Second: 22,944.16041
Overall Steps per Second: 10,857.18663

Timestep Collection Time: 2.17929
Timestep Consumption Time: 2.42614
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.60543

Cumulative Model Updates: 176,378
Cumulative Timesteps: 1,470,881,912

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1470881912...
Checkpoint 1470881912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.71542
Value Function Loss: 0.02354

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14845
Policy Update Magnitude: 0.33335
Value Function Update Magnitude: 0.33731

Collected Steps per Second: 22,692.49425
Overall Steps per Second: 10,751.64930

Timestep Collection Time: 2.20434
Timestep Consumption Time: 2.44815
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.65250

Cumulative Model Updates: 176,384
Cumulative Timesteps: 1,470,931,934

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.69529
Value Function Loss: 0.02439

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.21061
Policy Update Magnitude: 0.33901
Value Function Update Magnitude: 0.35068

Collected Steps per Second: 23,122.79623
Overall Steps per Second: 10,929.76952

Timestep Collection Time: 2.16289
Timestep Consumption Time: 2.41287
PPO Batch Consumption Time: 0.27641
Total Iteration Time: 4.57576

Cumulative Model Updates: 176,390
Cumulative Timesteps: 1,470,981,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1470981946...
Checkpoint 1470981946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.68597
Value Function Loss: 0.02164

Mean KL Divergence: 0.03329
SB3 Clip Fraction: 0.32888
Policy Update Magnitude: 0.28901
Value Function Update Magnitude: 0.36218

Collected Steps per Second: 22,545.96837
Overall Steps per Second: 10,582.74368

Timestep Collection Time: 2.21893
Timestep Consumption Time: 2.50839
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.72732

Cumulative Model Updates: 176,396
Cumulative Timesteps: 1,471,031,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.70209
Value Function Loss: 0.02682

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.19003
Policy Update Magnitude: 0.27662
Value Function Update Magnitude: 0.35117

Collected Steps per Second: 23,202.38777
Overall Steps per Second: 10,901.50385

Timestep Collection Time: 2.15598
Timestep Consumption Time: 2.43274
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.58872

Cumulative Model Updates: 176,402
Cumulative Timesteps: 1,471,081,998

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1471081998...
Checkpoint 1471081998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.69836
Value Function Loss: 0.03313

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.17321
Policy Update Magnitude: 0.37471
Value Function Update Magnitude: 0.38253

Collected Steps per Second: 22,407.48042
Overall Steps per Second: 10,634.16287

Timestep Collection Time: 2.23158
Timestep Consumption Time: 2.47063
PPO Batch Consumption Time: 0.28404
Total Iteration Time: 4.70220

Cumulative Model Updates: 176,408
Cumulative Timesteps: 1,471,132,002

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.69636
Value Function Loss: 0.03986

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14324
Policy Update Magnitude: 0.41422
Value Function Update Magnitude: 0.32192

Collected Steps per Second: 23,229.26216
Overall Steps per Second: 10,931.36010

Timestep Collection Time: 2.15340
Timestep Consumption Time: 2.42260
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.57601

Cumulative Model Updates: 176,414
Cumulative Timesteps: 1,471,182,024

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1471182024...
Checkpoint 1471182024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.70236
Value Function Loss: 0.03288

Mean KL Divergence: 0.01190
SB3 Clip Fraction: 0.15731
Policy Update Magnitude: 0.41451
Value Function Update Magnitude: 0.32431

Collected Steps per Second: 22,446.69818
Overall Steps per Second: 10,663.79593

Timestep Collection Time: 2.22875
Timestep Consumption Time: 2.46264
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.69139

Cumulative Model Updates: 176,420
Cumulative Timesteps: 1,471,232,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.67683
Value Function Loss: 0.04110

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.18839
Policy Update Magnitude: 0.42803
Value Function Update Magnitude: 0.38226

Collected Steps per Second: 23,052.26540
Overall Steps per Second: 10,929.92590

Timestep Collection Time: 2.16968
Timestep Consumption Time: 2.40638
PPO Batch Consumption Time: 0.27649
Total Iteration Time: 4.57606

Cumulative Model Updates: 176,426
Cumulative Timesteps: 1,471,282,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1471282068...
Checkpoint 1471282068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.67490
Value Function Loss: 0.04624

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.67656
Value Function Update Magnitude: 0.41256

Collected Steps per Second: 21,651.67613
Overall Steps per Second: 10,647.00532

Timestep Collection Time: 2.31169
Timestep Consumption Time: 2.38935
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.70104

Cumulative Model Updates: 176,432
Cumulative Timesteps: 1,471,332,120

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.68449
Value Function Loss: 0.04271

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.73474
Value Function Update Magnitude: 0.37221

Collected Steps per Second: 22,441.06864
Overall Steps per Second: 10,953.65530

Timestep Collection Time: 2.22931
Timestep Consumption Time: 2.33794
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.56724

Cumulative Model Updates: 176,438
Cumulative Timesteps: 1,471,382,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1471382148...
Checkpoint 1471382148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.70133
Value Function Loss: 0.03106

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.09805
Policy Update Magnitude: 0.65360
Value Function Update Magnitude: 0.39269

Collected Steps per Second: 22,088.13855
Overall Steps per Second: 10,568.92995

Timestep Collection Time: 2.26447
Timestep Consumption Time: 2.46808
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.73255

Cumulative Model Updates: 176,444
Cumulative Timesteps: 1,471,432,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,292.59339
Policy Entropy: 3.71451
Value Function Loss: 0.02778

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08385
Policy Update Magnitude: 0.60886
Value Function Update Magnitude: 0.42317

Collected Steps per Second: 23,383.80510
Overall Steps per Second: 10,906.93798

Timestep Collection Time: 2.14003
Timestep Consumption Time: 2.44806
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.58809

Cumulative Model Updates: 176,450
Cumulative Timesteps: 1,471,482,208

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1471482208...
Checkpoint 1471482208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,163.57342
Policy Entropy: 3.67865
Value Function Loss: 0.03527

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07155
Policy Update Magnitude: 0.61028
Value Function Update Magnitude: 0.54924

Collected Steps per Second: 22,500.03216
Overall Steps per Second: 10,668.61434

Timestep Collection Time: 2.22337
Timestep Consumption Time: 2.46571
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.68908

Cumulative Model Updates: 176,456
Cumulative Timesteps: 1,471,532,234

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,961.82327
Policy Entropy: 3.69603
Value Function Loss: 0.03941

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09789
Policy Update Magnitude: 0.62463
Value Function Update Magnitude: 0.68613

Collected Steps per Second: 23,206.82477
Overall Steps per Second: 10,942.09988

Timestep Collection Time: 2.15506
Timestep Consumption Time: 2.41555
PPO Batch Consumption Time: 0.27625
Total Iteration Time: 4.57060

Cumulative Model Updates: 176,462
Cumulative Timesteps: 1,471,582,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1471582246...
Checkpoint 1471582246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,839.32901
Policy Entropy: 3.69424
Value Function Loss: 0.04743

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16324
Policy Update Magnitude: 0.53749
Value Function Update Magnitude: 0.62344

Collected Steps per Second: 22,575.98210
Overall Steps per Second: 10,594.51414

Timestep Collection Time: 2.21625
Timestep Consumption Time: 2.50638
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.72263

Cumulative Model Updates: 176,468
Cumulative Timesteps: 1,471,632,280

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,272.80319
Policy Entropy: 3.69147
Value Function Loss: 0.05189

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.16532
Policy Update Magnitude: 0.51132
Value Function Update Magnitude: 0.48571

Collected Steps per Second: 22,803.16135
Overall Steps per Second: 10,851.33495

Timestep Collection Time: 2.19356
Timestep Consumption Time: 2.41602
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.60957

Cumulative Model Updates: 176,474
Cumulative Timesteps: 1,471,682,300

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1471682300...
Checkpoint 1471682300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 430,886.85563
Policy Entropy: 3.65614
Value Function Loss: 0.06070

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.16169
Policy Update Magnitude: 0.51206
Value Function Update Magnitude: 0.45713

Collected Steps per Second: 22,553.35291
Overall Steps per Second: 10,683.21495

Timestep Collection Time: 2.21723
Timestep Consumption Time: 2.46357
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.68080

Cumulative Model Updates: 176,480
Cumulative Timesteps: 1,471,732,306

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239,295.99007
Policy Entropy: 3.66789
Value Function Loss: 0.06708

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.15101
Policy Update Magnitude: 0.58948
Value Function Update Magnitude: 0.39282

Collected Steps per Second: 22,918.22285
Overall Steps per Second: 10,852.02101

Timestep Collection Time: 2.18202
Timestep Consumption Time: 2.42615
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.60817

Cumulative Model Updates: 176,486
Cumulative Timesteps: 1,471,782,314

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1471782314...
Checkpoint 1471782314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291,082.39455
Policy Entropy: 3.67654
Value Function Loss: 0.08015

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.63072
Value Function Update Magnitude: 0.36417

Collected Steps per Second: 22,258.92248
Overall Steps per Second: 10,748.45998

Timestep Collection Time: 2.24764
Timestep Consumption Time: 2.40698
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.65462

Cumulative Model Updates: 176,492
Cumulative Timesteps: 1,471,832,344

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,803.45830
Policy Entropy: 3.71414
Value Function Loss: 0.08837

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11535
Policy Update Magnitude: 0.79549
Value Function Update Magnitude: 0.36833

Collected Steps per Second: 22,088.21597
Overall Steps per Second: 10,526.70190

Timestep Collection Time: 2.26591
Timestep Consumption Time: 2.48866
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.75458

Cumulative Model Updates: 176,498
Cumulative Timesteps: 1,471,882,394

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1471882394...
Checkpoint 1471882394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,665.36419
Policy Entropy: 3.72832
Value Function Loss: 0.08161

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.11649
Policy Update Magnitude: 0.97116
Value Function Update Magnitude: 0.42697

Collected Steps per Second: 21,572.30659
Overall Steps per Second: 10,616.67133

Timestep Collection Time: 2.31816
Timestep Consumption Time: 2.39217
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.71033

Cumulative Model Updates: 176,504
Cumulative Timesteps: 1,471,932,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,502.30276
Policy Entropy: 3.73855
Value Function Loss: 0.06141

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.14363
Policy Update Magnitude: 0.87555
Value Function Update Magnitude: 0.47969

Collected Steps per Second: 21,976.47429
Overall Steps per Second: 10,806.10553

Timestep Collection Time: 2.27634
Timestep Consumption Time: 2.35308
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.62942

Cumulative Model Updates: 176,510
Cumulative Timesteps: 1,471,982,428

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1471982428...
Checkpoint 1471982428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,742.48584
Policy Entropy: 3.75153
Value Function Loss: 0.03958

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11039
Policy Update Magnitude: 0.70389
Value Function Update Magnitude: 0.54030

Collected Steps per Second: 22,020.02642
Overall Steps per Second: 10,710.06498

Timestep Collection Time: 2.27166
Timestep Consumption Time: 2.39890
PPO Batch Consumption Time: 0.28547
Total Iteration Time: 4.67056

Cumulative Model Updates: 176,516
Cumulative Timesteps: 1,472,032,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,325.71882
Policy Entropy: 3.74867
Value Function Loss: 0.02803

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06268
Policy Update Magnitude: 0.62157
Value Function Update Magnitude: 0.61627

Collected Steps per Second: 22,328.87766
Overall Steps per Second: 10,604.29697

Timestep Collection Time: 2.24051
Timestep Consumption Time: 2.47720
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.71771

Cumulative Model Updates: 176,522
Cumulative Timesteps: 1,472,082,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1472082478...
Checkpoint 1472082478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,325.71882
Policy Entropy: 3.73173
Value Function Loss: 0.02443

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11888
Policy Update Magnitude: 0.54357
Value Function Update Magnitude: 0.55835

Collected Steps per Second: 22,758.24753
Overall Steps per Second: 10,918.59081

Timestep Collection Time: 2.19709
Timestep Consumption Time: 2.38244
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.57953

Cumulative Model Updates: 176,528
Cumulative Timesteps: 1,472,132,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,446.00099
Policy Entropy: 3.70839
Value Function Loss: 0.02461

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.17505
Policy Update Magnitude: 0.41141
Value Function Update Magnitude: 0.55722

Collected Steps per Second: 22,887.01100
Overall Steps per Second: 10,888.47610

Timestep Collection Time: 2.18561
Timestep Consumption Time: 2.40842
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.59403

Cumulative Model Updates: 176,534
Cumulative Timesteps: 1,472,182,502

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1472182502...
Checkpoint 1472182502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,025.10376
Policy Entropy: 3.72517
Value Function Loss: 0.02378

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.16019
Policy Update Magnitude: 0.33779
Value Function Update Magnitude: 0.50535

Collected Steps per Second: 22,489.81592
Overall Steps per Second: 10,691.23611

Timestep Collection Time: 2.22350
Timestep Consumption Time: 2.45379
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.67729

Cumulative Model Updates: 176,540
Cumulative Timesteps: 1,472,232,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,025.10376
Policy Entropy: 3.72866
Value Function Loss: 0.02103

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.15066
Policy Update Magnitude: 0.29784
Value Function Update Magnitude: 0.49012

Collected Steps per Second: 23,023.98872
Overall Steps per Second: 10,860.67294

Timestep Collection Time: 2.17252
Timestep Consumption Time: 2.43309
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.60561

Cumulative Model Updates: 176,546
Cumulative Timesteps: 1,472,282,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1472282528...
Checkpoint 1472282528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,025.10376
Policy Entropy: 3.75210
Value Function Loss: 0.01939

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.27390
Value Function Update Magnitude: 0.44917

Collected Steps per Second: 22,703.74240
Overall Steps per Second: 10,713.11383

Timestep Collection Time: 2.20325
Timestep Consumption Time: 2.46598
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.66923

Cumulative Model Updates: 176,552
Cumulative Timesteps: 1,472,332,550

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,025.10376
Policy Entropy: 3.71400
Value Function Loss: 0.01998

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.29033
Value Function Update Magnitude: 0.39597

Collected Steps per Second: 23,146.32411
Overall Steps per Second: 10,883.97531

Timestep Collection Time: 2.16121
Timestep Consumption Time: 2.43491
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.59611

Cumulative Model Updates: 176,558
Cumulative Timesteps: 1,472,382,574

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1472382574...
Checkpoint 1472382574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,025.10376
Policy Entropy: 3.70716
Value Function Loss: 0.02286

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14060
Policy Update Magnitude: 0.32710
Value Function Update Magnitude: 0.37381

Collected Steps per Second: 22,786.85828
Overall Steps per Second: 10,649.11486

Timestep Collection Time: 2.19512
Timestep Consumption Time: 2.50198
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.69710

Cumulative Model Updates: 176,564
Cumulative Timesteps: 1,472,432,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285,217.25817
Policy Entropy: 3.70053
Value Function Loss: 0.02726

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.36312
Value Function Update Magnitude: 0.49327

Collected Steps per Second: 23,271.04113
Overall Steps per Second: 10,914.34710

Timestep Collection Time: 2.14885
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.58168

Cumulative Model Updates: 176,570
Cumulative Timesteps: 1,472,482,600

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1472482600...
Checkpoint 1472482600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,895.30624
Policy Entropy: 3.72445
Value Function Loss: 0.03812

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.41367
Value Function Update Magnitude: 0.58961

Collected Steps per Second: 22,637.46657
Overall Steps per Second: 10,656.97305

Timestep Collection Time: 2.21102
Timestep Consumption Time: 2.48562
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.69664

Cumulative Model Updates: 176,576
Cumulative Timesteps: 1,472,532,652

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,323.18274
Policy Entropy: 3.72875
Value Function Loss: 0.04063

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.50644
Value Function Update Magnitude: 0.54310

Collected Steps per Second: 22,803.88861
Overall Steps per Second: 10,839.97985

Timestep Collection Time: 2.19261
Timestep Consumption Time: 2.41995
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.61255

Cumulative Model Updates: 176,582
Cumulative Timesteps: 1,472,582,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1472582652...
Checkpoint 1472582652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 356,843.44850
Policy Entropy: 3.69383
Value Function Loss: 0.06352

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.53800
Value Function Update Magnitude: 0.50746

Collected Steps per Second: 22,587.75221
Overall Steps per Second: 10,664.40469

Timestep Collection Time: 2.21439
Timestep Consumption Time: 2.47580
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.69018

Cumulative Model Updates: 176,588
Cumulative Timesteps: 1,472,632,670

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,396.11861
Policy Entropy: 3.70765
Value Function Loss: 0.06026

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.57232
Value Function Update Magnitude: 0.50989

Collected Steps per Second: 23,040.12273
Overall Steps per Second: 10,868.70920

Timestep Collection Time: 2.17134
Timestep Consumption Time: 2.43160
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.60294

Cumulative Model Updates: 176,594
Cumulative Timesteps: 1,472,682,698

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1472682698...
Checkpoint 1472682698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,011.56569
Policy Entropy: 3.70273
Value Function Loss: 0.06456

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.57115
Value Function Update Magnitude: 0.50275

Collected Steps per Second: 22,834.70113
Overall Steps per Second: 10,704.46151

Timestep Collection Time: 2.19061
Timestep Consumption Time: 2.48239
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.67300

Cumulative Model Updates: 176,600
Cumulative Timesteps: 1,472,732,720

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,314.48207
Policy Entropy: 3.74490
Value Function Loss: 0.05259

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.58167
Value Function Update Magnitude: 0.58692

Collected Steps per Second: 22,972.61990
Overall Steps per Second: 10,860.53590

Timestep Collection Time: 2.17703
Timestep Consumption Time: 2.42790
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.60493

Cumulative Model Updates: 176,606
Cumulative Timesteps: 1,472,782,732

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1472782732...
Checkpoint 1472782732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,346.77080
Policy Entropy: 3.74864
Value Function Loss: 0.04444

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.54696
Value Function Update Magnitude: 0.87490

Collected Steps per Second: 23,024.28397
Overall Steps per Second: 10,686.46686

Timestep Collection Time: 2.17284
Timestep Consumption Time: 2.50860
PPO Batch Consumption Time: 0.29342
Total Iteration Time: 4.68143

Cumulative Model Updates: 176,612
Cumulative Timesteps: 1,472,832,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,024.94740
Policy Entropy: 3.73850
Value Function Loss: 0.03976

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12582
Policy Update Magnitude: 0.49840
Value Function Update Magnitude: 0.90128

Collected Steps per Second: 22,802.31196
Overall Steps per Second: 10,831.15130

Timestep Collection Time: 2.19355
Timestep Consumption Time: 2.42443
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.61798

Cumulative Model Updates: 176,618
Cumulative Timesteps: 1,472,882,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1472882778...
Checkpoint 1472882778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 483,162.46592
Policy Entropy: 3.72901
Value Function Loss: 0.03887

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.46595
Value Function Update Magnitude: 0.66903

Collected Steps per Second: 22,038.61314
Overall Steps per Second: 10,650.56014

Timestep Collection Time: 2.26911
Timestep Consumption Time: 2.42623
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.69534

Cumulative Model Updates: 176,624
Cumulative Timesteps: 1,472,932,786

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,484.16798
Policy Entropy: 3.71053
Value Function Loss: 0.03374

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11552
Policy Update Magnitude: 0.46032
Value Function Update Magnitude: 0.55505

Collected Steps per Second: 23,048.35887
Overall Steps per Second: 10,897.74596

Timestep Collection Time: 2.16953
Timestep Consumption Time: 2.41895
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.58847

Cumulative Model Updates: 176,630
Cumulative Timesteps: 1,472,982,790

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1472982790...
Checkpoint 1472982790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,774.26930
Policy Entropy: 3.72633
Value Function Loss: 0.02613

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05630
Policy Update Magnitude: 0.48233
Value Function Update Magnitude: 0.59172

Collected Steps per Second: 22,603.24680
Overall Steps per Second: 10,721.87919

Timestep Collection Time: 2.21251
Timestep Consumption Time: 2.45178
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.66429

Cumulative Model Updates: 176,636
Cumulative Timesteps: 1,473,032,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,608.29539
Policy Entropy: 3.72122
Value Function Loss: 0.02310

Mean KL Divergence: 0.00736
SB3 Clip Fraction: 0.09502
Policy Update Magnitude: 0.45882
Value Function Update Magnitude: 0.57035

Collected Steps per Second: 22,792.85164
Overall Steps per Second: 10,853.95067

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.41372
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.60809

Cumulative Model Updates: 176,642
Cumulative Timesteps: 1,473,082,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1473082816...
Checkpoint 1473082816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,608.29539
Policy Entropy: 3.70674
Value Function Loss: 0.02433

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.14730
Policy Update Magnitude: 0.38079
Value Function Update Magnitude: 0.53015

Collected Steps per Second: 21,904.73263
Overall Steps per Second: 10,706.98919

Timestep Collection Time: 2.28371
Timestep Consumption Time: 2.38838
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.67209

Cumulative Model Updates: 176,648
Cumulative Timesteps: 1,473,132,840

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,583.31653
Policy Entropy: 3.69842
Value Function Loss: 0.02580

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.40095
Value Function Update Magnitude: 0.52773

Collected Steps per Second: 22,355.91451
Overall Steps per Second: 10,889.61748

Timestep Collection Time: 2.23726
Timestep Consumption Time: 2.35574
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.59300

Cumulative Model Updates: 176,654
Cumulative Timesteps: 1,473,182,856

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1473182856...
Checkpoint 1473182856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,402.53034
Policy Entropy: 3.66003
Value Function Loss: 0.04050

Mean KL Divergence: 0.01131
SB3 Clip Fraction: 0.14692
Policy Update Magnitude: 0.40898
Value Function Update Magnitude: 0.49897

Collected Steps per Second: 22,191.78054
Overall Steps per Second: 10,718.33061

Timestep Collection Time: 2.25444
Timestep Consumption Time: 2.41327
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.66770

Cumulative Model Updates: 176,660
Cumulative Timesteps: 1,473,232,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,402.53034
Policy Entropy: 3.68508
Value Function Loss: 0.04099

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.40509
Value Function Update Magnitude: 0.33499

Collected Steps per Second: 21,967.15071
Overall Steps per Second: 10,581.07460

Timestep Collection Time: 2.27740
Timestep Consumption Time: 2.45066
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.72806

Cumulative Model Updates: 176,666
Cumulative Timesteps: 1,473,282,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1473282914...
Checkpoint 1473282914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,649.31192
Policy Entropy: 3.68177
Value Function Loss: 0.04823

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13575
Policy Update Magnitude: 0.39398
Value Function Update Magnitude: 0.29158

Collected Steps per Second: 23,123.06758
Overall Steps per Second: 10,948.65194

Timestep Collection Time: 2.16312
Timestep Consumption Time: 2.40529
PPO Batch Consumption Time: 0.28080
Total Iteration Time: 4.56842

Cumulative Model Updates: 176,672
Cumulative Timesteps: 1,473,332,932

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,649.31192
Policy Entropy: 3.70523
Value Function Loss: 0.03414

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13079
Policy Update Magnitude: 0.38997
Value Function Update Magnitude: 0.29864

Collected Steps per Second: 22,989.34278
Overall Steps per Second: 10,924.62513

Timestep Collection Time: 2.17518
Timestep Consumption Time: 2.40218
PPO Batch Consumption Time: 0.27611
Total Iteration Time: 4.57737

Cumulative Model Updates: 176,678
Cumulative Timesteps: 1,473,382,938

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1473382938...
Checkpoint 1473382938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,649.31192
Policy Entropy: 3.69403
Value Function Loss: 0.02884

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.37458
Value Function Update Magnitude: 0.41223

Collected Steps per Second: 22,810.73274
Overall Steps per Second: 10,650.78624

Timestep Collection Time: 2.19327
Timestep Consumption Time: 2.50404
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.69731

Cumulative Model Updates: 176,684
Cumulative Timesteps: 1,473,432,968

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224,458.75994
Policy Entropy: 3.70529
Value Function Loss: 0.02651

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.37744
Value Function Update Magnitude: 0.59223

Collected Steps per Second: 22,716.73113
Overall Steps per Second: 10,819.27066

Timestep Collection Time: 2.20102
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.62138

Cumulative Model Updates: 176,690
Cumulative Timesteps: 1,473,482,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1473482968...
Checkpoint 1473482968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,816.13366
Policy Entropy: 3.70921
Value Function Loss: 0.02698

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.37893
Value Function Update Magnitude: 0.72001

Collected Steps per Second: 22,709.53729
Overall Steps per Second: 10,674.52235

Timestep Collection Time: 2.20181
Timestep Consumption Time: 2.48243
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.68424

Cumulative Model Updates: 176,696
Cumulative Timesteps: 1,473,532,970

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,816.13366
Policy Entropy: 3.71621
Value Function Loss: 0.02325

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.38683
Value Function Update Magnitude: 0.62701

Collected Steps per Second: 22,706.53179
Overall Steps per Second: 10,811.50463

Timestep Collection Time: 2.20271
Timestep Consumption Time: 2.42347
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.62618

Cumulative Model Updates: 176,702
Cumulative Timesteps: 1,473,582,986

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1473582986...
Checkpoint 1473582986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,816.13366
Policy Entropy: 3.70886
Value Function Loss: 0.01998

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12620
Policy Update Magnitude: 0.35363
Value Function Update Magnitude: 0.49347

Collected Steps per Second: 22,437.45526
Overall Steps per Second: 10,785.19545

Timestep Collection Time: 2.22842
Timestep Consumption Time: 2.40757
PPO Batch Consumption Time: 0.27579
Total Iteration Time: 4.63598

Cumulative Model Updates: 176,708
Cumulative Timesteps: 1,473,632,986

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 473,897.03435
Policy Entropy: 3.68238
Value Function Loss: 0.02145

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.32875
Value Function Update Magnitude: 0.41865

Collected Steps per Second: 23,123.04559
Overall Steps per Second: 10,860.63636

Timestep Collection Time: 2.16252
Timestep Consumption Time: 2.44163
PPO Batch Consumption Time: 0.28160
Total Iteration Time: 4.60415

Cumulative Model Updates: 176,714
Cumulative Timesteps: 1,473,682,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1473682990...
Checkpoint 1473682990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,248.44107
Policy Entropy: 3.69211
Value Function Loss: 0.02218

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.35086
Value Function Update Magnitude: 0.51772

Collected Steps per Second: 22,918.07718
Overall Steps per Second: 10,729.60406

Timestep Collection Time: 2.18168
Timestep Consumption Time: 2.47832
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.66000

Cumulative Model Updates: 176,720
Cumulative Timesteps: 1,473,732,990

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,248.44107
Policy Entropy: 3.68288
Value Function Loss: 0.02368

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.36020
Value Function Update Magnitude: 0.56908

Collected Steps per Second: 22,595.54778
Overall Steps per Second: 10,787.28270

Timestep Collection Time: 2.21344
Timestep Consumption Time: 2.42294
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.63639

Cumulative Model Updates: 176,726
Cumulative Timesteps: 1,473,783,004

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1473783004...
Checkpoint 1473783004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,248.44107
Policy Entropy: 3.68767
Value Function Loss: 0.02102

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 0.35079
Value Function Update Magnitude: 0.51005

Collected Steps per Second: 22,355.54779
Overall Steps per Second: 10,804.55575

Timestep Collection Time: 2.23730
Timestep Consumption Time: 2.39186
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.62916

Cumulative Model Updates: 176,732
Cumulative Timesteps: 1,473,833,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,248.44107
Policy Entropy: 3.67787
Value Function Loss: 0.01996

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.31797
Value Function Update Magnitude: 0.38702

Collected Steps per Second: 22,507.25105
Overall Steps per Second: 10,756.97107

Timestep Collection Time: 2.22151
Timestep Consumption Time: 2.42664
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.64815

Cumulative Model Updates: 176,738
Cumulative Timesteps: 1,473,883,020

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1473883020...
Checkpoint 1473883020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,248.44107
Policy Entropy: 3.67844
Value Function Loss: 0.02036

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.28567
Value Function Update Magnitude: 0.29177

Collected Steps per Second: 23,152.05579
Overall Steps per Second: 11,006.95433

Timestep Collection Time: 2.16041
Timestep Consumption Time: 2.38381
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.54422

Cumulative Model Updates: 176,744
Cumulative Timesteps: 1,473,933,038

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,248.44107
Policy Entropy: 3.68029
Value Function Loss: 0.02149

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12884
Policy Update Magnitude: 0.30121
Value Function Update Magnitude: 0.30367

Collected Steps per Second: 23,005.69867
Overall Steps per Second: 10,929.31206

Timestep Collection Time: 2.17424
Timestep Consumption Time: 2.40244
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.57668

Cumulative Model Updates: 176,750
Cumulative Timesteps: 1,473,983,058

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1473983058...
Checkpoint 1473983058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,248.44107
Policy Entropy: 3.67541
Value Function Loss: 0.02606

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.30669
Value Function Update Magnitude: 0.41352

Collected Steps per Second: 22,873.48694
Overall Steps per Second: 10,671.42200

Timestep Collection Time: 2.18655
Timestep Consumption Time: 2.50017
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.68672

Cumulative Model Updates: 176,756
Cumulative Timesteps: 1,474,033,072

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,790.49359
Policy Entropy: 3.68593
Value Function Loss: 0.02841

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.34004
Value Function Update Magnitude: 0.39582

Collected Steps per Second: 22,847.30664
Overall Steps per Second: 10,854.31386

Timestep Collection Time: 2.18853
Timestep Consumption Time: 2.41812
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.60665

Cumulative Model Updates: 176,762
Cumulative Timesteps: 1,474,083,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1474083074...
Checkpoint 1474083074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,790.49359
Policy Entropy: 3.69058
Value Function Loss: 0.02752

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13112
Policy Update Magnitude: 0.35974
Value Function Update Magnitude: 0.42089

Collected Steps per Second: 22,633.49169
Overall Steps per Second: 10,738.47416

Timestep Collection Time: 2.20991
Timestep Consumption Time: 2.44792
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.65783

Cumulative Model Updates: 176,768
Cumulative Timesteps: 1,474,133,092

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 168,790.49359
Policy Entropy: 3.69181
Value Function Loss: 0.02464

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.35102
Value Function Update Magnitude: 0.36446

Collected Steps per Second: 23,119.54413
Overall Steps per Second: 10,940.20637

Timestep Collection Time: 2.16267
Timestep Consumption Time: 2.40763
PPO Batch Consumption Time: 0.27579
Total Iteration Time: 4.57030

Cumulative Model Updates: 176,774
Cumulative Timesteps: 1,474,183,092

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1474183092...
Checkpoint 1474183092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,790.49359
Policy Entropy: 3.68698
Value Function Loss: 0.01955

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.33705
Value Function Update Magnitude: 0.31091

Collected Steps per Second: 22,807.30757
Overall Steps per Second: 10,678.63829

Timestep Collection Time: 2.19342
Timestep Consumption Time: 2.49126
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.68468

Cumulative Model Updates: 176,780
Cumulative Timesteps: 1,474,233,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,903.94453
Policy Entropy: 3.67315
Value Function Loss: 0.02902

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13074
Policy Update Magnitude: 0.38107
Value Function Update Magnitude: 0.41882

Collected Steps per Second: 23,135.28472
Overall Steps per Second: 10,854.92363

Timestep Collection Time: 2.16250
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.60897

Cumulative Model Updates: 176,786
Cumulative Timesteps: 1,474,283,148

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1474283148...
Checkpoint 1474283148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,862.23747
Policy Entropy: 3.69591
Value Function Loss: 0.03499

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12842
Policy Update Magnitude: 0.47491
Value Function Update Magnitude: 0.66090

Collected Steps per Second: 23,080.98380
Overall Steps per Second: 10,790.44681

Timestep Collection Time: 2.16767
Timestep Consumption Time: 2.46902
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.63669

Cumulative Model Updates: 176,792
Cumulative Timesteps: 1,474,333,180

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,112.50323
Policy Entropy: 3.68848
Value Function Loss: 0.04236

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.50494
Value Function Update Magnitude: 0.63266

Collected Steps per Second: 23,148.58631
Overall Steps per Second: 10,724.04936

Timestep Collection Time: 2.16074
Timestep Consumption Time: 2.50336
PPO Batch Consumption Time: 0.29313
Total Iteration Time: 4.66410

Cumulative Model Updates: 176,798
Cumulative Timesteps: 1,474,383,198

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1474383198...
Checkpoint 1474383198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,851.73777
Policy Entropy: 3.70555
Value Function Loss: 0.03578

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.48523
Value Function Update Magnitude: 0.61055

Collected Steps per Second: 22,580.65506
Overall Steps per Second: 10,642.62870

Timestep Collection Time: 2.21535
Timestep Consumption Time: 2.48499
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.70034

Cumulative Model Updates: 176,804
Cumulative Timesteps: 1,474,433,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,237.52467
Policy Entropy: 3.68078
Value Function Loss: 0.03230

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.45893
Value Function Update Magnitude: 0.67660

Collected Steps per Second: 22,892.72318
Overall Steps per Second: 10,855.41297

Timestep Collection Time: 2.18445
Timestep Consumption Time: 2.42228
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.60673

Cumulative Model Updates: 176,810
Cumulative Timesteps: 1,474,483,230

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1474483230...
Checkpoint 1474483230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,460.04741
Policy Entropy: 3.69815
Value Function Loss: 0.02992

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.44483
Value Function Update Magnitude: 0.64154

Collected Steps per Second: 22,949.92326
Overall Steps per Second: 10,683.97911

Timestep Collection Time: 2.17918
Timestep Consumption Time: 2.50185
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.68103

Cumulative Model Updates: 176,816
Cumulative Timesteps: 1,474,533,242

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,460.04741
Policy Entropy: 3.67004
Value Function Loss: 0.03343

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13398
Policy Update Magnitude: 0.43373
Value Function Update Magnitude: 0.55612

Collected Steps per Second: 23,032.39552
Overall Steps per Second: 10,863.60773

Timestep Collection Time: 2.17164
Timestep Consumption Time: 2.43254
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.60418

Cumulative Model Updates: 176,822
Cumulative Timesteps: 1,474,583,260

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1474583260...
Checkpoint 1474583260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,460.04741
Policy Entropy: 3.68497
Value Function Loss: 0.02929

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13224
Policy Update Magnitude: 0.41184
Value Function Update Magnitude: 0.45281

Collected Steps per Second: 22,820.64859
Overall Steps per Second: 10,704.76954

Timestep Collection Time: 2.19187
Timestep Consumption Time: 2.48081
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.67268

Cumulative Model Updates: 176,828
Cumulative Timesteps: 1,474,633,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,209.61824
Policy Entropy: 3.67281
Value Function Loss: 0.02763

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.38518
Value Function Update Magnitude: 0.41263

Collected Steps per Second: 22,618.00438
Overall Steps per Second: 10,820.11261

Timestep Collection Time: 2.21107
Timestep Consumption Time: 2.41088
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.62195

Cumulative Model Updates: 176,834
Cumulative Timesteps: 1,474,683,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1474683290...
Checkpoint 1474683290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330,209.61824
Policy Entropy: 3.69821
Value Function Loss: 0.02601

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.37038
Value Function Update Magnitude: 0.41913

Collected Steps per Second: 22,571.60019
Overall Steps per Second: 10,727.64050

Timestep Collection Time: 2.21606
Timestep Consumption Time: 2.44666
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.66272

Cumulative Model Updates: 176,840
Cumulative Timesteps: 1,474,733,310

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,209.61824
Policy Entropy: 3.67751
Value Function Loss: 0.02552

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.36558
Value Function Update Magnitude: 0.43636

Collected Steps per Second: 22,951.70424
Overall Steps per Second: 10,861.18407

Timestep Collection Time: 2.17945
Timestep Consumption Time: 2.42613
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.60558

Cumulative Model Updates: 176,846
Cumulative Timesteps: 1,474,783,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1474783332...
Checkpoint 1474783332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330,209.61824
Policy Entropy: 3.67527
Value Function Loss: 0.02600

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12922
Policy Update Magnitude: 0.35829
Value Function Update Magnitude: 0.42621

Collected Steps per Second: 22,680.74341
Overall Steps per Second: 10,661.85135

Timestep Collection Time: 2.20487
Timestep Consumption Time: 2.48550
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.69037

Cumulative Model Updates: 176,852
Cumulative Timesteps: 1,474,833,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,209.61824
Policy Entropy: 3.66171
Value Function Loss: 0.02339

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13288
Policy Update Magnitude: 0.35273
Value Function Update Magnitude: 0.39285

Collected Steps per Second: 22,975.35854
Overall Steps per Second: 10,853.11894

Timestep Collection Time: 2.17712
Timestep Consumption Time: 2.43170
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.60881

Cumulative Model Updates: 176,858
Cumulative Timesteps: 1,474,883,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1474883360...
Checkpoint 1474883360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330,209.61824
Policy Entropy: 3.67089
Value Function Loss: 0.02254

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13484
Policy Update Magnitude: 0.32691
Value Function Update Magnitude: 0.33353

Collected Steps per Second: 22,884.99585
Overall Steps per Second: 10,710.24714

Timestep Collection Time: 2.18519
Timestep Consumption Time: 2.48399
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.66917

Cumulative Model Updates: 176,864
Cumulative Timesteps: 1,474,933,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,209.61824
Policy Entropy: 3.67870
Value Function Loss: 0.01913

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.30744
Value Function Update Magnitude: 0.35337

Collected Steps per Second: 22,930.16718
Overall Steps per Second: 10,858.99752

Timestep Collection Time: 2.18053
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.60448

Cumulative Model Updates: 176,870
Cumulative Timesteps: 1,474,983,368

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1474983368...
Checkpoint 1474983368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 524,010.11819
Policy Entropy: 3.69764
Value Function Loss: 0.01930

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.13001
Policy Update Magnitude: 0.30143
Value Function Update Magnitude: 0.49216

Collected Steps per Second: 22,116.21162
Overall Steps per Second: 10,672.68602

Timestep Collection Time: 2.26187
Timestep Consumption Time: 2.42523
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.68710

Cumulative Model Updates: 176,876
Cumulative Timesteps: 1,475,033,392

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,708.23551
Policy Entropy: 3.71883
Value Function Loss: 0.02040

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.34499
Value Function Update Magnitude: 0.67944

Collected Steps per Second: 22,545.46324
Overall Steps per Second: 10,983.39639

Timestep Collection Time: 2.21792
Timestep Consumption Time: 2.33477
PPO Batch Consumption Time: 0.27551
Total Iteration Time: 4.55269

Cumulative Model Updates: 176,882
Cumulative Timesteps: 1,475,083,396

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1475083396...
Checkpoint 1475083396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,726.01685
Policy Entropy: 3.70757
Value Function Loss: 0.02188

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.34510
Value Function Update Magnitude: 0.78214

Collected Steps per Second: 22,343.37108
Overall Steps per Second: 10,946.68773

Timestep Collection Time: 2.23789
Timestep Consumption Time: 2.32988
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.56777

Cumulative Model Updates: 176,888
Cumulative Timesteps: 1,475,133,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,812.74930
Policy Entropy: 3.70722
Value Function Loss: 0.02150

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11889
Policy Update Magnitude: 0.35174
Value Function Update Magnitude: 0.67794

Collected Steps per Second: 22,405.35335
Overall Steps per Second: 10,630.23362

Timestep Collection Time: 2.23268
Timestep Consumption Time: 2.47314
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.70582

Cumulative Model Updates: 176,894
Cumulative Timesteps: 1,475,183,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1475183422...
Checkpoint 1475183422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,812.74930
Policy Entropy: 3.69299
Value Function Loss: 0.02078

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12718
Policy Update Magnitude: 0.34529
Value Function Update Magnitude: 0.59673

Collected Steps per Second: 22,531.38757
Overall Steps per Second: 10,691.28144

Timestep Collection Time: 2.22099
Timestep Consumption Time: 2.45965
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.68064

Cumulative Model Updates: 176,900
Cumulative Timesteps: 1,475,233,464

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,812.74930
Policy Entropy: 3.70221
Value Function Loss: 0.01927

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.33373
Value Function Update Magnitude: 0.45791

Collected Steps per Second: 22,864.20889
Overall Steps per Second: 10,763.07936

Timestep Collection Time: 2.18866
Timestep Consumption Time: 2.46075
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.64941

Cumulative Model Updates: 176,906
Cumulative Timesteps: 1,475,283,506

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1475283506...
Checkpoint 1475283506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,812.74930
Policy Entropy: 3.68621
Value Function Loss: 0.01935

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.12190
Policy Update Magnitude: 0.32507
Value Function Update Magnitude: 0.35569

Collected Steps per Second: 23,057.91151
Overall Steps per Second: 10,737.20242

Timestep Collection Time: 2.17001
Timestep Consumption Time: 2.49004
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.66006

Cumulative Model Updates: 176,912
Cumulative Timesteps: 1,475,333,542

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,812.74930
Policy Entropy: 3.67549
Value Function Loss: 0.02362

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.38674
Value Function Update Magnitude: 0.38053

Collected Steps per Second: 22,939.83824
Overall Steps per Second: 10,878.66041

Timestep Collection Time: 2.18031
Timestep Consumption Time: 2.41731
PPO Batch Consumption Time: 0.27573
Total Iteration Time: 4.59762

Cumulative Model Updates: 176,918
Cumulative Timesteps: 1,475,383,558

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1475383558...
Checkpoint 1475383558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,212.12933
Policy Entropy: 3.67833
Value Function Loss: 0.03155

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.45873
Value Function Update Magnitude: 0.66235

Collected Steps per Second: 22,750.45837
Overall Steps per Second: 10,687.07079

Timestep Collection Time: 2.19846
Timestep Consumption Time: 2.48159
PPO Batch Consumption Time: 0.28919
Total Iteration Time: 4.68005

Cumulative Model Updates: 176,924
Cumulative Timesteps: 1,475,433,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,532.84099
Policy Entropy: 3.68896
Value Function Loss: 0.04101

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.53268
Value Function Update Magnitude: 0.66431

Collected Steps per Second: 22,642.40999
Overall Steps per Second: 10,796.33154

Timestep Collection Time: 2.20913
Timestep Consumption Time: 2.42393
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.63306

Cumulative Model Updates: 176,930
Cumulative Timesteps: 1,475,483,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1475483594...
Checkpoint 1475483594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,532.84099
Policy Entropy: 3.69233
Value Function Loss: 0.04070

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.54283
Value Function Update Magnitude: 0.61433

Collected Steps per Second: 22,566.74413
Overall Steps per Second: 10,659.61564

Timestep Collection Time: 2.21733
Timestep Consumption Time: 2.47683
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.69417

Cumulative Model Updates: 176,936
Cumulative Timesteps: 1,475,533,632

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,532.84099
Policy Entropy: 3.68832
Value Function Loss: 0.03309

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.50969
Value Function Update Magnitude: 0.76744

Collected Steps per Second: 23,122.02765
Overall Steps per Second: 10,952.13299

Timestep Collection Time: 2.16279
Timestep Consumption Time: 2.40327
PPO Batch Consumption Time: 0.27581
Total Iteration Time: 4.56605

Cumulative Model Updates: 176,942
Cumulative Timesteps: 1,475,583,640

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1475583640...
Checkpoint 1475583640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,738.41734
Policy Entropy: 3.67118
Value Function Loss: 0.02791

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.47238
Value Function Update Magnitude: 0.79691

Collected Steps per Second: 21,822.18043
Overall Steps per Second: 10,611.92754

Timestep Collection Time: 2.29171
Timestep Consumption Time: 2.42092
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.71262

Cumulative Model Updates: 176,948
Cumulative Timesteps: 1,475,633,650

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,738.41734
Policy Entropy: 3.67478
Value Function Loss: 0.02501

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13121
Policy Update Magnitude: 0.42087
Value Function Update Magnitude: 0.66700

Collected Steps per Second: 22,312.98658
Overall Steps per Second: 10,914.24363

Timestep Collection Time: 2.24219
Timestep Consumption Time: 2.34173
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.58392

Cumulative Model Updates: 176,954
Cumulative Timesteps: 1,475,683,680

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1475683680...
Checkpoint 1475683680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 359,738.41734
Policy Entropy: 3.68146
Value Function Loss: 0.02160

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.37200
Value Function Update Magnitude: 0.52943

Collected Steps per Second: 22,232.60763
Overall Steps per Second: 10,694.48384

Timestep Collection Time: 2.24931
Timestep Consumption Time: 2.42675
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.67606

Cumulative Model Updates: 176,960
Cumulative Timesteps: 1,475,733,688

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 359,738.41734
Policy Entropy: 3.69085
Value Function Loss: 0.01781

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13120
Policy Update Magnitude: 0.33767
Value Function Update Magnitude: 0.42768

Collected Steps per Second: 22,525.60117
Overall Steps per Second: 10,811.23589

Timestep Collection Time: 2.22032
Timestep Consumption Time: 2.40580
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.62611

Cumulative Model Updates: 176,966
Cumulative Timesteps: 1,475,783,702

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1475783702...
Checkpoint 1475783702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 342,691.68771
Policy Entropy: 3.68996
Value Function Loss: 0.01940

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.32501
Value Function Update Magnitude: 0.40815

Collected Steps per Second: 22,924.41379
Overall Steps per Second: 10,745.51801

Timestep Collection Time: 2.18178
Timestep Consumption Time: 2.47281
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.65459

Cumulative Model Updates: 176,972
Cumulative Timesteps: 1,475,833,718

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 342,691.68771
Policy Entropy: 3.67947
Value Function Loss: 0.02150

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13115
Policy Update Magnitude: 0.33913
Value Function Update Magnitude: 0.48999

Collected Steps per Second: 22,873.75465
Overall Steps per Second: 10,868.36422

Timestep Collection Time: 2.18626
Timestep Consumption Time: 2.41498
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.60124

Cumulative Model Updates: 176,978
Cumulative Timesteps: 1,475,883,726

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1475883726...
Checkpoint 1475883726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,733.07139
Policy Entropy: 3.68207
Value Function Loss: 0.02300

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13287
Policy Update Magnitude: 0.38145
Value Function Update Magnitude: 0.62884

Collected Steps per Second: 22,906.48409
Overall Steps per Second: 10,714.59568

Timestep Collection Time: 2.18384
Timestep Consumption Time: 2.48494
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.66877

Cumulative Model Updates: 176,984
Cumulative Timesteps: 1,475,933,750

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348,733.07139
Policy Entropy: 3.68702
Value Function Loss: 0.02099

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12989
Policy Update Magnitude: 0.39930
Value Function Update Magnitude: 0.57958

Collected Steps per Second: 23,123.19265
Overall Steps per Second: 10,775.45930

Timestep Collection Time: 2.16311
Timestep Consumption Time: 2.47873
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.64184

Cumulative Model Updates: 176,990
Cumulative Timesteps: 1,475,983,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1475983768...
Checkpoint 1475983768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,733.07139
Policy Entropy: 3.69228
Value Function Loss: 0.02011

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13913
Policy Update Magnitude: 0.37072
Value Function Update Magnitude: 0.54925

Collected Steps per Second: 22,883.94647
Overall Steps per Second: 10,681.62213

Timestep Collection Time: 2.18546
Timestep Consumption Time: 2.49660
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.68206

Cumulative Model Updates: 176,996
Cumulative Timesteps: 1,476,033,780

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348,733.07139
Policy Entropy: 3.68197
Value Function Loss: 0.02049

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.36371
Value Function Update Magnitude: 0.46534

Collected Steps per Second: 22,775.80810
Overall Steps per Second: 10,840.47690

Timestep Collection Time: 2.19540
Timestep Consumption Time: 2.41713
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.61253

Cumulative Model Updates: 177,002
Cumulative Timesteps: 1,476,083,782

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1476083782...
Checkpoint 1476083782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,733.07139
Policy Entropy: 3.67153
Value Function Loss: 0.02006

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.38834
Value Function Update Magnitude: 0.37453

Collected Steps per Second: 22,532.21036
Overall Steps per Second: 10,684.07915

Timestep Collection Time: 2.21905
Timestep Consumption Time: 2.46081
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.67986

Cumulative Model Updates: 177,008
Cumulative Timesteps: 1,476,133,782

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 348,733.07139
Policy Entropy: 3.66140
Value Function Loss: 0.02193

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13072
Policy Update Magnitude: 0.39538
Value Function Update Magnitude: 0.35571

Collected Steps per Second: 21,995.08055
Overall Steps per Second: 10,816.88925

Timestep Collection Time: 2.27387
Timestep Consumption Time: 2.34982
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.62370

Cumulative Model Updates: 177,014
Cumulative Timesteps: 1,476,183,796

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1476183796...
Checkpoint 1476183796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,733.07139
Policy Entropy: 3.66470
Value Function Loss: 0.02116

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13882
Policy Update Magnitude: 0.37271
Value Function Update Magnitude: 0.31081

Collected Steps per Second: 22,016.08249
Overall Steps per Second: 10,710.92977

Timestep Collection Time: 2.27134
Timestep Consumption Time: 2.39735
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.66869

Cumulative Model Updates: 177,020
Cumulative Timesteps: 1,476,233,802

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 530,987.63957
Policy Entropy: 3.64939
Value Function Loss: 0.03478

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.43739
Value Function Update Magnitude: 0.41247

Collected Steps per Second: 21,870.85328
Overall Steps per Second: 10,494.29783

Timestep Collection Time: 2.28743
Timestep Consumption Time: 2.47973
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.76716

Cumulative Model Updates: 177,026
Cumulative Timesteps: 1,476,283,830

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1476283830...
Checkpoint 1476283830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,641.35261
Policy Entropy: 3.67919
Value Function Loss: 0.03700

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.60651
Value Function Update Magnitude: 0.67781

Collected Steps per Second: 22,365.59032
Overall Steps per Second: 10,623.98366

Timestep Collection Time: 2.23585
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.70690

Cumulative Model Updates: 177,032
Cumulative Timesteps: 1,476,333,836

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279,326.74968
Policy Entropy: 3.68640
Value Function Loss: 0.04540

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13657
Policy Update Magnitude: 0.65156
Value Function Update Magnitude: 0.65159

Collected Steps per Second: 22,864.78609
Overall Steps per Second: 10,850.44301

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.42221
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.60977

Cumulative Model Updates: 177,038
Cumulative Timesteps: 1,476,383,854

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1476383854...
Checkpoint 1476383854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 858,743.96126
Policy Entropy: 3.70697
Value Function Loss: 0.04412

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.66263
Value Function Update Magnitude: 0.60004

Collected Steps per Second: 22,697.93298
Overall Steps per Second: 10,695.86727

Timestep Collection Time: 2.20311
Timestep Consumption Time: 2.47216
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.67526

Cumulative Model Updates: 177,044
Cumulative Timesteps: 1,476,433,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 695,582.73989
Policy Entropy: 3.68157
Value Function Loss: 0.04602

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.65875
Value Function Update Magnitude: 0.59359

Collected Steps per Second: 22,655.57225
Overall Steps per Second: 10,658.79339

Timestep Collection Time: 2.20767
Timestep Consumption Time: 2.48479
PPO Batch Consumption Time: 0.28690
Total Iteration Time: 4.69246

Cumulative Model Updates: 177,050
Cumulative Timesteps: 1,476,483,876

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1476483876...
Checkpoint 1476483876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 361,106.39029
Policy Entropy: 3.67672
Value Function Loss: 0.04288

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 0.67780
Value Function Update Magnitude: 0.56324

Collected Steps per Second: 22,843.53394
Overall Steps per Second: 10,869.32282

Timestep Collection Time: 2.18915
Timestep Consumption Time: 2.41169
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.60084

Cumulative Model Updates: 177,056
Cumulative Timesteps: 1,476,533,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,638.41971
Policy Entropy: 3.68194
Value Function Loss: 0.03677

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16990
Policy Update Magnitude: 0.63036
Value Function Update Magnitude: 0.56538

Collected Steps per Second: 23,174.36202
Overall Steps per Second: 10,882.58571

Timestep Collection Time: 2.15764
Timestep Consumption Time: 2.43704
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.59468

Cumulative Model Updates: 177,062
Cumulative Timesteps: 1,476,583,886

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1476583886...
Checkpoint 1476583886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,875.15815
Policy Entropy: 3.72517
Value Function Loss: 0.03164

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14352
Policy Update Magnitude: 0.56446
Value Function Update Magnitude: 0.81155

Collected Steps per Second: 22,902.11067
Overall Steps per Second: 10,651.11844

Timestep Collection Time: 2.18417
Timestep Consumption Time: 2.51224
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.69641

Cumulative Model Updates: 177,068
Cumulative Timesteps: 1,476,633,908

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,012.24556
Policy Entropy: 3.73135
Value Function Loss: 0.02865

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.52934
Value Function Update Magnitude: 1.01634

Collected Steps per Second: 22,882.04824
Overall Steps per Second: 10,857.76707

Timestep Collection Time: 2.18564
Timestep Consumption Time: 2.42046
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.60610

Cumulative Model Updates: 177,074
Cumulative Timesteps: 1,476,683,920

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1476683920...
Checkpoint 1476683920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,012.24556
Policy Entropy: 3.71699
Value Function Loss: 0.02601

Mean KL Divergence: 0.00653
SB3 Clip Fraction: 0.07929
Policy Update Magnitude: 0.58033
Value Function Update Magnitude: 0.89418

Collected Steps per Second: 22,725.86217
Overall Steps per Second: 10,715.38510

Timestep Collection Time: 2.20093
Timestep Consumption Time: 2.46694
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.66787

Cumulative Model Updates: 177,080
Cumulative Timesteps: 1,476,733,938

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,906.34168
Policy Entropy: 3.68491
Value Function Loss: 0.02709

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08147
Policy Update Magnitude: 0.65104
Value Function Update Magnitude: 0.74141

Collected Steps per Second: 23,054.71944
Overall Steps per Second: 10,862.55107

Timestep Collection Time: 2.16919
Timestep Consumption Time: 2.43470
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.60389

Cumulative Model Updates: 177,086
Cumulative Timesteps: 1,476,783,948

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1476783948...
Checkpoint 1476783948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.69779
Value Function Loss: 0.02643

Mean KL Divergence: 0.00567
SB3 Clip Fraction: 0.06513
Policy Update Magnitude: 0.65591
Value Function Update Magnitude: 0.74345

Collected Steps per Second: 22,900.12579
Overall Steps per Second: 10,698.56146

Timestep Collection Time: 2.18505
Timestep Consumption Time: 2.49202
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.67708

Cumulative Model Updates: 177,092
Cumulative Timesteps: 1,476,833,986

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.70099
Value Function Loss: 0.02364

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08469
Policy Update Magnitude: 0.60768
Value Function Update Magnitude: 0.72909

Collected Steps per Second: 23,005.69629
Overall Steps per Second: 10,884.36381

Timestep Collection Time: 2.17468
Timestep Consumption Time: 2.42182
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.59650

Cumulative Model Updates: 177,098
Cumulative Timesteps: 1,476,884,016

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1476884016...
Checkpoint 1476884016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.69690
Value Function Loss: 0.02197

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.06758
Policy Update Magnitude: 0.56342
Value Function Update Magnitude: 0.68441

Collected Steps per Second: 21,899.51692
Overall Steps per Second: 10,651.61461

Timestep Collection Time: 2.28425
Timestep Consumption Time: 2.41213
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.69638

Cumulative Model Updates: 177,104
Cumulative Timesteps: 1,476,934,040

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.69313
Value Function Loss: 0.02003

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.06985
Policy Update Magnitude: 0.54130
Value Function Update Magnitude: 0.50821

Collected Steps per Second: 22,094.51966
Overall Steps per Second: 10,872.04195

Timestep Collection Time: 2.26427
Timestep Consumption Time: 2.33726
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.60153

Cumulative Model Updates: 177,110
Cumulative Timesteps: 1,476,984,068

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1476984068...
Checkpoint 1476984068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.70524
Value Function Loss: 0.02057

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.06962
Policy Update Magnitude: 0.50649
Value Function Update Magnitude: 0.38063

Collected Steps per Second: 21,660.87407
Overall Steps per Second: 10,622.43916

Timestep Collection Time: 2.30849
Timestep Consumption Time: 2.39890
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.70739

Cumulative Model Updates: 177,116
Cumulative Timesteps: 1,477,034,072

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.69282
Value Function Loss: 0.02034

Mean KL Divergence: 0.00660
SB3 Clip Fraction: 0.08170
Policy Update Magnitude: 0.48878
Value Function Update Magnitude: 0.34656

Collected Steps per Second: 22,820.01843
Overall Steps per Second: 10,894.64169

Timestep Collection Time: 2.19167
Timestep Consumption Time: 2.39902
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.59070

Cumulative Model Updates: 177,122
Cumulative Timesteps: 1,477,084,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1477084086...
Checkpoint 1477084086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.69562
Value Function Loss: 0.02008

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06436
Policy Update Magnitude: 0.48757
Value Function Update Magnitude: 0.34435

Collected Steps per Second: 22,518.41441
Overall Steps per Second: 10,712.48844

Timestep Collection Time: 2.22094
Timestep Consumption Time: 2.44763
PPO Batch Consumption Time: 0.28615
Total Iteration Time: 4.66857

Cumulative Model Updates: 177,128
Cumulative Timesteps: 1,477,134,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.69861
Value Function Loss: 0.01805

Mean KL Divergence: 0.00675
SB3 Clip Fraction: 0.08375
Policy Update Magnitude: 0.48170
Value Function Update Magnitude: 0.32262

Collected Steps per Second: 23,203.39663
Overall Steps per Second: 10,901.38070

Timestep Collection Time: 2.15529
Timestep Consumption Time: 2.43220
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.58749

Cumulative Model Updates: 177,134
Cumulative Timesteps: 1,477,184,108

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1477184108...
Checkpoint 1477184108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.70395
Value Function Loss: 0.02238

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.48666
Value Function Update Magnitude: 0.34219

Collected Steps per Second: 22,575.26809
Overall Steps per Second: 10,622.95339

Timestep Collection Time: 2.21508
Timestep Consumption Time: 2.49227
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.70735

Cumulative Model Updates: 177,140
Cumulative Timesteps: 1,477,234,114

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.70777
Value Function Loss: 0.02151

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.51297
Value Function Update Magnitude: 0.40523

Collected Steps per Second: 22,989.39453
Overall Steps per Second: 10,883.79303

Timestep Collection Time: 2.17526
Timestep Consumption Time: 2.41946
PPO Batch Consumption Time: 0.27651
Total Iteration Time: 4.59472

Cumulative Model Updates: 177,146
Cumulative Timesteps: 1,477,284,122

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1477284122...
Checkpoint 1477284122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.68965
Value Function Loss: 0.02195

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13165
Policy Update Magnitude: 0.51622
Value Function Update Magnitude: 0.44296

Collected Steps per Second: 22,353.10161
Overall Steps per Second: 10,762.25211

Timestep Collection Time: 2.23799
Timestep Consumption Time: 2.41029
PPO Batch Consumption Time: 0.27507
Total Iteration Time: 4.64828

Cumulative Model Updates: 177,152
Cumulative Timesteps: 1,477,334,148

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.69267
Value Function Loss: 0.02265

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.17176
Policy Update Magnitude: 0.47802
Value Function Update Magnitude: 0.43231

Collected Steps per Second: 23,207.99752
Overall Steps per Second: 10,815.99516

Timestep Collection Time: 2.15495
Timestep Consumption Time: 2.46895
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.62389

Cumulative Model Updates: 177,158
Cumulative Timesteps: 1,477,384,160

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1477384160...
Checkpoint 1477384160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.64561
Value Function Loss: 0.03268

Mean KL Divergence: 0.02008
SB3 Clip Fraction: 0.21872
Policy Update Magnitude: 0.45122
Value Function Update Magnitude: 0.39590

Collected Steps per Second: 22,561.24666
Overall Steps per Second: 10,669.25125

Timestep Collection Time: 2.21770
Timestep Consumption Time: 2.47185
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.68955

Cumulative Model Updates: 177,164
Cumulative Timesteps: 1,477,434,194

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.66356
Value Function Loss: 0.05124

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.14207
Policy Update Magnitude: 0.48820
Value Function Update Magnitude: 0.34396

Collected Steps per Second: 22,503.14317
Overall Steps per Second: 10,653.68837

Timestep Collection Time: 2.22316
Timestep Consumption Time: 2.47268
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.69584

Cumulative Model Updates: 177,170
Cumulative Timesteps: 1,477,484,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1477484222...
Checkpoint 1477484222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.66444
Value Function Loss: 0.04902

Mean KL Divergence: 0.01786
SB3 Clip Fraction: 0.19568
Policy Update Magnitude: 0.54602
Value Function Update Magnitude: 0.28606

Collected Steps per Second: 22,533.39525
Overall Steps per Second: 10,836.16346

Timestep Collection Time: 2.21999
Timestep Consumption Time: 2.39640
PPO Batch Consumption Time: 0.27597
Total Iteration Time: 4.61639

Cumulative Model Updates: 177,176
Cumulative Timesteps: 1,477,534,246

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.67333
Value Function Loss: 0.04015

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.19076
Policy Update Magnitude: 0.45897
Value Function Update Magnitude: 0.25581

Collected Steps per Second: 22,104.06750
Overall Steps per Second: 10,859.80365

Timestep Collection Time: 2.26257
Timestep Consumption Time: 2.34267
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.60524

Cumulative Model Updates: 177,182
Cumulative Timesteps: 1,477,584,258

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1477584258...
Checkpoint 1477584258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,189.85210
Policy Entropy: 3.66537
Value Function Loss: 0.03571

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.17046
Policy Update Magnitude: 0.40427
Value Function Update Magnitude: 0.27471

Collected Steps per Second: 22,091.16174
Overall Steps per Second: 10,722.34532

Timestep Collection Time: 2.26335
Timestep Consumption Time: 2.39981
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.66316

Cumulative Model Updates: 177,188
Cumulative Timesteps: 1,477,634,258

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 565,408.20675
Policy Entropy: 3.64065
Value Function Loss: 0.04321

Mean KL Divergence: 0.01292
SB3 Clip Fraction: 0.16194
Policy Update Magnitude: 0.42231
Value Function Update Magnitude: 0.32880

Collected Steps per Second: 22,195.93808
Overall Steps per Second: 10,605.80600

Timestep Collection Time: 2.25375
Timestep Consumption Time: 2.46292
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.71666

Cumulative Model Updates: 177,194
Cumulative Timesteps: 1,477,684,282

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1477684282...
Checkpoint 1477684282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,718.64738
Policy Entropy: 3.65197
Value Function Loss: 0.05458

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14375
Policy Update Magnitude: 0.50275
Value Function Update Magnitude: 0.36553

Collected Steps per Second: 22,442.08072
Overall Steps per Second: 10,673.98636

Timestep Collection Time: 2.22840
Timestep Consumption Time: 2.45682
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.68522

Cumulative Model Updates: 177,200
Cumulative Timesteps: 1,477,734,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 679,444.59883
Policy Entropy: 3.65882
Value Function Loss: 0.05060

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13585
Policy Update Magnitude: 0.55762
Value Function Update Magnitude: 0.38477

Collected Steps per Second: 22,341.14862
Overall Steps per Second: 10,731.00853

Timestep Collection Time: 2.23802
Timestep Consumption Time: 2.42137
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.65939

Cumulative Model Updates: 177,206
Cumulative Timesteps: 1,477,784,292

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1477784292...
Checkpoint 1477784292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,949.29311
Policy Entropy: 3.69624
Value Function Loss: 0.04560

Mean KL Divergence: 0.00723
SB3 Clip Fraction: 0.09282
Policy Update Magnitude: 0.69399
Value Function Update Magnitude: 0.55392

Collected Steps per Second: 22,825.41497
Overall Steps per Second: 10,656.49345

Timestep Collection Time: 2.19063
Timestep Consumption Time: 2.50153
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.69216

Cumulative Model Updates: 177,212
Cumulative Timesteps: 1,477,834,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,579.30030
Policy Entropy: 3.69861
Value Function Loss: 0.03943

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.72891
Value Function Update Magnitude: 0.67074

Collected Steps per Second: 22,772.02633
Overall Steps per Second: 10,811.57109

Timestep Collection Time: 2.19612
Timestep Consumption Time: 2.42948
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.62560

Cumulative Model Updates: 177,218
Cumulative Timesteps: 1,477,884,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1477884304...
Checkpoint 1477884304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,933.11319
Policy Entropy: 3.72022
Value Function Loss: 0.03132

Mean KL Divergence: 0.00690
SB3 Clip Fraction: 0.08455
Policy Update Magnitude: 0.69211
Value Function Update Magnitude: 0.71137

Collected Steps per Second: 22,353.35439
Overall Steps per Second: 10,748.28473

Timestep Collection Time: 2.23698
Timestep Consumption Time: 2.41530
PPO Batch Consumption Time: 0.27632
Total Iteration Time: 4.65228

Cumulative Model Updates: 177,224
Cumulative Timesteps: 1,477,934,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,512.70439
Policy Entropy: 3.72497
Value Function Loss: 0.02501

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.64160
Value Function Update Magnitude: 0.71617

Collected Steps per Second: 23,208.20449
Overall Steps per Second: 10,925.43042

Timestep Collection Time: 2.15596
Timestep Consumption Time: 2.42381
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.57977

Cumulative Model Updates: 177,230
Cumulative Timesteps: 1,477,984,344

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1477984344...
Checkpoint 1477984344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,512.70439
Policy Entropy: 3.71981
Value Function Loss: 0.02100

Mean KL Divergence: 0.01428
SB3 Clip Fraction: 0.18586
Policy Update Magnitude: 0.51658
Value Function Update Magnitude: 0.64555

Collected Steps per Second: 22,756.96908
Overall Steps per Second: 10,661.39380

Timestep Collection Time: 2.19739
Timestep Consumption Time: 2.49299
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.69038

Cumulative Model Updates: 177,236
Cumulative Timesteps: 1,478,034,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,512.70439
Policy Entropy: 3.71605
Value Function Loss: 0.02283

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.15981
Policy Update Magnitude: 0.39654
Value Function Update Magnitude: 0.67739

Collected Steps per Second: 23,201.48912
Overall Steps per Second: 10,842.22948

Timestep Collection Time: 2.15564
Timestep Consumption Time: 2.45725
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.61289

Cumulative Model Updates: 177,242
Cumulative Timesteps: 1,478,084,364

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1478084364...
Checkpoint 1478084364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 324,935.70172
Policy Entropy: 3.69985
Value Function Loss: 0.02819

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.15344
Policy Update Magnitude: 0.35960
Value Function Update Magnitude: 0.76151

Collected Steps per Second: 21,901.76438
Overall Steps per Second: 10,659.32776

Timestep Collection Time: 2.28347
Timestep Consumption Time: 2.40838
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.69185

Cumulative Model Updates: 177,248
Cumulative Timesteps: 1,478,134,376

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,882.49347
Policy Entropy: 3.71835
Value Function Loss: 0.03379

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.15412
Policy Update Magnitude: 0.42960
Value Function Update Magnitude: 0.91858

Collected Steps per Second: 22,407.20041
Overall Steps per Second: 10,880.99091

Timestep Collection Time: 2.23241
Timestep Consumption Time: 2.36478
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.59719

Cumulative Model Updates: 177,254
Cumulative Timesteps: 1,478,184,398

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1478184398...
Checkpoint 1478184398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,875.10752
Policy Entropy: 3.72926
Value Function Loss: 0.03613

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.14845
Policy Update Magnitude: 0.48364
Value Function Update Magnitude: 1.01652

Collected Steps per Second: 22,173.55177
Overall Steps per Second: 10,705.88389

Timestep Collection Time: 2.25494
Timestep Consumption Time: 2.41539
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.67033

Cumulative Model Updates: 177,260
Cumulative Timesteps: 1,478,234,398

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,650.15874
Policy Entropy: 3.74066
Value Function Loss: 0.03099

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14672
Policy Update Magnitude: 0.48739
Value Function Update Magnitude: 0.98953

Collected Steps per Second: 22,471.29313
Overall Steps per Second: 10,876.08723

Timestep Collection Time: 2.22542
Timestep Consumption Time: 2.37256
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.59798

Cumulative Model Updates: 177,266
Cumulative Timesteps: 1,478,284,406

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1478284406...
Checkpoint 1478284406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,650.15874
Policy Entropy: 3.71591
Value Function Loss: 0.02893

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.42151
Value Function Update Magnitude: 0.81198

Collected Steps per Second: 22,209.37194
Overall Steps per Second: 10,636.95710

Timestep Collection Time: 2.25157
Timestep Consumption Time: 2.44958
PPO Batch Consumption Time: 0.28719
Total Iteration Time: 4.70116

Cumulative Model Updates: 177,272
Cumulative Timesteps: 1,478,334,412

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,650.15874
Policy Entropy: 3.70039
Value Function Loss: 0.02832

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13839
Policy Update Magnitude: 0.39409
Value Function Update Magnitude: 0.61266

Collected Steps per Second: 23,012.19808
Overall Steps per Second: 10,955.96681

Timestep Collection Time: 2.17346
Timestep Consumption Time: 2.39173
PPO Batch Consumption Time: 0.27623
Total Iteration Time: 4.56518

Cumulative Model Updates: 177,278
Cumulative Timesteps: 1,478,384,428

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1478384428...
Checkpoint 1478384428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 402,727.98540
Policy Entropy: 3.69677
Value Function Loss: 0.03259

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14289
Policy Update Magnitude: 0.40952
Value Function Update Magnitude: 0.56579

Collected Steps per Second: 22,254.04507
Overall Steps per Second: 10,575.96314

Timestep Collection Time: 2.24786
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.72997

Cumulative Model Updates: 177,284
Cumulative Timesteps: 1,478,434,452

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,972.54854
Policy Entropy: 3.71529
Value Function Loss: 0.03169

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13308
Policy Update Magnitude: 0.44732
Value Function Update Magnitude: 0.63564

Collected Steps per Second: 23,052.92686
Overall Steps per Second: 10,885.87460

Timestep Collection Time: 2.17031
Timestep Consumption Time: 2.42574
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.59605

Cumulative Model Updates: 177,290
Cumulative Timesteps: 1,478,484,484

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1478484484...
Checkpoint 1478484484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,778.22529
Policy Entropy: 3.71726
Value Function Loss: 0.03779

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13732
Policy Update Magnitude: 0.47129
Value Function Update Magnitude: 0.60654

Collected Steps per Second: 22,256.23964
Overall Steps per Second: 10,743.58145

Timestep Collection Time: 2.24728
Timestep Consumption Time: 2.40815
PPO Batch Consumption Time: 0.27568
Total Iteration Time: 4.65543

Cumulative Model Updates: 177,296
Cumulative Timesteps: 1,478,534,500

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 175,206.91600
Policy Entropy: 3.72483
Value Function Loss: 0.04595

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.52777
Value Function Update Magnitude: 0.60397

Collected Steps per Second: 23,052.89969
Overall Steps per Second: 10,896.17964

Timestep Collection Time: 2.17083
Timestep Consumption Time: 2.42197
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.59280

Cumulative Model Updates: 177,302
Cumulative Timesteps: 1,478,584,544

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1478584544...
Checkpoint 1478584544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,390.70322
Policy Entropy: 3.71014
Value Function Loss: 0.05224

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.56198
Value Function Update Magnitude: 0.61796

Collected Steps per Second: 22,831.23991
Overall Steps per Second: 10,681.35267

Timestep Collection Time: 2.19068
Timestep Consumption Time: 2.49187
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.68255

Cumulative Model Updates: 177,308
Cumulative Timesteps: 1,478,634,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,148.62875
Policy Entropy: 3.70639
Value Function Loss: 0.05154

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13036
Policy Update Magnitude: 0.58207
Value Function Update Magnitude: 0.61720

Collected Steps per Second: 22,987.79367
Overall Steps per Second: 10,857.74751

Timestep Collection Time: 2.17594
Timestep Consumption Time: 2.43091
PPO Batch Consumption Time: 0.28081
Total Iteration Time: 4.60685

Cumulative Model Updates: 177,314
Cumulative Timesteps: 1,478,684,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1478684580...
Checkpoint 1478684580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201,869.80249
Policy Entropy: 3.70604
Value Function Loss: 0.05037

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14133
Policy Update Magnitude: 0.60721
Value Function Update Magnitude: 0.65532

Collected Steps per Second: 22,589.23237
Overall Steps per Second: 10,623.51279

Timestep Collection Time: 2.21353
Timestep Consumption Time: 2.49320
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.70673

Cumulative Model Updates: 177,320
Cumulative Timesteps: 1,478,734,582

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 291,797.79944
Policy Entropy: 3.70773
Value Function Loss: 0.05498

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14099
Policy Update Magnitude: 0.60416
Value Function Update Magnitude: 0.75304

Collected Steps per Second: 23,164.67550
Overall Steps per Second: 10,957.69942

Timestep Collection Time: 2.15846
Timestep Consumption Time: 2.40454
PPO Batch Consumption Time: 0.27618
Total Iteration Time: 4.56300

Cumulative Model Updates: 177,326
Cumulative Timesteps: 1,478,784,582

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1478784582...
Checkpoint 1478784582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,986.62571
Policy Entropy: 3.72988
Value Function Loss: 0.05541

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14406
Policy Update Magnitude: 0.62902
Value Function Update Magnitude: 0.76365

Collected Steps per Second: 22,703.53107
Overall Steps per Second: 10,643.70092

Timestep Collection Time: 2.20336
Timestep Consumption Time: 2.49651
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.69987

Cumulative Model Updates: 177,332
Cumulative Timesteps: 1,478,834,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,629.51881
Policy Entropy: 3.72164
Value Function Loss: 0.05380

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.61171
Value Function Update Magnitude: 0.71355

Collected Steps per Second: 23,180.91565
Overall Steps per Second: 10,942.98062

Timestep Collection Time: 2.15781
Timestep Consumption Time: 2.41316
PPO Batch Consumption Time: 0.27631
Total Iteration Time: 4.57097

Cumulative Model Updates: 177,338
Cumulative Timesteps: 1,478,884,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1478884626...
Checkpoint 1478884626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,688.21616
Policy Entropy: 3.72345
Value Function Loss: 0.04478

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13555
Policy Update Magnitude: 0.54691
Value Function Update Magnitude: 0.68130

Collected Steps per Second: 22,055.78854
Overall Steps per Second: 10,728.11971

Timestep Collection Time: 2.26816
Timestep Consumption Time: 2.39492
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.66307

Cumulative Model Updates: 177,344
Cumulative Timesteps: 1,478,934,652

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,630.87410
Policy Entropy: 3.70808
Value Function Loss: 0.04148

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13705
Policy Update Magnitude: 0.49076
Value Function Update Magnitude: 0.55061

Collected Steps per Second: 22,420.32413
Overall Steps per Second: 10,769.79080

Timestep Collection Time: 2.23181
Timestep Consumption Time: 2.41433
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.64614

Cumulative Model Updates: 177,350
Cumulative Timesteps: 1,478,984,690

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1478984690...
Checkpoint 1478984690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,026.16157
Policy Entropy: 3.70561
Value Function Loss: 0.03419

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.46780
Value Function Update Magnitude: 0.48825

Collected Steps per Second: 22,180.71771
Overall Steps per Second: 10,706.78139

Timestep Collection Time: 2.25448
Timestep Consumption Time: 2.41602
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.67050

Cumulative Model Updates: 177,356
Cumulative Timesteps: 1,479,034,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,026.16157
Policy Entropy: 3.69351
Value Function Loss: 0.03297

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.45731
Value Function Update Magnitude: 0.53034

Collected Steps per Second: 22,582.64617
Overall Steps per Second: 10,885.31928

Timestep Collection Time: 2.21533
Timestep Consumption Time: 2.38059
PPO Batch Consumption Time: 0.27608
Total Iteration Time: 4.59591

Cumulative Model Updates: 177,362
Cumulative Timesteps: 1,479,084,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1479084724...
Checkpoint 1479084724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,307.62481
Policy Entropy: 3.70053
Value Function Loss: 0.03115

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13270
Policy Update Magnitude: 0.45802
Value Function Update Magnitude: 0.52797

Collected Steps per Second: 22,722.09024
Overall Steps per Second: 10,728.06613

Timestep Collection Time: 2.20103
Timestep Consumption Time: 2.46076
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.66179

Cumulative Model Updates: 177,368
Cumulative Timesteps: 1,479,134,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,736.86814
Policy Entropy: 3.70197
Value Function Loss: 0.02951

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.42765
Value Function Update Magnitude: 0.58109

Collected Steps per Second: 23,365.87618
Overall Steps per Second: 10,875.68739

Timestep Collection Time: 2.14116
Timestep Consumption Time: 2.45901
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.60017

Cumulative Model Updates: 177,374
Cumulative Timesteps: 1,479,184,766

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1479184766...
Checkpoint 1479184766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,736.86814
Policy Entropy: 3.69924
Value Function Loss: 0.02792

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.39994
Value Function Update Magnitude: 0.60314

Collected Steps per Second: 22,588.29896
Overall Steps per Second: 10,631.47266

Timestep Collection Time: 2.21433
Timestep Consumption Time: 2.49038
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.70471

Cumulative Model Updates: 177,380
Cumulative Timesteps: 1,479,234,784

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,963.52680
Policy Entropy: 3.69526
Value Function Loss: 0.02482

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13519
Policy Update Magnitude: 0.37955
Value Function Update Magnitude: 0.52729

Collected Steps per Second: 22,974.73790
Overall Steps per Second: 10,827.39198

Timestep Collection Time: 2.17665
Timestep Consumption Time: 2.44200
PPO Batch Consumption Time: 0.28139
Total Iteration Time: 4.61866

Cumulative Model Updates: 177,386
Cumulative Timesteps: 1,479,284,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1479284792...
Checkpoint 1479284792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256,963.52680
Policy Entropy: 3.68844
Value Function Loss: 0.02402

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.39372
Value Function Update Magnitude: 0.56778

Collected Steps per Second: 22,359.88550
Overall Steps per Second: 10,642.88436

Timestep Collection Time: 2.23633
Timestep Consumption Time: 2.46202
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.69835

Cumulative Model Updates: 177,392
Cumulative Timesteps: 1,479,334,796

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256,963.52680
Policy Entropy: 3.70085
Value Function Loss: 0.02079

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.40231
Value Function Update Magnitude: 0.54937

Collected Steps per Second: 23,069.75848
Overall Steps per Second: 10,871.14859

Timestep Collection Time: 2.16803
Timestep Consumption Time: 2.43277
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.60080

Cumulative Model Updates: 177,398
Cumulative Timesteps: 1,479,384,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1479384812...
Checkpoint 1479384812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 794,414.42418
Policy Entropy: 3.69950
Value Function Loss: 0.02614

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.42585
Value Function Update Magnitude: 0.64941

Collected Steps per Second: 22,770.46173
Overall Steps per Second: 10,655.58052

Timestep Collection Time: 2.19600
Timestep Consumption Time: 2.49675
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.69275

Cumulative Model Updates: 177,404
Cumulative Timesteps: 1,479,434,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,749.46809
Policy Entropy: 3.71155
Value Function Loss: 0.02493

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14101
Policy Update Magnitude: 0.43725
Value Function Update Magnitude: 0.81472

Collected Steps per Second: 22,892.27154
Overall Steps per Second: 10,861.52282

Timestep Collection Time: 2.18423
Timestep Consumption Time: 2.41936
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.60359

Cumulative Model Updates: 177,410
Cumulative Timesteps: 1,479,484,818

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1479484818...
Checkpoint 1479484818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,304.39223
Policy Entropy: 3.71330
Value Function Loss: 0.02907

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.14146
Policy Update Magnitude: 0.44210
Value Function Update Magnitude: 0.80240

Collected Steps per Second: 22,299.13102
Overall Steps per Second: 10,660.23721

Timestep Collection Time: 2.24260
Timestep Consumption Time: 2.44848
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.69108

Cumulative Model Updates: 177,416
Cumulative Timesteps: 1,479,534,826

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,515.70770
Policy Entropy: 3.71515
Value Function Loss: 0.02532

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.45336
Value Function Update Magnitude: 0.74581

Collected Steps per Second: 23,300.02119
Overall Steps per Second: 10,919.78124

Timestep Collection Time: 2.14686
Timestep Consumption Time: 2.43400
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.58086

Cumulative Model Updates: 177,422
Cumulative Timesteps: 1,479,584,848

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1479584848...
Checkpoint 1479584848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 671,610.72108
Policy Entropy: 3.71540
Value Function Loss: 0.03133

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.43545
Value Function Update Magnitude: 0.74106

Collected Steps per Second: 22,828.83096
Overall Steps per Second: 10,649.25795

Timestep Collection Time: 2.19126
Timestep Consumption Time: 2.50615
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.69742

Cumulative Model Updates: 177,428
Cumulative Timesteps: 1,479,634,872

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,658.70604
Policy Entropy: 3.71655
Value Function Loss: 0.03016

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13266
Policy Update Magnitude: 0.45162
Value Function Update Magnitude: 0.85813

Collected Steps per Second: 23,134.02440
Overall Steps per Second: 10,961.17246

Timestep Collection Time: 2.16227
Timestep Consumption Time: 2.40129
PPO Batch Consumption Time: 0.27592
Total Iteration Time: 4.56356

Cumulative Model Updates: 177,434
Cumulative Timesteps: 1,479,684,894

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1479684894...
Checkpoint 1479684894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,050.95563
Policy Entropy: 3.69915
Value Function Loss: 0.03765

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.44658
Value Function Update Magnitude: 0.76211

Collected Steps per Second: 22,293.80504
Overall Steps per Second: 10,597.77458

Timestep Collection Time: 2.24349
Timestep Consumption Time: 2.47599
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.71948

Cumulative Model Updates: 177,440
Cumulative Timesteps: 1,479,734,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 174,534.94577
Policy Entropy: 3.68394
Value Function Loss: 0.03898

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12971
Policy Update Magnitude: 0.46783
Value Function Update Magnitude: 0.72191

Collected Steps per Second: 23,062.73658
Overall Steps per Second: 10,881.58146

Timestep Collection Time: 2.16913
Timestep Consumption Time: 2.42818
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.59731

Cumulative Model Updates: 177,446
Cumulative Timesteps: 1,479,784,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1479784936...
Checkpoint 1479784936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,544.67941
Policy Entropy: 3.68631
Value Function Loss: 0.04290

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13631
Policy Update Magnitude: 0.48938
Value Function Update Magnitude: 0.92496

Collected Steps per Second: 22,707.84567
Overall Steps per Second: 10,657.95186

Timestep Collection Time: 2.20241
Timestep Consumption Time: 2.49005
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.69246

Cumulative Model Updates: 177,452
Cumulative Timesteps: 1,479,834,948

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,900.75304
Policy Entropy: 3.70468
Value Function Loss: 0.04603

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.56058
Value Function Update Magnitude: 0.91795

Collected Steps per Second: 23,135.29024
Overall Steps per Second: 10,897.76049

Timestep Collection Time: 2.16181
Timestep Consumption Time: 2.42758
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.58938

Cumulative Model Updates: 177,458
Cumulative Timesteps: 1,479,884,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1479884962...
Checkpoint 1479884962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 883,596.18699
Policy Entropy: 3.71440
Value Function Loss: 0.04422

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13584
Policy Update Magnitude: 0.55965
Value Function Update Magnitude: 0.94467

Collected Steps per Second: 22,346.91681
Overall Steps per Second: 10,668.36746

Timestep Collection Time: 2.23834
Timestep Consumption Time: 2.45029
PPO Batch Consumption Time: 0.28333
Total Iteration Time: 4.68863

Cumulative Model Updates: 177,464
Cumulative Timesteps: 1,479,934,982

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,159.20312
Policy Entropy: 3.73148
Value Function Loss: 0.04129

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.54553
Value Function Update Magnitude: 1.04392

Collected Steps per Second: 22,753.11199
Overall Steps per Second: 10,815.91642

Timestep Collection Time: 2.19829
Timestep Consumption Time: 2.42619
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.62448

Cumulative Model Updates: 177,470
Cumulative Timesteps: 1,479,985,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1479985000...
Checkpoint 1479985000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,057.05894
Policy Entropy: 3.72819
Value Function Loss: 0.03921

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13448
Policy Update Magnitude: 0.51168
Value Function Update Magnitude: 1.03150

Collected Steps per Second: 22,599.86170
Overall Steps per Second: 10,698.41595

Timestep Collection Time: 2.21285
Timestep Consumption Time: 2.46168
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.67452

Cumulative Model Updates: 177,476
Cumulative Timesteps: 1,480,035,010

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,670.83082
Policy Entropy: 3.72812
Value Function Loss: 0.03593

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.50535
Value Function Update Magnitude: 1.01630

Collected Steps per Second: 23,305.24025
Overall Steps per Second: 10,932.41058

Timestep Collection Time: 2.14578
Timestep Consumption Time: 2.42850
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.57429

Cumulative Model Updates: 177,482
Cumulative Timesteps: 1,480,085,018

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1480085018...
Checkpoint 1480085018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279,309.05934
Policy Entropy: 3.71399
Value Function Loss: 0.03248

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14214
Policy Update Magnitude: 0.47262
Value Function Update Magnitude: 0.97748

Collected Steps per Second: 22,578.51416
Overall Steps per Second: 10,661.14259

Timestep Collection Time: 2.21538
Timestep Consumption Time: 2.47642
PPO Batch Consumption Time: 0.28710
Total Iteration Time: 4.69180

Cumulative Model Updates: 177,488
Cumulative Timesteps: 1,480,135,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279,309.05934
Policy Entropy: 3.70861
Value Function Loss: 0.02545

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14822
Policy Update Magnitude: 0.43251
Value Function Update Magnitude: 0.85789

Collected Steps per Second: 23,089.11786
Overall Steps per Second: 10,885.63908

Timestep Collection Time: 2.16587
Timestep Consumption Time: 2.42807
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.59394

Cumulative Model Updates: 177,494
Cumulative Timesteps: 1,480,185,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1480185046...
Checkpoint 1480185046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757,850.63569
Policy Entropy: 3.70954
Value Function Loss: 0.02634

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14391
Policy Update Magnitude: 0.46722
Value Function Update Magnitude: 0.82573

Collected Steps per Second: 22,636.98003
Overall Steps per Second: 10,629.90837

Timestep Collection Time: 2.20913
Timestep Consumption Time: 2.49533
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.70446

Cumulative Model Updates: 177,500
Cumulative Timesteps: 1,480,235,054

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,463.73784
Policy Entropy: 3.70456
Value Function Loss: 0.02725

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.49474
Value Function Update Magnitude: 0.84113

Collected Steps per Second: 22,888.23821
Overall Steps per Second: 10,867.91914

Timestep Collection Time: 2.18601
Timestep Consumption Time: 2.41781
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.60383

Cumulative Model Updates: 177,506
Cumulative Timesteps: 1,480,285,088

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1480285088...
Checkpoint 1480285088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,127.01519
Policy Entropy: 3.72203
Value Function Loss: 0.03010

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13419
Policy Update Magnitude: 0.49561
Value Function Update Magnitude: 0.84734

Collected Steps per Second: 22,519.22239
Overall Steps per Second: 10,673.99935

Timestep Collection Time: 2.22077
Timestep Consumption Time: 2.46445
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.68522

Cumulative Model Updates: 177,512
Cumulative Timesteps: 1,480,335,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,943.76606
Policy Entropy: 3.71713
Value Function Loss: 0.02856

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.45299
Value Function Update Magnitude: 0.74336

Collected Steps per Second: 23,302.70529
Overall Steps per Second: 10,971.47970

Timestep Collection Time: 2.14593
Timestep Consumption Time: 2.41189
PPO Batch Consumption Time: 0.27634
Total Iteration Time: 4.55782

Cumulative Model Updates: 177,518
Cumulative Timesteps: 1,480,385,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1480385104...
Checkpoint 1480385104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,016.10112
Policy Entropy: 3.70532
Value Function Loss: 0.02693

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13820
Policy Update Magnitude: 0.44189
Value Function Update Magnitude: 0.62161

Collected Steps per Second: 22,726.91327
Overall Steps per Second: 10,660.88853

Timestep Collection Time: 2.20030
Timestep Consumption Time: 2.49030
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.69060

Cumulative Model Updates: 177,524
Cumulative Timesteps: 1,480,435,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 230,367.13841
Policy Entropy: 3.70570
Value Function Loss: 0.02370

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14536
Policy Update Magnitude: 0.43050
Value Function Update Magnitude: 0.60200

Collected Steps per Second: 23,178.62975
Overall Steps per Second: 10,862.89502

Timestep Collection Time: 2.15742
Timestep Consumption Time: 2.44596
PPO Batch Consumption Time: 0.28063
Total Iteration Time: 4.60338

Cumulative Model Updates: 177,530
Cumulative Timesteps: 1,480,485,116

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1480485116...
Checkpoint 1480485116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,189.63239
Policy Entropy: 3.71517
Value Function Loss: 0.02345

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.42342
Value Function Update Magnitude: 0.72352

Collected Steps per Second: 22,677.46723
Overall Steps per Second: 10,618.81574

Timestep Collection Time: 2.20563
Timestep Consumption Time: 2.50469
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.71032

Cumulative Model Updates: 177,536
Cumulative Timesteps: 1,480,535,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,587.64468
Policy Entropy: 3.71820
Value Function Loss: 0.02015

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14166
Policy Update Magnitude: 0.41114
Value Function Update Magnitude: 0.77182

Collected Steps per Second: 22,916.33810
Overall Steps per Second: 10,838.98788

Timestep Collection Time: 2.18307
Timestep Consumption Time: 2.43249
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.61556

Cumulative Model Updates: 177,542
Cumulative Timesteps: 1,480,585,162

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1480585162...
Checkpoint 1480585162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,349.73041
Policy Entropy: 3.71634
Value Function Loss: 0.02506

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14400
Policy Update Magnitude: 0.45044
Value Function Update Magnitude: 0.80642

Collected Steps per Second: 22,586.91341
Overall Steps per Second: 10,690.94943

Timestep Collection Time: 2.21403
Timestep Consumption Time: 2.46358
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.67760

Cumulative Model Updates: 177,548
Cumulative Timesteps: 1,480,635,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,037.68471
Policy Entropy: 3.71085
Value Function Loss: 0.02274

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.46466
Value Function Update Magnitude: 0.75495

Collected Steps per Second: 22,892.03572
Overall Steps per Second: 10,861.28755

Timestep Collection Time: 2.18530
Timestep Consumption Time: 2.42060
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.60590

Cumulative Model Updates: 177,554
Cumulative Timesteps: 1,480,685,196

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1480685196...
Checkpoint 1480685196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,784.94857
Policy Entropy: 3.71760
Value Function Loss: 0.02770

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.48927
Value Function Update Magnitude: 0.81637

Collected Steps per Second: 22,606.27351
Overall Steps per Second: 10,724.82170

Timestep Collection Time: 2.21213
Timestep Consumption Time: 2.45070
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.66283

Cumulative Model Updates: 177,560
Cumulative Timesteps: 1,480,735,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204,148.17089
Policy Entropy: 3.71617
Value Function Loss: 0.03250

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14438
Policy Update Magnitude: 0.50693
Value Function Update Magnitude: 0.88518

Collected Steps per Second: 23,051.52979
Overall Steps per Second: 10,871.29880

Timestep Collection Time: 2.16983
Timestep Consumption Time: 2.43109
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.60092

Cumulative Model Updates: 177,566
Cumulative Timesteps: 1,480,785,222

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1480785222...
Checkpoint 1480785222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,738.50427
Policy Entropy: 3.73662
Value Function Loss: 0.04920

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14041
Policy Update Magnitude: 0.55268
Value Function Update Magnitude: 0.86960

Collected Steps per Second: 22,602.76628
Overall Steps per Second: 10,625.75768

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.49482
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.70818

Cumulative Model Updates: 177,572
Cumulative Timesteps: 1,480,835,250

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,289.03068
Policy Entropy: 3.74286
Value Function Loss: 0.05975

Mean KL Divergence: 0.01141
SB3 Clip Fraction: 0.14488
Policy Update Magnitude: 0.64156
Value Function Update Magnitude: 0.90928

Collected Steps per Second: 23,058.75921
Overall Steps per Second: 10,884.29653

Timestep Collection Time: 2.16863
Timestep Consumption Time: 2.42569
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.59433

Cumulative Model Updates: 177,578
Cumulative Timesteps: 1,480,885,256

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1480885256...
Checkpoint 1480885256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,382.46961
Policy Entropy: 3.74320
Value Function Loss: 0.05784

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14709
Policy Update Magnitude: 0.64195
Value Function Update Magnitude: 0.73579

Collected Steps per Second: 22,301.06518
Overall Steps per Second: 10,759.61440

Timestep Collection Time: 2.24240
Timestep Consumption Time: 2.40535
PPO Batch Consumption Time: 0.27629
Total Iteration Time: 4.64775

Cumulative Model Updates: 177,584
Cumulative Timesteps: 1,480,935,264

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 598,704.01972
Policy Entropy: 3.71573
Value Function Loss: 0.04811

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15462
Policy Update Magnitude: 0.60334
Value Function Update Magnitude: 0.64664

Collected Steps per Second: 22,768.82436
Overall Steps per Second: 10,784.99136

Timestep Collection Time: 2.19634
Timestep Consumption Time: 2.44048
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.63681

Cumulative Model Updates: 177,590
Cumulative Timesteps: 1,480,985,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1480985272...
Checkpoint 1480985272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 385,723.80434
Policy Entropy: 3.71774
Value Function Loss: 0.04257

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11119
Policy Update Magnitude: 0.70017
Value Function Update Magnitude: 0.64002

Collected Steps per Second: 22,352.76502
Overall Steps per Second: 10,679.04359

Timestep Collection Time: 2.23802
Timestep Consumption Time: 2.44648
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.68450

Cumulative Model Updates: 177,596
Cumulative Timesteps: 1,481,035,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,237.17618
Policy Entropy: 3.70144
Value Function Loss: 0.05504

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.16886
Policy Update Magnitude: 0.75202
Value Function Update Magnitude: 0.73952

Collected Steps per Second: 22,644.23249
Overall Steps per Second: 10,824.66669

Timestep Collection Time: 2.20895
Timestep Consumption Time: 2.41198
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.62093

Cumulative Model Updates: 177,602
Cumulative Timesteps: 1,481,085,318

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1481085318...
Checkpoint 1481085318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,415.77122
Policy Entropy: 3.70749
Value Function Loss: 0.06911

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.16512
Policy Update Magnitude: 0.66407
Value Function Update Magnitude: 0.80606

Collected Steps per Second: 22,039.50149
Overall Steps per Second: 10,684.53003

Timestep Collection Time: 2.26874
Timestep Consumption Time: 2.41111
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.67985

Cumulative Model Updates: 177,608
Cumulative Timesteps: 1,481,135,320

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,919.44728
Policy Entropy: 3.70713
Value Function Loss: 0.07275

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.68880
Value Function Update Magnitude: 0.74160

Collected Steps per Second: 22,308.18705
Overall Steps per Second: 10,565.59802

Timestep Collection Time: 2.24267
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.73518

Cumulative Model Updates: 177,614
Cumulative Timesteps: 1,481,185,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1481185350...
Checkpoint 1481185350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,326.89466
Policy Entropy: 3.71761
Value Function Loss: 0.06183

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.15991
Policy Update Magnitude: 0.68182
Value Function Update Magnitude: 0.64829

Collected Steps per Second: 22,235.17321
Overall Steps per Second: 10,564.13566

Timestep Collection Time: 2.24968
Timestep Consumption Time: 2.48540
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.73508

Cumulative Model Updates: 177,620
Cumulative Timesteps: 1,481,235,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,471.46230
Policy Entropy: 3.73017
Value Function Loss: 0.05631

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.66999
Value Function Update Magnitude: 0.57255

Collected Steps per Second: 22,725.07477
Overall Steps per Second: 10,859.33678

Timestep Collection Time: 2.20039
Timestep Consumption Time: 2.40431
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.60470

Cumulative Model Updates: 177,626
Cumulative Timesteps: 1,481,285,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1481285376...
Checkpoint 1481285376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,301.55795
Policy Entropy: 3.73836
Value Function Loss: 0.04934

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.67855
Value Function Update Magnitude: 0.70652

Collected Steps per Second: 21,441.42022
Overall Steps per Second: 10,723.13268

Timestep Collection Time: 2.33268
Timestep Consumption Time: 2.33163
PPO Batch Consumption Time: 0.27592
Total Iteration Time: 4.66431

Cumulative Model Updates: 177,632
Cumulative Timesteps: 1,481,335,392

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,896.80199
Policy Entropy: 3.72563
Value Function Loss: 0.04418

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.65734
Value Function Update Magnitude: 0.83206

Collected Steps per Second: 22,235.48134
Overall Steps per Second: 10,845.02920

Timestep Collection Time: 2.24902
Timestep Consumption Time: 2.36213
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.61114

Cumulative Model Updates: 177,638
Cumulative Timesteps: 1,481,385,400

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1481385400...
Checkpoint 1481385400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,909.30986
Policy Entropy: 3.68499
Value Function Loss: 0.04348

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13236
Policy Update Magnitude: 0.61355
Value Function Update Magnitude: 0.73751

Collected Steps per Second: 21,805.18686
Overall Steps per Second: 10,636.41832

Timestep Collection Time: 2.29432
Timestep Consumption Time: 2.40915
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.70346

Cumulative Model Updates: 177,644
Cumulative Timesteps: 1,481,435,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,095.44921
Policy Entropy: 3.68936
Value Function Loss: 0.04183

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.56668
Value Function Update Magnitude: 0.70776

Collected Steps per Second: 23,236.42123
Overall Steps per Second: 11,018.92350

Timestep Collection Time: 2.15257
Timestep Consumption Time: 2.38671
PPO Batch Consumption Time: 0.27566
Total Iteration Time: 4.53928

Cumulative Model Updates: 177,650
Cumulative Timesteps: 1,481,485,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1481485446...
Checkpoint 1481485446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,349.42355
Policy Entropy: 3.70452
Value Function Loss: 0.04164

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13347
Policy Update Magnitude: 0.51552
Value Function Update Magnitude: 0.62607

Collected Steps per Second: 22,485.03156
Overall Steps per Second: 10,703.97888

Timestep Collection Time: 2.22468
Timestep Consumption Time: 2.44854
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.67322

Cumulative Model Updates: 177,656
Cumulative Timesteps: 1,481,535,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,283.43705
Policy Entropy: 3.71949
Value Function Loss: 0.04091

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.54747
Value Function Update Magnitude: 0.64528

Collected Steps per Second: 23,049.96601
Overall Steps per Second: 10,807.91230

Timestep Collection Time: 2.16946
Timestep Consumption Time: 2.45733
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.62680

Cumulative Model Updates: 177,662
Cumulative Timesteps: 1,481,585,474

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1481585474...
Checkpoint 1481585474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,743.44468
Policy Entropy: 3.72125
Value Function Loss: 0.04493

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13349
Policy Update Magnitude: 0.58794
Value Function Update Magnitude: 0.63573

Collected Steps per Second: 22,403.33622
Overall Steps per Second: 10,606.90462

Timestep Collection Time: 2.23199
Timestep Consumption Time: 2.48230
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.71429

Cumulative Model Updates: 177,668
Cumulative Timesteps: 1,481,635,478

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,589.15810
Policy Entropy: 3.71000
Value Function Loss: 0.04104

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.56259
Value Function Update Magnitude: 0.60105

Collected Steps per Second: 23,233.83158
Overall Steps per Second: 10,912.53279

Timestep Collection Time: 2.15246
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.58280

Cumulative Model Updates: 177,674
Cumulative Timesteps: 1,481,685,488

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1481685488...
Checkpoint 1481685488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,102.17396
Policy Entropy: 3.71263
Value Function Loss: 0.03794

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.51700
Value Function Update Magnitude: 0.62334

Collected Steps per Second: 22,253.44154
Overall Steps per Second: 10,668.75829

Timestep Collection Time: 2.24711
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.68714

Cumulative Model Updates: 177,680
Cumulative Timesteps: 1,481,735,494

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,341.91098
Policy Entropy: 3.70041
Value Function Loss: 0.03664

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.49156
Value Function Update Magnitude: 0.53812

Collected Steps per Second: 23,060.20563
Overall Steps per Second: 10,875.04624

Timestep Collection Time: 2.16945
Timestep Consumption Time: 2.43080
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.60026

Cumulative Model Updates: 177,686
Cumulative Timesteps: 1,481,785,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1481785522...
Checkpoint 1481785522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,189.37775
Policy Entropy: 3.70074
Value Function Loss: 0.03117

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.49241
Value Function Update Magnitude: 0.48260

Collected Steps per Second: 22,531.40512
Overall Steps per Second: 10,614.15109

Timestep Collection Time: 2.21939
Timestep Consumption Time: 2.49187
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.71126

Cumulative Model Updates: 177,692
Cumulative Timesteps: 1,481,835,528

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,468.87105
Policy Entropy: 3.68434
Value Function Loss: 0.03114

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.45626
Value Function Update Magnitude: 0.47786

Collected Steps per Second: 22,935.31393
Overall Steps per Second: 10,888.28937

Timestep Collection Time: 2.18092
Timestep Consumption Time: 2.41301
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.59393

Cumulative Model Updates: 177,698
Cumulative Timesteps: 1,481,885,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1481885548...
Checkpoint 1481885548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,209.02963
Policy Entropy: 3.69980
Value Function Loss: 0.02844

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.42259
Value Function Update Magnitude: 0.47783

Collected Steps per Second: 22,416.74061
Overall Steps per Second: 10,706.78041

Timestep Collection Time: 2.23181
Timestep Consumption Time: 2.44093
PPO Batch Consumption Time: 0.28188
Total Iteration Time: 4.67274

Cumulative Model Updates: 177,704
Cumulative Timesteps: 1,481,935,578

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,856.19133
Policy Entropy: 3.69103
Value Function Loss: 0.03143

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.40608
Value Function Update Magnitude: 0.45077

Collected Steps per Second: 22,525.52139
Overall Steps per Second: 10,982.50966

Timestep Collection Time: 2.22006
Timestep Consumption Time: 2.33336
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.55342

Cumulative Model Updates: 177,710
Cumulative Timesteps: 1,481,985,586

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1481985586...
Checkpoint 1481985586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,188.95024
Policy Entropy: 3.70928
Value Function Loss: 0.03120

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.43184
Value Function Update Magnitude: 0.50553

Collected Steps per Second: 22,044.12333
Overall Steps per Second: 10,703.59157

Timestep Collection Time: 2.26918
Timestep Consumption Time: 2.40421
PPO Batch Consumption Time: 0.28949
Total Iteration Time: 4.67338

Cumulative Model Updates: 177,716
Cumulative Timesteps: 1,482,035,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,218.72567
Policy Entropy: 3.69746
Value Function Loss: 0.02861

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 0.45313
Value Function Update Magnitude: 0.58382

Collected Steps per Second: 22,799.51371
Overall Steps per Second: 10,856.85237

Timestep Collection Time: 2.19373
Timestep Consumption Time: 2.41313
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.60686

Cumulative Model Updates: 177,722
Cumulative Timesteps: 1,482,085,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1482085624...
Checkpoint 1482085624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,771.82642
Policy Entropy: 3.69362
Value Function Loss: 0.03071

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12411
Policy Update Magnitude: 0.48571
Value Function Update Magnitude: 0.54933

Collected Steps per Second: 21,912.73658
Overall Steps per Second: 10,574.58382

Timestep Collection Time: 2.28269
Timestep Consumption Time: 2.44752
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.73021

Cumulative Model Updates: 177,728
Cumulative Timesteps: 1,482,135,644

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,458.95148
Policy Entropy: 3.70211
Value Function Loss: 0.03014

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13430
Policy Update Magnitude: 0.46909
Value Function Update Magnitude: 0.46323

Collected Steps per Second: 23,033.37010
Overall Steps per Second: 10,958.69204

Timestep Collection Time: 2.17094
Timestep Consumption Time: 2.39202
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.56295

Cumulative Model Updates: 177,734
Cumulative Timesteps: 1,482,185,648

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1482185648...
Checkpoint 1482185648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,169.97943
Policy Entropy: 3.69175
Value Function Loss: 0.02877

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14102
Policy Update Magnitude: 0.43471
Value Function Update Magnitude: 0.46572

Collected Steps per Second: 23,045.07986
Overall Steps per Second: 10,961.00835

Timestep Collection Time: 2.17044
Timestep Consumption Time: 2.39282
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.56327

Cumulative Model Updates: 177,740
Cumulative Timesteps: 1,482,235,666

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,180.44704
Policy Entropy: 3.69869
Value Function Loss: 0.02588

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.39752
Value Function Update Magnitude: 0.40554

Collected Steps per Second: 23,098.58973
Overall Steps per Second: 10,901.82263

Timestep Collection Time: 2.16533
Timestep Consumption Time: 2.42253
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.58786

Cumulative Model Updates: 177,746
Cumulative Timesteps: 1,482,285,682

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1482285682...
Checkpoint 1482285682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,063.95485
Policy Entropy: 3.67722
Value Function Loss: 0.02676

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13734
Policy Update Magnitude: 0.36851
Value Function Update Magnitude: 0.37334

Collected Steps per Second: 22,561.43783
Overall Steps per Second: 10,715.80956

Timestep Collection Time: 2.21653
Timestep Consumption Time: 2.45022
PPO Batch Consumption Time: 0.28169
Total Iteration Time: 4.66675

Cumulative Model Updates: 177,752
Cumulative Timesteps: 1,482,335,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,063.95485
Policy Entropy: 3.67792
Value Function Loss: 0.02466

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13440
Policy Update Magnitude: 0.35371
Value Function Update Magnitude: 0.36753

Collected Steps per Second: 23,030.12864
Overall Steps per Second: 10,885.71389

Timestep Collection Time: 2.17133
Timestep Consumption Time: 2.42240
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.59373

Cumulative Model Updates: 177,758
Cumulative Timesteps: 1,482,385,696

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1482385696...
Checkpoint 1482385696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,697.40336
Policy Entropy: 3.65906
Value Function Loss: 0.02971

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13806
Policy Update Magnitude: 0.37103
Value Function Update Magnitude: 0.34953

Collected Steps per Second: 22,926.60181
Overall Steps per Second: 10,642.65094

Timestep Collection Time: 2.18087
Timestep Consumption Time: 2.51720
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.69808

Cumulative Model Updates: 177,764
Cumulative Timesteps: 1,482,435,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,302.47627
Policy Entropy: 3.67397
Value Function Loss: 0.02664

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.14187
Policy Update Magnitude: 0.37905
Value Function Update Magnitude: 0.38008

Collected Steps per Second: 22,981.29323
Overall Steps per Second: 10,854.20295

Timestep Collection Time: 2.17725
Timestep Consumption Time: 2.43258
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.60983

Cumulative Model Updates: 177,770
Cumulative Timesteps: 1,482,485,732

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1482485732...
Checkpoint 1482485732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,302.47627
Policy Entropy: 3.67411
Value Function Loss: 0.02630

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14050
Policy Update Magnitude: 0.37810
Value Function Update Magnitude: 0.39620

Collected Steps per Second: 22,269.07246
Overall Steps per Second: 10,734.73925

Timestep Collection Time: 2.24616
Timestep Consumption Time: 2.41347
PPO Batch Consumption Time: 0.27654
Total Iteration Time: 4.65964

Cumulative Model Updates: 177,776
Cumulative Timesteps: 1,482,535,752

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,302.47627
Policy Entropy: 3.67551
Value Function Loss: 0.02291

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.36967
Value Function Update Magnitude: 0.34044

Collected Steps per Second: 22,950.14040
Overall Steps per Second: 10,862.54033

Timestep Collection Time: 2.17977
Timestep Consumption Time: 2.42560
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.60537

Cumulative Model Updates: 177,782
Cumulative Timesteps: 1,482,585,778

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1482585778...
Checkpoint 1482585778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207,541.28294
Policy Entropy: 3.67529
Value Function Loss: 0.02436

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12743
Policy Update Magnitude: 0.37416
Value Function Update Magnitude: 0.38331

Collected Steps per Second: 22,723.29337
Overall Steps per Second: 10,651.73343

Timestep Collection Time: 2.20171
Timestep Consumption Time: 2.49518
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.69689

Cumulative Model Updates: 177,788
Cumulative Timesteps: 1,482,635,808

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,301.76752
Policy Entropy: 3.66443
Value Function Loss: 0.02686

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13263
Policy Update Magnitude: 0.39438
Value Function Update Magnitude: 0.48137

Collected Steps per Second: 22,083.96932
Overall Steps per Second: 10,445.77224

Timestep Collection Time: 2.26517
Timestep Consumption Time: 2.52375
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.78892

Cumulative Model Updates: 177,794
Cumulative Timesteps: 1,482,685,832

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1482685832...
Checkpoint 1482685832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,301.76752
Policy Entropy: 3.67210
Value Function Loss: 0.02782

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.43448
Value Function Update Magnitude: 0.51400

Collected Steps per Second: 22,683.31929
Overall Steps per Second: 10,662.48956

Timestep Collection Time: 2.20647
Timestep Consumption Time: 2.48756
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.69403

Cumulative Model Updates: 177,800
Cumulative Timesteps: 1,482,735,882

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,301.76752
Policy Entropy: 3.67427
Value Function Loss: 0.02851

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.48353
Value Function Update Magnitude: 0.50484

Collected Steps per Second: 22,918.08144
Overall Steps per Second: 10,839.21902

Timestep Collection Time: 2.18247
Timestep Consumption Time: 2.43207
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.61454

Cumulative Model Updates: 177,806
Cumulative Timesteps: 1,482,785,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1482785900...
Checkpoint 1482785900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183,345.69491
Policy Entropy: 3.69858
Value Function Loss: 0.02695

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.50296
Value Function Update Magnitude: 0.46529

Collected Steps per Second: 21,750.69201
Overall Steps per Second: 10,726.35287

Timestep Collection Time: 2.29997
Timestep Consumption Time: 2.36387
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.66384

Cumulative Model Updates: 177,812
Cumulative Timesteps: 1,482,835,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,345.69491
Policy Entropy: 3.70361
Value Function Loss: 0.02546

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12920
Policy Update Magnitude: 0.44135
Value Function Update Magnitude: 0.42326

Collected Steps per Second: 22,357.83245
Overall Steps per Second: 10,913.83328

Timestep Collection Time: 2.23644
Timestep Consumption Time: 2.34508
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.58153

Cumulative Model Updates: 177,818
Cumulative Timesteps: 1,482,885,928

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1482885928...
Checkpoint 1482885928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183,345.69491
Policy Entropy: 3.68094
Value Function Loss: 0.02619

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14182
Policy Update Magnitude: 0.40308
Value Function Update Magnitude: 0.45736

Collected Steps per Second: 22,055.77910
Overall Steps per Second: 10,642.57992

Timestep Collection Time: 2.26716
Timestep Consumption Time: 2.43132
PPO Batch Consumption Time: 0.28231
Total Iteration Time: 4.69848

Cumulative Model Updates: 177,824
Cumulative Timesteps: 1,482,935,932

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 199,567.42747
Policy Entropy: 3.67176
Value Function Loss: 0.02583

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.43609
Value Function Update Magnitude: 0.54783

Collected Steps per Second: 22,876.70362
Overall Steps per Second: 10,872.75479

Timestep Collection Time: 2.18607
Timestep Consumption Time: 2.41350
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.59957

Cumulative Model Updates: 177,830
Cumulative Timesteps: 1,482,985,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1482985942...
Checkpoint 1482985942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,861.72771
Policy Entropy: 3.67963
Value Function Loss: 0.03051

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13603
Policy Update Magnitude: 0.49321
Value Function Update Magnitude: 0.65011

Collected Steps per Second: 22,727.36877
Overall Steps per Second: 10,699.06162

Timestep Collection Time: 2.20069
Timestep Consumption Time: 2.47411
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.67480

Cumulative Model Updates: 177,836
Cumulative Timesteps: 1,483,035,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,255.66879
Policy Entropy: 3.69605
Value Function Loss: 0.02890

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.49613
Value Function Update Magnitude: 0.67407

Collected Steps per Second: 23,001.58603
Overall Steps per Second: 10,927.54323

Timestep Collection Time: 2.17455
Timestep Consumption Time: 2.40270
PPO Batch Consumption Time: 0.27591
Total Iteration Time: 4.57724

Cumulative Model Updates: 177,842
Cumulative Timesteps: 1,483,085,976

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1483085976...
Checkpoint 1483085976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,661.53740
Policy Entropy: 3.67526
Value Function Loss: 0.03120

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14022
Policy Update Magnitude: 0.47178
Value Function Update Magnitude: 0.56208

Collected Steps per Second: 22,720.78079
Overall Steps per Second: 10,638.11459

Timestep Collection Time: 2.20133
Timestep Consumption Time: 2.50025
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.70159

Cumulative Model Updates: 177,848
Cumulative Timesteps: 1,483,135,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,661.53740
Policy Entropy: 3.66877
Value Function Loss: 0.02996

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.50731
Value Function Update Magnitude: 0.48471

Collected Steps per Second: 22,739.34649
Overall Steps per Second: 10,825.03606

Timestep Collection Time: 2.19936
Timestep Consumption Time: 2.42067
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.62003

Cumulative Model Updates: 177,854
Cumulative Timesteps: 1,483,186,004

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1483186004...
Checkpoint 1483186004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,890.54375
Policy Entropy: 3.63939
Value Function Loss: 0.03723

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14489
Policy Update Magnitude: 0.52861
Value Function Update Magnitude: 0.59393

Collected Steps per Second: 22,805.92285
Overall Steps per Second: 10,678.63181

Timestep Collection Time: 2.19303
Timestep Consumption Time: 2.49053
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.68356

Cumulative Model Updates: 177,860
Cumulative Timesteps: 1,483,236,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,153.84741
Policy Entropy: 3.66055
Value Function Loss: 0.03826

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14835
Policy Update Magnitude: 0.59429
Value Function Update Magnitude: 0.55211

Collected Steps per Second: 22,812.95294
Overall Steps per Second: 10,868.20440

Timestep Collection Time: 2.19261
Timestep Consumption Time: 2.40980
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.60242

Cumulative Model Updates: 177,866
Cumulative Timesteps: 1,483,286,038

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1483286038...
Checkpoint 1483286038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,153.84741
Policy Entropy: 3.67476
Value Function Loss: 0.03279

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.61893
Value Function Update Magnitude: 0.60039

Collected Steps per Second: 23,060.03036
Overall Steps per Second: 10,770.56364

Timestep Collection Time: 2.17008
Timestep Consumption Time: 2.47611
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.64618

Cumulative Model Updates: 177,872
Cumulative Timesteps: 1,483,336,080

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 74,153.84741
Policy Entropy: 3.69673
Value Function Loss: 0.02527

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13149
Policy Update Magnitude: 0.60158
Value Function Update Magnitude: 0.62769

Collected Steps per Second: 22,332.88937
Overall Steps per Second: 10,818.60044

Timestep Collection Time: 2.23939
Timestep Consumption Time: 2.38339
PPO Batch Consumption Time: 0.28381
Total Iteration Time: 4.62278

Cumulative Model Updates: 177,878
Cumulative Timesteps: 1,483,386,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1483386092...
Checkpoint 1483386092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,480.48450
Policy Entropy: 3.71387
Value Function Loss: 0.01997

Mean KL Divergence: 0.02095
SB3 Clip Fraction: 0.24016
Policy Update Magnitude: 0.51171
Value Function Update Magnitude: 0.56045

Collected Steps per Second: 22,176.34068
Overall Steps per Second: 10,696.43984

Timestep Collection Time: 2.25673
Timestep Consumption Time: 2.42202
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.67875

Cumulative Model Updates: 177,884
Cumulative Timesteps: 1,483,436,138

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 139,480.48450
Policy Entropy: 3.73890
Value Function Loss: 0.02332

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.18794
Policy Update Magnitude: 0.48995
Value Function Update Magnitude: 0.61195

Collected Steps per Second: 22,301.71657
Overall Steps per Second: 10,916.62051

Timestep Collection Time: 2.24279
Timestep Consumption Time: 2.33903
PPO Batch Consumption Time: 0.27558
Total Iteration Time: 4.58182

Cumulative Model Updates: 177,890
Cumulative Timesteps: 1,483,486,156

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1483486156...
Checkpoint 1483486156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412,610.26665
Policy Entropy: 3.73818
Value Function Loss: 0.02684

Mean KL Divergence: 0.01451
SB3 Clip Fraction: 0.18064
Policy Update Magnitude: 0.59242
Value Function Update Magnitude: 0.66057

Collected Steps per Second: 21,891.08242
Overall Steps per Second: 10,564.58881

Timestep Collection Time: 2.28586
Timestep Consumption Time: 2.45072
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.73658

Cumulative Model Updates: 177,896
Cumulative Timesteps: 1,483,536,196

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412,610.26665
Policy Entropy: 3.70715
Value Function Loss: 0.02636

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.19753
Policy Update Magnitude: 0.52560
Value Function Update Magnitude: 0.59380

Collected Steps per Second: 22,790.40104
Overall Steps per Second: 10,858.77014

Timestep Collection Time: 2.19452
Timestep Consumption Time: 2.41134
PPO Batch Consumption Time: 0.27963
Total Iteration Time: 4.60586

Cumulative Model Updates: 177,902
Cumulative Timesteps: 1,483,586,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1483586210...
Checkpoint 1483586210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412,610.26665
Policy Entropy: 3.68947
Value Function Loss: 0.02496

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.17725
Policy Update Magnitude: 0.48287
Value Function Update Magnitude: 0.49715

Collected Steps per Second: 22,899.83035
Overall Steps per Second: 10,702.98373

Timestep Collection Time: 2.18368
Timestep Consumption Time: 2.48847
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.67216

Cumulative Model Updates: 177,908
Cumulative Timesteps: 1,483,636,216

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 412,610.26665
Policy Entropy: 3.68205
Value Function Loss: 0.02236

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12463
Policy Update Magnitude: 0.46942
Value Function Update Magnitude: 0.46338

Collected Steps per Second: 23,127.51280
Overall Steps per Second: 10,901.39146

Timestep Collection Time: 2.16322
Timestep Consumption Time: 2.42610
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.58932

Cumulative Model Updates: 177,914
Cumulative Timesteps: 1,483,686,246

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1483686246...
Checkpoint 1483686246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 412,610.26665
Policy Entropy: 3.69079
Value Function Loss: 0.02104

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14045
Policy Update Magnitude: 0.43560
Value Function Update Magnitude: 0.49221

Collected Steps per Second: 22,890.98447
Overall Steps per Second: 10,691.43861

Timestep Collection Time: 2.18558
Timestep Consumption Time: 2.49387
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.67945

Cumulative Model Updates: 177,920
Cumulative Timesteps: 1,483,736,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.71720
Value Function Loss: 0.01901

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14210
Policy Update Magnitude: 0.41734
Value Function Update Magnitude: 0.44991

Collected Steps per Second: 22,425.65583
Overall Steps per Second: 10,654.93848

Timestep Collection Time: 2.23012
Timestep Consumption Time: 2.46366
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.69379

Cumulative Model Updates: 177,926
Cumulative Timesteps: 1,483,786,288

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1483786288...
Checkpoint 1483786288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.73239
Value Function Loss: 0.01783

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.16243
Policy Update Magnitude: 0.38477
Value Function Update Magnitude: 0.42641

Collected Steps per Second: 22,820.34262
Overall Steps per Second: 10,895.40056

Timestep Collection Time: 2.19129
Timestep Consumption Time: 2.39835
PPO Batch Consumption Time: 0.27575
Total Iteration Time: 4.58964

Cumulative Model Updates: 177,932
Cumulative Timesteps: 1,483,836,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.70015
Value Function Loss: 0.02566

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.17524
Policy Update Magnitude: 0.37915
Value Function Update Magnitude: 0.46504

Collected Steps per Second: 22,905.57697
Overall Steps per Second: 10,922.81522

Timestep Collection Time: 2.18401
Timestep Consumption Time: 2.39595
PPO Batch Consumption Time: 0.27586
Total Iteration Time: 4.57995

Cumulative Model Updates: 177,938
Cumulative Timesteps: 1,483,886,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1483886320...
Checkpoint 1483886320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.68009
Value Function Loss: 0.02822

Mean KL Divergence: 0.01284
SB3 Clip Fraction: 0.17067
Policy Update Magnitude: 0.41910
Value Function Update Magnitude: 0.56407

Collected Steps per Second: 22,777.85434
Overall Steps per Second: 10,707.29186

Timestep Collection Time: 2.19564
Timestep Consumption Time: 2.47519
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.67084

Cumulative Model Updates: 177,944
Cumulative Timesteps: 1,483,936,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.64822
Value Function Loss: 0.03388

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14983
Policy Update Magnitude: 0.42226
Value Function Update Magnitude: 0.44575

Collected Steps per Second: 21,833.69996
Overall Steps per Second: 10,774.82062

Timestep Collection Time: 2.29114
Timestep Consumption Time: 2.35154
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.64268

Cumulative Model Updates: 177,950
Cumulative Timesteps: 1,483,986,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1483986356...
Checkpoint 1483986356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.67248
Value Function Loss: 0.02828

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.47768
Value Function Update Magnitude: 0.36423

Collected Steps per Second: 22,071.72893
Overall Steps per Second: 10,680.52703

Timestep Collection Time: 2.26706
Timestep Consumption Time: 2.41791
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.68497

Cumulative Model Updates: 177,956
Cumulative Timesteps: 1,484,036,394

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.66141
Value Function Loss: 0.03501

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.51120
Value Function Update Magnitude: 0.37370

Collected Steps per Second: 22,210.75397
Overall Steps per Second: 10,613.66538

Timestep Collection Time: 2.25143
Timestep Consumption Time: 2.46004
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.71147

Cumulative Model Updates: 177,962
Cumulative Timesteps: 1,484,086,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1484086400...
Checkpoint 1484086400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.67400
Value Function Loss: 0.03212

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14281
Policy Update Magnitude: 0.46539
Value Function Update Magnitude: 0.34306

Collected Steps per Second: 23,001.77751
Overall Steps per Second: 10,976.22360

Timestep Collection Time: 2.17383
Timestep Consumption Time: 2.38165
PPO Batch Consumption Time: 0.27539
Total Iteration Time: 4.55548

Cumulative Model Updates: 177,968
Cumulative Timesteps: 1,484,136,402

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.68898
Value Function Loss: 0.03343

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13574
Policy Update Magnitude: 0.46016
Value Function Update Magnitude: 0.31856

Collected Steps per Second: 22,473.85215
Overall Steps per Second: 10,773.13880

Timestep Collection Time: 2.22516
Timestep Consumption Time: 2.41675
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.64192

Cumulative Model Updates: 177,974
Cumulative Timesteps: 1,484,186,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1484186410...
Checkpoint 1484186410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.70083
Value Function Loss: 0.02642

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14193
Policy Update Magnitude: 0.43350
Value Function Update Magnitude: 0.33238

Collected Steps per Second: 22,525.60182
Overall Steps per Second: 10,791.90931

Timestep Collection Time: 2.22058
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.27572
Total Iteration Time: 4.63495

Cumulative Model Updates: 177,980
Cumulative Timesteps: 1,484,236,430

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.71077
Value Function Loss: 0.02227

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.43499
Value Function Update Magnitude: 0.36646

Collected Steps per Second: 23,017.18568
Overall Steps per Second: 10,907.08751

Timestep Collection Time: 2.17333
Timestep Consumption Time: 2.41304
PPO Batch Consumption Time: 0.27548
Total Iteration Time: 4.58638

Cumulative Model Updates: 177,986
Cumulative Timesteps: 1,484,286,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1484286454...
Checkpoint 1484286454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.68289
Value Function Loss: 0.02506

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.40307
Value Function Update Magnitude: 0.34090

Collected Steps per Second: 22,971.33475
Overall Steps per Second: 10,798.50479

Timestep Collection Time: 2.17689
Timestep Consumption Time: 2.45394
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.63083

Cumulative Model Updates: 177,992
Cumulative Timesteps: 1,484,336,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.69170
Value Function Loss: 0.02381

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.36663
Value Function Update Magnitude: 0.28464

Collected Steps per Second: 23,090.98066
Overall Steps per Second: 10,727.47120

Timestep Collection Time: 2.16647
Timestep Consumption Time: 2.49688
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.66335

Cumulative Model Updates: 177,998
Cumulative Timesteps: 1,484,386,486

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1484386486...
Checkpoint 1484386486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.67482
Value Function Loss: 0.02324

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14141
Policy Update Magnitude: 0.35765
Value Function Update Magnitude: 0.36421

Collected Steps per Second: 23,081.67127
Overall Steps per Second: 10,792.48801

Timestep Collection Time: 2.16665
Timestep Consumption Time: 2.46712
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.63378

Cumulative Model Updates: 178,004
Cumulative Timesteps: 1,484,436,496

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.69066
Value Function Loss: 0.01971

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.37434
Value Function Update Magnitude: 0.43037

Collected Steps per Second: 22,983.46101
Overall Steps per Second: 10,724.15845

Timestep Collection Time: 2.17548
Timestep Consumption Time: 2.48689
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.66237

Cumulative Model Updates: 178,010
Cumulative Timesteps: 1,484,486,496

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1484486496...
Checkpoint 1484486496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 401,405.86417
Policy Entropy: 3.68314
Value Function Loss: 0.02234

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13521
Policy Update Magnitude: 0.38520
Value Function Update Magnitude: 0.42926

Collected Steps per Second: 22,995.06834
Overall Steps per Second: 10,743.91504

Timestep Collection Time: 2.17499
Timestep Consumption Time: 2.48011
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.65510

Cumulative Model Updates: 178,016
Cumulative Timesteps: 1,484,536,510

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,976.78629
Policy Entropy: 3.69324
Value Function Loss: 0.02409

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12827
Policy Update Magnitude: 0.40758
Value Function Update Magnitude: 0.41398

Collected Steps per Second: 23,018.28532
Overall Steps per Second: 10,818.68150

Timestep Collection Time: 2.17236
Timestep Consumption Time: 2.44965
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.62201

Cumulative Model Updates: 178,022
Cumulative Timesteps: 1,484,586,514

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1484586514...
Checkpoint 1484586514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 635,976.78629
Policy Entropy: 3.70582
Value Function Loss: 0.02371

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13849
Policy Update Magnitude: 0.40914
Value Function Update Magnitude: 0.41932

Collected Steps per Second: 22,882.69005
Overall Steps per Second: 10,715.99214

Timestep Collection Time: 2.18567
Timestep Consumption Time: 2.48156
PPO Batch Consumption Time: 0.29113
Total Iteration Time: 4.66723

Cumulative Model Updates: 178,028
Cumulative Timesteps: 1,484,636,528

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 635,976.78629
Policy Entropy: 3.69119
Value Function Loss: 0.02419

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.38056
Value Function Update Magnitude: 0.37363

Collected Steps per Second: 22,827.55203
Overall Steps per Second: 10,823.45421

Timestep Collection Time: 2.19095
Timestep Consumption Time: 2.42994
PPO Batch Consumption Time: 0.28040
Total Iteration Time: 4.62089

Cumulative Model Updates: 178,034
Cumulative Timesteps: 1,484,686,542

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1484686542...
Checkpoint 1484686542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422,871.09028
Policy Entropy: 3.70530
Value Function Loss: 0.02364

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.38140
Value Function Update Magnitude: 0.50221

Collected Steps per Second: 22,779.81519
Overall Steps per Second: 10,701.46642

Timestep Collection Time: 2.19554
Timestep Consumption Time: 2.47802
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.67357

Cumulative Model Updates: 178,040
Cumulative Timesteps: 1,484,736,556

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277,447.92735
Policy Entropy: 3.69989
Value Function Loss: 0.02729

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12917
Policy Update Magnitude: 0.40903
Value Function Update Magnitude: 0.55233

Collected Steps per Second: 22,431.62388
Overall Steps per Second: 10,840.37741

Timestep Collection Time: 2.23167
Timestep Consumption Time: 2.38625
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.61792

Cumulative Model Updates: 178,046
Cumulative Timesteps: 1,484,786,616

Timesteps Collected: 50,060
--------END ITERATION REPORT--------


Saving checkpoint 1484786616...
Checkpoint 1484786616 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277,447.92735
Policy Entropy: 3.70943
Value Function Loss: 0.02524

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.41394
Value Function Update Magnitude: 0.52346

Collected Steps per Second: 22,120.93008
Overall Steps per Second: 10,680.21170

Timestep Collection Time: 2.26112
Timestep Consumption Time: 2.42212
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.68324

Cumulative Model Updates: 178,052
Cumulative Timesteps: 1,484,836,634

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277,447.92735
Policy Entropy: 3.68586
Value Function Loss: 0.02673

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.41347
Value Function Update Magnitude: 0.46448

Collected Steps per Second: 21,883.57528
Overall Steps per Second: 10,456.06223

Timestep Collection Time: 2.28491
Timestep Consumption Time: 2.49720
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.78211

Cumulative Model Updates: 178,058
Cumulative Timesteps: 1,484,886,636

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1484886636...
Checkpoint 1484886636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,370.62430
Policy Entropy: 3.69844
Value Function Loss: 0.02493

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.42187
Value Function Update Magnitude: 0.44135

Collected Steps per Second: 22,684.80853
Overall Steps per Second: 10,697.41410

Timestep Collection Time: 2.20544
Timestep Consumption Time: 2.47139
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.67683

Cumulative Model Updates: 178,064
Cumulative Timesteps: 1,484,936,666

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,181.74787
Policy Entropy: 3.70122
Value Function Loss: 0.02779

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.41558
Value Function Update Magnitude: 0.48721

Collected Steps per Second: 22,727.73444
Overall Steps per Second: 10,802.38000

Timestep Collection Time: 2.20031
Timestep Consumption Time: 2.42904
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.62935

Cumulative Model Updates: 178,070
Cumulative Timesteps: 1,484,986,674

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1484986674...
Checkpoint 1484986674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,569.73452
Policy Entropy: 3.71369
Value Function Loss: 0.02710

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.42556
Value Function Update Magnitude: 0.47825

Collected Steps per Second: 23,018.31868
Overall Steps per Second: 10,752.42818

Timestep Collection Time: 2.17340
Timestep Consumption Time: 2.47932
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.65272

Cumulative Model Updates: 178,076
Cumulative Timesteps: 1,485,036,702

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316,555.63903
Policy Entropy: 3.70282
Value Function Loss: 0.02710

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13161
Policy Update Magnitude: 0.42954
Value Function Update Magnitude: 0.50722

Collected Steps per Second: 23,040.86951
Overall Steps per Second: 10,789.06756

Timestep Collection Time: 2.17032
Timestep Consumption Time: 2.46456
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.63488

Cumulative Model Updates: 178,082
Cumulative Timesteps: 1,485,086,708

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1485086708...
Checkpoint 1485086708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,395.99802
Policy Entropy: 3.71120
Value Function Loss: 0.02460

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.41270
Value Function Update Magnitude: 0.50959

Collected Steps per Second: 22,956.27537
Overall Steps per Second: 10,716.03573

Timestep Collection Time: 2.17814
Timestep Consumption Time: 2.48795
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.66609

Cumulative Model Updates: 178,088
Cumulative Timesteps: 1,485,136,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,528.98843
Policy Entropy: 3.69597
Value Function Loss: 0.02280

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.42134
Value Function Update Magnitude: 0.59878

Collected Steps per Second: 22,873.98615
Overall Steps per Second: 10,875.32947

Timestep Collection Time: 2.18729
Timestep Consumption Time: 2.41322
PPO Batch Consumption Time: 0.27639
Total Iteration Time: 4.60050

Cumulative Model Updates: 178,094
Cumulative Timesteps: 1,485,186,742

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1485186742...
Checkpoint 1485186742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,528.98843
Policy Entropy: 3.69355
Value Function Loss: 0.02115

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.41941
Value Function Update Magnitude: 0.71353

Collected Steps per Second: 22,890.28164
Overall Steps per Second: 10,728.59284

Timestep Collection Time: 2.18468
Timestep Consumption Time: 2.47651
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.66119

Cumulative Model Updates: 178,100
Cumulative Timesteps: 1,485,236,750

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,528.98843
Policy Entropy: 3.69082
Value Function Loss: 0.01987

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13335
Policy Update Magnitude: 0.43056
Value Function Update Magnitude: 0.64213

Collected Steps per Second: 22,989.90100
Overall Steps per Second: 10,792.12399

Timestep Collection Time: 2.17487
Timestep Consumption Time: 2.45814
PPO Batch Consumption Time: 0.28695
Total Iteration Time: 4.63301

Cumulative Model Updates: 178,106
Cumulative Timesteps: 1,485,286,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1485286750...
Checkpoint 1485286750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,528.98843
Policy Entropy: 3.69975
Value Function Loss: 0.02037

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12681
Policy Update Magnitude: 0.40182
Value Function Update Magnitude: 0.47233

Collected Steps per Second: 22,528.79458
Overall Steps per Second: 10,988.71086

Timestep Collection Time: 2.21991
Timestep Consumption Time: 2.33130
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.55122

Cumulative Model Updates: 178,112
Cumulative Timesteps: 1,485,336,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,528.98843
Policy Entropy: 3.68890
Value Function Loss: 0.01840

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.36914
Value Function Update Magnitude: 0.37129

Collected Steps per Second: 22,041.45843
Overall Steps per Second: 10,747.13496

Timestep Collection Time: 2.26909
Timestep Consumption Time: 2.38462
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.65371

Cumulative Model Updates: 178,118
Cumulative Timesteps: 1,485,386,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1485386776...
Checkpoint 1485386776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,815.41453
Policy Entropy: 3.67521
Value Function Loss: 0.02192

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.36350
Value Function Update Magnitude: 0.33807

Collected Steps per Second: 21,992.29281
Overall Steps per Second: 10,538.64990

Timestep Collection Time: 2.27452
Timestep Consumption Time: 2.47200
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.74653

Cumulative Model Updates: 178,124
Cumulative Timesteps: 1,485,436,798

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,865.38522
Policy Entropy: 3.68579
Value Function Loss: 0.02357

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13041
Policy Update Magnitude: 0.38235
Value Function Update Magnitude: 0.32756

Collected Steps per Second: 23,035.12345
Overall Steps per Second: 10,789.02535

Timestep Collection Time: 2.17129
Timestep Consumption Time: 2.46453
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.63582

Cumulative Model Updates: 178,130
Cumulative Timesteps: 1,485,486,814

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1485486814...
Checkpoint 1485486814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,865.38522
Policy Entropy: 3.67690
Value Function Loss: 0.02683

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.40127
Value Function Update Magnitude: 0.34425

Collected Steps per Second: 22,529.79959
Overall Steps per Second: 10,691.18768

Timestep Collection Time: 2.22159
Timestep Consumption Time: 2.46002
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.68161

Cumulative Model Updates: 178,136
Cumulative Timesteps: 1,485,536,866

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,865.38522
Policy Entropy: 3.68541
Value Function Loss: 0.02494

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13302
Policy Update Magnitude: 0.41582
Value Function Update Magnitude: 0.39144

Collected Steps per Second: 22,808.99057
Overall Steps per Second: 10,810.26152

Timestep Collection Time: 2.19299
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.62709

Cumulative Model Updates: 178,142
Cumulative Timesteps: 1,485,586,886

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1485586886...
Checkpoint 1485586886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,865.38522
Policy Entropy: 3.68039
Value Function Loss: 0.02111

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13085
Policy Update Magnitude: 0.38697
Value Function Update Magnitude: 0.48959

Collected Steps per Second: 22,850.12992
Overall Steps per Second: 10,675.78008

Timestep Collection Time: 2.18861
Timestep Consumption Time: 2.49583
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.68444

Cumulative Model Updates: 178,148
Cumulative Timesteps: 1,485,636,896

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,523.34507
Policy Entropy: 3.68983
Value Function Loss: 0.02236

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12277
Policy Update Magnitude: 0.39304
Value Function Update Magnitude: 0.41833

Collected Steps per Second: 22,932.87814
Overall Steps per Second: 10,820.54743

Timestep Collection Time: 2.18080
Timestep Consumption Time: 2.44115
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.62195

Cumulative Model Updates: 178,154
Cumulative Timesteps: 1,485,686,908

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1485686908...
Checkpoint 1485686908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,523.34507
Policy Entropy: 3.69487
Value Function Loss: 0.02234

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.42867
Value Function Update Magnitude: 0.35036

Collected Steps per Second: 22,936.91500
Overall Steps per Second: 10,758.08437

Timestep Collection Time: 2.18007
Timestep Consumption Time: 2.46797
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.64804

Cumulative Model Updates: 178,160
Cumulative Timesteps: 1,485,736,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,523.34507
Policy Entropy: 3.68566
Value Function Loss: 0.02247

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06828
Policy Update Magnitude: 0.56312
Value Function Update Magnitude: 0.41339

Collected Steps per Second: 23,014.60927
Overall Steps per Second: 10,875.15310

Timestep Collection Time: 2.17375
Timestep Consumption Time: 2.42646
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.60021

Cumulative Model Updates: 178,166
Cumulative Timesteps: 1,485,786,940

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1485786940...
Checkpoint 1485786940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,523.34507
Policy Entropy: 3.68389
Value Function Loss: 0.02123

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06981
Policy Update Magnitude: 0.57088
Value Function Update Magnitude: 0.45146

Collected Steps per Second: 22,180.59338
Overall Steps per Second: 10,705.19928

Timestep Collection Time: 2.25431
Timestep Consumption Time: 2.41650
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.67081

Cumulative Model Updates: 178,172
Cumulative Timesteps: 1,485,836,942

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,523.34507
Policy Entropy: 3.67673
Value Function Loss: 0.02141

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06078
Policy Update Magnitude: 0.57326
Value Function Update Magnitude: 0.40711

Collected Steps per Second: 22,319.75612
Overall Steps per Second: 10,871.40119

Timestep Collection Time: 2.24088
Timestep Consumption Time: 2.35981
PPO Batch Consumption Time: 0.28058
Total Iteration Time: 4.60069

Cumulative Model Updates: 178,178
Cumulative Timesteps: 1,485,886,958

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1485886958...
Checkpoint 1485886958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,301.60783
Policy Entropy: 3.68808
Value Function Loss: 0.03018

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08258
Policy Update Magnitude: 0.64076
Value Function Update Magnitude: 0.31263

Collected Steps per Second: 22,074.62168
Overall Steps per Second: 10,699.38360

Timestep Collection Time: 2.26604
Timestep Consumption Time: 2.40918
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.67522

Cumulative Model Updates: 178,184
Cumulative Timesteps: 1,485,936,980

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,301.60783
Policy Entropy: 3.70300
Value Function Loss: 0.02576

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.09894
Policy Update Magnitude: 0.63667
Value Function Update Magnitude: 0.33384

Collected Steps per Second: 22,425.81231
Overall Steps per Second: 10,785.28956

Timestep Collection Time: 2.23136
Timestep Consumption Time: 2.40830
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.63965

Cumulative Model Updates: 178,190
Cumulative Timesteps: 1,485,987,020

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1485987020...
Checkpoint 1485987020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,301.60783
Policy Entropy: 3.68386
Value Function Loss: 0.02629

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15680
Policy Update Magnitude: 0.55141
Value Function Update Magnitude: 0.47529

Collected Steps per Second: 22,829.21919
Overall Steps per Second: 10,718.97985

Timestep Collection Time: 2.19079
Timestep Consumption Time: 2.47514
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.66593

Cumulative Model Updates: 178,196
Cumulative Timesteps: 1,486,037,034

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,301.60783
Policy Entropy: 3.67506
Value Function Loss: 0.02676

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.17819
Policy Update Magnitude: 0.51299
Value Function Update Magnitude: 0.46777

Collected Steps per Second: 22,835.91499
Overall Steps per Second: 10,886.26036

Timestep Collection Time: 2.19076
Timestep Consumption Time: 2.40476
PPO Batch Consumption Time: 0.27696
Total Iteration Time: 4.59552

Cumulative Model Updates: 178,202
Cumulative Timesteps: 1,486,087,062

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1486087062...
Checkpoint 1486087062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,301.60783
Policy Entropy: 3.64813
Value Function Loss: 0.03566

Mean KL Divergence: 0.01390
SB3 Clip Fraction: 0.17370
Policy Update Magnitude: 0.47678
Value Function Update Magnitude: 0.36279

Collected Steps per Second: 22,411.62989
Overall Steps per Second: 10,651.98186

Timestep Collection Time: 2.23223
Timestep Consumption Time: 2.46436
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.69659

Cumulative Model Updates: 178,208
Cumulative Timesteps: 1,486,137,090

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,301.60783
Policy Entropy: 3.67044
Value Function Loss: 0.03718

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.16675
Policy Update Magnitude: 0.46714
Value Function Update Magnitude: 0.29079

Collected Steps per Second: 22,820.63443
Overall Steps per Second: 10,809.99419

Timestep Collection Time: 2.19109
Timestep Consumption Time: 2.43445
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.62553

Cumulative Model Updates: 178,214
Cumulative Timesteps: 1,486,187,092

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1486187092...
Checkpoint 1486187092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,301.60783
Policy Entropy: 3.66573
Value Function Loss: 0.03584

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16706
Policy Update Magnitude: 0.47166
Value Function Update Magnitude: 0.30830

Collected Steps per Second: 22,390.69043
Overall Steps per Second: 10,769.93172

Timestep Collection Time: 2.23450
Timestep Consumption Time: 2.41103
PPO Batch Consumption Time: 0.27610
Total Iteration Time: 4.64553

Cumulative Model Updates: 178,220
Cumulative Timesteps: 1,486,237,124

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 465,301.60783
Policy Entropy: 3.68522
Value Function Loss: 0.02765

Mean KL Divergence: 0.01204
SB3 Clip Fraction: 0.15713
Policy Update Magnitude: 0.47582
Value Function Update Magnitude: 0.32361

Collected Steps per Second: 23,052.36609
Overall Steps per Second: 10,914.82117

Timestep Collection Time: 2.16993
Timestep Consumption Time: 2.41301
PPO Batch Consumption Time: 0.27604
Total Iteration Time: 4.58294

Cumulative Model Updates: 178,226
Cumulative Timesteps: 1,486,287,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1486287146...
Checkpoint 1486287146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 465,301.60783
Policy Entropy: 3.68153
Value Function Loss: 0.02695

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15082
Policy Update Magnitude: 0.42286
Value Function Update Magnitude: 0.30714

Collected Steps per Second: 22,784.55489
Overall Steps per Second: 10,676.73717

Timestep Collection Time: 2.19500
Timestep Consumption Time: 2.48921
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68420

Cumulative Model Updates: 178,232
Cumulative Timesteps: 1,486,337,158

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 824,829.86931
Policy Entropy: 3.68171
Value Function Loss: 0.02947

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14320
Policy Update Magnitude: 0.40030
Value Function Update Magnitude: 0.30427

Collected Steps per Second: 23,069.60438
Overall Steps per Second: 10,818.68945

Timestep Collection Time: 2.16779
Timestep Consumption Time: 2.45477
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.62256

Cumulative Model Updates: 178,238
Cumulative Timesteps: 1,486,387,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1486387168...
Checkpoint 1486387168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,811.30788
Policy Entropy: 3.68449
Value Function Loss: 0.03266

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14600
Policy Update Magnitude: 0.43893
Value Function Update Magnitude: 0.34861

Collected Steps per Second: 22,735.21081
Overall Steps per Second: 10,635.68170

Timestep Collection Time: 2.19941
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.70153

Cumulative Model Updates: 178,244
Cumulative Timesteps: 1,486,437,172

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,811.30788
Policy Entropy: 3.68933
Value Function Loss: 0.03157

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.47843
Value Function Update Magnitude: 0.37255

Collected Steps per Second: 22,478.95912
Overall Steps per Second: 10,961.15070

Timestep Collection Time: 2.22519
Timestep Consumption Time: 2.33820
PPO Batch Consumption Time: 0.27643
Total Iteration Time: 4.56339

Cumulative Model Updates: 178,250
Cumulative Timesteps: 1,486,487,192

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1486487192...
Checkpoint 1486487192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,367.28708
Policy Entropy: 3.69588
Value Function Loss: 0.02760

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14370
Policy Update Magnitude: 0.43105
Value Function Update Magnitude: 0.37952

Collected Steps per Second: 22,107.14608
Overall Steps per Second: 10,723.30430

Timestep Collection Time: 2.26289
Timestep Consumption Time: 2.40228
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.66517

Cumulative Model Updates: 178,256
Cumulative Timesteps: 1,486,537,218

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,013.08048
Policy Entropy: 3.69872
Value Function Loss: 0.02696

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.43570
Value Function Update Magnitude: 0.51363

Collected Steps per Second: 22,452.46361
Overall Steps per Second: 10,800.85220

Timestep Collection Time: 2.22737
Timestep Consumption Time: 2.40282
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.63019

Cumulative Model Updates: 178,262
Cumulative Timesteps: 1,486,587,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1486587228...
Checkpoint 1486587228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,743.62201
Policy Entropy: 3.70602
Value Function Loss: 0.03037

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13762
Policy Update Magnitude: 0.45524
Value Function Update Magnitude: 0.56176

Collected Steps per Second: 22,000.75225
Overall Steps per Second: 10,618.69031

Timestep Collection Time: 2.27320
Timestep Consumption Time: 2.43661
PPO Batch Consumption Time: 0.28465
Total Iteration Time: 4.70981

Cumulative Model Updates: 178,268
Cumulative Timesteps: 1,486,637,240

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 649,858.83680
Policy Entropy: 3.71304
Value Function Loss: 0.03554

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.47526
Value Function Update Magnitude: 0.63300

Collected Steps per Second: 23,010.16790
Overall Steps per Second: 10,977.18954

Timestep Collection Time: 2.17382
Timestep Consumption Time: 2.38290
PPO Batch Consumption Time: 0.27546
Total Iteration Time: 4.55672

Cumulative Model Updates: 178,274
Cumulative Timesteps: 1,486,687,260

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1486687260...
Checkpoint 1486687260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279,749.95088
Policy Entropy: 3.69838
Value Function Loss: 0.03815

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.53068
Value Function Update Magnitude: 0.66058

Collected Steps per Second: 22,572.64300
Overall Steps per Second: 10,692.89118

Timestep Collection Time: 2.21525
Timestep Consumption Time: 2.46113
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.67638

Cumulative Model Updates: 178,280
Cumulative Timesteps: 1,486,737,264

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279,749.95088
Policy Entropy: 3.68394
Value Function Loss: 0.03508

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14234
Policy Update Magnitude: 0.50934
Value Function Update Magnitude: 0.60860

Collected Steps per Second: 23,350.13174
Overall Steps per Second: 10,802.07374

Timestep Collection Time: 2.14157
Timestep Consumption Time: 2.48772
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.62930

Cumulative Model Updates: 178,286
Cumulative Timesteps: 1,486,787,270

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1486787270...
Checkpoint 1486787270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323,760.79943
Policy Entropy: 3.66770
Value Function Loss: 0.02926

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.45599
Value Function Update Magnitude: 0.57947

Collected Steps per Second: 22,733.98151
Overall Steps per Second: 10,640.22955

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.50050
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.70046

Cumulative Model Updates: 178,292
Cumulative Timesteps: 1,486,837,284

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,265.45031
Policy Entropy: 3.66522
Value Function Loss: 0.02843

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14100
Policy Update Magnitude: 0.44241
Value Function Update Magnitude: 0.53670

Collected Steps per Second: 22,976.20753
Overall Steps per Second: 10,865.69543

Timestep Collection Time: 2.17712
Timestep Consumption Time: 2.42654
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.60366

Cumulative Model Updates: 178,298
Cumulative Timesteps: 1,486,887,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1486887306...
Checkpoint 1486887306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,284.00777
Policy Entropy: 3.67034
Value Function Loss: 0.02858

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.47098
Value Function Update Magnitude: 0.59739

Collected Steps per Second: 22,707.08362
Overall Steps per Second: 10,700.71585

Timestep Collection Time: 2.20213
Timestep Consumption Time: 2.47083
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.67296

Cumulative Model Updates: 178,304
Cumulative Timesteps: 1,486,937,310

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,284.00777
Policy Entropy: 3.68186
Value Function Loss: 0.02656

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.47037
Value Function Update Magnitude: 0.65376

Collected Steps per Second: 23,114.86968
Overall Steps per Second: 10,880.07713

Timestep Collection Time: 2.16328
Timestep Consumption Time: 2.43264
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.59592

Cumulative Model Updates: 178,310
Cumulative Timesteps: 1,486,987,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1486987314...
Checkpoint 1486987314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,284.00777
Policy Entropy: 3.66524
Value Function Loss: 0.02962

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.43535
Value Function Update Magnitude: 0.56604

Collected Steps per Second: 22,531.18485
Overall Steps per Second: 10,661.40295

Timestep Collection Time: 2.21915
Timestep Consumption Time: 2.47067
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.68981

Cumulative Model Updates: 178,316
Cumulative Timesteps: 1,487,037,314

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,284.00777
Policy Entropy: 3.68940
Value Function Loss: 0.02570

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12632
Policy Update Magnitude: 0.42051
Value Function Update Magnitude: 0.42280

Collected Steps per Second: 23,166.18630
Overall Steps per Second: 10,960.05083

Timestep Collection Time: 2.15849
Timestep Consumption Time: 2.40390
PPO Batch Consumption Time: 0.27524
Total Iteration Time: 4.56239

Cumulative Model Updates: 178,322
Cumulative Timesteps: 1,487,087,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1487087318...
Checkpoint 1487087318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,284.00777
Policy Entropy: 3.66785
Value Function Loss: 0.02430

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13480
Policy Update Magnitude: 0.39367
Value Function Update Magnitude: 0.34208

Collected Steps per Second: 23,102.64496
Overall Steps per Second: 10,736.06421

Timestep Collection Time: 2.16616
Timestep Consumption Time: 2.49514
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.66130

Cumulative Model Updates: 178,328
Cumulative Timesteps: 1,487,137,362

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 570,964.00715
Policy Entropy: 3.68997
Value Function Loss: 0.02032

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.35405
Value Function Update Magnitude: 0.41025

Collected Steps per Second: 23,091.37383
Overall Steps per Second: 10,730.71230

Timestep Collection Time: 2.16635
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.66176

Cumulative Model Updates: 178,334
Cumulative Timesteps: 1,487,187,386

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1487187386...
Checkpoint 1487187386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 322,413.76907
Policy Entropy: 3.68291
Value Function Loss: 0.02365

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13425
Policy Update Magnitude: 0.37717
Value Function Update Magnitude: 0.59705

Collected Steps per Second: 22,638.37865
Overall Steps per Second: 10,659.08892

Timestep Collection Time: 2.20935
Timestep Consumption Time: 2.48299
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.69233

Cumulative Model Updates: 178,340
Cumulative Timesteps: 1,487,237,402

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,211.08600
Policy Entropy: 3.72296
Value Function Loss: 0.02536

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12636
Policy Update Magnitude: 0.38541
Value Function Update Magnitude: 0.71149

Collected Steps per Second: 23,363.72645
Overall Steps per Second: 10,952.88741

Timestep Collection Time: 2.14101
Timestep Consumption Time: 2.42600
PPO Batch Consumption Time: 0.28018
Total Iteration Time: 4.56701

Cumulative Model Updates: 178,346
Cumulative Timesteps: 1,487,287,424

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1487287424...
Checkpoint 1487287424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,886.49874
Policy Entropy: 3.73573
Value Function Loss: 0.02765

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.40211
Value Function Update Magnitude: 0.77576

Collected Steps per Second: 23,055.24819
Overall Steps per Second: 10,799.49612

Timestep Collection Time: 2.16922
Timestep Consumption Time: 2.46173
PPO Batch Consumption Time: 0.28699
Total Iteration Time: 4.63096

Cumulative Model Updates: 178,352
Cumulative Timesteps: 1,487,337,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,108.72512
Policy Entropy: 3.73998
Value Function Loss: 0.02583

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.41225
Value Function Update Magnitude: 0.86072

Collected Steps per Second: 23,227.53187
Overall Steps per Second: 10,761.43639

Timestep Collection Time: 2.15331
Timestep Consumption Time: 2.49440
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.64771

Cumulative Model Updates: 178,358
Cumulative Timesteps: 1,487,387,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1487387452...
Checkpoint 1487387452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 389.75400
Policy Entropy: 3.72440
Value Function Loss: 0.02344

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11562
Policy Update Magnitude: 0.41143
Value Function Update Magnitude: 0.83694

Collected Steps per Second: 22,950.00549
Overall Steps per Second: 10,769.56381

Timestep Collection Time: 2.17900
Timestep Consumption Time: 2.46446
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.64346

Cumulative Model Updates: 178,364
Cumulative Timesteps: 1,487,437,460

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.31837
Policy Entropy: 3.71012
Value Function Loss: 0.02111

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13869
Policy Update Magnitude: 0.39182
Value Function Update Magnitude: 0.71981

Collected Steps per Second: 22,535.58292
Overall Steps per Second: 10,730.70151

Timestep Collection Time: 2.21925
Timestep Consumption Time: 2.44140
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.66065

Cumulative Model Updates: 178,370
Cumulative Timesteps: 1,487,487,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1487487472...
Checkpoint 1487487472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278.31837
Policy Entropy: 3.69043
Value Function Loss: 0.02308

Mean KL Divergence: 0.02331
SB3 Clip Fraction: 0.27825
Policy Update Magnitude: 0.37677
Value Function Update Magnitude: 0.60996

Collected Steps per Second: 22,049.85143
Overall Steps per Second: 10,685.79133

Timestep Collection Time: 2.26822
Timestep Consumption Time: 2.41220
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.68042

Cumulative Model Updates: 178,376
Cumulative Timesteps: 1,487,537,486

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 844,144.29062
Policy Entropy: 3.64688
Value Function Loss: 0.04810

Mean KL Divergence: 0.01971
SB3 Clip Fraction: 0.23297
Policy Update Magnitude: 0.42005
Value Function Update Magnitude: 0.60502

Collected Steps per Second: 22,371.30462
Overall Steps per Second: 10,780.47505

Timestep Collection Time: 2.23572
Timestep Consumption Time: 2.40378
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.63950

Cumulative Model Updates: 178,382
Cumulative Timesteps: 1,487,587,502

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1487587502...
Checkpoint 1487587502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267,746.62690
Policy Entropy: 3.65937
Value Function Loss: 0.08850

Mean KL Divergence: 0.02026
SB3 Clip Fraction: 0.22052
Policy Update Magnitude: 0.52456
Value Function Update Magnitude: 0.52849

Collected Steps per Second: 21,971.39053
Overall Steps per Second: 10,730.74221

Timestep Collection Time: 2.27587
Timestep Consumption Time: 2.38401
PPO Batch Consumption Time: 0.28613
Total Iteration Time: 4.65988

Cumulative Model Updates: 178,388
Cumulative Timesteps: 1,487,637,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,230.23789
Policy Entropy: 3.71513
Value Function Loss: 0.13004

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.20429
Policy Update Magnitude: 0.64661
Value Function Update Magnitude: 0.48520

Collected Steps per Second: 22,415.72395
Overall Steps per Second: 10,954.21677

Timestep Collection Time: 2.23183
Timestep Consumption Time: 2.33518
PPO Batch Consumption Time: 0.27605
Total Iteration Time: 4.56701

Cumulative Model Updates: 178,394
Cumulative Timesteps: 1,487,687,534

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1487687534...
Checkpoint 1487687534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,633.48964
Policy Entropy: 3.78566
Value Function Loss: 0.13213

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.16410
Policy Update Magnitude: 0.74337
Value Function Update Magnitude: 0.53229

Collected Steps per Second: 22,012.84125
Overall Steps per Second: 10,705.99655

Timestep Collection Time: 2.27258
Timestep Consumption Time: 2.40013
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.67271

Cumulative Model Updates: 178,400
Cumulative Timesteps: 1,487,737,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,520.25431
Policy Entropy: 3.86260
Value Function Loss: 0.13057

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.81064
Value Function Update Magnitude: 0.61919

Collected Steps per Second: 22,855.33677
Overall Steps per Second: 10,778.69362

Timestep Collection Time: 2.18942
Timestep Consumption Time: 2.45307
PPO Batch Consumption Time: 0.28359
Total Iteration Time: 4.64249

Cumulative Model Updates: 178,406
Cumulative Timesteps: 1,487,787,600

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1487787600...
Checkpoint 1487787600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,400.34575
Policy Entropy: 3.94104
Value Function Loss: 0.09670

Mean KL Divergence: 0.01313
SB3 Clip Fraction: 0.13933
Policy Update Magnitude: 0.92216
Value Function Update Magnitude: 0.56412

Collected Steps per Second: 22,459.46905
Overall Steps per Second: 10,622.96167

Timestep Collection Time: 2.22659
Timestep Consumption Time: 2.48095
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.70754

Cumulative Model Updates: 178,412
Cumulative Timesteps: 1,487,837,608

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 363.79402
Policy Entropy: 4.02873
Value Function Loss: 0.07643

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.11936
Policy Update Magnitude: 1.05295
Value Function Update Magnitude: 0.68906

Collected Steps per Second: 22,990.86309
Overall Steps per Second: 10,974.91832

Timestep Collection Time: 2.17565
Timestep Consumption Time: 2.38202
PPO Batch Consumption Time: 0.27570
Total Iteration Time: 4.55766

Cumulative Model Updates: 178,418
Cumulative Timesteps: 1,487,887,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1487887628...
Checkpoint 1487887628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,942.57531
Policy Entropy: 4.04421
Value Function Loss: 0.06920

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.11980
Policy Update Magnitude: 1.15180
Value Function Update Magnitude: 0.82919

Collected Steps per Second: 22,763.34667
Overall Steps per Second: 11,034.07609

Timestep Collection Time: 2.19713
Timestep Consumption Time: 2.33556
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.53269

Cumulative Model Updates: 178,424
Cumulative Timesteps: 1,487,937,642

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147.79531
Policy Entropy: 4.05818
Value Function Loss: 0.06433

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 1.23249
Value Function Update Magnitude: 0.76068

Collected Steps per Second: 23,243.20626
Overall Steps per Second: 10,938.18230

Timestep Collection Time: 2.15151
Timestep Consumption Time: 2.42036
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.57187

Cumulative Model Updates: 178,430
Cumulative Timesteps: 1,487,987,650

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1487987650...
Checkpoint 1487987650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,025.55211
Policy Entropy: 4.04885
Value Function Loss: 0.06013

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.10978
Policy Update Magnitude: 1.24596
Value Function Update Magnitude: 0.85783

Collected Steps per Second: 22,618.31487
Overall Steps per Second: 10,617.36047

Timestep Collection Time: 2.21086
Timestep Consumption Time: 2.49897
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.70983

Cumulative Model Updates: 178,436
Cumulative Timesteps: 1,488,037,656

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704.74390
Policy Entropy: 4.08339
Value Function Loss: 0.05478

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.08988
Policy Update Magnitude: 1.26989
Value Function Update Magnitude: 0.82141

Collected Steps per Second: 22,903.35191
Overall Steps per Second: 10,878.66485

Timestep Collection Time: 2.18431
Timestep Consumption Time: 2.41442
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.59873

Cumulative Model Updates: 178,442
Cumulative Timesteps: 1,488,087,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1488087684...
Checkpoint 1488087684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,644.50535
Policy Entropy: 4.04220
Value Function Loss: 0.05720

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.08673
Policy Update Magnitude: 1.25102
Value Function Update Magnitude: 0.79868

Collected Steps per Second: 22,595.81447
Overall Steps per Second: 10,701.68252

Timestep Collection Time: 2.21360
Timestep Consumption Time: 2.46025
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.67384

Cumulative Model Updates: 178,448
Cumulative Timesteps: 1,488,137,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,760.59870
Policy Entropy: 4.02184
Value Function Loss: 0.06452

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07399
Policy Update Magnitude: 1.18280
Value Function Update Magnitude: 0.75819

Collected Steps per Second: 22,699.09911
Overall Steps per Second: 10,904.98105

Timestep Collection Time: 2.20282
Timestep Consumption Time: 2.38243
PPO Batch Consumption Time: 0.28441
Total Iteration Time: 4.58524

Cumulative Model Updates: 178,454
Cumulative Timesteps: 1,488,187,704

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1488187704...
Checkpoint 1488187704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 294.91957
Policy Entropy: 3.97740
Value Function Loss: 0.06820

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07308
Policy Update Magnitude: 1.13115
Value Function Update Magnitude: 0.70636

Collected Steps per Second: 22,117.96054
Overall Steps per Second: 10,691.10194

Timestep Collection Time: 2.26151
Timestep Consumption Time: 2.41715
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.67866

Cumulative Model Updates: 178,460
Cumulative Timesteps: 1,488,237,724

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,454.30971
Policy Entropy: 3.92561
Value Function Loss: 0.06876

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07124
Policy Update Magnitude: 1.01883
Value Function Update Magnitude: 0.79545

Collected Steps per Second: 22,601.24620
Overall Steps per Second: 10,885.43480

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.38198
PPO Batch Consumption Time: 0.28402
Total Iteration Time: 4.59513

Cumulative Model Updates: 178,466
Cumulative Timesteps: 1,488,287,744

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1488287744...
Checkpoint 1488287744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,124.88346
Policy Entropy: 3.87847
Value Function Loss: 0.06450

Mean KL Divergence: 0.00715
SB3 Clip Fraction: 0.08999
Policy Update Magnitude: 0.90429
Value Function Update Magnitude: 0.74425

Collected Steps per Second: 22,338.11300
Overall Steps per Second: 10,822.39677

Timestep Collection Time: 2.23877
Timestep Consumption Time: 2.38220
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.62097

Cumulative Model Updates: 178,472
Cumulative Timesteps: 1,488,337,754

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154.48759
Policy Entropy: 3.82605
Value Function Loss: 0.05693

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.74654
Value Function Update Magnitude: 0.61112

Collected Steps per Second: 22,709.90146
Overall Steps per Second: 10,845.12006

Timestep Collection Time: 2.20283
Timestep Consumption Time: 2.40994
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.61277

Cumulative Model Updates: 178,478
Cumulative Timesteps: 1,488,387,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1488387780...
Checkpoint 1488387780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 85.81377
Policy Entropy: 3.77895
Value Function Loss: 0.04722

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.62302
Value Function Update Magnitude: 0.53423

Collected Steps per Second: 22,126.33436
Overall Steps per Second: 10,863.66176

Timestep Collection Time: 2.25993
Timestep Consumption Time: 2.34294
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.60287

Cumulative Model Updates: 178,484
Cumulative Timesteps: 1,488,437,784

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,836.13545
Policy Entropy: 3.73221
Value Function Loss: 0.03948

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.16101
Policy Update Magnitude: 0.57311
Value Function Update Magnitude: 0.49472

Collected Steps per Second: 22,278.57471
Overall Steps per Second: 10,749.07533

Timestep Collection Time: 2.24575
Timestep Consumption Time: 2.40879
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.65454

Cumulative Model Updates: 178,490
Cumulative Timesteps: 1,488,487,816

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1488487816...
Checkpoint 1488487816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,836.13545
Policy Entropy: 3.67905
Value Function Loss: 0.04060

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.18843
Policy Update Magnitude: 0.49737
Value Function Update Magnitude: 0.46609

Collected Steps per Second: 22,015.96979
Overall Steps per Second: 10,554.15162

Timestep Collection Time: 2.27171
Timestep Consumption Time: 2.46708
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.73880

Cumulative Model Updates: 178,496
Cumulative Timesteps: 1,488,537,830

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,942.64174
Policy Entropy: 3.70274
Value Function Loss: 0.04564

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13136
Policy Update Magnitude: 0.52310
Value Function Update Magnitude: 0.51573

Collected Steps per Second: 22,670.57240
Overall Steps per Second: 10,768.62005

Timestep Collection Time: 2.20674
Timestep Consumption Time: 2.43898
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.64572

Cumulative Model Updates: 178,502
Cumulative Timesteps: 1,488,587,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1488587858...
Checkpoint 1488587858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,004.41827
Policy Entropy: 3.73812
Value Function Loss: 0.04634

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15692
Policy Update Magnitude: 0.54435
Value Function Update Magnitude: 0.41881

Collected Steps per Second: 22,453.28796
Overall Steps per Second: 10,695.82210

Timestep Collection Time: 2.22907
Timestep Consumption Time: 2.45033
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.67940

Cumulative Model Updates: 178,508
Cumulative Timesteps: 1,488,637,908

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,824.31245
Policy Entropy: 3.80451
Value Function Loss: 0.04517

Mean KL Divergence: 0.01942
SB3 Clip Fraction: 0.22317
Policy Update Magnitude: 0.49747
Value Function Update Magnitude: 0.37598

Collected Steps per Second: 23,232.63968
Overall Steps per Second: 10,951.62407

Timestep Collection Time: 2.15335
Timestep Consumption Time: 2.41474
PPO Batch Consumption Time: 0.27567
Total Iteration Time: 4.56809

Cumulative Model Updates: 178,514
Cumulative Timesteps: 1,488,687,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1488687936...
Checkpoint 1488687936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,814.74180
Policy Entropy: 3.85771
Value Function Loss: 0.06173

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.17790
Policy Update Magnitude: 0.49786
Value Function Update Magnitude: 0.48273

Collected Steps per Second: 22,576.26770
Overall Steps per Second: 10,633.25329

Timestep Collection Time: 2.21516
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.70317

Cumulative Model Updates: 178,520
Cumulative Timesteps: 1,488,737,946

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67.20841
Policy Entropy: 3.86917
Value Function Loss: 0.07797

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13375
Policy Update Magnitude: 0.59986
Value Function Update Magnitude: 0.51874

Collected Steps per Second: 23,069.55506
Overall Steps per Second: 10,902.34101

Timestep Collection Time: 2.16831
Timestep Consumption Time: 2.41988
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.58819

Cumulative Model Updates: 178,526
Cumulative Timesteps: 1,488,787,968

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1488787968...
Checkpoint 1488787968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,808.93359
Policy Entropy: 3.87334
Value Function Loss: 0.07866

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13648
Policy Update Magnitude: 0.60289
Value Function Update Magnitude: 0.54871

Collected Steps per Second: 22,582.04044
Overall Steps per Second: 10,614.10066

Timestep Collection Time: 2.21415
Timestep Consumption Time: 2.49657
PPO Batch Consumption Time: 0.29240
Total Iteration Time: 4.71071

Cumulative Model Updates: 178,532
Cumulative Timesteps: 1,488,837,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,906.29825
Policy Entropy: 3.84583
Value Function Loss: 0.06180

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.55844
Value Function Update Magnitude: 0.61650

Collected Steps per Second: 22,610.52943
Overall Steps per Second: 10,830.26618

Timestep Collection Time: 2.21136
Timestep Consumption Time: 2.40533
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.61669

Cumulative Model Updates: 178,538
Cumulative Timesteps: 1,488,887,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1488887968...
Checkpoint 1488887968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,363.60384
Policy Entropy: 3.80289
Value Function Loss: 0.05015

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.51964
Value Function Update Magnitude: 0.65235

Collected Steps per Second: 22,847.15382
Overall Steps per Second: 10,682.68968

Timestep Collection Time: 2.18846
Timestep Consumption Time: 2.49201
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.68047

Cumulative Model Updates: 178,544
Cumulative Timesteps: 1,488,937,968

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,198.30175
Policy Entropy: 3.77555
Value Function Loss: 0.03826

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.45425
Value Function Update Magnitude: 0.63997

Collected Steps per Second: 23,362.94277
Overall Steps per Second: 10,893.36932

Timestep Collection Time: 2.14083
Timestep Consumption Time: 2.45059
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.59142

Cumulative Model Updates: 178,550
Cumulative Timesteps: 1,488,987,984

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1488987984...
Checkpoint 1488987984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,164.42425
Policy Entropy: 3.75663
Value Function Loss: 0.03158

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13979
Policy Update Magnitude: 0.42300
Value Function Update Magnitude: 0.66092

Collected Steps per Second: 22,760.78059
Overall Steps per Second: 10,655.33301

Timestep Collection Time: 2.19799
Timestep Consumption Time: 2.49712
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.69511

Cumulative Model Updates: 178,556
Cumulative Timesteps: 1,489,038,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,418.23887
Policy Entropy: 3.73177
Value Function Loss: 0.02509

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13744
Policy Update Magnitude: 0.40616
Value Function Update Magnitude: 0.61174

Collected Steps per Second: 22,999.44488
Overall Steps per Second: 10,885.53998

Timestep Collection Time: 2.17484
Timestep Consumption Time: 2.42025
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.59509

Cumulative Model Updates: 178,562
Cumulative Timesteps: 1,489,088,032

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1489088032...
Checkpoint 1489088032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,321.87648
Policy Entropy: 3.73325
Value Function Loss: 0.02173

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13219
Policy Update Magnitude: 0.34902
Value Function Update Magnitude: 0.44909

Collected Steps per Second: 22,702.92756
Overall Steps per Second: 10,672.20874

Timestep Collection Time: 2.20298
Timestep Consumption Time: 2.48340
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.68638

Cumulative Model Updates: 178,568
Cumulative Timesteps: 1,489,138,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,567.16184
Policy Entropy: 3.69754
Value Function Loss: 0.02323

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.28961
Value Function Update Magnitude: 0.41608

Collected Steps per Second: 23,119.31808
Overall Steps per Second: 10,913.20820

Timestep Collection Time: 2.16330
Timestep Consumption Time: 2.41959
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.58289

Cumulative Model Updates: 178,574
Cumulative Timesteps: 1,489,188,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1489188060...
Checkpoint 1489188060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,719.19535
Policy Entropy: 3.72547
Value Function Loss: 0.02791

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12722
Policy Update Magnitude: 0.31013
Value Function Update Magnitude: 0.52502

Collected Steps per Second: 22,637.69027
Overall Steps per Second: 10,656.44706

Timestep Collection Time: 2.21109
Timestep Consumption Time: 2.48597
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.69706

Cumulative Model Updates: 178,580
Cumulative Timesteps: 1,489,238,114

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,579.15013
Policy Entropy: 3.70824
Value Function Loss: 0.03550

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.36714
Value Function Update Magnitude: 0.54245

Collected Steps per Second: 23,283.73470
Overall Steps per Second: 10,908.33135

Timestep Collection Time: 2.14802
Timestep Consumption Time: 2.43691
PPO Batch Consumption Time: 0.28116
Total Iteration Time: 4.58494

Cumulative Model Updates: 178,586
Cumulative Timesteps: 1,489,288,128

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1489288128...
Checkpoint 1489288128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,421.15331
Policy Entropy: 3.72272
Value Function Loss: 0.04080

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12176
Policy Update Magnitude: 0.41284
Value Function Update Magnitude: 0.49846

Collected Steps per Second: 22,655.98851
Overall Steps per Second: 10,656.48345

Timestep Collection Time: 2.20701
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.69217

Cumulative Model Updates: 178,592
Cumulative Timesteps: 1,489,338,130

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,374.35120
Policy Entropy: 3.69539
Value Function Loss: 0.04302

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.43602
Value Function Update Magnitude: 0.47213

Collected Steps per Second: 22,548.20207
Overall Steps per Second: 10,854.95338

Timestep Collection Time: 2.21756
Timestep Consumption Time: 2.38882
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.60638

Cumulative Model Updates: 178,598
Cumulative Timesteps: 1,489,388,132

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1489388132...
Checkpoint 1489388132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,482.47424
Policy Entropy: 3.69939
Value Function Loss: 0.03934

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12804
Policy Update Magnitude: 0.44999
Value Function Update Magnitude: 0.45520

Collected Steps per Second: 22,131.91289
Overall Steps per Second: 10,664.31919

Timestep Collection Time: 2.25954
Timestep Consumption Time: 2.42974
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68928

Cumulative Model Updates: 178,604
Cumulative Timesteps: 1,489,438,140

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,465.84425
Policy Entropy: 3.68472
Value Function Loss: 0.03816

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13370
Policy Update Magnitude: 0.41655
Value Function Update Magnitude: 0.43813

Collected Steps per Second: 22,651.33172
Overall Steps per Second: 10,920.09306

Timestep Collection Time: 2.20799
Timestep Consumption Time: 2.37200
PPO Batch Consumption Time: 0.28244
Total Iteration Time: 4.58000

Cumulative Model Updates: 178,610
Cumulative Timesteps: 1,489,488,154

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1489488154...
Checkpoint 1489488154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,355.77847
Policy Entropy: 3.71491
Value Function Loss: 0.03202

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.40922
Value Function Update Magnitude: 0.46682

Collected Steps per Second: 21,954.16380
Overall Steps per Second: 10,601.09205

Timestep Collection Time: 2.27775
Timestep Consumption Time: 2.43932
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.71706

Cumulative Model Updates: 178,616
Cumulative Timesteps: 1,489,538,160

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322.38087
Policy Entropy: 3.72712
Value Function Loss: 0.03598

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12224
Policy Update Magnitude: 0.40395
Value Function Update Magnitude: 0.48484

Collected Steps per Second: 23,420.30339
Overall Steps per Second: 10,933.35653

Timestep Collection Time: 2.13610
Timestep Consumption Time: 2.43963
PPO Batch Consumption Time: 0.28538
Total Iteration Time: 4.57572

Cumulative Model Updates: 178,622
Cumulative Timesteps: 1,489,588,188

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1489588188...
Checkpoint 1489588188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,316.10871
Policy Entropy: 3.73680
Value Function Loss: 0.03723

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12116
Policy Update Magnitude: 0.44489
Value Function Update Magnitude: 0.54808

Collected Steps per Second: 22,740.32771
Overall Steps per Second: 10,757.17665

Timestep Collection Time: 2.19926
Timestep Consumption Time: 2.44991
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.64918

Cumulative Model Updates: 178,628
Cumulative Timesteps: 1,489,638,200

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,824.89278
Policy Entropy: 3.71451
Value Function Loss: 0.04121

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.43157
Value Function Update Magnitude: 0.54070

Collected Steps per Second: 23,045.71732
Overall Steps per Second: 10,786.66288

Timestep Collection Time: 2.17073
Timestep Consumption Time: 2.46704
PPO Batch Consumption Time: 0.29041
Total Iteration Time: 4.63776

Cumulative Model Updates: 178,634
Cumulative Timesteps: 1,489,688,226

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1489688226...
Checkpoint 1489688226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,172.16430
Policy Entropy: 3.69581
Value Function Loss: 0.03612

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.39518
Value Function Update Magnitude: 0.45662

Collected Steps per Second: 23,020.34896
Overall Steps per Second: 10,737.20453

Timestep Collection Time: 2.17243
Timestep Consumption Time: 2.48521
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.65764

Cumulative Model Updates: 178,640
Cumulative Timesteps: 1,489,738,236

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,260.06274
Policy Entropy: 3.67480
Value Function Loss: 0.03593

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13906
Policy Update Magnitude: 0.37960
Value Function Update Magnitude: 0.42117

Collected Steps per Second: 22,954.15536
Overall Steps per Second: 10,807.35017

Timestep Collection Time: 2.17843
Timestep Consumption Time: 2.44842
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.62685

Cumulative Model Updates: 178,646
Cumulative Timesteps: 1,489,788,240

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1489788240...
Checkpoint 1489788240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,376.83176
Policy Entropy: 3.65623
Value Function Loss: 0.03395

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.39041
Value Function Update Magnitude: 0.49445

Collected Steps per Second: 22,648.80659
Overall Steps per Second: 10,626.71219

Timestep Collection Time: 2.20877
Timestep Consumption Time: 2.49880
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.70757

Cumulative Model Updates: 178,652
Cumulative Timesteps: 1,489,838,266

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,464.37544
Policy Entropy: 3.66407
Value Function Loss: 0.03270

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13143
Policy Update Magnitude: 0.37425
Value Function Update Magnitude: 0.47233

Collected Steps per Second: 23,026.95120
Overall Steps per Second: 10,896.89958

Timestep Collection Time: 2.17224
Timestep Consumption Time: 2.41806
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.59030

Cumulative Model Updates: 178,658
Cumulative Timesteps: 1,489,888,286

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1489888286...
Checkpoint 1489888286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,464.37544
Policy Entropy: 3.65962
Value Function Loss: 0.02722

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13680
Policy Update Magnitude: 0.36245
Value Function Update Magnitude: 0.43717

Collected Steps per Second: 22,619.68078
Overall Steps per Second: 10,692.64226

Timestep Collection Time: 2.21170
Timestep Consumption Time: 2.46703
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.67873

Cumulative Model Updates: 178,664
Cumulative Timesteps: 1,489,938,314

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,464.37544
Policy Entropy: 3.65556
Value Function Loss: 0.02561

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13909
Policy Update Magnitude: 0.34799
Value Function Update Magnitude: 0.46799

Collected Steps per Second: 23,043.02364
Overall Steps per Second: 10,929.73229

Timestep Collection Time: 2.17029
Timestep Consumption Time: 2.40530
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.57559

Cumulative Model Updates: 178,670
Cumulative Timesteps: 1,489,988,324

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1489988324...
Checkpoint 1489988324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253,504.34921
Policy Entropy: 3.65663
Value Function Loss: 0.02656

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.33978
Value Function Update Magnitude: 0.49750

Collected Steps per Second: 22,593.47101
Overall Steps per Second: 10,620.55618

Timestep Collection Time: 2.21383
Timestep Consumption Time: 2.49572
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70955

Cumulative Model Updates: 178,676
Cumulative Timesteps: 1,490,038,342

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,398.23375
Policy Entropy: 3.66600
Value Function Loss: 0.02606

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.14491
Policy Update Magnitude: 0.36597
Value Function Update Magnitude: 0.52411

Collected Steps per Second: 23,173.82672
Overall Steps per Second: 10,954.10231

Timestep Collection Time: 2.15890
Timestep Consumption Time: 2.40834
PPO Batch Consumption Time: 0.27631
Total Iteration Time: 4.56724

Cumulative Model Updates: 178,682
Cumulative Timesteps: 1,490,088,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1490088372...
Checkpoint 1490088372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,398.23375
Policy Entropy: 3.67084
Value Function Loss: 0.02550

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13856
Policy Update Magnitude: 0.36983
Value Function Update Magnitude: 0.53043

Collected Steps per Second: 22,664.30203
Overall Steps per Second: 10,676.35879

Timestep Collection Time: 2.20691
Timestep Consumption Time: 2.47802
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.68493

Cumulative Model Updates: 178,688
Cumulative Timesteps: 1,490,138,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,599.63298
Policy Entropy: 3.67200
Value Function Loss: 0.02648

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.38677
Value Function Update Magnitude: 0.54161

Collected Steps per Second: 22,547.43767
Overall Steps per Second: 10,839.09207

Timestep Collection Time: 2.21861
Timestep Consumption Time: 2.39654
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.61515

Cumulative Model Updates: 178,694
Cumulative Timesteps: 1,490,188,414

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1490188414...
Checkpoint 1490188414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,599.63298
Policy Entropy: 3.67978
Value Function Loss: 0.02316

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13594
Policy Update Magnitude: 0.38162
Value Function Update Magnitude: 0.46578

Collected Steps per Second: 21,783.64252
Overall Steps per Second: 10,625.54977

Timestep Collection Time: 2.29649
Timestep Consumption Time: 2.41159
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.70809

Cumulative Model Updates: 178,700
Cumulative Timesteps: 1,490,238,440

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,219.67847
Policy Entropy: 3.67808
Value Function Loss: 0.02275

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.36742
Value Function Update Magnitude: 0.43194

Collected Steps per Second: 22,469.04140
Overall Steps per Second: 10,721.31849

Timestep Collection Time: 2.22626
Timestep Consumption Time: 2.43939
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.66566

Cumulative Model Updates: 178,706
Cumulative Timesteps: 1,490,288,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1490288462...
Checkpoint 1490288462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,307.89338
Policy Entropy: 3.68333
Value Function Loss: 0.02095

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.32412
Value Function Update Magnitude: 0.39447

Collected Steps per Second: 22,641.29182
Overall Steps per Second: 10,885.02121

Timestep Collection Time: 2.20924
Timestep Consumption Time: 2.38607
PPO Batch Consumption Time: 0.27592
Total Iteration Time: 4.59531

Cumulative Model Updates: 178,712
Cumulative Timesteps: 1,490,338,482

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,010.09538
Policy Entropy: 3.66533
Value Function Loss: 0.02369

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.31484
Value Function Update Magnitude: 0.45960

Collected Steps per Second: 23,053.17241
Overall Steps per Second: 10,876.47217

Timestep Collection Time: 2.16907
Timestep Consumption Time: 2.42837
PPO Batch Consumption Time: 0.28144
Total Iteration Time: 4.59745

Cumulative Model Updates: 178,718
Cumulative Timesteps: 1,490,388,486

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1490388486...
Checkpoint 1490388486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,010.09538
Policy Entropy: 3.67848
Value Function Loss: 0.02022

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.33694
Value Function Update Magnitude: 0.42475

Collected Steps per Second: 22,761.51539
Overall Steps per Second: 10,643.73322

Timestep Collection Time: 2.19695
Timestep Consumption Time: 2.50121
PPO Batch Consumption Time: 0.29304
Total Iteration Time: 4.69816

Cumulative Model Updates: 178,724
Cumulative Timesteps: 1,490,438,492

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,010.09538
Policy Entropy: 3.66588
Value Function Loss: 0.01863

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.31712
Value Function Update Magnitude: 0.38920

Collected Steps per Second: 23,279.02445
Overall Steps per Second: 10,991.05314

Timestep Collection Time: 2.14889
Timestep Consumption Time: 2.40245
PPO Batch Consumption Time: 0.27571
Total Iteration Time: 4.55134

Cumulative Model Updates: 178,730
Cumulative Timesteps: 1,490,488,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1490488516...
Checkpoint 1490488516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,260.02592
Policy Entropy: 3.67713
Value Function Loss: 0.01861

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12420
Policy Update Magnitude: 0.30123
Value Function Update Magnitude: 0.41372

Collected Steps per Second: 22,818.91397
Overall Steps per Second: 10,746.00373

Timestep Collection Time: 2.19125
Timestep Consumption Time: 2.46183
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.65308

Cumulative Model Updates: 178,736
Cumulative Timesteps: 1,490,538,518

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,752.65948
Policy Entropy: 3.67548
Value Function Loss: 0.02218

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12346
Policy Update Magnitude: 0.31089
Value Function Update Magnitude: 0.43693

Collected Steps per Second: 23,190.69716
Overall Steps per Second: 10,751.77137

Timestep Collection Time: 2.15655
Timestep Consumption Time: 2.49496
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.65151

Cumulative Model Updates: 178,742
Cumulative Timesteps: 1,490,588,530

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1490588530...
Checkpoint 1490588530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,164.26668
Policy Entropy: 3.69889
Value Function Loss: 0.02198

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12517
Policy Update Magnitude: 0.31686
Value Function Update Magnitude: 0.45910

Collected Steps per Second: 22,732.66811
Overall Steps per Second: 10,672.14958

Timestep Collection Time: 2.20053
Timestep Consumption Time: 2.48681
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.68734

Cumulative Model Updates: 178,748
Cumulative Timesteps: 1,490,638,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,670.16954
Policy Entropy: 3.67927
Value Function Loss: 0.02344

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12524
Policy Update Magnitude: 0.36114
Value Function Update Magnitude: 0.47067

Collected Steps per Second: 23,287.02909
Overall Steps per Second: 10,864.16896

Timestep Collection Time: 2.14841
Timestep Consumption Time: 2.45664
PPO Batch Consumption Time: 0.28407
Total Iteration Time: 4.60505

Cumulative Model Updates: 178,754
Cumulative Timesteps: 1,490,688,584

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1490688584...
Checkpoint 1490688584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,670.16954
Policy Entropy: 3.67716
Value Function Loss: 0.02409

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.38850
Value Function Update Magnitude: 0.46063

Collected Steps per Second: 21,795.45970
Overall Steps per Second: 10,640.57925

Timestep Collection Time: 2.29543
Timestep Consumption Time: 2.40638
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.70181

Cumulative Model Updates: 178,760
Cumulative Timesteps: 1,490,738,614

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,335.06846
Policy Entropy: 3.65745
Value Function Loss: 0.02813

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12666
Policy Update Magnitude: 0.44679
Value Function Update Magnitude: 0.52807

Collected Steps per Second: 22,541.01834
Overall Steps per Second: 10,887.24824

Timestep Collection Time: 2.21818
Timestep Consumption Time: 2.37435
PPO Batch Consumption Time: 0.28213
Total Iteration Time: 4.59253

Cumulative Model Updates: 178,766
Cumulative Timesteps: 1,490,788,614

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1490788614...
Checkpoint 1490788614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,335.06846
Policy Entropy: 3.64918
Value Function Loss: 0.03129

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.50422
Value Function Update Magnitude: 0.60154

Collected Steps per Second: 21,879.43393
Overall Steps per Second: 10,698.29402

Timestep Collection Time: 2.28635
Timestep Consumption Time: 2.38954
PPO Batch Consumption Time: 0.27611
Total Iteration Time: 4.67589

Cumulative Model Updates: 178,772
Cumulative Timesteps: 1,490,838,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,335.06846
Policy Entropy: 3.65250
Value Function Loss: 0.03139

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.49932
Value Function Update Magnitude: 0.51800

Collected Steps per Second: 23,206.49329
Overall Steps per Second: 10,881.98026

Timestep Collection Time: 2.15500
Timestep Consumption Time: 2.44067
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.59567

Cumulative Model Updates: 178,778
Cumulative Timesteps: 1,490,888,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1490888648...
Checkpoint 1490888648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,335.06846
Policy Entropy: 3.65740
Value Function Loss: 0.02567

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14554
Policy Update Magnitude: 0.45813
Value Function Update Magnitude: 0.54701

Collected Steps per Second: 22,591.87607
Overall Steps per Second: 10,653.24113

Timestep Collection Time: 2.21336
Timestep Consumption Time: 2.48042
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.69378

Cumulative Model Updates: 178,784
Cumulative Timesteps: 1,490,938,652

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,335.06846
Policy Entropy: 3.66629
Value Function Loss: 0.02212

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.14287
Policy Update Magnitude: 0.39920
Value Function Update Magnitude: 0.38370

Collected Steps per Second: 23,434.83651
Overall Steps per Second: 10,857.24018

Timestep Collection Time: 2.13477
Timestep Consumption Time: 2.47303
PPO Batch Consumption Time: 0.28505
Total Iteration Time: 4.60780

Cumulative Model Updates: 178,790
Cumulative Timesteps: 1,490,988,680

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1490988680...
Checkpoint 1490988680 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144,071.27217
Policy Entropy: 3.68371
Value Function Loss: 0.01986

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.37648
Value Function Update Magnitude: 0.32685

Collected Steps per Second: 22,521.14233
Overall Steps per Second: 10,675.80460

Timestep Collection Time: 2.22094
Timestep Consumption Time: 2.46424
PPO Batch Consumption Time: 0.28665
Total Iteration Time: 4.68517

Cumulative Model Updates: 178,796
Cumulative Timesteps: 1,491,038,698

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,247.06710
Policy Entropy: 3.68411
Value Function Loss: 0.02267

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.36546
Value Function Update Magnitude: 0.35550

Collected Steps per Second: 23,203.45597
Overall Steps per Second: 10,956.69214

Timestep Collection Time: 2.15511
Timestep Consumption Time: 2.40886
PPO Batch Consumption Time: 0.27574
Total Iteration Time: 4.56397

Cumulative Model Updates: 178,802
Cumulative Timesteps: 1,491,088,704

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1491088704...
Checkpoint 1491088704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221,789.63699
Policy Entropy: 3.68643
Value Function Loss: 0.02523

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.40668
Value Function Update Magnitude: 0.37867

Collected Steps per Second: 23,057.53541
Overall Steps per Second: 10,825.30576

Timestep Collection Time: 2.16918
Timestep Consumption Time: 2.45110
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.62029

Cumulative Model Updates: 178,808
Cumulative Timesteps: 1,491,138,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,660.48700
Policy Entropy: 3.67794
Value Function Loss: 0.02751

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15796
Policy Update Magnitude: 0.42527
Value Function Update Magnitude: 0.39508

Collected Steps per Second: 22,933.50229
Overall Steps per Second: 10,643.78585

Timestep Collection Time: 2.18126
Timestep Consumption Time: 2.51857
PPO Batch Consumption Time: 0.29324
Total Iteration Time: 4.69983

Cumulative Model Updates: 178,814
Cumulative Timesteps: 1,491,188,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1491188744...
Checkpoint 1491188744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,860.55762
Policy Entropy: 3.69596
Value Function Loss: 0.02479

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13887
Policy Update Magnitude: 0.46110
Value Function Update Magnitude: 0.40414

Collected Steps per Second: 22,706.73716
Overall Steps per Second: 10,629.72512

Timestep Collection Time: 2.20217
Timestep Consumption Time: 2.50200
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.70417

Cumulative Model Updates: 178,820
Cumulative Timesteps: 1,491,238,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,642.60185
Policy Entropy: 3.70049
Value Function Loss: 0.02243

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.17155
Policy Update Magnitude: 0.42409
Value Function Update Magnitude: 0.40043

Collected Steps per Second: 22,274.06196
Overall Steps per Second: 10,892.16664

Timestep Collection Time: 2.24611
Timestep Consumption Time: 2.34710
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.59321

Cumulative Model Updates: 178,826
Cumulative Timesteps: 1,491,288,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1491288778...
Checkpoint 1491288778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,642.60185
Policy Entropy: 3.71514
Value Function Loss: 0.01784

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.42560
Value Function Update Magnitude: 0.41400

Collected Steps per Second: 22,091.46785
Overall Steps per Second: 10,673.09328

Timestep Collection Time: 2.26404
Timestep Consumption Time: 2.42214
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.68618

Cumulative Model Updates: 178,832
Cumulative Timesteps: 1,491,338,794

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,642.60185
Policy Entropy: 3.67176
Value Function Loss: 0.02332

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10969
Policy Update Magnitude: 0.43396
Value Function Update Magnitude: 0.42998

Collected Steps per Second: 22,371.58584
Overall Steps per Second: 10,791.16066

Timestep Collection Time: 2.23525
Timestep Consumption Time: 2.39873
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.63398

Cumulative Model Updates: 178,838
Cumulative Timesteps: 1,491,388,800

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1491388800...
Checkpoint 1491388800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,642.60185
Policy Entropy: 3.65523
Value Function Loss: 0.02648

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.11622
Policy Update Magnitude: 0.53085
Value Function Update Magnitude: 0.45835

Collected Steps per Second: 22,493.71386
Overall Steps per Second: 10,811.57184

Timestep Collection Time: 2.22382
Timestep Consumption Time: 2.40289
PPO Batch Consumption Time: 0.27585
Total Iteration Time: 4.62671

Cumulative Model Updates: 178,844
Cumulative Timesteps: 1,491,438,822

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,642.60185
Policy Entropy: 3.67297
Value Function Loss: 0.02568

Mean KL Divergence: 0.01877
SB3 Clip Fraction: 0.22297
Policy Update Magnitude: 0.46717
Value Function Update Magnitude: 0.43956

Collected Steps per Second: 22,706.09601
Overall Steps per Second: 10,918.96420

Timestep Collection Time: 2.20214
Timestep Consumption Time: 2.37723
PPO Batch Consumption Time: 0.27532
Total Iteration Time: 4.57937

Cumulative Model Updates: 178,850
Cumulative Timesteps: 1,491,488,824

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1491488824...
Checkpoint 1491488824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,642.60185
Policy Entropy: 3.68400
Value Function Loss: 0.02295

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.17343
Policy Update Magnitude: 0.41386
Value Function Update Magnitude: 0.41065

Collected Steps per Second: 22,953.45640
Overall Steps per Second: 10,735.18203

Timestep Collection Time: 2.17893
Timestep Consumption Time: 2.47996
PPO Batch Consumption Time: 0.28761
Total Iteration Time: 4.65889

Cumulative Model Updates: 178,856
Cumulative Timesteps: 1,491,538,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,642.60185
Policy Entropy: 3.66092
Value Function Loss: 0.02432

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.17938
Policy Update Magnitude: 0.40562
Value Function Update Magnitude: 0.41645

Collected Steps per Second: 23,524.95325
Overall Steps per Second: 10,816.67216

Timestep Collection Time: 2.12574
Timestep Consumption Time: 2.49749
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.62323

Cumulative Model Updates: 178,862
Cumulative Timesteps: 1,491,588,846

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1491588846...
Checkpoint 1491588846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,642.60185
Policy Entropy: 3.62800
Value Function Loss: 0.03372

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14607
Policy Update Magnitude: 0.45539
Value Function Update Magnitude: 0.33471

Collected Steps per Second: 22,430.04026
Overall Steps per Second: 10,585.64107

Timestep Collection Time: 2.23094
Timestep Consumption Time: 2.49622
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.72716

Cumulative Model Updates: 178,868
Cumulative Timesteps: 1,491,638,886

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134,841.87901
Policy Entropy: 3.65286
Value Function Loss: 0.04097

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 0.50015
Value Function Update Magnitude: 0.34424

Collected Steps per Second: 22,772.90789
Overall Steps per Second: 10,836.84144

Timestep Collection Time: 2.19682
Timestep Consumption Time: 2.41965
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.61647

Cumulative Model Updates: 178,874
Cumulative Timesteps: 1,491,688,914

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1491688914...
Checkpoint 1491688914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,288.28795
Policy Entropy: 3.66326
Value Function Loss: 0.04126

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.55329
Value Function Update Magnitude: 0.40151

Collected Steps per Second: 22,872.87835
Overall Steps per Second: 10,675.69278

Timestep Collection Time: 2.18600
Timestep Consumption Time: 2.49754
PPO Batch Consumption Time: 0.29316
Total Iteration Time: 4.68354

Cumulative Model Updates: 178,880
Cumulative Timesteps: 1,491,738,914

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,288.28795
Policy Entropy: 3.69545
Value Function Loss: 0.03340

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13149
Policy Update Magnitude: 0.55713
Value Function Update Magnitude: 0.49587

Collected Steps per Second: 23,251.83017
Overall Steps per Second: 10,915.80606

Timestep Collection Time: 2.15174
Timestep Consumption Time: 2.43170
PPO Batch Consumption Time: 0.28013
Total Iteration Time: 4.58345

Cumulative Model Updates: 178,886
Cumulative Timesteps: 1,491,788,946

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1491788946...
Checkpoint 1491788946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,288.28795
Policy Entropy: 3.68497
Value Function Loss: 0.02465

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13662
Policy Update Magnitude: 0.48958
Value Function Update Magnitude: 0.47324

Collected Steps per Second: 22,088.91890
Overall Steps per Second: 10,635.76360

Timestep Collection Time: 2.26376
Timestep Consumption Time: 2.43774
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.70150

Cumulative Model Updates: 178,892
Cumulative Timesteps: 1,491,838,950

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,288.28795
Policy Entropy: 3.68259
Value Function Loss: 0.02001

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.42018
Value Function Update Magnitude: 0.41138

Collected Steps per Second: 22,273.72998
Overall Steps per Second: 10,910.61808

Timestep Collection Time: 2.24480
Timestep Consumption Time: 2.33789
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.58269

Cumulative Model Updates: 178,898
Cumulative Timesteps: 1,491,888,950

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1491888950...
Checkpoint 1491888950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,288.28795
Policy Entropy: 3.66682
Value Function Loss: 0.01908

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.13945
Policy Update Magnitude: 0.39257
Value Function Update Magnitude: 0.36229

Collected Steps per Second: 22,226.25970
Overall Steps per Second: 10,663.90289

Timestep Collection Time: 2.25058
Timestep Consumption Time: 2.44020
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.69078

Cumulative Model Updates: 178,904
Cumulative Timesteps: 1,491,938,972

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,288.28795
Policy Entropy: 3.67891
Value Function Loss: 0.02222

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.40452
Value Function Update Magnitude: 0.43844

Collected Steps per Second: 23,111.12442
Overall Steps per Second: 10,897.42671

Timestep Collection Time: 2.16415
Timestep Consumption Time: 2.42555
PPO Batch Consumption Time: 0.28159
Total Iteration Time: 4.58971

Cumulative Model Updates: 178,910
Cumulative Timesteps: 1,491,988,988

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1491988988...
Checkpoint 1491988988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 387,744.31234
Policy Entropy: 3.66608
Value Function Loss: 0.02755

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13794
Policy Update Magnitude: 0.44007
Value Function Update Magnitude: 0.43635

Collected Steps per Second: 22,782.92209
Overall Steps per Second: 10,727.89865

Timestep Collection Time: 2.19463
Timestep Consumption Time: 2.46612
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.66074

Cumulative Model Updates: 178,916
Cumulative Timesteps: 1,492,038,988

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 135,232.74735
Policy Entropy: 3.68425
Value Function Loss: 0.02785

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.11802
Policy Update Magnitude: 0.50262
Value Function Update Magnitude: 0.48740

Collected Steps per Second: 22,815.60947
Overall Steps per Second: 10,846.43022

Timestep Collection Time: 2.19280
Timestep Consumption Time: 2.41978
PPO Batch Consumption Time: 0.27630
Total Iteration Time: 4.61258

Cumulative Model Updates: 178,922
Cumulative Timesteps: 1,492,089,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1492089018...
Checkpoint 1492089018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 135,232.74735
Policy Entropy: 3.67677
Value Function Loss: 0.02958

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.11574
Policy Update Magnitude: 0.45827
Value Function Update Magnitude: 0.48057

Collected Steps per Second: 22,501.62024
Overall Steps per Second: 10,609.02447

Timestep Collection Time: 2.22313
Timestep Consumption Time: 2.49210
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.71523

Cumulative Model Updates: 178,928
Cumulative Timesteps: 1,492,139,042

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.68250
Value Function Loss: 0.02840

Mean KL Divergence: 0.00549
SB3 Clip Fraction: 0.06267
Policy Update Magnitude: 0.57008
Value Function Update Magnitude: 0.45598

Collected Steps per Second: 22,636.78689
Overall Steps per Second: 10,784.08910

Timestep Collection Time: 2.20924
Timestep Consumption Time: 2.42815
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.63739

Cumulative Model Updates: 178,934
Cumulative Timesteps: 1,492,189,052

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1492189052...
Checkpoint 1492189052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.66503
Value Function Loss: 0.02797

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07319
Policy Update Magnitude: 0.62510
Value Function Update Magnitude: 0.41609

Collected Steps per Second: 22,724.59443
Overall Steps per Second: 10,744.75701

Timestep Collection Time: 2.20035
Timestep Consumption Time: 2.45327
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.65362

Cumulative Model Updates: 178,940
Cumulative Timesteps: 1,492,239,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.66895
Value Function Loss: 0.02319

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07242
Policy Update Magnitude: 0.58854
Value Function Update Magnitude: 0.43060

Collected Steps per Second: 23,168.54127
Overall Steps per Second: 10,904.24006

Timestep Collection Time: 2.15827
Timestep Consumption Time: 2.42747
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.58574

Cumulative Model Updates: 178,946
Cumulative Timesteps: 1,492,289,058

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1492289058...
Checkpoint 1492289058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.68771
Value Function Loss: 0.01830

Mean KL Divergence: 0.00594
SB3 Clip Fraction: 0.06917
Policy Update Magnitude: 0.53775
Value Function Update Magnitude: 0.38134

Collected Steps per Second: 22,904.73969
Overall Steps per Second: 10,719.27230

Timestep Collection Time: 2.18488
Timestep Consumption Time: 2.48373
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.66860

Cumulative Model Updates: 178,952
Cumulative Timesteps: 1,492,339,102

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.69415
Value Function Loss: 0.01623

Mean KL Divergence: 0.00463
SB3 Clip Fraction: 0.04990
Policy Update Magnitude: 0.47061
Value Function Update Magnitude: 0.29611

Collected Steps per Second: 22,520.23499
Overall Steps per Second: 10,816.97286

Timestep Collection Time: 2.22023
Timestep Consumption Time: 2.40214
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.62237

Cumulative Model Updates: 178,958
Cumulative Timesteps: 1,492,389,102

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1492389102...
Checkpoint 1492389102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.69129
Value Function Loss: 0.01559

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05988
Policy Update Magnitude: 0.42813
Value Function Update Magnitude: 0.24604

Collected Steps per Second: 22,119.83311
Overall Steps per Second: 10,667.49915

Timestep Collection Time: 2.26159
Timestep Consumption Time: 2.42798
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68957

Cumulative Model Updates: 178,964
Cumulative Timesteps: 1,492,439,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.68604
Value Function Loss: 0.01622

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07270
Policy Update Magnitude: 0.41008
Value Function Update Magnitude: 0.24871

Collected Steps per Second: 22,264.92401
Overall Steps per Second: 10,628.42937

Timestep Collection Time: 2.24622
Timestep Consumption Time: 2.45927
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.70549

Cumulative Model Updates: 178,970
Cumulative Timesteps: 1,492,489,140

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1492489140...
Checkpoint 1492489140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.69249
Value Function Loss: 0.01526

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08231
Policy Update Magnitude: 0.41750
Value Function Update Magnitude: 0.39000

Collected Steps per Second: 23,094.94419
Overall Steps per Second: 10,931.54490

Timestep Collection Time: 2.16541
Timestep Consumption Time: 2.40942
PPO Batch Consumption Time: 0.28156
Total Iteration Time: 4.57483

Cumulative Model Updates: 178,976
Cumulative Timesteps: 1,492,539,150

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.70831
Value Function Loss: 0.01416

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.14020
Policy Update Magnitude: 0.37924
Value Function Update Magnitude: 0.47257

Collected Steps per Second: 22,478.34973
Overall Steps per Second: 10,805.36263

Timestep Collection Time: 2.22534
Timestep Consumption Time: 2.40403
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.62937

Cumulative Model Updates: 178,982
Cumulative Timesteps: 1,492,589,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1492589172...
Checkpoint 1492589172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.70300
Value Function Loss: 0.01451

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.09058
Policy Update Magnitude: 0.37208
Value Function Update Magnitude: 0.44382

Collected Steps per Second: 22,846.50030
Overall Steps per Second: 10,704.15003

Timestep Collection Time: 2.18852
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.67109

Cumulative Model Updates: 178,988
Cumulative Timesteps: 1,492,639,172

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.70416
Value Function Loss: 0.01516

Mean KL Divergence: 0.00765
SB3 Clip Fraction: 0.09715
Policy Update Magnitude: 0.38318
Value Function Update Magnitude: 0.44166

Collected Steps per Second: 23,040.41441
Overall Steps per Second: 10,904.31026

Timestep Collection Time: 2.17105
Timestep Consumption Time: 2.41631
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.58736

Cumulative Model Updates: 178,994
Cumulative Timesteps: 1,492,689,194

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1492689194...
Checkpoint 1492689194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.68023
Value Function Loss: 0.01652

Mean KL Divergence: 0.01522
SB3 Clip Fraction: 0.19640
Policy Update Magnitude: 0.34928
Value Function Update Magnitude: 0.42385

Collected Steps per Second: 22,809.78210
Overall Steps per Second: 10,669.99961

Timestep Collection Time: 2.19292
Timestep Consumption Time: 2.49499
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.68791

Cumulative Model Updates: 179,000
Cumulative Timesteps: 1,492,739,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.69107
Value Function Loss: 0.01681

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.21889
Policy Update Magnitude: 0.37652
Value Function Update Magnitude: 0.45944

Collected Steps per Second: 22,824.90425
Overall Steps per Second: 10,828.35533

Timestep Collection Time: 2.19173
Timestep Consumption Time: 2.42818
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.61991

Cumulative Model Updates: 179,006
Cumulative Timesteps: 1,492,789,240

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1492789240...
Checkpoint 1492789240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.68048
Value Function Loss: 0.01710

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.16857
Policy Update Magnitude: 0.40348
Value Function Update Magnitude: 0.44691

Collected Steps per Second: 22,511.67635
Overall Steps per Second: 10,774.10970

Timestep Collection Time: 2.22231
Timestep Consumption Time: 2.42104
PPO Batch Consumption Time: 0.27553
Total Iteration Time: 4.64335

Cumulative Model Updates: 179,012
Cumulative Timesteps: 1,492,839,268

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.69044
Value Function Loss: 0.01600

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.42620
Value Function Update Magnitude: 0.36891

Collected Steps per Second: 22,631.49359
Overall Steps per Second: 10,779.83344

Timestep Collection Time: 2.21046
Timestep Consumption Time: 2.43024
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.64070

Cumulative Model Updates: 179,018
Cumulative Timesteps: 1,492,889,294

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1492889294...
Checkpoint 1492889294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.69245
Value Function Loss: 0.01524

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.06958
Policy Update Magnitude: 0.42248
Value Function Update Magnitude: 0.26851

Collected Steps per Second: 22,638.22732
Overall Steps per Second: 10,727.80752

Timestep Collection Time: 2.20980
Timestep Consumption Time: 2.45341
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.66321

Cumulative Model Updates: 179,024
Cumulative Timesteps: 1,492,939,320

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,045.70738
Policy Entropy: 3.69456
Value Function Loss: 0.01451

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06399
Policy Update Magnitude: 0.39542
Value Function Update Magnitude: 0.21030

Collected Steps per Second: 23,041.48739
Overall Steps per Second: 10,906.07202

Timestep Collection Time: 2.17130
Timestep Consumption Time: 2.41605
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.58735

Cumulative Model Updates: 179,030
Cumulative Timesteps: 1,492,989,350

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1492989350...
Checkpoint 1492989350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210,627.12319
Policy Entropy: 3.68444
Value Function Loss: 0.01829

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06705
Policy Update Magnitude: 0.45853
Value Function Update Magnitude: 0.30365

Collected Steps per Second: 22,428.45633
Overall Steps per Second: 10,822.16242

Timestep Collection Time: 2.23029
Timestep Consumption Time: 2.39189
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.62218

Cumulative Model Updates: 179,036
Cumulative Timesteps: 1,493,039,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,627.12319
Policy Entropy: 3.68978
Value Function Loss: 0.01733

Mean KL Divergence: 0.00629
SB3 Clip Fraction: 0.07617
Policy Update Magnitude: 0.52356
Value Function Update Magnitude: 0.43734

Collected Steps per Second: 22,661.70437
Overall Steps per Second: 10,827.23330

Timestep Collection Time: 2.20769
Timestep Consumption Time: 2.41307
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.62076

Cumulative Model Updates: 179,042
Cumulative Timesteps: 1,493,089,402

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1493089402...
Checkpoint 1493089402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210,627.12319
Policy Entropy: 3.69249
Value Function Loss: 0.01851

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.52358
Value Function Update Magnitude: 0.41285

Collected Steps per Second: 22,203.51974
Overall Steps per Second: 10,618.11529

Timestep Collection Time: 2.25235
Timestep Consumption Time: 2.45753
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.70988

Cumulative Model Updates: 179,048
Cumulative Timesteps: 1,493,139,412

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 210,627.12319
Policy Entropy: 3.68467
Value Function Loss: 0.01808

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06647
Policy Update Magnitude: 0.52038
Value Function Update Magnitude: 0.33717

Collected Steps per Second: 22,964.67929
Overall Steps per Second: 10,806.98439

Timestep Collection Time: 2.17743
Timestep Consumption Time: 2.44958
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.62701

Cumulative Model Updates: 179,054
Cumulative Timesteps: 1,493,189,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1493189416...
Checkpoint 1493189416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210,627.12319
Policy Entropy: 3.67661
Value Function Loss: 0.01686

Mean KL Divergence: 0.01084
SB3 Clip Fraction: 0.13961
Policy Update Magnitude: 0.47085
Value Function Update Magnitude: 0.32517

Collected Steps per Second: 22,896.50860
Overall Steps per Second: 10,777.31846

Timestep Collection Time: 2.18435
Timestep Consumption Time: 2.45632
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.64067

Cumulative Model Updates: 179,060
Cumulative Timesteps: 1,493,239,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,023,947.57034
Policy Entropy: 3.66029
Value Function Loss: 0.03607

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.17320
Policy Update Magnitude: 0.44315
Value Function Update Magnitude: 0.47796

Collected Steps per Second: 22,842.86491
Overall Steps per Second: 10,804.49559

Timestep Collection Time: 2.18983
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.28057
Total Iteration Time: 4.62974

Cumulative Model Updates: 179,066
Cumulative Timesteps: 1,493,289,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1493289452...
Checkpoint 1493289452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312,106.84678
Policy Entropy: 3.67814
Value Function Loss: 0.04668

Mean KL Divergence: 0.01362
SB3 Clip Fraction: 0.17011
Policy Update Magnitude: 0.54208
Value Function Update Magnitude: 0.65066

Collected Steps per Second: 22,706.58333
Overall Steps per Second: 10,662.30465

Timestep Collection Time: 2.20271
Timestep Consumption Time: 2.48821
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.69092

Cumulative Model Updates: 179,072
Cumulative Timesteps: 1,493,339,468

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 409,246.49546
Policy Entropy: 3.65446
Value Function Loss: 0.06119

Mean KL Divergence: 0.01397
SB3 Clip Fraction: 0.16494
Policy Update Magnitude: 0.59835
Value Function Update Magnitude: 0.55136

Collected Steps per Second: 22,809.69758
Overall Steps per Second: 10,815.36537

Timestep Collection Time: 2.19354
Timestep Consumption Time: 2.43266
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.62620

Cumulative Model Updates: 179,078
Cumulative Timesteps: 1,493,389,502

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1493389502...
Checkpoint 1493389502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237,027.72124
Policy Entropy: 3.70557
Value Function Loss: 0.04067

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13730
Policy Update Magnitude: 0.57625
Value Function Update Magnitude: 0.50544

Collected Steps per Second: 22,576.36811
Overall Steps per Second: 10,645.38373

Timestep Collection Time: 2.21701
Timestep Consumption Time: 2.48475
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.70176

Cumulative Model Updates: 179,084
Cumulative Timesteps: 1,493,439,554

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 229,600.28270
Policy Entropy: 3.67990
Value Function Loss: 0.03657

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.14459
Policy Update Magnitude: 0.51658
Value Function Update Magnitude: 0.47639

Collected Steps per Second: 22,728.41592
Overall Steps per Second: 10,692.94952

Timestep Collection Time: 2.20077
Timestep Consumption Time: 2.47708
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.67785

Cumulative Model Updates: 179,090
Cumulative Timesteps: 1,493,489,574

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1493489574...
Checkpoint 1493489574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,881.36091
Policy Entropy: 3.71224
Value Function Loss: 0.02730

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.48499
Value Function Update Magnitude: 0.50139

Collected Steps per Second: 22,893.27943
Overall Steps per Second: 10,870.83086

Timestep Collection Time: 2.18422
Timestep Consumption Time: 2.41561
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.59983

Cumulative Model Updates: 179,096
Cumulative Timesteps: 1,493,539,578

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,529.42325
Policy Entropy: 3.70241
Value Function Loss: 0.03201

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14693
Policy Update Magnitude: 0.45625
Value Function Update Magnitude: 0.50211

Collected Steps per Second: 23,107.91205
Overall Steps per Second: 10,922.18365

Timestep Collection Time: 2.16402
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.57839

Cumulative Model Updates: 179,102
Cumulative Timesteps: 1,493,589,584

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1493589584...
Checkpoint 1493589584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,020.63478
Policy Entropy: 3.72127
Value Function Loss: 0.03069

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.44285
Value Function Update Magnitude: 0.52429

Collected Steps per Second: 22,848.50201
Overall Steps per Second: 10,655.19023

Timestep Collection Time: 2.18894
Timestep Consumption Time: 2.50492
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.69386

Cumulative Model Updates: 179,108
Cumulative Timesteps: 1,493,639,598

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,540.26592
Policy Entropy: 3.70457
Value Function Loss: 0.03395

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.44170
Value Function Update Magnitude: 0.54650

Collected Steps per Second: 22,397.35144
Overall Steps per Second: 10,910.43057

Timestep Collection Time: 2.23276
Timestep Consumption Time: 2.35074
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.58350

Cumulative Model Updates: 179,114
Cumulative Timesteps: 1,493,689,606

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1493689606...
Checkpoint 1493689606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232,241.23358
Policy Entropy: 3.69720
Value Function Loss: 0.03732

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.43419
Value Function Update Magnitude: 0.53044

Collected Steps per Second: 22,026.43560
Overall Steps per Second: 10,636.13193

Timestep Collection Time: 2.27045
Timestep Consumption Time: 2.43144
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.70190

Cumulative Model Updates: 179,120
Cumulative Timesteps: 1,493,739,616

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,235.96548
Policy Entropy: 3.69572
Value Function Loss: 0.03700

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13328
Policy Update Magnitude: 0.49949
Value Function Update Magnitude: 0.52849

Collected Steps per Second: 22,210.25381
Overall Steps per Second: 10,873.27752

Timestep Collection Time: 2.25148
Timestep Consumption Time: 2.34750
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.59898

Cumulative Model Updates: 179,126
Cumulative Timesteps: 1,493,789,622

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1493789622...
Checkpoint 1493789622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226,917.03393
Policy Entropy: 3.67557
Value Function Loss: 0.03661

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14009
Policy Update Magnitude: 0.52297
Value Function Update Magnitude: 0.59543

Collected Steps per Second: 22,295.50549
Overall Steps per Second: 10,672.21241

Timestep Collection Time: 2.24350
Timestep Consumption Time: 2.44344
PPO Batch Consumption Time: 0.28557
Total Iteration Time: 4.68694

Cumulative Model Updates: 179,132
Cumulative Timesteps: 1,493,839,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,037.19804
Policy Entropy: 3.68679
Value Function Loss: 0.02990

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13672
Policy Update Magnitude: 0.53446
Value Function Update Magnitude: 0.70370

Collected Steps per Second: 22,547.44360
Overall Steps per Second: 10,856.36829

Timestep Collection Time: 2.21781
Timestep Consumption Time: 2.38833
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.60614

Cumulative Model Updates: 179,138
Cumulative Timesteps: 1,493,889,648

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1493889648...
Checkpoint 1493889648 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,306.58861
Policy Entropy: 3.68146
Value Function Loss: 0.02854

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14622
Policy Update Magnitude: 0.49302
Value Function Update Magnitude: 0.79047

Collected Steps per Second: 22,664.03418
Overall Steps per Second: 10,702.60585

Timestep Collection Time: 2.20658
Timestep Consumption Time: 2.46611
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.67269

Cumulative Model Updates: 179,144
Cumulative Timesteps: 1,493,939,658

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,082.19771
Policy Entropy: 3.69644
Value Function Loss: 0.03000

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.49090
Value Function Update Magnitude: 0.75613

Collected Steps per Second: 22,512.54602
Overall Steps per Second: 10,614.93823

Timestep Collection Time: 2.22098
Timestep Consumption Time: 2.48936
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.71034

Cumulative Model Updates: 179,150
Cumulative Timesteps: 1,493,989,658

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1493989658...
Checkpoint 1493989658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,000.46212
Policy Entropy: 3.69023
Value Function Loss: 0.03452

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13315
Policy Update Magnitude: 0.49786
Value Function Update Magnitude: 0.60808

Collected Steps per Second: 22,855.85169
Overall Steps per Second: 10,854.66993

Timestep Collection Time: 2.18806
Timestep Consumption Time: 2.41917
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.60723

Cumulative Model Updates: 179,156
Cumulative Timesteps: 1,494,039,668

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,180.93901
Policy Entropy: 3.69562
Value Function Loss: 0.03235

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.43628
Value Function Update Magnitude: 0.51617

Collected Steps per Second: 22,813.90116
Overall Steps per Second: 10,909.51066

Timestep Collection Time: 2.19270
Timestep Consumption Time: 2.39266
PPO Batch Consumption Time: 0.27690
Total Iteration Time: 4.58536

Cumulative Model Updates: 179,162
Cumulative Timesteps: 1,494,089,692

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1494089692...
Checkpoint 1494089692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,984.08204
Policy Entropy: 3.69294
Value Function Loss: 0.02801

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13060
Policy Update Magnitude: 0.38525
Value Function Update Magnitude: 0.52881

Collected Steps per Second: 22,640.37601
Overall Steps per Second: 10,716.09101

Timestep Collection Time: 2.20871
Timestep Consumption Time: 2.45773
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.66644

Cumulative Model Updates: 179,168
Cumulative Timesteps: 1,494,139,698

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,984.08204
Policy Entropy: 3.69020
Value Function Loss: 0.02123

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.34426
Value Function Update Magnitude: 0.53001

Collected Steps per Second: 22,909.77499
Overall Steps per Second: 10,868.83995

Timestep Collection Time: 2.18352
Timestep Consumption Time: 2.41899
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.60252

Cumulative Model Updates: 179,174
Cumulative Timesteps: 1,494,189,722

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1494189722...
Checkpoint 1494189722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 383,586.85925
Policy Entropy: 3.67018
Value Function Loss: 0.02897

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.38113
Value Function Update Magnitude: 0.51005

Collected Steps per Second: 22,859.19295
Overall Steps per Second: 10,659.48552

Timestep Collection Time: 2.18862
Timestep Consumption Time: 2.50486
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.69347

Cumulative Model Updates: 179,180
Cumulative Timesteps: 1,494,239,752

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,028.49778
Policy Entropy: 3.68818
Value Function Loss: 0.02951

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13715
Policy Update Magnitude: 0.44186
Value Function Update Magnitude: 0.61265

Collected Steps per Second: 22,841.99002
Overall Steps per Second: 10,840.14176

Timestep Collection Time: 2.18965
Timestep Consumption Time: 2.42431
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.61396

Cumulative Model Updates: 179,186
Cumulative Timesteps: 1,494,289,768

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1494289768...
Checkpoint 1494289768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,891.94770
Policy Entropy: 3.68786
Value Function Loss: 0.03184

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.46493
Value Function Update Magnitude: 0.72445

Collected Steps per Second: 22,617.70703
Overall Steps per Second: 10,756.65938

Timestep Collection Time: 2.21154
Timestep Consumption Time: 2.43860
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.65014

Cumulative Model Updates: 179,192
Cumulative Timesteps: 1,494,339,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,339.17496
Policy Entropy: 3.70125
Value Function Loss: 0.02718

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.46691
Value Function Update Magnitude: 0.73104

Collected Steps per Second: 22,735.33279
Overall Steps per Second: 10,801.05328

Timestep Collection Time: 2.19940
Timestep Consumption Time: 2.43015
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.62955

Cumulative Model Updates: 179,198
Cumulative Timesteps: 1,494,389,792

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1494389792...
Checkpoint 1494389792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,339.17496
Policy Entropy: 3.65718
Value Function Loss: 0.02836

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.47238
Value Function Update Magnitude: 0.64307

Collected Steps per Second: 22,753.55909
Overall Steps per Second: 10,699.20150

Timestep Collection Time: 2.19851
Timestep Consumption Time: 2.47698
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.67549

Cumulative Model Updates: 179,204
Cumulative Timesteps: 1,494,439,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,242.44235
Policy Entropy: 3.65507
Value Function Loss: 0.02678

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.14190
Policy Update Magnitude: 0.47262
Value Function Update Magnitude: 0.50288

Collected Steps per Second: 22,574.91197
Overall Steps per Second: 10,667.20465

Timestep Collection Time: 2.21573
Timestep Consumption Time: 2.47340
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.68914

Cumulative Model Updates: 179,210
Cumulative Timesteps: 1,494,489,836

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1494489836...
Checkpoint 1494489836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,242.44235
Policy Entropy: 3.65615
Value Function Loss: 0.02491

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14563
Policy Update Magnitude: 0.46166
Value Function Update Magnitude: 0.43932

Collected Steps per Second: 22,952.79728
Overall Steps per Second: 10,950.69291

Timestep Collection Time: 2.17882
Timestep Consumption Time: 2.38801
PPO Batch Consumption Time: 0.27543
Total Iteration Time: 4.56683

Cumulative Model Updates: 179,216
Cumulative Timesteps: 1,494,539,846

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,242.44235
Policy Entropy: 3.68300
Value Function Loss: 0.01937

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.42164
Value Function Update Magnitude: 0.33281

Collected Steps per Second: 22,761.73780
Overall Steps per Second: 10,808.68213

Timestep Collection Time: 2.19702
Timestep Consumption Time: 2.42963
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.62665

Cumulative Model Updates: 179,222
Cumulative Timesteps: 1,494,589,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1494589854...
Checkpoint 1494589854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,242.44235
Policy Entropy: 3.66500
Value Function Loss: 0.01975

Mean KL Divergence: 0.00685
SB3 Clip Fraction: 0.08774
Policy Update Magnitude: 0.44777
Value Function Update Magnitude: 0.32151

Collected Steps per Second: 22,753.36659
Overall Steps per Second: 10,684.60774

Timestep Collection Time: 2.19853
Timestep Consumption Time: 2.48334
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.68188

Cumulative Model Updates: 179,228
Cumulative Timesteps: 1,494,639,878

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 157,703.12934
Policy Entropy: 3.66548
Value Function Loss: 0.02114

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.50799
Value Function Update Magnitude: 0.41459

Collected Steps per Second: 21,926.01262
Overall Steps per Second: 10,848.43014

Timestep Collection Time: 2.28103
Timestep Consumption Time: 2.32922
PPO Batch Consumption Time: 0.27667
Total Iteration Time: 4.61025

Cumulative Model Updates: 179,234
Cumulative Timesteps: 1,494,689,892

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1494689892...
Checkpoint 1494689892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,008.41241
Policy Entropy: 3.67953
Value Function Loss: 0.02219

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.43938
Value Function Update Magnitude: 0.50137

Collected Steps per Second: 22,147.58018
Overall Steps per Second: 10,731.62938

Timestep Collection Time: 2.25822
Timestep Consumption Time: 2.40221
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.66043

Cumulative Model Updates: 179,240
Cumulative Timesteps: 1,494,739,906

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,253.21903
Policy Entropy: 3.68102
Value Function Loss: 0.02369

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.16318
Policy Update Magnitude: 0.41186
Value Function Update Magnitude: 0.62719

Collected Steps per Second: 22,355.68168
Overall Steps per Second: 10,942.98054

Timestep Collection Time: 2.23728
Timestep Consumption Time: 2.33332
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.57060

Cumulative Model Updates: 179,246
Cumulative Timesteps: 1,494,789,922

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1494789922...
Checkpoint 1494789922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,253.21903
Policy Entropy: 3.68327
Value Function Loss: 0.02126

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14840
Policy Update Magnitude: 0.45667
Value Function Update Magnitude: 0.73697

Collected Steps per Second: 22,239.30596
Overall Steps per Second: 10,621.87916

Timestep Collection Time: 2.24827
Timestep Consumption Time: 2.45899
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.70727

Cumulative Model Updates: 179,252
Cumulative Timesteps: 1,494,839,922

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,253.21903
Policy Entropy: 3.68411
Value Function Loss: 0.01854

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.44681
Value Function Update Magnitude: 0.68626

Collected Steps per Second: 22,898.35073
Overall Steps per Second: 10,874.36646

Timestep Collection Time: 2.18444
Timestep Consumption Time: 2.41537
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.59981

Cumulative Model Updates: 179,258
Cumulative Timesteps: 1,494,889,942

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1494889942...
Checkpoint 1494889942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,253.21903
Policy Entropy: 3.68830
Value Function Loss: 0.01649

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06340
Policy Update Magnitude: 0.45493
Value Function Update Magnitude: 0.51316

Collected Steps per Second: 22,918.69587
Overall Steps per Second: 10,707.91351

Timestep Collection Time: 2.18189
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.67000

Cumulative Model Updates: 179,264
Cumulative Timesteps: 1,494,939,948

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,253.21903
Policy Entropy: 3.68849
Value Function Loss: 0.01774

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.05950
Policy Update Magnitude: 0.54555
Value Function Update Magnitude: 0.45403

Collected Steps per Second: 22,911.25112
Overall Steps per Second: 10,892.98870

Timestep Collection Time: 2.18233
Timestep Consumption Time: 2.40777
PPO Batch Consumption Time: 0.27556
Total Iteration Time: 4.59011

Cumulative Model Updates: 179,270
Cumulative Timesteps: 1,494,989,948

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1494989948...
Checkpoint 1494989948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,253.21903
Policy Entropy: 3.68645
Value Function Loss: 0.01746

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.05391
Policy Update Magnitude: 0.56937
Value Function Update Magnitude: 0.46884

Collected Steps per Second: 22,940.16458
Overall Steps per Second: 10,761.16796

Timestep Collection Time: 2.18072
Timestep Consumption Time: 2.46804
PPO Batch Consumption Time: 0.28772
Total Iteration Time: 4.64875

Cumulative Model Updates: 179,276
Cumulative Timesteps: 1,495,039,974

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,253.21903
Policy Entropy: 3.67184
Value Function Loss: 0.01763

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09193
Policy Update Magnitude: 0.54955
Value Function Update Magnitude: 0.47825

Collected Steps per Second: 22,913.17104
Overall Steps per Second: 10,741.87716

Timestep Collection Time: 2.18302
Timestep Consumption Time: 2.47352
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.65654

Cumulative Model Updates: 179,282
Cumulative Timesteps: 1,495,089,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1495089994...
Checkpoint 1495089994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,253.21903
Policy Entropy: 3.66633
Value Function Loss: 0.01790

Mean KL Divergence: 0.02235
SB3 Clip Fraction: 0.24723
Policy Update Magnitude: 0.45024
Value Function Update Magnitude: 0.46297

Collected Steps per Second: 22,834.03682
Overall Steps per Second: 10,700.67695

Timestep Collection Time: 2.19015
Timestep Consumption Time: 2.48338
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.67354

Cumulative Model Updates: 179,288
Cumulative Timesteps: 1,495,140,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,137.99778
Policy Entropy: 3.64870
Value Function Loss: 0.03402

Mean KL Divergence: 0.02332
SB3 Clip Fraction: 0.24713
Policy Update Magnitude: 0.49566
Value Function Update Magnitude: 0.45753

Collected Steps per Second: 22,878.97017
Overall Steps per Second: 10,872.26949

Timestep Collection Time: 2.18568
Timestep Consumption Time: 2.41373
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.59941

Cumulative Model Updates: 179,294
Cumulative Timesteps: 1,495,190,010

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1495190010...
Checkpoint 1495190010 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 275,041.92775
Policy Entropy: 3.61840
Value Function Loss: 0.06346

Mean KL Divergence: 0.03624
SB3 Clip Fraction: 0.30504
Policy Update Magnitude: 0.67605
Value Function Update Magnitude: 0.45954

Collected Steps per Second: 22,268.57551
Overall Steps per Second: 10,602.34802

Timestep Collection Time: 2.24604
Timestep Consumption Time: 2.47141
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.71745

Cumulative Model Updates: 179,300
Cumulative Timesteps: 1,495,240,026

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,142,771.94893
Policy Entropy: 3.61490
Value Function Loss: 0.11043

Mean KL Divergence: 0.02376
SB3 Clip Fraction: 0.23447
Policy Update Magnitude: 0.92074
Value Function Update Magnitude: 0.51403

Collected Steps per Second: 22,387.54522
Overall Steps per Second: 10,524.08810

Timestep Collection Time: 2.23526
Timestep Consumption Time: 2.51974
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.75500

Cumulative Model Updates: 179,306
Cumulative Timesteps: 1,495,290,068

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1495290068...
Checkpoint 1495290068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,780.68242
Policy Entropy: 3.65828
Value Function Loss: 0.13476

Mean KL Divergence: 0.01793
SB3 Clip Fraction: 0.20020
Policy Update Magnitude: 1.11908
Value Function Update Magnitude: 0.52520

Collected Steps per Second: 22,603.02346
Overall Steps per Second: 10,661.53401

Timestep Collection Time: 2.21342
Timestep Consumption Time: 2.47915
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.69257

Cumulative Model Updates: 179,312
Cumulative Timesteps: 1,495,340,098

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,900.88892
Policy Entropy: 3.72602
Value Function Loss: 0.11198

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.18226
Policy Update Magnitude: 1.36233
Value Function Update Magnitude: 0.63887

Collected Steps per Second: 22,878.21507
Overall Steps per Second: 10,797.57130

Timestep Collection Time: 2.18557
Timestep Consumption Time: 2.44528
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.63086

Cumulative Model Updates: 179,318
Cumulative Timesteps: 1,495,390,100

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1495390100...
Checkpoint 1495390100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,914.65144
Policy Entropy: 3.77905
Value Function Loss: 0.10143

Mean KL Divergence: 0.01484
SB3 Clip Fraction: 0.16648
Policy Update Magnitude: 1.12111
Value Function Update Magnitude: 0.67767

Collected Steps per Second: 22,962.70469
Overall Steps per Second: 10,692.00978

Timestep Collection Time: 2.17919
Timestep Consumption Time: 2.50094
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.68013

Cumulative Model Updates: 179,324
Cumulative Timesteps: 1,495,440,140

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,624.68453
Policy Entropy: 3.84101
Value Function Loss: 0.08969

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 1.16558
Value Function Update Magnitude: 0.68368

Collected Steps per Second: 22,946.68522
Overall Steps per Second: 10,916.00449

Timestep Collection Time: 2.17992
Timestep Consumption Time: 2.40252
PPO Batch Consumption Time: 0.27653
Total Iteration Time: 4.58245

Cumulative Model Updates: 179,330
Cumulative Timesteps: 1,495,490,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1495490162...
Checkpoint 1495490162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,533.79938
Policy Entropy: 3.86170
Value Function Loss: 0.07854

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 1.09482
Value Function Update Magnitude: 0.75022

Collected Steps per Second: 22,616.20075
Overall Steps per Second: 10,654.16687

Timestep Collection Time: 2.21116
Timestep Consumption Time: 2.48259
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.69375

Cumulative Model Updates: 179,336
Cumulative Timesteps: 1,495,540,170

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102.82248
Policy Entropy: 3.85108
Value Function Loss: 0.07060

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.86301
Value Function Update Magnitude: 0.72004

Collected Steps per Second: 22,827.62844
Overall Steps per Second: 10,819.37065

Timestep Collection Time: 2.19050
Timestep Consumption Time: 2.43121
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.62171

Cumulative Model Updates: 179,342
Cumulative Timesteps: 1,495,590,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1495590174...
Checkpoint 1495590174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,626.10832
Policy Entropy: 3.79975
Value Function Loss: 0.06554

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.73651
Value Function Update Magnitude: 0.65990

Collected Steps per Second: 22,895.26073
Overall Steps per Second: 10,704.39234

Timestep Collection Time: 2.18438
Timestep Consumption Time: 2.48772
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.67210

Cumulative Model Updates: 179,348
Cumulative Timesteps: 1,495,640,186

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,216.47110
Policy Entropy: 3.77698
Value Function Loss: 0.06940

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.70791
Value Function Update Magnitude: 0.73332

Collected Steps per Second: 22,700.46603
Overall Steps per Second: 10,837.15107

Timestep Collection Time: 2.20366
Timestep Consumption Time: 2.41232
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.61597

Cumulative Model Updates: 179,354
Cumulative Timesteps: 1,495,690,210

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1495690210...
Checkpoint 1495690210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,698.02277
Policy Entropy: 3.77582
Value Function Loss: 0.07280

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12107
Policy Update Magnitude: 0.73654
Value Function Update Magnitude: 0.67443

Collected Steps per Second: 22,627.96773
Overall Steps per Second: 10,672.98351

Timestep Collection Time: 2.21036
Timestep Consumption Time: 2.47586
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.68622

Cumulative Model Updates: 179,360
Cumulative Timesteps: 1,495,740,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,068.46811
Policy Entropy: 3.76697
Value Function Loss: 0.07705

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12460
Policy Update Magnitude: 0.73972
Value Function Update Magnitude: 0.58800

Collected Steps per Second: 22,817.19133
Overall Steps per Second: 10,844.89123

Timestep Collection Time: 2.19186
Timestep Consumption Time: 2.41972
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.61157

Cumulative Model Updates: 179,366
Cumulative Timesteps: 1,495,790,238

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1495790238...
Checkpoint 1495790238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,291.53332
Policy Entropy: 3.77028
Value Function Loss: 0.07562

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.69877
Value Function Update Magnitude: 0.74221

Collected Steps per Second: 22,574.48336
Overall Steps per Second: 10,694.63820

Timestep Collection Time: 2.21516
Timestep Consumption Time: 2.46065
PPO Batch Consumption Time: 0.28477
Total Iteration Time: 4.67580

Cumulative Model Updates: 179,372
Cumulative Timesteps: 1,495,840,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 820.41244
Policy Entropy: 3.77637
Value Function Loss: 0.07450

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.11697
Policy Update Magnitude: 0.65037
Value Function Update Magnitude: 0.80059

Collected Steps per Second: 22,724.69699
Overall Steps per Second: 10,831.51243

Timestep Collection Time: 2.20060
Timestep Consumption Time: 2.41630
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.61690

Cumulative Model Updates: 179,378
Cumulative Timesteps: 1,495,890,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1495890252...
Checkpoint 1495890252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,718.82702
Policy Entropy: 3.78852
Value Function Loss: 0.06676

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11662
Policy Update Magnitude: 0.63762
Value Function Update Magnitude: 0.63519

Collected Steps per Second: 22,378.94683
Overall Steps per Second: 10,786.04627

Timestep Collection Time: 2.23532
Timestep Consumption Time: 2.40253
PPO Batch Consumption Time: 0.27581
Total Iteration Time: 4.63784

Cumulative Model Updates: 179,384
Cumulative Timesteps: 1,495,940,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 969.41287
Policy Entropy: 3.76111
Value Function Loss: 0.05720

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12960
Policy Update Magnitude: 0.57339
Value Function Update Magnitude: 0.58003

Collected Steps per Second: 22,746.72219
Overall Steps per Second: 10,802.37225

Timestep Collection Time: 2.19882
Timestep Consumption Time: 2.43127
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.63009

Cumulative Model Updates: 179,390
Cumulative Timesteps: 1,495,990,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1495990292...
Checkpoint 1495990292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,270.59133
Policy Entropy: 3.75455
Value Function Loss: 0.04940

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12623
Policy Update Magnitude: 0.51227
Value Function Update Magnitude: 0.61417

Collected Steps per Second: 22,719.66147
Overall Steps per Second: 10,679.97286

Timestep Collection Time: 2.20188
Timestep Consumption Time: 2.48221
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.68409

Cumulative Model Updates: 179,396
Cumulative Timesteps: 1,496,040,318

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,892.41552
Policy Entropy: 3.75144
Value Function Loss: 0.04549

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13090
Policy Update Magnitude: 0.48288
Value Function Update Magnitude: 0.62192

Collected Steps per Second: 22,896.57091
Overall Steps per Second: 10,876.53057

Timestep Collection Time: 2.18496
Timestep Consumption Time: 2.41467
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.59963

Cumulative Model Updates: 179,402
Cumulative Timesteps: 1,496,090,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1496090346...
Checkpoint 1496090346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,423.23265
Policy Entropy: 3.76005
Value Function Loss: 0.04286

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.46301
Value Function Update Magnitude: 0.74838

Collected Steps per Second: 22,780.10130
Overall Steps per Second: 10,697.95324

Timestep Collection Time: 2.19604
Timestep Consumption Time: 2.48018
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.67622

Cumulative Model Updates: 179,408
Cumulative Timesteps: 1,496,140,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278.23104
Policy Entropy: 3.78750
Value Function Loss: 0.04151

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.43376
Value Function Update Magnitude: 0.78772

Collected Steps per Second: 22,860.22056
Overall Steps per Second: 10,833.92594

Timestep Collection Time: 2.18791
Timestep Consumption Time: 2.42870
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.61661

Cumulative Model Updates: 179,414
Cumulative Timesteps: 1,496,190,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1496190388...
Checkpoint 1496190388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38.99444
Policy Entropy: 3.77811
Value Function Loss: 0.04164

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12523
Policy Update Magnitude: 0.44748
Value Function Update Magnitude: 0.81754

Collected Steps per Second: 22,788.86543
Overall Steps per Second: 10,713.30825

Timestep Collection Time: 2.19484
Timestep Consumption Time: 2.47393
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.66877

Cumulative Model Updates: 179,420
Cumulative Timesteps: 1,496,240,406

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,642.25590
Policy Entropy: 3.77458
Value Function Loss: 0.04119

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.47129
Value Function Update Magnitude: 0.76667

Collected Steps per Second: 23,166.60762
Overall Steps per Second: 10,964.78848

Timestep Collection Time: 2.15888
Timestep Consumption Time: 2.40245
PPO Batch Consumption Time: 0.27629
Total Iteration Time: 4.56133

Cumulative Model Updates: 179,426
Cumulative Timesteps: 1,496,290,420

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1496290420...
Checkpoint 1496290420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 340.44310
Policy Entropy: 3.75764
Value Function Loss: 0.03666

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13369
Policy Update Magnitude: 0.44304
Value Function Update Magnitude: 0.69975

Collected Steps per Second: 23,031.45188
Overall Steps per Second: 10,963.37640

Timestep Collection Time: 2.17155
Timestep Consumption Time: 2.39036
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.56192

Cumulative Model Updates: 179,432
Cumulative Timesteps: 1,496,340,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62.95264
Policy Entropy: 3.74982
Value Function Loss: 0.03425

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.40620
Value Function Update Magnitude: 0.66479

Collected Steps per Second: 21,822.05714
Overall Steps per Second: 10,631.91878

Timestep Collection Time: 2.29218
Timestep Consumption Time: 2.41252
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.70470

Cumulative Model Updates: 179,438
Cumulative Timesteps: 1,496,390,454

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1496390454...
Checkpoint 1496390454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30.64858
Policy Entropy: 3.75333
Value Function Loss: 0.03334

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13282
Policy Update Magnitude: 0.39312
Value Function Update Magnitude: 0.61291

Collected Steps per Second: 22,047.34089
Overall Steps per Second: 10,741.31923

Timestep Collection Time: 2.26794
Timestep Consumption Time: 2.38717
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.65511

Cumulative Model Updates: 179,444
Cumulative Timesteps: 1,496,440,456

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,515.49510
Policy Entropy: 3.73417
Value Function Loss: 0.03254

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.39874
Value Function Update Magnitude: 0.56397

Collected Steps per Second: 22,312.00775
Overall Steps per Second: 10,738.61401

Timestep Collection Time: 2.24166
Timestep Consumption Time: 2.41592
PPO Batch Consumption Time: 0.28158
Total Iteration Time: 4.65758

Cumulative Model Updates: 179,450
Cumulative Timesteps: 1,496,490,472

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1496490472...
Checkpoint 1496490472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,152.51033
Policy Entropy: 3.73350
Value Function Loss: 0.02684

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.40040
Value Function Update Magnitude: 0.58902

Collected Steps per Second: 22,866.76657
Overall Steps per Second: 10,827.56705

Timestep Collection Time: 2.18745
Timestep Consumption Time: 2.43224
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.61969

Cumulative Model Updates: 179,456
Cumulative Timesteps: 1,496,540,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,673.88684
Policy Entropy: 3.71898
Value Function Loss: 0.02481

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13675
Policy Update Magnitude: 0.36095
Value Function Update Magnitude: 0.55983

Collected Steps per Second: 23,197.69945
Overall Steps per Second: 10,826.31327

Timestep Collection Time: 2.15625
Timestep Consumption Time: 2.46398
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.62022

Cumulative Model Updates: 179,462
Cumulative Timesteps: 1,496,590,512

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1496590512...
Checkpoint 1496590512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,595.87774
Policy Entropy: 3.73015
Value Function Loss: 0.02184

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13441
Policy Update Magnitude: 0.30703
Value Function Update Magnitude: 0.53626

Collected Steps per Second: 22,760.88197
Overall Steps per Second: 10,732.43241

Timestep Collection Time: 2.19772
Timestep Consumption Time: 2.46311
PPO Batch Consumption Time: 0.28731
Total Iteration Time: 4.66083

Cumulative Model Updates: 179,468
Cumulative Timesteps: 1,496,640,534

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,199.78477
Policy Entropy: 3.72667
Value Function Loss: 0.02264

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.27055
Value Function Update Magnitude: 0.54293

Collected Steps per Second: 23,052.20633
Overall Steps per Second: 10,742.02721

Timestep Collection Time: 2.16960
Timestep Consumption Time: 2.48632
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.65592

Cumulative Model Updates: 179,474
Cumulative Timesteps: 1,496,690,548

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1496690548...
Checkpoint 1496690548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.55267
Policy Entropy: 3.72666
Value Function Loss: 0.02278

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12347
Policy Update Magnitude: 0.27795
Value Function Update Magnitude: 0.61888

Collected Steps per Second: 22,615.52175
Overall Steps per Second: 10,667.03172

Timestep Collection Time: 2.21202
Timestep Consumption Time: 2.47776
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.68978

Cumulative Model Updates: 179,480
Cumulative Timesteps: 1,496,740,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.64615
Policy Entropy: 3.70658
Value Function Loss: 0.02474

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.29902
Value Function Update Magnitude: 0.65646

Collected Steps per Second: 23,625.53880
Overall Steps per Second: 10,817.19773

Timestep Collection Time: 2.11737
Timestep Consumption Time: 2.50712
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.62449

Cumulative Model Updates: 179,486
Cumulative Timesteps: 1,496,790,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1496790598...
Checkpoint 1496790598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.64615
Policy Entropy: 3.70498
Value Function Loss: 0.02406

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12335
Policy Update Magnitude: 0.31646
Value Function Update Magnitude: 0.53912

Collected Steps per Second: 22,530.01449
Overall Steps per Second: 10,655.71601

Timestep Collection Time: 2.21979
Timestep Consumption Time: 2.47365
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.69344

Cumulative Model Updates: 179,492
Cumulative Timesteps: 1,496,840,610

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.64615
Policy Entropy: 3.69572
Value Function Loss: 0.02136

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13786
Policy Update Magnitude: 0.31883
Value Function Update Magnitude: 0.46396

Collected Steps per Second: 23,412.51483
Overall Steps per Second: 10,937.81253

Timestep Collection Time: 2.13783
Timestep Consumption Time: 2.43822
PPO Batch Consumption Time: 0.28077
Total Iteration Time: 4.57605

Cumulative Model Updates: 179,498
Cumulative Timesteps: 1,496,890,662

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1496890662...
Checkpoint 1496890662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 979.64615
Policy Entropy: 3.68747
Value Function Loss: 0.01989

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.29367
Value Function Update Magnitude: 0.40356

Collected Steps per Second: 22,188.40065
Overall Steps per Second: 10,726.98826

Timestep Collection Time: 2.25451
Timestep Consumption Time: 2.40887
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.66338

Cumulative Model Updates: 179,504
Cumulative Timesteps: 1,496,940,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 979.64615
Policy Entropy: 3.67639
Value Function Loss: 0.02076

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.27662
Value Function Update Magnitude: 0.35902

Collected Steps per Second: 22,426.02962
Overall Steps per Second: 10,810.92744

Timestep Collection Time: 2.22973
Timestep Consumption Time: 2.39559
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.62532

Cumulative Model Updates: 179,510
Cumulative Timesteps: 1,496,990,690

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1496990690...
Checkpoint 1496990690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,156.85995
Policy Entropy: 3.68814
Value Function Loss: 0.02320

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12663
Policy Update Magnitude: 0.30399
Value Function Update Magnitude: 0.39777

Collected Steps per Second: 22,198.64717
Overall Steps per Second: 10,749.59716

Timestep Collection Time: 2.25257
Timestep Consumption Time: 2.39914
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.65171

Cumulative Model Updates: 179,516
Cumulative Timesteps: 1,497,040,694

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,704.04769
Policy Entropy: 3.69240
Value Function Loss: 0.02447

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.36082
Value Function Update Magnitude: 0.64179

Collected Steps per Second: 22,632.77822
Overall Steps per Second: 10,800.04236

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.42149
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.63165

Cumulative Model Updates: 179,522
Cumulative Timesteps: 1,497,090,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1497090716...
Checkpoint 1497090716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,704.04769
Policy Entropy: 3.69190
Value Function Loss: 0.02376

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.39885
Value Function Update Magnitude: 0.68724

Collected Steps per Second: 22,789.46890
Overall Steps per Second: 10,786.67235

Timestep Collection Time: 2.19496
Timestep Consumption Time: 2.44243
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.63739

Cumulative Model Updates: 179,528
Cumulative Timesteps: 1,497,140,738

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,704.04769
Policy Entropy: 3.67924
Value Function Loss: 0.02336

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12834
Policy Update Magnitude: 0.40387
Value Function Update Magnitude: 0.56223

Collected Steps per Second: 23,421.61383
Overall Steps per Second: 10,774.47096

Timestep Collection Time: 2.13487
Timestep Consumption Time: 2.50592
PPO Batch Consumption Time: 0.29066
Total Iteration Time: 4.64078

Cumulative Model Updates: 179,534
Cumulative Timesteps: 1,497,190,740

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1497190740...
Checkpoint 1497190740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,704.04769
Policy Entropy: 3.65679
Value Function Loss: 0.02774

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.42926
Value Function Update Magnitude: 0.43874

Collected Steps per Second: 22,810.40292
Overall Steps per Second: 10,704.36439

Timestep Collection Time: 2.19251
Timestep Consumption Time: 2.47960
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.67211

Cumulative Model Updates: 179,540
Cumulative Timesteps: 1,497,240,752

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,603.30604
Policy Entropy: 3.67641
Value Function Loss: 0.03336

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.48390
Value Function Update Magnitude: 0.45245

Collected Steps per Second: 22,899.01744
Overall Steps per Second: 10,826.64298

Timestep Collection Time: 2.18437
Timestep Consumption Time: 2.43571
PPO Batch Consumption Time: 0.28064
Total Iteration Time: 4.62008

Cumulative Model Updates: 179,546
Cumulative Timesteps: 1,497,290,772

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1497290772...
Checkpoint 1497290772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,991.98024
Policy Entropy: 3.69160
Value Function Loss: 0.03793

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.46912
Value Function Update Magnitude: 0.52883

Collected Steps per Second: 22,322.35811
Overall Steps per Second: 10,625.71733

Timestep Collection Time: 2.24044
Timestep Consumption Time: 2.46625
PPO Batch Consumption Time: 0.28535
Total Iteration Time: 4.70669

Cumulative Model Updates: 179,552
Cumulative Timesteps: 1,497,340,784

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,895.32636
Policy Entropy: 3.70193
Value Function Loss: 0.03301

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.43540
Value Function Update Magnitude: 0.58618

Collected Steps per Second: 23,111.31171
Overall Steps per Second: 10,977.68923

Timestep Collection Time: 2.16422
Timestep Consumption Time: 2.39211
PPO Batch Consumption Time: 0.27608
Total Iteration Time: 4.55633

Cumulative Model Updates: 179,558
Cumulative Timesteps: 1,497,390,802

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1497390802...
Checkpoint 1497390802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,895.32636
Policy Entropy: 3.69484
Value Function Loss: 0.02840

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.38508
Value Function Update Magnitude: 0.54674

Collected Steps per Second: 22,878.65837
Overall Steps per Second: 10,754.93079

Timestep Collection Time: 2.18675
Timestep Consumption Time: 2.46507
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.65182

Cumulative Model Updates: 179,564
Cumulative Timesteps: 1,497,440,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,895.32636
Policy Entropy: 3.68557
Value Function Loss: 0.02078

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.13162
Policy Update Magnitude: 0.35607
Value Function Update Magnitude: 0.49389

Collected Steps per Second: 22,319.46972
Overall Steps per Second: 10,774.91187

Timestep Collection Time: 2.24029
Timestep Consumption Time: 2.40031
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.64059

Cumulative Model Updates: 179,570
Cumulative Timesteps: 1,497,490,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1497490834...
Checkpoint 1497490834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,766.20698
Policy Entropy: 3.68038
Value Function Loss: 0.02242

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.34381
Value Function Update Magnitude: 0.48845

Collected Steps per Second: 22,035.22455
Overall Steps per Second: 10,723.29591

Timestep Collection Time: 2.26982
Timestep Consumption Time: 2.39442
PPO Batch Consumption Time: 0.29011
Total Iteration Time: 4.66424

Cumulative Model Updates: 179,576
Cumulative Timesteps: 1,497,540,850

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,766.20698
Policy Entropy: 3.68051
Value Function Loss: 0.02043

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.31571
Value Function Update Magnitude: 0.49765

Collected Steps per Second: 22,491.22724
Overall Steps per Second: 10,776.05921

Timestep Collection Time: 2.22344
Timestep Consumption Time: 2.41721
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.64066

Cumulative Model Updates: 179,582
Cumulative Timesteps: 1,497,590,858

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1497590858...
Checkpoint 1497590858 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,766.20698
Policy Entropy: 3.67653
Value Function Loss: 0.01982

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.13030
Policy Update Magnitude: 0.29529
Value Function Update Magnitude: 0.49419

Collected Steps per Second: 22,254.75847
Overall Steps per Second: 10,640.80093

Timestep Collection Time: 2.24734
Timestep Consumption Time: 2.45287
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.70021

Cumulative Model Updates: 179,588
Cumulative Timesteps: 1,497,640,872

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,766.20698
Policy Entropy: 3.67620
Value Function Loss: 0.01984

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.31143
Value Function Update Magnitude: 0.37346

Collected Steps per Second: 23,535.10205
Overall Steps per Second: 10,924.45317

Timestep Collection Time: 2.12457
Timestep Consumption Time: 2.45250
PPO Batch Consumption Time: 0.28660
Total Iteration Time: 4.57707

Cumulative Model Updates: 179,594
Cumulative Timesteps: 1,497,690,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1497690874...
Checkpoint 1497690874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,766.20698
Policy Entropy: 3.68373
Value Function Loss: 0.01867

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.32279
Value Function Update Magnitude: 0.35959

Collected Steps per Second: 22,808.45351
Overall Steps per Second: 10,783.36414

Timestep Collection Time: 2.19462
Timestep Consumption Time: 2.44734
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.64197

Cumulative Model Updates: 179,600
Cumulative Timesteps: 1,497,740,930

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,766.20698
Policy Entropy: 3.67129
Value Function Loss: 0.01953

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12930
Policy Update Magnitude: 0.33830
Value Function Update Magnitude: 0.40219

Collected Steps per Second: 23,105.26052
Overall Steps per Second: 10,735.76577

Timestep Collection Time: 2.16436
Timestep Consumption Time: 2.49372
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.65807

Cumulative Model Updates: 179,606
Cumulative Timesteps: 1,497,790,938

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1497790938...
Checkpoint 1497790938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,258.30643
Policy Entropy: 3.68773
Value Function Loss: 0.02113

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13032
Policy Update Magnitude: 0.39063
Value Function Update Magnitude: 0.52718

Collected Steps per Second: 21,503.48672
Overall Steps per Second: 10,291.11287

Timestep Collection Time: 2.32623
Timestep Consumption Time: 2.53447
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.86070

Cumulative Model Updates: 179,612
Cumulative Timesteps: 1,497,840,960

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,737.68485
Policy Entropy: 3.68663
Value Function Loss: 0.02200

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.46643
Value Function Update Magnitude: 0.61111

Collected Steps per Second: 22,576.43953
Overall Steps per Second: 10,809.68263

Timestep Collection Time: 2.21470
Timestep Consumption Time: 2.41078
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.62548

Cumulative Model Updates: 179,618
Cumulative Timesteps: 1,497,890,960

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1497890960...
Checkpoint 1497890960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,956.83026
Policy Entropy: 3.70515
Value Function Loss: 0.02512

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13716
Policy Update Magnitude: 0.48979
Value Function Update Magnitude: 0.66671

Collected Steps per Second: 22,388.51594
Overall Steps per Second: 10,696.40128

Timestep Collection Time: 2.23436
Timestep Consumption Time: 2.44235
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.67671

Cumulative Model Updates: 179,624
Cumulative Timesteps: 1,497,940,984

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,290.64636
Policy Entropy: 3.71300
Value Function Loss: 0.02483

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08847
Policy Update Magnitude: 0.57352
Value Function Update Magnitude: 0.76067

Collected Steps per Second: 23,342.66190
Overall Steps per Second: 10,860.55090

Timestep Collection Time: 2.14277
Timestep Consumption Time: 2.46270
PPO Batch Consumption Time: 0.28314
Total Iteration Time: 4.60548

Cumulative Model Updates: 179,630
Cumulative Timesteps: 1,497,991,002

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1497991002...
Checkpoint 1497991002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,536.26320
Policy Entropy: 3.70072
Value Function Loss: 0.02650

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09173
Policy Update Magnitude: 0.60005
Value Function Update Magnitude: 0.79774

Collected Steps per Second: 22,845.47104
Overall Steps per Second: 10,657.21170

Timestep Collection Time: 2.18862
Timestep Consumption Time: 2.50304
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.69166

Cumulative Model Updates: 179,636
Cumulative Timesteps: 1,498,041,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,536.26320
Policy Entropy: 3.69346
Value Function Loss: 0.02311

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08374
Policy Update Magnitude: 0.57862
Value Function Update Magnitude: 0.77913

Collected Steps per Second: 22,264.21878
Overall Steps per Second: 10,885.91687

Timestep Collection Time: 2.24585
Timestep Consumption Time: 2.34743
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.59327

Cumulative Model Updates: 179,642
Cumulative Timesteps: 1,498,091,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1498091004...
Checkpoint 1498091004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,636.90398
Policy Entropy: 3.67462
Value Function Loss: 0.02232

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14813
Policy Update Magnitude: 0.51007
Value Function Update Magnitude: 0.70760

Collected Steps per Second: 21,622.46291
Overall Steps per Second: 10,670.59667

Timestep Collection Time: 2.31306
Timestep Consumption Time: 2.37403
PPO Batch Consumption Time: 0.28250
Total Iteration Time: 4.68709

Cumulative Model Updates: 179,648
Cumulative Timesteps: 1,498,141,018

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,306.28863
Policy Entropy: 3.69173
Value Function Loss: 0.02030

Mean KL Divergence: 0.01803
SB3 Clip Fraction: 0.22797
Policy Update Magnitude: 0.42704
Value Function Update Magnitude: 0.67937

Collected Steps per Second: 22,366.53917
Overall Steps per Second: 10,902.43873

Timestep Collection Time: 2.23691
Timestep Consumption Time: 2.35215
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.58907

Cumulative Model Updates: 179,654
Cumulative Timesteps: 1,498,191,050

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1498191050...
Checkpoint 1498191050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,367.63933
Policy Entropy: 3.72437
Value Function Loss: 0.01934

Mean KL Divergence: 0.01629
SB3 Clip Fraction: 0.19483
Policy Update Magnitude: 0.39086
Value Function Update Magnitude: 0.65744

Collected Steps per Second: 22,072.53915
Overall Steps per Second: 10,630.55590

Timestep Collection Time: 2.26625
Timestep Consumption Time: 2.43924
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.70549

Cumulative Model Updates: 179,660
Cumulative Timesteps: 1,498,241,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,943.45906
Policy Entropy: 3.72852
Value Function Loss: 0.01909

Mean KL Divergence: 0.01183
SB3 Clip Fraction: 0.14579
Policy Update Magnitude: 0.43612
Value Function Update Magnitude: 0.63266

Collected Steps per Second: 23,206.20754
Overall Steps per Second: 10,995.65693

Timestep Collection Time: 2.15468
Timestep Consumption Time: 2.39275
PPO Batch Consumption Time: 0.27641
Total Iteration Time: 4.54743

Cumulative Model Updates: 179,666
Cumulative Timesteps: 1,498,291,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1498291074...
Checkpoint 1498291074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,206.70845
Policy Entropy: 3.71326
Value Function Loss: 0.02124

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.16060
Policy Update Magnitude: 0.46896
Value Function Update Magnitude: 0.57579

Collected Steps per Second: 22,487.26198
Overall Steps per Second: 10,671.42002

Timestep Collection Time: 2.22482
Timestep Consumption Time: 2.46341
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.68822

Cumulative Model Updates: 179,672
Cumulative Timesteps: 1,498,341,104

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,206.70845
Policy Entropy: 3.70242
Value Function Loss: 0.02092

Mean KL Divergence: 0.01527
SB3 Clip Fraction: 0.18271
Policy Update Magnitude: 0.44677
Value Function Update Magnitude: 0.50095

Collected Steps per Second: 23,189.94838
Overall Steps per Second: 10,835.78212

Timestep Collection Time: 2.15637
Timestep Consumption Time: 2.45853
PPO Batch Consumption Time: 0.28320
Total Iteration Time: 4.61490

Cumulative Model Updates: 179,678
Cumulative Timesteps: 1,498,391,110

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1498391110...
Checkpoint 1498391110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,206.70845
Policy Entropy: 3.68489
Value Function Loss: 0.02001

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13960
Policy Update Magnitude: 0.39788
Value Function Update Magnitude: 0.36047

Collected Steps per Second: 22,678.79516
Overall Steps per Second: 10,580.34135

Timestep Collection Time: 2.20514
Timestep Consumption Time: 2.52155
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.72669

Cumulative Model Updates: 179,684
Cumulative Timesteps: 1,498,441,120

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,206.70845
Policy Entropy: 3.68405
Value Function Loss: 0.01592

Mean KL Divergence: 0.01348
SB3 Clip Fraction: 0.17764
Policy Update Magnitude: 0.33073
Value Function Update Magnitude: 0.25638

Collected Steps per Second: 23,206.56975
Overall Steps per Second: 10,899.34765

Timestep Collection Time: 2.15499
Timestep Consumption Time: 2.43335
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.58835

Cumulative Model Updates: 179,690
Cumulative Timesteps: 1,498,491,130

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1498491130...
Checkpoint 1498491130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,206.70845
Policy Entropy: 3.67017
Value Function Loss: 0.01828

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.17874
Policy Update Magnitude: 0.30415
Value Function Update Magnitude: 0.28539

Collected Steps per Second: 22,666.76127
Overall Steps per Second: 10,693.92331

Timestep Collection Time: 2.20702
Timestep Consumption Time: 2.47096
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.67798

Cumulative Model Updates: 179,696
Cumulative Timesteps: 1,498,541,156

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 101,206.70845
Policy Entropy: 3.68676
Value Function Loss: 0.02013

Mean KL Divergence: 0.02040
SB3 Clip Fraction: 0.23089
Policy Update Magnitude: 0.33527
Value Function Update Magnitude: 0.35368

Collected Steps per Second: 22,994.41274
Overall Steps per Second: 10,849.75552

Timestep Collection Time: 2.17548
Timestep Consumption Time: 2.43513
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.61061

Cumulative Model Updates: 179,702
Cumulative Timesteps: 1,498,591,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1498591180...
Checkpoint 1498591180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,206.70845
Policy Entropy: 3.70664
Value Function Loss: 0.01815

Mean KL Divergence: 0.01728
SB3 Clip Fraction: 0.20653
Policy Update Magnitude: 0.33826
Value Function Update Magnitude: 0.36234

Collected Steps per Second: 22,739.33725
Overall Steps per Second: 10,688.82849

Timestep Collection Time: 2.19954
Timestep Consumption Time: 2.47974
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.67928

Cumulative Model Updates: 179,708
Cumulative Timesteps: 1,498,641,196

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223,542.73856
Policy Entropy: 3.68609
Value Function Loss: 0.02401

Mean KL Divergence: 0.01386
SB3 Clip Fraction: 0.17116
Policy Update Magnitude: 0.37937
Value Function Update Magnitude: 0.39621

Collected Steps per Second: 23,071.24353
Overall Steps per Second: 10,948.68624

Timestep Collection Time: 2.16824
Timestep Consumption Time: 2.40071
PPO Batch Consumption Time: 0.27627
Total Iteration Time: 4.56895

Cumulative Model Updates: 179,714
Cumulative Timesteps: 1,498,691,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1498691220...
Checkpoint 1498691220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,074.12360
Policy Entropy: 3.69307
Value Function Loss: 0.02460

Mean KL Divergence: 0.01270
SB3 Clip Fraction: 0.16172
Policy Update Magnitude: 0.39443
Value Function Update Magnitude: 0.46021

Collected Steps per Second: 22,736.34808
Overall Steps per Second: 10,688.43833

Timestep Collection Time: 2.20027
Timestep Consumption Time: 2.48012
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.68038

Cumulative Model Updates: 179,720
Cumulative Timesteps: 1,498,741,246

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 574,374.42517
Policy Entropy: 3.67722
Value Function Loss: 0.03285

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.17295
Policy Update Magnitude: 0.40034
Value Function Update Magnitude: 0.46083

Collected Steps per Second: 23,197.10541
Overall Steps per Second: 10,802.47010

Timestep Collection Time: 2.15622
Timestep Consumption Time: 2.47402
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.63024

Cumulative Model Updates: 179,726
Cumulative Timesteps: 1,498,791,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1498791264...
Checkpoint 1498791264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 143,856.05083
Policy Entropy: 3.72520
Value Function Loss: 0.03123

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14830
Policy Update Magnitude: 0.43487
Value Function Update Magnitude: 0.58431

Collected Steps per Second: 22,024.02896
Overall Steps per Second: 10,647.20304

Timestep Collection Time: 2.27070
Timestep Consumption Time: 2.42631
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.69701

Cumulative Model Updates: 179,732
Cumulative Timesteps: 1,498,841,274

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,307.98637
Policy Entropy: 3.72071
Value Function Loss: 0.03603

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.44815
Value Function Update Magnitude: 0.66558

Collected Steps per Second: 22,308.15422
Overall Steps per Second: 10,902.47957

Timestep Collection Time: 2.24133
Timestep Consumption Time: 2.34478
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.58611

Cumulative Model Updates: 179,738
Cumulative Timesteps: 1,498,891,274

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1498891274...
Checkpoint 1498891274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,748.66847
Policy Entropy: 3.73103
Value Function Loss: 0.03825

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12126
Policy Update Magnitude: 0.50312
Value Function Update Magnitude: 0.92902

Collected Steps per Second: 21,660.05007
Overall Steps per Second: 10,682.77737

Timestep Collection Time: 2.30904
Timestep Consumption Time: 2.37270
PPO Batch Consumption Time: 0.28468
Total Iteration Time: 4.68174

Cumulative Model Updates: 179,744
Cumulative Timesteps: 1,498,941,288

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,209.47458
Policy Entropy: 3.73151
Value Function Loss: 0.04602

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13727
Policy Update Magnitude: 0.59415
Value Function Update Magnitude: 0.96412

Collected Steps per Second: 22,350.91109
Overall Steps per Second: 10,883.59640

Timestep Collection Time: 2.23839
Timestep Consumption Time: 2.35844
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.59683

Cumulative Model Updates: 179,750
Cumulative Timesteps: 1,498,991,318

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1498991318...
Checkpoint 1498991318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,580.45372
Policy Entropy: 3.72707
Value Function Loss: 0.04486

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.64146
Value Function Update Magnitude: 0.88652

Collected Steps per Second: 21,665.44289
Overall Steps per Second: 10,632.81827

Timestep Collection Time: 2.30884
Timestep Consumption Time: 2.39565
PPO Batch Consumption Time: 0.28594
Total Iteration Time: 4.70449

Cumulative Model Updates: 179,756
Cumulative Timesteps: 1,499,041,340

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,345.45604
Policy Entropy: 3.73357
Value Function Loss: 0.04016

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11808
Policy Update Magnitude: 0.63676
Value Function Update Magnitude: 0.67719

Collected Steps per Second: 22,308.34438
Overall Steps per Second: 10,883.87471

Timestep Collection Time: 2.24149
Timestep Consumption Time: 2.35283
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.59432

Cumulative Model Updates: 179,762
Cumulative Timesteps: 1,499,091,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1499091344...
Checkpoint 1499091344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 182,688.34145
Policy Entropy: 3.71657
Value Function Loss: 0.04049

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12434
Policy Update Magnitude: 0.52138
Value Function Update Magnitude: 0.61277

Collected Steps per Second: 22,001.03084
Overall Steps per Second: 10,728.74173

Timestep Collection Time: 2.27289
Timestep Consumption Time: 2.38804
PPO Batch Consumption Time: 0.27583
Total Iteration Time: 4.66094

Cumulative Model Updates: 179,768
Cumulative Timesteps: 1,499,141,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,384.64093
Policy Entropy: 3.70422
Value Function Loss: 0.03614

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13213
Policy Update Magnitude: 0.53746
Value Function Update Magnitude: 0.72563

Collected Steps per Second: 23,107.90833
Overall Steps per Second: 10,875.67066

Timestep Collection Time: 2.16445
Timestep Consumption Time: 2.43443
PPO Batch Consumption Time: 0.28212
Total Iteration Time: 4.59889

Cumulative Model Updates: 179,774
Cumulative Timesteps: 1,499,191,366

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1499191366...
Checkpoint 1499191366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212,380.47905
Policy Entropy: 3.68261
Value Function Loss: 0.03803

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13714
Policy Update Magnitude: 0.48917
Value Function Update Magnitude: 0.69824

Collected Steps per Second: 22,586.85568
Overall Steps per Second: 10,699.78827

Timestep Collection Time: 2.21430
Timestep Consumption Time: 2.46000
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.67430

Cumulative Model Updates: 179,780
Cumulative Timesteps: 1,499,241,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,988.68318
Policy Entropy: 3.69157
Value Function Loss: 0.03007

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08172
Policy Update Magnitude: 0.51886
Value Function Update Magnitude: 0.60707

Collected Steps per Second: 23,194.89404
Overall Steps per Second: 10,820.60727

Timestep Collection Time: 2.15685
Timestep Consumption Time: 2.46655
PPO Batch Consumption Time: 0.28349
Total Iteration Time: 4.62340

Cumulative Model Updates: 179,786
Cumulative Timesteps: 1,499,291,408

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1499291408...
Checkpoint 1499291408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,917.01767
Policy Entropy: 3.71406
Value Function Loss: 0.02421

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.17381
Policy Update Magnitude: 0.48864
Value Function Update Magnitude: 0.49663

Collected Steps per Second: 21,971.75314
Overall Steps per Second: 10,653.47111

Timestep Collection Time: 2.27674
Timestep Consumption Time: 2.41882
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.69556

Cumulative Model Updates: 179,792
Cumulative Timesteps: 1,499,341,432

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,923.22563
Policy Entropy: 3.73668
Value Function Loss: 0.01896

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.16483
Policy Update Magnitude: 0.40212
Value Function Update Magnitude: 0.40812

Collected Steps per Second: 23,317.75987
Overall Steps per Second: 10,955.83097

Timestep Collection Time: 2.14463
Timestep Consumption Time: 2.41988
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.56451

Cumulative Model Updates: 179,798
Cumulative Timesteps: 1,499,391,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1499391440...
Checkpoint 1499391440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,923.22563
Policy Entropy: 3.70370
Value Function Loss: 0.01749

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12811
Policy Update Magnitude: 0.35586
Value Function Update Magnitude: 0.41913

Collected Steps per Second: 22,825.51841
Overall Steps per Second: 10,664.14552

Timestep Collection Time: 2.19114
Timestep Consumption Time: 2.49878
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.68992

Cumulative Model Updates: 179,804
Cumulative Timesteps: 1,499,441,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,923.22563
Policy Entropy: 3.66714
Value Function Loss: 0.01834

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13323
Policy Update Magnitude: 0.36016
Value Function Update Magnitude: 0.44383

Collected Steps per Second: 23,261.35271
Overall Steps per Second: 10,852.65276

Timestep Collection Time: 2.15018
Timestep Consumption Time: 2.45847
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.60864

Cumulative Model Updates: 179,810
Cumulative Timesteps: 1,499,491,470

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1499491470...
Checkpoint 1499491470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,923.22563
Policy Entropy: 3.64727
Value Function Loss: 0.02230

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08799
Policy Update Magnitude: 0.42866
Value Function Update Magnitude: 0.38452

Collected Steps per Second: 22,339.34449
Overall Steps per Second: 10,639.30264

Timestep Collection Time: 2.23838
Timestep Consumption Time: 2.46155
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.69993

Cumulative Model Updates: 179,816
Cumulative Timesteps: 1,499,541,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,923.22563
Policy Entropy: 3.66767
Value Function Loss: 0.02293

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.54105
Value Function Update Magnitude: 0.40514

Collected Steps per Second: 23,290.27460
Overall Steps per Second: 10,862.37839

Timestep Collection Time: 2.14690
Timestep Consumption Time: 2.45632
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.60323

Cumulative Model Updates: 179,822
Cumulative Timesteps: 1,499,591,476

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1499591476...
Checkpoint 1499591476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,923.22563
Policy Entropy: 3.66281
Value Function Loss: 0.03642

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15707
Policy Update Magnitude: 0.48603
Value Function Update Magnitude: 0.41360

Collected Steps per Second: 22,500.98842
Overall Steps per Second: 10,636.40625

Timestep Collection Time: 2.22275
Timestep Consumption Time: 2.47941
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.70215

Cumulative Model Updates: 179,828
Cumulative Timesteps: 1,499,641,490

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,466.81767
Policy Entropy: 3.66509
Value Function Loss: 0.04574

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.16412
Policy Update Magnitude: 0.49539
Value Function Update Magnitude: 0.52239

Collected Steps per Second: 23,212.08733
Overall Steps per Second: 10,975.62747

Timestep Collection Time: 2.15483
Timestep Consumption Time: 2.40236
PPO Batch Consumption Time: 0.27570
Total Iteration Time: 4.55719

Cumulative Model Updates: 179,834
Cumulative Timesteps: 1,499,691,508

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1499691508...
Checkpoint 1499691508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,340.04776
Policy Entropy: 3.66170
Value Function Loss: 0.04527

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.16499
Policy Update Magnitude: 0.51849
Value Function Update Magnitude: 0.62751

Collected Steps per Second: 22,609.99561
Overall Steps per Second: 10,622.88795

Timestep Collection Time: 2.21265
Timestep Consumption Time: 2.49680
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.70945

Cumulative Model Updates: 179,840
Cumulative Timesteps: 1,499,741,536

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,340.04776
Policy Entropy: 3.67882
Value Function Loss: 0.03432

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15121
Policy Update Magnitude: 0.47932
Value Function Update Magnitude: 0.60833

Collected Steps per Second: 22,953.67315
Overall Steps per Second: 10,877.40783

Timestep Collection Time: 2.17830
Timestep Consumption Time: 2.41838
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.59668

Cumulative Model Updates: 179,846
Cumulative Timesteps: 1,499,791,536

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1499791536...
Checkpoint 1499791536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,421.39307
Policy Entropy: 3.69784
Value Function Loss: 0.02293

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13756
Policy Update Magnitude: 0.41393
Value Function Update Magnitude: 0.50346

Collected Steps per Second: 22,824.67931
Overall Steps per Second: 10,687.67061

Timestep Collection Time: 2.19175
Timestep Consumption Time: 2.48897
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.68072

Cumulative Model Updates: 179,852
Cumulative Timesteps: 1,499,841,562

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,421.39307
Policy Entropy: 3.67563
Value Function Loss: 0.01842

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.14035
Policy Update Magnitude: 0.33432
Value Function Update Magnitude: 0.47462

Collected Steps per Second: 23,416.78329
Overall Steps per Second: 10,872.37361

Timestep Collection Time: 2.13539
Timestep Consumption Time: 2.46379
PPO Batch Consumption Time: 0.28482
Total Iteration Time: 4.59918

Cumulative Model Updates: 179,858
Cumulative Timesteps: 1,499,891,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1499891566...
Checkpoint 1499891566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,421.39307
Policy Entropy: 3.66648
Value Function Loss: 0.01861

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13616
Policy Update Magnitude: 0.31848
Value Function Update Magnitude: 0.51877

Collected Steps per Second: 22,636.68478
Overall Steps per Second: 10,654.11252

Timestep Collection Time: 2.21066
Timestep Consumption Time: 2.48631
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.69697

Cumulative Model Updates: 179,864
Cumulative Timesteps: 1,499,941,608

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,421.39307
Policy Entropy: 3.65185
Value Function Loss: 0.02004

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.14363
Policy Update Magnitude: 0.33227
Value Function Update Magnitude: 0.48349

Collected Steps per Second: 23,126.94840
Overall Steps per Second: 10,944.41816

Timestep Collection Time: 2.16241
Timestep Consumption Time: 2.40704
PPO Batch Consumption Time: 0.27581
Total Iteration Time: 4.56945

Cumulative Model Updates: 179,870
Cumulative Timesteps: 1,499,991,618

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1499991618...
Checkpoint 1499991618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,952.63644
Policy Entropy: 3.67092
Value Function Loss: 0.02375

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.33635
Value Function Update Magnitude: 0.39095

Collected Steps per Second: 22,657.59246
Overall Steps per Second: 10,660.92719

Timestep Collection Time: 2.20765
Timestep Consumption Time: 2.48425
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.69190

Cumulative Model Updates: 179,876
Cumulative Timesteps: 1,500,041,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,474.77822
Policy Entropy: 3.66899
Value Function Loss: 0.02523

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.14294
Policy Update Magnitude: 0.36590
Value Function Update Magnitude: 0.37059

Collected Steps per Second: 23,317.93506
Overall Steps per Second: 10,882.56411

Timestep Collection Time: 2.14487
Timestep Consumption Time: 2.45092
PPO Batch Consumption Time: 0.28545
Total Iteration Time: 4.59579

Cumulative Model Updates: 179,882
Cumulative Timesteps: 1,500,091,652

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1500091652...
Checkpoint 1500091652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 830,425.28481
Policy Entropy: 3.67941
Value Function Loss: 0.03404

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.41306
Value Function Update Magnitude: 0.45666

Collected Steps per Second: 21,953.57981
Overall Steps per Second: 10,665.94747

Timestep Collection Time: 2.27844
Timestep Consumption Time: 2.41125
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.68969

Cumulative Model Updates: 179,888
Cumulative Timesteps: 1,500,141,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,369.97866
Policy Entropy: 3.69620
Value Function Loss: 0.03668

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.44622
Value Function Update Magnitude: 0.70605

Collected Steps per Second: 22,503.75231
Overall Steps per Second: 10,860.92655

Timestep Collection Time: 2.22283
Timestep Consumption Time: 2.38286
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.60568

Cumulative Model Updates: 179,894
Cumulative Timesteps: 1,500,191,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1500191694...
Checkpoint 1500191694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,562.23882
Policy Entropy: 3.70730
Value Function Loss: 0.03876

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12877
Policy Update Magnitude: 0.47665
Value Function Update Magnitude: 0.91565

Collected Steps per Second: 21,915.39462
Overall Steps per Second: 10,614.14948

Timestep Collection Time: 2.28205
Timestep Consumption Time: 2.42977
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.71182

Cumulative Model Updates: 179,900
Cumulative Timesteps: 1,500,241,706

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,418.53643
Policy Entropy: 3.72606
Value Function Loss: 0.03385

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.49112
Value Function Update Magnitude: 0.88291

Collected Steps per Second: 22,429.15155
Overall Steps per Second: 10,919.85167

Timestep Collection Time: 2.23013
Timestep Consumption Time: 2.35051
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.58065

Cumulative Model Updates: 179,906
Cumulative Timesteps: 1,500,291,726

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1500291726...
Checkpoint 1500291726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,301.67097
Policy Entropy: 3.69681
Value Function Loss: 0.03290

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12393
Policy Update Magnitude: 0.47650
Value Function Update Magnitude: 0.79540

Collected Steps per Second: 22,195.00639
Overall Steps per Second: 10,689.66565

Timestep Collection Time: 2.25465
Timestep Consumption Time: 2.42669
PPO Batch Consumption Time: 0.28393
Total Iteration Time: 4.68134

Cumulative Model Updates: 179,912
Cumulative Timesteps: 1,500,341,768

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 217,119.84042
Policy Entropy: 3.69340
Value Function Loss: 0.03239

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.46324
Value Function Update Magnitude: 0.63435

Collected Steps per Second: 22,755.31701
Overall Steps per Second: 10,856.23796

Timestep Collection Time: 2.19790
Timestep Consumption Time: 2.40903
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.60694

Cumulative Model Updates: 179,918
Cumulative Timesteps: 1,500,391,782

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1500391782...
Checkpoint 1500391782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,441.66158
Policy Entropy: 3.66036
Value Function Loss: 0.03907

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.46780
Value Function Update Magnitude: 0.56155

Collected Steps per Second: 22,674.95997
Overall Steps per Second: 10,706.64728

Timestep Collection Time: 2.20631
Timestep Consumption Time: 2.46630
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.67261

Cumulative Model Updates: 179,924
Cumulative Timesteps: 1,500,441,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,920.88917
Policy Entropy: 3.66818
Value Function Loss: 0.03737

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.51052
Value Function Update Magnitude: 0.51768

Collected Steps per Second: 23,161.92465
Overall Steps per Second: 10,949.34898

Timestep Collection Time: 2.15880
Timestep Consumption Time: 2.40786
PPO Batch Consumption Time: 0.27549
Total Iteration Time: 4.56666

Cumulative Model Updates: 179,930
Cumulative Timesteps: 1,500,491,812

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1500491812...
Checkpoint 1500491812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,920.88917
Policy Entropy: 3.65292
Value Function Loss: 0.03552

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.48323
Value Function Update Magnitude: 0.46813

Collected Steps per Second: 22,704.18729
Overall Steps per Second: 10,689.83830

Timestep Collection Time: 2.20259
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.67809

Cumulative Model Updates: 179,936
Cumulative Timesteps: 1,500,541,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,920.88917
Policy Entropy: 3.66264
Value Function Loss: 0.02919

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12771
Policy Update Magnitude: 0.42347
Value Function Update Magnitude: 0.38137

Collected Steps per Second: 23,294.97044
Overall Steps per Second: 10,781.42757

Timestep Collection Time: 2.14690
Timestep Consumption Time: 2.49182
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.63872

Cumulative Model Updates: 179,942
Cumulative Timesteps: 1,500,591,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1500591832...
Checkpoint 1500591832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,920.88917
Policy Entropy: 3.66344
Value Function Loss: 0.02319

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.37274
Value Function Update Magnitude: 0.32324

Collected Steps per Second: 22,765.25666
Overall Steps per Second: 10,649.24536

Timestep Collection Time: 2.19800
Timestep Consumption Time: 2.50074
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.69874

Cumulative Model Updates: 179,948
Cumulative Timesteps: 1,500,641,870

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,920.88917
Policy Entropy: 3.65621
Value Function Loss: 0.02325

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.33946
Value Function Update Magnitude: 0.27374

Collected Steps per Second: 23,087.00351
Overall Steps per Second: 10,907.28764

Timestep Collection Time: 2.16711
Timestep Consumption Time: 2.41992
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.58702

Cumulative Model Updates: 179,954
Cumulative Timesteps: 1,500,691,902

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1500691902...
Checkpoint 1500691902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,920.88917
Policy Entropy: 3.66195
Value Function Loss: 0.02455

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12944
Policy Update Magnitude: 0.37744
Value Function Update Magnitude: 0.40484

Collected Steps per Second: 22,324.95787
Overall Steps per Second: 10,648.46051

Timestep Collection Time: 2.24081
Timestep Consumption Time: 2.45715
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.69796

Cumulative Model Updates: 179,960
Cumulative Timesteps: 1,500,741,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 353,812.75875
Policy Entropy: 3.66583
Value Function Loss: 0.02710

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.44223
Value Function Update Magnitude: 0.51033

Collected Steps per Second: 23,155.87290
Overall Steps per Second: 10,910.17458

Timestep Collection Time: 2.15937
Timestep Consumption Time: 2.42370
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.58306

Cumulative Model Updates: 179,966
Cumulative Timesteps: 1,500,791,930

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1500791930...
Checkpoint 1500791930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 292,861.65321
Policy Entropy: 3.69547
Value Function Loss: 0.02648

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12064
Policy Update Magnitude: 0.47154
Value Function Update Magnitude: 0.55444

Collected Steps per Second: 22,723.31863
Overall Steps per Second: 10,639.39079

Timestep Collection Time: 2.20082
Timestep Consumption Time: 2.49963
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.70046

Cumulative Model Updates: 179,972
Cumulative Timesteps: 1,500,841,940

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,719.38034
Policy Entropy: 3.70436
Value Function Loss: 0.02517

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06717
Policy Update Magnitude: 0.50421
Value Function Update Magnitude: 0.60813

Collected Steps per Second: 22,278.17355
Overall Steps per Second: 10,876.55173

Timestep Collection Time: 2.24489
Timestep Consumption Time: 2.35326
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.59815

Cumulative Model Updates: 179,978
Cumulative Timesteps: 1,500,891,952

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1500891952...
Checkpoint 1500891952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,852.39658
Policy Entropy: 3.70295
Value Function Loss: 0.02198

Mean KL Divergence: 0.00542
SB3 Clip Fraction: 0.06428
Policy Update Magnitude: 0.51849
Value Function Update Magnitude: 0.52733

Collected Steps per Second: 21,947.43111
Overall Steps per Second: 10,656.44611

Timestep Collection Time: 2.27936
Timestep Consumption Time: 2.41508
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69444

Cumulative Model Updates: 179,984
Cumulative Timesteps: 1,500,941,978

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,852.39658
Policy Entropy: 3.69798
Value Function Loss: 0.02135

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06175
Policy Update Magnitude: 0.51058
Value Function Update Magnitude: 0.43694

Collected Steps per Second: 22,243.85066
Overall Steps per Second: 10,866.52759

Timestep Collection Time: 2.24889
Timestep Consumption Time: 2.35460
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.60349

Cumulative Model Updates: 179,990
Cumulative Timesteps: 1,500,992,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1500992002...
Checkpoint 1500992002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,852.39658
Policy Entropy: 3.69880
Value Function Loss: 0.01907

Mean KL Divergence: 0.00681
SB3 Clip Fraction: 0.08573
Policy Update Magnitude: 0.47442
Value Function Update Magnitude: 0.40109

Collected Steps per Second: 22,034.52431
Overall Steps per Second: 10,747.73279

Timestep Collection Time: 2.26944
Timestep Consumption Time: 2.38326
PPO Batch Consumption Time: 0.27593
Total Iteration Time: 4.65270

Cumulative Model Updates: 179,996
Cumulative Timesteps: 1,501,042,008

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,479.71440
Policy Entropy: 3.67958
Value Function Loss: 0.02380

Mean KL Divergence: 0.01320
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.50071
Value Function Update Magnitude: 0.58861

Collected Steps per Second: 23,249.30093
Overall Steps per Second: 10,906.52960

Timestep Collection Time: 2.15275
Timestep Consumption Time: 2.43624
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.58899

Cumulative Model Updates: 180,002
Cumulative Timesteps: 1,501,092,058

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1501092058...
Checkpoint 1501092058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328,760.81334
Policy Entropy: 3.68149
Value Function Loss: 0.03159

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15035
Policy Update Magnitude: 0.59510
Value Function Update Magnitude: 0.63881

Collected Steps per Second: 22,264.43874
Overall Steps per Second: 10,634.98413

Timestep Collection Time: 2.24609
Timestep Consumption Time: 2.45612
PPO Batch Consumption Time: 0.28520
Total Iteration Time: 4.70222

Cumulative Model Updates: 180,008
Cumulative Timesteps: 1,501,142,066

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 266,297.89798
Policy Entropy: 3.68387
Value Function Loss: 0.03730

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12188
Policy Update Magnitude: 0.70330
Value Function Update Magnitude: 0.73101

Collected Steps per Second: 23,084.69463
Overall Steps per Second: 10,895.34331

Timestep Collection Time: 2.16698
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.59132

Cumulative Model Updates: 180,014
Cumulative Timesteps: 1,501,192,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1501192090...
Checkpoint 1501192090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 266,297.89798
Policy Entropy: 3.68573
Value Function Loss: 0.03686

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11357
Policy Update Magnitude: 0.75956
Value Function Update Magnitude: 0.73982

Collected Steps per Second: 22,589.72908
Overall Steps per Second: 10,610.37337

Timestep Collection Time: 2.21366
Timestep Consumption Time: 2.49927
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.71294

Cumulative Model Updates: 180,020
Cumulative Timesteps: 1,501,242,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 479,136.90260
Policy Entropy: 3.69775
Value Function Loss: 0.03166

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15520
Policy Update Magnitude: 0.70751
Value Function Update Magnitude: 0.72747

Collected Steps per Second: 22,944.81520
Overall Steps per Second: 10,875.58126

Timestep Collection Time: 2.18001
Timestep Consumption Time: 2.41928
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.59929

Cumulative Model Updates: 180,026
Cumulative Timesteps: 1,501,292,116

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1501292116...
Checkpoint 1501292116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,999.85150
Policy Entropy: 3.69274
Value Function Loss: 0.02853

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14868
Policy Update Magnitude: 0.52181
Value Function Update Magnitude: 0.64415

Collected Steps per Second: 22,340.24694
Overall Steps per Second: 10,753.91381

Timestep Collection Time: 2.23910
Timestep Consumption Time: 2.41242
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.65152

Cumulative Model Updates: 180,032
Cumulative Timesteps: 1,501,342,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328,716.88537
Policy Entropy: 3.70123
Value Function Loss: 0.02573

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.45129
Value Function Update Magnitude: 0.63549

Collected Steps per Second: 23,281.08299
Overall Steps per Second: 10,866.26925

Timestep Collection Time: 2.14878
Timestep Consumption Time: 2.45500
PPO Batch Consumption Time: 0.28325
Total Iteration Time: 4.60379

Cumulative Model Updates: 180,038
Cumulative Timesteps: 1,501,392,164

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1501392164...
Checkpoint 1501392164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 328,716.88537
Policy Entropy: 3.66301
Value Function Loss: 0.03281

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14021
Policy Update Magnitude: 0.49751
Value Function Update Magnitude: 0.65673

Collected Steps per Second: 22,623.98403
Overall Steps per Second: 10,615.72680

Timestep Collection Time: 2.21040
Timestep Consumption Time: 2.50035
PPO Batch Consumption Time: 0.29081
Total Iteration Time: 4.71075

Cumulative Model Updates: 180,044
Cumulative Timesteps: 1,501,442,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328,359.45473
Policy Entropy: 3.66539
Value Function Loss: 0.03752

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13439
Policy Update Magnitude: 0.54838
Value Function Update Magnitude: 0.74535

Collected Steps per Second: 22,012.98698
Overall Steps per Second: 10,843.18063

Timestep Collection Time: 2.27248
Timestep Consumption Time: 2.34093
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.61341

Cumulative Model Updates: 180,050
Cumulative Timesteps: 1,501,492,196

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1501492196...
Checkpoint 1501492196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,576.64300
Policy Entropy: 3.66731
Value Function Loss: 0.04136

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14212
Policy Update Magnitude: 0.58787
Value Function Update Magnitude: 0.72421

Collected Steps per Second: 21,828.22994
Overall Steps per Second: 10,724.38015

Timestep Collection Time: 2.29080
Timestep Consumption Time: 2.37185
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.66265

Cumulative Model Updates: 180,056
Cumulative Timesteps: 1,501,542,200

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,777.63335
Policy Entropy: 3.69348
Value Function Loss: 0.03767

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13780
Policy Update Magnitude: 0.59957
Value Function Update Magnitude: 0.68542

Collected Steps per Second: 22,356.61888
Overall Steps per Second: 10,876.29974

Timestep Collection Time: 2.23656
Timestep Consumption Time: 2.36077
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.59734

Cumulative Model Updates: 180,062
Cumulative Timesteps: 1,501,592,202

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1501592202...
Checkpoint 1501592202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,978.72271
Policy Entropy: 3.69084
Value Function Loss: 0.03552

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.53893
Value Function Update Magnitude: 0.57258

Collected Steps per Second: 21,929.28123
Overall Steps per Second: 10,722.71272

Timestep Collection Time: 2.28042
Timestep Consumption Time: 2.38332
PPO Batch Consumption Time: 0.27607
Total Iteration Time: 4.66375

Cumulative Model Updates: 180,068
Cumulative Timesteps: 1,501,642,210

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,978.72271
Policy Entropy: 3.66757
Value Function Loss: 0.03061

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13978
Policy Update Magnitude: 0.49503
Value Function Update Magnitude: 0.56055

Collected Steps per Second: 22,624.38015
Overall Steps per Second: 10,839.57605

Timestep Collection Time: 2.21071
Timestep Consumption Time: 2.40349
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.61420

Cumulative Model Updates: 180,074
Cumulative Timesteps: 1,501,692,226

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1501692226...
Checkpoint 1501692226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,978.72271
Policy Entropy: 3.65910
Value Function Loss: 0.02779

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.14123
Policy Update Magnitude: 0.43651
Value Function Update Magnitude: 0.48037

Collected Steps per Second: 22,940.28225
Overall Steps per Second: 10,787.04051

Timestep Collection Time: 2.18027
Timestep Consumption Time: 2.45641
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.63667

Cumulative Model Updates: 180,080
Cumulative Timesteps: 1,501,742,242

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,978.72271
Policy Entropy: 3.67522
Value Function Loss: 0.02079

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13393
Policy Update Magnitude: 0.36934
Value Function Update Magnitude: 0.35666

Collected Steps per Second: 22,819.53297
Overall Steps per Second: 10,754.33955

Timestep Collection Time: 2.19286
Timestep Consumption Time: 2.46015
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.65301

Cumulative Model Updates: 180,086
Cumulative Timesteps: 1,501,792,282

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1501792282...
Checkpoint 1501792282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,978.72271
Policy Entropy: 3.67952
Value Function Loss: 0.01975

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.13159
Policy Update Magnitude: 0.31826
Value Function Update Magnitude: 0.25829

Collected Steps per Second: 22,955.11728
Overall Steps per Second: 10,713.37617

Timestep Collection Time: 2.17895
Timestep Consumption Time: 2.48980
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.66874

Cumulative Model Updates: 180,092
Cumulative Timesteps: 1,501,842,300

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,978.72271
Policy Entropy: 3.66759
Value Function Loss: 0.02226

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.32473
Value Function Update Magnitude: 0.27041

Collected Steps per Second: 22,884.46547
Overall Steps per Second: 10,832.09796

Timestep Collection Time: 2.18611
Timestep Consumption Time: 2.43238
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.61850

Cumulative Model Updates: 180,098
Cumulative Timesteps: 1,501,892,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1501892328...
Checkpoint 1501892328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,978.72271
Policy Entropy: 3.66315
Value Function Loss: 0.02035

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.36123
Value Function Update Magnitude: 0.35575

Collected Steps per Second: 22,991.00730
Overall Steps per Second: 10,735.95820

Timestep Collection Time: 2.17520
Timestep Consumption Time: 2.48298
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.65818

Cumulative Model Updates: 180,104
Cumulative Timesteps: 1,501,942,338

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,978.72271
Policy Entropy: 3.67126
Value Function Loss: 0.01934

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.37070
Value Function Update Magnitude: 0.45073

Collected Steps per Second: 23,217.06860
Overall Steps per Second: 10,779.26072

Timestep Collection Time: 2.15540
Timestep Consumption Time: 2.48704
PPO Batch Consumption Time: 0.28764
Total Iteration Time: 4.64243

Cumulative Model Updates: 180,110
Cumulative Timesteps: 1,501,992,380

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1501992380...
Checkpoint 1501992380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,978.72271
Policy Entropy: 3.67386
Value Function Loss: 0.01770

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.34533
Value Function Update Magnitude: 0.36970

Collected Steps per Second: 22,534.38325
Overall Steps per Second: 10,667.99698

Timestep Collection Time: 2.21945
Timestep Consumption Time: 2.46878
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.68823

Cumulative Model Updates: 180,116
Cumulative Timesteps: 1,502,042,394

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,403.42039
Policy Entropy: 3.68862
Value Function Loss: 0.02071

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13277
Policy Update Magnitude: 0.33625
Value Function Update Magnitude: 0.36062

Collected Steps per Second: 22,391.48731
Overall Steps per Second: 10,927.62692

Timestep Collection Time: 2.23362
Timestep Consumption Time: 2.34322
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.57684

Cumulative Model Updates: 180,122
Cumulative Timesteps: 1,502,092,408

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1502092408...
Checkpoint 1502092408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,403.42039
Policy Entropy: 3.69696
Value Function Loss: 0.02286

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.36304
Value Function Update Magnitude: 0.40565

Collected Steps per Second: 22,251.92705
Overall Steps per Second: 10,756.09498

Timestep Collection Time: 2.24745
Timestep Consumption Time: 2.40201
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.64946

Cumulative Model Updates: 180,128
Cumulative Timesteps: 1,502,142,418

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,403.42039
Policy Entropy: 3.69514
Value Function Loss: 0.02301

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.40004
Value Function Update Magnitude: 0.49463

Collected Steps per Second: 22,244.80919
Overall Steps per Second: 10,725.95002

Timestep Collection Time: 2.24781
Timestep Consumption Time: 2.41397
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.66178

Cumulative Model Updates: 180,134
Cumulative Timesteps: 1,502,192,420

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1502192420...
Checkpoint 1502192420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,403.42039
Policy Entropy: 3.68190
Value Function Loss: 0.02088

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.38298
Value Function Update Magnitude: 0.49158

Collected Steps per Second: 22,691.27176
Overall Steps per Second: 10,712.68806

Timestep Collection Time: 2.20411
Timestep Consumption Time: 2.46456
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.66867

Cumulative Model Updates: 180,140
Cumulative Timesteps: 1,502,242,434

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,403.42039
Policy Entropy: 3.67189
Value Function Loss: 0.01986

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.34510
Value Function Update Magnitude: 0.38839

Collected Steps per Second: 23,051.40457
Overall Steps per Second: 10,951.31097

Timestep Collection Time: 2.17028
Timestep Consumption Time: 2.39794
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.56822

Cumulative Model Updates: 180,146
Cumulative Timesteps: 1,502,292,462

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1502292462...
Checkpoint 1502292462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,184.54834
Policy Entropy: 3.66345
Value Function Loss: 0.02096

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13099
Policy Update Magnitude: 0.32465
Value Function Update Magnitude: 0.34891

Collected Steps per Second: 22,647.53936
Overall Steps per Second: 10,625.65838

Timestep Collection Time: 2.20898
Timestep Consumption Time: 2.49924
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.70823

Cumulative Model Updates: 180,152
Cumulative Timesteps: 1,502,342,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 702,354.46606
Policy Entropy: 3.66719
Value Function Loss: 0.02174

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.38767
Value Function Update Magnitude: 0.41571

Collected Steps per Second: 22,767.24430
Overall Steps per Second: 10,833.71056

Timestep Collection Time: 2.19702
Timestep Consumption Time: 2.42005
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.61707

Cumulative Model Updates: 180,158
Cumulative Timesteps: 1,502,392,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1502392510...
Checkpoint 1502392510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262,566.74416
Policy Entropy: 3.68656
Value Function Loss: 0.02793

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13427
Policy Update Magnitude: 0.41857
Value Function Update Magnitude: 0.52375

Collected Steps per Second: 22,808.92032
Overall Steps per Second: 10,697.76443

Timestep Collection Time: 2.19274
Timestep Consumption Time: 2.48244
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.67518

Cumulative Model Updates: 180,164
Cumulative Timesteps: 1,502,442,524

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,657.58750
Policy Entropy: 3.71931
Value Function Loss: 0.02952

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12080
Policy Update Magnitude: 0.44811
Value Function Update Magnitude: 0.61847

Collected Steps per Second: 23,226.28642
Overall Steps per Second: 10,903.77563

Timestep Collection Time: 2.15282
Timestep Consumption Time: 2.43293
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.58575

Cumulative Model Updates: 180,170
Cumulative Timesteps: 1,502,492,526

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1502492526...
Checkpoint 1502492526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,359.34761
Policy Entropy: 3.72148
Value Function Loss: 0.03210

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.48842
Value Function Update Magnitude: 0.64305

Collected Steps per Second: 23,069.31705
Overall Steps per Second: 10,754.99067

Timestep Collection Time: 2.16781
Timestep Consumption Time: 2.48212
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.64993

Cumulative Model Updates: 180,176
Cumulative Timesteps: 1,502,542,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,577.74096
Policy Entropy: 3.70508
Value Function Loss: 0.03491

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12206
Policy Update Magnitude: 0.52389
Value Function Update Magnitude: 0.56919

Collected Steps per Second: 22,489.68724
Overall Steps per Second: 10,761.32768

Timestep Collection Time: 2.22404
Timestep Consumption Time: 2.42390
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.64794

Cumulative Model Updates: 180,182
Cumulative Timesteps: 1,502,592,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1502592554...
Checkpoint 1502592554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,630.95750
Policy Entropy: 3.69870
Value Function Loss: 0.03285

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13071
Policy Update Magnitude: 0.55991
Value Function Update Magnitude: 0.66523

Collected Steps per Second: 22,504.53047
Overall Steps per Second: 10,657.03984

Timestep Collection Time: 2.22195
Timestep Consumption Time: 2.47016
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.69211

Cumulative Model Updates: 180,188
Cumulative Timesteps: 1,502,642,558

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,935.92609
Policy Entropy: 3.67325
Value Function Loss: 0.03836

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13422
Policy Update Magnitude: 0.57365
Value Function Update Magnitude: 0.65442

Collected Steps per Second: 22,944.06283
Overall Steps per Second: 10,880.65994

Timestep Collection Time: 2.17921
Timestep Consumption Time: 2.41610
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.59531

Cumulative Model Updates: 180,194
Cumulative Timesteps: 1,502,692,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1502692558...
Checkpoint 1502692558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,387.61942
Policy Entropy: 3.70807
Value Function Loss: 0.04010

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.11953
Policy Update Magnitude: 0.55926
Value Function Update Magnitude: 0.61624

Collected Steps per Second: 22,577.06342
Overall Steps per Second: 10,702.61673

Timestep Collection Time: 2.21464
Timestep Consumption Time: 2.45712
PPO Batch Consumption Time: 0.28553
Total Iteration Time: 4.67175

Cumulative Model Updates: 180,200
Cumulative Timesteps: 1,502,742,558

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,210.46341
Policy Entropy: 3.71248
Value Function Loss: 0.04401

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.52962
Value Function Update Magnitude: 0.62776

Collected Steps per Second: 23,277.95479
Overall Steps per Second: 10,897.14901

Timestep Collection Time: 2.14924
Timestep Consumption Time: 2.44187
PPO Batch Consumption Time: 0.28304
Total Iteration Time: 4.59111

Cumulative Model Updates: 180,206
Cumulative Timesteps: 1,502,792,588

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1502792588...
Checkpoint 1502792588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 497.15925
Policy Entropy: 3.73723
Value Function Loss: 0.04073

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.53074
Value Function Update Magnitude: 0.57702

Collected Steps per Second: 22,040.37971
Overall Steps per Second: 10,678.32773

Timestep Collection Time: 2.26865
Timestep Consumption Time: 2.41391
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.68257

Cumulative Model Updates: 180,212
Cumulative Timesteps: 1,502,842,590

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88.35575
Policy Entropy: 3.71867
Value Function Loss: 0.03284

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.51406
Value Function Update Magnitude: 0.68988

Collected Steps per Second: 22,438.55811
Overall Steps per Second: 10,873.34997

Timestep Collection Time: 2.22893
Timestep Consumption Time: 2.37076
PPO Batch Consumption Time: 0.28153
Total Iteration Time: 4.59969

Cumulative Model Updates: 180,218
Cumulative Timesteps: 1,502,892,604

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1502892604...
Checkpoint 1502892604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,630.36078
Policy Entropy: 3.70776
Value Function Loss: 0.03737

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12593
Policy Update Magnitude: 0.55321
Value Function Update Magnitude: 0.86605

Collected Steps per Second: 22,086.41324
Overall Steps per Second: 10,663.96018

Timestep Collection Time: 2.26483
Timestep Consumption Time: 2.42592
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.69075

Cumulative Model Updates: 180,224
Cumulative Timesteps: 1,502,942,626

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,132.76969
Policy Entropy: 3.71588
Value Function Loss: 0.03728

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13566
Policy Update Magnitude: 0.58038
Value Function Update Magnitude: 0.92026

Collected Steps per Second: 22,270.40627
Overall Steps per Second: 10,895.15680

Timestep Collection Time: 2.24648
Timestep Consumption Time: 2.34547
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.59195

Cumulative Model Updates: 180,230
Cumulative Timesteps: 1,502,992,656

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1502992656...
Checkpoint 1502992656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,929.96745
Policy Entropy: 3.71220
Value Function Loss: 0.04324

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.57030
Value Function Update Magnitude: 0.86736

Collected Steps per Second: 22,209.51171
Overall Steps per Second: 10,626.57567

Timestep Collection Time: 2.25273
Timestep Consumption Time: 2.45547
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.70820

Cumulative Model Updates: 180,236
Cumulative Timesteps: 1,503,042,688

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,898.81456
Policy Entropy: 3.72563
Value Function Loss: 0.03849

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.58598
Value Function Update Magnitude: 0.84111

Collected Steps per Second: 22,796.40003
Overall Steps per Second: 10,892.33814

Timestep Collection Time: 2.19421
Timestep Consumption Time: 2.39801
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.59222

Cumulative Model Updates: 180,242
Cumulative Timesteps: 1,503,092,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1503092708...
Checkpoint 1503092708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257,393.61470
Policy Entropy: 3.70006
Value Function Loss: 0.03781

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.54371
Value Function Update Magnitude: 0.77783

Collected Steps per Second: 22,760.12171
Overall Steps per Second: 10,716.98948

Timestep Collection Time: 2.19718
Timestep Consumption Time: 2.46906
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.66624

Cumulative Model Updates: 180,248
Cumulative Timesteps: 1,503,142,716

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257,393.61470
Policy Entropy: 3.68877
Value Function Loss: 0.02836

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.49677
Value Function Update Magnitude: 0.68749

Collected Steps per Second: 22,892.87591
Overall Steps per Second: 10,872.88615

Timestep Collection Time: 2.18426
Timestep Consumption Time: 2.41470
PPO Batch Consumption Time: 0.27635
Total Iteration Time: 4.59896

Cumulative Model Updates: 180,254
Cumulative Timesteps: 1,503,192,720

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1503192720...
Checkpoint 1503192720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257,393.61470
Policy Entropy: 3.68948
Value Function Loss: 0.02316

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.40864
Value Function Update Magnitude: 0.51325

Collected Steps per Second: 22,848.82138
Overall Steps per Second: 10,669.60928

Timestep Collection Time: 2.18917
Timestep Consumption Time: 2.49891
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.68808

Cumulative Model Updates: 180,260
Cumulative Timesteps: 1,503,242,740

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257,393.61470
Policy Entropy: 3.68973
Value Function Loss: 0.01636

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.32951
Value Function Update Magnitude: 0.34279

Collected Steps per Second: 22,833.93720
Overall Steps per Second: 10,827.88301

Timestep Collection Time: 2.19060
Timestep Consumption Time: 2.42896
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.61955

Cumulative Model Updates: 180,266
Cumulative Timesteps: 1,503,292,760

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1503292760...
Checkpoint 1503292760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 274,658.19879
Policy Entropy: 3.69227
Value Function Loss: 0.02189

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12289
Policy Update Magnitude: 0.33061
Value Function Update Magnitude: 0.43375

Collected Steps per Second: 22,870.13782
Overall Steps per Second: 10,662.28243

Timestep Collection Time: 2.18687
Timestep Consumption Time: 2.50387
PPO Batch Consumption Time: 0.29115
Total Iteration Time: 4.69074

Cumulative Model Updates: 180,272
Cumulative Timesteps: 1,503,342,774

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,579.38313
Policy Entropy: 3.70936
Value Function Loss: 0.02412

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11946
Policy Update Magnitude: 0.45192
Value Function Update Magnitude: 0.61703

Collected Steps per Second: 22,598.71075
Overall Steps per Second: 10,679.28809

Timestep Collection Time: 2.21305
Timestep Consumption Time: 2.47004
PPO Batch Consumption Time: 0.28672
Total Iteration Time: 4.68308

Cumulative Model Updates: 180,278
Cumulative Timesteps: 1,503,392,786

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1503392786...
Checkpoint 1503392786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,862.15519
Policy Entropy: 3.69852
Value Function Loss: 0.02784

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.50914
Value Function Update Magnitude: 0.57043

Collected Steps per Second: 22,740.76492
Overall Steps per Second: 10,822.17112

Timestep Collection Time: 2.19993
Timestep Consumption Time: 2.42281
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.62273

Cumulative Model Updates: 180,284
Cumulative Timesteps: 1,503,442,814

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,862.15519
Policy Entropy: 3.70851
Value Function Loss: 0.02261

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12475
Policy Update Magnitude: 0.50107
Value Function Update Magnitude: 0.50345

Collected Steps per Second: 22,998.08161
Overall Steps per Second: 10,859.12060

Timestep Collection Time: 2.17453
Timestep Consumption Time: 2.43082
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.60535

Cumulative Model Updates: 180,290
Cumulative Timesteps: 1,503,492,824

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1503492824...
Checkpoint 1503492824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,862.15519
Policy Entropy: 3.67667
Value Function Loss: 0.02041

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13344
Policy Update Magnitude: 0.42799
Value Function Update Magnitude: 0.44167

Collected Steps per Second: 22,702.26786
Overall Steps per Second: 10,745.23386

Timestep Collection Time: 2.20348
Timestep Consumption Time: 2.45198
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.65546

Cumulative Model Updates: 180,296
Cumulative Timesteps: 1,503,542,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,862.15519
Policy Entropy: 3.67107
Value Function Loss: 0.01863

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.34587
Value Function Update Magnitude: 0.34365

Collected Steps per Second: 22,828.75901
Overall Steps per Second: 10,850.32994

Timestep Collection Time: 2.19022
Timestep Consumption Time: 2.41794
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.60815

Cumulative Model Updates: 180,302
Cumulative Timesteps: 1,503,592,848

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1503592848...
Checkpoint 1503592848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,862.15519
Policy Entropy: 3.65922
Value Function Loss: 0.02046

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.32151
Value Function Update Magnitude: 0.26621

Collected Steps per Second: 22,589.36157
Overall Steps per Second: 10,683.50715

Timestep Collection Time: 2.21414
Timestep Consumption Time: 2.46747
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.68161

Cumulative Model Updates: 180,308
Cumulative Timesteps: 1,503,642,864

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,862.15519
Policy Entropy: 3.67203
Value Function Loss: 0.02141

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.34353
Value Function Update Magnitude: 0.23201

Collected Steps per Second: 22,231.19267
Overall Steps per Second: 10,879.80449

Timestep Collection Time: 2.24936
Timestep Consumption Time: 2.34686
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.59622

Cumulative Model Updates: 180,314
Cumulative Timesteps: 1,503,692,870

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1503692870...
Checkpoint 1503692870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,862.15519
Policy Entropy: 3.66601
Value Function Loss: 0.02289

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.39226
Value Function Update Magnitude: 0.28325

Collected Steps per Second: 22,168.68944
Overall Steps per Second: 10,725.44318

Timestep Collection Time: 2.25552
Timestep Consumption Time: 2.40647
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.66200

Cumulative Model Updates: 180,320
Cumulative Timesteps: 1,503,742,872

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,555.15131
Policy Entropy: 3.68658
Value Function Loss: 0.02016

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.12164
Policy Update Magnitude: 0.42384
Value Function Update Magnitude: 0.50474

Collected Steps per Second: 22,497.30825
Overall Steps per Second: 10,811.98164

Timestep Collection Time: 2.22364
Timestep Consumption Time: 2.40326
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.62690

Cumulative Model Updates: 180,326
Cumulative Timesteps: 1,503,792,898

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1503792898...
Checkpoint 1503792898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,555.15131
Policy Entropy: 3.66946
Value Function Loss: 0.02116

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.41189
Value Function Update Magnitude: 0.60565

Collected Steps per Second: 22,845.14390
Overall Steps per Second: 10,775.56006

Timestep Collection Time: 2.18952
Timestep Consumption Time: 2.45246
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.64199

Cumulative Model Updates: 180,332
Cumulative Timesteps: 1,503,842,918

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,555.15131
Policy Entropy: 3.68419
Value Function Loss: 0.01909

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12462
Policy Update Magnitude: 0.39294
Value Function Update Magnitude: 0.54692

Collected Steps per Second: 23,112.21734
Overall Steps per Second: 10,820.06952

Timestep Collection Time: 2.16440
Timestep Consumption Time: 2.45886
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.62326

Cumulative Model Updates: 180,338
Cumulative Timesteps: 1,503,892,942

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1503892942...
Checkpoint 1503892942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,555.15131
Policy Entropy: 3.66323
Value Function Loss: 0.01957

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12700
Policy Update Magnitude: 0.36765
Value Function Update Magnitude: 0.45930

Collected Steps per Second: 22,949.53868
Overall Steps per Second: 10,755.55009

Timestep Collection Time: 2.17991
Timestep Consumption Time: 2.47145
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.65137

Cumulative Model Updates: 180,344
Cumulative Timesteps: 1,503,942,970

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,555.15131
Policy Entropy: 3.68047
Value Function Loss: 0.01789

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12904
Policy Update Magnitude: 0.37002
Value Function Update Magnitude: 0.45407

Collected Steps per Second: 22,987.38663
Overall Steps per Second: 10,792.66964

Timestep Collection Time: 2.17537
Timestep Consumption Time: 2.45796
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.63333

Cumulative Model Updates: 180,350
Cumulative Timesteps: 1,503,992,976

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1503992976...
Checkpoint 1503992976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 256,509.49245
Policy Entropy: 3.67957
Value Function Loss: 0.01881

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.37974
Value Function Update Magnitude: 0.53694

Collected Steps per Second: 22,885.74716
Overall Steps per Second: 10,705.12335

Timestep Collection Time: 2.18477
Timestep Consumption Time: 2.48589
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.67066

Cumulative Model Updates: 180,356
Cumulative Timesteps: 1,504,042,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,461.35711
Policy Entropy: 3.70779
Value Function Loss: 0.01863

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.39415
Value Function Update Magnitude: 0.60525

Collected Steps per Second: 22,946.49200
Overall Steps per Second: 10,889.20755

Timestep Collection Time: 2.17942
Timestep Consumption Time: 2.41320
PPO Batch Consumption Time: 0.27572
Total Iteration Time: 4.59262

Cumulative Model Updates: 180,362
Cumulative Timesteps: 1,504,092,986

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1504092986...
Checkpoint 1504092986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,543.98829
Policy Entropy: 3.69796
Value Function Loss: 0.02367

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.45140
Value Function Update Magnitude: 0.67593

Collected Steps per Second: 22,675.66091
Overall Steps per Second: 10,671.15240

Timestep Collection Time: 2.20642
Timestep Consumption Time: 2.48211
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.68853

Cumulative Model Updates: 180,368
Cumulative Timesteps: 1,504,143,018

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,543.98829
Policy Entropy: 3.68709
Value Function Loss: 0.02496

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.50838
Value Function Update Magnitude: 0.78911

Collected Steps per Second: 23,211.22348
Overall Steps per Second: 10,819.69557

Timestep Collection Time: 2.15465
Timestep Consumption Time: 2.46766
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.62231

Cumulative Model Updates: 180,374
Cumulative Timesteps: 1,504,193,030

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1504193030...
Checkpoint 1504193030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,543.98829
Policy Entropy: 3.66070
Value Function Loss: 0.02407

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.50176
Value Function Update Magnitude: 0.75719

Collected Steps per Second: 22,921.01823
Overall Steps per Second: 10,717.99693

Timestep Collection Time: 2.18193
Timestep Consumption Time: 2.48424
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.66617

Cumulative Model Updates: 180,380
Cumulative Timesteps: 1,504,243,042

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,927.94805
Policy Entropy: 3.68197
Value Function Loss: 0.02171

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.48015
Value Function Update Magnitude: 0.66877

Collected Steps per Second: 23,177.65953
Overall Steps per Second: 10,817.89590

Timestep Collection Time: 2.15846
Timestep Consumption Time: 2.46610
PPO Batch Consumption Time: 0.28502
Total Iteration Time: 4.62456

Cumulative Model Updates: 180,386
Cumulative Timesteps: 1,504,293,070

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1504293070...
Checkpoint 1504293070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,225.29840
Policy Entropy: 3.68665
Value Function Loss: 0.02020

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.43703
Value Function Update Magnitude: 0.67385

Collected Steps per Second: 22,724.94238
Overall Steps per Second: 10,634.40310

Timestep Collection Time: 2.20119
Timestep Consumption Time: 2.50260
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.70379

Cumulative Model Updates: 180,392
Cumulative Timesteps: 1,504,343,092

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,562.68636
Policy Entropy: 3.68969
Value Function Loss: 0.02193

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13250
Policy Update Magnitude: 0.42663
Value Function Update Magnitude: 0.72653

Collected Steps per Second: 22,867.66332
Overall Steps per Second: 10,835.42031

Timestep Collection Time: 2.18719
Timestep Consumption Time: 2.42878
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.61597

Cumulative Model Updates: 180,398
Cumulative Timesteps: 1,504,393,108

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1504393108...
Checkpoint 1504393108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,562.68636
Policy Entropy: 3.66322
Value Function Loss: 0.02337

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.41860
Value Function Update Magnitude: 0.66609

Collected Steps per Second: 22,698.36258
Overall Steps per Second: 10,666.96532

Timestep Collection Time: 2.20377
Timestep Consumption Time: 2.48566
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.68943

Cumulative Model Updates: 180,404
Cumulative Timesteps: 1,504,443,130

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,562.68636
Policy Entropy: 3.67185
Value Function Loss: 0.02198

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.44182
Value Function Update Magnitude: 0.49155

Collected Steps per Second: 22,954.35489
Overall Steps per Second: 10,894.49664

Timestep Collection Time: 2.18059
Timestep Consumption Time: 2.41384
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.59443

Cumulative Model Updates: 180,410
Cumulative Timesteps: 1,504,493,184

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1504493184...
Checkpoint 1504493184 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 296,277.36084
Policy Entropy: 3.64684
Value Function Loss: 0.04322

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.17695
Policy Update Magnitude: 0.49624
Value Function Update Magnitude: 0.43499

Collected Steps per Second: 22,868.37637
Overall Steps per Second: 10,698.74654

Timestep Collection Time: 2.18835
Timestep Consumption Time: 2.48921
PPO Batch Consumption Time: 0.28905
Total Iteration Time: 4.67756

Cumulative Model Updates: 180,416
Cumulative Timesteps: 1,504,543,228

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,582.17355
Policy Entropy: 3.63535
Value Function Loss: 0.06012

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.16589
Policy Update Magnitude: 0.61916
Value Function Update Magnitude: 0.51898

Collected Steps per Second: 22,683.08563
Overall Steps per Second: 10,702.35671

Timestep Collection Time: 2.20534
Timestep Consumption Time: 2.46877
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.67411

Cumulative Model Updates: 180,422
Cumulative Timesteps: 1,504,593,252

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1504593252...
Checkpoint 1504593252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,582.17355
Policy Entropy: 3.61312
Value Function Loss: 0.06524

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.15913
Policy Update Magnitude: 0.65822
Value Function Update Magnitude: 0.53770

Collected Steps per Second: 22,633.18689
Overall Steps per Second: 10,826.20151

Timestep Collection Time: 2.20932
Timestep Consumption Time: 2.40947
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.61879

Cumulative Model Updates: 180,428
Cumulative Timesteps: 1,504,643,256

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542,247.27154
Policy Entropy: 3.62271
Value Function Loss: 0.06635

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.64760
Value Function Update Magnitude: 0.48298

Collected Steps per Second: 22,468.66979
Overall Steps per Second: 10,672.18109

Timestep Collection Time: 2.22755
Timestep Consumption Time: 2.46222
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.68976

Cumulative Model Updates: 180,434
Cumulative Timesteps: 1,504,693,306

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1504693306...
Checkpoint 1504693306 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,391.29076
Policy Entropy: 3.65031
Value Function Loss: 0.06051

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.68702
Value Function Update Magnitude: 0.43964

Collected Steps per Second: 22,916.02370
Overall Steps per Second: 10,892.54065

Timestep Collection Time: 2.18258
Timestep Consumption Time: 2.40919
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.59177

Cumulative Model Updates: 180,440
Cumulative Timesteps: 1,504,743,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,391.29076
Policy Entropy: 3.62851
Value Function Loss: 0.06078

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.13991
Policy Update Magnitude: 0.67522
Value Function Update Magnitude: 0.39739

Collected Steps per Second: 22,700.57891
Overall Steps per Second: 10,827.88820

Timestep Collection Time: 2.20259
Timestep Consumption Time: 2.41512
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.61771

Cumulative Model Updates: 180,446
Cumulative Timesteps: 1,504,793,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1504793322...
Checkpoint 1504793322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,085.32943
Policy Entropy: 3.63693
Value Function Loss: 0.04975

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.65004
Value Function Update Magnitude: 0.41769

Collected Steps per Second: 22,022.91581
Overall Steps per Second: 10,702.25729

Timestep Collection Time: 2.27036
Timestep Consumption Time: 2.40155
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.67191

Cumulative Model Updates: 180,452
Cumulative Timesteps: 1,504,843,322

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,085.32943
Policy Entropy: 3.61979
Value Function Loss: 0.05418

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.61062
Value Function Update Magnitude: 0.39148

Collected Steps per Second: 21,971.96448
Overall Steps per Second: 10,669.54010

Timestep Collection Time: 2.27599
Timestep Consumption Time: 2.41100
PPO Batch Consumption Time: 0.28746
Total Iteration Time: 4.68699

Cumulative Model Updates: 180,458
Cumulative Timesteps: 1,504,893,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1504893330...
Checkpoint 1504893330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,085.32943
Policy Entropy: 3.63399
Value Function Loss: 0.04375

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14423
Policy Update Magnitude: 0.63220
Value Function Update Magnitude: 0.35527

Collected Steps per Second: 21,846.91353
Overall Steps per Second: 10,506.74274

Timestep Collection Time: 2.28884
Timestep Consumption Time: 2.47039
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.75923

Cumulative Model Updates: 180,464
Cumulative Timesteps: 1,504,943,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,085.32943
Policy Entropy: 3.65479
Value Function Loss: 0.03489

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14986
Policy Update Magnitude: 0.57033
Value Function Update Magnitude: 0.50278

Collected Steps per Second: 23,061.02552
Overall Steps per Second: 10,851.33191

Timestep Collection Time: 2.16816
Timestep Consumption Time: 2.43957
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.60773

Cumulative Model Updates: 180,470
Cumulative Timesteps: 1,504,993,334

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1504993334...
Checkpoint 1504993334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,085.32943
Policy Entropy: 3.66790
Value Function Loss: 0.03041

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13570
Policy Update Magnitude: 0.51675
Value Function Update Magnitude: 0.56433

Collected Steps per Second: 22,926.19327
Overall Steps per Second: 10,789.49978

Timestep Collection Time: 2.18100
Timestep Consumption Time: 2.45332
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.63432

Cumulative Model Updates: 180,476
Cumulative Timesteps: 1,505,043,336

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,859.53808
Policy Entropy: 3.67447
Value Function Loss: 0.02804

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.13966
Policy Update Magnitude: 0.54324
Value Function Update Magnitude: 0.67611

Collected Steps per Second: 23,288.92490
Overall Steps per Second: 10,746.38571

Timestep Collection Time: 2.14789
Timestep Consumption Time: 2.50689
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.65477

Cumulative Model Updates: 180,482
Cumulative Timesteps: 1,505,093,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1505093358...
Checkpoint 1505093358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,532.64571
Policy Entropy: 3.68285
Value Function Loss: 0.02913

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13835
Policy Update Magnitude: 0.52073
Value Function Update Magnitude: 0.71268

Collected Steps per Second: 23,161.31328
Overall Steps per Second: 10,761.61955

Timestep Collection Time: 2.16041
Timestep Consumption Time: 2.48926
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.64967

Cumulative Model Updates: 180,488
Cumulative Timesteps: 1,505,143,396

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.69924
Value Function Loss: 0.02771

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13035
Policy Update Magnitude: 0.47587
Value Function Update Magnitude: 0.59336

Collected Steps per Second: 23,099.73014
Overall Steps per Second: 10,791.68077

Timestep Collection Time: 2.16522
Timestep Consumption Time: 2.46946
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.63468

Cumulative Model Updates: 180,494
Cumulative Timesteps: 1,505,193,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1505193412...
Checkpoint 1505193412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.69822
Value Function Loss: 0.02551

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14481
Policy Update Magnitude: 0.43716
Value Function Update Magnitude: 0.52222

Collected Steps per Second: 22,802.62221
Overall Steps per Second: 10,661.74818

Timestep Collection Time: 2.19299
Timestep Consumption Time: 2.49723
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.69023

Cumulative Model Updates: 180,500
Cumulative Timesteps: 1,505,243,418

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.69666
Value Function Loss: 0.02093

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.39608
Value Function Update Magnitude: 0.47630

Collected Steps per Second: 22,930.16012
Overall Steps per Second: 10,860.66774

Timestep Collection Time: 2.18106
Timestep Consumption Time: 2.42382
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.60487

Cumulative Model Updates: 180,506
Cumulative Timesteps: 1,505,293,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1505293430...
Checkpoint 1505293430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.69380
Value Function Loss: 0.01874

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.36648
Value Function Update Magnitude: 0.39528

Collected Steps per Second: 22,979.08696
Overall Steps per Second: 10,723.28952

Timestep Collection Time: 2.17589
Timestep Consumption Time: 2.48686
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.66275

Cumulative Model Updates: 180,512
Cumulative Timesteps: 1,505,343,430

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.68190
Value Function Loss: 0.01679

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.34018
Value Function Update Magnitude: 0.30162

Collected Steps per Second: 23,084.17797
Overall Steps per Second: 10,924.37929

Timestep Collection Time: 2.16703
Timestep Consumption Time: 2.41209
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.57912

Cumulative Model Updates: 180,518
Cumulative Timesteps: 1,505,393,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1505393454...
Checkpoint 1505393454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.69564
Value Function Loss: 0.01557

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11619
Policy Update Magnitude: 0.33045
Value Function Update Magnitude: 0.24414

Collected Steps per Second: 23,076.52419
Overall Steps per Second: 10,771.62940

Timestep Collection Time: 2.16757
Timestep Consumption Time: 2.47611
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.64368

Cumulative Model Updates: 180,524
Cumulative Timesteps: 1,505,443,474

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.69239
Value Function Loss: 0.01534

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08331
Policy Update Magnitude: 0.35157
Value Function Update Magnitude: 0.28361

Collected Steps per Second: 23,080.30898
Overall Steps per Second: 10,700.68225

Timestep Collection Time: 2.16713
Timestep Consumption Time: 2.50715
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.67428

Cumulative Model Updates: 180,530
Cumulative Timesteps: 1,505,493,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1505493492...
Checkpoint 1505493492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.71993
Value Function Loss: 0.01270

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11158
Policy Update Magnitude: 0.35506
Value Function Update Magnitude: 0.31529

Collected Steps per Second: 23,115.68001
Overall Steps per Second: 10,766.32792

Timestep Collection Time: 2.16416
Timestep Consumption Time: 2.48237
PPO Batch Consumption Time: 0.29006
Total Iteration Time: 4.64652

Cumulative Model Updates: 180,536
Cumulative Timesteps: 1,505,543,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.70094
Value Function Loss: 0.01441

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10869
Policy Update Magnitude: 0.33718
Value Function Update Magnitude: 0.37867

Collected Steps per Second: 23,089.24331
Overall Steps per Second: 10,783.54439

Timestep Collection Time: 2.16742
Timestep Consumption Time: 2.47336
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.64077

Cumulative Model Updates: 180,542
Cumulative Timesteps: 1,505,593,562

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1505593562...
Checkpoint 1505593562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.70802
Value Function Loss: 0.01368

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06923
Policy Update Magnitude: 0.41046
Value Function Update Magnitude: 0.42447

Collected Steps per Second: 22,643.18385
Overall Steps per Second: 10,650.40254

Timestep Collection Time: 2.20905
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.69654

Cumulative Model Updates: 180,548
Cumulative Timesteps: 1,505,643,582

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.69645
Value Function Loss: 0.01413

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05823
Policy Update Magnitude: 0.45064
Value Function Update Magnitude: 0.39332

Collected Steps per Second: 23,157.08149
Overall Steps per Second: 10,917.79002

Timestep Collection Time: 2.15925
Timestep Consumption Time: 2.42061
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.57986

Cumulative Model Updates: 180,554
Cumulative Timesteps: 1,505,693,584

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1505693584...
Checkpoint 1505693584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.70515
Value Function Loss: 0.01332

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04257
Policy Update Magnitude: 0.44554
Value Function Update Magnitude: 0.33992

Collected Steps per Second: 22,971.86911
Overall Steps per Second: 10,729.35542

Timestep Collection Time: 2.17675
Timestep Consumption Time: 2.48374
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.66049

Cumulative Model Updates: 180,560
Cumulative Timesteps: 1,505,743,588

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.71466
Value Function Loss: 0.01383

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05492
Policy Update Magnitude: 0.43330
Value Function Update Magnitude: 0.35406

Collected Steps per Second: 22,148.67276
Overall Steps per Second: 10,792.49589

Timestep Collection Time: 2.25846
Timestep Consumption Time: 2.37642
PPO Batch Consumption Time: 0.28223
Total Iteration Time: 4.63489

Cumulative Model Updates: 180,566
Cumulative Timesteps: 1,505,793,610

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1505793610...
Checkpoint 1505793610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.71073
Value Function Loss: 0.01391

Mean KL Divergence: 0.00502
SB3 Clip Fraction: 0.05739
Policy Update Magnitude: 0.44744
Value Function Update Magnitude: 0.34339

Collected Steps per Second: 22,013.10893
Overall Steps per Second: 10,659.14812

Timestep Collection Time: 2.27228
Timestep Consumption Time: 2.42040
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.69268

Cumulative Model Updates: 180,572
Cumulative Timesteps: 1,505,843,630

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.70710
Value Function Loss: 0.01408

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06176
Policy Update Magnitude: 0.43358
Value Function Update Magnitude: 0.33946

Collected Steps per Second: 21,977.66569
Overall Steps per Second: 10,536.46656

Timestep Collection Time: 2.27622
Timestep Consumption Time: 2.47167
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.74789

Cumulative Model Updates: 180,578
Cumulative Timesteps: 1,505,893,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1505893656...
Checkpoint 1505893656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.69775
Value Function Loss: 0.01369

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05303
Policy Update Magnitude: 0.41679
Value Function Update Magnitude: 0.35488

Collected Steps per Second: 22,972.03453
Overall Steps per Second: 10,942.07669

Timestep Collection Time: 2.17656
Timestep Consumption Time: 2.39296
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.56952

Cumulative Model Updates: 180,584
Cumulative Timesteps: 1,505,943,656

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.68126
Value Function Loss: 0.01589

Mean KL Divergence: 0.00677
SB3 Clip Fraction: 0.08598
Policy Update Magnitude: 0.41403
Value Function Update Magnitude: 0.39964

Collected Steps per Second: 23,106.52206
Overall Steps per Second: 10,946.62717

Timestep Collection Time: 2.16450
Timestep Consumption Time: 2.40440
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.56890

Cumulative Model Updates: 180,590
Cumulative Timesteps: 1,505,993,670

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1505993670...
Checkpoint 1505993670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.67191
Value Function Loss: 0.02269

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.11780
Policy Update Magnitude: 0.51242
Value Function Update Magnitude: 0.42590

Collected Steps per Second: 22,730.73124
Overall Steps per Second: 10,659.90776

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.49131
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.69141

Cumulative Model Updates: 180,596
Cumulative Timesteps: 1,506,043,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.66167
Value Function Loss: 0.02376

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.19603
Policy Update Magnitude: 0.51906
Value Function Update Magnitude: 0.35059

Collected Steps per Second: 22,992.41240
Overall Steps per Second: 10,892.74717

Timestep Collection Time: 2.17489
Timestep Consumption Time: 2.41587
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.59076

Cumulative Model Updates: 180,602
Cumulative Timesteps: 1,506,093,686

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1506093686...
Checkpoint 1506093686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,182.48045
Policy Entropy: 3.69869
Value Function Loss: 0.01860

Mean KL Divergence: 0.01940
SB3 Clip Fraction: 0.23386
Policy Update Magnitude: 0.46467
Value Function Update Magnitude: 0.36785

Collected Steps per Second: 22,577.49132
Overall Steps per Second: 10,684.62479

Timestep Collection Time: 2.21584
Timestep Consumption Time: 2.46641
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.68224

Cumulative Model Updates: 180,608
Cumulative Timesteps: 1,506,143,714

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,824.15038
Policy Entropy: 3.71544
Value Function Loss: 0.01552

Mean KL Divergence: 0.01764
SB3 Clip Fraction: 0.21502
Policy Update Magnitude: 0.41871
Value Function Update Magnitude: 0.42315

Collected Steps per Second: 23,042.80615
Overall Steps per Second: 10,880.65834

Timestep Collection Time: 2.17005
Timestep Consumption Time: 2.42563
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.59568

Cumulative Model Updates: 180,614
Cumulative Timesteps: 1,506,193,718

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1506193718...
Checkpoint 1506193718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,999.21985
Policy Entropy: 3.70877
Value Function Loss: 0.01556

Mean KL Divergence: 0.01837
SB3 Clip Fraction: 0.21694
Policy Update Magnitude: 0.37598
Value Function Update Magnitude: 0.53855

Collected Steps per Second: 22,656.94502
Overall Steps per Second: 10,664.12363

Timestep Collection Time: 2.20701
Timestep Consumption Time: 2.48199
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.68899

Cumulative Model Updates: 180,620
Cumulative Timesteps: 1,506,243,722

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,999.21985
Policy Entropy: 3.68536
Value Function Loss: 0.01772

Mean KL Divergence: 0.01692
SB3 Clip Fraction: 0.20284
Policy Update Magnitude: 0.39093
Value Function Update Magnitude: 0.64143

Collected Steps per Second: 23,183.12161
Overall Steps per Second: 10,910.53775

Timestep Collection Time: 2.15924
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.58804

Cumulative Model Updates: 180,626
Cumulative Timesteps: 1,506,293,780

Timesteps Collected: 50,058
--------END ITERATION REPORT--------


Saving checkpoint 1506293780...
Checkpoint 1506293780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,078.55757
Policy Entropy: 3.66325
Value Function Loss: 0.02288

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16603
Policy Update Magnitude: 0.46718
Value Function Update Magnitude: 0.73580

Collected Steps per Second: 22,531.26429
Overall Steps per Second: 10,670.41394

Timestep Collection Time: 2.21985
Timestep Consumption Time: 2.46750
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.68735

Cumulative Model Updates: 180,632
Cumulative Timesteps: 1,506,343,796

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,078.55757
Policy Entropy: 3.66025
Value Function Loss: 0.02778

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.49379
Value Function Update Magnitude: 0.75330

Collected Steps per Second: 22,867.00426
Overall Steps per Second: 10,835.18953

Timestep Collection Time: 2.18734
Timestep Consumption Time: 2.42891
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.61626

Cumulative Model Updates: 180,638
Cumulative Timesteps: 1,506,393,814

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1506393814...
Checkpoint 1506393814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,078.55757
Policy Entropy: 3.65910
Value Function Loss: 0.02564

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16647
Policy Update Magnitude: 0.57184
Value Function Update Magnitude: 0.73917

Collected Steps per Second: 22,555.09102
Overall Steps per Second: 10,673.95542

Timestep Collection Time: 2.21812
Timestep Consumption Time: 2.46899
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.68711

Cumulative Model Updates: 180,644
Cumulative Timesteps: 1,506,443,844

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 682,178.85564
Policy Entropy: 3.62416
Value Function Loss: 0.04826

Mean KL Divergence: 0.03696
SB3 Clip Fraction: 0.31734
Policy Update Magnitude: 0.53082
Value Function Update Magnitude: 0.65347

Collected Steps per Second: 23,064.41602
Overall Steps per Second: 10,915.47722

Timestep Collection Time: 2.16862
Timestep Consumption Time: 2.41368
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.58230

Cumulative Model Updates: 180,650
Cumulative Timesteps: 1,506,493,862

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1506493862...
Checkpoint 1506493862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,214.47902
Policy Entropy: 3.62570
Value Function Loss: 0.07052

Mean KL Divergence: 0.02163
SB3 Clip Fraction: 0.22682
Policy Update Magnitude: 0.65200
Value Function Update Magnitude: 0.63083

Collected Steps per Second: 22,592.77272
Overall Steps per Second: 10,663.22801

Timestep Collection Time: 2.21381
Timestep Consumption Time: 2.47671
PPO Batch Consumption Time: 0.28976
Total Iteration Time: 4.69051

Cumulative Model Updates: 180,656
Cumulative Timesteps: 1,506,543,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 518,779.08405
Policy Entropy: 3.61656
Value Function Loss: 0.10368

Mean KL Divergence: 0.02036
SB3 Clip Fraction: 0.21163
Policy Update Magnitude: 0.79703
Value Function Update Magnitude: 0.63438

Collected Steps per Second: 22,327.12102
Overall Steps per Second: 10,592.77128

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.72265

Cumulative Model Updates: 180,662
Cumulative Timesteps: 1,506,593,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1506593904...
Checkpoint 1506593904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,603.27362
Policy Entropy: 3.69825
Value Function Loss: 0.10454

Mean KL Divergence: 0.01520
SB3 Clip Fraction: 0.18567
Policy Update Magnitude: 0.80402
Value Function Update Magnitude: 0.52468

Collected Steps per Second: 22,479.65198
Overall Steps per Second: 10,602.89978

Timestep Collection Time: 2.22459
Timestep Consumption Time: 2.49186
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.71645

Cumulative Model Updates: 180,668
Cumulative Timesteps: 1,506,643,912

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,275.68058
Policy Entropy: 3.69294
Value Function Loss: 0.09449

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.17846
Policy Update Magnitude: 0.76652
Value Function Update Magnitude: 0.46814

Collected Steps per Second: 22,999.62566
Overall Steps per Second: 10,822.90270

Timestep Collection Time: 2.17421
Timestep Consumption Time: 2.44618
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.62039

Cumulative Model Updates: 180,674
Cumulative Timesteps: 1,506,693,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1506693918...
Checkpoint 1506693918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,168.52159
Policy Entropy: 3.69806
Value Function Loss: 0.06841

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.16553
Policy Update Magnitude: 0.67546
Value Function Update Magnitude: 0.45922

Collected Steps per Second: 22,833.93917
Overall Steps per Second: 10,720.93222

Timestep Collection Time: 2.19069
Timestep Consumption Time: 2.47514
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.66583

Cumulative Model Updates: 180,680
Cumulative Timesteps: 1,506,743,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,411.75761
Policy Entropy: 3.66137
Value Function Loss: 0.06796

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 0.61220
Value Function Update Magnitude: 0.42230

Collected Steps per Second: 22,471.27120
Overall Steps per Second: 10,786.41201

Timestep Collection Time: 2.22640
Timestep Consumption Time: 2.41184
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.63824

Cumulative Model Updates: 180,686
Cumulative Timesteps: 1,506,793,970

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1506793970...
Checkpoint 1506793970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,828.11749
Policy Entropy: 3.68531
Value Function Loss: 0.05510

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12809
Policy Update Magnitude: 0.69632
Value Function Update Magnitude: 0.41554

Collected Steps per Second: 22,038.65393
Overall Steps per Second: 10,639.54544

Timestep Collection Time: 2.26910
Timestep Consumption Time: 2.43110
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.70020

Cumulative Model Updates: 180,692
Cumulative Timesteps: 1,506,843,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 365.80543
Policy Entropy: 3.68388
Value Function Loss: 0.06389

Mean KL Divergence: 0.01092
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.71840
Value Function Update Magnitude: 0.56379

Collected Steps per Second: 22,284.59862
Overall Steps per Second: 10,904.58763

Timestep Collection Time: 2.24451
Timestep Consumption Time: 2.34237
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.58688

Cumulative Model Updates: 180,698
Cumulative Timesteps: 1,506,893,996

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1506893996...
Checkpoint 1506893996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,469.35449
Policy Entropy: 3.71226
Value Function Loss: 0.05488

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.69491
Value Function Update Magnitude: 0.54823

Collected Steps per Second: 21,954.55698
Overall Steps per Second: 10,666.06724

Timestep Collection Time: 2.27798
Timestep Consumption Time: 2.41091
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.68889

Cumulative Model Updates: 180,704
Cumulative Timesteps: 1,506,944,008

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,354.89849
Policy Entropy: 3.69147
Value Function Loss: 0.06344

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14242
Policy Update Magnitude: 0.67688
Value Function Update Magnitude: 0.56165

Collected Steps per Second: 22,340.52620
Overall Steps per Second: 10,891.77176

Timestep Collection Time: 2.23826
Timestep Consumption Time: 2.35272
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.59099

Cumulative Model Updates: 180,710
Cumulative Timesteps: 1,506,994,012

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1506994012...
Checkpoint 1506994012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,312.89362
Policy Entropy: 3.70930
Value Function Loss: 0.06000

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.66103
Value Function Update Magnitude: 0.58082

Collected Steps per Second: 21,901.30100
Overall Steps per Second: 10,653.87928

Timestep Collection Time: 2.28297
Timestep Consumption Time: 2.41016
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.69313

Cumulative Model Updates: 180,716
Cumulative Timesteps: 1,507,044,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,823.42685
Policy Entropy: 3.70899
Value Function Loss: 0.04983

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.61425
Value Function Update Magnitude: 0.55978

Collected Steps per Second: 23,116.03890
Overall Steps per Second: 10,921.01054

Timestep Collection Time: 2.16326
Timestep Consumption Time: 2.41562
PPO Batch Consumption Time: 0.28076
Total Iteration Time: 4.57888

Cumulative Model Updates: 180,722
Cumulative Timesteps: 1,507,094,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1507094018...
Checkpoint 1507094018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,823.42685
Policy Entropy: 3.71039
Value Function Loss: 0.03343

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 0.54393
Value Function Update Magnitude: 0.53916

Collected Steps per Second: 22,795.27193
Overall Steps per Second: 10,756.64583

Timestep Collection Time: 2.19388
Timestep Consumption Time: 2.45534
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.64922

Cumulative Model Updates: 180,728
Cumulative Timesteps: 1,507,144,028

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,823.42685
Policy Entropy: 3.70536
Value Function Loss: 0.02263

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.46204
Value Function Update Magnitude: 0.48778

Collected Steps per Second: 23,261.08766
Overall Steps per Second: 10,759.49571

Timestep Collection Time: 2.15020
Timestep Consumption Time: 2.49834
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.64855

Cumulative Model Updates: 180,734
Cumulative Timesteps: 1,507,194,044

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1507194044...
Checkpoint 1507194044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,375.71054
Policy Entropy: 3.71053
Value Function Loss: 0.01963

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07814
Policy Update Magnitude: 0.45443
Value Function Update Magnitude: 0.43796

Collected Steps per Second: 22,644.49037
Overall Steps per Second: 10,625.34091

Timestep Collection Time: 2.20875
Timestep Consumption Time: 2.49849
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.70724

Cumulative Model Updates: 180,740
Cumulative Timesteps: 1,507,244,060

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,758.57652
Policy Entropy: 3.69996
Value Function Loss: 0.02010

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.43952
Value Function Update Magnitude: 0.50329

Collected Steps per Second: 23,341.09660
Overall Steps per Second: 10,942.08903

Timestep Collection Time: 2.14412
Timestep Consumption Time: 2.42960
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.57372

Cumulative Model Updates: 180,746
Cumulative Timesteps: 1,507,294,106

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1507294106...
Checkpoint 1507294106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,758.57652
Policy Entropy: 3.72264
Value Function Loss: 0.02105

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09174
Policy Update Magnitude: 0.52676
Value Function Update Magnitude: 0.54289

Collected Steps per Second: 22,689.45113
Overall Steps per Second: 10,670.29801

Timestep Collection Time: 2.20455
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.68778

Cumulative Model Updates: 180,752
Cumulative Timesteps: 1,507,344,126

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,758.57652
Policy Entropy: 3.72097
Value Function Loss: 0.02292

Mean KL Divergence: 0.01804
SB3 Clip Fraction: 0.21508
Policy Update Magnitude: 0.56204
Value Function Update Magnitude: 0.64604

Collected Steps per Second: 23,027.53218
Overall Steps per Second: 10,919.09133

Timestep Collection Time: 2.17236
Timestep Consumption Time: 2.40898
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.58133

Cumulative Model Updates: 180,758
Cumulative Timesteps: 1,507,394,150

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1507394150...
Checkpoint 1507394150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,812.13054
Policy Entropy: 3.71912
Value Function Loss: 0.04080

Mean KL Divergence: 0.02283
SB3 Clip Fraction: 0.24799
Policy Update Magnitude: 0.59724
Value Function Update Magnitude: 0.62661

Collected Steps per Second: 22,772.15885
Overall Steps per Second: 10,689.22917

Timestep Collection Time: 2.19637
Timestep Consumption Time: 2.48274
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.67910

Cumulative Model Updates: 180,764
Cumulative Timesteps: 1,507,444,166

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 198,128.57521
Policy Entropy: 3.73056
Value Function Loss: 0.04691

Mean KL Divergence: 0.01718
SB3 Clip Fraction: 0.19997
Policy Update Magnitude: 0.75553
Value Function Update Magnitude: 0.76900

Collected Steps per Second: 22,022.64727
Overall Steps per Second: 10,876.22877

Timestep Collection Time: 2.27048
Timestep Consumption Time: 2.32688
PPO Batch Consumption Time: 0.27629
Total Iteration Time: 4.59737

Cumulative Model Updates: 180,770
Cumulative Timesteps: 1,507,494,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1507494168...
Checkpoint 1507494168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,791.09192
Policy Entropy: 3.73221
Value Function Loss: 0.05329

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.76739
Value Function Update Magnitude: 0.79966

Collected Steps per Second: 21,822.92288
Overall Steps per Second: 10,616.30527

Timestep Collection Time: 2.29254
Timestep Consumption Time: 2.42002
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.71256

Cumulative Model Updates: 180,776
Cumulative Timesteps: 1,507,544,198

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,350.97393
Policy Entropy: 3.75803
Value Function Loss: 0.04193

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.16173
Policy Update Magnitude: 0.71269
Value Function Update Magnitude: 0.81024

Collected Steps per Second: 22,355.11943
Overall Steps per Second: 10,863.04787

Timestep Collection Time: 2.23752
Timestep Consumption Time: 2.36708
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.60460

Cumulative Model Updates: 180,782
Cumulative Timesteps: 1,507,594,218

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1507594218...
Checkpoint 1507594218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,600.77711
Policy Entropy: 3.70697
Value Function Loss: 0.04512

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14116
Policy Update Magnitude: 0.67888
Value Function Update Magnitude: 0.77059

Collected Steps per Second: 21,996.62714
Overall Steps per Second: 10,619.94626

Timestep Collection Time: 2.27362
Timestep Consumption Time: 2.43563
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.70925

Cumulative Model Updates: 180,788
Cumulative Timesteps: 1,507,644,230

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,911.42597
Policy Entropy: 3.74327
Value Function Loss: 0.04132

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13789
Policy Update Magnitude: 0.63942
Value Function Update Magnitude: 0.78500

Collected Steps per Second: 22,369.07598
Overall Steps per Second: 10,669.99612

Timestep Collection Time: 2.23648
Timestep Consumption Time: 2.45218
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.68866

Cumulative Model Updates: 180,794
Cumulative Timesteps: 1,507,694,258

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1507694258...
Checkpoint 1507694258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,339.90524
Policy Entropy: 3.71263
Value Function Loss: 0.04456

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.56089
Value Function Update Magnitude: 0.67262

Collected Steps per Second: 22,798.89405
Overall Steps per Second: 10,941.08347

Timestep Collection Time: 2.19370
Timestep Consumption Time: 2.37751
PPO Batch Consumption Time: 0.27561
Total Iteration Time: 4.57121

Cumulative Model Updates: 180,800
Cumulative Timesteps: 1,507,744,272

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,519.65333
Policy Entropy: 3.71789
Value Function Loss: 0.03465

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14383
Policy Update Magnitude: 0.49799
Value Function Update Magnitude: 0.59549

Collected Steps per Second: 22,907.97315
Overall Steps per Second: 10,902.63996

Timestep Collection Time: 2.18300
Timestep Consumption Time: 2.40378
PPO Batch Consumption Time: 0.27691
Total Iteration Time: 4.58678

Cumulative Model Updates: 180,806
Cumulative Timesteps: 1,507,794,280

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1507794280...
Checkpoint 1507794280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.43467
Policy Entropy: 3.66662
Value Function Loss: 0.03051

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.42994
Value Function Update Magnitude: 0.54302

Collected Steps per Second: 22,994.96844
Overall Steps per Second: 10,741.28642

Timestep Collection Time: 2.17517
Timestep Consumption Time: 2.48144
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.65661

Cumulative Model Updates: 180,812
Cumulative Timesteps: 1,507,844,298

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.43467
Policy Entropy: 3.67869
Value Function Loss: 0.02442

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.40650
Value Function Update Magnitude: 0.52591

Collected Steps per Second: 23,111.37124
Overall Steps per Second: 10,786.71376

Timestep Collection Time: 2.16508
Timestep Consumption Time: 2.47377
PPO Batch Consumption Time: 0.28653
Total Iteration Time: 4.63885

Cumulative Model Updates: 180,818
Cumulative Timesteps: 1,507,894,336

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1507894336...
Checkpoint 1507894336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,670.34595
Policy Entropy: 3.67843
Value Function Loss: 0.02492

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.40494
Value Function Update Magnitude: 0.42357

Collected Steps per Second: 22,693.32401
Overall Steps per Second: 10,669.36065

Timestep Collection Time: 2.20426
Timestep Consumption Time: 2.48412
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.68838

Cumulative Model Updates: 180,824
Cumulative Timesteps: 1,507,944,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,986.35967
Policy Entropy: 3.69115
Value Function Loss: 0.02407

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13846
Policy Update Magnitude: 0.44666
Value Function Update Magnitude: 0.51911

Collected Steps per Second: 23,309.52345
Overall Steps per Second: 10,855.58355

Timestep Collection Time: 2.14513
Timestep Consumption Time: 2.46098
PPO Batch Consumption Time: 0.28348
Total Iteration Time: 4.60611

Cumulative Model Updates: 180,830
Cumulative Timesteps: 1,507,994,360

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1507994360...
Checkpoint 1507994360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,986.35967
Policy Entropy: 3.69565
Value Function Loss: 0.02414

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.12867
Policy Update Magnitude: 0.46818
Value Function Update Magnitude: 0.55930

Collected Steps per Second: 22,629.38590
Overall Steps per Second: 10,619.90850

Timestep Collection Time: 2.21058
Timestep Consumption Time: 2.49982
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.71040

Cumulative Model Updates: 180,836
Cumulative Timesteps: 1,508,044,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 622,656.34550
Policy Entropy: 3.67452
Value Function Loss: 0.02545

Mean KL Divergence: 0.02289
SB3 Clip Fraction: 0.26505
Policy Update Magnitude: 0.41272
Value Function Update Magnitude: 0.49200

Collected Steps per Second: 23,120.55578
Overall Steps per Second: 10,883.72955

Timestep Collection Time: 2.16336
Timestep Consumption Time: 2.43231
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.59567

Cumulative Model Updates: 180,842
Cumulative Timesteps: 1,508,094,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1508094402...
Checkpoint 1508094402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,932.06425
Policy Entropy: 3.65707
Value Function Loss: 0.05679

Mean KL Divergence: 0.01846
SB3 Clip Fraction: 0.22345
Policy Update Magnitude: 0.45999
Value Function Update Magnitude: 0.53282

Collected Steps per Second: 22,302.73114
Overall Steps per Second: 10,686.47420

Timestep Collection Time: 2.24367
Timestep Consumption Time: 2.43888
PPO Batch Consumption Time: 0.28163
Total Iteration Time: 4.68255

Cumulative Model Updates: 180,848
Cumulative Timesteps: 1,508,144,442

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,757.10737
Policy Entropy: 3.68192
Value Function Loss: 0.07787

Mean KL Divergence: 0.01925
SB3 Clip Fraction: 0.20942
Policy Update Magnitude: 0.62274
Value Function Update Magnitude: 0.59171

Collected Steps per Second: 22,648.61900
Overall Steps per Second: 10,790.80129

Timestep Collection Time: 2.20888
Timestep Consumption Time: 2.42729
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.63617

Cumulative Model Updates: 180,854
Cumulative Timesteps: 1,508,194,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1508194470...
Checkpoint 1508194470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,854.51652
Policy Entropy: 3.71106
Value Function Loss: 0.11077

Mean KL Divergence: 0.02060
SB3 Clip Fraction: 0.21303
Policy Update Magnitude: 0.70657
Value Function Update Magnitude: 0.60049

Collected Steps per Second: 22,270.53892
Overall Steps per Second: 10,691.35826

Timestep Collection Time: 2.24611
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.67873

Cumulative Model Updates: 180,860
Cumulative Timesteps: 1,508,244,492

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,347.34710
Policy Entropy: 3.76001
Value Function Loss: 0.09506

Mean KL Divergence: 0.01570
SB3 Clip Fraction: 0.18305
Policy Update Magnitude: 0.71978
Value Function Update Magnitude: 0.57038

Collected Steps per Second: 22,842.60112
Overall Steps per Second: 10,890.91214

Timestep Collection Time: 2.19003
Timestep Consumption Time: 2.40334
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.59337

Cumulative Model Updates: 180,866
Cumulative Timesteps: 1,508,294,518

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1508294518...
Checkpoint 1508294518 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,910.08026
Policy Entropy: 3.76194
Value Function Loss: 0.10243

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.17461
Policy Update Magnitude: 0.80476
Value Function Update Magnitude: 0.61527

Collected Steps per Second: 22,576.84516
Overall Steps per Second: 10,746.42790

Timestep Collection Time: 2.21537
Timestep Consumption Time: 2.43883
PPO Batch Consumption Time: 0.28739
Total Iteration Time: 4.65420

Cumulative Model Updates: 180,872
Cumulative Timesteps: 1,508,344,534

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,062.69614
Policy Entropy: 3.81802
Value Function Loss: 0.10423

Mean KL Divergence: 0.01891
SB3 Clip Fraction: 0.19537
Policy Update Magnitude: 1.07225
Value Function Update Magnitude: 0.68238

Collected Steps per Second: 22,873.85367
Overall Steps per Second: 10,888.81765

Timestep Collection Time: 2.18616
Timestep Consumption Time: 2.40625
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.59242

Cumulative Model Updates: 180,878
Cumulative Timesteps: 1,508,394,540

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1508394540...
Checkpoint 1508394540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,791.31390
Policy Entropy: 3.86485
Value Function Loss: 0.10390

Mean KL Divergence: 0.01774
SB3 Clip Fraction: 0.18248
Policy Update Magnitude: 1.05813
Value Function Update Magnitude: 0.66603

Collected Steps per Second: 22,318.96053
Overall Steps per Second: 10,765.83708

Timestep Collection Time: 2.24025
Timestep Consumption Time: 2.40407
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.64432

Cumulative Model Updates: 180,884
Cumulative Timesteps: 1,508,444,540

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,326.54895
Policy Entropy: 3.92824
Value Function Loss: 0.08856

Mean KL Divergence: 0.01399
SB3 Clip Fraction: 0.15056
Policy Update Magnitude: 1.11214
Value Function Update Magnitude: 0.65414

Collected Steps per Second: 22,665.35534
Overall Steps per Second: 10,782.47189

Timestep Collection Time: 2.20672
Timestep Consumption Time: 2.43192
PPO Batch Consumption Time: 0.29308
Total Iteration Time: 4.63864

Cumulative Model Updates: 180,890
Cumulative Timesteps: 1,508,494,556

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1508494556...
Checkpoint 1508494556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.89800
Policy Entropy: 3.95610
Value Function Loss: 0.08026

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.11295
Policy Update Magnitude: 1.24127
Value Function Update Magnitude: 0.71161

Collected Steps per Second: 22,689.83381
Overall Steps per Second: 10,650.37090

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.69730

Cumulative Model Updates: 180,896
Cumulative Timesteps: 1,508,544,584

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,016.04707
Policy Entropy: 3.93833
Value Function Loss: 0.07378

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.11261
Policy Update Magnitude: 1.40007
Value Function Update Magnitude: 0.66744

Collected Steps per Second: 23,079.48331
Overall Steps per Second: 10,860.44206

Timestep Collection Time: 2.16807
Timestep Consumption Time: 2.43929
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.60736

Cumulative Model Updates: 180,902
Cumulative Timesteps: 1,508,594,622

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1508594622...
Checkpoint 1508594622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,898.81297
Policy Entropy: 3.86027
Value Function Loss: 0.07746

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.11110
Policy Update Magnitude: 1.35989
Value Function Update Magnitude: 0.67642

Collected Steps per Second: 22,171.26477
Overall Steps per Second: 10,727.47307

Timestep Collection Time: 2.25517
Timestep Consumption Time: 2.40576
PPO Batch Consumption Time: 0.27585
Total Iteration Time: 4.66093

Cumulative Model Updates: 180,908
Cumulative Timesteps: 1,508,644,622

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,804.41341
Policy Entropy: 3.79158
Value Function Loss: 0.06988

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.11222
Policy Update Magnitude: 1.20940
Value Function Update Magnitude: 0.62574

Collected Steps per Second: 23,082.91302
Overall Steps per Second: 10,870.52734

Timestep Collection Time: 2.16645
Timestep Consumption Time: 2.43388
PPO Batch Consumption Time: 0.28110
Total Iteration Time: 4.60033

Cumulative Model Updates: 180,914
Cumulative Timesteps: 1,508,694,630

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1508694630...
Checkpoint 1508694630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,618.44048
Policy Entropy: 3.76669
Value Function Loss: 0.06194

Mean KL Divergence: 0.00776
SB3 Clip Fraction: 0.09511
Policy Update Magnitude: 1.04796
Value Function Update Magnitude: 0.57601

Collected Steps per Second: 22,543.18907
Overall Steps per Second: 10,610.61084

Timestep Collection Time: 2.21841
Timestep Consumption Time: 2.49480
PPO Batch Consumption Time: 0.29280
Total Iteration Time: 4.71321

Cumulative Model Updates: 180,920
Cumulative Timesteps: 1,508,744,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,292.04076
Policy Entropy: 3.77545
Value Function Loss: 0.05091

Mean KL Divergence: 0.00650
SB3 Clip Fraction: 0.07877
Policy Update Magnitude: 0.92619
Value Function Update Magnitude: 0.57250

Collected Steps per Second: 22,103.62085
Overall Steps per Second: 10,814.17163

Timestep Collection Time: 2.26325
Timestep Consumption Time: 2.36272
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.62597

Cumulative Model Updates: 180,926
Cumulative Timesteps: 1,508,794,666

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1508794666...
Checkpoint 1508794666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,739.63524
Policy Entropy: 3.75384
Value Function Loss: 0.04440

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07089
Policy Update Magnitude: 0.86525
Value Function Update Magnitude: 0.60787

Collected Steps per Second: 21,746.24305
Overall Steps per Second: 10,803.15293

Timestep Collection Time: 2.30026
Timestep Consumption Time: 2.33006
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.63031

Cumulative Model Updates: 180,932
Cumulative Timesteps: 1,508,844,688

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,952.18347
Policy Entropy: 3.74775
Value Function Loss: 0.03728

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07623
Policy Update Magnitude: 0.74075
Value Function Update Magnitude: 0.62985

Collected Steps per Second: 22,489.82275
Overall Steps per Second: 10,898.15524

Timestep Collection Time: 2.22403
Timestep Consumption Time: 2.36556
PPO Batch Consumption Time: 0.28104
Total Iteration Time: 4.58958

Cumulative Model Updates: 180,938
Cumulative Timesteps: 1,508,894,706

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1508894706...
Checkpoint 1508894706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,578.83871
Policy Entropy: 3.73796
Value Function Loss: 0.03289

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11115
Policy Update Magnitude: 0.68131
Value Function Update Magnitude: 0.65673

Collected Steps per Second: 21,700.40874
Overall Steps per Second: 10,626.07362

Timestep Collection Time: 2.30530
Timestep Consumption Time: 2.40255
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.70785

Cumulative Model Updates: 180,944
Cumulative Timesteps: 1,508,944,732

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,677.72419
Policy Entropy: 3.71788
Value Function Loss: 0.03580

Mean KL Divergence: 0.01330
SB3 Clip Fraction: 0.17831
Policy Update Magnitude: 0.54977
Value Function Update Magnitude: 0.75266

Collected Steps per Second: 22,520.79600
Overall Steps per Second: 10,807.58339

Timestep Collection Time: 2.22026
Timestep Consumption Time: 2.40631
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.62657

Cumulative Model Updates: 180,950
Cumulative Timesteps: 1,508,994,734

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1508994734...
Checkpoint 1508994734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,292.04938
Policy Entropy: 3.70613
Value Function Loss: 0.03841

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15668
Policy Update Magnitude: 0.51218
Value Function Update Magnitude: 0.81408

Collected Steps per Second: 22,552.17253
Overall Steps per Second: 10,726.96261

Timestep Collection Time: 2.21708
Timestep Consumption Time: 2.44407
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.66115

Cumulative Model Updates: 180,956
Cumulative Timesteps: 1,509,044,734

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,128.02093
Policy Entropy: 3.70210
Value Function Loss: 0.03629

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.61407
Value Function Update Magnitude: 0.69526

Collected Steps per Second: 22,888.42788
Overall Steps per Second: 10,910.81932

Timestep Collection Time: 2.18503
Timestep Consumption Time: 2.39867
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.58371

Cumulative Model Updates: 180,962
Cumulative Timesteps: 1,509,094,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1509094746...
Checkpoint 1509094746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,128.02093
Policy Entropy: 3.71406
Value Function Loss: 0.02996

Mean KL Divergence: 0.01614
SB3 Clip Fraction: 0.19885
Policy Update Magnitude: 0.54221
Value Function Update Magnitude: 0.65181

Collected Steps per Second: 23,026.01309
Overall Steps per Second: 10,724.12522

Timestep Collection Time: 2.17233
Timestep Consumption Time: 2.49192
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.66425

Cumulative Model Updates: 180,968
Cumulative Timesteps: 1,509,144,766

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,925.64681
Policy Entropy: 3.69663
Value Function Loss: 0.04407

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.19485
Policy Update Magnitude: 0.45957
Value Function Update Magnitude: 0.61387

Collected Steps per Second: 23,049.47483
Overall Steps per Second: 10,814.26919

Timestep Collection Time: 2.16959
Timestep Consumption Time: 2.45467
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.62426

Cumulative Model Updates: 180,974
Cumulative Timesteps: 1,509,194,774

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1509194774...
Checkpoint 1509194774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,792.59957
Policy Entropy: 3.70743
Value Function Loss: 0.04655

Mean KL Divergence: 0.01445
SB3 Clip Fraction: 0.18863
Policy Update Magnitude: 0.47537
Value Function Update Magnitude: 0.60434

Collected Steps per Second: 22,486.30469
Overall Steps per Second: 10,641.09944

Timestep Collection Time: 2.22447
Timestep Consumption Time: 2.47618
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.70064

Cumulative Model Updates: 180,980
Cumulative Timesteps: 1,509,244,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,927.98462
Policy Entropy: 3.71635
Value Function Loss: 0.05276

Mean KL Divergence: 0.01341
SB3 Clip Fraction: 0.17320
Policy Update Magnitude: 0.47761
Value Function Update Magnitude: 0.48283

Collected Steps per Second: 23,165.27591
Overall Steps per Second: 10,892.02999

Timestep Collection Time: 2.15875
Timestep Consumption Time: 2.43250
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.59125

Cumulative Model Updates: 180,986
Cumulative Timesteps: 1,509,294,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1509294802...
Checkpoint 1509294802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,628.46621
Policy Entropy: 3.72765
Value Function Loss: 0.04747

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.49032
Value Function Update Magnitude: 0.39938

Collected Steps per Second: 22,561.55590
Overall Steps per Second: 10,651.77633

Timestep Collection Time: 2.21651
Timestep Consumption Time: 2.47829
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.69480

Cumulative Model Updates: 180,992
Cumulative Timesteps: 1,509,344,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,080.96612
Policy Entropy: 3.71231
Value Function Loss: 0.04842

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15633
Policy Update Magnitude: 0.51606
Value Function Update Magnitude: 0.45140

Collected Steps per Second: 22,983.35742
Overall Steps per Second: 10,853.43215

Timestep Collection Time: 2.17636
Timestep Consumption Time: 2.43232
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.60868

Cumulative Model Updates: 180,998
Cumulative Timesteps: 1,509,394,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1509394830...
Checkpoint 1509394830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,080.96612
Policy Entropy: 3.69125
Value Function Loss: 0.04780

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15115
Policy Update Magnitude: 0.50331
Value Function Update Magnitude: 0.54417

Collected Steps per Second: 22,243.48274
Overall Steps per Second: 10,702.05457

Timestep Collection Time: 2.24830
Timestep Consumption Time: 2.42464
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.67293

Cumulative Model Updates: 181,004
Cumulative Timesteps: 1,509,444,840

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,366.73748
Policy Entropy: 3.68505
Value Function Loss: 0.04592

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14864
Policy Update Magnitude: 0.45230
Value Function Update Magnitude: 0.49565

Collected Steps per Second: 22,934.93945
Overall Steps per Second: 10,877.09290

Timestep Collection Time: 2.18069
Timestep Consumption Time: 2.41741
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.59810

Cumulative Model Updates: 181,010
Cumulative Timesteps: 1,509,494,854

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1509494854...
Checkpoint 1509494854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,060.72191
Policy Entropy: 3.68838
Value Function Loss: 0.03896

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14661
Policy Update Magnitude: 0.40995
Value Function Update Magnitude: 0.37847

Collected Steps per Second: 23,177.72803
Overall Steps per Second: 10,851.08208

Timestep Collection Time: 2.15862
Timestep Consumption Time: 2.45216
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.61078

Cumulative Model Updates: 181,016
Cumulative Timesteps: 1,509,544,886

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,987.56740
Policy Entropy: 3.70664
Value Function Loss: 0.03199

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.15059
Policy Update Magnitude: 0.39096
Value Function Update Magnitude: 0.36024

Collected Steps per Second: 22,506.85697
Overall Steps per Second: 10,733.05366

Timestep Collection Time: 2.22270
Timestep Consumption Time: 2.43823
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.66093

Cumulative Model Updates: 181,022
Cumulative Timesteps: 1,509,594,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1509594912...
Checkpoint 1509594912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,987.56740
Policy Entropy: 3.70402
Value Function Loss: 0.02368

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13538
Policy Update Magnitude: 0.35112
Value Function Update Magnitude: 0.43498

Collected Steps per Second: 21,721.74096
Overall Steps per Second: 10,650.56290

Timestep Collection Time: 2.30212
Timestep Consumption Time: 2.39303
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.69515

Cumulative Model Updates: 181,028
Cumulative Timesteps: 1,509,644,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,987.56740
Policy Entropy: 3.70086
Value Function Loss: 0.02087

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.33002
Value Function Update Magnitude: 0.48095

Collected Steps per Second: 22,610.97410
Overall Steps per Second: 10,917.93016

Timestep Collection Time: 2.21264
Timestep Consumption Time: 2.36973
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.58237

Cumulative Model Updates: 181,034
Cumulative Timesteps: 1,509,694,948

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1509694948...
Checkpoint 1509694948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,987.56740
Policy Entropy: 3.67557
Value Function Loss: 0.02491

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.34375
Value Function Update Magnitude: 0.48975

Collected Steps per Second: 21,762.57923
Overall Steps per Second: 10,638.70604

Timestep Collection Time: 2.29853
Timestep Consumption Time: 2.40335
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.70189

Cumulative Model Updates: 181,040
Cumulative Timesteps: 1,509,744,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,281.17312
Policy Entropy: 3.68708
Value Function Loss: 0.02650

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13809
Policy Update Magnitude: 0.37874
Value Function Update Magnitude: 0.49564

Collected Steps per Second: 23,459.34945
Overall Steps per Second: 10,897.53317

Timestep Collection Time: 2.13245
Timestep Consumption Time: 2.45813
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.59058

Cumulative Model Updates: 181,046
Cumulative Timesteps: 1,509,794,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1509794996...
Checkpoint 1509794996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,644.56208
Policy Entropy: 3.69003
Value Function Loss: 0.02759

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.38472
Value Function Update Magnitude: 0.56844

Collected Steps per Second: 22,524.44405
Overall Steps per Second: 10,638.16185

Timestep Collection Time: 2.21999
Timestep Consumption Time: 2.48045
PPO Batch Consumption Time: 0.28609
Total Iteration Time: 4.70044

Cumulative Model Updates: 181,052
Cumulative Timesteps: 1,509,845,000

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,644.56208
Policy Entropy: 3.70016
Value Function Loss: 0.02410

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.36178
Value Function Update Magnitude: 0.52224

Collected Steps per Second: 22,946.17583
Overall Steps per Second: 10,846.96102

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.61438

Cumulative Model Updates: 181,058
Cumulative Timesteps: 1,509,895,052

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1509895052...
Checkpoint 1509895052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,426.77361
Policy Entropy: 3.66852
Value Function Loss: 0.02728

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.36288
Value Function Update Magnitude: 0.50207

Collected Steps per Second: 22,670.43223
Overall Steps per Second: 10,731.93726

Timestep Collection Time: 2.20613
Timestep Consumption Time: 2.45416
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.66030

Cumulative Model Updates: 181,064
Cumulative Timesteps: 1,509,945,066

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,421.31972
Policy Entropy: 3.67961
Value Function Loss: 0.03177

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.42060
Value Function Update Magnitude: 0.58258

Collected Steps per Second: 23,315.24385
Overall Steps per Second: 10,958.21726

Timestep Collection Time: 2.14546
Timestep Consumption Time: 2.41933
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.56479

Cumulative Model Updates: 181,070
Cumulative Timesteps: 1,509,995,088

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1509995088...
Checkpoint 1509995088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,588.15927
Policy Entropy: 3.67470
Value Function Loss: 0.03457

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13932
Policy Update Magnitude: 0.45726
Value Function Update Magnitude: 0.54772

Collected Steps per Second: 22,673.28841
Overall Steps per Second: 10,647.43135

Timestep Collection Time: 2.20594
Timestep Consumption Time: 2.49153
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.69747

Cumulative Model Updates: 181,076
Cumulative Timesteps: 1,510,045,104

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,914.69925
Policy Entropy: 3.69207
Value Function Loss: 0.03662

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13281
Policy Update Magnitude: 0.45489
Value Function Update Magnitude: 0.55871

Collected Steps per Second: 23,097.05684
Overall Steps per Second: 10,864.58802

Timestep Collection Time: 2.16651
Timestep Consumption Time: 2.43928
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.60579

Cumulative Model Updates: 181,082
Cumulative Timesteps: 1,510,095,144

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1510095144...
Checkpoint 1510095144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,303.90783
Policy Entropy: 3.69428
Value Function Loss: 0.03350

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13444
Policy Update Magnitude: 0.46865
Value Function Update Magnitude: 0.67685

Collected Steps per Second: 22,808.31659
Overall Steps per Second: 10,699.27496

Timestep Collection Time: 2.19446
Timestep Consumption Time: 2.48361
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.67807

Cumulative Model Updates: 181,088
Cumulative Timesteps: 1,510,145,196

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,885.41372
Policy Entropy: 3.69932
Value Function Loss: 0.03005

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.44688
Value Function Update Magnitude: 0.70495

Collected Steps per Second: 22,589.30278
Overall Steps per Second: 10,864.76814

Timestep Collection Time: 2.21494
Timestep Consumption Time: 2.39022
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.60516

Cumulative Model Updates: 181,094
Cumulative Timesteps: 1,510,195,230

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1510195230...
Checkpoint 1510195230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,425.31935
Policy Entropy: 3.69302
Value Function Loss: 0.03037

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13619
Policy Update Magnitude: 0.48132
Value Function Update Magnitude: 0.63935

Collected Steps per Second: 21,791.38618
Overall Steps per Second: 10,610.30765

Timestep Collection Time: 2.29448
Timestep Consumption Time: 2.41791
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.71240

Cumulative Model Updates: 181,100
Cumulative Timesteps: 1,510,245,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,993.11994
Policy Entropy: 3.69581
Value Function Loss: 0.02789

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12933
Policy Update Magnitude: 0.48621
Value Function Update Magnitude: 0.70029

Collected Steps per Second: 22,396.34937
Overall Steps per Second: 10,964.61755

Timestep Collection Time: 2.23295
Timestep Consumption Time: 2.32808
PPO Batch Consumption Time: 0.27622
Total Iteration Time: 4.56103

Cumulative Model Updates: 181,106
Cumulative Timesteps: 1,510,295,240

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1510295240...
Checkpoint 1510295240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,993.11994
Policy Entropy: 3.67834
Value Function Loss: 0.02592

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13432
Policy Update Magnitude: 0.42896
Value Function Update Magnitude: 0.59237

Collected Steps per Second: 21,941.48875
Overall Steps per Second: 10,624.32651

Timestep Collection Time: 2.27924
Timestep Consumption Time: 2.42788
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.70712

Cumulative Model Updates: 181,112
Cumulative Timesteps: 1,510,345,250

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,397.47415
Policy Entropy: 3.69010
Value Function Loss: 0.02356

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12975
Policy Update Magnitude: 0.35797
Value Function Update Magnitude: 0.44127

Collected Steps per Second: 23,102.79502
Overall Steps per Second: 10,879.68040

Timestep Collection Time: 2.16623
Timestep Consumption Time: 2.43372
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.59995

Cumulative Model Updates: 181,118
Cumulative Timesteps: 1,510,395,296

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1510395296...
Checkpoint 1510395296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,793.55024
Policy Entropy: 3.70467
Value Function Loss: 0.02262

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.33002
Value Function Update Magnitude: 0.42701

Collected Steps per Second: 22,433.95041
Overall Steps per Second: 10,645.14250

Timestep Collection Time: 2.22957
Timestep Consumption Time: 2.46910
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.69867

Cumulative Model Updates: 181,124
Cumulative Timesteps: 1,510,445,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,933.41435
Policy Entropy: 3.70291
Value Function Loss: 0.02889

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12832
Policy Update Magnitude: 0.38716
Value Function Update Magnitude: 0.54087

Collected Steps per Second: 23,255.21477
Overall Steps per Second: 10,910.90023

Timestep Collection Time: 2.15023
Timestep Consumption Time: 2.43271
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.58294

Cumulative Model Updates: 181,130
Cumulative Timesteps: 1,510,495,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1510495318...
Checkpoint 1510495318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,471.31548
Policy Entropy: 3.71720
Value Function Loss: 0.02942

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12719
Policy Update Magnitude: 0.43134
Value Function Update Magnitude: 0.61626

Collected Steps per Second: 22,792.17232
Overall Steps per Second: 10,647.22046

Timestep Collection Time: 2.19496
Timestep Consumption Time: 2.50373
PPO Batch Consumption Time: 0.29227
Total Iteration Time: 4.69869

Cumulative Model Updates: 181,136
Cumulative Timesteps: 1,510,545,346

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,065.72057
Policy Entropy: 3.71924
Value Function Loss: 0.03642

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.45398
Value Function Update Magnitude: 0.58432

Collected Steps per Second: 23,067.46225
Overall Steps per Second: 10,857.47024

Timestep Collection Time: 2.16764
Timestep Consumption Time: 2.43767
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.60531

Cumulative Model Updates: 181,142
Cumulative Timesteps: 1,510,595,348

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1510595348...
Checkpoint 1510595348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,982.50898
Policy Entropy: 3.74221
Value Function Loss: 0.03236

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.44206
Value Function Update Magnitude: 0.59863

Collected Steps per Second: 22,778.45403
Overall Steps per Second: 10,663.04410

Timestep Collection Time: 2.19576
Timestep Consumption Time: 2.49483
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.69059

Cumulative Model Updates: 181,148
Cumulative Timesteps: 1,510,645,364

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,585.36550
Policy Entropy: 3.71585
Value Function Loss: 0.03202

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.43858
Value Function Update Magnitude: 0.59954

Collected Steps per Second: 22,970.32348
Overall Steps per Second: 10,874.83268

Timestep Collection Time: 2.17681
Timestep Consumption Time: 2.42115
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.59796

Cumulative Model Updates: 181,154
Cumulative Timesteps: 1,510,695,366

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1510695366...
Checkpoint 1510695366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,258.63093
Policy Entropy: 3.70063
Value Function Loss: 0.02620

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.41094
Value Function Update Magnitude: 0.58702

Collected Steps per Second: 22,487.75804
Overall Steps per Second: 10,723.08442

Timestep Collection Time: 2.22352
Timestep Consumption Time: 2.43950
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.66302

Cumulative Model Updates: 181,160
Cumulative Timesteps: 1,510,745,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,258.63093
Policy Entropy: 3.68293
Value Function Loss: 0.02458

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13660
Policy Update Magnitude: 0.42374
Value Function Update Magnitude: 0.57568

Collected Steps per Second: 23,367.33719
Overall Steps per Second: 10,875.82320

Timestep Collection Time: 2.14042
Timestep Consumption Time: 2.45840
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.59882

Cumulative Model Updates: 181,166
Cumulative Timesteps: 1,510,795,384

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1510795384...
Checkpoint 1510795384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,258.63093
Policy Entropy: 3.67804
Value Function Loss: 0.02487

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13591
Policy Update Magnitude: 0.42584
Value Function Update Magnitude: 0.53702

Collected Steps per Second: 22,550.63525
Overall Steps per Second: 10,629.14393

Timestep Collection Time: 2.21839
Timestep Consumption Time: 2.48811
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.70649

Cumulative Model Updates: 181,172
Cumulative Timesteps: 1,510,845,410

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,293.61907
Policy Entropy: 3.67585
Value Function Loss: 0.02930

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13056
Policy Update Magnitude: 0.41904
Value Function Update Magnitude: 0.50242

Collected Steps per Second: 22,783.86677
Overall Steps per Second: 10,840.77559

Timestep Collection Time: 2.19550
Timestep Consumption Time: 2.41874
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.61425

Cumulative Model Updates: 181,178
Cumulative Timesteps: 1,510,895,432

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1510895432...
Checkpoint 1510895432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,944.83947
Policy Entropy: 3.67276
Value Function Loss: 0.03134

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.47242
Value Function Update Magnitude: 0.47802

Collected Steps per Second: 22,696.71508
Overall Steps per Second: 10,735.99146

Timestep Collection Time: 2.20314
Timestep Consumption Time: 2.45447
PPO Batch Consumption Time: 0.28430
Total Iteration Time: 4.65760

Cumulative Model Updates: 181,184
Cumulative Timesteps: 1,510,945,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,893.30566
Policy Entropy: 3.66183
Value Function Loss: 0.03449

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.48188
Value Function Update Magnitude: 0.45121

Collected Steps per Second: 22,983.12656
Overall Steps per Second: 10,832.94434

Timestep Collection Time: 2.17612
Timestep Consumption Time: 2.44072
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.61684

Cumulative Model Updates: 181,190
Cumulative Timesteps: 1,510,995,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1510995450...
Checkpoint 1510995450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332,037.46359
Policy Entropy: 3.66320
Value Function Loss: 0.03868

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.47746
Value Function Update Magnitude: 0.41825

Collected Steps per Second: 22,246.74813
Overall Steps per Second: 10,735.91260

Timestep Collection Time: 2.24878
Timestep Consumption Time: 2.41110
PPO Batch Consumption Time: 0.27659
Total Iteration Time: 4.65987

Cumulative Model Updates: 181,196
Cumulative Timesteps: 1,511,045,478

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,703.41469
Policy Entropy: 3.67266
Value Function Loss: 0.04022

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.52593
Value Function Update Magnitude: 0.58516

Collected Steps per Second: 23,393.22133
Overall Steps per Second: 10,880.31146

Timestep Collection Time: 2.13746
Timestep Consumption Time: 2.45818
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.59564

Cumulative Model Updates: 181,202
Cumulative Timesteps: 1,511,095,480

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1511095480...
Checkpoint 1511095480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,840.65946
Policy Entropy: 3.69133
Value Function Loss: 0.04009

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13125
Policy Update Magnitude: 0.52624
Value Function Update Magnitude: 0.62818

Collected Steps per Second: 23,100.01307
Overall Steps per Second: 10,803.23641

Timestep Collection Time: 2.16597
Timestep Consumption Time: 2.46542
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.63139

Cumulative Model Updates: 181,208
Cumulative Timesteps: 1,511,145,514

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,365.23795
Policy Entropy: 3.71321
Value Function Loss: 0.03585

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.49591
Value Function Update Magnitude: 0.57175

Collected Steps per Second: 22,474.62214
Overall Steps per Second: 10,740.19297

Timestep Collection Time: 2.22562
Timestep Consumption Time: 2.43165
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.65727

Cumulative Model Updates: 181,214
Cumulative Timesteps: 1,511,195,534

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1511195534...
Checkpoint 1511195534 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,801.40584
Policy Entropy: 3.71769
Value Function Loss: 0.03711

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13687
Policy Update Magnitude: 0.48645
Value Function Update Magnitude: 0.56589

Collected Steps per Second: 21,852.45543
Overall Steps per Second: 10,619.07365

Timestep Collection Time: 2.28890
Timestep Consumption Time: 2.42131
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.71020

Cumulative Model Updates: 181,220
Cumulative Timesteps: 1,511,245,552

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,892.19683
Policy Entropy: 3.71162
Value Function Loss: 0.03514

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.46242
Value Function Update Magnitude: 0.59637

Collected Steps per Second: 22,378.89977
Overall Steps per Second: 10,912.70640

Timestep Collection Time: 2.23532
Timestep Consumption Time: 2.34869
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.58401

Cumulative Model Updates: 181,226
Cumulative Timesteps: 1,511,295,576

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1511295576...
Checkpoint 1511295576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,892.19683
Policy Entropy: 3.68298
Value Function Loss: 0.03242

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13738
Policy Update Magnitude: 0.44050
Value Function Update Magnitude: 0.58679

Collected Steps per Second: 22,061.78022
Overall Steps per Second: 10,696.35509

Timestep Collection Time: 2.26654
Timestep Consumption Time: 2.40832
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.67486

Cumulative Model Updates: 181,232
Cumulative Timesteps: 1,511,345,580

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237,669.45402
Policy Entropy: 3.66833
Value Function Loss: 0.03443

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.40628
Value Function Update Magnitude: 0.49115

Collected Steps per Second: 23,275.13650
Overall Steps per Second: 10,901.84167

Timestep Collection Time: 2.14907
Timestep Consumption Time: 2.43914
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.58822

Cumulative Model Updates: 181,238
Cumulative Timesteps: 1,511,395,600

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1511395600...
Checkpoint 1511395600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 180,874.18617
Policy Entropy: 3.68946
Value Function Loss: 0.03283

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.45292
Value Function Update Magnitude: 0.45756

Collected Steps per Second: 22,260.94866
Overall Steps per Second: 10,609.64759

Timestep Collection Time: 2.24636
Timestep Consumption Time: 2.46690
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.71326

Cumulative Model Updates: 181,244
Cumulative Timesteps: 1,511,445,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,129.79240
Policy Entropy: 3.69586
Value Function Loss: 0.03602

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12684
Policy Update Magnitude: 0.50866
Value Function Update Magnitude: 0.45412

Collected Steps per Second: 23,047.25111
Overall Steps per Second: 10,873.00615

Timestep Collection Time: 2.16954
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.59873

Cumulative Model Updates: 181,250
Cumulative Timesteps: 1,511,495,608

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1511495608...
Checkpoint 1511495608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,631.75768
Policy Entropy: 3.69778
Value Function Loss: 0.03330

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13007
Policy Update Magnitude: 0.48934
Value Function Update Magnitude: 0.48069

Collected Steps per Second: 22,828.43591
Overall Steps per Second: 10,678.47832

Timestep Collection Time: 2.19113
Timestep Consumption Time: 2.49306
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.68419

Cumulative Model Updates: 181,256
Cumulative Timesteps: 1,511,545,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,035.77341
Policy Entropy: 3.67329
Value Function Loss: 0.03316

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.44629
Value Function Update Magnitude: 0.44271

Collected Steps per Second: 22,955.38142
Overall Steps per Second: 10,853.07072

Timestep Collection Time: 2.17849
Timestep Consumption Time: 2.42924
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.60773

Cumulative Model Updates: 181,262
Cumulative Timesteps: 1,511,595,636

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1511595636...
Checkpoint 1511595636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,427.71353
Policy Entropy: 3.67297
Value Function Loss: 0.02754

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13661
Policy Update Magnitude: 0.43010
Value Function Update Magnitude: 0.43877

Collected Steps per Second: 22,536.81310
Overall Steps per Second: 10,653.28682

Timestep Collection Time: 2.21859
Timestep Consumption Time: 2.47479
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.69339

Cumulative Model Updates: 181,268
Cumulative Timesteps: 1,511,645,636

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,005.40001
Policy Entropy: 3.68024
Value Function Loss: 0.02444

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13442
Policy Update Magnitude: 0.36761
Value Function Update Magnitude: 0.37864

Collected Steps per Second: 23,014.36037
Overall Steps per Second: 10,905.33225

Timestep Collection Time: 2.17343
Timestep Consumption Time: 2.41332
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.58675

Cumulative Model Updates: 181,274
Cumulative Timesteps: 1,511,695,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1511695656...
Checkpoint 1511695656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,690.11384
Policy Entropy: 3.68402
Value Function Loss: 0.02347

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12682
Policy Update Magnitude: 0.33509
Value Function Update Magnitude: 0.34205

Collected Steps per Second: 22,852.98558
Overall Steps per Second: 10,689.53371

Timestep Collection Time: 2.18825
Timestep Consumption Time: 2.48997
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.67822

Cumulative Model Updates: 181,280
Cumulative Timesteps: 1,511,745,664

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,690.11384
Policy Entropy: 3.68153
Value Function Loss: 0.02113

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13782
Policy Update Magnitude: 0.34101
Value Function Update Magnitude: 0.38088

Collected Steps per Second: 23,234.97547
Overall Steps per Second: 10,905.80848

Timestep Collection Time: 2.15210
Timestep Consumption Time: 2.43298
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.58508

Cumulative Model Updates: 181,286
Cumulative Timesteps: 1,511,795,668

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1511795668...
Checkpoint 1511795668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,289.05744
Policy Entropy: 3.67776
Value Function Loss: 0.02386

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.36508
Value Function Update Magnitude: 0.36620

Collected Steps per Second: 22,846.01427
Overall Steps per Second: 10,642.18940

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.51052
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.69978

Cumulative Model Updates: 181,292
Cumulative Timesteps: 1,511,845,684

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,791.10251
Policy Entropy: 3.68556
Value Function Loss: 0.02277

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12924
Policy Update Magnitude: 0.37562
Value Function Update Magnitude: 0.37319

Collected Steps per Second: 22,968.42342
Overall Steps per Second: 10,874.05620

Timestep Collection Time: 2.17690
Timestep Consumption Time: 2.42120
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.59810

Cumulative Model Updates: 181,298
Cumulative Timesteps: 1,511,895,684

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1511895684...
Checkpoint 1511895684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,791.10251
Policy Entropy: 3.69034
Value Function Loss: 0.02283

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13411
Policy Update Magnitude: 0.36688
Value Function Update Magnitude: 0.53027

Collected Steps per Second: 22,907.71095
Overall Steps per Second: 10,689.92715

Timestep Collection Time: 2.18319
Timestep Consumption Time: 2.49523
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.67842

Cumulative Model Updates: 181,304
Cumulative Timesteps: 1,511,945,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,791.10251
Policy Entropy: 3.69323
Value Function Loss: 0.01953

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.36301
Value Function Update Magnitude: 0.56736

Collected Steps per Second: 23,084.90971
Overall Steps per Second: 10,880.10424

Timestep Collection Time: 2.16670
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.59720

Cumulative Model Updates: 181,310
Cumulative Timesteps: 1,511,995,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1511995714...
Checkpoint 1511995714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,247.77727
Policy Entropy: 3.69658
Value Function Loss: 0.01923

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.37335
Value Function Update Magnitude: 0.54238

Collected Steps per Second: 22,853.52535
Overall Steps per Second: 10,656.35385

Timestep Collection Time: 2.18872
Timestep Consumption Time: 2.50519
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.69391

Cumulative Model Updates: 181,316
Cumulative Timesteps: 1,512,045,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,247.77727
Policy Entropy: 3.68246
Value Function Loss: 0.02192

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12404
Policy Update Magnitude: 0.39059
Value Function Update Magnitude: 0.51254

Collected Steps per Second: 22,930.14420
Overall Steps per Second: 10,873.23961

Timestep Collection Time: 2.18141
Timestep Consumption Time: 2.41888
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.60028

Cumulative Model Updates: 181,322
Cumulative Timesteps: 1,512,095,754

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1512095754...
Checkpoint 1512095754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,247.77727
Policy Entropy: 3.67579
Value Function Loss: 0.02596

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 0.45580
Value Function Update Magnitude: 0.43724

Collected Steps per Second: 22,366.33159
Overall Steps per Second: 10,753.59586

Timestep Collection Time: 2.23667
Timestep Consumption Time: 2.41536
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.65203

Cumulative Model Updates: 181,328
Cumulative Timesteps: 1,512,145,780

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,247.77727
Policy Entropy: 3.66478
Value Function Loss: 0.02766

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.46241
Value Function Update Magnitude: 0.48744

Collected Steps per Second: 22,892.19040
Overall Steps per Second: 10,886.93672

Timestep Collection Time: 2.18537
Timestep Consumption Time: 2.40986
PPO Batch Consumption Time: 0.27652
Total Iteration Time: 4.59523

Cumulative Model Updates: 181,334
Cumulative Timesteps: 1,512,195,808

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1512195808...
Checkpoint 1512195808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,247.77727
Policy Entropy: 3.67008
Value Function Loss: 0.02637

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.44053
Value Function Update Magnitude: 0.46531

Collected Steps per Second: 22,799.28310
Overall Steps per Second: 10,703.09016

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.47889
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.67230

Cumulative Model Updates: 181,340
Cumulative Timesteps: 1,512,245,816

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,247.77727
Policy Entropy: 3.66121
Value Function Loss: 0.02362

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13105
Policy Update Magnitude: 0.39265
Value Function Update Magnitude: 0.39795

Collected Steps per Second: 23,114.40916
Overall Steps per Second: 10,831.05096

Timestep Collection Time: 2.16333
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.28291
Total Iteration Time: 4.61673

Cumulative Model Updates: 181,346
Cumulative Timesteps: 1,512,295,820

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1512295820...
Checkpoint 1512295820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,247.77727
Policy Entropy: 3.66638
Value Function Loss: 0.02038

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.37086
Value Function Update Magnitude: 0.32481

Collected Steps per Second: 21,959.38116
Overall Steps per Second: 10,680.10328

Timestep Collection Time: 2.27812
Timestep Consumption Time: 2.40592
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.68404

Cumulative Model Updates: 181,352
Cumulative Timesteps: 1,512,345,846

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,247.77727
Policy Entropy: 3.67017
Value Function Loss: 0.02280

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12338
Policy Update Magnitude: 0.43363
Value Function Update Magnitude: 0.44671

Collected Steps per Second: 21,935.66477
Overall Steps per Second: 10,799.02346

Timestep Collection Time: 2.28040
Timestep Consumption Time: 2.35169
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.63209

Cumulative Model Updates: 181,358
Cumulative Timesteps: 1,512,395,868

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1512395868...
Checkpoint 1512395868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,598.85892
Policy Entropy: 3.67199
Value Function Loss: 0.02479

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.49427
Value Function Update Magnitude: 0.56931

Collected Steps per Second: 22,141.76940
Overall Steps per Second: 10,643.03387

Timestep Collection Time: 2.25836
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.69828

Cumulative Model Updates: 181,364
Cumulative Timesteps: 1,512,445,872

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,916.58203
Policy Entropy: 3.67489
Value Function Loss: 0.02573

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12845
Policy Update Magnitude: 0.46460
Value Function Update Magnitude: 0.63731

Collected Steps per Second: 22,728.02130
Overall Steps per Second: 10,859.32895

Timestep Collection Time: 2.20116
Timestep Consumption Time: 2.40576
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.60691

Cumulative Model Updates: 181,370
Cumulative Timesteps: 1,512,495,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1512495900...
Checkpoint 1512495900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,916.58203
Policy Entropy: 3.67935
Value Function Loss: 0.02316

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.41451
Value Function Update Magnitude: 0.58057

Collected Steps per Second: 22,693.78555
Overall Steps per Second: 10,705.43702

Timestep Collection Time: 2.20430
Timestep Consumption Time: 2.46846
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.67277

Cumulative Model Updates: 181,376
Cumulative Timesteps: 1,512,545,924

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,916.58203
Policy Entropy: 3.68861
Value Function Loss: 0.01926

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.36517
Value Function Update Magnitude: 0.42858

Collected Steps per Second: 23,011.38531
Overall Steps per Second: 10,835.48370

Timestep Collection Time: 2.17310
Timestep Consumption Time: 2.44192
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.61502

Cumulative Model Updates: 181,382
Cumulative Timesteps: 1,512,595,930

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1512595930...
Checkpoint 1512595930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,916.58203
Policy Entropy: 3.68920
Value Function Loss: 0.01730

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12721
Policy Update Magnitude: 0.30889
Value Function Update Magnitude: 0.35972

Collected Steps per Second: 22,745.59921
Overall Steps per Second: 10,713.47039

Timestep Collection Time: 2.19876
Timestep Consumption Time: 2.46939
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.66814

Cumulative Model Updates: 181,388
Cumulative Timesteps: 1,512,645,942

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,174.82816
Policy Entropy: 3.70178
Value Function Loss: 0.01967

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.32118
Value Function Update Magnitude: 0.40175

Collected Steps per Second: 22,679.04315
Overall Steps per Second: 10,836.51724

Timestep Collection Time: 2.20503
Timestep Consumption Time: 2.40974
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.61477

Cumulative Model Updates: 181,394
Cumulative Timesteps: 1,512,695,950

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1512695950...
Checkpoint 1512695950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,609.96240
Policy Entropy: 3.70808
Value Function Loss: 0.02220

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12880
Policy Update Magnitude: 0.39797
Value Function Update Magnitude: 0.57048

Collected Steps per Second: 22,829.27818
Overall Steps per Second: 10,701.93296

Timestep Collection Time: 2.19157
Timestep Consumption Time: 2.48347
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.67504

Cumulative Model Updates: 181,400
Cumulative Timesteps: 1,512,745,982

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,666.48334
Policy Entropy: 3.72621
Value Function Loss: 0.02371

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.42778
Value Function Update Magnitude: 0.59930

Collected Steps per Second: 23,052.80501
Overall Steps per Second: 10,889.45844

Timestep Collection Time: 2.17006
Timestep Consumption Time: 2.42392
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.59398

Cumulative Model Updates: 181,406
Cumulative Timesteps: 1,512,796,008

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1512796008...
Checkpoint 1512796008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,800.05780
Policy Entropy: 3.73951
Value Function Loss: 0.02458

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12450
Policy Update Magnitude: 0.43348
Value Function Update Magnitude: 0.66714

Collected Steps per Second: 22,721.69249
Overall Steps per Second: 10,666.45937

Timestep Collection Time: 2.20054
Timestep Consumption Time: 2.48705
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.68759

Cumulative Model Updates: 181,412
Cumulative Timesteps: 1,512,846,008

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.74154
Policy Entropy: 3.71821
Value Function Loss: 0.02483

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.40333
Value Function Update Magnitude: 0.61830

Collected Steps per Second: 22,405.99806
Overall Steps per Second: 10,964.70311

Timestep Collection Time: 2.23181
Timestep Consumption Time: 2.32882
PPO Batch Consumption Time: 0.27537
Total Iteration Time: 4.56063

Cumulative Model Updates: 181,418
Cumulative Timesteps: 1,512,896,014

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1512896014...
Checkpoint 1512896014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.74154
Policy Entropy: 3.68976
Value Function Loss: 0.02173

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.36725
Value Function Update Magnitude: 0.52191

Collected Steps per Second: 21,969.91775
Overall Steps per Second: 10,644.38789

Timestep Collection Time: 2.27666
Timestep Consumption Time: 2.42234
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.69900

Cumulative Model Updates: 181,424
Cumulative Timesteps: 1,512,946,032

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.74154
Policy Entropy: 3.68793
Value Function Loss: 0.01721

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12714
Policy Update Magnitude: 0.32708
Value Function Update Magnitude: 0.46767

Collected Steps per Second: 22,166.84352
Overall Steps per Second: 10,883.93427

Timestep Collection Time: 2.25634
Timestep Consumption Time: 2.33905
PPO Batch Consumption Time: 0.27643
Total Iteration Time: 4.59540

Cumulative Model Updates: 181,430
Cumulative Timesteps: 1,512,996,048

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1512996048...
Checkpoint 1512996048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.74154
Policy Entropy: 3.69347
Value Function Loss: 0.01555

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.31640
Value Function Update Magnitude: 0.33605

Collected Steps per Second: 22,114.46709
Overall Steps per Second: 10,603.91155

Timestep Collection Time: 2.26151
Timestep Consumption Time: 2.45487
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.71637

Cumulative Model Updates: 181,436
Cumulative Timesteps: 1,513,046,060

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.74154
Policy Entropy: 3.70446
Value Function Loss: 0.01473

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.29985
Value Function Update Magnitude: 0.28865

Collected Steps per Second: 22,903.68255
Overall Steps per Second: 10,918.45240

Timestep Collection Time: 2.18480
Timestep Consumption Time: 2.39827
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.58307

Cumulative Model Updates: 181,442
Cumulative Timesteps: 1,513,096,100

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1513096100...
Checkpoint 1513096100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,188.74154
Policy Entropy: 3.69019
Value Function Loss: 0.01969

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08301
Policy Update Magnitude: 0.42976
Value Function Update Magnitude: 0.36567

Collected Steps per Second: 22,479.25195
Overall Steps per Second: 10,641.89088

Timestep Collection Time: 2.22490
Timestep Consumption Time: 2.47483
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.69973

Cumulative Model Updates: 181,448
Cumulative Timesteps: 1,513,146,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,780.52026
Policy Entropy: 3.70018
Value Function Loss: 0.01994

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08376
Policy Update Magnitude: 0.50321
Value Function Update Magnitude: 0.45903

Collected Steps per Second: 23,078.43294
Overall Steps per Second: 10,897.48834

Timestep Collection Time: 2.16678
Timestep Consumption Time: 2.42198
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.58876

Cumulative Model Updates: 181,454
Cumulative Timesteps: 1,513,196,120

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1513196120...
Checkpoint 1513196120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,780.52026
Policy Entropy: 3.69328
Value Function Loss: 0.02302

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.15438
Policy Update Magnitude: 0.44293
Value Function Update Magnitude: 0.48970

Collected Steps per Second: 22,902.16205
Overall Steps per Second: 10,657.33960

Timestep Collection Time: 2.18416
Timestep Consumption Time: 2.50951
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.69367

Cumulative Model Updates: 181,460
Cumulative Timesteps: 1,513,246,142

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,780.52026
Policy Entropy: 3.68410
Value Function Loss: 0.02397

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.23563
Policy Update Magnitude: 0.37490
Value Function Update Magnitude: 0.41270

Collected Steps per Second: 23,018.55231
Overall Steps per Second: 10,889.61736

Timestep Collection Time: 2.17364
Timestep Consumption Time: 2.42101
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.59465

Cumulative Model Updates: 181,466
Cumulative Timesteps: 1,513,296,176

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1513296176...
Checkpoint 1513296176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199,540.63665
Policy Entropy: 3.62020
Value Function Loss: 0.04315

Mean KL Divergence: 0.02828
SB3 Clip Fraction: 0.28733
Policy Update Magnitude: 0.37338
Value Function Update Magnitude: 0.35863

Collected Steps per Second: 22,709.92307
Overall Steps per Second: 10,655.59363

Timestep Collection Time: 2.20230
Timestep Consumption Time: 2.49139
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.69369

Cumulative Model Updates: 181,472
Cumulative Timesteps: 1,513,346,190

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 553,235.11720
Policy Entropy: 3.61517
Value Function Loss: 0.06230

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.23575
Policy Update Magnitude: 0.52647
Value Function Update Magnitude: 0.36242

Collected Steps per Second: 23,110.76305
Overall Steps per Second: 10,949.65619

Timestep Collection Time: 2.16410
Timestep Consumption Time: 2.40353
PPO Batch Consumption Time: 0.27662
Total Iteration Time: 4.56763

Cumulative Model Updates: 181,478
Cumulative Timesteps: 1,513,396,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1513396204...
Checkpoint 1513396204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 599,318.62781
Policy Entropy: 3.63238
Value Function Loss: 0.07289

Mean KL Divergence: 0.02087
SB3 Clip Fraction: 0.22493
Policy Update Magnitude: 0.67448
Value Function Update Magnitude: 0.47034

Collected Steps per Second: 22,771.35554
Overall Steps per Second: 10,644.65783

Timestep Collection Time: 2.19679
Timestep Consumption Time: 2.50265
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.69945

Cumulative Model Updates: 181,484
Cumulative Timesteps: 1,513,446,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,877.88724
Policy Entropy: 3.69379
Value Function Loss: 0.06307

Mean KL Divergence: 0.01098
SB3 Clip Fraction: 0.13819
Policy Update Magnitude: 0.95848
Value Function Update Magnitude: 0.50464

Collected Steps per Second: 22,400.04802
Overall Steps per Second: 10,932.40423

Timestep Collection Time: 2.23258
Timestep Consumption Time: 2.34189
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.57447

Cumulative Model Updates: 181,490
Cumulative Timesteps: 1,513,496,238

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1513496238...
Checkpoint 1513496238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,382.82532
Policy Entropy: 3.71259
Value Function Loss: 0.05115

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13178
Policy Update Magnitude: 1.03385
Value Function Update Magnitude: 0.51863

Collected Steps per Second: 21,760.39518
Overall Steps per Second: 10,578.69222

Timestep Collection Time: 2.29968
Timestep Consumption Time: 2.43077
PPO Batch Consumption Time: 0.29277
Total Iteration Time: 4.73045

Cumulative Model Updates: 181,496
Cumulative Timesteps: 1,513,546,280

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,811.72087
Policy Entropy: 3.72654
Value Function Loss: 0.04388

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11512
Policy Update Magnitude: 0.91914
Value Function Update Magnitude: 0.68820

Collected Steps per Second: 22,281.90629
Overall Steps per Second: 10,890.71261

Timestep Collection Time: 2.24523
Timestep Consumption Time: 2.34841
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.59364

Cumulative Model Updates: 181,502
Cumulative Timesteps: 1,513,596,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1513596308...
Checkpoint 1513596308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,040.47852
Policy Entropy: 3.71921
Value Function Loss: 0.04487

Mean KL Divergence: 0.00795
SB3 Clip Fraction: 0.09687
Policy Update Magnitude: 0.85621
Value Function Update Magnitude: 0.67169

Collected Steps per Second: 22,146.13813
Overall Steps per Second: 10,711.25096

Timestep Collection Time: 2.25890
Timestep Consumption Time: 2.41151
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.67042

Cumulative Model Updates: 181,508
Cumulative Timesteps: 1,513,646,334

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 373.22198
Policy Entropy: 3.75991
Value Function Loss: 0.03705

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13092
Policy Update Magnitude: 0.73523
Value Function Update Magnitude: 0.59230

Collected Steps per Second: 22,373.33139
Overall Steps per Second: 10,816.23443

Timestep Collection Time: 2.23516
Timestep Consumption Time: 2.38826
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.62342

Cumulative Model Updates: 181,514
Cumulative Timesteps: 1,513,696,342

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1513696342...
Checkpoint 1513696342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 254.74688
Policy Entropy: 3.75982
Value Function Loss: 0.02885

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13481
Policy Update Magnitude: 0.60564
Value Function Update Magnitude: 0.53923

Collected Steps per Second: 23,063.04259
Overall Steps per Second: 10,818.56137

Timestep Collection Time: 2.16901
Timestep Consumption Time: 2.45489
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.62390

Cumulative Model Updates: 181,520
Cumulative Timesteps: 1,513,746,366

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.74688
Policy Entropy: 3.75314
Value Function Loss: 0.02252

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10418
Policy Update Magnitude: 0.54953
Value Function Update Magnitude: 0.49478

Collected Steps per Second: 22,960.13536
Overall Steps per Second: 10,796.00883

Timestep Collection Time: 2.17873
Timestep Consumption Time: 2.45483
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.63356

Cumulative Model Updates: 181,526
Cumulative Timesteps: 1,513,796,390

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1513796390...
Checkpoint 1513796390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,503.29455
Policy Entropy: 3.72502
Value Function Loss: 0.02745

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.16935
Policy Update Magnitude: 0.48481
Value Function Update Magnitude: 0.58172

Collected Steps per Second: 22,885.53766
Overall Steps per Second: 10,662.58952

Timestep Collection Time: 2.18479
Timestep Consumption Time: 2.50451
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.68929

Cumulative Model Updates: 181,532
Cumulative Timesteps: 1,513,846,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,406.43410
Policy Entropy: 3.73941
Value Function Loss: 0.02703

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.17006
Policy Update Magnitude: 0.46848
Value Function Update Magnitude: 0.63763

Collected Steps per Second: 23,000.19402
Overall Steps per Second: 10,911.45677

Timestep Collection Time: 2.17607
Timestep Consumption Time: 2.41085
PPO Batch Consumption Time: 0.27618
Total Iteration Time: 4.58692

Cumulative Model Updates: 181,538
Cumulative Timesteps: 1,513,896,440

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1513896440...
Checkpoint 1513896440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,406.43410
Policy Entropy: 3.72740
Value Function Loss: 0.03061

Mean KL Divergence: 0.01176
SB3 Clip Fraction: 0.15555
Policy Update Magnitude: 0.40129
Value Function Update Magnitude: 0.49528

Collected Steps per Second: 22,761.98500
Overall Steps per Second: 10,684.09727

Timestep Collection Time: 2.19761
Timestep Consumption Time: 2.48430
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.68191

Cumulative Model Updates: 181,544
Cumulative Timesteps: 1,513,946,462

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,406.43410
Policy Entropy: 3.73384
Value Function Loss: 0.02441

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13767
Policy Update Magnitude: 0.32980
Value Function Update Magnitude: 0.35805

Collected Steps per Second: 22,967.55406
Overall Steps per Second: 10,854.04794

Timestep Collection Time: 2.17698
Timestep Consumption Time: 2.42959
PPO Batch Consumption Time: 0.27679
Total Iteration Time: 4.60658

Cumulative Model Updates: 181,550
Cumulative Timesteps: 1,513,996,462

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1513996462...
Checkpoint 1513996462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,406.43410
Policy Entropy: 3.70985
Value Function Loss: 0.02850

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13981
Policy Update Magnitude: 0.28350
Value Function Update Magnitude: 0.25842

Collected Steps per Second: 22,557.66677
Overall Steps per Second: 10,607.31849

Timestep Collection Time: 2.21769
Timestep Consumption Time: 2.49848
PPO Batch Consumption Time: 0.29014
Total Iteration Time: 4.71618

Cumulative Model Updates: 181,556
Cumulative Timesteps: 1,514,046,488

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,406.43410
Policy Entropy: 3.72796
Value Function Loss: 0.02392

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14706
Policy Update Magnitude: 0.26678
Value Function Update Magnitude: 0.19281

Collected Steps per Second: 22,700.90263
Overall Steps per Second: 10,841.77277

Timestep Collection Time: 2.20291
Timestep Consumption Time: 2.40962
PPO Batch Consumption Time: 0.27677
Total Iteration Time: 4.61253

Cumulative Model Updates: 181,562
Cumulative Timesteps: 1,514,096,496

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1514096496...
Checkpoint 1514096496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,406.43410
Policy Entropy: 3.72087
Value Function Loss: 0.02055

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14714
Policy Update Magnitude: 0.24831
Value Function Update Magnitude: 0.20894

Collected Steps per Second: 22,964.34918
Overall Steps per Second: 10,723.00788

Timestep Collection Time: 2.17746
Timestep Consumption Time: 2.48578
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.66324

Cumulative Model Updates: 181,568
Cumulative Timesteps: 1,514,146,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,406.43410
Policy Entropy: 3.71403
Value Function Loss: 0.02082

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.14125
Policy Update Magnitude: 0.24511
Value Function Update Magnitude: 0.24231

Collected Steps per Second: 22,015.09018
Overall Steps per Second: 10,811.97210

Timestep Collection Time: 2.27226
Timestep Consumption Time: 2.35446
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.62672

Cumulative Model Updates: 181,574
Cumulative Timesteps: 1,514,196,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1514196524...
Checkpoint 1514196524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 232,682.05437
Policy Entropy: 3.68913
Value Function Loss: 0.02731

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13868
Policy Update Magnitude: 0.29985
Value Function Update Magnitude: 0.31350

Collected Steps per Second: 22,172.37183
Overall Steps per Second: 10,739.34690

Timestep Collection Time: 2.25506
Timestep Consumption Time: 2.40072
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.65578

Cumulative Model Updates: 181,580
Cumulative Timesteps: 1,514,246,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,633.95183
Policy Entropy: 3.69241
Value Function Loss: 0.03527

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13617
Policy Update Magnitude: 0.41032
Value Function Update Magnitude: 0.43939

Collected Steps per Second: 22,260.69530
Overall Steps per Second: 10,581.82206

Timestep Collection Time: 2.24665
Timestep Consumption Time: 2.47957
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.72622

Cumulative Model Updates: 181,586
Cumulative Timesteps: 1,514,296,536

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1514296536...
Checkpoint 1514296536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,512.63420
Policy Entropy: 3.69385
Value Function Loss: 0.03920

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.49191
Value Function Update Magnitude: 0.62693

Collected Steps per Second: 23,182.72521
Overall Steps per Second: 11,024.10044

Timestep Collection Time: 2.15695
Timestep Consumption Time: 2.37893
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.53588

Cumulative Model Updates: 181,592
Cumulative Timesteps: 1,514,346,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,157.08505
Policy Entropy: 3.72283
Value Function Loss: 0.03934

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.51868
Value Function Update Magnitude: 0.69824

Collected Steps per Second: 22,977.33263
Overall Steps per Second: 10,867.05273

Timestep Collection Time: 2.17641
Timestep Consumption Time: 2.42539
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.60180

Cumulative Model Updates: 181,598
Cumulative Timesteps: 1,514,396,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1514396548...
Checkpoint 1514396548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,479.53299
Policy Entropy: 3.71662
Value Function Loss: 0.03469

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.47258
Value Function Update Magnitude: 0.74320

Collected Steps per Second: 22,625.66693
Overall Steps per Second: 10,612.32955

Timestep Collection Time: 2.21006
Timestep Consumption Time: 2.50182
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.71188

Cumulative Model Updates: 181,604
Cumulative Timesteps: 1,514,446,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,435.70507
Policy Entropy: 3.72002
Value Function Loss: 0.03063

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13761
Policy Update Magnitude: 0.46459
Value Function Update Magnitude: 0.69549

Collected Steps per Second: 22,654.83506
Overall Steps per Second: 10,677.91139

Timestep Collection Time: 2.20792
Timestep Consumption Time: 2.47652
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.68444

Cumulative Model Updates: 181,610
Cumulative Timesteps: 1,514,496,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1514496572...
Checkpoint 1514496572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,371.25940
Policy Entropy: 3.70377
Value Function Loss: 0.03207

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.43890
Value Function Update Magnitude: 0.61496

Collected Steps per Second: 22,787.44910
Overall Steps per Second: 10,832.93003

Timestep Collection Time: 2.19638
Timestep Consumption Time: 2.42379
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.62017

Cumulative Model Updates: 181,616
Cumulative Timesteps: 1,514,546,622

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,371.25940
Policy Entropy: 3.70025
Value Function Loss: 0.03024

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.42725
Value Function Update Magnitude: 0.47075

Collected Steps per Second: 22,862.21287
Overall Steps per Second: 10,726.16617

Timestep Collection Time: 2.18833
Timestep Consumption Time: 2.47597
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.66429

Cumulative Model Updates: 181,622
Cumulative Timesteps: 1,514,596,652

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1514596652...
Checkpoint 1514596652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,371.25940
Policy Entropy: 3.69187
Value Function Loss: 0.02887

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.41238
Value Function Update Magnitude: 0.44133

Collected Steps per Second: 22,878.80542
Overall Steps per Second: 10,846.72790

Timestep Collection Time: 2.18753
Timestep Consumption Time: 2.42658
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.61411

Cumulative Model Updates: 181,628
Cumulative Timesteps: 1,514,646,700

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,371.25940
Policy Entropy: 3.69149
Value Function Loss: 0.02472

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12937
Policy Update Magnitude: 0.40254
Value Function Update Magnitude: 0.46852

Collected Steps per Second: 22,711.61576
Overall Steps per Second: 10,671.12320

Timestep Collection Time: 2.20160
Timestep Consumption Time: 2.48413
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.68573

Cumulative Model Updates: 181,634
Cumulative Timesteps: 1,514,696,702

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1514696702...
Checkpoint 1514696702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,541.14988
Policy Entropy: 3.69861
Value Function Loss: 0.02545

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.38251
Value Function Update Magnitude: 0.47888

Collected Steps per Second: 22,130.97515
Overall Steps per Second: 10,880.17632

Timestep Collection Time: 2.25946
Timestep Consumption Time: 2.33642
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.59588

Cumulative Model Updates: 181,640
Cumulative Timesteps: 1,514,746,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 458,721.76554
Policy Entropy: 3.69806
Value Function Loss: 0.02676

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12875
Policy Update Magnitude: 0.37899
Value Function Update Magnitude: 0.49775

Collected Steps per Second: 22,316.00793
Overall Steps per Second: 10,894.02534

Timestep Collection Time: 2.24135
Timestep Consumption Time: 2.34997
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.59132

Cumulative Model Updates: 181,646
Cumulative Timesteps: 1,514,796,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1514796724...
Checkpoint 1514796724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,956.13604
Policy Entropy: 3.70069
Value Function Loss: 0.03025

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.41333
Value Function Update Magnitude: 0.48372

Collected Steps per Second: 22,269.86191
Overall Steps per Second: 10,730.07909

Timestep Collection Time: 2.24519
Timestep Consumption Time: 2.41461
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.65980

Cumulative Model Updates: 181,652
Cumulative Timesteps: 1,514,846,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,099.65517
Policy Entropy: 3.70443
Value Function Loss: 0.02980

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.44829
Value Function Update Magnitude: 0.48175

Collected Steps per Second: 22,138.35373
Overall Steps per Second: 10,600.32557

Timestep Collection Time: 2.25907
Timestep Consumption Time: 2.45890
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.71797

Cumulative Model Updates: 181,658
Cumulative Timesteps: 1,514,896,736

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1514896736...
Checkpoint 1514896736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,099.65517
Policy Entropy: 3.70237
Value Function Loss: 0.02783

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.46938
Value Function Update Magnitude: 0.48990

Collected Steps per Second: 22,815.54627
Overall Steps per Second: 10,930.36717

Timestep Collection Time: 2.19166
Timestep Consumption Time: 2.38311
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.57478

Cumulative Model Updates: 181,664
Cumulative Timesteps: 1,514,946,740

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,099.65517
Policy Entropy: 3.70842
Value Function Loss: 0.02233

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12939
Policy Update Magnitude: 0.45552
Value Function Update Magnitude: 0.49693

Collected Steps per Second: 22,987.96504
Overall Steps per Second: 10,871.71421

Timestep Collection Time: 2.17679
Timestep Consumption Time: 2.42598
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.60277

Cumulative Model Updates: 181,670
Cumulative Timesteps: 1,514,996,780

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1514996780...
Checkpoint 1514996780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 105,099.65517
Policy Entropy: 3.69751
Value Function Loss: 0.01794

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13128
Policy Update Magnitude: 0.39303
Value Function Update Magnitude: 0.43830

Collected Steps per Second: 22,594.98115
Overall Steps per Second: 10,698.07746

Timestep Collection Time: 2.21403
Timestep Consumption Time: 2.46214
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.67617

Cumulative Model Updates: 181,676
Cumulative Timesteps: 1,515,046,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,099.65517
Policy Entropy: 3.71923
Value Function Loss: 0.01445

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.17895
Policy Update Magnitude: 0.32947
Value Function Update Magnitude: 0.33547

Collected Steps per Second: 22,976.94221
Overall Steps per Second: 10,899.90579

Timestep Collection Time: 2.17688
Timestep Consumption Time: 2.41197
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.58885

Cumulative Model Updates: 181,682
Cumulative Timesteps: 1,515,096,824

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1515096824...
Checkpoint 1515096824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 516,951.05904
Policy Entropy: 3.70948
Value Function Loss: 0.01802

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.18681
Policy Update Magnitude: 0.30030
Value Function Update Magnitude: 0.43762

Collected Steps per Second: 22,978.44363
Overall Steps per Second: 10,727.03682

Timestep Collection Time: 2.17682
Timestep Consumption Time: 2.48616
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.66298

Cumulative Model Updates: 181,688
Cumulative Timesteps: 1,515,146,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,613.19912
Policy Entropy: 3.72896
Value Function Loss: 0.01954

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.15494
Policy Update Magnitude: 0.31585
Value Function Update Magnitude: 0.58789

Collected Steps per Second: 23,188.51279
Overall Steps per Second: 10,878.57869

Timestep Collection Time: 2.15650
Timestep Consumption Time: 2.44024
PPO Batch Consumption Time: 0.28060
Total Iteration Time: 4.59674

Cumulative Model Updates: 181,694
Cumulative Timesteps: 1,515,196,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1515196850...
Checkpoint 1515196850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,041.60274
Policy Entropy: 3.71345
Value Function Loss: 0.02252

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.16272
Policy Update Magnitude: 0.34137
Value Function Update Magnitude: 0.61423

Collected Steps per Second: 22,976.44565
Overall Steps per Second: 10,769.77515

Timestep Collection Time: 2.17684
Timestep Consumption Time: 2.46727
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.64411

Cumulative Model Updates: 181,700
Cumulative Timesteps: 1,515,246,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,041.60274
Policy Entropy: 3.71731
Value Function Loss: 0.02190

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14433
Policy Update Magnitude: 0.39100
Value Function Update Magnitude: 0.62806

Collected Steps per Second: 22,468.27063
Overall Steps per Second: 10,756.75396

Timestep Collection Time: 2.22652
Timestep Consumption Time: 2.42414
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.65066

Cumulative Model Updates: 181,706
Cumulative Timesteps: 1,515,296,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1515296892...
Checkpoint 1515296892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 113,041.60274
Policy Entropy: 3.69920
Value Function Loss: 0.01804

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14073
Policy Update Magnitude: 0.39977
Value Function Update Magnitude: 0.60239

Collected Steps per Second: 22,319.79252
Overall Steps per Second: 10,793.57306

Timestep Collection Time: 2.24025
Timestep Consumption Time: 2.39232
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.63257

Cumulative Model Updates: 181,712
Cumulative Timesteps: 1,515,346,894

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 636,283.54276
Policy Entropy: 3.70519
Value Function Loss: 0.01974

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06556
Policy Update Magnitude: 0.46510
Value Function Update Magnitude: 0.58172

Collected Steps per Second: 22,478.52106
Overall Steps per Second: 10,722.27387

Timestep Collection Time: 2.22443
Timestep Consumption Time: 2.43894
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.66338

Cumulative Model Updates: 181,718
Cumulative Timesteps: 1,515,396,896

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1515396896...
Checkpoint 1515396896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338,158.52067
Policy Entropy: 3.70493
Value Function Loss: 0.01954

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05622
Policy Update Magnitude: 0.51190
Value Function Update Magnitude: 0.59832

Collected Steps per Second: 22,842.69974
Overall Steps per Second: 10,740.08660

Timestep Collection Time: 2.19011
Timestep Consumption Time: 2.46795
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.65806

Cumulative Model Updates: 181,724
Cumulative Timesteps: 1,515,446,924

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 338,158.52067
Policy Entropy: 3.70560
Value Function Loss: 0.01939

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08789
Policy Update Magnitude: 0.48270
Value Function Update Magnitude: 0.60360

Collected Steps per Second: 22,745.74685
Overall Steps per Second: 10,931.84359

Timestep Collection Time: 2.19865
Timestep Consumption Time: 2.37606
PPO Batch Consumption Time: 0.27551
Total Iteration Time: 4.57471

Cumulative Model Updates: 181,730
Cumulative Timesteps: 1,515,496,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1515496934...
Checkpoint 1515496934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 522,056.61260
Policy Entropy: 3.71356
Value Function Loss: 0.01826

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.37658
Value Function Update Magnitude: 0.53210

Collected Steps per Second: 22,825.99472
Overall Steps per Second: 10,745.83939

Timestep Collection Time: 2.19075
Timestep Consumption Time: 2.46277
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.65352

Cumulative Model Updates: 181,736
Cumulative Timesteps: 1,515,546,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,041.81671
Policy Entropy: 3.71901
Value Function Loss: 0.01814

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07023
Policy Update Magnitude: 0.39317
Value Function Update Magnitude: 0.51986

Collected Steps per Second: 23,023.62420
Overall Steps per Second: 10,716.12350

Timestep Collection Time: 2.17307
Timestep Consumption Time: 2.49578
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.66885

Cumulative Model Updates: 181,742
Cumulative Timesteps: 1,515,596,972

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1515596972...
Checkpoint 1515596972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,433.50959
Policy Entropy: 3.71256
Value Function Loss: 0.01907

Mean KL Divergence: 0.01767
SB3 Clip Fraction: 0.21480
Policy Update Magnitude: 0.36725
Value Function Update Magnitude: 0.56620

Collected Steps per Second: 22,969.23457
Overall Steps per Second: 10,701.10461

Timestep Collection Time: 2.17787
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.67466

Cumulative Model Updates: 181,748
Cumulative Timesteps: 1,515,646,996

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 355,334.08199
Policy Entropy: 3.64087
Value Function Loss: 0.06549

Mean KL Divergence: 0.02524
SB3 Clip Fraction: 0.25602
Policy Update Magnitude: 0.41330
Value Function Update Magnitude: 0.54167

Collected Steps per Second: 22,732.84063
Overall Steps per Second: 10,815.02209

Timestep Collection Time: 2.20052
Timestep Consumption Time: 2.42490
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.62542

Cumulative Model Updates: 181,754
Cumulative Timesteps: 1,515,697,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1515697020...
Checkpoint 1515697020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337,097.16062
Policy Entropy: 3.61625
Value Function Loss: 0.11446

Mean KL Divergence: 0.02121
SB3 Clip Fraction: 0.21481
Policy Update Magnitude: 0.54984
Value Function Update Magnitude: 0.52257

Collected Steps per Second: 22,684.13619
Overall Steps per Second: 10,675.45149

Timestep Collection Time: 2.20542
Timestep Consumption Time: 2.48085
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.68627

Cumulative Model Updates: 181,760
Cumulative Timesteps: 1,515,747,048

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,167.39852
Policy Entropy: 3.61598
Value Function Loss: 0.14422

Mean KL Divergence: 0.01933
SB3 Clip Fraction: 0.19052
Policy Update Magnitude: 0.66587
Value Function Update Magnitude: 0.51527

Collected Steps per Second: 23,142.81950
Overall Steps per Second: 10,877.12680

Timestep Collection Time: 2.16162
Timestep Consumption Time: 2.43757
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.59919

Cumulative Model Updates: 181,766
Cumulative Timesteps: 1,515,797,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1515797074...
Checkpoint 1515797074 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 439.83336
Policy Entropy: 3.75712
Value Function Loss: 0.11841

Mean KL Divergence: 0.01609
SB3 Clip Fraction: 0.15895
Policy Update Magnitude: 0.81901
Value Function Update Magnitude: 0.69590

Collected Steps per Second: 22,827.34543
Overall Steps per Second: 10,727.75500

Timestep Collection Time: 2.19141
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.66304

Cumulative Model Updates: 181,772
Cumulative Timesteps: 1,515,847,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,778.41019
Policy Entropy: 3.80656
Value Function Loss: 0.09110

Mean KL Divergence: 0.01649
SB3 Clip Fraction: 0.15730
Policy Update Magnitude: 0.96254
Value Function Update Magnitude: 0.75771

Collected Steps per Second: 22,301.77649
Overall Steps per Second: 10,865.95910

Timestep Collection Time: 2.24224
Timestep Consumption Time: 2.35984
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.60208

Cumulative Model Updates: 181,778
Cumulative Timesteps: 1,515,897,104

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1515897104...
Checkpoint 1515897104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,247.79506
Policy Entropy: 3.85505
Value Function Loss: 0.07176

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.15475
Policy Update Magnitude: 0.97619
Value Function Update Magnitude: 0.85185

Collected Steps per Second: 22,338.43184
Overall Steps per Second: 10,780.77987

Timestep Collection Time: 2.23946
Timestep Consumption Time: 2.40084
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.64030

Cumulative Model Updates: 181,784
Cumulative Timesteps: 1,515,947,130

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,107.78133
Policy Entropy: 3.85686
Value Function Loss: 0.06429

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.14668
Policy Update Magnitude: 1.21905
Value Function Update Magnitude: 0.95740

Collected Steps per Second: 23,058.39635
Overall Steps per Second: 10,754.16154

Timestep Collection Time: 2.16884
Timestep Consumption Time: 2.48145
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.65029

Cumulative Model Updates: 181,790
Cumulative Timesteps: 1,515,997,140

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1515997140...
Checkpoint 1515997140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 609.41791
Policy Entropy: 3.91717
Value Function Loss: 0.05486

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.13888
Policy Update Magnitude: 1.35544
Value Function Update Magnitude: 1.02536

Collected Steps per Second: 22,666.53151
Overall Steps per Second: 10,618.00585

Timestep Collection Time: 2.20687
Timestep Consumption Time: 2.50419
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.71105

Cumulative Model Updates: 181,796
Cumulative Timesteps: 1,516,047,162

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15.52862
Policy Entropy: 3.91982
Value Function Loss: 0.05743

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.13067
Policy Update Magnitude: 1.32301
Value Function Update Magnitude: 1.09629

Collected Steps per Second: 22,758.01000
Overall Steps per Second: 10,843.80998

Timestep Collection Time: 2.19773
Timestep Consumption Time: 2.41467
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.61240

Cumulative Model Updates: 181,802
Cumulative Timesteps: 1,516,097,178

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1516097178...
Checkpoint 1516097178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 822.60350
Policy Entropy: 3.90053
Value Function Loss: 0.06366

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.12307
Policy Update Magnitude: 1.20380
Value Function Update Magnitude: 0.93147

Collected Steps per Second: 22,057.69798
Overall Steps per Second: 10,670.04339

Timestep Collection Time: 2.26687
Timestep Consumption Time: 2.41933
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.68620

Cumulative Model Updates: 181,808
Cumulative Timesteps: 1,516,147,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25.44462
Policy Entropy: 3.85582
Value Function Loss: 0.06764

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.11558
Policy Update Magnitude: 1.03190
Value Function Update Magnitude: 0.79895

Collected Steps per Second: 22,642.04806
Overall Steps per Second: 10,641.81353

Timestep Collection Time: 2.20969
Timestep Consumption Time: 2.49176
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.70145

Cumulative Model Updates: 181,814
Cumulative Timesteps: 1,516,197,212

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1516197212...
Checkpoint 1516197212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43.73358
Policy Entropy: 3.89720
Value Function Loss: 0.06499

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 1.02693
Value Function Update Magnitude: 0.69767

Collected Steps per Second: 22,638.21447
Overall Steps per Second: 10,863.73800

Timestep Collection Time: 2.20874
Timestep Consumption Time: 2.39391
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.60265

Cumulative Model Updates: 181,820
Cumulative Timesteps: 1,516,247,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,496.88822
Policy Entropy: 3.90694
Value Function Loss: 0.06423

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 1.00355
Value Function Update Magnitude: 0.70699

Collected Steps per Second: 22,498.22824
Overall Steps per Second: 10,633.69233

Timestep Collection Time: 2.22293
Timestep Consumption Time: 2.48023
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.70316

Cumulative Model Updates: 181,826
Cumulative Timesteps: 1,516,297,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1516297226...
Checkpoint 1516297226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153.55558
Policy Entropy: 3.92472
Value Function Loss: 0.06074

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10076
Policy Update Magnitude: 0.93612
Value Function Update Magnitude: 0.75534

Collected Steps per Second: 22,552.35368
Overall Steps per Second: 10,719.26982

Timestep Collection Time: 2.21804
Timestep Consumption Time: 2.44851
PPO Batch Consumption Time: 0.28840
Total Iteration Time: 4.66655

Cumulative Model Updates: 181,832
Cumulative Timesteps: 1,516,347,248

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.50385
Policy Entropy: 3.85939
Value Function Loss: 0.06396

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.76608
Value Function Update Magnitude: 0.67639

Collected Steps per Second: 22,988.83223
Overall Steps per Second: 10,761.21122

Timestep Collection Time: 2.17575
Timestep Consumption Time: 2.47224
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.64799

Cumulative Model Updates: 181,838
Cumulative Timesteps: 1,516,397,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1516397266...
Checkpoint 1516397266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,836.44685
Policy Entropy: 3.79373
Value Function Loss: 0.05911

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.11771
Policy Update Magnitude: 0.63402
Value Function Update Magnitude: 0.49053

Collected Steps per Second: 22,630.15849
Overall Steps per Second: 10,665.37363

Timestep Collection Time: 2.20944
Timestep Consumption Time: 2.47863
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.68807

Cumulative Model Updates: 181,844
Cumulative Timesteps: 1,516,447,266

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,985.55085
Policy Entropy: 3.74568
Value Function Loss: 0.05434

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14396
Policy Update Magnitude: 0.51693
Value Function Update Magnitude: 0.41834

Collected Steps per Second: 23,154.10056
Overall Steps per Second: 10,866.99144

Timestep Collection Time: 2.15988
Timestep Consumption Time: 2.44213
PPO Batch Consumption Time: 0.28546
Total Iteration Time: 4.60201

Cumulative Model Updates: 181,850
Cumulative Timesteps: 1,516,497,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1516497276...
Checkpoint 1516497276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,206.05596
Policy Entropy: 3.75365
Value Function Loss: 0.04869

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13535
Policy Update Magnitude: 0.46716
Value Function Update Magnitude: 0.51471

Collected Steps per Second: 22,586.55016
Overall Steps per Second: 10,628.77505

Timestep Collection Time: 2.21442
Timestep Consumption Time: 2.49130
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.70572

Cumulative Model Updates: 181,856
Cumulative Timesteps: 1,516,547,292

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,123.39959
Policy Entropy: 3.76439
Value Function Loss: 0.04096

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.48175
Value Function Update Magnitude: 0.58981

Collected Steps per Second: 22,927.40591
Overall Steps per Second: 10,831.68819

Timestep Collection Time: 2.18158
Timestep Consumption Time: 2.43617
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.61775

Cumulative Model Updates: 181,862
Cumulative Timesteps: 1,516,597,310

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1516597310...
Checkpoint 1516597310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,406.06845
Policy Entropy: 3.77154
Value Function Loss: 0.03583

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14226
Policy Update Magnitude: 0.46207
Value Function Update Magnitude: 0.58842

Collected Steps per Second: 22,785.07072
Overall Steps per Second: 10,641.57680

Timestep Collection Time: 2.19459
Timestep Consumption Time: 2.50433
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.69893

Cumulative Model Updates: 181,868
Cumulative Timesteps: 1,516,647,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,406.06845
Policy Entropy: 3.74613
Value Function Loss: 0.02981

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.16033
Policy Update Magnitude: 0.42335
Value Function Update Magnitude: 0.51250

Collected Steps per Second: 22,869.37511
Overall Steps per Second: 10,867.48627

Timestep Collection Time: 2.18738
Timestep Consumption Time: 2.41571
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.60309

Cumulative Model Updates: 181,874
Cumulative Timesteps: 1,516,697,338

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1516697338...
Checkpoint 1516697338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,406.06845
Policy Entropy: 3.75909
Value Function Loss: 0.02706

Mean KL Divergence: 0.01944
SB3 Clip Fraction: 0.21538
Policy Update Magnitude: 0.39722
Value Function Update Magnitude: 0.44390

Collected Steps per Second: 22,544.42321
Overall Steps per Second: 10,722.74417

Timestep Collection Time: 2.21855
Timestep Consumption Time: 2.44592
PPO Batch Consumption Time: 0.28210
Total Iteration Time: 4.66448

Cumulative Model Updates: 181,880
Cumulative Timesteps: 1,516,747,354

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,225.40888
Policy Entropy: 3.77342
Value Function Loss: 0.03360

Mean KL Divergence: 0.01874
SB3 Clip Fraction: 0.21333
Policy Update Magnitude: 0.43552
Value Function Update Magnitude: 0.44431

Collected Steps per Second: 23,013.13840
Overall Steps per Second: 10,866.13063

Timestep Collection Time: 2.17345
Timestep Consumption Time: 2.42966
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.60311

Cumulative Model Updates: 181,886
Cumulative Timesteps: 1,516,797,372

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1516797372...
Checkpoint 1516797372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,414.92550
Policy Entropy: 3.77951
Value Function Loss: 0.03574

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.59811
Value Function Update Magnitude: 0.43826

Collected Steps per Second: 22,784.79455
Overall Steps per Second: 10,691.29767

Timestep Collection Time: 2.19462
Timestep Consumption Time: 2.48245
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.67707

Cumulative Model Updates: 181,892
Cumulative Timesteps: 1,516,847,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,776.52020
Policy Entropy: 3.75176
Value Function Loss: 0.03590

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.65523
Value Function Update Magnitude: 0.46933

Collected Steps per Second: 22,304.65263
Overall Steps per Second: 10,901.00285

Timestep Collection Time: 2.24186
Timestep Consumption Time: 2.34524
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.58710

Cumulative Model Updates: 181,898
Cumulative Timesteps: 1,516,897,380

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1516897380...
Checkpoint 1516897380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,776.52020
Policy Entropy: 3.73241
Value Function Loss: 0.02701

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.56742
Value Function Update Magnitude: 0.38289

Collected Steps per Second: 21,842.39234
Overall Steps per Second: 10,661.58790

Timestep Collection Time: 2.28949
Timestep Consumption Time: 2.40099
PPO Batch Consumption Time: 0.28823
Total Iteration Time: 4.69048

Cumulative Model Updates: 181,904
Cumulative Timesteps: 1,516,947,388

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,776.52020
Policy Entropy: 3.72261
Value Function Loss: 0.02224

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.19757
Policy Update Magnitude: 0.40381
Value Function Update Magnitude: 0.35566

Collected Steps per Second: 22,298.65400
Overall Steps per Second: 10,918.24893

Timestep Collection Time: 2.24238
Timestep Consumption Time: 2.33729
PPO Batch Consumption Time: 0.27689
Total Iteration Time: 4.57967

Cumulative Model Updates: 181,910
Cumulative Timesteps: 1,516,997,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1516997390...
Checkpoint 1516997390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,776.52020
Policy Entropy: 3.71682
Value Function Loss: 0.02103

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.16822
Policy Update Magnitude: 0.32336
Value Function Update Magnitude: 0.31558

Collected Steps per Second: 22,011.80507
Overall Steps per Second: 10,620.86007

Timestep Collection Time: 2.27287
Timestep Consumption Time: 2.43767
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.71054

Cumulative Model Updates: 181,916
Cumulative Timesteps: 1,517,047,420

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,435.39605
Policy Entropy: 3.67172
Value Function Loss: 0.02661

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.18537
Policy Update Magnitude: 0.34903
Value Function Update Magnitude: 0.29092

Collected Steps per Second: 23,103.99541
Overall Steps per Second: 10,900.54481

Timestep Collection Time: 2.16525
Timestep Consumption Time: 2.42406
PPO Batch Consumption Time: 0.28233
Total Iteration Time: 4.58931

Cumulative Model Updates: 181,922
Cumulative Timesteps: 1,517,097,446

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1517097446...
Checkpoint 1517097446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,912.85112
Policy Entropy: 3.68263
Value Function Loss: 0.04232

Mean KL Divergence: 0.00756
SB3 Clip Fraction: 0.09629
Policy Update Magnitude: 0.60122
Value Function Update Magnitude: 0.35607

Collected Steps per Second: 22,488.43781
Overall Steps per Second: 10,655.76589

Timestep Collection Time: 2.22425
Timestep Consumption Time: 2.46992
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.69417

Cumulative Model Updates: 181,928
Cumulative Timesteps: 1,517,147,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,936.13177
Policy Entropy: 3.71913
Value Function Loss: 0.05109

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13937
Policy Update Magnitude: 0.70619
Value Function Update Magnitude: 0.51940

Collected Steps per Second: 22,972.65473
Overall Steps per Second: 10,934.32390

Timestep Collection Time: 2.17789
Timestep Consumption Time: 2.39779
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.57568

Cumulative Model Updates: 181,934
Cumulative Timesteps: 1,517,197,498

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1517197498...
Checkpoint 1517197498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,589.63769
Policy Entropy: 3.72092
Value Function Loss: 0.05219

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.16349
Policy Update Magnitude: 0.59178
Value Function Update Magnitude: 0.58653

Collected Steps per Second: 22,482.86942
Overall Steps per Second: 10,616.10167

Timestep Collection Time: 2.22498
Timestep Consumption Time: 2.48710
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.71209

Cumulative Model Updates: 181,940
Cumulative Timesteps: 1,517,247,522

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,589.63769
Policy Entropy: 3.71130
Value Function Loss: 0.03407

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.15040
Policy Update Magnitude: 0.46619
Value Function Update Magnitude: 0.64956

Collected Steps per Second: 22,886.65225
Overall Steps per Second: 10,836.66698

Timestep Collection Time: 2.18468
Timestep Consumption Time: 2.42929
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.61396

Cumulative Model Updates: 181,946
Cumulative Timesteps: 1,517,297,522

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1517297522...
Checkpoint 1517297522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,924.73721
Policy Entropy: 3.66850
Value Function Loss: 0.03121

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14723
Policy Update Magnitude: 0.42502
Value Function Update Magnitude: 0.58960

Collected Steps per Second: 22,556.19058
Overall Steps per Second: 10,736.44301

Timestep Collection Time: 2.21740
Timestep Consumption Time: 2.44113
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.65853

Cumulative Model Updates: 181,952
Cumulative Timesteps: 1,517,347,538

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,126.49501
Policy Entropy: 3.66564
Value Function Loss: 0.03130

Mean KL Divergence: 0.00787
SB3 Clip Fraction: 0.10204
Policy Update Magnitude: 0.49809
Value Function Update Magnitude: 0.52623

Collected Steps per Second: 23,083.05845
Overall Steps per Second: 10,932.18824

Timestep Collection Time: 2.16713
Timestep Consumption Time: 2.40871
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.57585

Cumulative Model Updates: 181,958
Cumulative Timesteps: 1,517,397,562

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1517397562...
Checkpoint 1517397562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,510.63943
Policy Entropy: 3.67143
Value Function Loss: 0.03263

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10787
Policy Update Magnitude: 0.58391
Value Function Update Magnitude: 0.52627

Collected Steps per Second: 22,712.57707
Overall Steps per Second: 10,670.11755

Timestep Collection Time: 2.20257
Timestep Consumption Time: 2.48585
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.68842

Cumulative Model Updates: 181,964
Cumulative Timesteps: 1,517,447,588

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,510.63943
Policy Entropy: 3.68947
Value Function Loss: 0.02891

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.08728
Policy Update Magnitude: 0.57334
Value Function Update Magnitude: 0.49560

Collected Steps per Second: 23,267.38055
Overall Steps per Second: 10,858.96427

Timestep Collection Time: 2.14893
Timestep Consumption Time: 2.45556
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.60449

Cumulative Model Updates: 181,970
Cumulative Timesteps: 1,517,497,588

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1517497588...
Checkpoint 1517497588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,510.63943
Policy Entropy: 3.68132
Value Function Loss: 0.02484

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08414
Policy Update Magnitude: 0.57469
Value Function Update Magnitude: 0.49743

Collected Steps per Second: 22,138.87564
Overall Steps per Second: 10,740.06383

Timestep Collection Time: 2.25937
Timestep Consumption Time: 2.39795
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.65733

Cumulative Model Updates: 181,976
Cumulative Timesteps: 1,517,547,608

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,510.63943
Policy Entropy: 3.65676
Value Function Loss: 0.02075

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09505
Policy Update Magnitude: 0.52422
Value Function Update Magnitude: 0.49611

Collected Steps per Second: 22,453.28991
Overall Steps per Second: 10,796.72934

Timestep Collection Time: 2.22774
Timestep Consumption Time: 2.40515
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.63288

Cumulative Model Updates: 181,982
Cumulative Timesteps: 1,517,597,628

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1517597628...
Checkpoint 1517597628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,510.63943
Policy Entropy: 3.66471
Value Function Loss: 0.02047

Mean KL Divergence: 0.01363
SB3 Clip Fraction: 0.16891
Policy Update Magnitude: 0.43361
Value Function Update Magnitude: 0.49725

Collected Steps per Second: 21,737.78285
Overall Steps per Second: 10,656.82219

Timestep Collection Time: 2.30042
Timestep Consumption Time: 2.39197
PPO Batch Consumption Time: 0.27635
Total Iteration Time: 4.69239

Cumulative Model Updates: 181,988
Cumulative Timesteps: 1,517,647,634

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,510.63943
Policy Entropy: 3.67073
Value Function Loss: 0.01976

Mean KL Divergence: 0.01457
SB3 Clip Fraction: 0.17961
Policy Update Magnitude: 0.36952
Value Function Update Magnitude: 0.57805

Collected Steps per Second: 23,383.81798
Overall Steps per Second: 10,925.33265

Timestep Collection Time: 2.13909
Timestep Consumption Time: 2.43926
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.57835

Cumulative Model Updates: 181,994
Cumulative Timesteps: 1,517,697,654

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1517697654...
Checkpoint 1517697654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,267.59213
Policy Entropy: 3.65927
Value Function Loss: 0.02963

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15444
Policy Update Magnitude: 0.36665
Value Function Update Magnitude: 0.64415

Collected Steps per Second: 22,678.97411
Overall Steps per Second: 10,709.87451

Timestep Collection Time: 2.20513
Timestep Consumption Time: 2.46440
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.66952

Cumulative Model Updates: 182,000
Cumulative Timesteps: 1,517,747,664

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,396.91431
Policy Entropy: 3.64567
Value Function Loss: 0.03933

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.14178
Policy Update Magnitude: 0.41265
Value Function Update Magnitude: 0.62198

Collected Steps per Second: 23,374.70150
Overall Steps per Second: 10,798.77799

Timestep Collection Time: 2.14009
Timestep Consumption Time: 2.49228
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.63238

Cumulative Model Updates: 182,006
Cumulative Timesteps: 1,517,797,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1517797688...
Checkpoint 1517797688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,880.83467
Policy Entropy: 3.66148
Value Function Loss: 0.04438

Mean KL Divergence: 0.01536
SB3 Clip Fraction: 0.18947
Policy Update Magnitude: 0.49193
Value Function Update Magnitude: 0.62815

Collected Steps per Second: 22,738.27570
Overall Steps per Second: 10,621.63836

Timestep Collection Time: 2.19920
Timestep Consumption Time: 2.50874
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.70794

Cumulative Model Updates: 182,012
Cumulative Timesteps: 1,517,847,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,880.83467
Policy Entropy: 3.64867
Value Function Loss: 0.04536

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.18847
Policy Update Magnitude: 0.45147
Value Function Update Magnitude: 0.60843

Collected Steps per Second: 22,891.53743
Overall Steps per Second: 10,862.76414

Timestep Collection Time: 2.18526
Timestep Consumption Time: 2.41983
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.60509

Cumulative Model Updates: 182,018
Cumulative Timesteps: 1,517,897,718

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1517897718...
Checkpoint 1517897718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,720.07572
Policy Entropy: 3.67018
Value Function Loss: 0.04048

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.17909
Policy Update Magnitude: 0.43616
Value Function Update Magnitude: 0.54515

Collected Steps per Second: 22,245.99806
Overall Steps per Second: 10,702.84543

Timestep Collection Time: 2.24831
Timestep Consumption Time: 2.42484
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.67315

Cumulative Model Updates: 182,024
Cumulative Timesteps: 1,517,947,734

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,785.36717
Policy Entropy: 3.66292
Value Function Loss: 0.03746

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16736
Policy Update Magnitude: 0.42913
Value Function Update Magnitude: 0.52993

Collected Steps per Second: 23,173.36839
Overall Steps per Second: 10,906.57677

Timestep Collection Time: 2.15894
Timestep Consumption Time: 2.42820
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.58714

Cumulative Model Updates: 182,030
Cumulative Timesteps: 1,517,997,764

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1517997764...
Checkpoint 1517997764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,178.56009
Policy Entropy: 3.70785
Value Function Loss: 0.02973

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14371
Policy Update Magnitude: 0.43789
Value Function Update Magnitude: 0.60815

Collected Steps per Second: 22,826.59176
Overall Steps per Second: 10,688.37394

Timestep Collection Time: 2.19069
Timestep Consumption Time: 2.48785
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.67854

Cumulative Model Updates: 182,036
Cumulative Timesteps: 1,518,047,770

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,178.56009
Policy Entropy: 3.68613
Value Function Loss: 0.02738

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13983
Policy Update Magnitude: 0.43585
Value Function Update Magnitude: 0.66653

Collected Steps per Second: 22,452.93287
Overall Steps per Second: 10,883.05474

Timestep Collection Time: 2.22786
Timestep Consumption Time: 2.36846
PPO Batch Consumption Time: 0.28138
Total Iteration Time: 4.59632

Cumulative Model Updates: 182,042
Cumulative Timesteps: 1,518,097,792

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1518097792...
Checkpoint 1518097792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,506.97691
Policy Entropy: 3.70230
Value Function Loss: 0.02524

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.40190
Value Function Update Magnitude: 0.71449

Collected Steps per Second: 21,792.73403
Overall Steps per Second: 10,630.65214

Timestep Collection Time: 2.29535
Timestep Consumption Time: 2.41010
PPO Batch Consumption Time: 0.28986
Total Iteration Time: 4.70545

Cumulative Model Updates: 182,048
Cumulative Timesteps: 1,518,147,814

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,506.97691
Policy Entropy: 3.67731
Value Function Loss: 0.02759

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.40440
Value Function Update Magnitude: 0.64493

Collected Steps per Second: 22,458.69911
Overall Steps per Second: 10,938.20244

Timestep Collection Time: 2.22729
Timestep Consumption Time: 2.34586
PPO Batch Consumption Time: 0.27664
Total Iteration Time: 4.57315

Cumulative Model Updates: 182,054
Cumulative Timesteps: 1,518,197,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1518197836...
Checkpoint 1518197836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,506.97691
Policy Entropy: 3.70342
Value Function Loss: 0.02571

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.40617
Value Function Update Magnitude: 0.61261

Collected Steps per Second: 22,129.90343
Overall Steps per Second: 10,584.63327

Timestep Collection Time: 2.26002
Timestep Consumption Time: 2.46513
PPO Batch Consumption Time: 0.28908
Total Iteration Time: 4.72515

Cumulative Model Updates: 182,060
Cumulative Timesteps: 1,518,247,850

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,506.97691
Policy Entropy: 3.69362
Value Function Loss: 0.02444

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.39277
Value Function Update Magnitude: 0.64495

Collected Steps per Second: 22,964.15611
Overall Steps per Second: 10,912.64078

Timestep Collection Time: 2.17757
Timestep Consumption Time: 2.40482
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.58239

Cumulative Model Updates: 182,066
Cumulative Timesteps: 1,518,297,856

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1518297856...
Checkpoint 1518297856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,971.50824
Policy Entropy: 3.70615
Value Function Loss: 0.02683

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.35593
Value Function Update Magnitude: 0.55020

Collected Steps per Second: 22,554.68619
Overall Steps per Second: 10,666.52927

Timestep Collection Time: 2.21754
Timestep Consumption Time: 2.47152
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.68906

Cumulative Model Updates: 182,072
Cumulative Timesteps: 1,518,347,872

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,848.26941
Policy Entropy: 3.71874
Value Function Loss: 0.02621

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12945
Policy Update Magnitude: 0.35039
Value Function Update Magnitude: 0.55207

Collected Steps per Second: 23,040.98222
Overall Steps per Second: 10,872.38029

Timestep Collection Time: 2.17109
Timestep Consumption Time: 2.42993
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.60102

Cumulative Model Updates: 182,078
Cumulative Timesteps: 1,518,397,896

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1518397896...
Checkpoint 1518397896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,848.26941
Policy Entropy: 3.71471
Value Function Loss: 0.02736

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12983
Policy Update Magnitude: 0.37134
Value Function Update Magnitude: 0.55382

Collected Steps per Second: 22,441.69360
Overall Steps per Second: 10,673.40963

Timestep Collection Time: 2.22826
Timestep Consumption Time: 2.45684
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.68510

Cumulative Model Updates: 182,084
Cumulative Timesteps: 1,518,447,902

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,848.26941
Policy Entropy: 3.71404
Value Function Loss: 0.02503

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.40350
Value Function Update Magnitude: 0.59915

Collected Steps per Second: 22,995.34091
Overall Steps per Second: 10,889.66707

Timestep Collection Time: 2.17435
Timestep Consumption Time: 2.41716
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.59151

Cumulative Model Updates: 182,090
Cumulative Timesteps: 1,518,497,902

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1518497902...
Checkpoint 1518497902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,610.52919
Policy Entropy: 3.70421
Value Function Loss: 0.02267

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.13262
Policy Update Magnitude: 0.40465
Value Function Update Magnitude: 0.72534

Collected Steps per Second: 22,425.79592
Overall Steps per Second: 10,647.58678

Timestep Collection Time: 2.23047
Timestep Consumption Time: 2.46731
PPO Batch Consumption Time: 0.28675
Total Iteration Time: 4.69778

Cumulative Model Updates: 182,096
Cumulative Timesteps: 1,518,547,922

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,610.52919
Policy Entropy: 3.70651
Value Function Loss: 0.02002

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.36471
Value Function Update Magnitude: 0.73038

Collected Steps per Second: 23,137.48860
Overall Steps per Second: 10,877.05260

Timestep Collection Time: 2.16203
Timestep Consumption Time: 2.43701
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.59904

Cumulative Model Updates: 182,102
Cumulative Timesteps: 1,518,597,946

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1518597946...
Checkpoint 1518597946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 139,545.23215
Policy Entropy: 3.70032
Value Function Loss: 0.02094

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.31930
Value Function Update Magnitude: 0.62999

Collected Steps per Second: 22,930.72478
Overall Steps per Second: 10,670.97679

Timestep Collection Time: 2.18240
Timestep Consumption Time: 2.50733
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.68973

Cumulative Model Updates: 182,108
Cumulative Timesteps: 1,518,647,990

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,008.92113
Policy Entropy: 3.68848
Value Function Loss: 0.02477

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.12302
Policy Update Magnitude: 0.32398
Value Function Update Magnitude: 0.60099

Collected Steps per Second: 23,261.09241
Overall Steps per Second: 10,987.17862

Timestep Collection Time: 2.15003
Timestep Consumption Time: 2.40182
PPO Batch Consumption Time: 0.27568
Total Iteration Time: 4.55185

Cumulative Model Updates: 182,114
Cumulative Timesteps: 1,518,698,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1518698002...
Checkpoint 1518698002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,902.13232
Policy Entropy: 3.69218
Value Function Loss: 0.03000

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.36535
Value Function Update Magnitude: 0.58325

Collected Steps per Second: 21,994.11910
Overall Steps per Second: 10,718.69286

Timestep Collection Time: 2.27424
Timestep Consumption Time: 2.39237
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.66661

Cumulative Model Updates: 182,120
Cumulative Timesteps: 1,518,748,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,711.50438
Policy Entropy: 3.70324
Value Function Loss: 0.02931

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12916
Policy Update Magnitude: 0.40978
Value Function Update Magnitude: 0.57065

Collected Steps per Second: 22,746.06032
Overall Steps per Second: 10,833.72147

Timestep Collection Time: 2.19959
Timestep Consumption Time: 2.41858
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.61817

Cumulative Model Updates: 182,126
Cumulative Timesteps: 1,518,798,054

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1518798054...
Checkpoint 1518798054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,711.50438
Policy Entropy: 3.69320
Value Function Loss: 0.02351

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.38556
Value Function Update Magnitude: 0.50313

Collected Steps per Second: 22,260.97571
Overall Steps per Second: 10,768.93077

Timestep Collection Time: 2.24662
Timestep Consumption Time: 2.39748
PPO Batch Consumption Time: 0.28763
Total Iteration Time: 4.64410

Cumulative Model Updates: 182,132
Cumulative Timesteps: 1,518,848,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,711.50438
Policy Entropy: 3.68783
Value Function Loss: 0.01863

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12641
Policy Update Magnitude: 0.32855
Value Function Update Magnitude: 0.42448

Collected Steps per Second: 22,847.86649
Overall Steps per Second: 10,738.07513

Timestep Collection Time: 2.18953
Timestep Consumption Time: 2.46922
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.65875

Cumulative Model Updates: 182,138
Cumulative Timesteps: 1,518,898,092

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1518898092...
Checkpoint 1518898092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,711.50438
Policy Entropy: 3.69674
Value Function Loss: 0.01556

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.29341
Value Function Update Magnitude: 0.37726

Collected Steps per Second: 22,555.10990
Overall Steps per Second: 10,676.17519

Timestep Collection Time: 2.21795
Timestep Consumption Time: 2.46782
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.68576

Cumulative Model Updates: 182,144
Cumulative Timesteps: 1,518,948,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,711.50438
Policy Entropy: 3.69443
Value Function Loss: 0.01700

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.27345
Value Function Update Magnitude: 0.37874

Collected Steps per Second: 23,349.91636
Overall Steps per Second: 10,889.66854

Timestep Collection Time: 2.14151
Timestep Consumption Time: 2.45037
PPO Batch Consumption Time: 0.28164
Total Iteration Time: 4.59188

Cumulative Model Updates: 182,150
Cumulative Timesteps: 1,518,998,122

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1518998122...
Checkpoint 1518998122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,711.50438
Policy Entropy: 3.71870
Value Function Loss: 0.01636

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.29812
Value Function Update Magnitude: 0.41662

Collected Steps per Second: 22,905.09001
Overall Steps per Second: 10,723.12416

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.48218
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.66711

Cumulative Model Updates: 182,156
Cumulative Timesteps: 1,519,048,168

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,711.50438
Policy Entropy: 3.69840
Value Function Loss: 0.01751

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12894
Policy Update Magnitude: 0.31141
Value Function Update Magnitude: 0.45282

Collected Steps per Second: 23,208.17700
Overall Steps per Second: 10,842.99426

Timestep Collection Time: 2.15579
Timestep Consumption Time: 2.45843
PPO Batch Consumption Time: 0.28533
Total Iteration Time: 4.61422

Cumulative Model Updates: 182,162
Cumulative Timesteps: 1,519,098,200

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1519098200...
Checkpoint 1519098200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,201.89528
Policy Entropy: 3.70262
Value Function Loss: 0.01889

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12543
Policy Update Magnitude: 0.34286
Value Function Update Magnitude: 0.55594

Collected Steps per Second: 22,343.36741
Overall Steps per Second: 10,617.81104

Timestep Collection Time: 2.23887
Timestep Consumption Time: 2.47245
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.71133

Cumulative Model Updates: 182,168
Cumulative Timesteps: 1,519,148,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,227.58163
Policy Entropy: 3.67961
Value Function Loss: 0.02156

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.37980
Value Function Update Magnitude: 0.66353

Collected Steps per Second: 22,940.59187
Overall Steps per Second: 10,888.85598

Timestep Collection Time: 2.18059
Timestep Consumption Time: 2.41347
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.59405

Cumulative Model Updates: 182,174
Cumulative Timesteps: 1,519,198,248

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1519198248...
Checkpoint 1519198248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,227.58163
Policy Entropy: 3.68659
Value Function Loss: 0.02045

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.36383
Value Function Update Magnitude: 0.68413

Collected Steps per Second: 22,753.81195
Overall Steps per Second: 10,647.86441

Timestep Collection Time: 2.19743
Timestep Consumption Time: 2.49834
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.69578

Cumulative Model Updates: 182,180
Cumulative Timesteps: 1,519,248,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,227.58163
Policy Entropy: 3.69761
Value Function Loss: 0.01829

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.31560
Value Function Update Magnitude: 0.55998

Collected Steps per Second: 23,289.80026
Overall Steps per Second: 10,961.09591

Timestep Collection Time: 2.14703
Timestep Consumption Time: 2.41492
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.56195

Cumulative Model Updates: 182,186
Cumulative Timesteps: 1,519,298,252

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1519298252...
Checkpoint 1519298252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,227.58163
Policy Entropy: 3.70233
Value Function Loss: 0.01518

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.26787
Value Function Update Magnitude: 0.40135

Collected Steps per Second: 21,721.78633
Overall Steps per Second: 10,612.79471

Timestep Collection Time: 2.30313
Timestep Consumption Time: 2.41081
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.71393

Cumulative Model Updates: 182,192
Cumulative Timesteps: 1,519,348,280

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,227.58163
Policy Entropy: 3.70203
Value Function Loss: 0.01540

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.12299
Policy Update Magnitude: 0.26015
Value Function Update Magnitude: 0.37541

Collected Steps per Second: 22,195.17809
Overall Steps per Second: 10,862.28123

Timestep Collection Time: 2.25409
Timestep Consumption Time: 2.35175
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.60585

Cumulative Model Updates: 182,198
Cumulative Timesteps: 1,519,398,310

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1519398310...
Checkpoint 1519398310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,227.58163
Policy Entropy: 3.69341
Value Function Loss: 0.01665

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.30291
Value Function Update Magnitude: 0.52847

Collected Steps per Second: 21,950.91826
Overall Steps per Second: 10,676.45425

Timestep Collection Time: 2.27826
Timestep Consumption Time: 2.40587
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.68414

Cumulative Model Updates: 182,204
Cumulative Timesteps: 1,519,448,320

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,394.09193
Policy Entropy: 3.70131
Value Function Loss: 0.01967

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.35570
Value Function Update Magnitude: 0.67599

Collected Steps per Second: 22,980.65957
Overall Steps per Second: 10,958.80923

Timestep Collection Time: 2.17574
Timestep Consumption Time: 2.38680
PPO Batch Consumption Time: 0.27598
Total Iteration Time: 4.56254

Cumulative Model Updates: 182,210
Cumulative Timesteps: 1,519,498,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1519498320...
Checkpoint 1519498320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,394.09193
Policy Entropy: 3.70916
Value Function Loss: 0.01909

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.37977
Value Function Update Magnitude: 0.67978

Collected Steps per Second: 22,549.84825
Overall Steps per Second: 10,683.19493

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.46451
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.68324

Cumulative Model Updates: 182,216
Cumulative Timesteps: 1,519,548,352

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,394.09193
Policy Entropy: 3.70531
Value Function Loss: 0.01758

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.36848
Value Function Update Magnitude: 0.58139

Collected Steps per Second: 23,539.11387
Overall Steps per Second: 10,820.51848

Timestep Collection Time: 2.12446
Timestep Consumption Time: 2.49713
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.62159

Cumulative Model Updates: 182,222
Cumulative Timesteps: 1,519,598,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1519598360...
Checkpoint 1519598360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,394.09193
Policy Entropy: 3.69954
Value Function Loss: 0.01672

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12418
Policy Update Magnitude: 0.31524
Value Function Update Magnitude: 0.42919

Collected Steps per Second: 22,820.05487
Overall Steps per Second: 10,664.07366

Timestep Collection Time: 2.19167
Timestep Consumption Time: 2.49828
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.68995

Cumulative Model Updates: 182,228
Cumulative Timesteps: 1,519,648,374

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,394.09193
Policy Entropy: 3.67500
Value Function Loss: 0.01755

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.32315
Value Function Update Magnitude: 0.42335

Collected Steps per Second: 23,282.11742
Overall Steps per Second: 10,971.43012

Timestep Collection Time: 2.14783
Timestep Consumption Time: 2.41001
PPO Batch Consumption Time: 0.27553
Total Iteration Time: 4.55784

Cumulative Model Updates: 182,234
Cumulative Timesteps: 1,519,698,380

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1519698380...
Checkpoint 1519698380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,394.09193
Policy Entropy: 3.66659
Value Function Loss: 0.01752

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.36376
Value Function Update Magnitude: 0.46235

Collected Steps per Second: 22,603.14651
Overall Steps per Second: 10,616.03611

Timestep Collection Time: 2.21314
Timestep Consumption Time: 2.49897
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.71212

Cumulative Model Updates: 182,240
Cumulative Timesteps: 1,519,748,404

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,394.09193
Policy Entropy: 3.66248
Value Function Loss: 0.02184

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.38658
Value Function Update Magnitude: 0.37172

Collected Steps per Second: 22,894.19596
Overall Steps per Second: 10,836.37323

Timestep Collection Time: 2.18510
Timestep Consumption Time: 2.43139
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.61649

Cumulative Model Updates: 182,246
Cumulative Timesteps: 1,519,798,430

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1519798430...
Checkpoint 1519798430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,394.09193
Policy Entropy: 3.66986
Value Function Loss: 0.02116

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13320
Policy Update Magnitude: 0.39396
Value Function Update Magnitude: 0.38433

Collected Steps per Second: 22,897.10460
Overall Steps per Second: 10,719.02384

Timestep Collection Time: 2.18403
Timestep Consumption Time: 2.48132
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.66535

Cumulative Model Updates: 182,252
Cumulative Timesteps: 1,519,848,438

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 158,394.09193
Policy Entropy: 3.67966
Value Function Loss: 0.01940

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13433
Policy Update Magnitude: 0.39089
Value Function Update Magnitude: 0.45499

Collected Steps per Second: 22,345.94457
Overall Steps per Second: 10,893.05006

Timestep Collection Time: 2.23915
Timestep Consumption Time: 2.35423
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.59339

Cumulative Model Updates: 182,258
Cumulative Timesteps: 1,519,898,474

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1519898474...
Checkpoint 1519898474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238,717.77876
Policy Entropy: 3.69102
Value Function Loss: 0.01949

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.40232
Value Function Update Magnitude: 0.41919

Collected Steps per Second: 21,794.26368
Overall Steps per Second: 10,622.59810

Timestep Collection Time: 2.29547
Timestep Consumption Time: 2.41412
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.70958

Cumulative Model Updates: 182,264
Cumulative Timesteps: 1,519,948,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,244.91041
Policy Entropy: 3.70254
Value Function Loss: 0.01998

Mean KL Divergence: 0.00778
SB3 Clip Fraction: 0.10645
Policy Update Magnitude: 0.36667
Value Function Update Magnitude: 0.46956

Collected Steps per Second: 22,472.28073
Overall Steps per Second: 10,811.92951

Timestep Collection Time: 2.22523
Timestep Consumption Time: 2.39985
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.62508

Cumulative Model Updates: 182,270
Cumulative Timesteps: 1,519,998,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1519998508...
Checkpoint 1519998508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,435.89413
Policy Entropy: 3.70559
Value Function Loss: 0.02022

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14149
Policy Update Magnitude: 0.36787
Value Function Update Magnitude: 0.54195

Collected Steps per Second: 22,580.76311
Overall Steps per Second: 10,736.65369

Timestep Collection Time: 2.21534
Timestep Consumption Time: 2.44384
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.65918

Cumulative Model Updates: 182,276
Cumulative Timesteps: 1,520,048,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,435.89413
Policy Entropy: 3.68433
Value Function Loss: 0.01845

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.15885
Policy Update Magnitude: 0.32949
Value Function Update Magnitude: 0.54118

Collected Steps per Second: 23,148.78568
Overall Steps per Second: 10,933.98560

Timestep Collection Time: 2.16037
Timestep Consumption Time: 2.41344
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.57381

Cumulative Model Updates: 182,282
Cumulative Timesteps: 1,520,098,542

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1520098542...
Checkpoint 1520098542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 365,682.90764
Policy Entropy: 3.66765
Value Function Loss: 0.02215

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14954
Policy Update Magnitude: 0.38204
Value Function Update Magnitude: 0.51223

Collected Steps per Second: 22,623.90217
Overall Steps per Second: 10,631.68696

Timestep Collection Time: 2.21049
Timestep Consumption Time: 2.49337
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.70386

Cumulative Model Updates: 182,288
Cumulative Timesteps: 1,520,148,552

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 408,194.79116
Policy Entropy: 3.67544
Value Function Loss: 0.02426

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13929
Policy Update Magnitude: 0.46061
Value Function Update Magnitude: 0.55818

Collected Steps per Second: 23,091.35624
Overall Steps per Second: 10,863.36064

Timestep Collection Time: 2.16739
Timestep Consumption Time: 2.43965
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.60705

Cumulative Model Updates: 182,294
Cumulative Timesteps: 1,520,198,600

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1520198600...
Checkpoint 1520198600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330,644.65736
Policy Entropy: 3.68969
Value Function Loss: 0.02699

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.45074
Value Function Update Magnitude: 0.62803

Collected Steps per Second: 22,945.28313
Overall Steps per Second: 10,713.37507

Timestep Collection Time: 2.18128
Timestep Consumption Time: 2.49045
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.67173

Cumulative Model Updates: 182,300
Cumulative Timesteps: 1,520,248,650

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,644.65736
Policy Entropy: 3.71086
Value Function Loss: 0.02173

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06249
Policy Update Magnitude: 0.50761
Value Function Update Magnitude: 0.53445

Collected Steps per Second: 23,422.46424
Overall Steps per Second: 10,865.55110

Timestep Collection Time: 2.13470
Timestep Consumption Time: 2.46700
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.60170

Cumulative Model Updates: 182,306
Cumulative Timesteps: 1,520,298,650

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1520298650...
Checkpoint 1520298650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330,644.65736
Policy Entropy: 3.70037
Value Function Loss: 0.01953

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.04992
Policy Update Magnitude: 0.51134
Value Function Update Magnitude: 0.46868

Collected Steps per Second: 22,606.29949
Overall Steps per Second: 10,621.48787

Timestep Collection Time: 2.21230
Timestep Consumption Time: 2.49626
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.70857

Cumulative Model Updates: 182,312
Cumulative Timesteps: 1,520,348,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,644.65736
Policy Entropy: 3.71189
Value Function Loss: 0.01561

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06528
Policy Update Magnitude: 0.47577
Value Function Update Magnitude: 0.35726

Collected Steps per Second: 23,059.98283
Overall Steps per Second: 10,880.82075

Timestep Collection Time: 2.16930
Timestep Consumption Time: 2.42815
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.59745

Cumulative Model Updates: 182,318
Cumulative Timesteps: 1,520,398,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1520398686...
Checkpoint 1520398686 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 619,426.33620
Policy Entropy: 3.71428
Value Function Loss: 0.01729

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06268
Policy Update Magnitude: 0.46311
Value Function Update Magnitude: 0.43176

Collected Steps per Second: 22,623.00149
Overall Steps per Second: 10,683.91726

Timestep Collection Time: 2.21049
Timestep Consumption Time: 2.47019
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.68068

Cumulative Model Updates: 182,324
Cumulative Timesteps: 1,520,448,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,405.85380
Policy Entropy: 3.73134
Value Function Loss: 0.01684

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05610
Policy Update Magnitude: 0.46276
Value Function Update Magnitude: 0.51313

Collected Steps per Second: 23,041.50755
Overall Steps per Second: 10,899.77720

Timestep Collection Time: 2.17113
Timestep Consumption Time: 2.41851
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.58964

Cumulative Model Updates: 182,330
Cumulative Timesteps: 1,520,498,720

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1520498720...
Checkpoint 1520498720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406,405.85380
Policy Entropy: 3.73504
Value Function Loss: 0.01648

Mean KL Divergence: 0.00447
SB3 Clip Fraction: 0.04813
Policy Update Magnitude: 0.42924
Value Function Update Magnitude: 0.50097

Collected Steps per Second: 22,707.22316
Overall Steps per Second: 10,656.22009

Timestep Collection Time: 2.20238
Timestep Consumption Time: 2.49065
PPO Batch Consumption Time: 0.29044
Total Iteration Time: 4.69303

Cumulative Model Updates: 182,336
Cumulative Timesteps: 1,520,548,730

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,405.85380
Policy Entropy: 3.73079
Value Function Loss: 0.01575

Mean KL Divergence: 0.00437
SB3 Clip Fraction: 0.04711
Policy Update Magnitude: 0.43385
Value Function Update Magnitude: 0.45711

Collected Steps per Second: 23,230.56346
Overall Steps per Second: 10,944.07661

Timestep Collection Time: 2.15294
Timestep Consumption Time: 2.41702
PPO Batch Consumption Time: 0.27615
Total Iteration Time: 4.56996

Cumulative Model Updates: 182,342
Cumulative Timesteps: 1,520,598,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1520598744...
Checkpoint 1520598744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406,405.85380
Policy Entropy: 3.71697
Value Function Loss: 0.01478

Mean KL Divergence: 0.00740
SB3 Clip Fraction: 0.09544
Policy Update Magnitude: 0.40484
Value Function Update Magnitude: 0.47717

Collected Steps per Second: 22,073.81662
Overall Steps per Second: 10,723.10170

Timestep Collection Time: 2.26531
Timestep Consumption Time: 2.39789
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.66320

Cumulative Model Updates: 182,348
Cumulative Timesteps: 1,520,648,748

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,405.85380
Policy Entropy: 3.72223
Value Function Loss: 0.01458

Mean KL Divergence: 0.01091
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.30916
Value Function Update Magnitude: 0.44935

Collected Steps per Second: 22,684.72748
Overall Steps per Second: 10,812.98754

Timestep Collection Time: 2.20615
Timestep Consumption Time: 2.42217
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.62832

Cumulative Model Updates: 182,354
Cumulative Timesteps: 1,520,698,794

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1520698794...
Checkpoint 1520698794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406,405.85380
Policy Entropy: 3.71052
Value Function Loss: 0.01530

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14922
Policy Update Magnitude: 0.27012
Value Function Update Magnitude: 0.39278

Collected Steps per Second: 21,604.39780
Overall Steps per Second: 10,597.04124

Timestep Collection Time: 2.31508
Timestep Consumption Time: 2.40472
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.71981

Cumulative Model Updates: 182,360
Cumulative Timesteps: 1,520,748,810

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 406,405.85380
Policy Entropy: 3.70669
Value Function Loss: 0.01525

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14397
Policy Update Magnitude: 0.29485
Value Function Update Magnitude: 0.36797

Collected Steps per Second: 23,015.10904
Overall Steps per Second: 10,962.49501

Timestep Collection Time: 2.17335
Timestep Consumption Time: 2.38947
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.56283

Cumulative Model Updates: 182,366
Cumulative Timesteps: 1,520,798,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1520798830...
Checkpoint 1520798830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 586,223.76305
Policy Entropy: 3.70087
Value Function Loss: 0.02147

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.36488
Value Function Update Magnitude: 0.41843

Collected Steps per Second: 22,184.40968
Overall Steps per Second: 10,608.67641

Timestep Collection Time: 2.25528
Timestep Consumption Time: 2.46086
PPO Batch Consumption Time: 0.28863
Total Iteration Time: 4.71614

Cumulative Model Updates: 182,372
Cumulative Timesteps: 1,520,848,862

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 823,787.87992
Policy Entropy: 3.68996
Value Function Loss: 0.03006

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10823
Policy Update Magnitude: 0.58378
Value Function Update Magnitude: 0.47814

Collected Steps per Second: 22,940.35151
Overall Steps per Second: 10,854.15315

Timestep Collection Time: 2.18035
Timestep Consumption Time: 2.42784
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.60819

Cumulative Model Updates: 182,378
Cumulative Timesteps: 1,520,898,880

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1520898880...
Checkpoint 1520898880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 287,253.28850
Policy Entropy: 3.68299
Value Function Loss: 0.03785

Mean KL Divergence: 0.01421
SB3 Clip Fraction: 0.16714
Policy Update Magnitude: 0.72589
Value Function Update Magnitude: 0.49572

Collected Steps per Second: 22,318.79170
Overall Steps per Second: 10,741.47124

Timestep Collection Time: 2.24071
Timestep Consumption Time: 2.41507
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.65579

Cumulative Model Updates: 182,384
Cumulative Timesteps: 1,520,948,890

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 318,036.14387
Policy Entropy: 3.65402
Value Function Loss: 0.05557

Mean KL Divergence: 0.02345
SB3 Clip Fraction: 0.24271
Policy Update Magnitude: 0.63420
Value Function Update Magnitude: 0.48515

Collected Steps per Second: 22,795.11444
Overall Steps per Second: 10,816.44764

Timestep Collection Time: 2.19468
Timestep Consumption Time: 2.43050
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.62518

Cumulative Model Updates: 182,390
Cumulative Timesteps: 1,520,998,918

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1520998918...
Checkpoint 1520998918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,430.76776
Policy Entropy: 3.67576
Value Function Loss: 0.07941

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.74101
Value Function Update Magnitude: 0.51765

Collected Steps per Second: 22,303.65577
Overall Steps per Second: 10,693.03698

Timestep Collection Time: 2.24259
Timestep Consumption Time: 2.43503
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.67762

Cumulative Model Updates: 182,396
Cumulative Timesteps: 1,521,048,936

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 182,713.03043
Policy Entropy: 3.71619
Value Function Loss: 0.09110

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.17570
Policy Update Magnitude: 1.01707
Value Function Update Magnitude: 0.56689

Collected Steps per Second: 23,060.03664
Overall Steps per Second: 10,927.77051

Timestep Collection Time: 2.17033
Timestep Consumption Time: 2.40956
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.57989

Cumulative Model Updates: 182,402
Cumulative Timesteps: 1,521,098,984

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1521098984...
Checkpoint 1521098984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,956.90641
Policy Entropy: 3.77407
Value Function Loss: 0.07980

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.15979
Policy Update Magnitude: 1.00528
Value Function Update Magnitude: 0.64219

Collected Steps per Second: 22,757.38888
Overall Steps per Second: 10,719.48104

Timestep Collection Time: 2.19823
Timestep Consumption Time: 2.46860
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.66683

Cumulative Model Updates: 182,408
Cumulative Timesteps: 1,521,149,010

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,707.63015
Policy Entropy: 3.78485
Value Function Loss: 0.05833

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15136
Policy Update Magnitude: 0.84189
Value Function Update Magnitude: 0.80371

Collected Steps per Second: 22,879.02303
Overall Steps per Second: 10,865.03842

Timestep Collection Time: 2.18593
Timestep Consumption Time: 2.41709
PPO Batch Consumption Time: 0.27641
Total Iteration Time: 4.60302

Cumulative Model Updates: 182,414
Cumulative Timesteps: 1,521,199,022

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1521199022...
Checkpoint 1521199022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,461.14750
Policy Entropy: 3.75131
Value Function Loss: 0.04065

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14673
Policy Update Magnitude: 0.64993
Value Function Update Magnitude: 0.98814

Collected Steps per Second: 22,821.90606
Overall Steps per Second: 10,654.85460

Timestep Collection Time: 2.19193
Timestep Consumption Time: 2.50302
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.69495

Cumulative Model Updates: 182,420
Cumulative Timesteps: 1,521,249,046

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,461.14750
Policy Entropy: 3.70594
Value Function Loss: 0.03091

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15609
Policy Update Magnitude: 0.50021
Value Function Update Magnitude: 0.95460

Collected Steps per Second: 23,327.58557
Overall Steps per Second: 10,835.09213

Timestep Collection Time: 2.14356
Timestep Consumption Time: 2.47145
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.61500

Cumulative Model Updates: 182,426
Cumulative Timesteps: 1,521,299,050

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1521299050...
Checkpoint 1521299050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,267.77647
Policy Entropy: 3.72674
Value Function Loss: 0.02449

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.42316
Value Function Update Magnitude: 0.72449

Collected Steps per Second: 22,792.42421
Overall Steps per Second: 10,680.04819

Timestep Collection Time: 2.19450
Timestep Consumption Time: 2.48881
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.68331

Cumulative Model Updates: 182,432
Cumulative Timesteps: 1,521,349,068

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 364,144.42930
Policy Entropy: 3.70763
Value Function Loss: 0.02509

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13836
Policy Update Magnitude: 0.42038
Value Function Update Magnitude: 0.61000

Collected Steps per Second: 22,965.08863
Overall Steps per Second: 10,872.72504

Timestep Collection Time: 2.17730
Timestep Consumption Time: 2.42154
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.59885

Cumulative Model Updates: 182,438
Cumulative Timesteps: 1,521,399,070

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1521399070...
Checkpoint 1521399070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285,764.94082
Policy Entropy: 3.70754
Value Function Loss: 0.02613

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11998
Policy Update Magnitude: 0.42567
Value Function Update Magnitude: 0.65069

Collected Steps per Second: 22,980.72227
Overall Steps per Second: 10,696.73121

Timestep Collection Time: 2.17791
Timestep Consumption Time: 2.50109
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.67900

Cumulative Model Updates: 182,444
Cumulative Timesteps: 1,521,449,120

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187,493.33331
Policy Entropy: 3.69844
Value Function Loss: 0.02531

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.41467
Value Function Update Magnitude: 0.69539

Collected Steps per Second: 23,139.92053
Overall Steps per Second: 10,888.57184

Timestep Collection Time: 2.16215
Timestep Consumption Time: 2.43276
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.59491

Cumulative Model Updates: 182,450
Cumulative Timesteps: 1,521,499,152

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1521499152...
Checkpoint 1521499152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,192.84292
Policy Entropy: 3.70055
Value Function Loss: 0.03231

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.47333
Value Function Update Magnitude: 0.69229

Collected Steps per Second: 22,598.06419
Overall Steps per Second: 10,606.85172

Timestep Collection Time: 2.21258
Timestep Consumption Time: 2.50136
PPO Batch Consumption Time: 0.29300
Total Iteration Time: 4.71393

Cumulative Model Updates: 182,456
Cumulative Timesteps: 1,521,549,152

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 387,972.40420
Policy Entropy: 3.71266
Value Function Loss: 0.03546

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.54575
Value Function Update Magnitude: 0.70471

Collected Steps per Second: 22,623.01087
Overall Steps per Second: 10,744.92812

Timestep Collection Time: 2.21076
Timestep Consumption Time: 2.44390
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.65466

Cumulative Model Updates: 182,462
Cumulative Timesteps: 1,521,599,166

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1521599166...
Checkpoint 1521599166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 312,958.70907
Policy Entropy: 3.71893
Value Function Loss: 0.04125

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.52220
Value Function Update Magnitude: 0.72112

Collected Steps per Second: 22,677.14759
Overall Steps per Second: 10,840.08890

Timestep Collection Time: 2.20548
Timestep Consumption Time: 2.40832
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.61380

Cumulative Model Updates: 182,468
Cumulative Timesteps: 1,521,649,180

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,602.65473
Policy Entropy: 3.74065
Value Function Loss: 0.03497

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.11986
Policy Update Magnitude: 0.49838
Value Function Update Magnitude: 0.77817

Collected Steps per Second: 22,989.23083
Overall Steps per Second: 10,900.72446

Timestep Collection Time: 2.17493
Timestep Consumption Time: 2.41192
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.58685

Cumulative Model Updates: 182,474
Cumulative Timesteps: 1,521,699,180

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1521699180...
Checkpoint 1521699180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,602.65473
Policy Entropy: 3.71414
Value Function Loss: 0.02838

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.44003
Value Function Update Magnitude: 0.83216

Collected Steps per Second: 22,516.50622
Overall Steps per Second: 10,601.59968

Timestep Collection Time: 2.22219
Timestep Consumption Time: 2.49747
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.71967

Cumulative Model Updates: 182,480
Cumulative Timesteps: 1,521,749,216

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,156.29269
Policy Entropy: 3.71520
Value Function Loss: 0.02356

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11542
Policy Update Magnitude: 0.42116
Value Function Update Magnitude: 0.75402

Collected Steps per Second: 22,715.06787
Overall Steps per Second: 10,835.16691

Timestep Collection Time: 2.20330
Timestep Consumption Time: 2.41574
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.61903

Cumulative Model Updates: 182,486
Cumulative Timesteps: 1,521,799,264

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1521799264...
Checkpoint 1521799264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,858.21938
Policy Entropy: 3.71397
Value Function Loss: 0.02454

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.43324
Value Function Update Magnitude: 0.69203

Collected Steps per Second: 22,686.68243
Overall Steps per Second: 10,697.51256

Timestep Collection Time: 2.20429
Timestep Consumption Time: 2.47044
PPO Batch Consumption Time: 0.28521
Total Iteration Time: 4.67473

Cumulative Model Updates: 182,492
Cumulative Timesteps: 1,521,849,272

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,258.86806
Policy Entropy: 3.73526
Value Function Loss: 0.02573

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12321
Policy Update Magnitude: 0.40203
Value Function Update Magnitude: 0.68403

Collected Steps per Second: 22,345.79070
Overall Steps per Second: 10,926.29823

Timestep Collection Time: 2.23845
Timestep Consumption Time: 2.33949
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.57795

Cumulative Model Updates: 182,498
Cumulative Timesteps: 1,521,899,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1521899292...
Checkpoint 1521899292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,571.98997
Policy Entropy: 3.72823
Value Function Loss: 0.02490

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.36301
Value Function Update Magnitude: 0.80848

Collected Steps per Second: 21,949.00050
Overall Steps per Second: 10,632.08798

Timestep Collection Time: 2.27865
Timestep Consumption Time: 2.42542
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.70406

Cumulative Model Updates: 182,504
Cumulative Timesteps: 1,521,949,306

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,571.98997
Policy Entropy: 3.70601
Value Function Loss: 0.02164

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.33300
Value Function Update Magnitude: 0.73330

Collected Steps per Second: 22,398.57558
Overall Steps per Second: 10,907.79408

Timestep Collection Time: 2.23237
Timestep Consumption Time: 2.35169
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.58406

Cumulative Model Updates: 182,510
Cumulative Timesteps: 1,521,999,308

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1521999308...
Checkpoint 1521999308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,676.64738
Policy Entropy: 3.69760
Value Function Loss: 0.02316

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12736
Policy Update Magnitude: 0.32102
Value Function Update Magnitude: 0.54921

Collected Steps per Second: 21,896.18549
Overall Steps per Second: 10,716.74358

Timestep Collection Time: 2.28359
Timestep Consumption Time: 2.38219
PPO Batch Consumption Time: 0.27607
Total Iteration Time: 4.66578

Cumulative Model Updates: 182,516
Cumulative Timesteps: 1,522,049,310

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,676.64738
Policy Entropy: 3.69684
Value Function Loss: 0.02344

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.36516
Value Function Update Magnitude: 0.50866

Collected Steps per Second: 22,927.04510
Overall Steps per Second: 10,866.14738

Timestep Collection Time: 2.18101
Timestep Consumption Time: 2.42081
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.60181

Cumulative Model Updates: 182,522
Cumulative Timesteps: 1,522,099,314

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1522099314...
Checkpoint 1522099314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,094.68174
Policy Entropy: 3.69757
Value Function Loss: 0.02985

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.41632
Value Function Update Magnitude: 0.54347

Collected Steps per Second: 22,595.21222
Overall Steps per Second: 10,692.67076

Timestep Collection Time: 2.21304
Timestep Consumption Time: 2.46344
PPO Batch Consumption Time: 0.29089
Total Iteration Time: 4.67647

Cumulative Model Updates: 182,528
Cumulative Timesteps: 1,522,149,318

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,148.32994
Policy Entropy: 3.69778
Value Function Loss: 0.03547

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12355
Policy Update Magnitude: 0.46477
Value Function Update Magnitude: 0.54702

Collected Steps per Second: 22,883.28158
Overall Steps per Second: 10,873.52396

Timestep Collection Time: 2.18561
Timestep Consumption Time: 2.41400
PPO Batch Consumption Time: 0.27623
Total Iteration Time: 4.59961

Cumulative Model Updates: 182,534
Cumulative Timesteps: 1,522,199,332

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1522199332...
Checkpoint 1522199332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,904.50744
Policy Entropy: 3.69934
Value Function Loss: 0.03728

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12481
Policy Update Magnitude: 0.49537
Value Function Update Magnitude: 0.54591

Collected Steps per Second: 22,787.24707
Overall Steps per Second: 10,697.34980

Timestep Collection Time: 2.19439
Timestep Consumption Time: 2.48004
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.67443

Cumulative Model Updates: 182,540
Cumulative Timesteps: 1,522,249,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,904.50744
Policy Entropy: 3.69266
Value Function Loss: 0.03079

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.49145
Value Function Update Magnitude: 0.52276

Collected Steps per Second: 23,071.21093
Overall Steps per Second: 10,835.03438

Timestep Collection Time: 2.16798
Timestep Consumption Time: 2.44834
PPO Batch Consumption Time: 0.28198
Total Iteration Time: 4.61632

Cumulative Model Updates: 182,546
Cumulative Timesteps: 1,522,299,354

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1522299354...
Checkpoint 1522299354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,407.48790
Policy Entropy: 3.66816
Value Function Loss: 0.03191

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.48086
Value Function Update Magnitude: 0.56826

Collected Steps per Second: 22,546.09945
Overall Steps per Second: 10,629.32835

Timestep Collection Time: 2.21892
Timestep Consumption Time: 2.48768
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.70660

Cumulative Model Updates: 182,552
Cumulative Timesteps: 1,522,349,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322,861.50022
Policy Entropy: 3.67738
Value Function Loss: 0.03353

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.49295
Value Function Update Magnitude: 0.62453

Collected Steps per Second: 23,039.32527
Overall Steps per Second: 10,882.84709

Timestep Collection Time: 2.17081
Timestep Consumption Time: 2.42486
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.59567

Cumulative Model Updates: 182,558
Cumulative Timesteps: 1,522,399,396

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1522399396...
Checkpoint 1522399396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,093.69427
Policy Entropy: 3.67665
Value Function Loss: 0.03566

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.47729
Value Function Update Magnitude: 0.58347

Collected Steps per Second: 22,677.02425
Overall Steps per Second: 10,616.35484

Timestep Collection Time: 2.20540
Timestep Consumption Time: 2.50544
PPO Batch Consumption Time: 0.28992
Total Iteration Time: 4.71084

Cumulative Model Updates: 182,564
Cumulative Timesteps: 1,522,449,408

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,093.69427
Policy Entropy: 3.69480
Value Function Loss: 0.03191

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.45280
Value Function Update Magnitude: 0.53049

Collected Steps per Second: 23,060.58860
Overall Steps per Second: 10,897.45450

Timestep Collection Time: 2.16950
Timestep Consumption Time: 2.42148
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.59098

Cumulative Model Updates: 182,570
Cumulative Timesteps: 1,522,499,438

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1522499438...
Checkpoint 1522499438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,093.69427
Policy Entropy: 3.68301
Value Function Loss: 0.02981

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13346
Policy Update Magnitude: 0.44717
Value Function Update Magnitude: 0.48976

Collected Steps per Second: 22,389.49474
Overall Steps per Second: 10,699.79844

Timestep Collection Time: 2.23355
Timestep Consumption Time: 2.44019
PPO Batch Consumption Time: 0.28165
Total Iteration Time: 4.67373

Cumulative Model Updates: 182,576
Cumulative Timesteps: 1,522,549,446

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 213,592.94941
Policy Entropy: 3.68099
Value Function Loss: 0.03110

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.43683
Value Function Update Magnitude: 0.49171

Collected Steps per Second: 23,147.82350
Overall Steps per Second: 10,896.16146

Timestep Collection Time: 2.16046
Timestep Consumption Time: 2.42923
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.58969

Cumulative Model Updates: 182,582
Cumulative Timesteps: 1,522,599,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1522599456...
Checkpoint 1522599456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,991.19954
Policy Entropy: 3.69341
Value Function Loss: 0.03814

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.46343
Value Function Update Magnitude: 0.50057

Collected Steps per Second: 22,545.46959
Overall Steps per Second: 10,625.64151

Timestep Collection Time: 2.21907
Timestep Consumption Time: 2.48935
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.70842

Cumulative Model Updates: 182,588
Cumulative Timesteps: 1,522,649,486

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,422.26444
Policy Entropy: 3.70047
Value Function Loss: 0.03834

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13524
Policy Update Magnitude: 0.49553
Value Function Update Magnitude: 0.58659

Collected Steps per Second: 23,188.33486
Overall Steps per Second: 10,914.81381

Timestep Collection Time: 2.15746
Timestep Consumption Time: 2.42603
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.58350

Cumulative Model Updates: 182,594
Cumulative Timesteps: 1,522,699,514

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1522699514...
Checkpoint 1522699514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,589.60925
Policy Entropy: 3.70883
Value Function Loss: 0.03779

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.49325
Value Function Update Magnitude: 0.63250

Collected Steps per Second: 22,785.20323
Overall Steps per Second: 10,661.67905

Timestep Collection Time: 2.19546
Timestep Consumption Time: 2.49648
PPO Batch Consumption Time: 0.29226
Total Iteration Time: 4.69194

Cumulative Model Updates: 182,600
Cumulative Timesteps: 1,522,749,538

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,699.51375
Policy Entropy: 3.71580
Value Function Loss: 0.03287

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12777
Policy Update Magnitude: 0.45255
Value Function Update Magnitude: 0.56846

Collected Steps per Second: 22,897.46556
Overall Steps per Second: 10,843.26891

Timestep Collection Time: 2.18443
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.61282

Cumulative Model Updates: 182,606
Cumulative Timesteps: 1,522,799,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1522799556...
Checkpoint 1522799556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,432.88237
Policy Entropy: 3.71192
Value Function Loss: 0.03334

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.42621
Value Function Update Magnitude: 0.54933

Collected Steps per Second: 23,020.25761
Overall Steps per Second: 10,720.33228

Timestep Collection Time: 2.17209
Timestep Consumption Time: 2.49213
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.66422

Cumulative Model Updates: 182,612
Cumulative Timesteps: 1,522,849,558

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,918.47392
Policy Entropy: 3.72396
Value Function Loss: 0.03185

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.41437
Value Function Update Magnitude: 0.54373

Collected Steps per Second: 22,785.73464
Overall Steps per Second: 10,808.85860

Timestep Collection Time: 2.19506
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.62732

Cumulative Model Updates: 182,618
Cumulative Timesteps: 1,522,899,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1522899574...
Checkpoint 1522899574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,469.87648
Policy Entropy: 3.72775
Value Function Loss: 0.03204

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12156
Policy Update Magnitude: 0.39500
Value Function Update Magnitude: 0.59019

Collected Steps per Second: 22,717.94288
Overall Steps per Second: 10,711.37773

Timestep Collection Time: 2.20090
Timestep Consumption Time: 2.46703
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.66793

Cumulative Model Updates: 182,624
Cumulative Timesteps: 1,522,949,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,579.27497
Policy Entropy: 3.74437
Value Function Loss: 0.02939

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11566
Policy Update Magnitude: 0.39226
Value Function Update Magnitude: 0.75862

Collected Steps per Second: 22,744.24620
Overall Steps per Second: 10,825.32356

Timestep Collection Time: 2.19889
Timestep Consumption Time: 2.42102
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.61991

Cumulative Model Updates: 182,630
Cumulative Timesteps: 1,522,999,586

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1522999586...
Checkpoint 1522999586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335,829.55708
Policy Entropy: 3.74863
Value Function Loss: 0.02945

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.11327
Policy Update Magnitude: 0.40569
Value Function Update Magnitude: 0.81074

Collected Steps per Second: 22,875.89437
Overall Steps per Second: 10,703.91192

Timestep Collection Time: 2.18789
Timestep Consumption Time: 2.48797
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.67586

Cumulative Model Updates: 182,636
Cumulative Timesteps: 1,523,049,636

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,019.35929
Policy Entropy: 3.74007
Value Function Loss: 0.02488

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.41582
Value Function Update Magnitude: 0.74976

Collected Steps per Second: 22,798.91918
Overall Steps per Second: 10,859.59169

Timestep Collection Time: 2.19414
Timestep Consumption Time: 2.41230
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.60643

Cumulative Model Updates: 182,642
Cumulative Timesteps: 1,523,099,660

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1523099660...
Checkpoint 1523099660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,019.35929
Policy Entropy: 3.71802
Value Function Loss: 0.02146

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.39481
Value Function Update Magnitude: 0.68998

Collected Steps per Second: 22,210.14087
Overall Steps per Second: 10,707.31214

Timestep Collection Time: 2.25140
Timestep Consumption Time: 2.41868
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.67008

Cumulative Model Updates: 182,648
Cumulative Timesteps: 1,523,149,664

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,019.35929
Policy Entropy: 3.70236
Value Function Loss: 0.01780

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.34291
Value Function Update Magnitude: 0.53730

Collected Steps per Second: 22,039.74241
Overall Steps per Second: 10,841.57269

Timestep Collection Time: 2.26872
Timestep Consumption Time: 2.34334
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.61206

Cumulative Model Updates: 182,654
Cumulative Timesteps: 1,523,199,666

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1523199666...
Checkpoint 1523199666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 331,070.84174
Policy Entropy: 3.67713
Value Function Loss: 0.02794

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13244
Policy Update Magnitude: 0.35786
Value Function Update Magnitude: 0.46385

Collected Steps per Second: 21,898.69487
Overall Steps per Second: 10,688.51734

Timestep Collection Time: 2.28388
Timestep Consumption Time: 2.39535
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.67923

Cumulative Model Updates: 182,660
Cumulative Timesteps: 1,523,249,680

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,446.22786
Policy Entropy: 3.69089
Value Function Loss: 0.02880

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.42769
Value Function Update Magnitude: 0.45795

Collected Steps per Second: 22,689.26907
Overall Steps per Second: 10,845.71697

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.40701
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.61122

Cumulative Model Updates: 182,666
Cumulative Timesteps: 1,523,299,692

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1523299692...
Checkpoint 1523299692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,877.51298
Policy Entropy: 3.68010
Value Function Loss: 0.03974

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.45894
Value Function Update Magnitude: 0.53156

Collected Steps per Second: 22,661.71259
Overall Steps per Second: 10,725.45954

Timestep Collection Time: 2.20769
Timestep Consumption Time: 2.45691
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.66460

Cumulative Model Updates: 182,672
Cumulative Timesteps: 1,523,349,722

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,831.95509
Policy Entropy: 3.71379
Value Function Loss: 0.03513

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.46249
Value Function Update Magnitude: 0.57949

Collected Steps per Second: 22,935.12438
Overall Steps per Second: 10,843.47981

Timestep Collection Time: 2.18006
Timestep Consumption Time: 2.43100
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.61107

Cumulative Model Updates: 182,678
Cumulative Timesteps: 1,523,399,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1523399722...
Checkpoint 1523399722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,307.69057
Policy Entropy: 3.70445
Value Function Loss: 0.04685

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.12899
Policy Update Magnitude: 0.48347
Value Function Update Magnitude: 0.69971

Collected Steps per Second: 23,018.33630
Overall Steps per Second: 10,767.33435

Timestep Collection Time: 2.17296
Timestep Consumption Time: 2.47238
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.64535

Cumulative Model Updates: 182,684
Cumulative Timesteps: 1,523,449,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,576.41110
Policy Entropy: 3.74245
Value Function Loss: 0.04718

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11912
Policy Update Magnitude: 0.55639
Value Function Update Magnitude: 0.82183

Collected Steps per Second: 22,998.87406
Overall Steps per Second: 10,891.46620

Timestep Collection Time: 2.17506
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.59295

Cumulative Model Updates: 182,690
Cumulative Timesteps: 1,523,499,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1523499764...
Checkpoint 1523499764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 81,600.61176
Policy Entropy: 3.72809
Value Function Loss: 0.05423

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.57668
Value Function Update Magnitude: 0.75284

Collected Steps per Second: 22,692.52849
Overall Steps per Second: 10,661.35785

Timestep Collection Time: 2.20390
Timestep Consumption Time: 2.48706
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.69096

Cumulative Model Updates: 182,696
Cumulative Timesteps: 1,523,549,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,942.60214
Policy Entropy: 3.75622
Value Function Loss: 0.04792

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13086
Policy Update Magnitude: 0.55171
Value Function Update Magnitude: 0.62766

Collected Steps per Second: 22,986.64778
Overall Steps per Second: 10,901.79278

Timestep Collection Time: 2.17639
Timestep Consumption Time: 2.41258
PPO Batch Consumption Time: 0.27663
Total Iteration Time: 4.58897

Cumulative Model Updates: 182,702
Cumulative Timesteps: 1,523,599,804

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1523599804...
Checkpoint 1523599804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,657.84908
Policy Entropy: 3.76446
Value Function Loss: 0.04114

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12464
Policy Update Magnitude: 0.52491
Value Function Update Magnitude: 0.59556

Collected Steps per Second: 22,681.34415
Overall Steps per Second: 10,662.22279

Timestep Collection Time: 2.20684
Timestep Consumption Time: 2.48768
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.69452

Cumulative Model Updates: 182,708
Cumulative Timesteps: 1,523,649,858

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,463.05442
Policy Entropy: 3.79314
Value Function Loss: 0.03863

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.11019
Policy Update Magnitude: 0.55631
Value Function Update Magnitude: 0.74762

Collected Steps per Second: 23,007.70567
Overall Steps per Second: 10,872.59972

Timestep Collection Time: 2.17362
Timestep Consumption Time: 2.42602
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.59964

Cumulative Model Updates: 182,714
Cumulative Timesteps: 1,523,699,868

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1523699868...
Checkpoint 1523699868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,242.93190
Policy Entropy: 3.76174
Value Function Loss: 0.04207

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.56375
Value Function Update Magnitude: 0.80069

Collected Steps per Second: 22,597.25653
Overall Steps per Second: 10,610.17885

Timestep Collection Time: 2.21292
Timestep Consumption Time: 2.50010
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.71302

Cumulative Model Updates: 182,720
Cumulative Timesteps: 1,523,749,874

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,245.74451
Policy Entropy: 3.75978
Value Function Loss: 0.04036

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12283
Policy Update Magnitude: 0.55179
Value Function Update Magnitude: 0.88417

Collected Steps per Second: 22,793.05267
Overall Steps per Second: 10,844.03772

Timestep Collection Time: 2.19427
Timestep Consumption Time: 2.41785
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.61212

Cumulative Model Updates: 182,726
Cumulative Timesteps: 1,523,799,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1523799888...
Checkpoint 1523799888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 238,778.52357
Policy Entropy: 3.73983
Value Function Loss: 0.03738

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12630
Policy Update Magnitude: 0.55837
Value Function Update Magnitude: 0.87585

Collected Steps per Second: 22,453.56488
Overall Steps per Second: 10,689.60407

Timestep Collection Time: 2.22744
Timestep Consumption Time: 2.45131
PPO Batch Consumption Time: 0.28277
Total Iteration Time: 4.67875

Cumulative Model Updates: 182,732
Cumulative Timesteps: 1,523,849,902

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,199.33698
Policy Entropy: 3.73516
Value Function Loss: 0.03933

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12640
Policy Update Magnitude: 0.55507
Value Function Update Magnitude: 0.74322

Collected Steps per Second: 22,814.58541
Overall Steps per Second: 10,856.72131

Timestep Collection Time: 2.19272
Timestep Consumption Time: 2.41512
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.60784

Cumulative Model Updates: 182,738
Cumulative Timesteps: 1,523,899,928

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1523899928...
Checkpoint 1523899928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,740.53767
Policy Entropy: 3.74800
Value Function Loss: 0.03990

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12770
Policy Update Magnitude: 0.54105
Value Function Update Magnitude: 0.74093

Collected Steps per Second: 22,701.10586
Overall Steps per Second: 10,702.63580

Timestep Collection Time: 2.20421
Timestep Consumption Time: 2.47109
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.67530

Cumulative Model Updates: 182,744
Cumulative Timesteps: 1,523,949,966

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,524.75725
Policy Entropy: 3.77179
Value Function Loss: 0.03900

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12162
Policy Update Magnitude: 0.52055
Value Function Update Magnitude: 0.71386

Collected Steps per Second: 22,956.55855
Overall Steps per Second: 10,844.15849

Timestep Collection Time: 2.17881
Timestep Consumption Time: 2.43363
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.61244

Cumulative Model Updates: 182,750
Cumulative Timesteps: 1,523,999,984

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1523999984...
Checkpoint 1523999984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,560.06542
Policy Entropy: 3.78385
Value Function Loss: 0.04129

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11280
Policy Update Magnitude: 0.50813
Value Function Update Magnitude: 0.64447

Collected Steps per Second: 22,584.85065
Overall Steps per Second: 10,694.35029

Timestep Collection Time: 2.21485
Timestep Consumption Time: 2.46258
PPO Batch Consumption Time: 0.28347
Total Iteration Time: 4.67742

Cumulative Model Updates: 182,756
Cumulative Timesteps: 1,524,050,006

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,065.52160
Policy Entropy: 3.77906
Value Function Loss: 0.04438

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11683
Policy Update Magnitude: 0.53928
Value Function Update Magnitude: 0.67842

Collected Steps per Second: 22,940.36656
Overall Steps per Second: 10,874.14369

Timestep Collection Time: 2.18070
Timestep Consumption Time: 2.41976
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.60045

Cumulative Model Updates: 182,762
Cumulative Timesteps: 1,524,100,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1524100032...
Checkpoint 1524100032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,038.67413
Policy Entropy: 3.73638
Value Function Loss: 0.04805

Mean KL Divergence: 0.00655
SB3 Clip Fraction: 0.08077
Policy Update Magnitude: 0.72995
Value Function Update Magnitude: 0.58994

Collected Steps per Second: 22,721.19657
Overall Steps per Second: 10,698.08320

Timestep Collection Time: 2.20085
Timestep Consumption Time: 2.47344
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.67430

Cumulative Model Updates: 182,768
Cumulative Timesteps: 1,524,150,038

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,596.53893
Policy Entropy: 3.73336
Value Function Loss: 0.04116

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09358
Policy Update Magnitude: 0.83206
Value Function Update Magnitude: 0.73018

Collected Steps per Second: 22,917.75100
Overall Steps per Second: 10,860.24185

Timestep Collection Time: 2.18241
Timestep Consumption Time: 2.42301
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.60542

Cumulative Model Updates: 182,774
Cumulative Timesteps: 1,524,200,054

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1524200054...
Checkpoint 1524200054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,804.30029
Policy Entropy: 3.71191
Value Function Loss: 0.03728

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13934
Policy Update Magnitude: 0.75049
Value Function Update Magnitude: 0.87708

Collected Steps per Second: 22,790.11322
Overall Steps per Second: 10,653.71298

Timestep Collection Time: 2.19437
Timestep Consumption Time: 2.49977
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.69414

Cumulative Model Updates: 182,780
Cumulative Timesteps: 1,524,250,064

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,091.59004
Policy Entropy: 3.73666
Value Function Loss: 0.03078

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13752
Policy Update Magnitude: 0.59818
Value Function Update Magnitude: 1.01944

Collected Steps per Second: 22,614.29088
Overall Steps per Second: 10,713.99997

Timestep Collection Time: 2.21170
Timestep Consumption Time: 2.45659
PPO Batch Consumption Time: 0.28636
Total Iteration Time: 4.66828

Cumulative Model Updates: 182,786
Cumulative Timesteps: 1,524,300,080

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1524300080...
Checkpoint 1524300080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,189.67477
Policy Entropy: 3.70536
Value Function Loss: 0.03216

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.16458
Policy Update Magnitude: 0.51942
Value Function Update Magnitude: 1.00176

Collected Steps per Second: 22,747.89766
Overall Steps per Second: 10,849.25052

Timestep Collection Time: 2.19924
Timestep Consumption Time: 2.41196
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.61119

Cumulative Model Updates: 182,792
Cumulative Timesteps: 1,524,350,108

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,466.85898
Policy Entropy: 3.68836
Value Function Loss: 0.04812

Mean KL Divergence: 0.01302
SB3 Clip Fraction: 0.17023
Policy Update Magnitude: 0.51576
Value Function Update Magnitude: 0.83459

Collected Steps per Second: 22,730.84791
Overall Steps per Second: 10,841.00810

Timestep Collection Time: 2.20141
Timestep Consumption Time: 2.41439
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.61581

Cumulative Model Updates: 182,798
Cumulative Timesteps: 1,524,400,148

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1524400148...
Checkpoint 1524400148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,924.36645
Policy Entropy: 3.70579
Value Function Loss: 0.05232

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13797
Policy Update Magnitude: 0.71786
Value Function Update Magnitude: 0.70588

Collected Steps per Second: 22,654.05639
Overall Steps per Second: 10,758.85654

Timestep Collection Time: 2.20738
Timestep Consumption Time: 2.44052
PPO Batch Consumption Time: 0.28206
Total Iteration Time: 4.64789

Cumulative Model Updates: 182,804
Cumulative Timesteps: 1,524,450,154

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,663.88623
Policy Entropy: 3.73857
Value Function Loss: 0.05234

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14331
Policy Update Magnitude: 0.71750
Value Function Update Magnitude: 0.68597

Collected Steps per Second: 23,155.96722
Overall Steps per Second: 10,880.41756

Timestep Collection Time: 2.15996
Timestep Consumption Time: 2.43692
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.59688

Cumulative Model Updates: 182,810
Cumulative Timesteps: 1,524,500,170

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1524500170...
Checkpoint 1524500170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,708.70200
Policy Entropy: 3.75953
Value Function Loss: 0.05728

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.18291
Policy Update Magnitude: 0.63059
Value Function Update Magnitude: 0.68077

Collected Steps per Second: 22,355.10974
Overall Steps per Second: 10,827.27230

Timestep Collection Time: 2.23770
Timestep Consumption Time: 2.38249
PPO Batch Consumption Time: 0.28848
Total Iteration Time: 4.62018

Cumulative Model Updates: 182,816
Cumulative Timesteps: 1,524,550,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,548.30071
Policy Entropy: 3.75260
Value Function Loss: 0.05459

Mean KL Divergence: 0.01253
SB3 Clip Fraction: 0.16180
Policy Update Magnitude: 0.65285
Value Function Update Magnitude: 0.70898

Collected Steps per Second: 22,450.35676
Overall Steps per Second: 10,687.77362

Timestep Collection Time: 2.22714
Timestep Consumption Time: 2.45111
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.67824

Cumulative Model Updates: 182,822
Cumulative Timesteps: 1,524,600,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1524600194...
Checkpoint 1524600194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,531.95510
Policy Entropy: 3.73745
Value Function Loss: 0.05546

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.17962
Policy Update Magnitude: 0.66518
Value Function Update Magnitude: 0.75052

Collected Steps per Second: 21,485.59243
Overall Steps per Second: 10,726.79585

Timestep Collection Time: 2.32816
Timestep Consumption Time: 2.33511
PPO Batch Consumption Time: 0.27583
Total Iteration Time: 4.66328

Cumulative Model Updates: 182,828
Cumulative Timesteps: 1,524,650,216

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,223.66802
Policy Entropy: 3.74176
Value Function Loss: 0.04150

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.17021
Policy Update Magnitude: 0.60975
Value Function Update Magnitude: 0.76326

Collected Steps per Second: 22,349.71100
Overall Steps per Second: 10,939.98713

Timestep Collection Time: 2.23779
Timestep Consumption Time: 2.33388
PPO Batch Consumption Time: 0.27576
Total Iteration Time: 4.57167

Cumulative Model Updates: 182,834
Cumulative Timesteps: 1,524,700,230

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1524700230...
Checkpoint 1524700230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,814.27003
Policy Entropy: 3.72648
Value Function Loss: 0.03204

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11084
Policy Update Magnitude: 0.60387
Value Function Update Magnitude: 0.69943

Collected Steps per Second: 22,349.94327
Overall Steps per Second: 10,604.06584

Timestep Collection Time: 2.23929
Timestep Consumption Time: 2.48041
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.71970

Cumulative Model Updates: 182,840
Cumulative Timesteps: 1,524,750,278

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,814.27003
Policy Entropy: 3.70187
Value Function Loss: 0.02763

Mean KL Divergence: 0.01394
SB3 Clip Fraction: 0.18044
Policy Update Magnitude: 0.48647
Value Function Update Magnitude: 0.59398

Collected Steps per Second: 22,960.66955
Overall Steps per Second: 10,858.01761

Timestep Collection Time: 2.17851
Timestep Consumption Time: 2.42823
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.60673

Cumulative Model Updates: 182,846
Cumulative Timesteps: 1,524,800,298

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1524800298...
Checkpoint 1524800298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,807.24995
Policy Entropy: 3.70844
Value Function Loss: 0.02549

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13946
Policy Update Magnitude: 0.39756
Value Function Update Magnitude: 0.50734

Collected Steps per Second: 22,921.91218
Overall Steps per Second: 10,771.87874

Timestep Collection Time: 2.18167
Timestep Consumption Time: 2.46079
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.64246

Cumulative Model Updates: 182,852
Cumulative Timesteps: 1,524,850,306

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309,950.55668
Policy Entropy: 3.69688
Value Function Loss: 0.02767

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.37421
Value Function Update Magnitude: 0.53413

Collected Steps per Second: 23,316.27352
Overall Steps per Second: 10,834.20075

Timestep Collection Time: 2.14520
Timestep Consumption Time: 2.47148
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.61668

Cumulative Model Updates: 182,858
Cumulative Timesteps: 1,524,900,324

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1524900324...
Checkpoint 1524900324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,543.16749
Policy Entropy: 3.70484
Value Function Loss: 0.02773

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.37950
Value Function Update Magnitude: 0.50899

Collected Steps per Second: 22,626.74584
Overall Steps per Second: 10,631.83352

Timestep Collection Time: 2.21110
Timestep Consumption Time: 2.49458
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.70568

Cumulative Model Updates: 182,864
Cumulative Timesteps: 1,524,950,354

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,543.16749
Policy Entropy: 3.68631
Value Function Loss: 0.03318

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.12945
Policy Update Magnitude: 0.44186
Value Function Update Magnitude: 0.41207

Collected Steps per Second: 22,828.40131
Overall Steps per Second: 10,848.23145

Timestep Collection Time: 2.19096
Timestep Consumption Time: 2.41957
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.61052

Cumulative Model Updates: 182,870
Cumulative Timesteps: 1,525,000,370

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1525000370...
Checkpoint 1525000370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323,790.56770
Policy Entropy: 3.68083
Value Function Loss: 0.03253

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15272
Policy Update Magnitude: 0.49978
Value Function Update Magnitude: 0.56747

Collected Steps per Second: 22,389.73599
Overall Steps per Second: 10,672.32603

Timestep Collection Time: 2.23442
Timestep Consumption Time: 2.45322
PPO Batch Consumption Time: 0.28294
Total Iteration Time: 4.68764

Cumulative Model Updates: 182,876
Cumulative Timesteps: 1,525,050,398

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323,790.56770
Policy Entropy: 3.67024
Value Function Loss: 0.03263

Mean KL Divergence: 0.02353
SB3 Clip Fraction: 0.27269
Policy Update Magnitude: 0.48691
Value Function Update Magnitude: 0.57309

Collected Steps per Second: 22,906.47590
Overall Steps per Second: 10,881.20175

Timestep Collection Time: 2.18323
Timestep Consumption Time: 2.41277
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.59600

Cumulative Model Updates: 182,882
Cumulative Timesteps: 1,525,100,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1525100408...
Checkpoint 1525100408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,404.13514
Policy Entropy: 3.67440
Value Function Loss: 0.05391

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.20749
Policy Update Magnitude: 0.48083
Value Function Update Magnitude: 0.45575

Collected Steps per Second: 22,647.65006
Overall Steps per Second: 10,698.83394

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.46597
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.67397

Cumulative Model Updates: 182,888
Cumulative Timesteps: 1,525,150,414

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,596.76139
Policy Entropy: 3.68846
Value Function Loss: 0.07174

Mean KL Divergence: 0.01991
SB3 Clip Fraction: 0.22266
Policy Update Magnitude: 0.53825
Value Function Update Magnitude: 0.46055

Collected Steps per Second: 22,620.05148
Overall Steps per Second: 10,816.05175

Timestep Collection Time: 2.21087
Timestep Consumption Time: 2.41281
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.62368

Cumulative Model Updates: 182,894
Cumulative Timesteps: 1,525,200,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1525200424...
Checkpoint 1525200424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,731.96150
Policy Entropy: 3.71279
Value Function Loss: 0.07849

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.24047
Policy Update Magnitude: 0.64742
Value Function Update Magnitude: 0.78188

Collected Steps per Second: 22,501.15523
Overall Steps per Second: 10,689.82919

Timestep Collection Time: 2.22229
Timestep Consumption Time: 2.45543
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.67772

Cumulative Model Updates: 182,900
Cumulative Timesteps: 1,525,250,428

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,143.62355
Policy Entropy: 3.77338
Value Function Loss: 0.08600

Mean KL Divergence: 0.01596
SB3 Clip Fraction: 0.18883
Policy Update Magnitude: 0.58636
Value Function Update Magnitude: 0.69051

Collected Steps per Second: 22,971.71685
Overall Steps per Second: 10,900.99460

Timestep Collection Time: 2.17755
Timestep Consumption Time: 2.41121
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.58876

Cumulative Model Updates: 182,906
Cumulative Timesteps: 1,525,300,450

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1525300450...
Checkpoint 1525300450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 178.81538
Policy Entropy: 3.77539
Value Function Loss: 0.09453

Mean KL Divergence: 0.01903
SB3 Clip Fraction: 0.20824
Policy Update Magnitude: 0.60229
Value Function Update Magnitude: 0.55551

Collected Steps per Second: 22,280.18732
Overall Steps per Second: 10,687.06985

Timestep Collection Time: 2.24442
Timestep Consumption Time: 2.43470
PPO Batch Consumption Time: 0.28102
Total Iteration Time: 4.67911

Cumulative Model Updates: 182,912
Cumulative Timesteps: 1,525,350,456

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,083.27272
Policy Entropy: 3.79751
Value Function Loss: 0.10273

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.17736
Policy Update Magnitude: 0.59738
Value Function Update Magnitude: 0.51413

Collected Steps per Second: 22,838.27129
Overall Steps per Second: 10,846.30397

Timestep Collection Time: 2.19045
Timestep Consumption Time: 2.42182
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.61226

Cumulative Model Updates: 182,918
Cumulative Timesteps: 1,525,400,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1525400482...
Checkpoint 1525400482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,895.16152
Policy Entropy: 3.82716
Value Function Loss: 0.09314

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.16140
Policy Update Magnitude: 0.66389
Value Function Update Magnitude: 0.60904

Collected Steps per Second: 22,520.58026
Overall Steps per Second: 10,685.57847

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.45950
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.68014

Cumulative Model Updates: 182,924
Cumulative Timesteps: 1,525,450,492

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,736.21999
Policy Entropy: 3.84094
Value Function Loss: 0.08514

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.15645
Policy Update Magnitude: 0.72163
Value Function Update Magnitude: 0.76925

Collected Steps per Second: 23,080.83499
Overall Steps per Second: 10,910.71002

Timestep Collection Time: 2.16656
Timestep Consumption Time: 2.41664
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.58320

Cumulative Model Updates: 182,930
Cumulative Timesteps: 1,525,500,498

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1525500498...
Checkpoint 1525500498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 466.66349
Policy Entropy: 3.89417
Value Function Loss: 0.07940

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.65125
Value Function Update Magnitude: 0.83572

Collected Steps per Second: 22,653.73473
Overall Steps per Second: 10,622.30452

Timestep Collection Time: 2.20767
Timestep Consumption Time: 2.50053
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.70821

Cumulative Model Updates: 182,936
Cumulative Timesteps: 1,525,550,510

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 251.53473
Policy Entropy: 3.96077
Value Function Loss: 0.07486

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11464
Policy Update Magnitude: 0.62772
Value Function Update Magnitude: 0.72815

Collected Steps per Second: 22,867.08272
Overall Steps per Second: 10,899.08397

Timestep Collection Time: 2.18664
Timestep Consumption Time: 2.40109
PPO Batch Consumption Time: 0.27904
Total Iteration Time: 4.58772

Cumulative Model Updates: 182,942
Cumulative Timesteps: 1,525,600,512

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1525600512...
Checkpoint 1525600512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,941.01609
Policy Entropy: 3.96616
Value Function Loss: 0.07456

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.11017
Policy Update Magnitude: 0.64203
Value Function Update Magnitude: 0.58270

Collected Steps per Second: 22,693.55423
Overall Steps per Second: 10,700.60385

Timestep Collection Time: 2.20327
Timestep Consumption Time: 2.46936
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.67263

Cumulative Model Updates: 182,948
Cumulative Timesteps: 1,525,650,512

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.54879
Policy Entropy: 3.92291
Value Function Loss: 0.07864

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.65761
Value Function Update Magnitude: 0.57388

Collected Steps per Second: 22,720.18225
Overall Steps per Second: 10,923.14227

Timestep Collection Time: 2.20077
Timestep Consumption Time: 2.37685
PPO Batch Consumption Time: 0.27576
Total Iteration Time: 4.57762

Cumulative Model Updates: 182,954
Cumulative Timesteps: 1,525,700,514

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1525700514...
Checkpoint 1525700514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,171.28208
Policy Entropy: 3.86374
Value Function Loss: 0.09063

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.65899
Value Function Update Magnitude: 0.66621

Collected Steps per Second: 22,616.84481
Overall Steps per Second: 10,715.38599

Timestep Collection Time: 2.21189
Timestep Consumption Time: 2.45672
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.66861

Cumulative Model Updates: 182,960
Cumulative Timesteps: 1,525,750,540

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.50792
Policy Entropy: 3.85784
Value Function Loss: 0.08363

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.13706
Policy Update Magnitude: 0.61388
Value Function Update Magnitude: 0.54787

Collected Steps per Second: 22,935.77771
Overall Steps per Second: 10,886.05169

Timestep Collection Time: 2.18044
Timestep Consumption Time: 2.41352
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.59395

Cumulative Model Updates: 182,966
Cumulative Timesteps: 1,525,800,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1525800550...
Checkpoint 1525800550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,307.79415
Policy Entropy: 3.82964
Value Function Loss: 0.08235

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.13457
Policy Update Magnitude: 0.59740
Value Function Update Magnitude: 0.48587

Collected Steps per Second: 22,229.26008
Overall Steps per Second: 10,897.12256

Timestep Collection Time: 2.24974
Timestep Consumption Time: 2.33955
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.58928

Cumulative Model Updates: 182,972
Cumulative Timesteps: 1,525,850,560

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,878.07877
Policy Entropy: 3.80858
Value Function Loss: 0.08127

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.58614
Value Function Update Magnitude: 0.43142

Collected Steps per Second: 22,032.34530
Overall Steps per Second: 10,708.37450

Timestep Collection Time: 2.26984
Timestep Consumption Time: 2.40033
PPO Batch Consumption Time: 0.28907
Total Iteration Time: 4.67018

Cumulative Model Updates: 182,978
Cumulative Timesteps: 1,525,900,570

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1525900570...
Checkpoint 1525900570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379.78202
Policy Entropy: 3.78918
Value Function Loss: 0.08621

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13592
Policy Update Magnitude: 0.58804
Value Function Update Magnitude: 0.40815

Collected Steps per Second: 21,979.15510
Overall Steps per Second: 10,835.23601

Timestep Collection Time: 2.27516
Timestep Consumption Time: 2.33997
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.61513

Cumulative Model Updates: 182,984
Cumulative Timesteps: 1,525,950,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 908.62572
Policy Entropy: 3.82128
Value Function Loss: 0.08248

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.12372
Policy Update Magnitude: 0.62698
Value Function Update Magnitude: 0.45441

Collected Steps per Second: 22,800.52413
Overall Steps per Second: 10,744.75424

Timestep Collection Time: 2.19372
Timestep Consumption Time: 2.46139
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.65511

Cumulative Model Updates: 182,990
Cumulative Timesteps: 1,526,000,594

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1526000594...
Checkpoint 1526000594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.38961
Policy Entropy: 3.88043
Value Function Loss: 0.07270

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.10980
Policy Update Magnitude: 0.67076
Value Function Update Magnitude: 0.58455

Collected Steps per Second: 22,555.84949
Overall Steps per Second: 10,795.72091

Timestep Collection Time: 2.21752
Timestep Consumption Time: 2.41561
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.63313

Cumulative Model Updates: 182,996
Cumulative Timesteps: 1,526,050,612

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 469.58784
Policy Entropy: 3.92890
Value Function Loss: 0.06472

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.10834
Policy Update Magnitude: 0.73424
Value Function Update Magnitude: 0.72307

Collected Steps per Second: 22,678.75626
Overall Steps per Second: 10,633.60663

Timestep Collection Time: 2.20576
Timestep Consumption Time: 2.49857
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.70433

Cumulative Model Updates: 183,002
Cumulative Timesteps: 1,526,100,636

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1526100636...
Checkpoint 1526100636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366.38237
Policy Entropy: 3.95817
Value Function Loss: 0.06268

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.72309
Value Function Update Magnitude: 0.65947

Collected Steps per Second: 22,812.00001
Overall Steps per Second: 10,942.05798

Timestep Collection Time: 2.19235
Timestep Consumption Time: 2.37827
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.57062

Cumulative Model Updates: 183,008
Cumulative Timesteps: 1,526,150,648

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,485.01738
Policy Entropy: 3.93617
Value Function Loss: 0.06422

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.10753
Policy Update Magnitude: 0.68998
Value Function Update Magnitude: 0.61341

Collected Steps per Second: 22,476.58109
Overall Steps per Second: 10,701.83994

Timestep Collection Time: 2.22507
Timestep Consumption Time: 2.44814
PPO Batch Consumption Time: 0.28782
Total Iteration Time: 4.67322

Cumulative Model Updates: 183,014
Cumulative Timesteps: 1,526,200,660

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1526200660...
Checkpoint 1526200660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 416.79833
Policy Entropy: 3.91468
Value Function Loss: 0.06416

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.11345
Policy Update Magnitude: 0.65314
Value Function Update Magnitude: 0.54214

Collected Steps per Second: 22,733.34521
Overall Steps per Second: 10,868.24433

Timestep Collection Time: 2.19994
Timestep Consumption Time: 2.40172
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.60166

Cumulative Model Updates: 183,020
Cumulative Timesteps: 1,526,250,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,338.47199
Policy Entropy: 3.90471
Value Function Loss: 0.06278

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.11396
Policy Update Magnitude: 0.64164
Value Function Update Magnitude: 0.55139

Collected Steps per Second: 23,010.68293
Overall Steps per Second: 10,969.13354

Timestep Collection Time: 2.17299
Timestep Consumption Time: 2.38544
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.55843

Cumulative Model Updates: 183,026
Cumulative Timesteps: 1,526,300,674

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1526300674...
Checkpoint 1526300674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,289.45842
Policy Entropy: 3.86374
Value Function Loss: 0.06537

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.11363
Policy Update Magnitude: 0.65336
Value Function Update Magnitude: 0.55496

Collected Steps per Second: 21,966.53942
Overall Steps per Second: 10,657.68882

Timestep Collection Time: 2.27655
Timestep Consumption Time: 2.41565
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.69220

Cumulative Model Updates: 183,032
Cumulative Timesteps: 1,526,350,682

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,404.33750
Policy Entropy: 3.84682
Value Function Loss: 0.07207

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.65275
Value Function Update Magnitude: 0.49219

Collected Steps per Second: 22,196.08730
Overall Steps per Second: 10,882.10555

Timestep Collection Time: 2.25301
Timestep Consumption Time: 2.34242
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.59543

Cumulative Model Updates: 183,038
Cumulative Timesteps: 1,526,400,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1526400690...
Checkpoint 1526400690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 618.95364
Policy Entropy: 3.82197
Value Function Loss: 0.07108

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.59985
Value Function Update Magnitude: 0.46724

Collected Steps per Second: 22,662.37974
Overall Steps per Second: 10,638.76193

Timestep Collection Time: 2.20727
Timestep Consumption Time: 2.49459
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.70186

Cumulative Model Updates: 183,044
Cumulative Timesteps: 1,526,450,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,922.78838
Policy Entropy: 3.81457
Value Function Loss: 0.07082

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.54608
Value Function Update Magnitude: 0.52880

Collected Steps per Second: 22,826.73885
Overall Steps per Second: 10,847.53010

Timestep Collection Time: 2.19076
Timestep Consumption Time: 2.41932
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.61008

Cumulative Model Updates: 183,050
Cumulative Timesteps: 1,526,500,720

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1526500720...
Checkpoint 1526500720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,716.06085
Policy Entropy: 3.80379
Value Function Loss: 0.06942

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.50314
Value Function Update Magnitude: 0.45639

Collected Steps per Second: 22,687.97907
Overall Steps per Second: 10,680.69821

Timestep Collection Time: 2.20513
Timestep Consumption Time: 2.47902
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.68415

Cumulative Model Updates: 183,056
Cumulative Timesteps: 1,526,550,750

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,575.79583
Policy Entropy: 3.79966
Value Function Loss: 0.06756

Mean KL Divergence: 0.01194
SB3 Clip Fraction: 0.13889
Policy Update Magnitude: 0.49975
Value Function Update Magnitude: 0.41974

Collected Steps per Second: 22,913.17765
Overall Steps per Second: 10,850.45488

Timestep Collection Time: 2.18346
Timestep Consumption Time: 2.42741
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.61087

Cumulative Model Updates: 183,062
Cumulative Timesteps: 1,526,600,780

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1526600780...
Checkpoint 1526600780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 655.81511
Policy Entropy: 3.83221
Value Function Loss: 0.06119

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13134
Policy Update Magnitude: 0.50708
Value Function Update Magnitude: 0.40596

Collected Steps per Second: 22,775.47416
Overall Steps per Second: 10,666.87049

Timestep Collection Time: 2.19613
Timestep Consumption Time: 2.49296
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.68910

Cumulative Model Updates: 183,068
Cumulative Timesteps: 1,526,650,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,951.62549
Policy Entropy: 3.84579
Value Function Loss: 0.05978

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13528
Policy Update Magnitude: 0.51587
Value Function Update Magnitude: 0.41018

Collected Steps per Second: 23,168.26378
Overall Steps per Second: 10,914.93705

Timestep Collection Time: 2.15847
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.58161

Cumulative Model Updates: 183,074
Cumulative Timesteps: 1,526,700,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1526700806...
Checkpoint 1526700806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,693.65598
Policy Entropy: 3.83943
Value Function Loss: 0.06156

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.48556
Value Function Update Magnitude: 0.38626

Collected Steps per Second: 22,602.79652
Overall Steps per Second: 10,685.05539

Timestep Collection Time: 2.21300
Timestep Consumption Time: 2.46830
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.68130

Cumulative Model Updates: 183,080
Cumulative Timesteps: 1,526,750,826

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,426.21150
Policy Entropy: 3.82342
Value Function Loss: 0.06323

Mean KL Divergence: 0.01005
SB3 Clip Fraction: 0.12608
Policy Update Magnitude: 0.48976
Value Function Update Magnitude: 0.40056

Collected Steps per Second: 22,816.10801
Overall Steps per Second: 10,832.46521

Timestep Collection Time: 2.19231
Timestep Consumption Time: 2.42529
PPO Batch Consumption Time: 0.27856
Total Iteration Time: 4.61760

Cumulative Model Updates: 183,086
Cumulative Timesteps: 1,526,800,846

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1526800846...
Checkpoint 1526800846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,452.66208
Policy Entropy: 3.77555
Value Function Loss: 0.06531

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12919
Policy Update Magnitude: 0.49568
Value Function Update Magnitude: 0.36632

Collected Steps per Second: 22,088.92242
Overall Steps per Second: 10,671.88121

Timestep Collection Time: 2.26494
Timestep Consumption Time: 2.42308
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.68802

Cumulative Model Updates: 183,092
Cumulative Timesteps: 1,526,850,876

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,397.16237
Policy Entropy: 3.73000
Value Function Loss: 0.06831

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.13704
Policy Update Magnitude: 0.48729
Value Function Update Magnitude: 0.38529

Collected Steps per Second: 23,223.20240
Overall Steps per Second: 10,920.66236

Timestep Collection Time: 2.15397
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.58049

Cumulative Model Updates: 183,098
Cumulative Timesteps: 1,526,900,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1526900898...
Checkpoint 1526900898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,757.47141
Policy Entropy: 3.70014
Value Function Loss: 0.07148

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.14676
Policy Update Magnitude: 0.48055
Value Function Update Magnitude: 0.36817

Collected Steps per Second: 22,768.11966
Overall Steps per Second: 10,660.94037

Timestep Collection Time: 2.19728
Timestep Consumption Time: 2.49536
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.69264

Cumulative Model Updates: 183,104
Cumulative Timesteps: 1,526,950,926

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,603.75261
Policy Entropy: 3.74636
Value Function Loss: 0.06893

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.49229
Value Function Update Magnitude: 0.34000

Collected Steps per Second: 22,805.07638
Overall Steps per Second: 10,851.48154

Timestep Collection Time: 2.19293
Timestep Consumption Time: 2.41565
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.60859

Cumulative Model Updates: 183,110
Cumulative Timesteps: 1,527,000,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1527000936...
Checkpoint 1527000936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,435.92161
Policy Entropy: 3.78849
Value Function Loss: 0.06623

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13682
Policy Update Magnitude: 0.47525
Value Function Update Magnitude: 0.34064

Collected Steps per Second: 22,530.93815
Overall Steps per Second: 10,696.67799

Timestep Collection Time: 2.21997
Timestep Consumption Time: 2.45606
PPO Batch Consumption Time: 0.28440
Total Iteration Time: 4.67603

Cumulative Model Updates: 183,116
Cumulative Timesteps: 1,527,050,954

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,974.83264
Policy Entropy: 3.82312
Value Function Loss: 0.06198

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.12793
Policy Update Magnitude: 0.46590
Value Function Update Magnitude: 0.38489

Collected Steps per Second: 23,148.54551
Overall Steps per Second: 10,934.31456

Timestep Collection Time: 2.16126
Timestep Consumption Time: 2.41425
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.57550

Cumulative Model Updates: 183,122
Cumulative Timesteps: 1,527,100,984

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1527100984...
Checkpoint 1527100984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77.26300
Policy Entropy: 3.81809
Value Function Loss: 0.06409

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.12542
Policy Update Magnitude: 0.47595
Value Function Update Magnitude: 0.42901

Collected Steps per Second: 22,319.48183
Overall Steps per Second: 10,619.12204

Timestep Collection Time: 2.24046
Timestep Consumption Time: 2.46859
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.70905

Cumulative Model Updates: 183,128
Cumulative Timesteps: 1,527,150,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,171.60483
Policy Entropy: 3.79047
Value Function Loss: 0.06637

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.49121
Value Function Update Magnitude: 0.38743

Collected Steps per Second: 22,615.77053
Overall Steps per Second: 10,636.26566

Timestep Collection Time: 2.21182
Timestep Consumption Time: 2.49115
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.70297

Cumulative Model Updates: 183,134
Cumulative Timesteps: 1,527,201,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1527201012...
Checkpoint 1527201012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,571.49717
Policy Entropy: 3.77835
Value Function Loss: 0.06661

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.50495
Value Function Update Magnitude: 0.39153

Collected Steps per Second: 22,761.99536
Overall Steps per Second: 10,810.45732

Timestep Collection Time: 2.19761
Timestep Consumption Time: 2.42958
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.62719

Cumulative Model Updates: 183,140
Cumulative Timesteps: 1,527,251,034

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,630.26049
Policy Entropy: 3.74128
Value Function Loss: 0.07017

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.13950
Policy Update Magnitude: 0.51196
Value Function Update Magnitude: 0.40186

Collected Steps per Second: 22,930.97264
Overall Steps per Second: 10,662.44552

Timestep Collection Time: 2.18089
Timestep Consumption Time: 2.50940
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.69029

Cumulative Model Updates: 183,146
Cumulative Timesteps: 1,527,301,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1527301044...
Checkpoint 1527301044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 722.20374
Policy Entropy: 3.77259
Value Function Loss: 0.07747

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.53109
Value Function Update Magnitude: 0.36649

Collected Steps per Second: 22,583.35746
Overall Steps per Second: 10,671.65926

Timestep Collection Time: 2.21464
Timestep Consumption Time: 2.47198
PPO Batch Consumption Time: 0.28926
Total Iteration Time: 4.68662

Cumulative Model Updates: 183,152
Cumulative Timesteps: 1,527,351,058

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,362.00977
Policy Entropy: 3.78081
Value Function Loss: 0.06629

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.12305
Policy Update Magnitude: 0.57660
Value Function Update Magnitude: 0.30029

Collected Steps per Second: 22,794.40786
Overall Steps per Second: 10,702.08315

Timestep Collection Time: 2.19361
Timestep Consumption Time: 2.47857
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.67217

Cumulative Model Updates: 183,158
Cumulative Timesteps: 1,527,401,060

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1527401060...
Checkpoint 1527401060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,858.89282
Policy Entropy: 3.79652
Value Function Loss: 0.06014

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.57803
Value Function Update Magnitude: 0.42994

Collected Steps per Second: 22,688.37210
Overall Steps per Second: 10,680.49391

Timestep Collection Time: 2.20509
Timestep Consumption Time: 2.47915
PPO Batch Consumption Time: 0.29139
Total Iteration Time: 4.68424

Cumulative Model Updates: 183,164
Cumulative Timesteps: 1,527,451,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,465.17296
Policy Entropy: 3.75475
Value Function Loss: 0.06376

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.54125
Value Function Update Magnitude: 0.46340

Collected Steps per Second: 22,794.48607
Overall Steps per Second: 10,896.36332

Timestep Collection Time: 2.19474
Timestep Consumption Time: 2.39652
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.59126

Cumulative Model Updates: 183,170
Cumulative Timesteps: 1,527,501,118

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1527501118...
Checkpoint 1527501118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,457.41874
Policy Entropy: 3.74733
Value Function Loss: 0.06548

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.48866
Value Function Update Magnitude: 0.43622

Collected Steps per Second: 22,726.19259
Overall Steps per Second: 10,718.63500

Timestep Collection Time: 2.20090
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.66645

Cumulative Model Updates: 183,176
Cumulative Timesteps: 1,527,551,136

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,694.26125
Policy Entropy: 3.76515
Value Function Loss: 0.06295

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15083
Policy Update Magnitude: 0.48462
Value Function Update Magnitude: 0.37754

Collected Steps per Second: 22,849.30672
Overall Steps per Second: 10,917.93201

Timestep Collection Time: 2.18913
Timestep Consumption Time: 2.39233
PPO Batch Consumption Time: 0.27636
Total Iteration Time: 4.58145

Cumulative Model Updates: 183,182
Cumulative Timesteps: 1,527,601,156

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1527601156...
Checkpoint 1527601156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,179.78720
Policy Entropy: 3.79435
Value Function Loss: 0.05724

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15375
Policy Update Magnitude: 0.47825
Value Function Update Magnitude: 0.36398

Collected Steps per Second: 22,674.46862
Overall Steps per Second: 10,622.81002

Timestep Collection Time: 2.20618
Timestep Consumption Time: 2.50293
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.70911

Cumulative Model Updates: 183,188
Cumulative Timesteps: 1,527,651,180

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,306.69662
Policy Entropy: 3.79301
Value Function Loss: 0.05797

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.16713
Policy Update Magnitude: 0.43681
Value Function Update Magnitude: 0.35434

Collected Steps per Second: 22,738.12747
Overall Steps per Second: 10,796.30020

Timestep Collection Time: 2.19992
Timestep Consumption Time: 2.43334
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.63325

Cumulative Model Updates: 183,194
Cumulative Timesteps: 1,527,701,202

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1527701202...
Checkpoint 1527701202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,344.49629
Policy Entropy: 3.77066
Value Function Loss: 0.05914

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.15495
Policy Update Magnitude: 0.45073
Value Function Update Magnitude: 0.30242

Collected Steps per Second: 22,842.42073
Overall Steps per Second: 10,743.22832

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.46578
PPO Batch Consumption Time: 0.28443
Total Iteration Time: 4.65521

Cumulative Model Updates: 183,200
Cumulative Timesteps: 1,527,751,214

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587.99977
Policy Entropy: 3.75510
Value Function Loss: 0.05811

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.14561
Policy Update Magnitude: 0.55007
Value Function Update Magnitude: 0.27882

Collected Steps per Second: 23,290.71905
Overall Steps per Second: 10,890.07521

Timestep Collection Time: 2.14755
Timestep Consumption Time: 2.44544
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.59299

Cumulative Model Updates: 183,206
Cumulative Timesteps: 1,527,801,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1527801232...
Checkpoint 1527801232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587.99977
Policy Entropy: 3.72460
Value Function Loss: 0.05617

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13554
Policy Update Magnitude: 0.58256
Value Function Update Magnitude: 0.24186

Collected Steps per Second: 22,333.55253
Overall Steps per Second: 10,654.36904

Timestep Collection Time: 2.23896
Timestep Consumption Time: 2.45432
PPO Batch Consumption Time: 0.28280
Total Iteration Time: 4.69329

Cumulative Model Updates: 183,212
Cumulative Timesteps: 1,527,851,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,672.84865
Policy Entropy: 3.72405
Value Function Loss: 0.05187

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15330
Policy Update Magnitude: 0.58423
Value Function Update Magnitude: 0.21990

Collected Steps per Second: 23,174.87546
Overall Steps per Second: 10,906.06185

Timestep Collection Time: 2.15811
Timestep Consumption Time: 2.42778
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.58589

Cumulative Model Updates: 183,218
Cumulative Timesteps: 1,527,901,250

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1527901250...
Checkpoint 1527901250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,744.53863
Policy Entropy: 3.73556
Value Function Loss: 0.05114

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14272
Policy Update Magnitude: 0.64227
Value Function Update Magnitude: 0.27451

Collected Steps per Second: 22,723.77494
Overall Steps per Second: 10,642.25580

Timestep Collection Time: 2.20139
Timestep Consumption Time: 2.49911
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.70051

Cumulative Model Updates: 183,224
Cumulative Timesteps: 1,527,951,274

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,378.24404
Policy Entropy: 3.76716
Value Function Loss: 0.05482

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.17838
Policy Update Magnitude: 0.64680
Value Function Update Magnitude: 0.39065

Collected Steps per Second: 22,846.89733
Overall Steps per Second: 10,895.37685

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.40168
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.59112

Cumulative Model Updates: 183,230
Cumulative Timesteps: 1,528,001,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1528001296...
Checkpoint 1528001296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,771.92069
Policy Entropy: 3.82031
Value Function Loss: 0.05523

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.17275
Policy Update Magnitude: 0.53592
Value Function Update Magnitude: 0.62306

Collected Steps per Second: 22,629.00809
Overall Steps per Second: 10,687.65864

Timestep Collection Time: 2.21114
Timestep Consumption Time: 2.47052
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.68166

Cumulative Model Updates: 183,236
Cumulative Timesteps: 1,528,051,332

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,618.94079
Policy Entropy: 3.85944
Value Function Loss: 0.05353

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.15539
Policy Update Magnitude: 0.49084
Value Function Update Magnitude: 0.55646

Collected Steps per Second: 22,882.57689
Overall Steps per Second: 10,844.97369

Timestep Collection Time: 2.18542
Timestep Consumption Time: 2.42575
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.61117

Cumulative Model Updates: 183,242
Cumulative Timesteps: 1,528,101,340

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1528101340...
Checkpoint 1528101340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,636.53110
Policy Entropy: 3.86786
Value Function Loss: 0.05379

Mean KL Divergence: 0.01412
SB3 Clip Fraction: 0.16772
Policy Update Magnitude: 0.52073
Value Function Update Magnitude: 0.54067

Collected Steps per Second: 22,666.03208
Overall Steps per Second: 10,661.98634

Timestep Collection Time: 2.20639
Timestep Consumption Time: 2.48411
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.69050

Cumulative Model Updates: 183,248
Cumulative Timesteps: 1,528,151,350

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,942.32681
Policy Entropy: 3.82774
Value Function Loss: 0.05680

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.14792
Policy Update Magnitude: 0.50336
Value Function Update Magnitude: 0.43192

Collected Steps per Second: 23,240.34593
Overall Steps per Second: 10,936.62262

Timestep Collection Time: 2.15238
Timestep Consumption Time: 2.42143
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.57381

Cumulative Model Updates: 183,254
Cumulative Timesteps: 1,528,201,372

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1528201372...
Checkpoint 1528201372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,856.19343
Policy Entropy: 3.77034
Value Function Loss: 0.04986

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15554
Policy Update Magnitude: 0.48033
Value Function Update Magnitude: 0.36539

Collected Steps per Second: 22,550.22236
Overall Steps per Second: 10,620.59572

Timestep Collection Time: 2.21763
Timestep Consumption Time: 2.49096
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.70859

Cumulative Model Updates: 183,260
Cumulative Timesteps: 1,528,251,380

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,856.19343
Policy Entropy: 3.71960
Value Function Loss: 0.03870

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07647
Policy Update Magnitude: 0.53466
Value Function Update Magnitude: 0.33724

Collected Steps per Second: 23,316.50740
Overall Steps per Second: 10,988.37309

Timestep Collection Time: 2.14655
Timestep Consumption Time: 2.40827
PPO Batch Consumption Time: 0.27592
Total Iteration Time: 4.55481

Cumulative Model Updates: 183,266
Cumulative Timesteps: 1,528,301,430

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1528301430...
Checkpoint 1528301430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,856.19343
Policy Entropy: 3.68763
Value Function Loss: 0.02887

Mean KL Divergence: 0.01216
SB3 Clip Fraction: 0.16108
Policy Update Magnitude: 0.47997
Value Function Update Magnitude: 0.31782

Collected Steps per Second: 22,506.50396
Overall Steps per Second: 10,600.20504

Timestep Collection Time: 2.22265
Timestep Consumption Time: 2.49651
PPO Batch Consumption Time: 0.29251
Total Iteration Time: 4.71915

Cumulative Model Updates: 183,272
Cumulative Timesteps: 1,528,351,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,856.19343
Policy Entropy: 3.68407
Value Function Loss: 0.02733

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.15175
Policy Update Magnitude: 0.33316
Value Function Update Magnitude: 0.30442

Collected Steps per Second: 23,177.07632
Overall Steps per Second: 10,938.24487

Timestep Collection Time: 2.15756
Timestep Consumption Time: 2.41410
PPO Batch Consumption Time: 0.27636
Total Iteration Time: 4.57167

Cumulative Model Updates: 183,278
Cumulative Timesteps: 1,528,401,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1528401460...
Checkpoint 1528401460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,856.19343
Policy Entropy: 3.66956
Value Function Loss: 0.02603

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.15282
Policy Update Magnitude: 0.27089
Value Function Update Magnitude: 0.27011

Collected Steps per Second: 22,498.42580
Overall Steps per Second: 10,573.04446

Timestep Collection Time: 2.22256
Timestep Consumption Time: 2.50683
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.72939

Cumulative Model Updates: 183,284
Cumulative Timesteps: 1,528,451,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,856.19343
Policy Entropy: 3.66251
Value Function Loss: 0.02512

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.14415
Policy Update Magnitude: 0.25443
Value Function Update Magnitude: 0.29149

Collected Steps per Second: 22,798.06204
Overall Steps per Second: 10,864.46596

Timestep Collection Time: 2.19457
Timestep Consumption Time: 2.41053
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.60510

Cumulative Model Updates: 183,290
Cumulative Timesteps: 1,528,501,496

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1528501496...
Checkpoint 1528501496 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,856.19343
Policy Entropy: 3.65877
Value Function Loss: 0.02430

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15448
Policy Update Magnitude: 0.24283
Value Function Update Magnitude: 0.27011

Collected Steps per Second: 22,573.47145
Overall Steps per Second: 10,709.60963

Timestep Collection Time: 2.21508
Timestep Consumption Time: 2.45381
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.66889

Cumulative Model Updates: 183,296
Cumulative Timesteps: 1,528,551,498

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,856.19343
Policy Entropy: 3.67560
Value Function Loss: 0.02431

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.25270
Value Function Update Magnitude: 0.27986

Collected Steps per Second: 22,556.26074
Overall Steps per Second: 10,903.04627

Timestep Collection Time: 2.21686
Timestep Consumption Time: 2.36938
PPO Batch Consumption Time: 0.28154
Total Iteration Time: 4.58624

Cumulative Model Updates: 183,302
Cumulative Timesteps: 1,528,601,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1528601502...
Checkpoint 1528601502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,856.19343
Policy Entropy: 3.65124
Value Function Loss: 0.02705

Mean KL Divergence: 0.01121
SB3 Clip Fraction: 0.14717
Policy Update Magnitude: 0.26104
Value Function Update Magnitude: 0.29539

Collected Steps per Second: 21,979.78401
Overall Steps per Second: 10,631.83721

Timestep Collection Time: 2.27509
Timestep Consumption Time: 2.42833
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.70342

Cumulative Model Updates: 183,308
Cumulative Timesteps: 1,528,651,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,334.63700
Policy Entropy: 3.66301
Value Function Loss: 0.03099

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12973
Policy Update Magnitude: 0.28969
Value Function Update Magnitude: 0.34262

Collected Steps per Second: 22,718.42847
Overall Steps per Second: 10,860.02614

Timestep Collection Time: 2.20174
Timestep Consumption Time: 2.40415
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.60588

Cumulative Model Updates: 183,314
Cumulative Timesteps: 1,528,701,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1528701528...
Checkpoint 1528701528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,222.62883
Policy Entropy: 3.66389
Value Function Loss: 0.03117

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.29709
Value Function Update Magnitude: 0.39103

Collected Steps per Second: 22,453.19617
Overall Steps per Second: 10,715.31107

Timestep Collection Time: 2.22775
Timestep Consumption Time: 2.44034
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.66809

Cumulative Model Updates: 183,320
Cumulative Timesteps: 1,528,751,548

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,485.56745
Policy Entropy: 3.68406
Value Function Loss: 0.03109

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.31157
Value Function Update Magnitude: 0.44590

Collected Steps per Second: 23,375.52087
Overall Steps per Second: 10,884.71355

Timestep Collection Time: 2.14104
Timestep Consumption Time: 2.45696
PPO Batch Consumption Time: 0.28513
Total Iteration Time: 4.59801

Cumulative Model Updates: 183,326
Cumulative Timesteps: 1,528,801,596

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1528801596...
Checkpoint 1528801596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,954.06379
Policy Entropy: 3.66887
Value Function Loss: 0.02971

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.13876
Policy Update Magnitude: 0.30976
Value Function Update Magnitude: 0.38967

Collected Steps per Second: 22,647.70721
Overall Steps per Second: 10,629.88534

Timestep Collection Time: 2.20773
Timestep Consumption Time: 2.49599
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.70372

Cumulative Model Updates: 183,332
Cumulative Timesteps: 1,528,851,596

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,954.06379
Policy Entropy: 3.66823
Value Function Loss: 0.02463

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.31412
Value Function Update Magnitude: 0.31614

Collected Steps per Second: 23,250.18137
Overall Steps per Second: 10,898.12122

Timestep Collection Time: 2.15069
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.58831

Cumulative Model Updates: 183,338
Cumulative Timesteps: 1,528,901,600

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1528901600...
Checkpoint 1528901600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,954.06379
Policy Entropy: 3.65737
Value Function Loss: 0.02165

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13883
Policy Update Magnitude: 0.29014
Value Function Update Magnitude: 0.27141

Collected Steps per Second: 22,482.80532
Overall Steps per Second: 10,678.27244

Timestep Collection Time: 2.22508
Timestep Consumption Time: 2.45976
PPO Batch Consumption Time: 0.28285
Total Iteration Time: 4.68484

Cumulative Model Updates: 183,344
Cumulative Timesteps: 1,528,951,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,624.06282
Policy Entropy: 3.65765
Value Function Loss: 0.02140

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13227
Policy Update Magnitude: 0.29416
Value Function Update Magnitude: 0.27089

Collected Steps per Second: 22,928.90878
Overall Steps per Second: 10,851.93860

Timestep Collection Time: 2.18074
Timestep Consumption Time: 2.42692
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.60766

Cumulative Model Updates: 183,350
Cumulative Timesteps: 1,529,001,628

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1529001628...
Checkpoint 1529001628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,274.84119
Policy Entropy: 3.66743
Value Function Loss: 0.02274

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.29428
Value Function Update Magnitude: 0.33852

Collected Steps per Second: 22,524.73723
Overall Steps per Second: 10,679.61667

Timestep Collection Time: 2.22102
Timestep Consumption Time: 2.46341
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.68444

Cumulative Model Updates: 183,356
Cumulative Timesteps: 1,529,051,656

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,966.67285
Policy Entropy: 3.66402
Value Function Loss: 0.02170

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.29630
Value Function Update Magnitude: 0.36942

Collected Steps per Second: 23,039.04132
Overall Steps per Second: 10,869.63374

Timestep Collection Time: 2.17032
Timestep Consumption Time: 2.42984
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.60016

Cumulative Model Updates: 183,362
Cumulative Timesteps: 1,529,101,658

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1529101658...
Checkpoint 1529101658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 162,503.93538
Policy Entropy: 3.67687
Value Function Loss: 0.02109

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06779
Policy Update Magnitude: 0.34431
Value Function Update Magnitude: 0.32672

Collected Steps per Second: 22,665.87514
Overall Steps per Second: 10,689.44666

Timestep Collection Time: 2.20737
Timestep Consumption Time: 2.47313
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.68050

Cumulative Model Updates: 183,368
Cumulative Timesteps: 1,529,151,690

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,635.44143
Policy Entropy: 3.67268
Value Function Loss: 0.01924

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.32987
Value Function Update Magnitude: 0.32012

Collected Steps per Second: 22,950.77302
Overall Steps per Second: 10,852.30249

Timestep Collection Time: 2.17866
Timestep Consumption Time: 2.42884
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.60750

Cumulative Model Updates: 183,374
Cumulative Timesteps: 1,529,201,692

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1529201692...
Checkpoint 1529201692 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,635.44143
Policy Entropy: 3.67554
Value Function Loss: 0.01685

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15033
Policy Update Magnitude: 0.25018
Value Function Update Magnitude: 0.35795

Collected Steps per Second: 22,433.48809
Overall Steps per Second: 10,677.85919

Timestep Collection Time: 2.22970
Timestep Consumption Time: 2.45476
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.68446

Cumulative Model Updates: 183,380
Cumulative Timesteps: 1,529,251,712

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,635.44143
Policy Entropy: 3.67946
Value Function Loss: 0.01521

Mean KL Divergence: 0.01281
SB3 Clip Fraction: 0.16513
Policy Update Magnitude: 0.21919
Value Function Update Magnitude: 0.27765

Collected Steps per Second: 23,040.71888
Overall Steps per Second: 10,900.78699

Timestep Collection Time: 2.17068
Timestep Consumption Time: 2.41743
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.58811

Cumulative Model Updates: 183,386
Cumulative Timesteps: 1,529,301,726

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1529301726...
Checkpoint 1529301726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,635.44143
Policy Entropy: 3.66711
Value Function Loss: 0.01390

Mean KL Divergence: 0.01681
SB3 Clip Fraction: 0.19423
Policy Update Magnitude: 0.22256
Value Function Update Magnitude: 0.19981

Collected Steps per Second: 22,716.65978
Overall Steps per Second: 10,652.14438

Timestep Collection Time: 2.20314
Timestep Consumption Time: 2.49526
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.69840

Cumulative Model Updates: 183,392
Cumulative Timesteps: 1,529,351,774

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,635.44143
Policy Entropy: 3.66663
Value Function Loss: 0.01855

Mean KL Divergence: 0.01922
SB3 Clip Fraction: 0.21617
Policy Update Magnitude: 0.28533
Value Function Update Magnitude: 0.33582

Collected Steps per Second: 22,969.40285
Overall Steps per Second: 10,877.17359

Timestep Collection Time: 2.17768
Timestep Consumption Time: 2.42094
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.59862

Cumulative Model Updates: 183,398
Cumulative Timesteps: 1,529,401,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1529401794...
Checkpoint 1529401794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91,743.43350
Policy Entropy: 3.69414
Value Function Loss: 0.02420

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.18072
Policy Update Magnitude: 0.41243
Value Function Update Magnitude: 0.62133

Collected Steps per Second: 22,385.04106
Overall Steps per Second: 10,676.06776

Timestep Collection Time: 2.23363
Timestep Consumption Time: 2.44974
PPO Batch Consumption Time: 0.28317
Total Iteration Time: 4.68337

Cumulative Model Updates: 183,404
Cumulative Timesteps: 1,529,451,794

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,193.64060
Policy Entropy: 3.69673
Value Function Loss: 0.03010

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.16447
Policy Update Magnitude: 0.49631
Value Function Update Magnitude: 0.83184

Collected Steps per Second: 22,191.56891
Overall Steps per Second: 10,884.28448

Timestep Collection Time: 2.25446
Timestep Consumption Time: 2.34208
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.59654

Cumulative Model Updates: 183,410
Cumulative Timesteps: 1,529,501,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1529501824...
Checkpoint 1529501824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,022.47476
Policy Entropy: 3.72447
Value Function Loss: 0.02993

Mean KL Divergence: 0.00751
SB3 Clip Fraction: 0.09432
Policy Update Magnitude: 0.63985
Value Function Update Magnitude: 0.79489

Collected Steps per Second: 21,853.71780
Overall Steps per Second: 10,705.16153

Timestep Collection Time: 2.28886
Timestep Consumption Time: 2.38366
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.67251

Cumulative Model Updates: 183,416
Cumulative Timesteps: 1,529,551,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,144.40064
Policy Entropy: 3.70760
Value Function Loss: 0.02687

Mean KL Divergence: 0.00652
SB3 Clip Fraction: 0.07792
Policy Update Magnitude: 0.67022
Value Function Update Magnitude: 0.71881

Collected Steps per Second: 22,583.34305
Overall Steps per Second: 10,875.24294

Timestep Collection Time: 2.21535
Timestep Consumption Time: 2.38501
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.60036

Cumulative Model Updates: 183,422
Cumulative Timesteps: 1,529,601,874

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1529601874...
Checkpoint 1529601874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,144.40064
Policy Entropy: 3.69873
Value Function Loss: 0.02059

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07288
Policy Update Magnitude: 0.57645
Value Function Update Magnitude: 0.66263

Collected Steps per Second: 21,945.32735
Overall Steps per Second: 10,721.66976

Timestep Collection Time: 2.27930
Timestep Consumption Time: 2.38602
PPO Batch Consumption Time: 0.27611
Total Iteration Time: 4.66532

Cumulative Model Updates: 183,428
Cumulative Timesteps: 1,529,651,894

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,144.40064
Policy Entropy: 3.67468
Value Function Loss: 0.01684

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08794
Policy Update Magnitude: 0.47505
Value Function Update Magnitude: 0.52326

Collected Steps per Second: 23,300.67691
Overall Steps per Second: 10,867.61202

Timestep Collection Time: 2.14809
Timestep Consumption Time: 2.45752
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.60561

Cumulative Model Updates: 183,434
Cumulative Timesteps: 1,529,701,946

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1529701946...
Checkpoint 1529701946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,144.40064
Policy Entropy: 3.67173
Value Function Loss: 0.01431

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13113
Policy Update Magnitude: 0.38555
Value Function Update Magnitude: 0.42357

Collected Steps per Second: 22,562.22810
Overall Steps per Second: 10,692.52867

Timestep Collection Time: 2.21733
Timestep Consumption Time: 2.46145
PPO Batch Consumption Time: 0.29101
Total Iteration Time: 4.67878

Cumulative Model Updates: 183,440
Cumulative Timesteps: 1,529,751,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,144.40064
Policy Entropy: 3.67649
Value Function Loss: 0.01467

Mean KL Divergence: 0.01083
SB3 Clip Fraction: 0.14418
Policy Update Magnitude: 0.32949
Value Function Update Magnitude: 0.35101

Collected Steps per Second: 23,372.04574
Overall Steps per Second: 10,855.34911

Timestep Collection Time: 2.13965
Timestep Consumption Time: 2.46711
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.60676

Cumulative Model Updates: 183,446
Cumulative Timesteps: 1,529,801,982

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1529801982...
Checkpoint 1529801982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,144.40064
Policy Entropy: 3.66981
Value Function Loss: 0.01408

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.29984
Value Function Update Magnitude: 0.28864

Collected Steps per Second: 22,476.82964
Overall Steps per Second: 10,637.08806

Timestep Collection Time: 2.22594
Timestep Consumption Time: 2.47761
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.70354

Cumulative Model Updates: 183,452
Cumulative Timesteps: 1,529,852,014

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,144.40064
Policy Entropy: 3.66380
Value Function Loss: 0.01520

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14369
Policy Update Magnitude: 0.30491
Value Function Update Magnitude: 0.39861

Collected Steps per Second: 23,128.44287
Overall Steps per Second: 10,918.01279

Timestep Collection Time: 2.16219
Timestep Consumption Time: 2.41813
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.58032

Cumulative Model Updates: 183,458
Cumulative Timesteps: 1,529,902,022

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1529902022...
Checkpoint 1529902022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.65625
Value Function Loss: 0.01822

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.17363
Policy Update Magnitude: 0.33141
Value Function Update Magnitude: 0.48636

Collected Steps per Second: 23,048.64571
Overall Steps per Second: 10,782.98733

Timestep Collection Time: 2.16950
Timestep Consumption Time: 2.46781
PPO Batch Consumption Time: 0.28936
Total Iteration Time: 4.63730

Cumulative Model Updates: 183,464
Cumulative Timesteps: 1,529,952,026

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.64624
Value Function Loss: 0.02350

Mean KL Divergence: 0.01879
SB3 Clip Fraction: 0.21304
Policy Update Magnitude: 0.36771
Value Function Update Magnitude: 0.47450

Collected Steps per Second: 23,192.16374
Overall Steps per Second: 10,762.81378

Timestep Collection Time: 2.15659
Timestep Consumption Time: 2.49052
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.64711

Cumulative Model Updates: 183,470
Cumulative Timesteps: 1,530,002,042

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1530002042...
Checkpoint 1530002042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.66543
Value Function Loss: 0.02148

Mean KL Divergence: 0.03527
SB3 Clip Fraction: 0.32322
Policy Update Magnitude: 0.32949
Value Function Update Magnitude: 0.41850

Collected Steps per Second: 22,818.31208
Overall Steps per Second: 10,626.47628

Timestep Collection Time: 2.19131
Timestep Consumption Time: 2.51411
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.70542

Cumulative Model Updates: 183,476
Cumulative Timesteps: 1,530,052,044

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.65902
Value Function Loss: 0.02710

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.19859
Policy Update Magnitude: 0.37648
Value Function Update Magnitude: 0.42880

Collected Steps per Second: 23,127.20271
Overall Steps per Second: 10,922.83402

Timestep Collection Time: 2.16248
Timestep Consumption Time: 2.41619
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.57867

Cumulative Model Updates: 183,482
Cumulative Timesteps: 1,530,102,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1530102056...
Checkpoint 1530102056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.68683
Value Function Loss: 0.02678

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13167
Policy Update Magnitude: 0.55634
Value Function Update Magnitude: 0.50606

Collected Steps per Second: 22,727.34088
Overall Steps per Second: 10,645.14313

Timestep Collection Time: 2.20087
Timestep Consumption Time: 2.49798
PPO Batch Consumption Time: 0.29243
Total Iteration Time: 4.69886

Cumulative Model Updates: 183,488
Cumulative Timesteps: 1,530,152,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.66923
Value Function Loss: 0.02640

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.12966
Policy Update Magnitude: 0.57754
Value Function Update Magnitude: 0.50111

Collected Steps per Second: 23,263.84564
Overall Steps per Second: 10,961.73790

Timestep Collection Time: 2.15020
Timestep Consumption Time: 2.41312
PPO Batch Consumption Time: 0.27617
Total Iteration Time: 4.56333

Cumulative Model Updates: 183,494
Cumulative Timesteps: 1,530,202,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1530202098...
Checkpoint 1530202098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.69721
Value Function Loss: 0.01985

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.47375
Value Function Update Magnitude: 0.37501

Collected Steps per Second: 22,764.27160
Overall Steps per Second: 10,685.96755

Timestep Collection Time: 2.19730
Timestep Consumption Time: 2.48360
PPO Batch Consumption Time: 0.29039
Total Iteration Time: 4.68091

Cumulative Model Updates: 183,500
Cumulative Timesteps: 1,530,252,118

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.70711
Value Function Loss: 0.01547

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13653
Policy Update Magnitude: 0.34030
Value Function Update Magnitude: 0.26490

Collected Steps per Second: 22,740.65523
Overall Steps per Second: 10,813.16748

Timestep Collection Time: 2.20046
Timestep Consumption Time: 2.42723
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.62769

Cumulative Model Updates: 183,506
Cumulative Timesteps: 1,530,302,158

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1530302158...
Checkpoint 1530302158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.71389
Value Function Loss: 0.01470

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14718
Policy Update Magnitude: 0.26351
Value Function Update Magnitude: 0.20016

Collected Steps per Second: 22,009.39596
Overall Steps per Second: 10,679.63025

Timestep Collection Time: 2.27185
Timestep Consumption Time: 2.41015
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.68200

Cumulative Model Updates: 183,512
Cumulative Timesteps: 1,530,352,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.72453
Value Function Loss: 0.01312

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13829
Policy Update Magnitude: 0.24174
Value Function Update Magnitude: 0.16566

Collected Steps per Second: 22,153.62694
Overall Steps per Second: 10,594.29717

Timestep Collection Time: 2.25814
Timestep Consumption Time: 2.46383
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.72197

Cumulative Model Updates: 183,518
Cumulative Timesteps: 1,530,402,186

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1530402186...
Checkpoint 1530402186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.69864
Value Function Loss: 0.01456

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15870
Policy Update Magnitude: 0.24140
Value Function Update Magnitude: 0.17432

Collected Steps per Second: 22,883.18315
Overall Steps per Second: 10,961.78014

Timestep Collection Time: 2.18527
Timestep Consumption Time: 2.37658
PPO Batch Consumption Time: 0.27587
Total Iteration Time: 4.56185

Cumulative Model Updates: 183,524
Cumulative Timesteps: 1,530,452,192

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.70144
Value Function Loss: 0.01525

Mean KL Divergence: 0.02032
SB3 Clip Fraction: 0.24029
Policy Update Magnitude: 0.26644
Value Function Update Magnitude: 0.21549

Collected Steps per Second: 22,774.02550
Overall Steps per Second: 10,917.44622

Timestep Collection Time: 2.19583
Timestep Consumption Time: 2.38472
PPO Batch Consumption Time: 0.27531
Total Iteration Time: 4.58056

Cumulative Model Updates: 183,530
Cumulative Timesteps: 1,530,502,200

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1530502200...
Checkpoint 1530502200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,205.68927
Policy Entropy: 3.65064
Value Function Loss: 0.03872

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.21169
Policy Update Magnitude: 0.31125
Value Function Update Magnitude: 0.37850

Collected Steps per Second: 22,185.49387
Overall Steps per Second: 10,562.66624

Timestep Collection Time: 2.25391
Timestep Consumption Time: 2.48013
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.73403

Cumulative Model Updates: 183,536
Cumulative Timesteps: 1,530,552,204

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 189,236.23481
Policy Entropy: 3.64835
Value Function Loss: 0.06048

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.20076
Policy Update Magnitude: 0.42763
Value Function Update Magnitude: 0.42214

Collected Steps per Second: 22,886.69466
Overall Steps per Second: 10,857.31446

Timestep Collection Time: 2.18502
Timestep Consumption Time: 2.42090
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.60593

Cumulative Model Updates: 183,542
Cumulative Timesteps: 1,530,602,212

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1530602212...
Checkpoint 1530602212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,855.93178
Policy Entropy: 3.63646
Value Function Loss: 0.08312

Mean KL Divergence: 0.01751
SB3 Clip Fraction: 0.19597
Policy Update Magnitude: 0.47904
Value Function Update Magnitude: 0.44800

Collected Steps per Second: 22,503.64778
Overall Steps per Second: 10,644.64288

Timestep Collection Time: 2.22293
Timestep Consumption Time: 2.47652
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.69945

Cumulative Model Updates: 183,548
Cumulative Timesteps: 1,530,652,236

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 280,910.65668
Policy Entropy: 3.66336
Value Function Loss: 0.08182

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.18872
Policy Update Magnitude: 0.47748
Value Function Update Magnitude: 0.43942

Collected Steps per Second: 23,009.57391
Overall Steps per Second: 10,873.67967

Timestep Collection Time: 2.17466
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.60175

Cumulative Model Updates: 183,554
Cumulative Timesteps: 1,530,702,274

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1530702274...
Checkpoint 1530702274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,088.85561
Policy Entropy: 3.65762
Value Function Loss: 0.07718

Mean KL Divergence: 0.01693
SB3 Clip Fraction: 0.19848
Policy Update Magnitude: 0.45416
Value Function Update Magnitude: 0.36710

Collected Steps per Second: 22,360.53767
Overall Steps per Second: 10,758.94565

Timestep Collection Time: 2.23859
Timestep Consumption Time: 2.41391
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.65250

Cumulative Model Updates: 183,560
Cumulative Timesteps: 1,530,752,330

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,760.70050
Policy Entropy: 3.65090
Value Function Loss: 0.06756

Mean KL Divergence: 0.01624
SB3 Clip Fraction: 0.19633
Policy Update Magnitude: 0.41323
Value Function Update Magnitude: 0.34196

Collected Steps per Second: 23,039.04538
Overall Steps per Second: 10,847.58948

Timestep Collection Time: 2.17110
Timestep Consumption Time: 2.44007
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.61116

Cumulative Model Updates: 183,566
Cumulative Timesteps: 1,530,802,350

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1530802350...
Checkpoint 1530802350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 345,551.00291
Policy Entropy: 3.63731
Value Function Loss: 0.06587

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.19124
Policy Update Magnitude: 0.38989
Value Function Update Magnitude: 0.32324

Collected Steps per Second: 22,533.56803
Overall Steps per Second: 10,688.99464

Timestep Collection Time: 2.21891
Timestep Consumption Time: 2.45880
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.67771

Cumulative Model Updates: 183,572
Cumulative Timesteps: 1,530,852,350

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,878.01992
Policy Entropy: 3.63157
Value Function Loss: 0.07192

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.18605
Policy Update Magnitude: 0.39310
Value Function Update Magnitude: 0.29436

Collected Steps per Second: 22,955.19640
Overall Steps per Second: 10,860.94914

Timestep Collection Time: 2.17964
Timestep Consumption Time: 2.42714
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.60678

Cumulative Model Updates: 183,578
Cumulative Timesteps: 1,530,902,384

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1530902384...
Checkpoint 1530902384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,013.11331
Policy Entropy: 3.63840
Value Function Loss: 0.08702

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.18118
Policy Update Magnitude: 0.42502
Value Function Update Magnitude: 0.34444

Collected Steps per Second: 22,407.98295
Overall Steps per Second: 10,691.71656

Timestep Collection Time: 2.23144
Timestep Consumption Time: 2.44527
PPO Batch Consumption Time: 0.28147
Total Iteration Time: 4.67670

Cumulative Model Updates: 183,584
Cumulative Timesteps: 1,530,952,386

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,480.03656
Policy Entropy: 3.67105
Value Function Loss: 0.08702

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.17375
Policy Update Magnitude: 0.45601
Value Function Update Magnitude: 0.33989

Collected Steps per Second: 22,985.18281
Overall Steps per Second: 10,862.50246

Timestep Collection Time: 2.17575
Timestep Consumption Time: 2.42816
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.60391

Cumulative Model Updates: 183,590
Cumulative Timesteps: 1,531,002,396

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1531002396...
Checkpoint 1531002396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265,492.64539
Policy Entropy: 3.68485
Value Function Loss: 0.09582

Mean KL Divergence: 0.01531
SB3 Clip Fraction: 0.17805
Policy Update Magnitude: 0.49778
Value Function Update Magnitude: 0.40537

Collected Steps per Second: 22,371.61176
Overall Steps per Second: 10,677.26166

Timestep Collection Time: 2.23614
Timestep Consumption Time: 2.44915
PPO Batch Consumption Time: 0.28324
Total Iteration Time: 4.68528

Cumulative Model Updates: 183,596
Cumulative Timesteps: 1,531,052,422

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 147,411.42572
Policy Entropy: 3.68211
Value Function Loss: 0.07081

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.18226
Policy Update Magnitude: 0.50922
Value Function Update Magnitude: 0.44112

Collected Steps per Second: 22,935.83661
Overall Steps per Second: 10,849.83333

Timestep Collection Time: 2.18069
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.60984

Cumulative Model Updates: 183,602
Cumulative Timesteps: 1,531,102,438

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1531102438...
Checkpoint 1531102438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,146.17208
Policy Entropy: 3.66640
Value Function Loss: 0.06292

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.18730
Policy Update Magnitude: 0.51852
Value Function Update Magnitude: 0.58472

Collected Steps per Second: 22,469.74410
Overall Steps per Second: 10,712.04233

Timestep Collection Time: 2.22539
Timestep Consumption Time: 2.44262
PPO Batch Consumption Time: 0.28215
Total Iteration Time: 4.66802

Cumulative Model Updates: 183,608
Cumulative Timesteps: 1,531,152,442

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328,292.80820
Policy Entropy: 3.65224
Value Function Loss: 0.06597

Mean KL Divergence: 0.01429
SB3 Clip Fraction: 0.18488
Policy Update Magnitude: 0.48089
Value Function Update Magnitude: 0.42784

Collected Steps per Second: 22,908.65628
Overall Steps per Second: 10,827.80878

Timestep Collection Time: 2.18284
Timestep Consumption Time: 2.43545
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.61829

Cumulative Model Updates: 183,614
Cumulative Timesteps: 1,531,202,448

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1531202448...
Checkpoint 1531202448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,735.09826
Policy Entropy: 3.63619
Value Function Loss: 0.07173

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.17598
Policy Update Magnitude: 0.47392
Value Function Update Magnitude: 0.37657

Collected Steps per Second: 22,070.83890
Overall Steps per Second: 10,664.01803

Timestep Collection Time: 2.26652
Timestep Consumption Time: 2.42439
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.69091

Cumulative Model Updates: 183,620
Cumulative Timesteps: 1,531,252,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 425,938.06597
Policy Entropy: 3.61945
Value Function Loss: 0.08216

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.16605
Policy Update Magnitude: 0.49316
Value Function Update Magnitude: 0.35669

Collected Steps per Second: 22,637.72285
Overall Steps per Second: 10,642.80590

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.49030
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.69989

Cumulative Model Updates: 183,626
Cumulative Timesteps: 1,531,302,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1531302492...
Checkpoint 1531302492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,756.01092
Policy Entropy: 3.63807
Value Function Loss: 0.08460

Mean KL Divergence: 0.01368
SB3 Clip Fraction: 0.15823
Policy Update Magnitude: 0.53448
Value Function Update Magnitude: 0.54962

Collected Steps per Second: 21,877.61546
Overall Steps per Second: 10,519.45400

Timestep Collection Time: 2.28581
Timestep Consumption Time: 2.46805
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.75386

Cumulative Model Updates: 183,632
Cumulative Timesteps: 1,531,352,500

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,180.03351
Policy Entropy: 3.65459
Value Function Loss: 0.09486

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.15765
Policy Update Magnitude: 0.57492
Value Function Update Magnitude: 0.52416

Collected Steps per Second: 22,748.78792
Overall Steps per Second: 10,801.06417

Timestep Collection Time: 2.19897
Timestep Consumption Time: 2.43242
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.63140

Cumulative Model Updates: 183,638
Cumulative Timesteps: 1,531,402,524

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1531402524...
Checkpoint 1531402524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240,983.42796
Policy Entropy: 3.67623
Value Function Loss: 0.10564

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.16187
Policy Update Magnitude: 0.59430
Value Function Update Magnitude: 0.44714

Collected Steps per Second: 22,349.01164
Overall Steps per Second: 10,726.91451

Timestep Collection Time: 2.23724
Timestep Consumption Time: 2.42394
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.66117

Cumulative Model Updates: 183,644
Cumulative Timesteps: 1,531,452,524

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,656.95393
Policy Entropy: 3.71775
Value Function Loss: 0.09473

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.15462
Policy Update Magnitude: 0.59214
Value Function Update Magnitude: 0.39801

Collected Steps per Second: 22,926.37955
Overall Steps per Second: 10,870.69437

Timestep Collection Time: 2.18177
Timestep Consumption Time: 2.41960
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.60136

Cumulative Model Updates: 183,650
Cumulative Timesteps: 1,531,502,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1531502544...
Checkpoint 1531502544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 864.22117
Policy Entropy: 3.73649
Value Function Loss: 0.09508

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14530
Policy Update Magnitude: 0.59671
Value Function Update Magnitude: 0.44417

Collected Steps per Second: 22,545.18130
Overall Steps per Second: 10,684.82494

Timestep Collection Time: 2.21848
Timestep Consumption Time: 2.46255
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.68103

Cumulative Model Updates: 183,656
Cumulative Timesteps: 1,531,552,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,460.02180
Policy Entropy: 3.76432
Value Function Loss: 0.08577

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.58354
Value Function Update Magnitude: 0.46460

Collected Steps per Second: 22,983.86906
Overall Steps per Second: 10,843.86585

Timestep Collection Time: 2.17605
Timestep Consumption Time: 2.43614
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.61219

Cumulative Model Updates: 183,662
Cumulative Timesteps: 1,531,602,574

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1531602574...
Checkpoint 1531602574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,495.73495
Policy Entropy: 3.73860
Value Function Loss: 0.08677

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13193
Policy Update Magnitude: 0.60370
Value Function Update Magnitude: 0.56998

Collected Steps per Second: 22,552.94262
Overall Steps per Second: 10,687.79108

Timestep Collection Time: 2.21834
Timestep Consumption Time: 2.46271
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.68104

Cumulative Model Updates: 183,668
Cumulative Timesteps: 1,531,652,604

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,581.36614
Policy Entropy: 3.71923
Value Function Loss: 0.08619

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.13944
Policy Update Magnitude: 0.58159
Value Function Update Magnitude: 0.53265

Collected Steps per Second: 22,700.54844
Overall Steps per Second: 10,672.45126

Timestep Collection Time: 2.20365
Timestep Consumption Time: 2.48356
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.68721

Cumulative Model Updates: 183,674
Cumulative Timesteps: 1,531,702,628

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1531702628...
Checkpoint 1531702628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,182.21492
Policy Entropy: 3.70662
Value Function Loss: 0.09249

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.14490
Policy Update Magnitude: 0.56025
Value Function Update Magnitude: 0.46115

Collected Steps per Second: 22,750.16808
Overall Steps per Second: 10,848.74792

Timestep Collection Time: 2.19963
Timestep Consumption Time: 2.41307
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.61270

Cumulative Model Updates: 183,680
Cumulative Timesteps: 1,531,752,670

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,891.02335
Policy Entropy: 3.73748
Value Function Loss: 0.08903

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.14552
Policy Update Magnitude: 0.55899
Value Function Update Magnitude: 0.35723

Collected Steps per Second: 22,618.46731
Overall Steps per Second: 10,611.37598

Timestep Collection Time: 2.21085
Timestep Consumption Time: 2.50164
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.71249

Cumulative Model Updates: 183,686
Cumulative Timesteps: 1,531,802,676

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1531802676...
Checkpoint 1531802676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,935.69822
Policy Entropy: 3.77839
Value Function Loss: 0.08633

Mean KL Divergence: 0.01111
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.56793
Value Function Update Magnitude: 0.38079

Collected Steps per Second: 22,475.14804
Overall Steps per Second: 10,607.59560

Timestep Collection Time: 2.22504
Timestep Consumption Time: 2.48932
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.71436

Cumulative Model Updates: 183,692
Cumulative Timesteps: 1,531,852,684

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,482.49695
Policy Entropy: 3.80405
Value Function Loss: 0.08238

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.12782
Policy Update Magnitude: 0.56536
Value Function Update Magnitude: 0.37242

Collected Steps per Second: 23,115.99894
Overall Steps per Second: 10,836.85566

Timestep Collection Time: 2.16352
Timestep Consumption Time: 2.45147
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.61499

Cumulative Model Updates: 183,698
Cumulative Timesteps: 1,531,902,696

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1531902696...
Checkpoint 1531902696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,566.08831
Policy Entropy: 3.80726
Value Function Loss: 0.07579

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.57701
Value Function Update Magnitude: 0.39907

Collected Steps per Second: 22,114.84665
Overall Steps per Second: 10,706.01045

Timestep Collection Time: 2.26102
Timestep Consumption Time: 2.40945
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.67046

Cumulative Model Updates: 183,704
Cumulative Timesteps: 1,531,952,698

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,306.21187
Policy Entropy: 3.81325
Value Function Loss: 0.07174

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.13293
Policy Update Magnitude: 0.56150
Value Function Update Magnitude: 0.44164

Collected Steps per Second: 22,886.62606
Overall Steps per Second: 10,802.52031

Timestep Collection Time: 2.18468
Timestep Consumption Time: 2.44387
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.62855

Cumulative Model Updates: 183,710
Cumulative Timesteps: 1,532,002,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1532002698...
Checkpoint 1532002698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,055.62191
Policy Entropy: 3.81526
Value Function Loss: 0.06455

Mean KL Divergence: 0.01099
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.55887
Value Function Update Magnitude: 0.54532

Collected Steps per Second: 22,308.29666
Overall Steps per Second: 10,685.76623

Timestep Collection Time: 2.24168
Timestep Consumption Time: 2.43819
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.67987

Cumulative Model Updates: 183,716
Cumulative Timesteps: 1,532,052,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,427.79614
Policy Entropy: 3.80977
Value Function Loss: 0.06944

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.55402
Value Function Update Magnitude: 0.54715

Collected Steps per Second: 22,599.33765
Overall Steps per Second: 10,650.15645

Timestep Collection Time: 2.21352
Timestep Consumption Time: 2.48350
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.69702

Cumulative Model Updates: 183,722
Cumulative Timesteps: 1,532,102,730

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1532102730...
Checkpoint 1532102730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,021.73537
Policy Entropy: 3.78966
Value Function Loss: 0.07038

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.58509
Value Function Update Magnitude: 0.47124

Collected Steps per Second: 22,670.36796
Overall Steps per Second: 10,835.14710

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.41044
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.61720

Cumulative Model Updates: 183,728
Cumulative Timesteps: 1,532,152,758

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,414.21994
Policy Entropy: 3.79086
Value Function Loss: 0.07295

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12061
Policy Update Magnitude: 0.58779
Value Function Update Magnitude: 0.41493

Collected Steps per Second: 22,918.40598
Overall Steps per Second: 10,908.23420

Timestep Collection Time: 2.18165
Timestep Consumption Time: 2.40204
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.58369

Cumulative Model Updates: 183,734
Cumulative Timesteps: 1,532,202,758

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1532202758...
Checkpoint 1532202758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,835.00931
Policy Entropy: 3.76928
Value Function Loss: 0.07464

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.61280
Value Function Update Magnitude: 0.41432

Collected Steps per Second: 21,850.63165
Overall Steps per Second: 10,668.10518

Timestep Collection Time: 2.28835
Timestep Consumption Time: 2.39870
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.68706

Cumulative Model Updates: 183,740
Cumulative Timesteps: 1,532,252,760

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,135.76475
Policy Entropy: 3.75517
Value Function Loss: 0.07356

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.15157
Policy Update Magnitude: 0.68282
Value Function Update Magnitude: 0.38286

Collected Steps per Second: 22,906.96314
Overall Steps per Second: 10,864.55421

Timestep Collection Time: 2.18353
Timestep Consumption Time: 2.42025
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.60378

Cumulative Model Updates: 183,746
Cumulative Timesteps: 1,532,302,778

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1532302778...
Checkpoint 1532302778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,549.83889
Policy Entropy: 3.74351
Value Function Loss: 0.07595

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.13451
Policy Update Magnitude: 0.61220
Value Function Update Magnitude: 0.38652

Collected Steps per Second: 22,359.28891
Overall Steps per Second: 10,756.96259

Timestep Collection Time: 2.23737
Timestep Consumption Time: 2.41320
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.65057

Cumulative Model Updates: 183,752
Cumulative Timesteps: 1,532,352,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,082.59666
Policy Entropy: 3.78893
Value Function Loss: 0.07383

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.16840
Policy Update Magnitude: 0.66645
Value Function Update Magnitude: 0.38579

Collected Steps per Second: 23,108.94403
Overall Steps per Second: 10,862.95363

Timestep Collection Time: 2.16418
Timestep Consumption Time: 2.43972
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.60390

Cumulative Model Updates: 183,758
Cumulative Timesteps: 1,532,402,816

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1532402816...
Checkpoint 1532402816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,312.90486
Policy Entropy: 3.81885
Value Function Loss: 0.07527

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.15302
Policy Update Magnitude: 0.63503
Value Function Update Magnitude: 0.37323

Collected Steps per Second: 22,444.92532
Overall Steps per Second: 10,688.17865

Timestep Collection Time: 2.22839
Timestep Consumption Time: 2.45117
PPO Batch Consumption Time: 0.28948
Total Iteration Time: 4.67956

Cumulative Model Updates: 183,764
Cumulative Timesteps: 1,532,452,832

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,848.00555
Policy Entropy: 3.84628
Value Function Loss: 0.06899

Mean KL Divergence: 0.01417
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.68539
Value Function Update Magnitude: 0.36715

Collected Steps per Second: 22,938.19454
Overall Steps per Second: 10,881.92659

Timestep Collection Time: 2.17986
Timestep Consumption Time: 2.41510
PPO Batch Consumption Time: 0.28167
Total Iteration Time: 4.59496

Cumulative Model Updates: 183,770
Cumulative Timesteps: 1,532,502,834

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1532502834...
Checkpoint 1532502834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,443.59930
Policy Entropy: 3.83886
Value Function Loss: 0.06899

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12089
Policy Update Magnitude: 0.75398
Value Function Update Magnitude: 0.41669

Collected Steps per Second: 22,590.36349
Overall Steps per Second: 10,693.07274

Timestep Collection Time: 2.21351
Timestep Consumption Time: 2.46279
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.67630

Cumulative Model Updates: 183,776
Cumulative Timesteps: 1,532,552,838

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,086.06290
Policy Entropy: 3.87479
Value Function Loss: 0.06488

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10741
Policy Update Magnitude: 0.83954
Value Function Update Magnitude: 0.59107

Collected Steps per Second: 23,213.89551
Overall Steps per Second: 10,792.83139

Timestep Collection Time: 2.15457
Timestep Consumption Time: 2.47962
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.63419

Cumulative Model Updates: 183,782
Cumulative Timesteps: 1,532,602,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1532602854...
Checkpoint 1532602854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,658.23833
Policy Entropy: 3.90040
Value Function Loss: 0.06080

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.09473
Policy Update Magnitude: 0.91259
Value Function Update Magnitude: 0.62874

Collected Steps per Second: 22,293.07498
Overall Steps per Second: 10,641.73180

Timestep Collection Time: 2.24312
Timestep Consumption Time: 2.45593
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.69905

Cumulative Model Updates: 183,788
Cumulative Timesteps: 1,532,652,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 256.02339
Policy Entropy: 3.90014
Value Function Loss: 0.05243

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07073
Policy Update Magnitude: 0.87409
Value Function Update Magnitude: 0.64461

Collected Steps per Second: 22,798.27904
Overall Steps per Second: 10,885.83552

Timestep Collection Time: 2.19350
Timestep Consumption Time: 2.40036
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.59386

Cumulative Model Updates: 183,794
Cumulative Timesteps: 1,532,702,868

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1532702868...
Checkpoint 1532702868 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86.15010
Policy Entropy: 3.85418
Value Function Loss: 0.04733

Mean KL Divergence: 0.00654
SB3 Clip Fraction: 0.08264
Policy Update Magnitude: 0.78016
Value Function Update Magnitude: 0.61121

Collected Steps per Second: 22,612.69843
Overall Steps per Second: 10,663.44275

Timestep Collection Time: 2.21194
Timestep Consumption Time: 2.47866
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.69061

Cumulative Model Updates: 183,800
Cumulative Timesteps: 1,532,752,886

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,016.11296
Policy Entropy: 3.82366
Value Function Loss: 0.03943

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08689
Policy Update Magnitude: 0.65362
Value Function Update Magnitude: 0.61321

Collected Steps per Second: 22,956.07802
Overall Steps per Second: 10,898.73402

Timestep Collection Time: 2.17921
Timestep Consumption Time: 2.41087
PPO Batch Consumption Time: 0.27927
Total Iteration Time: 4.59007

Cumulative Model Updates: 183,806
Cumulative Timesteps: 1,532,802,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1532802912...
Checkpoint 1532802912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.96441
Policy Entropy: 3.80174
Value Function Loss: 0.03301

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11422
Policy Update Magnitude: 0.54614
Value Function Update Magnitude: 0.60326

Collected Steps per Second: 22,596.15369
Overall Steps per Second: 10,650.14149

Timestep Collection Time: 2.21383
Timestep Consumption Time: 2.48320
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.69703

Cumulative Model Updates: 183,812
Cumulative Timesteps: 1,532,852,936

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,120.96441
Policy Entropy: 3.76599
Value Function Loss: 0.03205

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.49704
Value Function Update Magnitude: 0.52220

Collected Steps per Second: 22,849.65504
Overall Steps per Second: 10,847.53987

Timestep Collection Time: 2.18839
Timestep Consumption Time: 2.42132
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.60971

Cumulative Model Updates: 183,818
Cumulative Timesteps: 1,532,902,940

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1532902940...
Checkpoint 1532902940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,395.11359
Policy Entropy: 3.76095
Value Function Loss: 0.02929

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10384
Policy Update Magnitude: 0.52227
Value Function Update Magnitude: 0.56151

Collected Steps per Second: 22,547.20712
Overall Steps per Second: 10,690.35978

Timestep Collection Time: 2.21908
Timestep Consumption Time: 2.46121
PPO Batch Consumption Time: 0.28327
Total Iteration Time: 4.68029

Cumulative Model Updates: 183,824
Cumulative Timesteps: 1,532,952,974

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 859.52259
Policy Entropy: 3.73417
Value Function Loss: 0.02740

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.47703
Value Function Update Magnitude: 0.54929

Collected Steps per Second: 22,896.91510
Overall Steps per Second: 10,854.48373

Timestep Collection Time: 2.18519
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.60952

Cumulative Model Updates: 183,830
Cumulative Timesteps: 1,533,003,008

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1533003008...
Checkpoint 1533003008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303.84413
Policy Entropy: 3.75203
Value Function Loss: 0.02427

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.17051
Policy Update Magnitude: 0.36515
Value Function Update Magnitude: 0.47909

Collected Steps per Second: 22,658.98218
Overall Steps per Second: 10,708.00462

Timestep Collection Time: 2.20751
Timestep Consumption Time: 2.46376
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.67127

Cumulative Model Updates: 183,836
Cumulative Timesteps: 1,533,053,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 303.84413
Policy Entropy: 3.75461
Value Function Loss: 0.02067

Mean KL Divergence: 0.02027
SB3 Clip Fraction: 0.22715
Policy Update Magnitude: 0.30686
Value Function Update Magnitude: 0.51392

Collected Steps per Second: 22,839.53850
Overall Steps per Second: 10,671.67716

Timestep Collection Time: 2.19024
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.68755

Cumulative Model Updates: 183,842
Cumulative Timesteps: 1,533,103,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1533103052...
Checkpoint 1533103052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,125.57899
Policy Entropy: 3.79206
Value Function Loss: 0.02475

Mean KL Divergence: 0.02319
SB3 Clip Fraction: 0.23488
Policy Update Magnitude: 0.30260
Value Function Update Magnitude: 0.52745

Collected Steps per Second: 22,735.88687
Overall Steps per Second: 10,828.64037

Timestep Collection Time: 2.20013
Timestep Consumption Time: 2.41928
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.61942

Cumulative Model Updates: 183,848
Cumulative Timesteps: 1,533,153,074

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,971.40272
Policy Entropy: 3.77785
Value Function Loss: 0.03138

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.17158
Policy Update Magnitude: 0.37159
Value Function Update Magnitude: 0.57700

Collected Steps per Second: 22,194.37425
Overall Steps per Second: 10,756.08246

Timestep Collection Time: 2.25390
Timestep Consumption Time: 2.39686
PPO Batch Consumption Time: 0.28582
Total Iteration Time: 4.65076

Cumulative Model Updates: 183,854
Cumulative Timesteps: 1,533,203,098

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1533203098...
Checkpoint 1533203098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,409.03380
Policy Entropy: 3.80451
Value Function Loss: 0.03716

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.17774
Policy Update Magnitude: 0.43285
Value Function Update Magnitude: 0.75305

Collected Steps per Second: 21,957.41772
Overall Steps per Second: 10,815.69413

Timestep Collection Time: 2.27713
Timestep Consumption Time: 2.34578
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.62291

Cumulative Model Updates: 183,860
Cumulative Timesteps: 1,533,253,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,212.84285
Policy Entropy: 3.81156
Value Function Loss: 0.03787

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.48206
Value Function Update Magnitude: 0.85491

Collected Steps per Second: 22,034.42171
Overall Steps per Second: 10,741.98239

Timestep Collection Time: 2.26936
Timestep Consumption Time: 2.38565
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.65501

Cumulative Model Updates: 183,866
Cumulative Timesteps: 1,533,303,102

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1533303102...
Checkpoint 1533303102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.86709
Policy Entropy: 3.81228
Value Function Loss: 0.03606

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14225
Policy Update Magnitude: 0.48416
Value Function Update Magnitude: 0.80499

Collected Steps per Second: 22,008.51234
Overall Steps per Second: 10,842.44868

Timestep Collection Time: 2.27303
Timestep Consumption Time: 2.34087
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.61390

Cumulative Model Updates: 183,872
Cumulative Timesteps: 1,533,353,128

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221.86709
Policy Entropy: 3.75788
Value Function Loss: 0.03500

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12741
Policy Update Magnitude: 0.45309
Value Function Update Magnitude: 0.56584

Collected Steps per Second: 22,643.39986
Overall Steps per Second: 10,896.09002

Timestep Collection Time: 2.20894
Timestep Consumption Time: 2.38151
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.59045

Cumulative Model Updates: 183,878
Cumulative Timesteps: 1,533,403,146

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1533403146...
Checkpoint 1533403146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221.86709
Policy Entropy: 3.71422
Value Function Loss: 0.02413

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14965
Policy Update Magnitude: 0.38453
Value Function Update Magnitude: 0.43681

Collected Steps per Second: 22,122.59195
Overall Steps per Second: 10,655.97997

Timestep Collection Time: 2.26022
Timestep Consumption Time: 2.43217
PPO Batch Consumption Time: 0.28172
Total Iteration Time: 4.69239

Cumulative Model Updates: 183,884
Cumulative Timesteps: 1,533,453,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,894.78986
Policy Entropy: 3.69000
Value Function Loss: 0.02448

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12510
Policy Update Magnitude: 0.36216
Value Function Update Magnitude: 0.36123

Collected Steps per Second: 22,811.74524
Overall Steps per Second: 10,883.62724

Timestep Collection Time: 2.19334
Timestep Consumption Time: 2.40384
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.59718

Cumulative Model Updates: 183,890
Cumulative Timesteps: 1,533,503,182

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1533503182...
Checkpoint 1533503182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,188.55802
Policy Entropy: 3.69194
Value Function Loss: 0.02381

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.10655
Policy Update Magnitude: 0.46962
Value Function Update Magnitude: 0.37969

Collected Steps per Second: 22,788.89937
Overall Steps per Second: 10,667.95815

Timestep Collection Time: 2.19607
Timestep Consumption Time: 2.49518
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.69124

Cumulative Model Updates: 183,896
Cumulative Timesteps: 1,533,553,228

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,829.12224
Policy Entropy: 3.70568
Value Function Loss: 0.02307

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08412
Policy Update Magnitude: 0.52528
Value Function Update Magnitude: 0.54453

Collected Steps per Second: 22,598.83228
Overall Steps per Second: 10,628.86058

Timestep Collection Time: 2.21330
Timestep Consumption Time: 2.49257
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.70587

Cumulative Model Updates: 183,902
Cumulative Timesteps: 1,533,603,246

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1533603246...
Checkpoint 1533603246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,187.88402
Policy Entropy: 3.70334
Value Function Loss: 0.02231

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07854
Policy Update Magnitude: 0.51942
Value Function Update Magnitude: 0.55676

Collected Steps per Second: 22,921.99809
Overall Steps per Second: 10,850.33298

Timestep Collection Time: 2.18262
Timestep Consumption Time: 2.42830
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.61092

Cumulative Model Updates: 183,908
Cumulative Timesteps: 1,533,653,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,248.13418
Policy Entropy: 3.71428
Value Function Loss: 0.02159

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14705
Policy Update Magnitude: 0.43675
Value Function Update Magnitude: 0.58507

Collected Steps per Second: 22,943.58434
Overall Steps per Second: 10,739.93722

Timestep Collection Time: 2.17969
Timestep Consumption Time: 2.47676
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.65645

Cumulative Model Updates: 183,914
Cumulative Timesteps: 1,533,703,286

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1533703286...
Checkpoint 1533703286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,248.13418
Policy Entropy: 3.71056
Value Function Loss: 0.01988

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15084
Policy Update Magnitude: 0.37995
Value Function Update Magnitude: 0.62770

Collected Steps per Second: 22,501.35740
Overall Steps per Second: 10,795.95585

Timestep Collection Time: 2.22244
Timestep Consumption Time: 2.40966
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.63210

Cumulative Model Updates: 183,920
Cumulative Timesteps: 1,533,753,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,721.93436
Policy Entropy: 3.71670
Value Function Loss: 0.02205

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14299
Policy Update Magnitude: 0.34162
Value Function Update Magnitude: 0.61150

Collected Steps per Second: 22,862.51782
Overall Steps per Second: 10,706.08060

Timestep Collection Time: 2.18707
Timestep Consumption Time: 2.48336
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.67043

Cumulative Model Updates: 183,926
Cumulative Timesteps: 1,533,803,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1533803296...
Checkpoint 1533803296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,927.67963
Policy Entropy: 3.71119
Value Function Loss: 0.02518

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13490
Policy Update Magnitude: 0.40808
Value Function Update Magnitude: 0.68992

Collected Steps per Second: 22,799.17719
Overall Steps per Second: 10,851.07781

Timestep Collection Time: 2.19306
Timestep Consumption Time: 2.41478
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.60784

Cumulative Model Updates: 183,932
Cumulative Timesteps: 1,533,853,296

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,142.86491
Policy Entropy: 3.70590
Value Function Loss: 0.02835

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12257
Policy Update Magnitude: 0.49148
Value Function Update Magnitude: 0.75194

Collected Steps per Second: 22,612.09335
Overall Steps per Second: 10,642.79312

Timestep Collection Time: 2.21147
Timestep Consumption Time: 2.48711
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.69858

Cumulative Model Updates: 183,938
Cumulative Timesteps: 1,533,903,302

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1533903302...
Checkpoint 1533903302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,142.86491
Policy Entropy: 3.68164
Value Function Loss: 0.02427

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.13654
Policy Update Magnitude: 0.49364
Value Function Update Magnitude: 0.73549

Collected Steps per Second: 22,843.81591
Overall Steps per Second: 10,797.49913

Timestep Collection Time: 2.19088
Timestep Consumption Time: 2.44427
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.63515

Cumulative Model Updates: 183,944
Cumulative Timesteps: 1,533,953,350

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,142.86491
Policy Entropy: 3.68883
Value Function Loss: 0.01865

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14058
Policy Update Magnitude: 0.46132
Value Function Update Magnitude: 0.62246

Collected Steps per Second: 22,936.16481
Overall Steps per Second: 10,753.26873

Timestep Collection Time: 2.18040
Timestep Consumption Time: 2.47028
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.65068

Cumulative Model Updates: 183,950
Cumulative Timesteps: 1,534,003,360

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1534003360...
Checkpoint 1534003360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,142.86491
Policy Entropy: 3.70625
Value Function Loss: 0.01402

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.16181
Policy Update Magnitude: 0.35979
Value Function Update Magnitude: 0.52418

Collected Steps per Second: 22,122.43143
Overall Steps per Second: 10,747.18283

Timestep Collection Time: 2.26024
Timestep Consumption Time: 2.39233
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.65257

Cumulative Model Updates: 183,956
Cumulative Timesteps: 1,534,053,362

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,394.47199
Policy Entropy: 3.70323
Value Function Loss: 0.01630

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.16336
Policy Update Magnitude: 0.29711
Value Function Update Magnitude: 0.49085

Collected Steps per Second: 22,219.18707
Overall Steps per Second: 10,696.81625

Timestep Collection Time: 2.25067
Timestep Consumption Time: 2.42437
PPO Batch Consumption Time: 0.29128
Total Iteration Time: 4.67504

Cumulative Model Updates: 183,962
Cumulative Timesteps: 1,534,103,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1534103370...
Checkpoint 1534103370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,994.78088
Policy Entropy: 3.69311
Value Function Loss: 0.01800

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.11543
Policy Update Magnitude: 0.33330
Value Function Update Magnitude: 0.49391

Collected Steps per Second: 22,164.49161
Overall Steps per Second: 10,700.24383

Timestep Collection Time: 2.25730
Timestep Consumption Time: 2.41848
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.67578

Cumulative Model Updates: 183,968
Cumulative Timesteps: 1,534,153,402

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,994.78088
Policy Entropy: 3.67942
Value Function Loss: 0.01954

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.11973
Policy Update Magnitude: 0.41850
Value Function Update Magnitude: 0.53194

Collected Steps per Second: 22,695.85061
Overall Steps per Second: 10,834.67706

Timestep Collection Time: 2.20437
Timestep Consumption Time: 2.41321
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.61758

Cumulative Model Updates: 183,974
Cumulative Timesteps: 1,534,203,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1534203432...
Checkpoint 1534203432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,994.78088
Policy Entropy: 3.67154
Value Function Loss: 0.02499

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08840
Policy Update Magnitude: 0.53840
Value Function Update Magnitude: 0.65496

Collected Steps per Second: 22,853.65343
Overall Steps per Second: 10,755.70952

Timestep Collection Time: 2.18915
Timestep Consumption Time: 2.46234
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.65148

Cumulative Model Updates: 183,980
Cumulative Timesteps: 1,534,253,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,994.78088
Policy Entropy: 3.63823
Value Function Loss: 0.03079

Mean KL Divergence: 0.01628
SB3 Clip Fraction: 0.19676
Policy Update Magnitude: 0.57977
Value Function Update Magnitude: 0.63140

Collected Steps per Second: 22,913.87972
Overall Steps per Second: 10,866.33358

Timestep Collection Time: 2.18235
Timestep Consumption Time: 2.41957
PPO Batch Consumption Time: 0.27572
Total Iteration Time: 4.60192

Cumulative Model Updates: 183,986
Cumulative Timesteps: 1,534,303,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1534303468...
Checkpoint 1534303468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,994.78088
Policy Entropy: 3.63281
Value Function Loss: 0.04210

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.17519
Policy Update Magnitude: 0.50847
Value Function Update Magnitude: 0.56438

Collected Steps per Second: 22,694.37350
Overall Steps per Second: 10,679.96161

Timestep Collection Time: 2.20363
Timestep Consumption Time: 2.47897
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.68260

Cumulative Model Updates: 183,992
Cumulative Timesteps: 1,534,353,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,994.78088
Policy Entropy: 3.65763
Value Function Loss: 0.03808

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.13702
Policy Update Magnitude: 0.52189
Value Function Update Magnitude: 0.50671

Collected Steps per Second: 23,036.25181
Overall Steps per Second: 10,806.25753

Timestep Collection Time: 2.17275
Timestep Consumption Time: 2.45901
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.63176

Cumulative Model Updates: 183,998
Cumulative Timesteps: 1,534,403,530

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1534403530...
Checkpoint 1534403530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,994.78088
Policy Entropy: 3.66715
Value Function Loss: 0.03396

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.50562
Value Function Update Magnitude: 0.46588

Collected Steps per Second: 22,766.97660
Overall Steps per Second: 10,633.73872

Timestep Collection Time: 2.19660
Timestep Consumption Time: 2.50635
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.70296

Cumulative Model Updates: 184,004
Cumulative Timesteps: 1,534,453,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,994.78088
Policy Entropy: 3.68984
Value Function Loss: 0.02379

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.43081
Value Function Update Magnitude: 0.45142

Collected Steps per Second: 22,621.20946
Overall Steps per Second: 10,831.28053

Timestep Collection Time: 2.21058
Timestep Consumption Time: 2.40623
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.61681

Cumulative Model Updates: 184,010
Cumulative Timesteps: 1,534,503,546

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1534503546...
Checkpoint 1534503546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,994.78088
Policy Entropy: 3.67244
Value Function Loss: 0.02596

Mean KL Divergence: 0.00682
SB3 Clip Fraction: 0.09010
Policy Update Magnitude: 0.43365
Value Function Update Magnitude: 0.36046

Collected Steps per Second: 22,692.72071
Overall Steps per Second: 10,712.87413

Timestep Collection Time: 2.20405
Timestep Consumption Time: 2.46472
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.66878

Cumulative Model Updates: 184,016
Cumulative Timesteps: 1,534,553,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,073.23166
Policy Entropy: 3.67485
Value Function Loss: 0.02939

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12300
Policy Update Magnitude: 0.51933
Value Function Update Magnitude: 0.39918

Collected Steps per Second: 22,084.86456
Overall Steps per Second: 10,844.03608

Timestep Collection Time: 2.26436
Timestep Consumption Time: 2.34721
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.61157

Cumulative Model Updates: 184,022
Cumulative Timesteps: 1,534,603,570

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1534603570...
Checkpoint 1534603570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.67446
Value Function Loss: 0.03552

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15639
Policy Update Magnitude: 0.46406
Value Function Update Magnitude: 0.42141

Collected Steps per Second: 22,136.08384
Overall Steps per Second: 10,699.35381

Timestep Collection Time: 2.25903
Timestep Consumption Time: 2.41471
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.67374

Cumulative Model Updates: 184,028
Cumulative Timesteps: 1,534,653,576

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.69081
Value Function Loss: 0.03268

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.45112
Value Function Update Magnitude: 0.35865

Collected Steps per Second: 22,084.50272
Overall Steps per Second: 10,580.04043

Timestep Collection Time: 2.26439
Timestep Consumption Time: 2.46224
PPO Batch Consumption Time: 0.28964
Total Iteration Time: 4.72664

Cumulative Model Updates: 184,034
Cumulative Timesteps: 1,534,703,584

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1534703584...
Checkpoint 1534703584 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.70777
Value Function Loss: 0.02589

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12874
Policy Update Magnitude: 0.41157
Value Function Update Magnitude: 0.34831

Collected Steps per Second: 22,914.09560
Overall Steps per Second: 10,942.71865

Timestep Collection Time: 2.18302
Timestep Consumption Time: 2.38824
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.57126

Cumulative Model Updates: 184,040
Cumulative Timesteps: 1,534,753,606

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.69832
Value Function Loss: 0.02020

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.37152
Value Function Update Magnitude: 0.36277

Collected Steps per Second: 23,055.89769
Overall Steps per Second: 10,921.59568

Timestep Collection Time: 2.16899
Timestep Consumption Time: 2.40983
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.57882

Cumulative Model Updates: 184,046
Cumulative Timesteps: 1,534,803,614

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1534803614...
Checkpoint 1534803614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.70215
Value Function Loss: 0.02111

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.35295
Value Function Update Magnitude: 0.45416

Collected Steps per Second: 22,884.51168
Overall Steps per Second: 10,668.72258

Timestep Collection Time: 2.18585
Timestep Consumption Time: 2.50281
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.68866

Cumulative Model Updates: 184,052
Cumulative Timesteps: 1,534,853,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.68530
Value Function Loss: 0.02253

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12815
Policy Update Magnitude: 0.39762
Value Function Update Magnitude: 0.69729

Collected Steps per Second: 22,886.98436
Overall Steps per Second: 10,859.75405

Timestep Collection Time: 2.18526
Timestep Consumption Time: 2.42019
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.60545

Cumulative Model Updates: 184,058
Cumulative Timesteps: 1,534,903,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1534903650...
Checkpoint 1534903650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.68238
Value Function Loss: 0.02311

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.44286
Value Function Update Magnitude: 0.72448

Collected Steps per Second: 22,667.56972
Overall Steps per Second: 10,722.86953

Timestep Collection Time: 2.20615
Timestep Consumption Time: 2.45753
PPO Batch Consumption Time: 0.28472
Total Iteration Time: 4.66368

Cumulative Model Updates: 184,064
Cumulative Timesteps: 1,534,953,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.67994
Value Function Loss: 0.02221

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.41578
Value Function Update Magnitude: 0.58473

Collected Steps per Second: 22,996.30166
Overall Steps per Second: 10,856.72321

Timestep Collection Time: 2.17444
Timestep Consumption Time: 2.43137
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.60581

Cumulative Model Updates: 184,070
Cumulative Timesteps: 1,535,003,662

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1535003662...
Checkpoint 1535003662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.68723
Value Function Loss: 0.02062

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.38636
Value Function Update Magnitude: 0.42390

Collected Steps per Second: 22,965.43616
Overall Steps per Second: 10,710.50519

Timestep Collection Time: 2.17832
Timestep Consumption Time: 2.49242
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.67074

Cumulative Model Updates: 184,076
Cumulative Timesteps: 1,535,053,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.69714
Value Function Loss: 0.01983

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12995
Policy Update Magnitude: 0.37219
Value Function Update Magnitude: 0.35711

Collected Steps per Second: 23,054.27889
Overall Steps per Second: 10,928.75802

Timestep Collection Time: 2.16914
Timestep Consumption Time: 2.40668
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.57582

Cumulative Model Updates: 184,082
Cumulative Timesteps: 1,535,103,696

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1535103696...
Checkpoint 1535103696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.70055
Value Function Loss: 0.01988

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.36568
Value Function Update Magnitude: 0.40045

Collected Steps per Second: 22,920.53159
Overall Steps per Second: 10,733.21244

Timestep Collection Time: 2.18224
Timestep Consumption Time: 2.47788
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.66011

Cumulative Model Updates: 184,088
Cumulative Timesteps: 1,535,153,714

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.69224
Value Function Loss: 0.01893

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12731
Policy Update Magnitude: 0.37797
Value Function Update Magnitude: 0.47655

Collected Steps per Second: 22,976.12703
Overall Steps per Second: 10,732.87983

Timestep Collection Time: 2.17652
Timestep Consumption Time: 2.48281
PPO Batch Consumption Time: 0.28603
Total Iteration Time: 4.65933

Cumulative Model Updates: 184,094
Cumulative Timesteps: 1,535,203,722

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1535203722...
Checkpoint 1535203722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.68289
Value Function Loss: 0.02003

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.38573
Value Function Update Magnitude: 0.46863

Collected Steps per Second: 22,601.62270
Overall Steps per Second: 10,659.20603

Timestep Collection Time: 2.21338
Timestep Consumption Time: 2.47984
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.69322

Cumulative Model Updates: 184,100
Cumulative Timesteps: 1,535,253,748

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.68437
Value Function Loss: 0.01894

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12419
Policy Update Magnitude: 0.38002
Value Function Update Magnitude: 0.42123

Collected Steps per Second: 22,854.78514
Overall Steps per Second: 10,819.07303

Timestep Collection Time: 2.18904
Timestep Consumption Time: 2.43520
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.62424

Cumulative Model Updates: 184,106
Cumulative Timesteps: 1,535,303,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1535303778...
Checkpoint 1535303778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,420.62935
Policy Entropy: 3.69606
Value Function Loss: 0.02110

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.37724
Value Function Update Magnitude: 0.41219

Collected Steps per Second: 22,680.82593
Overall Steps per Second: 10,738.63364

Timestep Collection Time: 2.20565
Timestep Consumption Time: 2.45286
PPO Batch Consumption Time: 0.28412
Total Iteration Time: 4.65851

Cumulative Model Updates: 184,112
Cumulative Timesteps: 1,535,353,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239,851.84534
Policy Entropy: 3.69484
Value Function Loss: 0.02241

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.40878
Value Function Update Magnitude: 0.51569

Collected Steps per Second: 23,159.46412
Overall Steps per Second: 10,955.18427

Timestep Collection Time: 2.15894
Timestep Consumption Time: 2.40510
PPO Batch Consumption Time: 0.27638
Total Iteration Time: 4.56405

Cumulative Model Updates: 184,118
Cumulative Timesteps: 1,535,403,804

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1535403804...
Checkpoint 1535403804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 239,851.84534
Policy Entropy: 3.69564
Value Function Loss: 0.02264

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11881
Policy Update Magnitude: 0.43783
Value Function Update Magnitude: 0.62578

Collected Steps per Second: 22,136.25140
Overall Steps per Second: 10,696.37747

Timestep Collection Time: 2.25901
Timestep Consumption Time: 2.41603
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.67504

Cumulative Model Updates: 184,124
Cumulative Timesteps: 1,535,453,810

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239,851.84534
Policy Entropy: 3.69403
Value Function Loss: 0.02044

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12079
Policy Update Magnitude: 0.44808
Value Function Update Magnitude: 0.62974

Collected Steps per Second: 22,389.65382
Overall Steps per Second: 10,814.08243

Timestep Collection Time: 2.23442
Timestep Consumption Time: 2.39177
PPO Batch Consumption Time: 0.28490
Total Iteration Time: 4.62619

Cumulative Model Updates: 184,130
Cumulative Timesteps: 1,535,503,838

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1535503838...
Checkpoint 1535503838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,676.34001
Policy Entropy: 3.67854
Value Function Loss: 0.02379

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12106
Policy Update Magnitude: 0.41550
Value Function Update Magnitude: 0.52513

Collected Steps per Second: 22,251.26900
Overall Steps per Second: 10,636.19691

Timestep Collection Time: 2.24733
Timestep Consumption Time: 2.45416
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.70149

Cumulative Model Updates: 184,136
Cumulative Timesteps: 1,535,553,844

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390,676.34001
Policy Entropy: 3.68315
Value Function Loss: 0.02349

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.41485
Value Function Update Magnitude: 0.40099

Collected Steps per Second: 23,073.89177
Overall Steps per Second: 10,912.46254

Timestep Collection Time: 2.16738
Timestep Consumption Time: 2.41545
PPO Batch Consumption Time: 0.28145
Total Iteration Time: 4.58283

Cumulative Model Updates: 184,142
Cumulative Timesteps: 1,535,603,854

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1535603854...
Checkpoint 1535603854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,676.34001
Policy Entropy: 3.68775
Value Function Loss: 0.02403

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.37597
Value Function Update Magnitude: 0.35967

Collected Steps per Second: 23,097.79485
Overall Steps per Second: 10,994.04795

Timestep Collection Time: 2.16627
Timestep Consumption Time: 2.38492
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.55119

Cumulative Model Updates: 184,148
Cumulative Timesteps: 1,535,653,890

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390,676.34001
Policy Entropy: 3.71827
Value Function Loss: 0.01917

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10732
Policy Update Magnitude: 0.36419
Value Function Update Magnitude: 0.35243

Collected Steps per Second: 22,935.46951
Overall Steps per Second: 10,788.12460

Timestep Collection Time: 2.18047
Timestep Consumption Time: 2.45519
PPO Batch Consumption Time: 0.28658
Total Iteration Time: 4.63565

Cumulative Model Updates: 184,154
Cumulative Timesteps: 1,535,703,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1535703900...
Checkpoint 1535703900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,676.34001
Policy Entropy: 3.71011
Value Function Loss: 0.01849

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06719
Policy Update Magnitude: 0.40445
Value Function Update Magnitude: 0.35480

Collected Steps per Second: 22,757.29444
Overall Steps per Second: 10,823.12526

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.42283
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.62011

Cumulative Model Updates: 184,160
Cumulative Timesteps: 1,535,753,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390,676.34001
Policy Entropy: 3.70708
Value Function Loss: 0.01606

Mean KL Divergence: 0.00735
SB3 Clip Fraction: 0.09361
Policy Update Magnitude: 0.41352
Value Function Update Magnitude: 0.35795

Collected Steps per Second: 23,071.77315
Overall Steps per Second: 10,890.30200

Timestep Collection Time: 2.16836
Timestep Consumption Time: 2.42545
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.59381

Cumulative Model Updates: 184,166
Cumulative Timesteps: 1,535,803,932

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1535803932...
Checkpoint 1535803932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 390,676.34001
Policy Entropy: 3.71594
Value Function Loss: 0.01425

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.09951
Policy Update Magnitude: 0.34214
Value Function Update Magnitude: 0.33224

Collected Steps per Second: 22,792.99770
Overall Steps per Second: 10,679.72921

Timestep Collection Time: 2.19409
Timestep Consumption Time: 2.48861
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.68270

Cumulative Model Updates: 184,172
Cumulative Timesteps: 1,535,853,942

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 390,676.34001
Policy Entropy: 3.70735
Value Function Loss: 0.01544

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.10692
Policy Update Magnitude: 0.30754
Value Function Update Magnitude: 0.30055

Collected Steps per Second: 22,744.66709
Overall Steps per Second: 10,851.27613

Timestep Collection Time: 2.20016
Timestep Consumption Time: 2.41146
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.61162

Cumulative Model Updates: 184,178
Cumulative Timesteps: 1,535,903,984

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1535903984...
Checkpoint 1535903984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 535,804.28875
Policy Entropy: 3.70050
Value Function Loss: 0.01732

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.32598
Value Function Update Magnitude: 0.32849

Collected Steps per Second: 22,569.58813
Overall Steps per Second: 10,795.07152

Timestep Collection Time: 2.21590
Timestep Consumption Time: 2.41695
PPO Batch Consumption Time: 0.27497
Total Iteration Time: 4.63285

Cumulative Model Updates: 184,184
Cumulative Timesteps: 1,535,953,996

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.67698
Value Function Loss: 0.02143

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.36272
Value Function Update Magnitude: 0.37955

Collected Steps per Second: 23,092.03823
Overall Steps per Second: 10,714.80405

Timestep Collection Time: 2.16568
Timestep Consumption Time: 2.50169
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.66737

Cumulative Model Updates: 184,190
Cumulative Timesteps: 1,536,004,006

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1536004006...
Checkpoint 1536004006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.68110
Value Function Loss: 0.02136

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11822
Policy Update Magnitude: 0.37502
Value Function Update Magnitude: 0.36175

Collected Steps per Second: 22,740.83989
Overall Steps per Second: 10,732.67441

Timestep Collection Time: 2.19983
Timestep Consumption Time: 2.46126
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.66109

Cumulative Model Updates: 184,196
Cumulative Timesteps: 1,536,054,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.69560
Value Function Loss: 0.01986

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12259
Policy Update Magnitude: 0.34258
Value Function Update Magnitude: 0.34629

Collected Steps per Second: 22,968.28510
Overall Steps per Second: 10,838.78613

Timestep Collection Time: 2.17770
Timestep Consumption Time: 2.43702
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.61472

Cumulative Model Updates: 184,202
Cumulative Timesteps: 1,536,104,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1536104050...
Checkpoint 1536104050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.69696
Value Function Loss: 0.01825

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.31400
Value Function Update Magnitude: 0.28684

Collected Steps per Second: 21,577.40341
Overall Steps per Second: 10,279.02947

Timestep Collection Time: 2.31872
Timestep Consumption Time: 2.54866
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.86739

Cumulative Model Updates: 184,208
Cumulative Timesteps: 1,536,154,082

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.70761
Value Function Loss: 0.01664

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.12180
Policy Update Magnitude: 0.29693
Value Function Update Magnitude: 0.30794

Collected Steps per Second: 22,300.46467
Overall Steps per Second: 10,564.15874

Timestep Collection Time: 2.24237
Timestep Consumption Time: 2.49118
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.73355

Cumulative Model Updates: 184,214
Cumulative Timesteps: 1,536,204,088

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1536204088...
Checkpoint 1536204088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.69208
Value Function Loss: 0.01750

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12572
Policy Update Magnitude: 0.30917
Value Function Update Magnitude: 0.38081

Collected Steps per Second: 23,009.79872
Overall Steps per Second: 10,912.16201

Timestep Collection Time: 2.17351
Timestep Consumption Time: 2.40963
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.58314

Cumulative Model Updates: 184,220
Cumulative Timesteps: 1,536,254,100

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.70019
Value Function Loss: 0.01780

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.12068
Policy Update Magnitude: 0.34467
Value Function Update Magnitude: 0.44019

Collected Steps per Second: 22,859.22214
Overall Steps per Second: 10,707.52740

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.48261
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.67017

Cumulative Model Updates: 184,226
Cumulative Timesteps: 1,536,304,106

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1536304106...
Checkpoint 1536304106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.69098
Value Function Loss: 0.01909

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11299
Policy Update Magnitude: 0.36273
Value Function Update Magnitude: 0.37791

Collected Steps per Second: 22,111.41128
Overall Steps per Second: 10,879.49839

Timestep Collection Time: 2.26263
Timestep Consumption Time: 2.33592
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.59856

Cumulative Model Updates: 184,232
Cumulative Timesteps: 1,536,354,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.69349
Value Function Loss: 0.01936

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12117
Policy Update Magnitude: 0.39395
Value Function Update Magnitude: 0.33109

Collected Steps per Second: 22,460.15559
Overall Steps per Second: 10,926.10603

Timestep Collection Time: 2.22625
Timestep Consumption Time: 2.35013
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.57638

Cumulative Model Updates: 184,238
Cumulative Timesteps: 1,536,404,138

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1536404138...
Checkpoint 1536404138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.68804
Value Function Loss: 0.01888

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12189
Policy Update Magnitude: 0.40256
Value Function Update Magnitude: 0.29231

Collected Steps per Second: 22,028.41598
Overall Steps per Second: 10,723.59199

Timestep Collection Time: 2.27007
Timestep Consumption Time: 2.39311
PPO Batch Consumption Time: 0.27594
Total Iteration Time: 4.66318

Cumulative Model Updates: 184,244
Cumulative Timesteps: 1,536,454,144

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.68131
Value Function Loss: 0.02304

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.43718
Value Function Update Magnitude: 0.32081

Collected Steps per Second: 22,955.75259
Overall Steps per Second: 10,882.56847

Timestep Collection Time: 2.17854
Timestep Consumption Time: 2.41688
PPO Batch Consumption Time: 0.28185
Total Iteration Time: 4.59542

Cumulative Model Updates: 184,250
Cumulative Timesteps: 1,536,504,154

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1536504154...
Checkpoint 1536504154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.68863
Value Function Loss: 0.02460

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.45787
Value Function Update Magnitude: 0.34106

Collected Steps per Second: 22,572.43317
Overall Steps per Second: 10,700.56016

Timestep Collection Time: 2.21545
Timestep Consumption Time: 2.45795
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.67340

Cumulative Model Updates: 184,256
Cumulative Timesteps: 1,536,554,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 606,747.82054
Policy Entropy: 3.68814
Value Function Loss: 0.02746

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12558
Policy Update Magnitude: 0.46314
Value Function Update Magnitude: 0.33556

Collected Steps per Second: 23,260.19091
Overall Steps per Second: 10,845.61806

Timestep Collection Time: 2.15080
Timestep Consumption Time: 2.46194
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.61274

Cumulative Model Updates: 184,262
Cumulative Timesteps: 1,536,604,190

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1536604190...
Checkpoint 1536604190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.69313
Value Function Loss: 0.02805

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.47041
Value Function Update Magnitude: 0.32898

Collected Steps per Second: 22,724.45705
Overall Steps per Second: 10,625.32050

Timestep Collection Time: 2.20115
Timestep Consumption Time: 2.50647
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.70762

Cumulative Model Updates: 184,268
Cumulative Timesteps: 1,536,654,210

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.68430
Value Function Loss: 0.02811

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.47806
Value Function Update Magnitude: 0.33500

Collected Steps per Second: 22,688.15291
Overall Steps per Second: 10,681.04094

Timestep Collection Time: 2.20494
Timestep Consumption Time: 2.47869
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.68363

Cumulative Model Updates: 184,274
Cumulative Timesteps: 1,536,704,236

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1536704236...
Checkpoint 1536704236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.69212
Value Function Loss: 0.02498

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.44845
Value Function Update Magnitude: 0.34953

Collected Steps per Second: 22,592.40455
Overall Steps per Second: 10,799.86404

Timestep Collection Time: 2.21322
Timestep Consumption Time: 2.41665
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.62987

Cumulative Model Updates: 184,280
Cumulative Timesteps: 1,536,754,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.70956
Value Function Loss: 0.01709

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.39027
Value Function Update Magnitude: 0.34592

Collected Steps per Second: 22,784.76006
Overall Steps per Second: 10,635.14482

Timestep Collection Time: 2.19471
Timestep Consumption Time: 2.50725
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.70196

Cumulative Model Updates: 184,286
Cumulative Timesteps: 1,536,804,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1536804244...
Checkpoint 1536804244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.71577
Value Function Loss: 0.01594

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12312
Policy Update Magnitude: 0.31129
Value Function Update Magnitude: 0.28776

Collected Steps per Second: 22,964.59955
Overall Steps per Second: 10,733.61115

Timestep Collection Time: 2.17892
Timestep Consumption Time: 2.48289
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.66180

Cumulative Model Updates: 184,292
Cumulative Timesteps: 1,536,854,282

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.71257
Value Function Loss: 0.01567

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11923
Policy Update Magnitude: 0.28901
Value Function Update Magnitude: 0.21776

Collected Steps per Second: 23,291.06121
Overall Steps per Second: 10,763.20221

Timestep Collection Time: 2.14795
Timestep Consumption Time: 2.50011
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.64806

Cumulative Model Updates: 184,298
Cumulative Timesteps: 1,536,904,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1536904310...
Checkpoint 1536904310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.68788
Value Function Loss: 0.01951

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11811
Policy Update Magnitude: 0.31945
Value Function Update Magnitude: 0.24003

Collected Steps per Second: 22,931.27564
Overall Steps per Second: 10,757.42146

Timestep Collection Time: 2.18095
Timestep Consumption Time: 2.46812
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.64907

Cumulative Model Updates: 184,304
Cumulative Timesteps: 1,536,954,322

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.68134
Value Function Loss: 0.01939

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11902
Policy Update Magnitude: 0.38515
Value Function Update Magnitude: 0.29978

Collected Steps per Second: 23,330.89780
Overall Steps per Second: 10,756.19278

Timestep Collection Time: 2.14368
Timestep Consumption Time: 2.50611
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.64979

Cumulative Model Updates: 184,310
Cumulative Timesteps: 1,537,004,336

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1537004336...
Checkpoint 1537004336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.68383
Value Function Loss: 0.02136

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.40944
Value Function Update Magnitude: 0.37140

Collected Steps per Second: 22,657.99945
Overall Steps per Second: 10,610.60612

Timestep Collection Time: 2.20717
Timestep Consumption Time: 2.50604
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.71321

Cumulative Model Updates: 184,316
Cumulative Timesteps: 1,537,054,346

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.68224
Value Function Loss: 0.03181

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12432
Policy Update Magnitude: 0.47052
Value Function Update Magnitude: 0.34443

Collected Steps per Second: 22,765.07932
Overall Steps per Second: 10,692.41316

Timestep Collection Time: 2.19749
Timestep Consumption Time: 2.48116
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.67864

Cumulative Model Updates: 184,322
Cumulative Timesteps: 1,537,104,372

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1537104372...
Checkpoint 1537104372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,073.87321
Policy Entropy: 3.68207
Value Function Loss: 0.03096

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13055
Policy Update Magnitude: 0.53883
Value Function Update Magnitude: 0.39457

Collected Steps per Second: 22,787.52645
Overall Steps per Second: 10,871.31518

Timestep Collection Time: 2.19489
Timestep Consumption Time: 2.40585
PPO Batch Consumption Time: 0.27694
Total Iteration Time: 4.60073

Cumulative Model Updates: 184,328
Cumulative Timesteps: 1,537,154,388

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 432,488.03038
Policy Entropy: 3.68618
Value Function Loss: 0.03971

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.39816

Collected Steps per Second: 22,391.14315
Overall Steps per Second: 10,878.03081

Timestep Collection Time: 2.23437
Timestep Consumption Time: 2.36481
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.59918

Cumulative Model Updates: 184,334
Cumulative Timesteps: 1,537,204,418

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1537204418...
Checkpoint 1537204418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283,768.52857
Policy Entropy: 3.71666
Value Function Loss: 0.02911

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.11741
Policy Update Magnitude: 0.52677
Value Function Update Magnitude: 0.37907

Collected Steps per Second: 21,996.86224
Overall Steps per Second: 10,656.78931

Timestep Collection Time: 2.27360
Timestep Consumption Time: 2.41937
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.69297

Cumulative Model Updates: 184,340
Cumulative Timesteps: 1,537,254,430

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,768.52857
Policy Entropy: 3.71506
Value Function Loss: 0.02584

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.45784
Value Function Update Magnitude: 0.37137

Collected Steps per Second: 22,454.17155
Overall Steps per Second: 10,962.03025

Timestep Collection Time: 2.22774
Timestep Consumption Time: 2.33547
PPO Batch Consumption Time: 0.27493
Total Iteration Time: 4.56321

Cumulative Model Updates: 184,346
Cumulative Timesteps: 1,537,304,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1537304452...
Checkpoint 1537304452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283,768.52857
Policy Entropy: 3.71059
Value Function Loss: 0.01959

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12695
Policy Update Magnitude: 0.40089
Value Function Update Magnitude: 0.34273

Collected Steps per Second: 21,955.03526
Overall Steps per Second: 10,643.03031

Timestep Collection Time: 2.27939
Timestep Consumption Time: 2.42266
PPO Batch Consumption Time: 0.28258
Total Iteration Time: 4.70204

Cumulative Model Updates: 184,352
Cumulative Timesteps: 1,537,354,496

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,768.52857
Policy Entropy: 3.68386
Value Function Loss: 0.02388

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12148
Policy Update Magnitude: 0.39894
Value Function Update Magnitude: 0.37662

Collected Steps per Second: 22,850.70208
Overall Steps per Second: 10,860.36597

Timestep Collection Time: 2.18855
Timestep Consumption Time: 2.41626
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.60482

Cumulative Model Updates: 184,358
Cumulative Timesteps: 1,537,404,506

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1537404506...
Checkpoint 1537404506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 283,768.52857
Policy Entropy: 3.69376
Value Function Loss: 0.02392

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.44788
Value Function Update Magnitude: 0.36498

Collected Steps per Second: 22,593.95563
Overall Steps per Second: 10,656.78949

Timestep Collection Time: 2.21325
Timestep Consumption Time: 2.47916
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.69241

Cumulative Model Updates: 184,364
Cumulative Timesteps: 1,537,454,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,768.52857
Policy Entropy: 3.68873
Value Function Loss: 0.02522

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12617
Policy Update Magnitude: 0.40823
Value Function Update Magnitude: 0.31269

Collected Steps per Second: 23,049.53165
Overall Steps per Second: 10,879.32448

Timestep Collection Time: 2.17002
Timestep Consumption Time: 2.42751
PPO Batch Consumption Time: 0.27707
Total Iteration Time: 4.59753

Cumulative Model Updates: 184,370
Cumulative Timesteps: 1,537,504,530

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1537504530...
Checkpoint 1537504530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.69594
Value Function Loss: 0.02129

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11954
Policy Update Magnitude: 0.39392
Value Function Update Magnitude: 0.38472

Collected Steps per Second: 22,545.14719
Overall Steps per Second: 10,694.31534

Timestep Collection Time: 2.21884
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28373
Total Iteration Time: 4.67763

Cumulative Model Updates: 184,376
Cumulative Timesteps: 1,537,554,554

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.68905
Value Function Loss: 0.02150

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.40212
Value Function Update Magnitude: 0.47606

Collected Steps per Second: 23,248.21844
Overall Steps per Second: 10,948.83713

Timestep Collection Time: 2.15182
Timestep Consumption Time: 2.41725
PPO Batch Consumption Time: 0.27663
Total Iteration Time: 4.56907

Cumulative Model Updates: 184,382
Cumulative Timesteps: 1,537,604,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1537604580...
Checkpoint 1537604580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.68572
Value Function Loss: 0.02047

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12536
Policy Update Magnitude: 0.39445
Value Function Update Magnitude: 0.51635

Collected Steps per Second: 22,490.29959
Overall Steps per Second: 10,575.33260

Timestep Collection Time: 2.22416
Timestep Consumption Time: 2.50591
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.73006

Cumulative Model Updates: 184,388
Cumulative Timesteps: 1,537,654,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.68342
Value Function Loss: 0.02371

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12483
Policy Update Magnitude: 0.39236
Value Function Update Magnitude: 0.43168

Collected Steps per Second: 23,275.98998
Overall Steps per Second: 10,956.22401

Timestep Collection Time: 2.14934
Timestep Consumption Time: 2.41683
PPO Batch Consumption Time: 0.27630
Total Iteration Time: 4.56617

Cumulative Model Updates: 184,394
Cumulative Timesteps: 1,537,704,630

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1537704630...
Checkpoint 1537704630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.67331
Value Function Loss: 0.02729

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12885
Policy Update Magnitude: 0.38516
Value Function Update Magnitude: 0.31512

Collected Steps per Second: 22,503.86186
Overall Steps per Second: 10,625.75588

Timestep Collection Time: 2.22309
Timestep Consumption Time: 2.48510
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.70818

Cumulative Model Updates: 184,400
Cumulative Timesteps: 1,537,754,658

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.68707
Value Function Loss: 0.02658

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.41317
Value Function Update Magnitude: 0.31502

Collected Steps per Second: 22,365.57155
Overall Steps per Second: 10,877.61242

Timestep Collection Time: 2.23594
Timestep Consumption Time: 2.36140
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.59733

Cumulative Model Updates: 184,406
Cumulative Timesteps: 1,537,804,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1537804666...
Checkpoint 1537804666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.69061
Value Function Loss: 0.02348

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12545
Policy Update Magnitude: 0.40751
Value Function Update Magnitude: 0.33158

Collected Steps per Second: 21,952.75116
Overall Steps per Second: 10,648.31206

Timestep Collection Time: 2.27844
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.29005
Total Iteration Time: 4.69727

Cumulative Model Updates: 184,412
Cumulative Timesteps: 1,537,854,684

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.69250
Value Function Loss: 0.02066

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.38391
Value Function Update Magnitude: 0.33029

Collected Steps per Second: 22,347.30307
Overall Steps per Second: 10,673.29262

Timestep Collection Time: 2.23857
Timestep Consumption Time: 2.44846
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.68703

Cumulative Model Updates: 184,418
Cumulative Timesteps: 1,537,904,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1537904710...
Checkpoint 1537904710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.68886
Value Function Loss: 0.02277

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.38569
Value Function Update Magnitude: 0.33325

Collected Steps per Second: 22,785.92815
Overall Steps per Second: 10,927.75595

Timestep Collection Time: 2.19557
Timestep Consumption Time: 2.38250
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.57807

Cumulative Model Updates: 184,424
Cumulative Timesteps: 1,537,954,738

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.68333
Value Function Loss: 0.02454

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12095
Policy Update Magnitude: 0.39349
Value Function Update Magnitude: 0.27253

Collected Steps per Second: 22,775.02367
Overall Steps per Second: 10,835.70247

Timestep Collection Time: 2.19539
Timestep Consumption Time: 2.41899
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.61438

Cumulative Model Updates: 184,430
Cumulative Timesteps: 1,538,004,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1538004738...
Checkpoint 1538004738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.68094
Value Function Loss: 0.02718

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12674
Policy Update Magnitude: 0.39968
Value Function Update Magnitude: 0.28913

Collected Steps per Second: 22,760.39013
Overall Steps per Second: 10,691.41395

Timestep Collection Time: 2.19680
Timestep Consumption Time: 2.47985
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.67665

Cumulative Model Updates: 184,436
Cumulative Timesteps: 1,538,054,738

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.67604
Value Function Loss: 0.02960

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.46711
Value Function Update Magnitude: 0.25636

Collected Steps per Second: 23,198.72376
Overall Steps per Second: 10,951.24641

Timestep Collection Time: 2.15546
Timestep Consumption Time: 2.41059
PPO Batch Consumption Time: 0.27547
Total Iteration Time: 4.56606

Cumulative Model Updates: 184,442
Cumulative Timesteps: 1,538,104,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1538104742...
Checkpoint 1538104742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.67779
Value Function Loss: 0.02528

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.46937
Value Function Update Magnitude: 0.25556

Collected Steps per Second: 22,546.66827
Overall Steps per Second: 10,625.63131

Timestep Collection Time: 2.21851
Timestep Consumption Time: 2.48898
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.70748

Cumulative Model Updates: 184,448
Cumulative Timesteps: 1,538,154,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.68471
Value Function Loss: 0.02610

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15093
Policy Update Magnitude: 0.47902
Value Function Update Magnitude: 0.27597

Collected Steps per Second: 23,246.49254
Overall Steps per Second: 10,917.60388

Timestep Collection Time: 2.15258
Timestep Consumption Time: 2.43084
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.58342

Cumulative Model Updates: 184,454
Cumulative Timesteps: 1,538,204,802

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1538204802...
Checkpoint 1538204802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,893.04743
Policy Entropy: 3.68633
Value Function Loss: 0.02265

Mean KL Divergence: 0.02461
SB3 Clip Fraction: 0.27154
Policy Update Magnitude: 0.44846
Value Function Update Magnitude: 0.29409

Collected Steps per Second: 22,937.09433
Overall Steps per Second: 10,720.99127

Timestep Collection Time: 2.18101
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.66617

Cumulative Model Updates: 184,460
Cumulative Timesteps: 1,538,254,828

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 525,696.52377
Policy Entropy: 3.66079
Value Function Loss: 0.05491

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.13771
Policy Update Magnitude: 0.53128
Value Function Update Magnitude: 0.34199

Collected Steps per Second: 23,020.49408
Overall Steps per Second: 10,774.78549

Timestep Collection Time: 2.17285
Timestep Consumption Time: 2.46947
PPO Batch Consumption Time: 0.28279
Total Iteration Time: 4.64232

Cumulative Model Updates: 184,466
Cumulative Timesteps: 1,538,304,848

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1538304848...
Checkpoint 1538304848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 381,478.46057
Policy Entropy: 3.66493
Value Function Loss: 0.06521

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11451
Policy Update Magnitude: 1.00107
Value Function Update Magnitude: 0.37214

Collected Steps per Second: 22,629.63425
Overall Steps per Second: 10,673.45039

Timestep Collection Time: 2.21073
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.68714

Cumulative Model Updates: 184,472
Cumulative Timesteps: 1,538,354,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,070,296.22076
Policy Entropy: 3.66012
Value Function Loss: 0.08585

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.17415
Policy Update Magnitude: 1.04461
Value Function Update Magnitude: 0.41916

Collected Steps per Second: 22,876.52751
Overall Steps per Second: 10,826.68308

Timestep Collection Time: 2.18565
Timestep Consumption Time: 2.43257
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.61822

Cumulative Model Updates: 184,478
Cumulative Timesteps: 1,538,404,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1538404876...
Checkpoint 1538404876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,776.72769
Policy Entropy: 3.70763
Value Function Loss: 0.05922

Mean KL Divergence: 0.02369
SB3 Clip Fraction: 0.25072
Policy Update Magnitude: 0.83173
Value Function Update Magnitude: 0.51532

Collected Steps per Second: 22,422.04445
Overall Steps per Second: 10,712.66586

Timestep Collection Time: 2.23013
Timestep Consumption Time: 2.43762
PPO Batch Consumption Time: 0.28126
Total Iteration Time: 4.66775

Cumulative Model Updates: 184,484
Cumulative Timesteps: 1,538,454,880

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,638.00565
Policy Entropy: 3.67970
Value Function Loss: 0.05463

Mean KL Divergence: 0.01640
SB3 Clip Fraction: 0.19135
Policy Update Magnitude: 0.81022
Value Function Update Magnitude: 0.54725

Collected Steps per Second: 22,898.09209
Overall Steps per Second: 10,866.30800

Timestep Collection Time: 2.18411
Timestep Consumption Time: 2.41837
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.60248

Cumulative Model Updates: 184,490
Cumulative Timesteps: 1,538,504,892

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1538504892...
Checkpoint 1538504892 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,021.71909
Policy Entropy: 3.68449
Value Function Loss: 0.04642

Mean KL Divergence: 0.01511
SB3 Clip Fraction: 0.18353
Policy Update Magnitude: 0.69731
Value Function Update Magnitude: 0.56034

Collected Steps per Second: 22,534.50740
Overall Steps per Second: 10,708.52653

Timestep Collection Time: 2.22033
Timestep Consumption Time: 2.45202
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.67235

Cumulative Model Updates: 184,496
Cumulative Timesteps: 1,538,554,926

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,204.97136
Policy Entropy: 3.62597
Value Function Loss: 0.05276

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.17619
Policy Update Magnitude: 0.63474
Value Function Update Magnitude: 0.58668

Collected Steps per Second: 22,701.61054
Overall Steps per Second: 10,795.70249

Timestep Collection Time: 2.20372
Timestep Consumption Time: 2.43035
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.63407

Cumulative Model Updates: 184,502
Cumulative Timesteps: 1,538,604,954

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1538604954...
Checkpoint 1538604954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,204.97136
Policy Entropy: 3.63316
Value Function Loss: 0.05856

Mean KL Divergence: 0.01255
SB3 Clip Fraction: 0.15604
Policy Update Magnitude: 0.73184
Value Function Update Magnitude: 0.53563

Collected Steps per Second: 22,503.89363
Overall Steps per Second: 10,789.01692

Timestep Collection Time: 2.22228
Timestep Consumption Time: 2.41299
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.63527

Cumulative Model Updates: 184,508
Cumulative Timesteps: 1,538,654,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,204.97136
Policy Entropy: 3.63299
Value Function Loss: 0.05613

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.14066
Policy Update Magnitude: 0.75931
Value Function Update Magnitude: 0.45990

Collected Steps per Second: 23,035.07893
Overall Steps per Second: 10,885.41634

Timestep Collection Time: 2.17095
Timestep Consumption Time: 2.42309
PPO Batch Consumption Time: 0.27642
Total Iteration Time: 4.59404

Cumulative Model Updates: 184,514
Cumulative Timesteps: 1,538,704,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1538704972...
Checkpoint 1538704972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,204.97136
Policy Entropy: 3.64403
Value Function Loss: 0.04709

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.78623
Value Function Update Magnitude: 0.48389

Collected Steps per Second: 22,228.42196
Overall Steps per Second: 10,630.79199

Timestep Collection Time: 2.25063
Timestep Consumption Time: 2.45532
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.70595

Cumulative Model Updates: 184,520
Cumulative Timesteps: 1,538,755,000

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,204.97136
Policy Entropy: 3.65959
Value Function Loss: 0.04092

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.13766
Policy Update Magnitude: 0.70770
Value Function Update Magnitude: 0.57220

Collected Steps per Second: 22,946.61005
Overall Steps per Second: 10,839.80163

Timestep Collection Time: 2.18002
Timestep Consumption Time: 2.43483
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.61484

Cumulative Model Updates: 184,526
Cumulative Timesteps: 1,538,805,024

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1538805024...
Checkpoint 1538805024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 659,118.91895
Policy Entropy: 3.66863
Value Function Loss: 0.04517

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13870
Policy Update Magnitude: 0.65977
Value Function Update Magnitude: 0.52582

Collected Steps per Second: 22,451.73322
Overall Steps per Second: 10,707.44110

Timestep Collection Time: 2.22816
Timestep Consumption Time: 2.44392
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.67208

Cumulative Model Updates: 184,532
Cumulative Timesteps: 1,538,855,050

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 659,118.91895
Policy Entropy: 3.66136
Value Function Loss: 0.03972

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15174
Policy Update Magnitude: 0.65654
Value Function Update Magnitude: 0.41694

Collected Steps per Second: 23,328.87372
Overall Steps per Second: 10,970.12947

Timestep Collection Time: 2.14361
Timestep Consumption Time: 2.41495
PPO Batch Consumption Time: 0.27572
Total Iteration Time: 4.55856

Cumulative Model Updates: 184,538
Cumulative Timesteps: 1,538,905,058

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1538905058...
Checkpoint 1538905058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 818,747.62375
Policy Entropy: 3.67025
Value Function Loss: 0.04092

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14436
Policy Update Magnitude: 0.60765
Value Function Update Magnitude: 0.41269

Collected Steps per Second: 22,512.95174
Overall Steps per Second: 10,628.26110

Timestep Collection Time: 2.22148
Timestep Consumption Time: 2.48409
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.70557

Cumulative Model Updates: 184,544
Cumulative Timesteps: 1,538,955,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 605,726.89796
Policy Entropy: 3.68043
Value Function Loss: 0.04362

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12412
Policy Update Magnitude: 0.63758
Value Function Update Magnitude: 0.49010

Collected Steps per Second: 22,411.86792
Overall Steps per Second: 10,835.47683

Timestep Collection Time: 2.23176
Timestep Consumption Time: 2.38437
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.61613

Cumulative Model Updates: 184,550
Cumulative Timesteps: 1,539,005,088

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1539005088...
Checkpoint 1539005088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213,355.31149
Policy Entropy: 3.70732
Value Function Loss: 0.04827

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12805
Policy Update Magnitude: 0.66189
Value Function Update Magnitude: 0.50835

Collected Steps per Second: 21,989.38477
Overall Steps per Second: 10,656.65552

Timestep Collection Time: 2.27482
Timestep Consumption Time: 2.41914
PPO Batch Consumption Time: 0.28947
Total Iteration Time: 4.69397

Cumulative Model Updates: 184,556
Cumulative Timesteps: 1,539,055,110

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,553.10141
Policy Entropy: 3.74058
Value Function Loss: 0.04178

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13279
Policy Update Magnitude: 0.60129
Value Function Update Magnitude: 0.64454

Collected Steps per Second: 22,476.66196
Overall Steps per Second: 10,959.11995

Timestep Collection Time: 2.22551
Timestep Consumption Time: 2.33891
PPO Batch Consumption Time: 0.27638
Total Iteration Time: 4.56442

Cumulative Model Updates: 184,562
Cumulative Timesteps: 1,539,105,132

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1539105132...
Checkpoint 1539105132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,543.01982
Policy Entropy: 3.75278
Value Function Loss: 0.03599

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.54634
Value Function Update Magnitude: 0.60180

Collected Steps per Second: 21,671.67973
Overall Steps per Second: 10,618.27200

Timestep Collection Time: 2.30780
Timestep Consumption Time: 2.40238
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.71018

Cumulative Model Updates: 184,568
Cumulative Timesteps: 1,539,155,146

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,512.79333
Policy Entropy: 3.75394
Value Function Loss: 0.03313

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11388
Policy Update Magnitude: 0.50106
Value Function Update Magnitude: 0.60612

Collected Steps per Second: 23,175.83632
Overall Steps per Second: 10,874.53923

Timestep Collection Time: 2.15871
Timestep Consumption Time: 2.44194
PPO Batch Consumption Time: 0.28242
Total Iteration Time: 4.60065

Cumulative Model Updates: 184,574
Cumulative Timesteps: 1,539,205,176

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1539205176...
Checkpoint 1539205176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,583.63482
Policy Entropy: 3.76243
Value Function Loss: 0.03002

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.48107
Value Function Update Magnitude: 0.72005

Collected Steps per Second: 22,717.88489
Overall Steps per Second: 10,685.94561

Timestep Collection Time: 2.20135
Timestep Consumption Time: 2.47863
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.67998

Cumulative Model Updates: 184,580
Cumulative Timesteps: 1,539,255,186

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.66566
Policy Entropy: 3.75390
Value Function Loss: 0.02818

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12515
Policy Update Magnitude: 0.45617
Value Function Update Magnitude: 0.69053

Collected Steps per Second: 23,339.71643
Overall Steps per Second: 10,910.86602

Timestep Collection Time: 2.14321
Timestep Consumption Time: 2.44139
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.58460

Cumulative Model Updates: 184,586
Cumulative Timesteps: 1,539,305,208

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1539305208...
Checkpoint 1539305208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,615.66566
Policy Entropy: 3.75290
Value Function Loss: 0.02327

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.43633
Value Function Update Magnitude: 0.64198

Collected Steps per Second: 22,907.36855
Overall Steps per Second: 10,729.02299

Timestep Collection Time: 2.18288
Timestep Consumption Time: 2.47775
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.66063

Cumulative Model Updates: 184,592
Cumulative Timesteps: 1,539,355,212

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,288.68799
Policy Entropy: 3.73102
Value Function Loss: 0.02292

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.40956
Value Function Update Magnitude: 0.60786

Collected Steps per Second: 23,014.07133
Overall Steps per Second: 10,766.76468

Timestep Collection Time: 2.17354
Timestep Consumption Time: 2.47242
PPO Batch Consumption Time: 0.28444
Total Iteration Time: 4.64596

Cumulative Model Updates: 184,598
Cumulative Timesteps: 1,539,405,234

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1539405234...
Checkpoint 1539405234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,137.52080
Policy Entropy: 3.73121
Value Function Loss: 0.02127

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13042
Policy Update Magnitude: 0.41056
Value Function Update Magnitude: 0.61294

Collected Steps per Second: 22,769.97833
Overall Steps per Second: 10,650.92981

Timestep Collection Time: 2.19675
Timestep Consumption Time: 2.49955
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.69630

Cumulative Model Updates: 184,604
Cumulative Timesteps: 1,539,455,254

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,863.68937
Policy Entropy: 3.72520
Value Function Loss: 0.02078

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.40356
Value Function Update Magnitude: 0.73634

Collected Steps per Second: 23,094.31819
Overall Steps per Second: 10,907.23244

Timestep Collection Time: 2.16573
Timestep Consumption Time: 2.41985
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.58558

Cumulative Model Updates: 184,610
Cumulative Timesteps: 1,539,505,270

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1539505270...
Checkpoint 1539505270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,863.68937
Policy Entropy: 3.71318
Value Function Loss: 0.02528

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.47029
Value Function Update Magnitude: 0.71146

Collected Steps per Second: 22,645.71316
Overall Steps per Second: 10,668.56755

Timestep Collection Time: 2.20792
Timestep Consumption Time: 2.47874
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.68666

Cumulative Model Updates: 184,616
Cumulative Timesteps: 1,539,555,270

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,863.68937
Policy Entropy: 3.71060
Value Function Loss: 0.02436

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12177
Policy Update Magnitude: 0.49374
Value Function Update Magnitude: 0.57917

Collected Steps per Second: 23,135.24843
Overall Steps per Second: 10,898.00146

Timestep Collection Time: 2.16216
Timestep Consumption Time: 2.42786
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.59002

Cumulative Model Updates: 184,622
Cumulative Timesteps: 1,539,605,292

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1539605292...
Checkpoint 1539605292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,863.68937
Policy Entropy: 3.70274
Value Function Loss: 0.02403

Mean KL Divergence: 0.01115
SB3 Clip Fraction: 0.14332
Policy Update Magnitude: 0.50477
Value Function Update Magnitude: 0.49081

Collected Steps per Second: 22,790.35529
Overall Steps per Second: 10,675.98138

Timestep Collection Time: 2.19514
Timestep Consumption Time: 2.49089
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.68603

Cumulative Model Updates: 184,628
Cumulative Timesteps: 1,539,655,320

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,863.68937
Policy Entropy: 3.68005
Value Function Loss: 0.02575

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.24995
Policy Update Magnitude: 0.40319
Value Function Update Magnitude: 0.39771

Collected Steps per Second: 23,034.58983
Overall Steps per Second: 10,895.63510

Timestep Collection Time: 2.17134
Timestep Consumption Time: 2.41912
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.59046

Cumulative Model Updates: 184,634
Cumulative Timesteps: 1,539,705,336

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1539705336...
Checkpoint 1539705336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,863.68937
Policy Entropy: 3.68661
Value Function Loss: 0.03298

Mean KL Divergence: 0.01838
SB3 Clip Fraction: 0.23813
Policy Update Magnitude: 0.36666
Value Function Update Magnitude: 0.34744

Collected Steps per Second: 22,512.59820
Overall Steps per Second: 10,612.45994

Timestep Collection Time: 2.22222
Timestep Consumption Time: 2.49186
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.71408

Cumulative Model Updates: 184,640
Cumulative Timesteps: 1,539,755,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 607,456.17837
Policy Entropy: 3.65157
Value Function Loss: 0.04764

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.20815
Policy Update Magnitude: 0.38090
Value Function Update Magnitude: 0.39050

Collected Steps per Second: 23,164.32005
Overall Steps per Second: 10,910.06726

Timestep Collection Time: 2.15866
Timestep Consumption Time: 2.42463
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.58329

Cumulative Model Updates: 184,646
Cumulative Timesteps: 1,539,805,368

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1539805368...
Checkpoint 1539805368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,120.02807
Policy Entropy: 3.63718
Value Function Loss: 0.06476

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.18899
Policy Update Magnitude: 0.44076
Value Function Update Magnitude: 0.49431

Collected Steps per Second: 22,384.63789
Overall Steps per Second: 10,652.53847

Timestep Collection Time: 2.23457
Timestep Consumption Time: 2.46103
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.69559

Cumulative Model Updates: 184,652
Cumulative Timesteps: 1,539,855,388

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 392,189.00284
Policy Entropy: 3.61656
Value Function Loss: 0.08709

Mean KL Divergence: 0.01507
SB3 Clip Fraction: 0.18183
Policy Update Magnitude: 0.49089
Value Function Update Magnitude: 0.44411

Collected Steps per Second: 22,269.04030
Overall Steps per Second: 10,858.15297

Timestep Collection Time: 2.24581
Timestep Consumption Time: 2.36013
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.60594

Cumulative Model Updates: 184,658
Cumulative Timesteps: 1,539,905,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1539905400...
Checkpoint 1539905400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295,723.33017
Policy Entropy: 3.59286
Value Function Loss: 0.09503

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.17921
Policy Update Magnitude: 0.50705
Value Function Update Magnitude: 0.44952

Collected Steps per Second: 21,749.67239
Overall Steps per Second: 10,654.66140

Timestep Collection Time: 2.29971
Timestep Consumption Time: 2.39476
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.69447

Cumulative Model Updates: 184,664
Cumulative Timesteps: 1,539,955,418

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255,973.80527
Policy Entropy: 3.57693
Value Function Loss: 0.09224

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.18002
Policy Update Magnitude: 0.51747
Value Function Update Magnitude: 0.45472

Collected Steps per Second: 22,199.08769
Overall Steps per Second: 10,848.78085

Timestep Collection Time: 2.25253
Timestep Consumption Time: 2.35666
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.60918

Cumulative Model Updates: 184,670
Cumulative Timesteps: 1,540,005,422

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1540005422...
Checkpoint 1540005422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,884.11596
Policy Entropy: 3.59285
Value Function Loss: 0.08741

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.17858
Policy Update Magnitude: 0.52820
Value Function Update Magnitude: 0.45083

Collected Steps per Second: 22,167.45352
Overall Steps per Second: 10,707.82274

Timestep Collection Time: 2.25664
Timestep Consumption Time: 2.41508
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.67172

Cumulative Model Updates: 184,676
Cumulative Timesteps: 1,540,055,446

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,969.35497
Policy Entropy: 3.62267
Value Function Loss: 0.07738

Mean KL Divergence: 0.01546
SB3 Clip Fraction: 0.18111
Policy Update Magnitude: 0.51875
Value Function Update Magnitude: 0.43563

Collected Steps per Second: 22,529.71755
Overall Steps per Second: 10,833.90060

Timestep Collection Time: 2.22000
Timestep Consumption Time: 2.39662
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.61662

Cumulative Model Updates: 184,682
Cumulative Timesteps: 1,540,105,462

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1540105462...
Checkpoint 1540105462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 754,103.15071
Policy Entropy: 3.63261
Value Function Loss: 0.07363

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.18261
Policy Update Magnitude: 0.48312
Value Function Update Magnitude: 0.42554

Collected Steps per Second: 22,347.87570
Overall Steps per Second: 10,735.78446

Timestep Collection Time: 2.23762
Timestep Consumption Time: 2.42026
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.65788

Cumulative Model Updates: 184,688
Cumulative Timesteps: 1,540,155,468

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,800.42450
Policy Entropy: 3.63917
Value Function Loss: 0.06713

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.19069
Policy Update Magnitude: 0.46107
Value Function Update Magnitude: 0.43460

Collected Steps per Second: 23,424.11591
Overall Steps per Second: 10,891.04750

Timestep Collection Time: 2.13541
Timestep Consumption Time: 2.45736
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.59276

Cumulative Model Updates: 184,694
Cumulative Timesteps: 1,540,205,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1540205488...
Checkpoint 1540205488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 307,160.67107
Policy Entropy: 3.62389
Value Function Loss: 0.06913

Mean KL Divergence: 0.01466
SB3 Clip Fraction: 0.18362
Policy Update Magnitude: 0.45165
Value Function Update Magnitude: 0.44743

Collected Steps per Second: 22,663.92353
Overall Steps per Second: 10,655.48795

Timestep Collection Time: 2.20818
Timestep Consumption Time: 2.48856
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.69673

Cumulative Model Updates: 184,700
Cumulative Timesteps: 1,540,255,534

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255,566.32950
Policy Entropy: 3.62253
Value Function Loss: 0.06789

Mean KL Divergence: 0.01404
SB3 Clip Fraction: 0.18021
Policy Update Magnitude: 0.42889
Value Function Update Magnitude: 0.44071

Collected Steps per Second: 22,935.22888
Overall Steps per Second: 10,842.48412

Timestep Collection Time: 2.18145
Timestep Consumption Time: 2.43299
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.61444

Cumulative Model Updates: 184,706
Cumulative Timesteps: 1,540,305,566

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1540305566...
Checkpoint 1540305566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 255,566.32950
Policy Entropy: 3.59834
Value Function Loss: 0.06669

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.18100
Policy Update Magnitude: 0.43524
Value Function Update Magnitude: 0.41967

Collected Steps per Second: 22,756.42254
Overall Steps per Second: 10,719.46952

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.46733
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.66460

Cumulative Model Updates: 184,712
Cumulative Timesteps: 1,540,355,568

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,268.84300
Policy Entropy: 3.59567
Value Function Loss: 0.06787

Mean KL Divergence: 0.01579
SB3 Clip Fraction: 0.18849
Policy Update Magnitude: 0.44779
Value Function Update Magnitude: 0.43786

Collected Steps per Second: 23,209.31945
Overall Steps per Second: 10,933.13720

Timestep Collection Time: 2.15439
Timestep Consumption Time: 2.41904
PPO Batch Consumption Time: 0.27692
Total Iteration Time: 4.57344

Cumulative Model Updates: 184,718
Cumulative Timesteps: 1,540,405,570

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1540405570...
Checkpoint 1540405570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,268.84300
Policy Entropy: 3.59632
Value Function Loss: 0.08377

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.19214
Policy Update Magnitude: 0.44357
Value Function Update Magnitude: 0.40597

Collected Steps per Second: 22,580.11480
Overall Steps per Second: 10,611.05663

Timestep Collection Time: 2.21575
Timestep Consumption Time: 2.49933
PPO Batch Consumption Time: 0.29188
Total Iteration Time: 4.71508

Cumulative Model Updates: 184,724
Cumulative Timesteps: 1,540,455,602

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,392.21670
Policy Entropy: 3.60682
Value Function Loss: 0.07379

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.19424
Policy Update Magnitude: 0.43233
Value Function Update Magnitude: 0.33687

Collected Steps per Second: 23,311.54028
Overall Steps per Second: 10,973.19388

Timestep Collection Time: 2.14512
Timestep Consumption Time: 2.41199
PPO Batch Consumption Time: 0.27553
Total Iteration Time: 4.55711

Cumulative Model Updates: 184,730
Cumulative Timesteps: 1,540,505,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1540505608...
Checkpoint 1540505608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749,105.75212
Policy Entropy: 3.62095
Value Function Loss: 0.06451

Mean KL Divergence: 0.01625
SB3 Clip Fraction: 0.19593
Policy Update Magnitude: 0.41698
Value Function Update Magnitude: 0.36415

Collected Steps per Second: 22,905.36534
Overall Steps per Second: 10,703.68260

Timestep Collection Time: 2.18359
Timestep Consumption Time: 2.48919
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.67278

Cumulative Model Updates: 184,736
Cumulative Timesteps: 1,540,555,624

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491,492.62822
Policy Entropy: 3.63107
Value Function Loss: 0.05890

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.20491
Policy Update Magnitude: 0.41089
Value Function Update Magnitude: 0.43836

Collected Steps per Second: 23,229.52438
Overall Steps per Second: 10,784.63851

Timestep Collection Time: 2.15312
Timestep Consumption Time: 2.48459
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.63771

Cumulative Model Updates: 184,742
Cumulative Timesteps: 1,540,605,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1540605640...
Checkpoint 1540605640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 491,492.62822
Policy Entropy: 3.63253
Value Function Loss: 0.05637

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.19827
Policy Update Magnitude: 0.41714
Value Function Update Magnitude: 0.43579

Collected Steps per Second: 22,511.59630
Overall Steps per Second: 10,647.63006

Timestep Collection Time: 2.22170
Timestep Consumption Time: 2.47550
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.69720

Cumulative Model Updates: 184,748
Cumulative Timesteps: 1,540,655,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297,120.25354
Policy Entropy: 3.64226
Value Function Loss: 0.05421

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.19360
Policy Update Magnitude: 0.42720
Value Function Update Magnitude: 0.47560

Collected Steps per Second: 23,015.51057
Overall Steps per Second: 10,882.22946

Timestep Collection Time: 2.17262
Timestep Consumption Time: 2.42239
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.59501

Cumulative Model Updates: 184,754
Cumulative Timesteps: 1,540,705,658

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1540705658...
Checkpoint 1540705658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 286,615.12497
Policy Entropy: 3.65315
Value Function Loss: 0.05316

Mean KL Divergence: 0.01543
SB3 Clip Fraction: 0.19696
Policy Update Magnitude: 0.43634
Value Function Update Magnitude: 0.51098

Collected Steps per Second: 22,501.22615
Overall Steps per Second: 10,670.36932

Timestep Collection Time: 2.22281
Timestep Consumption Time: 2.46456
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.68737

Cumulative Model Updates: 184,760
Cumulative Timesteps: 1,540,755,674

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,941.83410
Policy Entropy: 3.66580
Value Function Loss: 0.05935

Mean KL Divergence: 0.01489
SB3 Clip Fraction: 0.19176
Policy Update Magnitude: 0.46247
Value Function Update Magnitude: 0.52923

Collected Steps per Second: 22,956.35695
Overall Steps per Second: 10,855.35813

Timestep Collection Time: 2.17909
Timestep Consumption Time: 2.42914
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.60823

Cumulative Model Updates: 184,766
Cumulative Timesteps: 1,540,805,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1540805698...
Checkpoint 1540805698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,681.23398
Policy Entropy: 3.67122
Value Function Loss: 0.06519

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.17298
Policy Update Magnitude: 0.46871
Value Function Update Magnitude: 0.50953

Collected Steps per Second: 22,462.48369
Overall Steps per Second: 10,666.06737

Timestep Collection Time: 2.22611
Timestep Consumption Time: 2.46203
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.68814

Cumulative Model Updates: 184,772
Cumulative Timesteps: 1,540,855,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,697.25974
Policy Entropy: 3.66400
Value Function Loss: 0.06526

Mean KL Divergence: 0.01647
SB3 Clip Fraction: 0.19406
Policy Update Magnitude: 0.48620
Value Function Update Magnitude: 0.53282

Collected Steps per Second: 22,946.82777
Overall Steps per Second: 10,882.73492

Timestep Collection Time: 2.17982
Timestep Consumption Time: 2.41645
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.59627

Cumulative Model Updates: 184,778
Cumulative Timesteps: 1,540,905,722

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1540905722...
Checkpoint 1540905722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 199,225.99726
Policy Entropy: 3.64808
Value Function Loss: 0.07005

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.19418
Policy Update Magnitude: 0.51160
Value Function Update Magnitude: 0.53770

Collected Steps per Second: 22,354.29537
Overall Steps per Second: 10,666.22955

Timestep Collection Time: 2.23671
Timestep Consumption Time: 2.45099
PPO Batch Consumption Time: 0.28297
Total Iteration Time: 4.68769

Cumulative Model Updates: 184,784
Cumulative Timesteps: 1,540,955,722

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,212.24521
Policy Entropy: 3.65556
Value Function Loss: 0.07535

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.15904
Policy Update Magnitude: 0.52217
Value Function Update Magnitude: 0.43837

Collected Steps per Second: 22,475.21457
Overall Steps per Second: 10,649.35059

Timestep Collection Time: 2.22512
Timestep Consumption Time: 2.47094
PPO Batch Consumption Time: 0.28740
Total Iteration Time: 4.69606

Cumulative Model Updates: 184,790
Cumulative Timesteps: 1,541,005,732

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1541005732...
Checkpoint 1541005732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,364.67279
Policy Entropy: 3.65836
Value Function Loss: 0.07911

Mean KL Divergence: 0.01824
SB3 Clip Fraction: 0.20554
Policy Update Magnitude: 0.57957
Value Function Update Magnitude: 0.41437

Collected Steps per Second: 22,687.55318
Overall Steps per Second: 10,814.40366

Timestep Collection Time: 2.20420
Timestep Consumption Time: 2.42000
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.62420

Cumulative Model Updates: 184,796
Cumulative Timesteps: 1,541,055,740

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,120.27775
Policy Entropy: 3.68169
Value Function Loss: 0.07654

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.16073
Policy Update Magnitude: 0.66029
Value Function Update Magnitude: 0.43196

Collected Steps per Second: 23,083.29080
Overall Steps per Second: 10,916.27028

Timestep Collection Time: 2.16754
Timestep Consumption Time: 2.41589
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.58343

Cumulative Model Updates: 184,802
Cumulative Timesteps: 1,541,105,774

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1541105774...
Checkpoint 1541105774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268,909.25802
Policy Entropy: 3.72208
Value Function Loss: 0.06550

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.15554
Policy Update Magnitude: 0.77906
Value Function Update Magnitude: 0.62262

Collected Steps per Second: 22,720.41974
Overall Steps per Second: 10,746.28897

Timestep Collection Time: 2.20242
Timestep Consumption Time: 2.45407
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.65649

Cumulative Model Updates: 184,808
Cumulative Timesteps: 1,541,155,814

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 142,970.84970
Policy Entropy: 3.73285
Value Function Loss: 0.05554

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.17530
Policy Update Magnitude: 0.77406
Value Function Update Magnitude: 0.56444

Collected Steps per Second: 23,040.65506
Overall Steps per Second: 10,872.08440

Timestep Collection Time: 2.17034
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.59949

Cumulative Model Updates: 184,814
Cumulative Timesteps: 1,541,205,820

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1541205820...
Checkpoint 1541205820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,816.74342
Policy Entropy: 3.76210
Value Function Loss: 0.03175

Mean KL Divergence: 0.01271
SB3 Clip Fraction: 0.16008
Policy Update Magnitude: 0.70689
Value Function Update Magnitude: 0.52389

Collected Steps per Second: 22,756.61089
Overall Steps per Second: 10,666.59181

Timestep Collection Time: 2.19734
Timestep Consumption Time: 2.49057
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.68791

Cumulative Model Updates: 184,820
Cumulative Timesteps: 1,541,255,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,545.50588
Policy Entropy: 3.76240
Value Function Loss: 0.02133

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.58391
Value Function Update Magnitude: 0.62460

Collected Steps per Second: 23,115.30972
Overall Steps per Second: 10,963.55728

Timestep Collection Time: 2.16393
Timestep Consumption Time: 2.39845
PPO Batch Consumption Time: 0.27550
Total Iteration Time: 4.56239

Cumulative Model Updates: 184,826
Cumulative Timesteps: 1,541,305,844

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1541305844...
Checkpoint 1541305844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,545.50588
Policy Entropy: 3.74511
Value Function Loss: 0.02062

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.51506
Value Function Update Magnitude: 0.64390

Collected Steps per Second: 21,991.27225
Overall Steps per Second: 10,681.74924

Timestep Collection Time: 2.27472
Timestep Consumption Time: 2.40841
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.68313

Cumulative Model Updates: 184,832
Cumulative Timesteps: 1,541,355,868

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,545.50588
Policy Entropy: 3.73533
Value Function Loss: 0.02182

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13070
Policy Update Magnitude: 0.43094
Value Function Update Magnitude: 0.57589

Collected Steps per Second: 22,304.50344
Overall Steps per Second: 10,829.23321

Timestep Collection Time: 2.24215
Timestep Consumption Time: 2.37591
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.61806

Cumulative Model Updates: 184,838
Cumulative Timesteps: 1,541,405,878

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1541405878...
Checkpoint 1541405878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415,217.69250
Policy Entropy: 3.73017
Value Function Loss: 0.01961

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06607
Policy Update Magnitude: 0.49708
Value Function Update Magnitude: 0.52017

Collected Steps per Second: 22,182.49644
Overall Steps per Second: 10,603.76437

Timestep Collection Time: 2.25412
Timestep Consumption Time: 2.46138
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.71550

Cumulative Model Updates: 184,844
Cumulative Timesteps: 1,541,455,880

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,217.69250
Policy Entropy: 3.72636
Value Function Loss: 0.01977

Mean KL Divergence: 0.00597
SB3 Clip Fraction: 0.07219
Policy Update Magnitude: 0.54182
Value Function Update Magnitude: 0.49715

Collected Steps per Second: 23,262.51275
Overall Steps per Second: 10,941.21133

Timestep Collection Time: 2.14964
Timestep Consumption Time: 2.42079
PPO Batch Consumption Time: 0.28260
Total Iteration Time: 4.57043

Cumulative Model Updates: 184,850
Cumulative Timesteps: 1,541,505,886

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1541505886...
Checkpoint 1541505886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415,217.69250
Policy Entropy: 3.74124
Value Function Loss: 0.01704

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07509
Policy Update Magnitude: 0.49143
Value Function Update Magnitude: 0.45860

Collected Steps per Second: 22,651.28936
Overall Steps per Second: 10,739.77505

Timestep Collection Time: 2.20853
Timestep Consumption Time: 2.44948
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.65801

Cumulative Model Updates: 184,856
Cumulative Timesteps: 1,541,555,912

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,217.69250
Policy Entropy: 3.73789
Value Function Loss: 0.01578

Mean KL Divergence: 0.00439
SB3 Clip Fraction: 0.04885
Policy Update Magnitude: 0.43445
Value Function Update Magnitude: 0.39500

Collected Steps per Second: 23,062.14332
Overall Steps per Second: 10,758.25219

Timestep Collection Time: 2.16840
Timestep Consumption Time: 2.47994
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.64834

Cumulative Model Updates: 184,862
Cumulative Timesteps: 1,541,605,920

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1541605920...
Checkpoint 1541605920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415,217.69250
Policy Entropy: 3.73450
Value Function Loss: 0.01457

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04866
Policy Update Magnitude: 0.40193
Value Function Update Magnitude: 0.30740

Collected Steps per Second: 22,670.61063
Overall Steps per Second: 10,643.54016

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.49219
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.69769

Cumulative Model Updates: 184,868
Cumulative Timesteps: 1,541,655,920

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,217.69250
Policy Entropy: 3.73060
Value Function Loss: 0.01330

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06211
Policy Update Magnitude: 0.37370
Value Function Update Magnitude: 0.30134

Collected Steps per Second: 23,096.71324
Overall Steps per Second: 10,875.70835

Timestep Collection Time: 2.16689
Timestep Consumption Time: 2.43493
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.60182

Cumulative Model Updates: 184,874
Cumulative Timesteps: 1,541,705,968

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1541705968...
Checkpoint 1541705968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415,217.69250
Policy Entropy: 3.73572
Value Function Loss: 0.01299

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.08075
Policy Update Magnitude: 0.32365
Value Function Update Magnitude: 0.30500

Collected Steps per Second: 22,514.81707
Overall Steps per Second: 10,693.61951

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.45728
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.68017

Cumulative Model Updates: 184,880
Cumulative Timesteps: 1,541,756,016

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,217.69250
Policy Entropy: 3.73803
Value Function Loss: 0.01229

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05986
Policy Update Magnitude: 0.33487
Value Function Update Magnitude: 0.28860

Collected Steps per Second: 22,626.67938
Overall Steps per Second: 10,805.24158

Timestep Collection Time: 2.21005
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.62794

Cumulative Model Updates: 184,886
Cumulative Timesteps: 1,541,806,022

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1541806022...
Checkpoint 1541806022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 415,217.69250
Policy Entropy: 3.73175
Value Function Loss: 0.01209

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04149
Policy Update Magnitude: 0.36535
Value Function Update Magnitude: 0.28779

Collected Steps per Second: 22,533.78875
Overall Steps per Second: 10,748.83154

Timestep Collection Time: 2.22022
Timestep Consumption Time: 2.43424
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.65446

Cumulative Model Updates: 184,892
Cumulative Timesteps: 1,541,856,052

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 415,217.69250
Policy Entropy: 3.73516
Value Function Loss: 0.01229

Mean KL Divergence: 0.00400
SB3 Clip Fraction: 0.04162
Policy Update Magnitude: 0.39617
Value Function Update Magnitude: 0.28914

Collected Steps per Second: 23,027.53989
Overall Steps per Second: 10,886.69337

Timestep Collection Time: 2.17157
Timestep Consumption Time: 2.42174
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.59331

Cumulative Model Updates: 184,898
Cumulative Timesteps: 1,541,906,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1541906058...
Checkpoint 1541906058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 425,602.70922
Policy Entropy: 3.72512
Value Function Loss: 0.01771

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06411
Policy Update Magnitude: 0.45314
Value Function Update Magnitude: 0.39353

Collected Steps per Second: 21,951.02594
Overall Steps per Second: 10,679.55896

Timestep Collection Time: 2.27807
Timestep Consumption Time: 2.40433
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.68240

Cumulative Model Updates: 184,904
Cumulative Timesteps: 1,541,956,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,213.42901
Policy Entropy: 3.71827
Value Function Loss: 0.01887

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05746
Policy Update Magnitude: 0.51855
Value Function Update Magnitude: 0.50129

Collected Steps per Second: 22,455.20373
Overall Steps per Second: 10,951.45847

Timestep Collection Time: 2.22764
Timestep Consumption Time: 2.33998
PPO Batch Consumption Time: 0.27608
Total Iteration Time: 4.56761

Cumulative Model Updates: 184,910
Cumulative Timesteps: 1,542,006,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1542006086...
Checkpoint 1542006086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183,213.42901
Policy Entropy: 3.70430
Value Function Loss: 0.02321

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.50474
Value Function Update Magnitude: 0.52446

Collected Steps per Second: 22,081.78632
Overall Steps per Second: 10,549.15178

Timestep Collection Time: 2.26485
Timestep Consumption Time: 2.47600
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.74086

Cumulative Model Updates: 184,916
Cumulative Timesteps: 1,542,056,098

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,213.42901
Policy Entropy: 3.70213
Value Function Loss: 0.02042

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14303
Policy Update Magnitude: 0.44785
Value Function Update Magnitude: 0.51153

Collected Steps per Second: 22,938.26721
Overall Steps per Second: 10,918.11523

Timestep Collection Time: 2.18072
Timestep Consumption Time: 2.40084
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.58156

Cumulative Model Updates: 184,922
Cumulative Timesteps: 1,542,106,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1542106120...
Checkpoint 1542106120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 353,817.11159
Policy Entropy: 3.68809
Value Function Loss: 0.04328

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.15468
Policy Update Magnitude: 0.49856
Value Function Update Magnitude: 0.47886

Collected Steps per Second: 22,674.90550
Overall Steps per Second: 10,706.96098

Timestep Collection Time: 2.20632
Timestep Consumption Time: 2.46616
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.67247

Cumulative Model Updates: 184,928
Cumulative Timesteps: 1,542,156,148

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,771.51667
Policy Entropy: 3.67979
Value Function Loss: 0.05079

Mean KL Divergence: 0.01433
SB3 Clip Fraction: 0.17037
Policy Update Magnitude: 0.71600
Value Function Update Magnitude: 0.53718

Collected Steps per Second: 22,863.18581
Overall Steps per Second: 10,805.44194

Timestep Collection Time: 2.18815
Timestep Consumption Time: 2.44174
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.62989

Cumulative Model Updates: 184,934
Cumulative Timesteps: 1,542,206,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1542206176...
Checkpoint 1542206176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,566.61322
Policy Entropy: 3.66282
Value Function Loss: 0.06650

Mean KL Divergence: 0.02551
SB3 Clip Fraction: 0.24013
Policy Update Magnitude: 0.72123
Value Function Update Magnitude: 0.61202

Collected Steps per Second: 22,489.44868
Overall Steps per Second: 10,711.17196

Timestep Collection Time: 2.22380
Timestep Consumption Time: 2.44535
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.66914

Cumulative Model Updates: 184,940
Cumulative Timesteps: 1,542,256,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,197.67439
Policy Entropy: 3.67347
Value Function Loss: 0.08411

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.14514
Policy Update Magnitude: 0.84082
Value Function Update Magnitude: 0.47242

Collected Steps per Second: 22,871.86796
Overall Steps per Second: 10,835.24822

Timestep Collection Time: 2.18635
Timestep Consumption Time: 2.42877
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.61512

Cumulative Model Updates: 184,946
Cumulative Timesteps: 1,542,306,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1542306194...
Checkpoint 1542306194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,051.02985
Policy Entropy: 3.66948
Value Function Loss: 0.08075

Mean KL Divergence: 0.01710
SB3 Clip Fraction: 0.18775
Policy Update Magnitude: 0.86814
Value Function Update Magnitude: 0.43215

Collected Steps per Second: 22,442.30885
Overall Steps per Second: 10,721.41425

Timestep Collection Time: 2.22865
Timestep Consumption Time: 2.43641
PPO Batch Consumption Time: 0.28205
Total Iteration Time: 4.66506

Cumulative Model Updates: 184,952
Cumulative Timesteps: 1,542,356,210

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,494.14816
Policy Entropy: 3.68678
Value Function Loss: 0.06574

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.20544
Policy Update Magnitude: 0.84880
Value Function Update Magnitude: 0.46790

Collected Steps per Second: 22,903.92383
Overall Steps per Second: 10,854.43674

Timestep Collection Time: 2.18443
Timestep Consumption Time: 2.42493
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.60936

Cumulative Model Updates: 184,958
Cumulative Timesteps: 1,542,406,242

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1542406242...
Checkpoint 1542406242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.69101
Value Function Loss: 0.04421

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.18695
Policy Update Magnitude: 0.71182
Value Function Update Magnitude: 0.49277

Collected Steps per Second: 22,672.92754
Overall Steps per Second: 10,641.43259

Timestep Collection Time: 2.20589
Timestep Consumption Time: 2.49404
PPO Batch Consumption Time: 0.28531
Total Iteration Time: 4.69993

Cumulative Model Updates: 184,964
Cumulative Timesteps: 1,542,456,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.67973
Value Function Loss: 0.03104

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13471
Policy Update Magnitude: 0.70864
Value Function Update Magnitude: 0.54809

Collected Steps per Second: 23,267.04184
Overall Steps per Second: 10,923.59326

Timestep Collection Time: 2.14913
Timestep Consumption Time: 2.42848
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.57761

Cumulative Model Updates: 184,970
Cumulative Timesteps: 1,542,506,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1542506260...
Checkpoint 1542506260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.66751
Value Function Loss: 0.02839

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.65945
Value Function Update Magnitude: 0.67980

Collected Steps per Second: 23,091.56331
Overall Steps per Second: 10,761.40003

Timestep Collection Time: 2.16616
Timestep Consumption Time: 2.48193
PPO Batch Consumption Time: 0.29058
Total Iteration Time: 4.64809

Cumulative Model Updates: 184,976
Cumulative Timesteps: 1,542,556,280

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.67726
Value Function Loss: 0.02428

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.16095
Policy Update Magnitude: 0.60176
Value Function Update Magnitude: 0.71698

Collected Steps per Second: 23,099.09946
Overall Steps per Second: 10,811.49612

Timestep Collection Time: 2.16485
Timestep Consumption Time: 2.46042
PPO Batch Consumption Time: 0.28236
Total Iteration Time: 4.62526

Cumulative Model Updates: 184,982
Cumulative Timesteps: 1,542,606,286

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1542606286...
Checkpoint 1542606286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.67799
Value Function Loss: 0.02501

Mean KL Divergence: 0.01612
SB3 Clip Fraction: 0.20908
Policy Update Magnitude: 0.50102
Value Function Update Magnitude: 0.64936

Collected Steps per Second: 21,976.36300
Overall Steps per Second: 10,662.23459

Timestep Collection Time: 2.27599
Timestep Consumption Time: 2.41515
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.69114

Cumulative Model Updates: 184,988
Cumulative Timesteps: 1,542,656,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.66945
Value Function Loss: 0.02336

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.14909
Policy Update Magnitude: 0.42865
Value Function Update Magnitude: 0.62401

Collected Steps per Second: 22,047.84538
Overall Steps per Second: 10,847.72035

Timestep Collection Time: 2.26861
Timestep Consumption Time: 2.34231
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.61092

Cumulative Model Updates: 184,994
Cumulative Timesteps: 1,542,706,322

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1542706322...
Checkpoint 1542706322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.68331
Value Function Loss: 0.02243

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.39627
Value Function Update Magnitude: 0.59888

Collected Steps per Second: 22,182.45790
Overall Steps per Second: 10,670.81960

Timestep Collection Time: 2.25439
Timestep Consumption Time: 2.43203
PPO Batch Consumption Time: 0.28295
Total Iteration Time: 4.68643

Cumulative Model Updates: 185,000
Cumulative Timesteps: 1,542,756,330

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.69034
Value Function Loss: 0.02096

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13562
Policy Update Magnitude: 0.39019
Value Function Update Magnitude: 0.54076

Collected Steps per Second: 22,843.95923
Overall Steps per Second: 10,895.95478

Timestep Collection Time: 2.19008
Timestep Consumption Time: 2.40154
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.59161

Cumulative Model Updates: 185,006
Cumulative Timesteps: 1,542,806,360

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1542806360...
Checkpoint 1542806360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.69582
Value Function Loss: 0.01964

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12662
Policy Update Magnitude: 0.39847
Value Function Update Magnitude: 0.64183

Collected Steps per Second: 22,891.48296
Overall Steps per Second: 10,764.65550

Timestep Collection Time: 2.18527
Timestep Consumption Time: 2.46179
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.64706

Cumulative Model Updates: 185,012
Cumulative Timesteps: 1,542,856,384

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.68723
Value Function Loss: 0.01868

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13826
Policy Update Magnitude: 0.36391
Value Function Update Magnitude: 0.59265

Collected Steps per Second: 23,262.80522
Overall Steps per Second: 10,807.75077

Timestep Collection Time: 2.14953
Timestep Consumption Time: 2.47715
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.62668

Cumulative Model Updates: 185,018
Cumulative Timesteps: 1,542,906,388

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1542906388...
Checkpoint 1542906388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.67947
Value Function Loss: 0.01847

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.13310
Policy Update Magnitude: 0.32087
Value Function Update Magnitude: 0.46569

Collected Steps per Second: 22,970.96751
Overall Steps per Second: 10,702.84215

Timestep Collection Time: 2.17771
Timestep Consumption Time: 2.49619
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.67390

Cumulative Model Updates: 185,024
Cumulative Timesteps: 1,542,956,412

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.69072
Value Function Loss: 0.01676

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.30860
Value Function Update Magnitude: 0.47405

Collected Steps per Second: 23,002.44057
Overall Steps per Second: 10,816.71729

Timestep Collection Time: 2.17499
Timestep Consumption Time: 2.45026
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.62525

Cumulative Model Updates: 185,030
Cumulative Timesteps: 1,543,006,442

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1543006442...
Checkpoint 1543006442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.68208
Value Function Loss: 0.01764

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12412
Policy Update Magnitude: 0.31071
Value Function Update Magnitude: 0.49252

Collected Steps per Second: 22,939.00917
Overall Steps per Second: 10,704.11474

Timestep Collection Time: 2.17969
Timestep Consumption Time: 2.49141
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.67110

Cumulative Model Updates: 185,036
Cumulative Timesteps: 1,543,056,442

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.67382
Value Function Loss: 0.01754

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12251
Policy Update Magnitude: 0.33886
Value Function Update Magnitude: 0.47591

Collected Steps per Second: 23,351.84328
Overall Steps per Second: 10,902.57242

Timestep Collection Time: 2.14227
Timestep Consumption Time: 2.44619
PPO Batch Consumption Time: 0.28150
Total Iteration Time: 4.58846

Cumulative Model Updates: 185,042
Cumulative Timesteps: 1,543,106,468

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1543106468...
Checkpoint 1543106468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.67046
Value Function Loss: 0.01903

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.35440
Value Function Update Magnitude: 0.39235

Collected Steps per Second: 22,981.24935
Overall Steps per Second: 10,696.49863

Timestep Collection Time: 2.17612
Timestep Consumption Time: 2.49924
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.67536

Cumulative Model Updates: 185,048
Cumulative Timesteps: 1,543,156,478

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.68518
Value Function Loss: 0.01659

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12913
Policy Update Magnitude: 0.32775
Value Function Update Magnitude: 0.33593

Collected Steps per Second: 22,507.86295
Overall Steps per Second: 10,767.62345

Timestep Collection Time: 2.22251
Timestep Consumption Time: 2.42327
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.64578

Cumulative Model Updates: 185,054
Cumulative Timesteps: 1,543,206,502

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1543206502...
Checkpoint 1543206502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.68750
Value Function Loss: 0.01602

Mean KL Divergence: 0.00846
SB3 Clip Fraction: 0.11208
Policy Update Magnitude: 0.33751
Value Function Update Magnitude: 0.30655

Collected Steps per Second: 22,748.25128
Overall Steps per Second: 10,673.83491

Timestep Collection Time: 2.19867
Timestep Consumption Time: 2.48718
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 4.68585

Cumulative Model Updates: 185,060
Cumulative Timesteps: 1,543,256,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.67858
Value Function Loss: 0.01607

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.35876
Value Function Update Magnitude: 0.36209

Collected Steps per Second: 22,734.31229
Overall Steps per Second: 10,683.56812

Timestep Collection Time: 2.20055
Timestep Consumption Time: 2.48215
PPO Batch Consumption Time: 0.28729
Total Iteration Time: 4.68271

Cumulative Model Updates: 185,066
Cumulative Timesteps: 1,543,306,546

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1543306546...
Checkpoint 1543306546 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.65749
Value Function Loss: 0.02071

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.16102
Policy Update Magnitude: 0.37538
Value Function Update Magnitude: 0.31326

Collected Steps per Second: 23,105.19990
Overall Steps per Second: 10,942.54303

Timestep Collection Time: 2.16453
Timestep Consumption Time: 2.40588
PPO Batch Consumption Time: 0.27622
Total Iteration Time: 4.57042

Cumulative Model Updates: 185,072
Cumulative Timesteps: 1,543,356,558

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.65446
Value Function Loss: 0.02104

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.17599
Policy Update Magnitude: 0.39990
Value Function Update Magnitude: 0.36407

Collected Steps per Second: 23,157.14118
Overall Steps per Second: 10,828.43433

Timestep Collection Time: 2.15985
Timestep Consumption Time: 2.45910
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.61895

Cumulative Model Updates: 185,078
Cumulative Timesteps: 1,543,406,574

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1543406574...
Checkpoint 1543406574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.66373
Value Function Loss: 0.02429

Mean KL Divergence: 0.01391
SB3 Clip Fraction: 0.17894
Policy Update Magnitude: 0.40395
Value Function Update Magnitude: 0.34055

Collected Steps per Second: 22,808.48795
Overall Steps per Second: 10,654.65444

Timestep Collection Time: 2.19322
Timestep Consumption Time: 2.50182
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.69504

Cumulative Model Updates: 185,084
Cumulative Timesteps: 1,543,456,598

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.65494
Value Function Loss: 0.02513

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.15933
Policy Update Magnitude: 0.44187
Value Function Update Magnitude: 0.30941

Collected Steps per Second: 21,980.07385
Overall Steps per Second: 10,696.63281

Timestep Collection Time: 2.27506
Timestep Consumption Time: 2.39987
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.67493

Cumulative Model Updates: 185,090
Cumulative Timesteps: 1,543,506,604

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1543506604...
Checkpoint 1543506604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.66721
Value Function Loss: 0.02332

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.11523
Policy Update Magnitude: 0.56763
Value Function Update Magnitude: 0.43022

Collected Steps per Second: 21,911.21079
Overall Steps per Second: 10,815.19839

Timestep Collection Time: 2.28267
Timestep Consumption Time: 2.34194
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.62460

Cumulative Model Updates: 185,096
Cumulative Timesteps: 1,543,556,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,661.29772
Policy Entropy: 3.67204
Value Function Loss: 0.02064

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15664
Policy Update Magnitude: 0.55881
Value Function Update Magnitude: 0.44115

Collected Steps per Second: 22,167.67525
Overall Steps per Second: 10,559.23202

Timestep Collection Time: 2.25608
Timestep Consumption Time: 2.48025
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.73633

Cumulative Model Updates: 185,102
Cumulative Timesteps: 1,543,606,632

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1543606632...
Checkpoint 1543606632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,077.93167
Policy Entropy: 3.67508
Value Function Loss: 0.02422

Mean KL Divergence: 0.00618
SB3 Clip Fraction: 0.07496
Policy Update Magnitude: 0.55843
Value Function Update Magnitude: 0.44898

Collected Steps per Second: 22,775.04961
Overall Steps per Second: 10,769.75897

Timestep Collection Time: 2.19653
Timestep Consumption Time: 2.44852
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.64504

Cumulative Model Updates: 185,108
Cumulative Timesteps: 1,543,656,658

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433,763.91150
Policy Entropy: 3.65278
Value Function Loss: 0.03030

Mean KL Divergence: 0.01427
SB3 Clip Fraction: 0.18196
Policy Update Magnitude: 0.57857
Value Function Update Magnitude: 0.53832

Collected Steps per Second: 23,076.66676
Overall Steps per Second: 10,801.28761

Timestep Collection Time: 2.16678
Timestep Consumption Time: 2.46249
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.62926

Cumulative Model Updates: 185,114
Cumulative Timesteps: 1,543,706,660

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1543706660...
Checkpoint 1543706660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 159,752.64007
Policy Entropy: 3.65638
Value Function Loss: 0.05928

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.19341
Policy Update Magnitude: 0.61154
Value Function Update Magnitude: 0.49368

Collected Steps per Second: 22,906.20455
Overall Steps per Second: 10,942.39734

Timestep Collection Time: 2.18351
Timestep Consumption Time: 2.38733
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.57084

Cumulative Model Updates: 185,120
Cumulative Timesteps: 1,543,756,676

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,609.91481
Policy Entropy: 3.68446
Value Function Loss: 0.05805

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.14861
Policy Update Magnitude: 0.74315
Value Function Update Magnitude: 0.45185

Collected Steps per Second: 22,789.76810
Overall Steps per Second: 10,674.47530

Timestep Collection Time: 2.19511
Timestep Consumption Time: 2.49140
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.68651

Cumulative Model Updates: 185,126
Cumulative Timesteps: 1,543,806,702

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1543806702...
Checkpoint 1543806702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,115.63126
Policy Entropy: 3.68604
Value Function Loss: 0.06538

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.77042
Value Function Update Magnitude: 0.46293

Collected Steps per Second: 22,722.38892
Overall Steps per Second: 10,677.66025

Timestep Collection Time: 2.20162
Timestep Consumption Time: 2.48349
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.68511

Cumulative Model Updates: 185,132
Cumulative Timesteps: 1,543,856,728

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278,185.04709
Policy Entropy: 3.69762
Value Function Loss: 0.04081

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.16914
Policy Update Magnitude: 0.63162
Value Function Update Magnitude: 0.44327

Collected Steps per Second: 23,164.04860
Overall Steps per Second: 10,729.74333

Timestep Collection Time: 2.15912
Timestep Consumption Time: 2.50213
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.66125

Cumulative Model Updates: 185,138
Cumulative Timesteps: 1,543,906,742

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1543906742...
Checkpoint 1543906742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278,185.04709
Policy Entropy: 3.67115
Value Function Loss: 0.03107

Mean KL Divergence: 0.01371
SB3 Clip Fraction: 0.17367
Policy Update Magnitude: 0.54270
Value Function Update Magnitude: 0.54248

Collected Steps per Second: 22,852.81431
Overall Steps per Second: 10,683.34379

Timestep Collection Time: 2.18879
Timestep Consumption Time: 2.49327
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.68205

Cumulative Model Updates: 185,144
Cumulative Timesteps: 1,543,956,762

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278,185.04709
Policy Entropy: 3.68238
Value Function Loss: 0.02488

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.18327
Policy Update Magnitude: 0.45073
Value Function Update Magnitude: 0.41738

Collected Steps per Second: 22,885.98084
Overall Steps per Second: 10,817.32506

Timestep Collection Time: 2.18553
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.62388

Cumulative Model Updates: 185,150
Cumulative Timesteps: 1,544,006,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1544006780...
Checkpoint 1544006780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278,185.04709
Policy Entropy: 3.68917
Value Function Loss: 0.01900

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07433
Policy Update Magnitude: 0.47654
Value Function Update Magnitude: 0.35814

Collected Steps per Second: 22,853.60409
Overall Steps per Second: 10,692.43167

Timestep Collection Time: 2.18898
Timestep Consumption Time: 2.48966
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.67864

Cumulative Model Updates: 185,156
Cumulative Timesteps: 1,544,056,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278,185.04709
Policy Entropy: 3.70436
Value Function Loss: 0.01741

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05516
Policy Update Magnitude: 0.45451
Value Function Update Magnitude: 0.30234

Collected Steps per Second: 22,982.03453
Overall Steps per Second: 10,894.92621

Timestep Collection Time: 2.17657
Timestep Consumption Time: 2.41474
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.59131

Cumulative Model Updates: 185,162
Cumulative Timesteps: 1,544,106,828

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1544106828...
Checkpoint 1544106828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 278,185.04709
Policy Entropy: 3.70860
Value Function Loss: 0.01563

Mean KL Divergence: 0.00421
SB3 Clip Fraction: 0.04511
Policy Update Magnitude: 0.40179
Value Function Update Magnitude: 0.26530

Collected Steps per Second: 22,645.82598
Overall Steps per Second: 10,687.95434

Timestep Collection Time: 2.20791
Timestep Consumption Time: 2.47025
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.67816

Cumulative Model Updates: 185,168
Cumulative Timesteps: 1,544,156,828

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 278,185.04709
Policy Entropy: 3.70342
Value Function Loss: 0.01517

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05056
Policy Update Magnitude: 0.38478
Value Function Update Magnitude: 0.30493

Collected Steps per Second: 23,054.53360
Overall Steps per Second: 10,910.97650

Timestep Collection Time: 2.17077
Timestep Consumption Time: 2.41599
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.58676

Cumulative Model Updates: 185,174
Cumulative Timesteps: 1,544,206,874

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1544206874...
Checkpoint 1544206874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,356.77122
Policy Entropy: 3.70429
Value Function Loss: 0.01721

Mean KL Divergence: 0.00394
SB3 Clip Fraction: 0.04073
Policy Update Magnitude: 0.43433
Value Function Update Magnitude: 0.42045

Collected Steps per Second: 22,660.46922
Overall Steps per Second: 10,619.26188

Timestep Collection Time: 2.20702
Timestep Consumption Time: 2.50254
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.70956

Cumulative Model Updates: 185,180
Cumulative Timesteps: 1,544,256,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,356.77122
Policy Entropy: 3.70113
Value Function Loss: 0.01545

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04830
Policy Update Magnitude: 0.48464
Value Function Update Magnitude: 0.51472

Collected Steps per Second: 23,148.06243
Overall Steps per Second: 10,893.23765

Timestep Collection Time: 2.16035
Timestep Consumption Time: 2.43038
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.59074

Cumulative Model Updates: 185,186
Cumulative Timesteps: 1,544,306,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1544306894...
Checkpoint 1544306894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 216,356.77122
Policy Entropy: 3.70381
Value Function Loss: 0.01516

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15098
Policy Update Magnitude: 0.44614
Value Function Update Magnitude: 0.49362

Collected Steps per Second: 23,095.68747
Overall Steps per Second: 10,757.64760

Timestep Collection Time: 2.16560
Timestep Consumption Time: 2.48374
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.64934

Cumulative Model Updates: 185,192
Cumulative Timesteps: 1,544,356,910

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 216,356.77122
Policy Entropy: 3.70752
Value Function Loss: 0.01297

Mean KL Divergence: 0.01799
SB3 Clip Fraction: 0.23219
Policy Update Magnitude: 0.35067
Value Function Update Magnitude: 0.46600

Collected Steps per Second: 21,705.53792
Overall Steps per Second: 10,743.17139

Timestep Collection Time: 2.30402
Timestep Consumption Time: 2.35103
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.65505

Cumulative Model Updates: 185,198
Cumulative Timesteps: 1,544,406,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1544406920...
Checkpoint 1544406920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,271.85173
Policy Entropy: 3.72165
Value Function Loss: 0.01578

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15120
Policy Update Magnitude: 0.40221
Value Function Update Magnitude: 0.58708

Collected Steps per Second: 22,175.58429
Overall Steps per Second: 10,679.15031

Timestep Collection Time: 2.25491
Timestep Consumption Time: 2.42748
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.68239

Cumulative Model Updates: 185,204
Cumulative Timesteps: 1,544,456,924

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,574.66306
Policy Entropy: 3.70676
Value Function Loss: 0.02056

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15405
Policy Update Magnitude: 0.43000
Value Function Update Magnitude: 0.69489

Collected Steps per Second: 22,651.26616
Overall Steps per Second: 10,938.79537

Timestep Collection Time: 2.20782
Timestep Consumption Time: 2.36398
PPO Batch Consumption Time: 0.28127
Total Iteration Time: 4.57180

Cumulative Model Updates: 185,210
Cumulative Timesteps: 1,544,506,934

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1544506934...
Checkpoint 1544506934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 821,239.02416
Policy Entropy: 3.70466
Value Function Loss: 0.02360

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.17241
Policy Update Magnitude: 0.45689
Value Function Update Magnitude: 0.73761

Collected Steps per Second: 22,428.23328
Overall Steps per Second: 10,629.66983

Timestep Collection Time: 2.23058
Timestep Consumption Time: 2.47587
PPO Batch Consumption Time: 0.29232
Total Iteration Time: 4.70645

Cumulative Model Updates: 185,216
Cumulative Timesteps: 1,544,556,962

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743,135.82070
Policy Entropy: 3.70732
Value Function Loss: 0.02222

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.17321
Policy Update Magnitude: 0.45951
Value Function Update Magnitude: 0.79310

Collected Steps per Second: 22,615.86083
Overall Steps per Second: 10,854.98603

Timestep Collection Time: 2.21084
Timestep Consumption Time: 2.39534
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.60618

Cumulative Model Updates: 185,222
Cumulative Timesteps: 1,544,606,962

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1544606962...
Checkpoint 1544606962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 743,135.82070
Policy Entropy: 3.68795
Value Function Loss: 0.02408

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15277
Policy Update Magnitude: 0.42724
Value Function Update Magnitude: 0.69197

Collected Steps per Second: 22,635.52921
Overall Steps per Second: 10,687.31434

Timestep Collection Time: 2.21068
Timestep Consumption Time: 2.47150
PPO Batch Consumption Time: 0.28559
Total Iteration Time: 4.68219

Cumulative Model Updates: 185,228
Cumulative Timesteps: 1,544,657,002

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 743,135.82070
Policy Entropy: 3.69370
Value Function Loss: 0.02531

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14325
Policy Update Magnitude: 0.45373
Value Function Update Magnitude: 0.57895

Collected Steps per Second: 23,012.26297
Overall Steps per Second: 10,873.79614

Timestep Collection Time: 2.17284
Timestep Consumption Time: 2.42555
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.59839

Cumulative Model Updates: 185,234
Cumulative Timesteps: 1,544,707,004

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1544707004...
Checkpoint 1544707004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911,565.04796
Policy Entropy: 3.67612
Value Function Loss: 0.02926

Mean KL Divergence: 0.01200
SB3 Clip Fraction: 0.15447
Policy Update Magnitude: 0.50045
Value Function Update Magnitude: 0.47047

Collected Steps per Second: 22,789.11774
Overall Steps per Second: 10,685.53526

Timestep Collection Time: 2.19482
Timestep Consumption Time: 2.48609
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.68091

Cumulative Model Updates: 185,240
Cumulative Timesteps: 1,544,757,022

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911,565.04796
Policy Entropy: 3.70555
Value Function Loss: 0.02413

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16724
Policy Update Magnitude: 0.49971
Value Function Update Magnitude: 0.44283

Collected Steps per Second: 22,944.48049
Overall Steps per Second: 10,865.78075

Timestep Collection Time: 2.17952
Timestep Consumption Time: 2.42282
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.60234

Cumulative Model Updates: 185,246
Cumulative Timesteps: 1,544,807,030

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1544807030...
Checkpoint 1544807030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911,565.04796
Policy Entropy: 3.69223
Value Function Loss: 0.02106

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11540
Policy Update Magnitude: 0.46720
Value Function Update Magnitude: 0.41846

Collected Steps per Second: 22,742.67304
Overall Steps per Second: 10,660.58782

Timestep Collection Time: 2.19860
Timestep Consumption Time: 2.49176
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.69036

Cumulative Model Updates: 185,252
Cumulative Timesteps: 1,544,857,032

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911,565.04796
Policy Entropy: 3.69481
Value Function Loss: 0.01712

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06117
Policy Update Magnitude: 0.49223
Value Function Update Magnitude: 0.40497

Collected Steps per Second: 22,738.10777
Overall Steps per Second: 10,825.59164

Timestep Collection Time: 2.19930
Timestep Consumption Time: 2.42012
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.61942

Cumulative Model Updates: 185,258
Cumulative Timesteps: 1,544,907,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1544907040...
Checkpoint 1544907040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911,565.04796
Policy Entropy: 3.68516
Value Function Loss: 0.01691

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06156
Policy Update Magnitude: 0.53250
Value Function Update Magnitude: 0.49154

Collected Steps per Second: 21,787.52229
Overall Steps per Second: 10,729.00069

Timestep Collection Time: 2.29517
Timestep Consumption Time: 2.36566
PPO Batch Consumption Time: 0.28162
Total Iteration Time: 4.66083

Cumulative Model Updates: 185,264
Cumulative Timesteps: 1,544,957,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911,565.04796
Policy Entropy: 3.69144
Value Function Loss: 0.01900

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06344
Policy Update Magnitude: 0.57403
Value Function Update Magnitude: 0.50135

Collected Steps per Second: 22,346.34076
Overall Steps per Second: 10,847.81829

Timestep Collection Time: 2.23822
Timestep Consumption Time: 2.37248
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.61070

Cumulative Model Updates: 185,270
Cumulative Timesteps: 1,545,007,062

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1545007062...
Checkpoint 1545007062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 911,565.04796
Policy Entropy: 3.70059
Value Function Loss: 0.02066

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05521
Policy Update Magnitude: 0.63196
Value Function Update Magnitude: 0.42322

Collected Steps per Second: 22,151.73446
Overall Steps per Second: 10,671.56112

Timestep Collection Time: 2.25779
Timestep Consumption Time: 2.42887
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.68666

Cumulative Model Updates: 185,276
Cumulative Timesteps: 1,545,057,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 911,565.04796
Policy Entropy: 3.69955
Value Function Loss: 0.02301

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06210
Policy Update Magnitude: 0.66046
Value Function Update Magnitude: 0.38191

Collected Steps per Second: 22,978.89428
Overall Steps per Second: 10,916.51659

Timestep Collection Time: 2.17652
Timestep Consumption Time: 2.40498
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.58150

Cumulative Model Updates: 185,282
Cumulative Timesteps: 1,545,107,090

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1545107090...
Checkpoint 1545107090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 708,465.66097
Policy Entropy: 3.70570
Value Function Loss: 0.02175

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07477
Policy Update Magnitude: 0.61293
Value Function Update Magnitude: 0.42545

Collected Steps per Second: 22,752.02381
Overall Steps per Second: 10,719.53308

Timestep Collection Time: 2.19963
Timestep Consumption Time: 2.46904
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.66867

Cumulative Model Updates: 185,288
Cumulative Timesteps: 1,545,157,136

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464,850.78478
Policy Entropy: 3.71422
Value Function Loss: 0.02085

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06238
Policy Update Magnitude: 0.59975
Value Function Update Magnitude: 0.53690

Collected Steps per Second: 23,212.10066
Overall Steps per Second: 10,833.45568

Timestep Collection Time: 2.15474
Timestep Consumption Time: 2.46207
PPO Batch Consumption Time: 0.28418
Total Iteration Time: 4.61681

Cumulative Model Updates: 185,294
Cumulative Timesteps: 1,545,207,152

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1545207152...
Checkpoint 1545207152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,850.78478
Policy Entropy: 3.71610
Value Function Loss: 0.01947

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.08066
Policy Update Magnitude: 0.55939
Value Function Update Magnitude: 0.52763

Collected Steps per Second: 22,932.30125
Overall Steps per Second: 10,703.18867

Timestep Collection Time: 2.18112
Timestep Consumption Time: 2.49207
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.67319

Cumulative Model Updates: 185,300
Cumulative Timesteps: 1,545,257,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464,850.78478
Policy Entropy: 3.70613
Value Function Loss: 0.02149

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05756
Policy Update Magnitude: 0.54289
Value Function Update Magnitude: 0.48331

Collected Steps per Second: 22,983.47741
Overall Steps per Second: 10,908.75376

Timestep Collection Time: 2.17617
Timestep Consumption Time: 2.40877
PPO Batch Consumption Time: 0.27551
Total Iteration Time: 4.58494

Cumulative Model Updates: 185,306
Cumulative Timesteps: 1,545,307,186

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1545307186...
Checkpoint 1545307186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,850.78478
Policy Entropy: 3.69275
Value Function Loss: 0.01982

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05535
Policy Update Magnitude: 0.58934
Value Function Update Magnitude: 0.46486

Collected Steps per Second: 22,808.46334
Overall Steps per Second: 10,732.26183

Timestep Collection Time: 2.19366
Timestep Consumption Time: 2.46836
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.66202

Cumulative Model Updates: 185,312
Cumulative Timesteps: 1,545,357,220

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464,850.78478
Policy Entropy: 3.69302
Value Function Loss: 0.01891

Mean KL Divergence: 0.00533
SB3 Clip Fraction: 0.06078
Policy Update Magnitude: 0.58470
Value Function Update Magnitude: 0.41950

Collected Steps per Second: 23,126.21447
Overall Steps per Second: 10,777.18512

Timestep Collection Time: 2.16309
Timestep Consumption Time: 2.47857
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.64166

Cumulative Model Updates: 185,318
Cumulative Timesteps: 1,545,407,244

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1545407244...
Checkpoint 1545407244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 464,850.78478
Policy Entropy: 3.69469
Value Function Loss: 0.01706

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15531
Policy Update Magnitude: 0.50969
Value Function Update Magnitude: 0.40632

Collected Steps per Second: 22,880.58318
Overall Steps per Second: 10,693.02024

Timestep Collection Time: 2.18622
Timestep Consumption Time: 2.49178
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.67800

Cumulative Model Updates: 185,324
Cumulative Timesteps: 1,545,457,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 464,850.78478
Policy Entropy: 3.67911
Value Function Loss: 0.01845

Mean KL Divergence: 0.02956
SB3 Clip Fraction: 0.32169
Policy Update Magnitude: 0.39797
Value Function Update Magnitude: 0.35041

Collected Steps per Second: 22,788.42708
Overall Steps per Second: 10,818.55472

Timestep Collection Time: 2.19445
Timestep Consumption Time: 2.42798
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.62243

Cumulative Model Updates: 185,330
Cumulative Timesteps: 1,545,507,274

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1545507274...
Checkpoint 1545507274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 644,951.69319
Policy Entropy: 3.63308
Value Function Loss: 0.05874

Mean KL Divergence: 0.02680
SB3 Clip Fraction: 0.27749
Policy Update Magnitude: 0.37660
Value Function Update Magnitude: 0.29267

Collected Steps per Second: 22,663.35124
Overall Steps per Second: 10,658.57807

Timestep Collection Time: 2.20629
Timestep Consumption Time: 2.48495
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.69124

Cumulative Model Updates: 185,336
Cumulative Timesteps: 1,545,557,276

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,427.54285
Policy Entropy: 3.64634
Value Function Loss: 0.07948

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.24171
Policy Update Magnitude: 0.45448
Value Function Update Magnitude: 0.37226

Collected Steps per Second: 22,495.86103
Overall Steps per Second: 10,594.97773

Timestep Collection Time: 2.22290
Timestep Consumption Time: 2.49689
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.71978

Cumulative Model Updates: 185,342
Cumulative Timesteps: 1,545,607,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1545607282...
Checkpoint 1545607282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 391,567.78203
Policy Entropy: 3.63126
Value Function Loss: 0.09091

Mean KL Divergence: 0.02397
SB3 Clip Fraction: 0.23156
Policy Update Magnitude: 0.53501
Value Function Update Magnitude: 0.50259

Collected Steps per Second: 22,839.75297
Overall Steps per Second: 10,863.42800

Timestep Collection Time: 2.19057
Timestep Consumption Time: 2.41498
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.60554

Cumulative Model Updates: 185,348
Cumulative Timesteps: 1,545,657,314

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,557.40017
Policy Entropy: 3.67302
Value Function Loss: 0.08775

Mean KL Divergence: 0.01832
SB3 Clip Fraction: 0.20798
Policy Update Magnitude: 0.59529
Value Function Update Magnitude: 0.55301

Collected Steps per Second: 22,701.52609
Overall Steps per Second: 10,606.37314

Timestep Collection Time: 2.20276
Timestep Consumption Time: 2.51195
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.71471

Cumulative Model Updates: 185,354
Cumulative Timesteps: 1,545,707,320

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1545707320...
Checkpoint 1545707320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,698.74500
Policy Entropy: 3.65276
Value Function Loss: 0.08689

Mean KL Divergence: 0.01577
SB3 Clip Fraction: 0.18859
Policy Update Magnitude: 0.58350
Value Function Update Magnitude: 0.56120

Collected Steps per Second: 22,235.31240
Overall Steps per Second: 10,595.58459

Timestep Collection Time: 2.24868
Timestep Consumption Time: 2.47027
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.71895

Cumulative Model Updates: 185,360
Cumulative Timesteps: 1,545,757,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,879.40996
Policy Entropy: 3.65788
Value Function Loss: 0.08615

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.18084
Policy Update Magnitude: 0.59833
Value Function Update Magnitude: 0.66514

Collected Steps per Second: 22,701.73122
Overall Steps per Second: 10,789.56994

Timestep Collection Time: 2.20248
Timestep Consumption Time: 2.43163
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.63410

Cumulative Model Updates: 185,366
Cumulative Timesteps: 1,545,807,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1545807320...
Checkpoint 1545807320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,070.72816
Policy Entropy: 3.65201
Value Function Loss: 0.08536

Mean KL Divergence: 0.01551
SB3 Clip Fraction: 0.18070
Policy Update Magnitude: 0.58524
Value Function Update Magnitude: 0.63541

Collected Steps per Second: 22,375.91993
Overall Steps per Second: 10,764.40789

Timestep Collection Time: 2.23553
Timestep Consumption Time: 2.41145
PPO Batch Consumption Time: 0.27669
Total Iteration Time: 4.64698

Cumulative Model Updates: 185,372
Cumulative Timesteps: 1,545,857,342

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 361,269.11829
Policy Entropy: 3.65264
Value Function Loss: 0.08504

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.17640
Policy Update Magnitude: 0.57956
Value Function Update Magnitude: 0.63529

Collected Steps per Second: 22,896.02442
Overall Steps per Second: 10,816.69344

Timestep Collection Time: 2.18492
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.62489

Cumulative Model Updates: 185,378
Cumulative Timesteps: 1,545,907,368

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1545907368...
Checkpoint 1545907368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,905.70276
Policy Entropy: 3.65178
Value Function Loss: 0.08636

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.16858
Policy Update Magnitude: 0.57354
Value Function Update Magnitude: 0.50827

Collected Steps per Second: 22,595.84533
Overall Steps per Second: 10,723.53598

Timestep Collection Time: 2.21377
Timestep Consumption Time: 2.45092
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.66469

Cumulative Model Updates: 185,384
Cumulative Timesteps: 1,545,957,390

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,156.19407
Policy Entropy: 3.65971
Value Function Loss: 0.09307

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.16539
Policy Update Magnitude: 0.58418
Value Function Update Magnitude: 0.45064

Collected Steps per Second: 22,769.74836
Overall Steps per Second: 10,795.64607

Timestep Collection Time: 2.19607
Timestep Consumption Time: 2.43580
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.63187

Cumulative Model Updates: 185,390
Cumulative Timesteps: 1,546,007,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1546007394...
Checkpoint 1546007394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,163.94575
Policy Entropy: 3.68104
Value Function Loss: 0.08536

Mean KL Divergence: 0.01379
SB3 Clip Fraction: 0.16371
Policy Update Magnitude: 0.60901
Value Function Update Magnitude: 0.61625

Collected Steps per Second: 22,496.15950
Overall Steps per Second: 10,699.54462

Timestep Collection Time: 2.22269
Timestep Consumption Time: 2.45059
PPO Batch Consumption Time: 0.28264
Total Iteration Time: 4.67328

Cumulative Model Updates: 185,396
Cumulative Timesteps: 1,546,057,396

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 232,049.76411
Policy Entropy: 3.69133
Value Function Loss: 0.08059

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.16846
Policy Update Magnitude: 0.62801
Value Function Update Magnitude: 0.95555

Collected Steps per Second: 22,599.48783
Overall Steps per Second: 10,608.77317

Timestep Collection Time: 2.21315
Timestep Consumption Time: 2.50144
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.71459

Cumulative Model Updates: 185,402
Cumulative Timesteps: 1,546,107,412

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1546107412...
Checkpoint 1546107412 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,383.20253
Policy Entropy: 3.76196
Value Function Loss: 0.07578

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15399
Policy Update Magnitude: 0.65289
Value Function Update Magnitude: 0.83065

Collected Steps per Second: 22,532.34374
Overall Steps per Second: 10,698.30431

Timestep Collection Time: 2.22010
Timestep Consumption Time: 2.45578
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.67588

Cumulative Model Updates: 185,408
Cumulative Timesteps: 1,546,157,436

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,021.16921
Policy Entropy: 3.80819
Value Function Loss: 0.06933

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.14446
Policy Update Magnitude: 0.66205
Value Function Update Magnitude: 0.67428

Collected Steps per Second: 22,858.52451
Overall Steps per Second: 10,713.11417

Timestep Collection Time: 2.18868
Timestep Consumption Time: 2.48130
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.66998

Cumulative Model Updates: 185,414
Cumulative Timesteps: 1,546,207,466

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1546207466...
Checkpoint 1546207466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,475.95369
Policy Entropy: 3.83787
Value Function Loss: 0.06774

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.63430
Value Function Update Magnitude: 0.63026

Collected Steps per Second: 22,676.93886
Overall Steps per Second: 10,636.21670

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.49674
PPO Batch Consumption Time: 0.28941
Total Iteration Time: 4.70224

Cumulative Model Updates: 185,420
Cumulative Timesteps: 1,546,257,480

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,168.64543
Policy Entropy: 3.80800
Value Function Loss: 0.07164

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.58527
Value Function Update Magnitude: 0.65346

Collected Steps per Second: 22,804.17909
Overall Steps per Second: 10,857.06710

Timestep Collection Time: 2.19337
Timestep Consumption Time: 2.41358
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.60695

Cumulative Model Updates: 185,426
Cumulative Timesteps: 1,546,307,498

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1546307498...
Checkpoint 1546307498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 338,266.41065
Policy Entropy: 3.77757
Value Function Loss: 0.07462

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.15184
Policy Update Magnitude: 0.53817
Value Function Update Magnitude: 0.65209

Collected Steps per Second: 22,473.36030
Overall Steps per Second: 10,667.66989

Timestep Collection Time: 2.22521
Timestep Consumption Time: 2.46260
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.68781

Cumulative Model Updates: 185,432
Cumulative Timesteps: 1,546,357,506

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,667.46993
Policy Entropy: 3.75967
Value Function Loss: 0.07599

Mean KL Divergence: 0.01295
SB3 Clip Fraction: 0.16090
Policy Update Magnitude: 0.51971
Value Function Update Magnitude: 0.58469

Collected Steps per Second: 22,929.20476
Overall Steps per Second: 10,899.71122

Timestep Collection Time: 2.18158
Timestep Consumption Time: 2.40771
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.58930

Cumulative Model Updates: 185,438
Cumulative Timesteps: 1,546,407,528

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1546407528...
Checkpoint 1546407528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,265.59137
Policy Entropy: 3.75022
Value Function Loss: 0.07722

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.16039
Policy Update Magnitude: 0.51304
Value Function Update Magnitude: 0.48778

Collected Steps per Second: 22,413.17818
Overall Steps per Second: 10,669.80177

Timestep Collection Time: 2.23128
Timestep Consumption Time: 2.45578
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.68706

Cumulative Model Updates: 185,444
Cumulative Timesteps: 1,546,457,538

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,254.52929
Policy Entropy: 3.74295
Value Function Loss: 0.07718

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.15708
Policy Update Magnitude: 0.50125
Value Function Update Magnitude: 0.48682

Collected Steps per Second: 22,662.37157
Overall Steps per Second: 10,679.69402

Timestep Collection Time: 2.20745
Timestep Consumption Time: 2.47677
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.68422

Cumulative Model Updates: 185,450
Cumulative Timesteps: 1,546,507,564

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1546507564...
Checkpoint 1546507564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,193.31366
Policy Entropy: 3.75002
Value Function Loss: 0.07513

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.15349
Policy Update Magnitude: 0.51288
Value Function Update Magnitude: 0.52935

Collected Steps per Second: 22,740.33439
Overall Steps per Second: 10,818.45227

Timestep Collection Time: 2.19988
Timestep Consumption Time: 2.42426
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.62414

Cumulative Model Updates: 185,456
Cumulative Timesteps: 1,546,557,590

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,611.50091
Policy Entropy: 3.75759
Value Function Loss: 0.07412

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.15850
Policy Update Magnitude: 0.52814
Value Function Update Magnitude: 0.55044

Collected Steps per Second: 23,021.80612
Overall Steps per Second: 10,917.10017

Timestep Collection Time: 2.17194
Timestep Consumption Time: 2.40821
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.58015

Cumulative Model Updates: 185,462
Cumulative Timesteps: 1,546,607,592

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1546607592...
Checkpoint 1546607592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,224.01029
Policy Entropy: 3.74326
Value Function Loss: 0.07204

Mean KL Divergence: 0.01223
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.52399
Value Function Update Magnitude: 0.48930

Collected Steps per Second: 22,783.79639
Overall Steps per Second: 10,683.78145

Timestep Collection Time: 2.19542
Timestep Consumption Time: 2.48644
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.68186

Cumulative Model Updates: 185,468
Cumulative Timesteps: 1,546,657,612

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,827.83067
Policy Entropy: 3.72662
Value Function Loss: 0.07481

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.16025
Policy Update Magnitude: 0.51366
Value Function Update Magnitude: 0.44418

Collected Steps per Second: 22,853.80479
Overall Steps per Second: 10,858.69894

Timestep Collection Time: 2.18843
Timestep Consumption Time: 2.41746
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.60589

Cumulative Model Updates: 185,474
Cumulative Timesteps: 1,546,707,626

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1546707626...
Checkpoint 1546707626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 189.55504
Policy Entropy: 3.72934
Value Function Loss: 0.07218

Mean KL Divergence: 0.01353
SB3 Clip Fraction: 0.16639
Policy Update Magnitude: 0.48263
Value Function Update Magnitude: 0.43411

Collected Steps per Second: 22,723.89980
Overall Steps per Second: 10,713.24073

Timestep Collection Time: 2.20068
Timestep Consumption Time: 2.46719
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.66787

Cumulative Model Updates: 185,480
Cumulative Timesteps: 1,546,757,634

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,298.80544
Policy Entropy: 3.72391
Value Function Loss: 0.07413

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.16154
Policy Update Magnitude: 0.45404
Value Function Update Magnitude: 0.39638

Collected Steps per Second: 22,667.45593
Overall Steps per Second: 10,816.08697

Timestep Collection Time: 2.20678
Timestep Consumption Time: 2.41800
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.62478

Cumulative Model Updates: 185,486
Cumulative Timesteps: 1,546,807,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1546807656...
Checkpoint 1546807656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,668.64234
Policy Entropy: 3.72582
Value Function Loss: 0.07321

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15371
Policy Update Magnitude: 0.45226
Value Function Update Magnitude: 0.39084

Collected Steps per Second: 22,825.43001
Overall Steps per Second: 10,721.90386

Timestep Collection Time: 2.19080
Timestep Consumption Time: 2.47311
PPO Batch Consumption Time: 0.28494
Total Iteration Time: 4.66391

Cumulative Model Updates: 185,492
Cumulative Timesteps: 1,546,857,662

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,792.18009
Policy Entropy: 3.71747
Value Function Loss: 0.07545

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.15205
Policy Update Magnitude: 0.46582
Value Function Update Magnitude: 0.42016

Collected Steps per Second: 22,797.01605
Overall Steps per Second: 10,641.91130

Timestep Collection Time: 2.19441
Timestep Consumption Time: 2.50644
PPO Batch Consumption Time: 0.28865
Total Iteration Time: 4.70085

Cumulative Model Updates: 185,498
Cumulative Timesteps: 1,546,907,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1546907688...
Checkpoint 1546907688 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,627.95213
Policy Entropy: 3.71894
Value Function Loss: 0.07486

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.15509
Policy Update Magnitude: 0.48024
Value Function Update Magnitude: 0.41919

Collected Steps per Second: 22,768.97825
Overall Steps per Second: 10,833.12001

Timestep Collection Time: 2.19597
Timestep Consumption Time: 2.41951
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.61548

Cumulative Model Updates: 185,504
Cumulative Timesteps: 1,546,957,688

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 488.54613
Policy Entropy: 3.70618
Value Function Loss: 0.07379

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.17230
Policy Update Magnitude: 0.48407
Value Function Update Magnitude: 0.57708

Collected Steps per Second: 22,587.60475
Overall Steps per Second: 10,598.51613

Timestep Collection Time: 2.21449
Timestep Consumption Time: 2.50504
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.71953

Cumulative Model Updates: 185,510
Cumulative Timesteps: 1,547,007,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1547007708...
Checkpoint 1547007708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,972.95126
Policy Entropy: 3.67741
Value Function Loss: 0.07197

Mean KL Divergence: 0.01542
SB3 Clip Fraction: 0.17848
Policy Update Magnitude: 0.44626
Value Function Update Magnitude: 0.46771

Collected Steps per Second: 22,723.43328
Overall Steps per Second: 10,655.03502

Timestep Collection Time: 2.20143
Timestep Consumption Time: 2.49344
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.69487

Cumulative Model Updates: 185,516
Cumulative Timesteps: 1,547,057,732

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,331.26406
Policy Entropy: 3.66852
Value Function Loss: 0.07348

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.18823
Policy Update Magnitude: 0.41450
Value Function Update Magnitude: 0.39427

Collected Steps per Second: 22,974.09109
Overall Steps per Second: 10,891.34367

Timestep Collection Time: 2.17802
Timestep Consumption Time: 2.41627
PPO Batch Consumption Time: 0.27672
Total Iteration Time: 4.59429

Cumulative Model Updates: 185,522
Cumulative Timesteps: 1,547,107,770

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1547107770...
Checkpoint 1547107770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,062.43499
Policy Entropy: 3.66453
Value Function Loss: 0.07597

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.18220
Policy Update Magnitude: 0.40436
Value Function Update Magnitude: 0.34301

Collected Steps per Second: 22,741.42240
Overall Steps per Second: 10,680.93947

Timestep Collection Time: 2.19889
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.68180

Cumulative Model Updates: 185,528
Cumulative Timesteps: 1,547,157,776

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,193.57896
Policy Entropy: 3.66874
Value Function Loss: 0.07747

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.18502
Policy Update Magnitude: 0.38752
Value Function Update Magnitude: 0.36970

Collected Steps per Second: 22,429.07290
Overall Steps per Second: 10,723.96523

Timestep Collection Time: 2.22961
Timestep Consumption Time: 2.43359
PPO Batch Consumption Time: 0.27939
Total Iteration Time: 4.66320

Cumulative Model Updates: 185,534
Cumulative Timesteps: 1,547,207,784

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1547207784...
Checkpoint 1547207784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,332.47514
Policy Entropy: 3.67248
Value Function Loss: 0.07530

Mean KL Divergence: 0.01553
SB3 Clip Fraction: 0.18391
Policy Update Magnitude: 0.39479
Value Function Update Magnitude: 0.36598

Collected Steps per Second: 22,183.30679
Overall Steps per Second: 10,668.33491

Timestep Collection Time: 2.25395
Timestep Consumption Time: 2.43282
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.68677

Cumulative Model Updates: 185,540
Cumulative Timesteps: 1,547,257,784

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,522.38045
Policy Entropy: 3.67677
Value Function Loss: 0.06839

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.17972
Policy Update Magnitude: 0.39768
Value Function Update Magnitude: 0.43047

Collected Steps per Second: 22,934.29798
Overall Steps per Second: 10,862.29005

Timestep Collection Time: 2.18084
Timestep Consumption Time: 2.42372
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.60455

Cumulative Model Updates: 185,546
Cumulative Timesteps: 1,547,307,800

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1547307800...
Checkpoint 1547307800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,636.92217
Policy Entropy: 3.66122
Value Function Loss: 0.06804

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.17787
Policy Update Magnitude: 0.40363
Value Function Update Magnitude: 0.62201

Collected Steps per Second: 22,759.12205
Overall Steps per Second: 10,739.49361

Timestep Collection Time: 2.19692
Timestep Consumption Time: 2.45879
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.65571

Cumulative Model Updates: 185,552
Cumulative Timesteps: 1,547,357,800

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,082.06025
Policy Entropy: 3.64361
Value Function Loss: 0.06669

Mean KL Divergence: 0.01680
SB3 Clip Fraction: 0.18751
Policy Update Magnitude: 0.40250
Value Function Update Magnitude: 0.50715

Collected Steps per Second: 22,802.73328
Overall Steps per Second: 10,812.05117

Timestep Collection Time: 2.19281
Timestep Consumption Time: 2.43185
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.62465

Cumulative Model Updates: 185,558
Cumulative Timesteps: 1,547,407,802

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1547407802...
Checkpoint 1547407802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,677.70094
Policy Entropy: 3.65943
Value Function Loss: 0.06223

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.18921
Policy Update Magnitude: 0.40207
Value Function Update Magnitude: 0.44041

Collected Steps per Second: 22,515.55571
Overall Steps per Second: 10,725.93720

Timestep Collection Time: 2.22095
Timestep Consumption Time: 2.44120
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.66216

Cumulative Model Updates: 185,564
Cumulative Timesteps: 1,547,457,808

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,254.96027
Policy Entropy: 3.67373
Value Function Loss: 0.05598

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.19297
Policy Update Magnitude: 0.40613
Value Function Update Magnitude: 0.48065

Collected Steps per Second: 22,005.95401
Overall Steps per Second: 10,760.91339

Timestep Collection Time: 2.27302
Timestep Consumption Time: 2.37528
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.64830

Cumulative Model Updates: 185,570
Cumulative Timesteps: 1,547,507,828

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1547507828...
Checkpoint 1547507828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,732.58581
Policy Entropy: 3.66677
Value Function Loss: 0.06075

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.19624
Policy Update Magnitude: 0.38862
Value Function Update Magnitude: 0.54306

Collected Steps per Second: 21,898.53971
Overall Steps per Second: 10,827.78341

Timestep Collection Time: 2.28335
Timestep Consumption Time: 2.33459
PPO Batch Consumption Time: 0.27589
Total Iteration Time: 4.61794

Cumulative Model Updates: 185,576
Cumulative Timesteps: 1,547,557,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,678.19624
Policy Entropy: 3.63508
Value Function Loss: 0.06332

Mean KL Divergence: 0.01755
SB3 Clip Fraction: 0.20093
Policy Update Magnitude: 0.38789
Value Function Update Magnitude: 0.41396

Collected Steps per Second: 22,303.02399
Overall Steps per Second: 10,775.18285

Timestep Collection Time: 2.24275
Timestep Consumption Time: 2.39940
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.64215

Cumulative Model Updates: 185,582
Cumulative Timesteps: 1,547,607,850

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1547607850...
Checkpoint 1547607850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,482.49535
Policy Entropy: 3.61166
Value Function Loss: 0.06755

Mean KL Divergence: 0.01723
SB3 Clip Fraction: 0.19879
Policy Update Magnitude: 0.39646
Value Function Update Magnitude: 0.34615

Collected Steps per Second: 21,907.31047
Overall Steps per Second: 10,660.09078

Timestep Collection Time: 2.28307
Timestep Consumption Time: 2.40882
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.69189

Cumulative Model Updates: 185,588
Cumulative Timesteps: 1,547,657,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,361.75498
Policy Entropy: 3.60556
Value Function Loss: 0.07009

Mean KL Divergence: 0.01670
SB3 Clip Fraction: 0.19586
Policy Update Magnitude: 0.40618
Value Function Update Magnitude: 0.35724

Collected Steps per Second: 22,814.71196
Overall Steps per Second: 10,886.77704

Timestep Collection Time: 2.19280
Timestep Consumption Time: 2.40250
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.59530

Cumulative Model Updates: 185,594
Cumulative Timesteps: 1,547,707,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1547707894...
Checkpoint 1547707894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,635.37638
Policy Entropy: 3.63740
Value Function Loss: 0.06828

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.18729
Policy Update Magnitude: 0.41160
Value Function Update Magnitude: 0.49820

Collected Steps per Second: 22,563.77027
Overall Steps per Second: 10,754.90744

Timestep Collection Time: 2.21612
Timestep Consumption Time: 2.43329
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.64941

Cumulative Model Updates: 185,600
Cumulative Timesteps: 1,547,757,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,620.37244
Policy Entropy: 3.66894
Value Function Loss: 0.07033

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.17590
Policy Update Magnitude: 0.40328
Value Function Update Magnitude: 0.55904

Collected Steps per Second: 23,160.81296
Overall Steps per Second: 10,854.89879

Timestep Collection Time: 2.15986
Timestep Consumption Time: 2.44857
PPO Batch Consumption Time: 0.28526
Total Iteration Time: 4.60843

Cumulative Model Updates: 185,606
Cumulative Timesteps: 1,547,807,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1547807922...
Checkpoint 1547807922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,262.70509
Policy Entropy: 3.64805
Value Function Loss: 0.07348

Mean KL Divergence: 0.01480
SB3 Clip Fraction: 0.17228
Policy Update Magnitude: 0.40936
Value Function Update Magnitude: 0.41767

Collected Steps per Second: 22,740.24549
Overall Steps per Second: 10,715.12228

Timestep Collection Time: 2.19989
Timestep Consumption Time: 2.46884
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.66873

Cumulative Model Updates: 185,612
Cumulative Timesteps: 1,547,857,948

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 116,173.18239
Policy Entropy: 3.60315
Value Function Loss: 0.07968

Mean KL Divergence: 0.01581
SB3 Clip Fraction: 0.18002
Policy Update Magnitude: 0.43565
Value Function Update Magnitude: 0.35791

Collected Steps per Second: 23,105.16505
Overall Steps per Second: 10,844.33869

Timestep Collection Time: 2.16402
Timestep Consumption Time: 2.44668
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.61070

Cumulative Model Updates: 185,618
Cumulative Timesteps: 1,547,907,948

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1547907948...
Checkpoint 1547907948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,857.56443
Policy Entropy: 3.61335
Value Function Loss: 0.07926

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.17361
Policy Update Magnitude: 0.47226
Value Function Update Magnitude: 0.35110

Collected Steps per Second: 22,611.58316
Overall Steps per Second: 10,707.20074

Timestep Collection Time: 2.21223
Timestep Consumption Time: 2.45958
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.67181

Cumulative Model Updates: 185,624
Cumulative Timesteps: 1,547,957,970

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,603.63829
Policy Entropy: 3.66965
Value Function Loss: 0.07401

Mean KL Divergence: 0.01571
SB3 Clip Fraction: 0.17291
Policy Update Magnitude: 0.49606
Value Function Update Magnitude: 0.43989

Collected Steps per Second: 23,042.99073
Overall Steps per Second: 10,896.10780

Timestep Collection Time: 2.17029
Timestep Consumption Time: 2.41942
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.58971

Cumulative Model Updates: 185,630
Cumulative Timesteps: 1,548,007,980

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1548007980...
Checkpoint 1548007980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,349.63818
Policy Entropy: 3.70569
Value Function Loss: 0.06758

Mean KL Divergence: 0.01510
SB3 Clip Fraction: 0.17149
Policy Update Magnitude: 0.48843
Value Function Update Magnitude: 0.44504

Collected Steps per Second: 22,189.75926
Overall Steps per Second: 10,573.88369

Timestep Collection Time: 2.25419
Timestep Consumption Time: 2.47633
PPO Batch Consumption Time: 0.28662
Total Iteration Time: 4.73052

Cumulative Model Updates: 185,636
Cumulative Timesteps: 1,548,058,000

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,478.15354
Policy Entropy: 3.69128
Value Function Loss: 0.06632

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.17267
Policy Update Magnitude: 0.46159
Value Function Update Magnitude: 0.39327

Collected Steps per Second: 22,877.71285
Overall Steps per Second: 10,856.15233

Timestep Collection Time: 2.18571
Timestep Consumption Time: 2.42034
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.60605

Cumulative Model Updates: 185,642
Cumulative Timesteps: 1,548,108,004

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1548108004...
Checkpoint 1548108004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,432.87573
Policy Entropy: 3.65353
Value Function Loss: 0.06737

Mean KL Divergence: 0.01533
SB3 Clip Fraction: 0.17657
Policy Update Magnitude: 0.44888
Value Function Update Magnitude: 0.39700

Collected Steps per Second: 22,405.55123
Overall Steps per Second: 10,785.88379

Timestep Collection Time: 2.23213
Timestep Consumption Time: 2.40468
PPO Batch Consumption Time: 0.27557
Total Iteration Time: 4.63680

Cumulative Model Updates: 185,648
Cumulative Timesteps: 1,548,158,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,648.65303
Policy Entropy: 3.65130
Value Function Loss: 0.06709

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.17974
Policy Update Magnitude: 0.44554
Value Function Update Magnitude: 0.39590

Collected Steps per Second: 23,045.39966
Overall Steps per Second: 10,909.86191

Timestep Collection Time: 2.17206
Timestep Consumption Time: 2.41608
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.58814

Cumulative Model Updates: 185,654
Cumulative Timesteps: 1,548,208,072

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1548208072...
Checkpoint 1548208072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,776.63879
Policy Entropy: 3.64218
Value Function Loss: 0.06741

Mean KL Divergence: 0.01492
SB3 Clip Fraction: 0.18034
Policy Update Magnitude: 0.43218
Value Function Update Magnitude: 0.38437

Collected Steps per Second: 22,499.14352
Overall Steps per Second: 10,564.32879

Timestep Collection Time: 2.22364
Timestep Consumption Time: 2.51211
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.73575

Cumulative Model Updates: 185,660
Cumulative Timesteps: 1,548,258,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,461.08520
Policy Entropy: 3.61971
Value Function Loss: 0.06740

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.17364
Policy Update Magnitude: 0.42011
Value Function Update Magnitude: 0.35620

Collected Steps per Second: 22,894.62558
Overall Steps per Second: 10,871.68091

Timestep Collection Time: 2.18444
Timestep Consumption Time: 2.41577
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.60021

Cumulative Model Updates: 185,666
Cumulative Timesteps: 1,548,308,114

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1548308114...
Checkpoint 1548308114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,852.23943
Policy Entropy: 3.62621
Value Function Loss: 0.06945

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.17777
Policy Update Magnitude: 0.41883
Value Function Update Magnitude: 0.36798

Collected Steps per Second: 22,596.31180
Overall Steps per Second: 10,707.38982

Timestep Collection Time: 2.21372
Timestep Consumption Time: 2.45800
PPO Batch Consumption Time: 0.28471
Total Iteration Time: 4.67173

Cumulative Model Updates: 185,672
Cumulative Timesteps: 1,548,358,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,781.08948
Policy Entropy: 3.63449
Value Function Loss: 0.06836

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.17334
Policy Update Magnitude: 0.43913
Value Function Update Magnitude: 0.37380

Collected Steps per Second: 22,862.16015
Overall Steps per Second: 10,834.05876

Timestep Collection Time: 2.18763
Timestep Consumption Time: 2.42874
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.61637

Cumulative Model Updates: 185,678
Cumulative Timesteps: 1,548,408,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1548408150...
Checkpoint 1548408150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,654.80619
Policy Entropy: 3.66360
Value Function Loss: 0.07001

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.16872
Policy Update Magnitude: 0.44650
Value Function Update Magnitude: 0.50164

Collected Steps per Second: 22,517.05876
Overall Steps per Second: 10,694.11764

Timestep Collection Time: 2.22267
Timestep Consumption Time: 2.45729
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.67996

Cumulative Model Updates: 185,684
Cumulative Timesteps: 1,548,458,198

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,907.18556
Policy Entropy: 3.66740
Value Function Loss: 0.06962

Mean KL Divergence: 0.01380
SB3 Clip Fraction: 0.15989
Policy Update Magnitude: 0.46658
Value Function Update Magnitude: 0.58854

Collected Steps per Second: 22,849.10479
Overall Steps per Second: 10,859.37309

Timestep Collection Time: 2.18844
Timestep Consumption Time: 2.41624
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.60469

Cumulative Model Updates: 185,690
Cumulative Timesteps: 1,548,508,202

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1548508202...
Checkpoint 1548508202 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,913.02737
Policy Entropy: 3.66492
Value Function Loss: 0.07118

Mean KL Divergence: 0.01471
SB3 Clip Fraction: 0.16551
Policy Update Magnitude: 0.45864
Value Function Update Magnitude: 0.46706

Collected Steps per Second: 22,814.43992
Overall Steps per Second: 10,725.76711

Timestep Collection Time: 2.19221
Timestep Consumption Time: 2.47077
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.66298

Cumulative Model Updates: 185,696
Cumulative Timesteps: 1,548,558,216

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,058.65045
Policy Entropy: 3.67318
Value Function Loss: 0.06942

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.16758
Policy Update Magnitude: 0.49038
Value Function Update Magnitude: 0.44636

Collected Steps per Second: 22,636.24747
Overall Steps per Second: 10,639.22417

Timestep Collection Time: 2.20938
Timestep Consumption Time: 2.49134
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.70072

Cumulative Model Updates: 185,702
Cumulative Timesteps: 1,548,608,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1548608228...
Checkpoint 1548608228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,460.81005
Policy Entropy: 3.67303
Value Function Loss: 0.06830

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.16878
Policy Update Magnitude: 0.49556
Value Function Update Magnitude: 0.56632

Collected Steps per Second: 22,108.48968
Overall Steps per Second: 10,853.38852

Timestep Collection Time: 2.26221
Timestep Consumption Time: 2.34594
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.60815

Cumulative Model Updates: 185,708
Cumulative Timesteps: 1,548,658,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,213.55501
Policy Entropy: 3.67997
Value Function Loss: 0.06558

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.16128
Policy Update Magnitude: 0.47708
Value Function Update Magnitude: 0.59774

Collected Steps per Second: 22,194.72175
Overall Steps per Second: 10,886.92412

Timestep Collection Time: 2.25378
Timestep Consumption Time: 2.34091
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.59469

Cumulative Model Updates: 185,714
Cumulative Timesteps: 1,548,708,264

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1548708264...
Checkpoint 1548708264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,663.43620
Policy Entropy: 3.67409
Value Function Loss: 0.06854

Mean KL Divergence: 0.01388
SB3 Clip Fraction: 0.16107
Policy Update Magnitude: 0.48381
Value Function Update Magnitude: 0.64541

Collected Steps per Second: 21,973.85829
Overall Steps per Second: 10,729.47520

Timestep Collection Time: 2.27661
Timestep Consumption Time: 2.38587
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.66248

Cumulative Model Updates: 185,720
Cumulative Timesteps: 1,548,758,290

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,883.35760
Policy Entropy: 3.67897
Value Function Loss: 0.06896

Mean KL Divergence: 0.01317
SB3 Clip Fraction: 0.15230
Policy Update Magnitude: 0.51269
Value Function Update Magnitude: 0.53868

Collected Steps per Second: 22,124.91076
Overall Steps per Second: 10,827.54181

Timestep Collection Time: 2.26035
Timestep Consumption Time: 2.35843
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.61878

Cumulative Model Updates: 185,726
Cumulative Timesteps: 1,548,808,300

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1548808300...
Checkpoint 1548808300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,041.45532
Policy Entropy: 3.68777
Value Function Loss: 0.06671

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.15439
Policy Update Magnitude: 0.52989
Value Function Update Magnitude: 0.51594

Collected Steps per Second: 21,467.53660
Overall Steps per Second: 10,684.83833

Timestep Collection Time: 2.33003
Timestep Consumption Time: 2.35137
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.68140

Cumulative Model Updates: 185,732
Cumulative Timesteps: 1,548,858,320

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,392.96317
Policy Entropy: 3.71549
Value Function Loss: 0.06652

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.14936
Policy Update Magnitude: 0.56104
Value Function Update Magnitude: 0.55492

Collected Steps per Second: 22,119.77034
Overall Steps per Second: 10,851.17053

Timestep Collection Time: 2.26096
Timestep Consumption Time: 2.34794
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.60890

Cumulative Model Updates: 185,738
Cumulative Timesteps: 1,548,908,332

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1548908332...
Checkpoint 1548908332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,222.10358
Policy Entropy: 3.69684
Value Function Loss: 0.06593

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.15753
Policy Update Magnitude: 0.52314
Value Function Update Magnitude: 0.60234

Collected Steps per Second: 21,975.68335
Overall Steps per Second: 10,770.62022

Timestep Collection Time: 2.27615
Timestep Consumption Time: 2.36796
PPO Batch Consumption Time: 0.28243
Total Iteration Time: 4.64412

Cumulative Model Updates: 185,744
Cumulative Timesteps: 1,548,958,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,906.87323
Policy Entropy: 3.67313
Value Function Loss: 0.06526

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.15453
Policy Update Magnitude: 0.49462
Value Function Update Magnitude: 0.54379

Collected Steps per Second: 22,378.75267
Overall Steps per Second: 10,877.15619

Timestep Collection Time: 2.23471
Timestep Consumption Time: 2.36300
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.59771

Cumulative Model Updates: 185,750
Cumulative Timesteps: 1,549,008,362

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1549008362...
Checkpoint 1549008362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,565.70569
Policy Entropy: 3.65553
Value Function Loss: 0.06822

Mean KL Divergence: 0.01407
SB3 Clip Fraction: 0.16199
Policy Update Magnitude: 0.49419
Value Function Update Magnitude: 0.50363

Collected Steps per Second: 21,606.30891
Overall Steps per Second: 10,586.87862

Timestep Collection Time: 2.31442
Timestep Consumption Time: 2.40898
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.72339

Cumulative Model Updates: 185,756
Cumulative Timesteps: 1,549,058,368

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,635.25249
Policy Entropy: 3.65986
Value Function Loss: 0.06639

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.15836
Policy Update Magnitude: 0.48804
Value Function Update Magnitude: 0.57218

Collected Steps per Second: 22,880.95100
Overall Steps per Second: 10,904.01170

Timestep Collection Time: 2.18662
Timestep Consumption Time: 2.40178
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.58840

Cumulative Model Updates: 185,762
Cumulative Timesteps: 1,549,108,400

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1549108400...
Checkpoint 1549108400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,223.35637
Policy Entropy: 3.69372
Value Function Loss: 0.06893

Mean KL Divergence: 0.01357
SB3 Clip Fraction: 0.15653
Policy Update Magnitude: 0.47134
Value Function Update Magnitude: 0.56500

Collected Steps per Second: 22,422.53173
Overall Steps per Second: 10,758.42556

Timestep Collection Time: 2.23088
Timestep Consumption Time: 2.41868
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.64957

Cumulative Model Updates: 185,768
Cumulative Timesteps: 1,549,158,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,830.00811
Policy Entropy: 3.69267
Value Function Loss: 0.07151

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.15286
Policy Update Magnitude: 0.47831
Value Function Update Magnitude: 0.49797

Collected Steps per Second: 23,122.02337
Overall Steps per Second: 10,875.11749

Timestep Collection Time: 2.16279
Timestep Consumption Time: 2.43560
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.59839

Cumulative Model Updates: 185,774
Cumulative Timesteps: 1,549,208,430

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1549208430...
Checkpoint 1549208430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,223.24513
Policy Entropy: 3.71222
Value Function Loss: 0.06626

Mean KL Divergence: 0.01387
SB3 Clip Fraction: 0.15550
Policy Update Magnitude: 0.48027
Value Function Update Magnitude: 0.48755

Collected Steps per Second: 22,635.19704
Overall Steps per Second: 10,689.10280

Timestep Collection Time: 2.21080
Timestep Consumption Time: 2.47079
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.68159

Cumulative Model Updates: 185,780
Cumulative Timesteps: 1,549,258,472

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,561.14840
Policy Entropy: 3.71072
Value Function Loss: 0.06731

Mean KL Divergence: 0.01331
SB3 Clip Fraction: 0.14901
Policy Update Magnitude: 0.49136
Value Function Update Magnitude: 0.46973

Collected Steps per Second: 22,871.87724
Overall Steps per Second: 10,892.33891

Timestep Collection Time: 2.18653
Timestep Consumption Time: 2.40477
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.59130

Cumulative Model Updates: 185,786
Cumulative Timesteps: 1,549,308,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1549308482...
Checkpoint 1549308482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,074.61290
Policy Entropy: 3.72959
Value Function Loss: 0.06527

Mean KL Divergence: 0.01321
SB3 Clip Fraction: 0.15453
Policy Update Magnitude: 0.47563
Value Function Update Magnitude: 0.42772

Collected Steps per Second: 22,688.68286
Overall Steps per Second: 10,722.51493

Timestep Collection Time: 2.20436
Timestep Consumption Time: 2.46003
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.66439

Cumulative Model Updates: 185,792
Cumulative Timesteps: 1,549,358,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,692.80298
Policy Entropy: 3.71784
Value Function Loss: 0.06655

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.14647
Policy Update Magnitude: 0.48689
Value Function Update Magnitude: 0.42867

Collected Steps per Second: 23,057.94997
Overall Steps per Second: 10,805.02141

Timestep Collection Time: 2.16914
Timestep Consumption Time: 2.45982
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.62896

Cumulative Model Updates: 185,798
Cumulative Timesteps: 1,549,408,512

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1549408512...
Checkpoint 1549408512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,106.48491
Policy Entropy: 3.72401
Value Function Loss: 0.06738

Mean KL Divergence: 0.01246
SB3 Clip Fraction: 0.15101
Policy Update Magnitude: 0.46303
Value Function Update Magnitude: 0.40834

Collected Steps per Second: 22,538.79724
Overall Steps per Second: 10,647.19446

Timestep Collection Time: 2.21866
Timestep Consumption Time: 2.47797
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.69664

Cumulative Model Updates: 185,804
Cumulative Timesteps: 1,549,458,518

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,657.12793
Policy Entropy: 3.70373
Value Function Loss: 0.06831

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.14623
Policy Update Magnitude: 0.45645
Value Function Update Magnitude: 0.41449

Collected Steps per Second: 23,016.00085
Overall Steps per Second: 10,873.78212

Timestep Collection Time: 2.17301
Timestep Consumption Time: 2.42649
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.59950

Cumulative Model Updates: 185,810
Cumulative Timesteps: 1,549,508,532

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1549508532...
Checkpoint 1549508532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,142.12892
Policy Entropy: 3.70242
Value Function Loss: 0.06637

Mean KL Divergence: 0.01276
SB3 Clip Fraction: 0.14841
Policy Update Magnitude: 0.46769
Value Function Update Magnitude: 0.41445

Collected Steps per Second: 22,255.06645
Overall Steps per Second: 10,690.98398

Timestep Collection Time: 2.24731
Timestep Consumption Time: 2.43084
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.67815

Cumulative Model Updates: 185,816
Cumulative Timesteps: 1,549,558,546

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,431.14612
Policy Entropy: 3.68452
Value Function Loss: 0.06728

Mean KL Divergence: 0.01234
SB3 Clip Fraction: 0.14658
Policy Update Magnitude: 0.48578
Value Function Update Magnitude: 0.46571

Collected Steps per Second: 22,987.11111
Overall Steps per Second: 10,848.54840

Timestep Collection Time: 2.17583
Timestep Consumption Time: 2.43456
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.61039

Cumulative Model Updates: 185,822
Cumulative Timesteps: 1,549,608,562

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1549608562...
Checkpoint 1549608562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,919.77902
Policy Entropy: 3.68792
Value Function Loss: 0.06420

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.14900
Policy Update Magnitude: 0.47273
Value Function Update Magnitude: 0.51800

Collected Steps per Second: 22,503.41541
Overall Steps per Second: 10,644.61574

Timestep Collection Time: 2.22206
Timestep Consumption Time: 2.47552
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.69759

Cumulative Model Updates: 185,828
Cumulative Timesteps: 1,549,658,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,597.60642
Policy Entropy: 3.68486
Value Function Loss: 0.07520

Mean KL Divergence: 0.01365
SB3 Clip Fraction: 0.15394
Policy Update Magnitude: 0.46142
Value Function Update Magnitude: 0.50765

Collected Steps per Second: 22,996.12832
Overall Steps per Second: 10,877.85494

Timestep Collection Time: 2.17593
Timestep Consumption Time: 2.42406
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.59999

Cumulative Model Updates: 185,834
Cumulative Timesteps: 1,549,708,604

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1549708604...
Checkpoint 1549708604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,612.40001
Policy Entropy: 3.70265
Value Function Loss: 0.07179

Mean KL Divergence: 0.01565
SB3 Clip Fraction: 0.17324
Policy Update Magnitude: 0.44764
Value Function Update Magnitude: 0.39084

Collected Steps per Second: 22,525.66902
Overall Steps per Second: 10,719.48292

Timestep Collection Time: 2.22040
Timestep Consumption Time: 2.44550
PPO Batch Consumption Time: 0.28238
Total Iteration Time: 4.66590

Cumulative Model Updates: 185,840
Cumulative Timesteps: 1,549,758,620

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,921.32188
Policy Entropy: 3.71014
Value Function Loss: 0.06398

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.18234
Policy Update Magnitude: 0.42142
Value Function Update Magnitude: 0.48612

Collected Steps per Second: 23,052.08053
Overall Steps per Second: 10,942.57770

Timestep Collection Time: 2.16926
Timestep Consumption Time: 2.40059
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.56986

Cumulative Model Updates: 185,846
Cumulative Timesteps: 1,549,808,626

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1549808626...
Checkpoint 1549808626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,965.76067
Policy Entropy: 3.69019
Value Function Loss: 0.05945

Mean KL Divergence: 0.01592
SB3 Clip Fraction: 0.18348
Policy Update Magnitude: 0.40306
Value Function Update Magnitude: 0.48957

Collected Steps per Second: 22,485.46772
Overall Steps per Second: 10,590.38428

Timestep Collection Time: 2.22455
Timestep Consumption Time: 2.49860
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.72315

Cumulative Model Updates: 185,852
Cumulative Timesteps: 1,549,858,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,755.92356
Policy Entropy: 3.66462
Value Function Loss: 0.05838

Mean KL Divergence: 0.01613
SB3 Clip Fraction: 0.18257
Policy Update Magnitude: 0.39130
Value Function Update Magnitude: 0.48888

Collected Steps per Second: 22,954.37484
Overall Steps per Second: 10,875.26364

Timestep Collection Time: 2.17850
Timestep Consumption Time: 2.41965
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.59814

Cumulative Model Updates: 185,858
Cumulative Timesteps: 1,549,908,652

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1549908652...
Checkpoint 1549908652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,826.47719
Policy Entropy: 3.65678
Value Function Loss: 0.05934

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.18760
Policy Update Magnitude: 0.39703
Value Function Update Magnitude: 0.42966

Collected Steps per Second: 22,685.81582
Overall Steps per Second: 10,708.93977

Timestep Collection Time: 2.20596
Timestep Consumption Time: 2.46715
PPO Batch Consumption Time: 0.28462
Total Iteration Time: 4.67310

Cumulative Model Updates: 185,864
Cumulative Timesteps: 1,549,958,696

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,913.51776
Policy Entropy: 3.66302
Value Function Loss: 0.05980

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.19836
Policy Update Magnitude: 0.38114
Value Function Update Magnitude: 0.37557

Collected Steps per Second: 23,154.89251
Overall Steps per Second: 10,884.49128

Timestep Collection Time: 2.16127
Timestep Consumption Time: 2.43646
PPO Batch Consumption Time: 0.27844
Total Iteration Time: 4.59773

Cumulative Model Updates: 185,870
Cumulative Timesteps: 1,550,008,740

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1550008740...
Checkpoint 1550008740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,056.31125
Policy Entropy: 3.68721
Value Function Loss: 0.06157

Mean KL Divergence: 0.01620
SB3 Clip Fraction: 0.18338
Policy Update Magnitude: 0.39519
Value Function Update Magnitude: 0.42076

Collected Steps per Second: 22,538.78934
Overall Steps per Second: 10,667.60155

Timestep Collection Time: 2.21946
Timestep Consumption Time: 2.46988
PPO Batch Consumption Time: 0.28601
Total Iteration Time: 4.68934

Cumulative Model Updates: 185,876
Cumulative Timesteps: 1,550,058,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,772.57960
Policy Entropy: 3.69298
Value Function Loss: 0.06866

Mean KL Divergence: 0.01605
SB3 Clip Fraction: 0.17867
Policy Update Magnitude: 0.47920
Value Function Update Magnitude: 0.38854

Collected Steps per Second: 22,849.99638
Overall Steps per Second: 10,823.53260

Timestep Collection Time: 2.18897
Timestep Consumption Time: 2.43226
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.62123

Cumulative Model Updates: 185,882
Cumulative Timesteps: 1,550,108,782

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1550108782...
Checkpoint 1550108782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,772.57960
Policy Entropy: 3.69825
Value Function Loss: 0.06246

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.15410
Policy Update Magnitude: 0.54607
Value Function Update Magnitude: 0.32129

Collected Steps per Second: 22,676.69305
Overall Steps per Second: 10,732.73409

Timestep Collection Time: 2.20570
Timestep Consumption Time: 2.45462
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.66032

Cumulative Model Updates: 185,888
Cumulative Timesteps: 1,550,158,800

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,772.57960
Policy Entropy: 3.69499
Value Function Loss: 0.04967

Mean KL Divergence: 0.01654
SB3 Clip Fraction: 0.19970
Policy Update Magnitude: 0.54677
Value Function Update Magnitude: 0.29694

Collected Steps per Second: 23,213.65457
Overall Steps per Second: 10,939.52927

Timestep Collection Time: 2.15511
Timestep Consumption Time: 2.41803
PPO Batch Consumption Time: 0.27677
Total Iteration Time: 4.57314

Cumulative Model Updates: 185,894
Cumulative Timesteps: 1,550,208,828

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1550208828...
Checkpoint 1550208828 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,959.67418
Policy Entropy: 3.66705
Value Function Loss: 0.05787

Mean KL Divergence: 0.02938
SB3 Clip Fraction: 0.28483
Policy Update Magnitude: 0.44734
Value Function Update Magnitude: 0.33637

Collected Steps per Second: 22,691.25486
Overall Steps per Second: 10,642.04041

Timestep Collection Time: 2.20446
Timestep Consumption Time: 2.49595
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.70041

Cumulative Model Updates: 185,900
Cumulative Timesteps: 1,550,258,850

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,128.73830
Policy Entropy: 3.71960
Value Function Loss: 0.05934

Mean KL Divergence: 0.02160
SB3 Clip Fraction: 0.22721
Policy Update Magnitude: 0.41579
Value Function Update Magnitude: 0.53492

Collected Steps per Second: 22,945.05783
Overall Steps per Second: 10,865.51238

Timestep Collection Time: 2.17912
Timestep Consumption Time: 2.42260
PPO Batch Consumption Time: 0.28208
Total Iteration Time: 4.60172

Cumulative Model Updates: 185,906
Cumulative Timesteps: 1,550,308,850

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1550308850...
Checkpoint 1550308850 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,530.44353
Policy Entropy: 3.71867
Value Function Loss: 0.07077

Mean KL Divergence: 0.02013
SB3 Clip Fraction: 0.20524
Policy Update Magnitude: 0.49306
Value Function Update Magnitude: 0.50554

Collected Steps per Second: 22,543.36339
Overall Steps per Second: 10,612.29321

Timestep Collection Time: 2.21866
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.71302

Cumulative Model Updates: 185,912
Cumulative Timesteps: 1,550,358,866

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,056.14505
Policy Entropy: 3.81127
Value Function Loss: 0.06628

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.14738
Policy Update Magnitude: 0.55324
Value Function Update Magnitude: 0.53100

Collected Steps per Second: 22,941.04279
Overall Steps per Second: 10,900.46400

Timestep Collection Time: 2.18072
Timestep Consumption Time: 2.40881
PPO Batch Consumption Time: 0.27887
Total Iteration Time: 4.58953

Cumulative Model Updates: 185,918
Cumulative Timesteps: 1,550,408,894

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1550408894...
Checkpoint 1550408894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,314.98894
Policy Entropy: 3.83640
Value Function Loss: 0.06197

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.15978
Policy Update Magnitude: 0.70937
Value Function Update Magnitude: 0.55965

Collected Steps per Second: 22,469.12315
Overall Steps per Second: 10,637.46731

Timestep Collection Time: 2.22545
Timestep Consumption Time: 2.47529
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.70074

Cumulative Model Updates: 185,924
Cumulative Timesteps: 1,550,458,898

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,106.47969
Policy Entropy: 3.87513
Value Function Loss: 0.05840

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.14554
Policy Update Magnitude: 0.76668
Value Function Update Magnitude: 0.69286

Collected Steps per Second: 23,004.36575
Overall Steps per Second: 10,916.52032

Timestep Collection Time: 2.17376
Timestep Consumption Time: 2.40700
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.58076

Cumulative Model Updates: 185,930
Cumulative Timesteps: 1,550,508,904

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1550508904...
Checkpoint 1550508904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 720.03483
Policy Entropy: 3.93155
Value Function Loss: 0.05280

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.86037
Value Function Update Magnitude: 0.69364

Collected Steps per Second: 22,455.33880
Overall Steps per Second: 10,832.19692

Timestep Collection Time: 2.22762
Timestep Consumption Time: 2.39028
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.61790

Cumulative Model Updates: 185,936
Cumulative Timesteps: 1,550,558,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,853.57981
Policy Entropy: 3.96253
Value Function Loss: 0.04417

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11173
Policy Update Magnitude: 0.93135
Value Function Update Magnitude: 0.75906

Collected Steps per Second: 22,388.65751
Overall Steps per Second: 10,707.10125

Timestep Collection Time: 2.23327
Timestep Consumption Time: 2.43652
PPO Batch Consumption Time: 0.29224
Total Iteration Time: 4.66980

Cumulative Model Updates: 185,942
Cumulative Timesteps: 1,550,608,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1550608926...
Checkpoint 1550608926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,693.03746
Policy Entropy: 4.00208
Value Function Loss: 0.03477

Mean KL Divergence: 0.00679
SB3 Clip Fraction: 0.08014
Policy Update Magnitude: 1.01768
Value Function Update Magnitude: 0.85341

Collected Steps per Second: 21,866.20280
Overall Steps per Second: 10,630.23159

Timestep Collection Time: 2.28709
Timestep Consumption Time: 2.41742
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.70451

Cumulative Model Updates: 185,948
Cumulative Timesteps: 1,550,658,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 536.39713
Policy Entropy: 3.98190
Value Function Loss: 0.03468

Mean KL Divergence: 0.00672
SB3 Clip Fraction: 0.08121
Policy Update Magnitude: 1.07357
Value Function Update Magnitude: 0.91681

Collected Steps per Second: 22,620.16965
Overall Steps per Second: 10,668.84048

Timestep Collection Time: 2.21112
Timestep Consumption Time: 2.47692
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.68804

Cumulative Model Updates: 185,954
Cumulative Timesteps: 1,550,708,952

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1550708952...
Checkpoint 1550708952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,606.80909
Policy Entropy: 3.98193
Value Function Loss: 0.03613

Mean KL Divergence: 0.00633
SB3 Clip Fraction: 0.07626
Policy Update Magnitude: 1.05017
Value Function Update Magnitude: 0.93090

Collected Steps per Second: 22,596.34069
Overall Steps per Second: 10,823.06665

Timestep Collection Time: 2.21310
Timestep Consumption Time: 2.40740
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.62050

Cumulative Model Updates: 185,960
Cumulative Timesteps: 1,550,758,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,102.35285
Policy Entropy: 3.95739
Value Function Loss: 0.04451

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07542
Policy Update Magnitude: 0.99126
Value Function Update Magnitude: 0.72877

Collected Steps per Second: 23,164.56877
Overall Steps per Second: 10,913.97586

Timestep Collection Time: 2.15881
Timestep Consumption Time: 2.42320
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.58201

Cumulative Model Updates: 185,966
Cumulative Timesteps: 1,550,808,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1550808968...
Checkpoint 1550808968 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,480.38077
Policy Entropy: 3.93942
Value Function Loss: 0.04707

Mean KL Divergence: 0.00643
SB3 Clip Fraction: 0.07867
Policy Update Magnitude: 0.90694
Value Function Update Magnitude: 0.65265

Collected Steps per Second: 22,314.89705
Overall Steps per Second: 10,743.83876

Timestep Collection Time: 2.24119
Timestep Consumption Time: 2.41375
PPO Batch Consumption Time: 0.27691
Total Iteration Time: 4.65495

Cumulative Model Updates: 185,972
Cumulative Timesteps: 1,550,858,980

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,606.11783
Policy Entropy: 3.94775
Value Function Loss: 0.05143

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.13793
Policy Update Magnitude: 0.77781
Value Function Update Magnitude: 0.50068

Collected Steps per Second: 22,920.86662
Overall Steps per Second: 10,870.18678

Timestep Collection Time: 2.18281
Timestep Consumption Time: 2.41987
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.60268

Cumulative Model Updates: 185,978
Cumulative Timesteps: 1,550,909,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1550909012...
Checkpoint 1550909012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,085.34550
Policy Entropy: 3.98278
Value Function Loss: 0.04276

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.60703
Value Function Update Magnitude: 0.58693

Collected Steps per Second: 22,407.39889
Overall Steps per Second: 10,674.36668

Timestep Collection Time: 2.23203
Timestep Consumption Time: 2.45340
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.68543

Cumulative Model Updates: 185,984
Cumulative Timesteps: 1,550,959,026

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,576.18184
Policy Entropy: 4.00878
Value Function Loss: 0.03958

Mean KL Divergence: 0.00656
SB3 Clip Fraction: 0.07722
Policy Update Magnitude: 0.77394
Value Function Update Magnitude: 0.74990

Collected Steps per Second: 22,841.42694
Overall Steps per Second: 10,913.25799

Timestep Collection Time: 2.19032
Timestep Consumption Time: 2.39401
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.58433

Cumulative Model Updates: 185,990
Cumulative Timesteps: 1,551,009,056

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1551009056...
Checkpoint 1551009056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33.26444
Policy Entropy: 4.02989
Value Function Loss: 0.03718

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.07621
Policy Update Magnitude: 0.89949
Value Function Update Magnitude: 0.84360

Collected Steps per Second: 22,459.96932
Overall Steps per Second: 10,656.33971

Timestep Collection Time: 2.22672
Timestep Consumption Time: 2.46645
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.69317

Cumulative Model Updates: 185,996
Cumulative Timesteps: 1,551,059,068

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,971.98390
Policy Entropy: 3.97125
Value Function Loss: 0.04891

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07849
Policy Update Magnitude: 0.85688
Value Function Update Magnitude: 0.70841

Collected Steps per Second: 23,153.97933
Overall Steps per Second: 10,887.96467

Timestep Collection Time: 2.16032
Timestep Consumption Time: 2.43374
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.59406

Cumulative Model Updates: 186,002
Cumulative Timesteps: 1,551,109,088

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1551109088...
Checkpoint 1551109088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 612.82145
Policy Entropy: 3.96134
Value Function Loss: 0.05133

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08500
Policy Update Magnitude: 0.76868
Value Function Update Magnitude: 0.53437

Collected Steps per Second: 22,698.35256
Overall Steps per Second: 10,719.60257

Timestep Collection Time: 2.20324
Timestep Consumption Time: 2.46204
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.66528

Cumulative Model Updates: 186,008
Cumulative Timesteps: 1,551,159,098

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,736.43270
Policy Entropy: 3.91185
Value Function Loss: 0.05258

Mean KL Divergence: 0.01929
SB3 Clip Fraction: 0.18439
Policy Update Magnitude: 0.55927
Value Function Update Magnitude: 0.47732

Collected Steps per Second: 23,146.80863
Overall Steps per Second: 10,947.87921

Timestep Collection Time: 2.16012
Timestep Consumption Time: 2.40697
PPO Batch Consumption Time: 0.28984
Total Iteration Time: 4.56709

Cumulative Model Updates: 186,014
Cumulative Timesteps: 1,551,209,098

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1551209098...
Checkpoint 1551209098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,930.78358
Policy Entropy: 3.91469
Value Function Loss: 0.05066

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.11919
Policy Update Magnitude: 0.46727
Value Function Update Magnitude: 0.53792

Collected Steps per Second: 21,933.52188
Overall Steps per Second: 10,714.72518

Timestep Collection Time: 2.27998
Timestep Consumption Time: 2.38724
PPO Batch Consumption Time: 0.28717
Total Iteration Time: 4.66722

Cumulative Model Updates: 186,020
Cumulative Timesteps: 1,551,259,106

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159.71876
Policy Entropy: 3.92785
Value Function Loss: 0.04879

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.10170
Policy Update Magnitude: 0.47555
Value Function Update Magnitude: 0.56548

Collected Steps per Second: 22,432.45289
Overall Steps per Second: 10,771.85027

Timestep Collection Time: 2.22918
Timestep Consumption Time: 2.41310
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.64229

Cumulative Model Updates: 186,026
Cumulative Timesteps: 1,551,309,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1551309112...
Checkpoint 1551309112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166.84938
Policy Entropy: 3.89738
Value Function Loss: 0.04956

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10352
Policy Update Magnitude: 0.44656
Value Function Update Magnitude: 0.49202

Collected Steps per Second: 22,106.66424
Overall Steps per Second: 10,737.23066

Timestep Collection Time: 2.26239
Timestep Consumption Time: 2.39560
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.65800

Cumulative Model Updates: 186,032
Cumulative Timesteps: 1,551,359,126

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.99516
Policy Entropy: 3.88383
Value Function Loss: 0.04965

Mean KL Divergence: 0.00770
SB3 Clip Fraction: 0.10242
Policy Update Magnitude: 0.42514
Value Function Update Magnitude: 0.43425

Collected Steps per Second: 22,260.23657
Overall Steps per Second: 10,744.46647

Timestep Collection Time: 2.24786
Timestep Consumption Time: 2.40923
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.65709

Cumulative Model Updates: 186,038
Cumulative Timesteps: 1,551,409,164

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1551409164...
Checkpoint 1551409164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,821.67393
Policy Entropy: 3.80980
Value Function Loss: 0.05021

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.38709
Value Function Update Magnitude: 0.31267

Collected Steps per Second: 21,947.06137
Overall Steps per Second: 10,630.59312

Timestep Collection Time: 2.27939
Timestep Consumption Time: 2.42646
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.70585

Cumulative Model Updates: 186,044
Cumulative Timesteps: 1,551,459,190

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,035.93568
Policy Entropy: 3.79581
Value Function Loss: 0.04273

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.40070
Value Function Update Magnitude: 0.27934

Collected Steps per Second: 22,513.43994
Overall Steps per Second: 10,982.59751

Timestep Collection Time: 2.22161
Timestep Consumption Time: 2.33251
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.55411

Cumulative Model Updates: 186,050
Cumulative Timesteps: 1,551,509,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1551509206...
Checkpoint 1551509206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,194.54179
Policy Entropy: 3.74691
Value Function Loss: 0.04715

Mean KL Divergence: 0.01103
SB3 Clip Fraction: 0.14528
Policy Update Magnitude: 0.33915
Value Function Update Magnitude: 0.39793

Collected Steps per Second: 22,136.35471
Overall Steps per Second: 10,591.35698

Timestep Collection Time: 2.25981
Timestep Consumption Time: 2.46328
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.72310

Cumulative Model Updates: 186,056
Cumulative Timesteps: 1,551,559,230

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,336.70203
Policy Entropy: 3.76213
Value Function Loss: 0.04399

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13324
Policy Update Magnitude: 0.36587
Value Function Update Magnitude: 0.31498

Collected Steps per Second: 22,885.50170
Overall Steps per Second: 10,922.24976

Timestep Collection Time: 2.18514
Timestep Consumption Time: 2.39340
PPO Batch Consumption Time: 0.27648
Total Iteration Time: 4.57854

Cumulative Model Updates: 186,062
Cumulative Timesteps: 1,551,609,238

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1551609238...
Checkpoint 1551609238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,257.26111
Policy Entropy: 3.76044
Value Function Loss: 0.05385

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.40326
Value Function Update Magnitude: 0.37579

Collected Steps per Second: 22,498.04286
Overall Steps per Second: 10,654.59291

Timestep Collection Time: 2.22339
Timestep Consumption Time: 2.47148
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.69488

Cumulative Model Updates: 186,068
Cumulative Timesteps: 1,551,659,260

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,777.01000
Policy Entropy: 3.79385
Value Function Loss: 0.05179

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11863
Policy Update Magnitude: 0.44483
Value Function Update Magnitude: 0.54887

Collected Steps per Second: 23,103.76609
Overall Steps per Second: 10,840.68279

Timestep Collection Time: 2.16424
Timestep Consumption Time: 2.44820
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.61244

Cumulative Model Updates: 186,074
Cumulative Timesteps: 1,551,709,262

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1551709262...
Checkpoint 1551709262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,049.95880
Policy Entropy: 3.75915
Value Function Loss: 0.05593

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13176
Policy Update Magnitude: 0.39500
Value Function Update Magnitude: 0.54933

Collected Steps per Second: 22,636.16525
Overall Steps per Second: 10,699.38819

Timestep Collection Time: 2.20885
Timestep Consumption Time: 2.46431
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.67316

Cumulative Model Updates: 186,080
Cumulative Timesteps: 1,551,759,262

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,006.89839
Policy Entropy: 3.73153
Value Function Loss: 0.04712

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13467
Policy Update Magnitude: 0.41987
Value Function Update Magnitude: 0.45088

Collected Steps per Second: 23,189.10098
Overall Steps per Second: 10,810.71335

Timestep Collection Time: 2.15644
Timestep Consumption Time: 2.46915
PPO Batch Consumption Time: 0.28328
Total Iteration Time: 4.62560

Cumulative Model Updates: 186,086
Cumulative Timesteps: 1,551,809,268

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1551809268...
Checkpoint 1551809268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,006.89839
Policy Entropy: 3.69164
Value Function Loss: 0.04155

Mean KL Divergence: 0.01338
SB3 Clip Fraction: 0.16265
Policy Update Magnitude: 0.42513
Value Function Update Magnitude: 0.41035

Collected Steps per Second: 22,543.69261
Overall Steps per Second: 10,663.78864

Timestep Collection Time: 2.21809
Timestep Consumption Time: 2.47105
PPO Batch Consumption Time: 0.28517
Total Iteration Time: 4.68914

Cumulative Model Updates: 186,092
Cumulative Timesteps: 1,551,859,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,006.89839
Policy Entropy: 3.69047
Value Function Loss: 0.03158

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13859
Policy Update Magnitude: 0.37973
Value Function Update Magnitude: 0.37949

Collected Steps per Second: 23,285.57942
Overall Steps per Second: 10,975.59351

Timestep Collection Time: 2.14725
Timestep Consumption Time: 2.40831
PPO Batch Consumption Time: 0.27527
Total Iteration Time: 4.55556

Cumulative Model Updates: 186,098
Cumulative Timesteps: 1,551,909,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1551909272...
Checkpoint 1551909272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,006.89839
Policy Entropy: 3.67390
Value Function Loss: 0.02766

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14269
Policy Update Magnitude: 0.29438
Value Function Update Magnitude: 0.38665

Collected Steps per Second: 22,949.64085
Overall Steps per Second: 10,755.88495

Timestep Collection Time: 2.17973
Timestep Consumption Time: 2.47112
PPO Batch Consumption Time: 0.28706
Total Iteration Time: 4.65085

Cumulative Model Updates: 186,104
Cumulative Timesteps: 1,551,959,296

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,698.82307
Policy Entropy: 3.68520
Value Function Loss: 0.02643

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.32073
Value Function Update Magnitude: 0.54029

Collected Steps per Second: 23,308.10293
Overall Steps per Second: 10,723.00585

Timestep Collection Time: 2.14603
Timestep Consumption Time: 2.51870
PPO Batch Consumption Time: 0.29250
Total Iteration Time: 4.66474

Cumulative Model Updates: 186,110
Cumulative Timesteps: 1,552,009,316

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1552009316...
Checkpoint 1552009316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,698.82307
Policy Entropy: 3.68406
Value Function Loss: 0.02543

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14110
Policy Update Magnitude: 0.32470
Value Function Update Magnitude: 0.58438

Collected Steps per Second: 22,284.10668
Overall Steps per Second: 10,645.69344

Timestep Collection Time: 2.24465
Timestep Consumption Time: 2.45396
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.69861

Cumulative Model Updates: 186,116
Cumulative Timesteps: 1,552,059,336

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,698.82307
Policy Entropy: 3.68158
Value Function Loss: 0.01995

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.32817
Value Function Update Magnitude: 0.57898

Collected Steps per Second: 23,130.85028
Overall Steps per Second: 10,903.80926

Timestep Collection Time: 2.16187
Timestep Consumption Time: 2.42423
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.58610

Cumulative Model Updates: 186,122
Cumulative Timesteps: 1,552,109,342

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1552109342...
Checkpoint 1552109342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,698.82307
Policy Entropy: 3.66595
Value Function Loss: 0.01991

Mean KL Divergence: 0.01120
SB3 Clip Fraction: 0.14842
Policy Update Magnitude: 0.31062
Value Function Update Magnitude: 0.54670

Collected Steps per Second: 22,522.23346
Overall Steps per Second: 10,679.15196

Timestep Collection Time: 2.22056
Timestep Consumption Time: 2.46258
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.68314

Cumulative Model Updates: 186,128
Cumulative Timesteps: 1,552,159,354

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,698.82307
Policy Entropy: 3.67570
Value Function Loss: 0.01795

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12861
Policy Update Magnitude: 0.30274
Value Function Update Magnitude: 0.56754

Collected Steps per Second: 23,196.68097
Overall Steps per Second: 10,934.62315

Timestep Collection Time: 2.15557
Timestep Consumption Time: 2.41725
PPO Batch Consumption Time: 0.27609
Total Iteration Time: 4.57281

Cumulative Model Updates: 186,134
Cumulative Timesteps: 1,552,209,356

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1552209356...
Checkpoint 1552209356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,698.82307
Policy Entropy: 3.65937
Value Function Loss: 0.02092

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.14806
Policy Update Magnitude: 0.28657
Value Function Update Magnitude: 0.48139

Collected Steps per Second: 22,534.36924
Overall Steps per Second: 10,598.88039

Timestep Collection Time: 2.21999
Timestep Consumption Time: 2.49995
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.71993

Cumulative Model Updates: 186,140
Cumulative Timesteps: 1,552,259,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,137.32623
Policy Entropy: 3.67192
Value Function Loss: 0.02112

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13683
Policy Update Magnitude: 0.29776
Value Function Update Magnitude: 0.42181

Collected Steps per Second: 23,255.59439
Overall Steps per Second: 10,963.47344

Timestep Collection Time: 2.15019
Timestep Consumption Time: 2.41077
PPO Batch Consumption Time: 0.27525
Total Iteration Time: 4.56096

Cumulative Model Updates: 186,146
Cumulative Timesteps: 1,552,309,386

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1552309386...
Checkpoint 1552309386 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,334.50229
Policy Entropy: 3.66661
Value Function Loss: 0.02484

Mean KL Divergence: 0.01068
SB3 Clip Fraction: 0.14277
Policy Update Magnitude: 0.30419
Value Function Update Magnitude: 0.52387

Collected Steps per Second: 22,683.44234
Overall Steps per Second: 10,685.54161

Timestep Collection Time: 2.20566
Timestep Consumption Time: 2.47655
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.68221

Cumulative Model Updates: 186,152
Cumulative Timesteps: 1,552,359,418

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,001.02409
Policy Entropy: 3.69079
Value Function Loss: 0.02525

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12466
Policy Update Magnitude: 0.33961
Value Function Update Magnitude: 0.64009

Collected Steps per Second: 22,526.11744
Overall Steps per Second: 10,792.63618

Timestep Collection Time: 2.22098
Timestep Consumption Time: 2.41459
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.63557

Cumulative Model Updates: 186,158
Cumulative Timesteps: 1,552,409,448

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1552409448...
Checkpoint 1552409448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,329.01333
Policy Entropy: 3.69076
Value Function Loss: 0.02613

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.34418
Value Function Update Magnitude: 0.72040

Collected Steps per Second: 21,849.68605
Overall Steps per Second: 10,662.23482

Timestep Collection Time: 2.28836
Timestep Consumption Time: 2.40109
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.68945

Cumulative Model Updates: 186,164
Cumulative Timesteps: 1,552,459,448

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,329.01333
Policy Entropy: 3.69309
Value Function Loss: 0.02134

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.35173
Value Function Update Magnitude: 0.65704

Collected Steps per Second: 22,807.38395
Overall Steps per Second: 10,880.28407

Timestep Collection Time: 2.19297
Timestep Consumption Time: 2.40396
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.59694

Cumulative Model Updates: 186,170
Cumulative Timesteps: 1,552,509,464

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1552509464...
Checkpoint 1552509464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,329.01333
Policy Entropy: 3.67164
Value Function Loss: 0.01943

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.13152
Policy Update Magnitude: 0.33946
Value Function Update Magnitude: 0.58517

Collected Steps per Second: 22,599.20708
Overall Steps per Second: 10,655.68835

Timestep Collection Time: 2.21282
Timestep Consumption Time: 2.48026
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.69308

Cumulative Model Updates: 186,176
Cumulative Timesteps: 1,552,559,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,329.01333
Policy Entropy: 3.66297
Value Function Loss: 0.01496

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13434
Policy Update Magnitude: 0.33994
Value Function Update Magnitude: 0.58852

Collected Steps per Second: 23,102.34331
Overall Steps per Second: 10,996.30643

Timestep Collection Time: 2.16523
Timestep Consumption Time: 2.38375
PPO Batch Consumption Time: 0.27544
Total Iteration Time: 4.54898

Cumulative Model Updates: 186,182
Cumulative Timesteps: 1,552,609,494

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1552609494...
Checkpoint 1552609494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,329.01333
Policy Entropy: 3.66783
Value Function Loss: 0.01493

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12853
Policy Update Magnitude: 0.32617
Value Function Update Magnitude: 0.54954

Collected Steps per Second: 22,575.96438
Overall Steps per Second: 10,618.55740

Timestep Collection Time: 2.21572
Timestep Consumption Time: 2.49509
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.71081

Cumulative Model Updates: 186,188
Cumulative Timesteps: 1,552,659,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,329.01333
Policy Entropy: 3.67966
Value Function Loss: 0.01415

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12422
Policy Update Magnitude: 0.34215
Value Function Update Magnitude: 0.56331

Collected Steps per Second: 22,927.18558
Overall Steps per Second: 10,897.07903

Timestep Collection Time: 2.18143
Timestep Consumption Time: 2.40824
PPO Batch Consumption Time: 0.27579
Total Iteration Time: 4.58967

Cumulative Model Updates: 186,194
Cumulative Timesteps: 1,552,709,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1552709530...
Checkpoint 1552709530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,113.15310
Policy Entropy: 3.68246
Value Function Loss: 0.01717

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.40437
Value Function Update Magnitude: 0.59083

Collected Steps per Second: 22,286.91915
Overall Steps per Second: 10,595.98665

Timestep Collection Time: 2.24428
Timestep Consumption Time: 2.47619
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.72047

Cumulative Model Updates: 186,200
Cumulative Timesteps: 1,552,759,548

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,113.15310
Policy Entropy: 3.67761
Value Function Loss: 0.02004

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07381
Policy Update Magnitude: 0.47967
Value Function Update Magnitude: 0.65101

Collected Steps per Second: 22,889.35199
Overall Steps per Second: 10,839.28782

Timestep Collection Time: 2.18451
Timestep Consumption Time: 2.42852
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.61303

Cumulative Model Updates: 186,206
Cumulative Timesteps: 1,552,809,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1552809550...
Checkpoint 1552809550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,113.15310
Policy Entropy: 3.68090
Value Function Loss: 0.01960

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07121
Policy Update Magnitude: 0.50149
Value Function Update Magnitude: 0.65847

Collected Steps per Second: 22,280.28751
Overall Steps per Second: 10,728.34429

Timestep Collection Time: 2.24494
Timestep Consumption Time: 2.41729
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.66223

Cumulative Model Updates: 186,212
Cumulative Timesteps: 1,552,859,568

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,113.15310
Policy Entropy: 3.68109
Value Function Loss: 0.01611

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06943
Policy Update Magnitude: 0.46696
Value Function Update Magnitude: 0.59762

Collected Steps per Second: 22,822.93252
Overall Steps per Second: 10,871.02566

Timestep Collection Time: 2.19122
Timestep Consumption Time: 2.40908
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.60030

Cumulative Model Updates: 186,218
Cumulative Timesteps: 1,552,909,578

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1552909578...
Checkpoint 1552909578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,113.15310
Policy Entropy: 3.68034
Value Function Loss: 0.01427

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06058
Policy Update Magnitude: 0.41308
Value Function Update Magnitude: 0.47409

Collected Steps per Second: 21,944.83898
Overall Steps per Second: 10,662.94399

Timestep Collection Time: 2.27953
Timestep Consumption Time: 2.41185
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.69139

Cumulative Model Updates: 186,224
Cumulative Timesteps: 1,552,959,602

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,113.15310
Policy Entropy: 3.67968
Value Function Loss: 0.01387

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06012
Policy Update Magnitude: 0.40662
Value Function Update Magnitude: 0.47522

Collected Steps per Second: 22,388.71426
Overall Steps per Second: 10,863.67521

Timestep Collection Time: 2.23461
Timestep Consumption Time: 2.37065
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.60526

Cumulative Model Updates: 186,230
Cumulative Timesteps: 1,553,009,632

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1553009632...
Checkpoint 1553009632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,578.97133
Policy Entropy: 3.69179
Value Function Loss: 0.01634

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07187
Policy Update Magnitude: 0.43630
Value Function Update Magnitude: 0.61299

Collected Steps per Second: 21,998.32956
Overall Steps per Second: 10,697.55178

Timestep Collection Time: 2.27317
Timestep Consumption Time: 2.40135
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.67453

Cumulative Model Updates: 186,236
Cumulative Timesteps: 1,553,059,638

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,351.10627
Policy Entropy: 3.70175
Value Function Loss: 0.01851

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.42368
Value Function Update Magnitude: 0.73510

Collected Steps per Second: 22,884.46242
Overall Steps per Second: 10,889.29093

Timestep Collection Time: 2.18594
Timestep Consumption Time: 2.40793
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.59387

Cumulative Model Updates: 186,242
Cumulative Timesteps: 1,553,109,662

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1553109662...
Checkpoint 1553109662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183,114.30536
Policy Entropy: 3.70993
Value Function Loss: 0.01991

Mean KL Divergence: 0.01315
SB3 Clip Fraction: 0.16428
Policy Update Magnitude: 0.36952
Value Function Update Magnitude: 0.80992

Collected Steps per Second: 22,648.49994
Overall Steps per Second: 10,713.81637

Timestep Collection Time: 2.20871
Timestep Consumption Time: 2.46040
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.66911

Cumulative Model Updates: 186,248
Cumulative Timesteps: 1,553,159,686

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,092.44565
Policy Entropy: 3.71591
Value Function Loss: 0.02214

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.41364
Value Function Update Magnitude: 0.76830

Collected Steps per Second: 22,812.51568
Overall Steps per Second: 10,824.42307

Timestep Collection Time: 2.19213
Timestep Consumption Time: 2.42779
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.61992

Cumulative Model Updates: 186,254
Cumulative Timesteps: 1,553,209,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1553209694...
Checkpoint 1553209694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,092.44565
Policy Entropy: 3.69543
Value Function Loss: 0.01983

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11690
Policy Update Magnitude: 0.47540
Value Function Update Magnitude: 0.71097

Collected Steps per Second: 22,795.41554
Overall Steps per Second: 10,642.05196

Timestep Collection Time: 2.19439
Timestep Consumption Time: 2.50602
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.70041

Cumulative Model Updates: 186,260
Cumulative Timesteps: 1,553,259,716

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,092.44565
Policy Entropy: 3.69666
Value Function Loss: 0.01787

Mean KL Divergence: 0.00791
SB3 Clip Fraction: 0.09926
Policy Update Magnitude: 0.46550
Value Function Update Magnitude: 0.65105

Collected Steps per Second: 22,479.34948
Overall Steps per Second: 10,658.84961

Timestep Collection Time: 2.22533
Timestep Consumption Time: 2.46786
PPO Batch Consumption Time: 0.28868
Total Iteration Time: 4.69319

Cumulative Model Updates: 186,266
Cumulative Timesteps: 1,553,309,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1553309740...
Checkpoint 1553309740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,092.44565
Policy Entropy: 3.69346
Value Function Loss: 0.01589

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07517
Policy Update Magnitude: 0.48775
Value Function Update Magnitude: 0.60842

Collected Steps per Second: 22,895.47945
Overall Steps per Second: 10,879.57120

Timestep Collection Time: 2.18480
Timestep Consumption Time: 2.41299
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.59779

Cumulative Model Updates: 186,272
Cumulative Timesteps: 1,553,359,762

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,869.00198
Policy Entropy: 3.72950
Value Function Loss: 0.01592

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07755
Policy Update Magnitude: 0.50912
Value Function Update Magnitude: 0.67766

Collected Steps per Second: 23,028.69721
Overall Steps per Second: 10,882.86716

Timestep Collection Time: 2.17225
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.59658

Cumulative Model Updates: 186,278
Cumulative Timesteps: 1,553,409,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1553409786...
Checkpoint 1553409786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 122,613.42316
Policy Entropy: 3.70548
Value Function Loss: 0.01890

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07062
Policy Update Magnitude: 0.55626
Value Function Update Magnitude: 0.71600

Collected Steps per Second: 22,717.76844
Overall Steps per Second: 10,725.62270

Timestep Collection Time: 2.20092
Timestep Consumption Time: 2.46081
PPO Batch Consumption Time: 0.28625
Total Iteration Time: 4.66173

Cumulative Model Updates: 186,284
Cumulative Timesteps: 1,553,459,786

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,613.42316
Policy Entropy: 3.69879
Value Function Loss: 0.02012

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06296
Policy Update Magnitude: 0.59842
Value Function Update Magnitude: 0.71110

Collected Steps per Second: 22,287.88107
Overall Steps per Second: 10,927.46803

Timestep Collection Time: 2.24382
Timestep Consumption Time: 2.33272
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.57654

Cumulative Model Updates: 186,290
Cumulative Timesteps: 1,553,509,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1553509796...
Checkpoint 1553509796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,057.29397
Policy Entropy: 3.68999
Value Function Loss: 0.02191

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06094
Policy Update Magnitude: 0.62222
Value Function Update Magnitude: 0.65986

Collected Steps per Second: 21,961.99021
Overall Steps per Second: 10,684.84195

Timestep Collection Time: 2.27666
Timestep Consumption Time: 2.40287
PPO Batch Consumption Time: 0.29190
Total Iteration Time: 4.67953

Cumulative Model Updates: 186,296
Cumulative Timesteps: 1,553,559,796

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,057.29397
Policy Entropy: 3.70871
Value Function Loss: 0.01900

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07446
Policy Update Magnitude: 0.58337
Value Function Update Magnitude: 0.62435

Collected Steps per Second: 22,333.56813
Overall Steps per Second: 10,779.43531

Timestep Collection Time: 2.23995
Timestep Consumption Time: 2.40093
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.64087

Cumulative Model Updates: 186,302
Cumulative Timesteps: 1,553,609,822

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1553609822...
Checkpoint 1553609822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,796.67903
Policy Entropy: 3.72515
Value Function Loss: 0.01740

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.07129
Policy Update Magnitude: 0.53400
Value Function Update Magnitude: 0.64419

Collected Steps per Second: 22,395.88916
Overall Steps per Second: 10,692.54057

Timestep Collection Time: 2.23362
Timestep Consumption Time: 2.44478
PPO Batch Consumption Time: 0.28700
Total Iteration Time: 4.67840

Cumulative Model Updates: 186,308
Cumulative Timesteps: 1,553,659,846

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,120.94626
Policy Entropy: 3.73361
Value Function Loss: 0.01553

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04977
Policy Update Magnitude: 0.49637
Value Function Update Magnitude: 0.63179

Collected Steps per Second: 22,993.18429
Overall Steps per Second: 10,957.70293

Timestep Collection Time: 2.17525
Timestep Consumption Time: 2.38921
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.56446

Cumulative Model Updates: 186,314
Cumulative Timesteps: 1,553,709,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1553709862...
Checkpoint 1553709862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,120.94626
Policy Entropy: 3.72383
Value Function Loss: 0.01680

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.04737
Policy Update Magnitude: 0.49226
Value Function Update Magnitude: 0.62124

Collected Steps per Second: 22,742.23031
Overall Steps per Second: 10,654.19375

Timestep Collection Time: 2.19864
Timestep Consumption Time: 2.49453
PPO Batch Consumption Time: 0.29180
Total Iteration Time: 4.69318

Cumulative Model Updates: 186,320
Cumulative Timesteps: 1,553,759,864

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,120.94626
Policy Entropy: 3.71266
Value Function Loss: 0.01995

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05034
Policy Update Magnitude: 0.57240
Value Function Update Magnitude: 0.66411

Collected Steps per Second: 22,735.22354
Overall Steps per Second: 10,789.82387

Timestep Collection Time: 2.19932
Timestep Consumption Time: 2.43486
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.63418

Cumulative Model Updates: 186,326
Cumulative Timesteps: 1,553,809,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1553809866...
Checkpoint 1553809866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,120.94626
Policy Entropy: 3.70900
Value Function Loss: 0.02138

Mean KL Divergence: 0.00648
SB3 Clip Fraction: 0.08058
Policy Update Magnitude: 0.57014
Value Function Update Magnitude: 0.68695

Collected Steps per Second: 22,702.12380
Overall Steps per Second: 10,661.85791

Timestep Collection Time: 2.20288
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.28954
Total Iteration Time: 4.69055

Cumulative Model Updates: 186,332
Cumulative Timesteps: 1,553,859,876

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,120.94626
Policy Entropy: 3.70473
Value Function Loss: 0.02501

Mean KL Divergence: 0.00699
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.60958
Value Function Update Magnitude: 0.71149

Collected Steps per Second: 22,944.89568
Overall Steps per Second: 10,898.68865

Timestep Collection Time: 2.17913
Timestep Consumption Time: 2.40857
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.58771

Cumulative Model Updates: 186,338
Cumulative Timesteps: 1,553,909,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1553909876...
Checkpoint 1553909876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205,344.31382
Policy Entropy: 3.70892
Value Function Loss: 0.02566

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.07017
Policy Update Magnitude: 0.62872
Value Function Update Magnitude: 0.88398

Collected Steps per Second: 22,991.18224
Overall Steps per Second: 10,718.38381

Timestep Collection Time: 2.17475
Timestep Consumption Time: 2.49014
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.66488

Cumulative Model Updates: 186,344
Cumulative Timesteps: 1,553,959,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205,344.31382
Policy Entropy: 3.71956
Value Function Loss: 0.02157

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08932
Policy Update Magnitude: 0.60554
Value Function Update Magnitude: 0.87601

Collected Steps per Second: 22,951.46367
Overall Steps per Second: 10,871.13090

Timestep Collection Time: 2.17851
Timestep Consumption Time: 2.42083
PPO Batch Consumption Time: 0.27664
Total Iteration Time: 4.59934

Cumulative Model Updates: 186,350
Cumulative Timesteps: 1,554,009,876

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1554009876...
Checkpoint 1554009876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205,344.31382
Policy Entropy: 3.71616
Value Function Loss: 0.02013

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06295
Policy Update Magnitude: 0.56464
Value Function Update Magnitude: 0.73097

Collected Steps per Second: 21,988.95674
Overall Steps per Second: 10,662.72263

Timestep Collection Time: 2.27523
Timestep Consumption Time: 2.41681
PPO Batch Consumption Time: 0.29060
Total Iteration Time: 4.69205

Cumulative Model Updates: 186,356
Cumulative Timesteps: 1,554,059,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 205,344.31382
Policy Entropy: 3.71239
Value Function Loss: 0.01869

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05265
Policy Update Magnitude: 0.56748
Value Function Update Magnitude: 0.63266

Collected Steps per Second: 22,412.60339
Overall Steps per Second: 10,940.15210

Timestep Collection Time: 2.23178
Timestep Consumption Time: 2.34037
PPO Batch Consumption Time: 0.27577
Total Iteration Time: 4.57215

Cumulative Model Updates: 186,362
Cumulative Timesteps: 1,554,109,926

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1554109926...
Checkpoint 1554109926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205,344.31382
Policy Entropy: 3.71162
Value Function Loss: 0.02018

Mean KL Divergence: 0.00640
SB3 Clip Fraction: 0.07741
Policy Update Magnitude: 0.59395
Value Function Update Magnitude: 0.61270

Collected Steps per Second: 22,012.40767
Overall Steps per Second: 10,565.12162

Timestep Collection Time: 2.27190
Timestep Consumption Time: 2.46160
PPO Batch Consumption Time: 0.29016
Total Iteration Time: 4.73350

Cumulative Model Updates: 186,368
Cumulative Timesteps: 1,554,159,936

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413,265.34934
Policy Entropy: 3.70625
Value Function Loss: 0.02304

Mean KL Divergence: 0.00587
SB3 Clip Fraction: 0.06904
Policy Update Magnitude: 0.59174
Value Function Update Magnitude: 0.60837

Collected Steps per Second: 22,968.05364
Overall Steps per Second: 10,954.81883

Timestep Collection Time: 2.17789
Timestep Consumption Time: 2.38832
PPO Batch Consumption Time: 0.27661
Total Iteration Time: 4.56621

Cumulative Model Updates: 186,374
Cumulative Timesteps: 1,554,209,958

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1554209958...
Checkpoint 1554209958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,907.29745
Policy Entropy: 3.71770
Value Function Loss: 0.02037

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11313
Policy Update Magnitude: 0.53551
Value Function Update Magnitude: 0.60331

Collected Steps per Second: 23,085.17920
Overall Steps per Second: 10,977.32258

Timestep Collection Time: 2.16641
Timestep Consumption Time: 2.38953
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.55594

Cumulative Model Updates: 186,380
Cumulative Timesteps: 1,554,259,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,907.29745
Policy Entropy: 3.71683
Value Function Loss: 0.01770

Mean KL Divergence: 0.02633
SB3 Clip Fraction: 0.28966
Policy Update Magnitude: 0.41325
Value Function Update Magnitude: 0.57463

Collected Steps per Second: 22,937.32112
Overall Steps per Second: 10,779.53100

Timestep Collection Time: 2.18003
Timestep Consumption Time: 2.45876
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.63879

Cumulative Model Updates: 186,386
Cumulative Timesteps: 1,554,309,974

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1554309974...
Checkpoint 1554309974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,907.29745
Policy Entropy: 3.70601
Value Function Loss: 0.02224

Mean KL Divergence: 0.03281
SB3 Clip Fraction: 0.33771
Policy Update Magnitude: 0.28495
Value Function Update Magnitude: 0.41649

Collected Steps per Second: 22,568.38611
Overall Steps per Second: 10,829.00750

Timestep Collection Time: 2.21637
Timestep Consumption Time: 2.40270
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.61908

Cumulative Model Updates: 186,392
Cumulative Timesteps: 1,554,359,994

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,907.29745
Policy Entropy: 3.66183
Value Function Loss: 0.03966

Mean KL Divergence: 0.02793
SB3 Clip Fraction: 0.28936
Policy Update Magnitude: 0.30621
Value Function Update Magnitude: 0.33220

Collected Steps per Second: 22,759.55794
Overall Steps per Second: 10,835.91958

Timestep Collection Time: 2.19732
Timestep Consumption Time: 2.41789
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.61521

Cumulative Model Updates: 186,398
Cumulative Timesteps: 1,554,410,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1554410004...
Checkpoint 1554410004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,402.21759
Policy Entropy: 3.63683
Value Function Loss: 0.05744

Mean KL Divergence: 0.02749
SB3 Clip Fraction: 0.29277
Policy Update Magnitude: 0.43060
Value Function Update Magnitude: 0.32925

Collected Steps per Second: 22,825.47726
Overall Steps per Second: 10,731.09729

Timestep Collection Time: 2.19176
Timestep Consumption Time: 2.47020
PPO Batch Consumption Time: 0.28463
Total Iteration Time: 4.66197

Cumulative Model Updates: 186,404
Cumulative Timesteps: 1,554,460,032

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 377,193.88014
Policy Entropy: 3.63746
Value Function Loss: 0.06887

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.23683
Policy Update Magnitude: 0.43309
Value Function Update Magnitude: 0.39976

Collected Steps per Second: 22,475.35249
Overall Steps per Second: 10,657.54826

Timestep Collection Time: 2.22475
Timestep Consumption Time: 2.46695
PPO Batch Consumption Time: 0.28778
Total Iteration Time: 4.69170

Cumulative Model Updates: 186,410
Cumulative Timesteps: 1,554,510,034

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1554510034...
Checkpoint 1554510034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236,522.34935
Policy Entropy: 3.68947
Value Function Loss: 0.08161

Mean KL Divergence: 0.01704
SB3 Clip Fraction: 0.20329
Policy Update Magnitude: 0.47195
Value Function Update Magnitude: 0.51334

Collected Steps per Second: 22,815.83646
Overall Steps per Second: 10,914.06173

Timestep Collection Time: 2.19190
Timestep Consumption Time: 2.39026
PPO Batch Consumption Time: 0.27683
Total Iteration Time: 4.58216

Cumulative Model Updates: 186,416
Cumulative Timesteps: 1,554,560,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 127,367.65414
Policy Entropy: 3.70557
Value Function Loss: 0.09470

Mean KL Divergence: 0.01741
SB3 Clip Fraction: 0.18555
Policy Update Magnitude: 0.53957
Value Function Update Magnitude: 0.58357

Collected Steps per Second: 22,675.87987
Overall Steps per Second: 10,863.70990

Timestep Collection Time: 2.20552
Timestep Consumption Time: 2.39807
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.60358

Cumulative Model Updates: 186,422
Cumulative Timesteps: 1,554,610,056

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1554610056...
Checkpoint 1554610056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,506.37373
Policy Entropy: 3.71707
Value Function Loss: 0.09553

Mean KL Divergence: 0.01730
SB3 Clip Fraction: 0.17950
Policy Update Magnitude: 0.60046
Value Function Update Magnitude: 0.58034

Collected Steps per Second: 22,528.99502
Overall Steps per Second: 10,656.48944

Timestep Collection Time: 2.21972
Timestep Consumption Time: 2.47301
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.69273

Cumulative Model Updates: 186,428
Cumulative Timesteps: 1,554,660,064

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,311.60203
Policy Entropy: 3.68770
Value Function Loss: 0.08584

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.18341
Policy Update Magnitude: 0.58298
Value Function Update Magnitude: 0.58936

Collected Steps per Second: 22,761.79132
Overall Steps per Second: 10,834.20873

Timestep Collection Time: 2.19763
Timestep Consumption Time: 2.41941
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.61704

Cumulative Model Updates: 186,434
Cumulative Timesteps: 1,554,710,086

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1554710086...
Checkpoint 1554710086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,365.76467
Policy Entropy: 3.68500
Value Function Loss: 0.08330

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.18058
Policy Update Magnitude: 0.56783
Value Function Update Magnitude: 0.58099

Collected Steps per Second: 22,575.71411
Overall Steps per Second: 10,725.37311

Timestep Collection Time: 2.21539
Timestep Consumption Time: 2.44776
PPO Batch Consumption Time: 0.28340
Total Iteration Time: 4.66315

Cumulative Model Updates: 186,440
Cumulative Timesteps: 1,554,760,100

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,586.92342
Policy Entropy: 3.68262
Value Function Loss: 0.07717

Mean KL Divergence: 0.01701
SB3 Clip Fraction: 0.18986
Policy Update Magnitude: 0.54354
Value Function Update Magnitude: 0.51701

Collected Steps per Second: 22,771.71792
Overall Steps per Second: 10,828.02782

Timestep Collection Time: 2.19632
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.61894

Cumulative Model Updates: 186,446
Cumulative Timesteps: 1,554,810,114

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1554810114...
Checkpoint 1554810114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,548.97844
Policy Entropy: 3.69829
Value Function Loss: 0.07715

Mean KL Divergence: 0.01569
SB3 Clip Fraction: 0.17741
Policy Update Magnitude: 0.53303
Value Function Update Magnitude: 0.57088

Collected Steps per Second: 22,546.08094
Overall Steps per Second: 10,677.06560

Timestep Collection Time: 2.21866
Timestep Consumption Time: 2.46634
PPO Batch Consumption Time: 0.28386
Total Iteration Time: 4.68500

Cumulative Model Updates: 186,452
Cumulative Timesteps: 1,554,860,136

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,164.38700
Policy Entropy: 3.69485
Value Function Loss: 0.08268

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.17953
Policy Update Magnitude: 0.51811
Value Function Update Magnitude: 0.66911

Collected Steps per Second: 22,687.88424
Overall Steps per Second: 10,682.59241

Timestep Collection Time: 2.20461
Timestep Consumption Time: 2.47758
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.68220

Cumulative Model Updates: 186,458
Cumulative Timesteps: 1,554,910,154

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1554910154...
Checkpoint 1554910154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 201,931.06131
Policy Entropy: 3.69074
Value Function Loss: 0.08126

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.17197
Policy Update Magnitude: 0.49326
Value Function Update Magnitude: 0.54855

Collected Steps per Second: 22,234.00600
Overall Steps per Second: 10,592.14880

Timestep Collection Time: 2.24980
Timestep Consumption Time: 2.47276
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.72255

Cumulative Model Updates: 186,464
Cumulative Timesteps: 1,554,960,176

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 352,122.53224
Policy Entropy: 3.67117
Value Function Loss: 0.07961

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.17818
Policy Update Magnitude: 0.47857
Value Function Update Magnitude: 0.45862

Collected Steps per Second: 22,796.35120
Overall Steps per Second: 10,740.80470

Timestep Collection Time: 2.19342
Timestep Consumption Time: 2.46191
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.65533

Cumulative Model Updates: 186,470
Cumulative Timesteps: 1,555,010,178

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1555010178...
Checkpoint 1555010178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,583.35795
Policy Entropy: 3.67398
Value Function Loss: 0.08686

Mean KL Divergence: 0.01554
SB3 Clip Fraction: 0.18037
Policy Update Magnitude: 0.47371
Value Function Update Magnitude: 0.39572

Collected Steps per Second: 22,314.36765
Overall Steps per Second: 10,652.59600

Timestep Collection Time: 2.24134
Timestep Consumption Time: 2.45367
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.69501

Cumulative Model Updates: 186,476
Cumulative Timesteps: 1,555,060,192

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 111,039.21736
Policy Entropy: 3.69008
Value Function Loss: 0.08080

Mean KL Divergence: 0.01597
SB3 Clip Fraction: 0.18459
Policy Update Magnitude: 0.48865
Value Function Update Magnitude: 0.33685

Collected Steps per Second: 22,961.43137
Overall Steps per Second: 10,832.55851

Timestep Collection Time: 2.17774
Timestep Consumption Time: 2.43835
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.61608

Cumulative Model Updates: 186,482
Cumulative Timesteps: 1,555,110,196

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1555110196...
Checkpoint 1555110196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,881.57117
Policy Entropy: 3.70015
Value Function Loss: 0.08562

Mean KL Divergence: 0.01534
SB3 Clip Fraction: 0.18076
Policy Update Magnitude: 0.46348
Value Function Update Magnitude: 0.36750

Collected Steps per Second: 22,671.35183
Overall Steps per Second: 10,736.31749

Timestep Collection Time: 2.20649
Timestep Consumption Time: 2.45284
PPO Batch Consumption Time: 0.28425
Total Iteration Time: 4.65933

Cumulative Model Updates: 186,488
Cumulative Timesteps: 1,555,160,220

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,322.02005
Policy Entropy: 3.68939
Value Function Loss: 0.07488

Mean KL Divergence: 0.01525
SB3 Clip Fraction: 0.18093
Policy Update Magnitude: 0.45984
Value Function Update Magnitude: 0.38082

Collected Steps per Second: 23,032.28856
Overall Steps per Second: 10,864.42028

Timestep Collection Time: 2.17269
Timestep Consumption Time: 2.43336
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.60604

Cumulative Model Updates: 186,494
Cumulative Timesteps: 1,555,210,262

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1555210262...
Checkpoint 1555210262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,322.02005
Policy Entropy: 3.64799
Value Function Loss: 0.06783

Mean KL Divergence: 0.01585
SB3 Clip Fraction: 0.18813
Policy Update Magnitude: 0.42045
Value Function Update Magnitude: 0.34575

Collected Steps per Second: 22,790.01296
Overall Steps per Second: 10,644.53011

Timestep Collection Time: 2.19491
Timestep Consumption Time: 2.50441
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.69931

Cumulative Model Updates: 186,500
Cumulative Timesteps: 1,555,260,284

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,009.01059
Policy Entropy: 3.66418
Value Function Loss: 0.07452

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.18654
Policy Update Magnitude: 0.41712
Value Function Update Magnitude: 0.33294

Collected Steps per Second: 22,529.03994
Overall Steps per Second: 10,628.76818

Timestep Collection Time: 2.21962
Timestep Consumption Time: 2.48515
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.70478

Cumulative Model Updates: 186,506
Cumulative Timesteps: 1,555,310,290

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1555310290...
Checkpoint 1555310290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,853.28414
Policy Entropy: 3.69612
Value Function Loss: 0.07724

Mean KL Divergence: 0.01591
SB3 Clip Fraction: 0.18317
Policy Update Magnitude: 0.44793
Value Function Update Magnitude: 0.39613

Collected Steps per Second: 22,894.94326
Overall Steps per Second: 10,956.20920

Timestep Collection Time: 2.18459
Timestep Consumption Time: 2.38050
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.56508

Cumulative Model Updates: 186,512
Cumulative Timesteps: 1,555,360,306

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,494.25578
Policy Entropy: 3.71156
Value Function Loss: 0.07660

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.17409
Policy Update Magnitude: 0.44170
Value Function Update Magnitude: 0.41091

Collected Steps per Second: 22,987.10583
Overall Steps per Second: 10,859.42505

Timestep Collection Time: 2.17583
Timestep Consumption Time: 2.42994
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.60577

Cumulative Model Updates: 186,518
Cumulative Timesteps: 1,555,410,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1555410322...
Checkpoint 1555410322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,707.32094
Policy Entropy: 3.67847
Value Function Loss: 0.07355

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.18427
Policy Update Magnitude: 0.41027
Value Function Update Magnitude: 0.39542

Collected Steps per Second: 22,321.75619
Overall Steps per Second: 10,696.99326

Timestep Collection Time: 2.24158
Timestep Consumption Time: 2.43600
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.67758

Cumulative Model Updates: 186,524
Cumulative Timesteps: 1,555,460,358

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,007.40215
Policy Entropy: 3.66013
Value Function Loss: 0.06819

Mean KL Divergence: 0.01626
SB3 Clip Fraction: 0.18815
Policy Update Magnitude: 0.39387
Value Function Update Magnitude: 0.38118

Collected Steps per Second: 22,906.15067
Overall Steps per Second: 10,863.77288

Timestep Collection Time: 2.18395
Timestep Consumption Time: 2.42089
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.60485

Cumulative Model Updates: 186,530
Cumulative Timesteps: 1,555,510,384

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1555510384...
Checkpoint 1555510384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,037.14026
Policy Entropy: 3.67111
Value Function Loss: 0.06298

Mean KL Divergence: 0.01594
SB3 Clip Fraction: 0.18974
Policy Update Magnitude: 0.37886
Value Function Update Magnitude: 0.35227

Collected Steps per Second: 22,705.78806
Overall Steps per Second: 10,684.88534

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.47792
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.68044

Cumulative Model Updates: 186,536
Cumulative Timesteps: 1,555,560,394

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,498.30837
Policy Entropy: 3.68586
Value Function Loss: 0.05971

Mean KL Divergence: 0.01528
SB3 Clip Fraction: 0.18173
Policy Update Magnitude: 0.38098
Value Function Update Magnitude: 0.34143

Collected Steps per Second: 22,846.48592
Overall Steps per Second: 10,827.64045

Timestep Collection Time: 2.18878
Timestep Consumption Time: 2.42958
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.61837

Cumulative Model Updates: 186,542
Cumulative Timesteps: 1,555,610,400

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1555610400...
Checkpoint 1555610400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,398.77055
Policy Entropy: 3.68717
Value Function Loss: 0.06035

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.18239
Policy Update Magnitude: 0.39833
Value Function Update Magnitude: 0.33508

Collected Steps per Second: 22,679.35701
Overall Steps per Second: 10,724.10384

Timestep Collection Time: 2.20553
Timestep Consumption Time: 2.45873
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.66426

Cumulative Model Updates: 186,548
Cumulative Timesteps: 1,555,660,420

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,123.92837
Policy Entropy: 3.68793
Value Function Loss: 0.06361

Mean KL Divergence: 0.01544
SB3 Clip Fraction: 0.18501
Policy Update Magnitude: 0.43279
Value Function Update Magnitude: 0.36707

Collected Steps per Second: 22,919.48490
Overall Steps per Second: 10,827.81059

Timestep Collection Time: 2.18155
Timestep Consumption Time: 2.43619
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.61774

Cumulative Model Updates: 186,554
Cumulative Timesteps: 1,555,710,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1555710420...
Checkpoint 1555710420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,200.73088
Policy Entropy: 3.70003
Value Function Loss: 0.06313

Mean KL Divergence: 0.01513
SB3 Clip Fraction: 0.18633
Policy Update Magnitude: 0.43947
Value Function Update Magnitude: 0.39685

Collected Steps per Second: 22,762.90141
Overall Steps per Second: 10,684.94367

Timestep Collection Time: 2.19805
Timestep Consumption Time: 2.48461
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.68266

Cumulative Model Updates: 186,560
Cumulative Timesteps: 1,555,760,454

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,782.56391
Policy Entropy: 3.67317
Value Function Loss: 0.06373

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.18552
Policy Update Magnitude: 0.41862
Value Function Update Magnitude: 0.39240

Collected Steps per Second: 22,853.29306
Overall Steps per Second: 10,830.00134

Timestep Collection Time: 2.18787
Timestep Consumption Time: 2.42894
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.61680

Cumulative Model Updates: 186,566
Cumulative Timesteps: 1,555,810,454

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1555810454...
Checkpoint 1555810454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260,236.24546
Policy Entropy: 3.64977
Value Function Loss: 0.06475

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.18948
Policy Update Magnitude: 0.41326
Value Function Update Magnitude: 0.38097

Collected Steps per Second: 22,846.88295
Overall Steps per Second: 10,730.48683

Timestep Collection Time: 2.18927
Timestep Consumption Time: 2.47203
PPO Batch Consumption Time: 0.28583
Total Iteration Time: 4.66130

Cumulative Model Updates: 186,572
Cumulative Timesteps: 1,555,860,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292,530.34497
Policy Entropy: 3.63040
Value Function Loss: 0.07034

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.19275
Policy Update Magnitude: 0.41650
Value Function Update Magnitude: 0.33806

Collected Steps per Second: 22,789.12397
Overall Steps per Second: 10,771.43925

Timestep Collection Time: 2.19482
Timestep Consumption Time: 2.44876
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.64358

Cumulative Model Updates: 186,578
Cumulative Timesteps: 1,555,910,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1555910490...
Checkpoint 1555910490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,434.87731
Policy Entropy: 3.65236
Value Function Loss: 0.06904

Mean KL Divergence: 0.01575
SB3 Clip Fraction: 0.18107
Policy Update Magnitude: 0.42357
Value Function Update Magnitude: 0.30652

Collected Steps per Second: 22,469.87282
Overall Steps per Second: 10,809.15970

Timestep Collection Time: 2.22591
Timestep Consumption Time: 2.40127
PPO Batch Consumption Time: 0.27617
Total Iteration Time: 4.62719

Cumulative Model Updates: 186,584
Cumulative Timesteps: 1,555,960,506

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,758.27847
Policy Entropy: 3.65120
Value Function Loss: 0.07108

Mean KL Divergence: 0.01478
SB3 Clip Fraction: 0.17729
Policy Update Magnitude: 0.42770
Value Function Update Magnitude: 0.31844

Collected Steps per Second: 21,153.23531
Overall Steps per Second: 10,440.82098

Timestep Collection Time: 2.36465
Timestep Consumption Time: 2.42616
PPO Batch Consumption Time: 0.27881
Total Iteration Time: 4.79081

Cumulative Model Updates: 186,590
Cumulative Timesteps: 1,556,010,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1556010526...
Checkpoint 1556010526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 371,095.34932
Policy Entropy: 3.65569
Value Function Loss: 0.07293

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.16859
Policy Update Magnitude: 0.42552
Value Function Update Magnitude: 0.32965

Collected Steps per Second: 21,911.71211
Overall Steps per Second: 10,588.75793

Timestep Collection Time: 2.28252
Timestep Consumption Time: 2.44079
PPO Batch Consumption Time: 0.29279
Total Iteration Time: 4.72331

Cumulative Model Updates: 186,596
Cumulative Timesteps: 1,556,060,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187,786.96960
Policy Entropy: 3.62329
Value Function Loss: 0.07570

Mean KL Divergence: 0.01350
SB3 Clip Fraction: 0.16060
Policy Update Magnitude: 0.43899
Value Function Update Magnitude: 0.35970

Collected Steps per Second: 21,719.33030
Overall Steps per Second: 10,579.88532

Timestep Collection Time: 2.30247
Timestep Consumption Time: 2.42424
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.72671

Cumulative Model Updates: 186,602
Cumulative Timesteps: 1,556,110,548

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1556110548...
Checkpoint 1556110548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,664.06291
Policy Entropy: 3.63966
Value Function Loss: 0.07364

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.16171
Policy Update Magnitude: 0.46046
Value Function Update Magnitude: 0.35619

Collected Steps per Second: 22,156.76478
Overall Steps per Second: 10,742.35371

Timestep Collection Time: 2.25809
Timestep Consumption Time: 2.39936
PPO Batch Consumption Time: 0.28757
Total Iteration Time: 4.65745

Cumulative Model Updates: 186,608
Cumulative Timesteps: 1,556,160,580

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,132.81116
Policy Entropy: 3.66145
Value Function Loss: 0.07196

Mean KL Divergence: 0.01347
SB3 Clip Fraction: 0.15746
Policy Update Magnitude: 0.45942
Value Function Update Magnitude: 0.31894

Collected Steps per Second: 22,451.53130
Overall Steps per Second: 10,749.84406

Timestep Collection Time: 2.22836
Timestep Consumption Time: 2.42567
PPO Batch Consumption Time: 0.29284
Total Iteration Time: 4.65402

Cumulative Model Updates: 186,614
Cumulative Timesteps: 1,556,210,610

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1556210610...
Checkpoint 1556210610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,713.03419
Policy Entropy: 3.67950
Value Function Loss: 0.06986

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.16276
Policy Update Magnitude: 0.47028
Value Function Update Magnitude: 0.32837

Collected Steps per Second: 21,769.01117
Overall Steps per Second: 10,642.91013

Timestep Collection Time: 2.29739
Timestep Consumption Time: 2.40170
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.69909

Cumulative Model Updates: 186,620
Cumulative Timesteps: 1,556,260,622

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,189.08639
Policy Entropy: 3.68817
Value Function Loss: 0.06976

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.16261
Policy Update Magnitude: 0.47084
Value Function Update Magnitude: 0.47681

Collected Steps per Second: 22,803.26115
Overall Steps per Second: 10,861.20237

Timestep Collection Time: 2.19355
Timestep Consumption Time: 2.41184
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.60538

Cumulative Model Updates: 186,626
Cumulative Timesteps: 1,556,310,642

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1556310642...
Checkpoint 1556310642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,189.13163
Policy Entropy: 3.66992
Value Function Loss: 0.07178

Mean KL Divergence: 0.01382
SB3 Clip Fraction: 0.16403
Policy Update Magnitude: 0.45820
Value Function Update Magnitude: 0.47757

Collected Steps per Second: 22,771.30311
Overall Steps per Second: 10,726.70993

Timestep Collection Time: 2.19575
Timestep Consumption Time: 2.46552
PPO Batch Consumption Time: 0.29231
Total Iteration Time: 4.66126

Cumulative Model Updates: 186,632
Cumulative Timesteps: 1,556,360,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,733.09372
Policy Entropy: 3.66380
Value Function Loss: 0.07036

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.17243
Policy Update Magnitude: 0.44852
Value Function Update Magnitude: 0.46905

Collected Steps per Second: 22,899.02415
Overall Steps per Second: 10,850.16260

Timestep Collection Time: 2.18359
Timestep Consumption Time: 2.42482
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.60841

Cumulative Model Updates: 186,638
Cumulative Timesteps: 1,556,410,644

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1556410644...
Checkpoint 1556410644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,496.48391
Policy Entropy: 3.65689
Value Function Loss: 0.08099

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.16752
Policy Update Magnitude: 0.45728
Value Function Update Magnitude: 0.43663

Collected Steps per Second: 22,872.86243
Overall Steps per Second: 10,796.85397

Timestep Collection Time: 2.18705
Timestep Consumption Time: 2.44616
PPO Batch Consumption Time: 0.28918
Total Iteration Time: 4.63320

Cumulative Model Updates: 186,644
Cumulative Timesteps: 1,556,460,668

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,131.46339
Policy Entropy: 3.67495
Value Function Loss: 0.08813

Mean KL Divergence: 0.01367
SB3 Clip Fraction: 0.15909
Policy Update Magnitude: 0.46430
Value Function Update Magnitude: 0.38854

Collected Steps per Second: 22,505.89382
Overall Steps per Second: 10,754.74598

Timestep Collection Time: 2.22182
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.64948

Cumulative Model Updates: 186,650
Cumulative Timesteps: 1,556,510,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1556510672...
Checkpoint 1556510672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,856.97748
Policy Entropy: 3.70488
Value Function Loss: 0.08070

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.15601
Policy Update Magnitude: 0.46395
Value Function Update Magnitude: 0.35059

Collected Steps per Second: 22,633.03220
Overall Steps per Second: 10,599.50400

Timestep Collection Time: 2.20960
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.71815

Cumulative Model Updates: 186,656
Cumulative Timesteps: 1,556,560,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,024.12031
Policy Entropy: 3.71197
Value Function Loss: 0.07068

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.15919
Policy Update Magnitude: 0.46448
Value Function Update Magnitude: 0.37663

Collected Steps per Second: 22,886.23520
Overall Steps per Second: 10,887.11905

Timestep Collection Time: 2.18481
Timestep Consumption Time: 2.40796
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.59277

Cumulative Model Updates: 186,662
Cumulative Timesteps: 1,556,610,684

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1556610684...
Checkpoint 1556610684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,978.04953
Policy Entropy: 3.72125
Value Function Loss: 0.06467

Mean KL Divergence: 0.01449
SB3 Clip Fraction: 0.16437
Policy Update Magnitude: 0.45787
Value Function Update Magnitude: 0.39407

Collected Steps per Second: 22,742.29224
Overall Steps per Second: 10,642.99450

Timestep Collection Time: 2.19987
Timestep Consumption Time: 2.50088
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.70074

Cumulative Model Updates: 186,668
Cumulative Timesteps: 1,556,660,714

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,135.69282
Policy Entropy: 3.68325
Value Function Loss: 0.06580

Mean KL Divergence: 0.01495
SB3 Clip Fraction: 0.17089
Policy Update Magnitude: 0.45432
Value Function Update Magnitude: 0.36360

Collected Steps per Second: 23,045.17043
Overall Steps per Second: 10,861.20347

Timestep Collection Time: 2.17087
Timestep Consumption Time: 2.43525
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.60612

Cumulative Model Updates: 186,674
Cumulative Timesteps: 1,556,710,742

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1556710742...
Checkpoint 1556710742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,882.14305
Policy Entropy: 3.69487
Value Function Loss: 0.06545

Mean KL Divergence: 0.01452
SB3 Clip Fraction: 0.16654
Policy Update Magnitude: 0.43714
Value Function Update Magnitude: 0.33667

Collected Steps per Second: 22,424.47966
Overall Steps per Second: 10,789.01068

Timestep Collection Time: 2.23078
Timestep Consumption Time: 2.40579
PPO Batch Consumption Time: 0.27638
Total Iteration Time: 4.63657

Cumulative Model Updates: 186,680
Cumulative Timesteps: 1,556,760,766

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,462.37894
Policy Entropy: 3.70484
Value Function Loss: 0.06571

Mean KL Divergence: 0.01419
SB3 Clip Fraction: 0.16263
Policy Update Magnitude: 0.45687
Value Function Update Magnitude: 0.38837

Collected Steps per Second: 22,995.14314
Overall Steps per Second: 10,810.12981

Timestep Collection Time: 2.17542
Timestep Consumption Time: 2.45210
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.62751

Cumulative Model Updates: 186,686
Cumulative Timesteps: 1,556,810,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1556810790...
Checkpoint 1556810790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,959.36462
Policy Entropy: 3.73484
Value Function Loss: 0.06579

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.16126
Policy Update Magnitude: 0.46905
Value Function Update Magnitude: 0.38841

Collected Steps per Second: 23,031.79195
Overall Steps per Second: 10,716.99532

Timestep Collection Time: 2.17143
Timestep Consumption Time: 2.49517
PPO Batch Consumption Time: 0.29268
Total Iteration Time: 4.66661

Cumulative Model Updates: 186,692
Cumulative Timesteps: 1,556,860,802

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,410.92742
Policy Entropy: 3.73650
Value Function Loss: 0.06731

Mean KL Divergence: 0.01329
SB3 Clip Fraction: 0.16164
Policy Update Magnitude: 0.47336
Value Function Update Magnitude: 0.46035

Collected Steps per Second: 22,884.82644
Overall Steps per Second: 10,832.58747

Timestep Collection Time: 2.18485
Timestep Consumption Time: 2.43085
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.61570

Cumulative Model Updates: 186,698
Cumulative Timesteps: 1,556,910,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1556910802...
Checkpoint 1556910802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,743.95437
Policy Entropy: 3.70685
Value Function Loss: 0.06481

Mean KL Divergence: 0.01280
SB3 Clip Fraction: 0.15848
Policy Update Magnitude: 0.46127
Value Function Update Magnitude: 0.58188

Collected Steps per Second: 22,242.97898
Overall Steps per Second: 10,729.43122

Timestep Collection Time: 2.24880
Timestep Consumption Time: 2.41314
PPO Batch Consumption Time: 0.27599
Total Iteration Time: 4.66194

Cumulative Model Updates: 186,704
Cumulative Timesteps: 1,556,960,822

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 386.95818
Policy Entropy: 3.68092
Value Function Loss: 0.07156

Mean KL Divergence: 0.01373
SB3 Clip Fraction: 0.16106
Policy Update Magnitude: 0.46103
Value Function Update Magnitude: 0.51375

Collected Steps per Second: 23,028.87648
Overall Steps per Second: 10,887.59190

Timestep Collection Time: 2.17188
Timestep Consumption Time: 2.42197
PPO Batch Consumption Time: 0.27677
Total Iteration Time: 4.59385

Cumulative Model Updates: 186,710
Cumulative Timesteps: 1,557,010,838

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1557010838...
Checkpoint 1557010838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,529.26069
Policy Entropy: 3.67084
Value Function Loss: 0.07249

Mean KL Divergence: 0.01500
SB3 Clip Fraction: 0.16836
Policy Update Magnitude: 0.44762
Value Function Update Magnitude: 0.40335

Collected Steps per Second: 22,814.30850
Overall Steps per Second: 10,796.69762

Timestep Collection Time: 2.19205
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.63197

Cumulative Model Updates: 186,716
Cumulative Timesteps: 1,557,060,848

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,849.13266
Policy Entropy: 3.67852
Value Function Loss: 0.07151

Mean KL Divergence: 0.01501
SB3 Clip Fraction: 0.17175
Policy Update Magnitude: 0.48474
Value Function Update Magnitude: 0.38520

Collected Steps per Second: 22,940.33243
Overall Steps per Second: 10,713.94973

Timestep Collection Time: 2.17992
Timestep Consumption Time: 2.48764
PPO Batch Consumption Time: 0.29009
Total Iteration Time: 4.66756

Cumulative Model Updates: 186,722
Cumulative Timesteps: 1,557,110,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1557110856...
Checkpoint 1557110856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,177.46075
Policy Entropy: 3.68057
Value Function Loss: 0.08206

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.16061
Policy Update Magnitude: 0.50539
Value Function Update Magnitude: 0.47388

Collected Steps per Second: 22,646.36624
Overall Steps per Second: 10,637.94450

Timestep Collection Time: 2.20892
Timestep Consumption Time: 2.49349
PPO Batch Consumption Time: 0.29271
Total Iteration Time: 4.70241

Cumulative Model Updates: 186,728
Cumulative Timesteps: 1,557,160,880

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,917.54651
Policy Entropy: 3.68262
Value Function Loss: 0.07845

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.15836
Policy Update Magnitude: 0.53049
Value Function Update Magnitude: 0.41136

Collected Steps per Second: 22,740.22380
Overall Steps per Second: 10,811.49430

Timestep Collection Time: 2.19884
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.62489

Cumulative Model Updates: 186,734
Cumulative Timesteps: 1,557,210,882

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1557210882...
Checkpoint 1557210882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,947.00672
Policy Entropy: 3.67910
Value Function Loss: 0.07537

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.15693
Policy Update Magnitude: 0.56539
Value Function Update Magnitude: 0.48426

Collected Steps per Second: 22,710.21839
Overall Steps per Second: 10,689.34221

Timestep Collection Time: 2.20165
Timestep Consumption Time: 2.47590
PPO Batch Consumption Time: 0.28564
Total Iteration Time: 4.67756

Cumulative Model Updates: 186,740
Cumulative Timesteps: 1,557,260,882

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,627.94933
Policy Entropy: 3.70068
Value Function Loss: 0.08001

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.62413
Value Function Update Magnitude: 0.42788

Collected Steps per Second: 22,691.17437
Overall Steps per Second: 10,830.01034

Timestep Collection Time: 2.20465
Timestep Consumption Time: 2.41456
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.61920

Cumulative Model Updates: 186,746
Cumulative Timesteps: 1,557,310,908

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1557310908...
Checkpoint 1557310908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,444.12628
Policy Entropy: 3.73225
Value Function Loss: 0.07699

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.15410
Policy Update Magnitude: 0.67529
Value Function Update Magnitude: 0.42710

Collected Steps per Second: 22,575.92852
Overall Steps per Second: 10,726.32941

Timestep Collection Time: 2.21590
Timestep Consumption Time: 2.44795
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.66385

Cumulative Model Updates: 186,752
Cumulative Timesteps: 1,557,360,934

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,902.91930
Policy Entropy: 3.77389
Value Function Loss: 0.07726

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.15619
Policy Update Magnitude: 0.76973
Value Function Update Magnitude: 0.45418

Collected Steps per Second: 22,955.66588
Overall Steps per Second: 10,894.14814

Timestep Collection Time: 2.17916
Timestep Consumption Time: 2.41267
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.59182

Cumulative Model Updates: 186,758
Cumulative Timesteps: 1,557,410,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1557410958...
Checkpoint 1557410958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,038.97963
Policy Entropy: 3.78854
Value Function Loss: 0.08303

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.15650
Policy Update Magnitude: 0.87827
Value Function Update Magnitude: 0.53821

Collected Steps per Second: 22,713.44743
Overall Steps per Second: 10,696.15995

Timestep Collection Time: 2.20248
Timestep Consumption Time: 2.47452
PPO Batch Consumption Time: 0.29263
Total Iteration Time: 4.67701

Cumulative Model Updates: 186,764
Cumulative Timesteps: 1,557,460,984

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,074.16575
Policy Entropy: 3.77109
Value Function Loss: 0.08162

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.15132
Policy Update Magnitude: 0.81542
Value Function Update Magnitude: 0.53405

Collected Steps per Second: 22,956.40293
Overall Steps per Second: 10,858.56949

Timestep Collection Time: 2.17935
Timestep Consumption Time: 2.42807
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.60742

Cumulative Model Updates: 186,770
Cumulative Timesteps: 1,557,511,014

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1557511014...
Checkpoint 1557511014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,040.30235
Policy Entropy: 3.77945
Value Function Loss: 0.07749

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.16399
Policy Update Magnitude: 0.85833
Value Function Update Magnitude: 0.57912

Collected Steps per Second: 22,472.61605
Overall Steps per Second: 10,678.42692

Timestep Collection Time: 2.22511
Timestep Consumption Time: 2.45760
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.68271

Cumulative Model Updates: 186,776
Cumulative Timesteps: 1,557,561,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,486.34368
Policy Entropy: 3.82886
Value Function Loss: 0.06711

Mean KL Divergence: 0.01243
SB3 Clip Fraction: 0.14634
Policy Update Magnitude: 0.89353
Value Function Update Magnitude: 0.68057

Collected Steps per Second: 22,703.14032
Overall Steps per Second: 10,843.19951

Timestep Collection Time: 2.20234
Timestep Consumption Time: 2.40885
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.61119

Cumulative Model Updates: 186,782
Cumulative Timesteps: 1,557,611,018

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1557611018...
Checkpoint 1557611018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 267.38393
Policy Entropy: 3.89380
Value Function Loss: 0.05632

Mean KL Divergence: 0.01061
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.89448
Value Function Update Magnitude: 0.70774

Collected Steps per Second: 22,807.32090
Overall Steps per Second: 10,738.77191

Timestep Collection Time: 2.19359
Timestep Consumption Time: 2.46523
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.65882

Cumulative Model Updates: 186,788
Cumulative Timesteps: 1,557,661,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40.40414
Policy Entropy: 3.93952
Value Function Loss: 0.05319

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.09937
Policy Update Magnitude: 1.01995
Value Function Update Magnitude: 0.61924

Collected Steps per Second: 22,734.96471
Overall Steps per Second: 10,919.58264

Timestep Collection Time: 2.20005
Timestep Consumption Time: 2.38053
PPO Batch Consumption Time: 0.27656
Total Iteration Time: 4.58058

Cumulative Model Updates: 186,794
Cumulative Timesteps: 1,557,711,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1557711066...
Checkpoint 1557711066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66.53697
Policy Entropy: 3.93691
Value Function Loss: 0.05057

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09438
Policy Update Magnitude: 1.03957
Value Function Update Magnitude: 0.74950

Collected Steps per Second: 22,644.60803
Overall Steps per Second: 10,714.98076

Timestep Collection Time: 2.20989
Timestep Consumption Time: 2.46040
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.67028

Cumulative Model Updates: 186,800
Cumulative Timesteps: 1,557,761,108

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24.10630
Policy Entropy: 3.88792
Value Function Loss: 0.05228

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08467
Policy Update Magnitude: 0.95278
Value Function Update Magnitude: 0.81667

Collected Steps per Second: 22,974.57207
Overall Steps per Second: 10,795.72527

Timestep Collection Time: 2.17632
Timestep Consumption Time: 2.45514
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.63146

Cumulative Model Updates: 186,806
Cumulative Timesteps: 1,557,811,108

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1557811108...
Checkpoint 1557811108 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,924.90025
Policy Entropy: 3.80833
Value Function Loss: 0.04991

Mean KL Divergence: 0.01326
SB3 Clip Fraction: 0.16343
Policy Update Magnitude: 0.75873
Value Function Update Magnitude: 0.69292

Collected Steps per Second: 22,684.53566
Overall Steps per Second: 10,691.74683

Timestep Collection Time: 2.20503
Timestep Consumption Time: 2.47335
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.67837

Cumulative Model Updates: 186,812
Cumulative Timesteps: 1,557,861,128

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,825.42206
Policy Entropy: 3.75419
Value Function Loss: 0.04494

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.16978
Policy Update Magnitude: 0.58821
Value Function Update Magnitude: 0.50290

Collected Steps per Second: 23,061.03196
Overall Steps per Second: 10,895.00264

Timestep Collection Time: 2.16851
Timestep Consumption Time: 2.42149
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.58999

Cumulative Model Updates: 186,818
Cumulative Timesteps: 1,557,911,136

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1557911136...
Checkpoint 1557911136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,675.07112
Policy Entropy: 3.72634
Value Function Loss: 0.04118

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15477
Policy Update Magnitude: 0.45324
Value Function Update Magnitude: 0.41613

Collected Steps per Second: 22,685.24819
Overall Steps per Second: 10,633.81388

Timestep Collection Time: 2.20434
Timestep Consumption Time: 2.49821
PPO Batch Consumption Time: 0.29202
Total Iteration Time: 4.70255

Cumulative Model Updates: 186,824
Cumulative Timesteps: 1,557,961,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,675.07112
Policy Entropy: 3.71591
Value Function Loss: 0.03698

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.14868
Policy Update Magnitude: 0.45197
Value Function Update Magnitude: 0.45794

Collected Steps per Second: 22,948.48080
Overall Steps per Second: 10,852.19319

Timestep Collection Time: 2.18054
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.61105

Cumulative Model Updates: 186,830
Cumulative Timesteps: 1,558,011,182

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1558011182...
Checkpoint 1558011182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,447.67656
Policy Entropy: 3.70942
Value Function Loss: 0.03942

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10619
Policy Update Magnitude: 0.57058
Value Function Update Magnitude: 0.48369

Collected Steps per Second: 22,402.17673
Overall Steps per Second: 10,651.41703

Timestep Collection Time: 2.23219
Timestep Consumption Time: 2.46258
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.69477

Cumulative Model Updates: 186,836
Cumulative Timesteps: 1,558,061,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,053.60672
Policy Entropy: 3.71856
Value Function Loss: 0.03599

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11869
Policy Update Magnitude: 0.62163
Value Function Update Magnitude: 0.47016

Collected Steps per Second: 22,923.62861
Overall Steps per Second: 10,869.11444

Timestep Collection Time: 2.18255
Timestep Consumption Time: 2.42058
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.60313

Cumulative Model Updates: 186,842
Cumulative Timesteps: 1,558,111,220

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1558111220...
Checkpoint 1558111220 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,803.14622
Policy Entropy: 3.72228
Value Function Loss: 0.03268

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.15376
Policy Update Magnitude: 0.50797
Value Function Update Magnitude: 0.48563

Collected Steps per Second: 22,610.75915
Overall Steps per Second: 10,717.25893

Timestep Collection Time: 2.21178
Timestep Consumption Time: 2.45453
PPO Batch Consumption Time: 0.28343
Total Iteration Time: 4.66631

Cumulative Model Updates: 186,848
Cumulative Timesteps: 1,558,161,230

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,803.14622
Policy Entropy: 3.72919
Value Function Loss: 0.03070

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.15945
Policy Update Magnitude: 0.40399
Value Function Update Magnitude: 0.51388

Collected Steps per Second: 23,011.35850
Overall Steps per Second: 10,881.69395

Timestep Collection Time: 2.17354
Timestep Consumption Time: 2.42281
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.59634

Cumulative Model Updates: 186,854
Cumulative Timesteps: 1,558,211,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1558211246...
Checkpoint 1558211246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,803.14622
Policy Entropy: 3.72896
Value Function Loss: 0.02818

Mean KL Divergence: 0.01366
SB3 Clip Fraction: 0.16791
Policy Update Magnitude: 0.35231
Value Function Update Magnitude: 0.40666

Collected Steps per Second: 22,759.73379
Overall Steps per Second: 10,667.62309

Timestep Collection Time: 2.19704
Timestep Consumption Time: 2.49042
PPO Batch Consumption Time: 0.28842
Total Iteration Time: 4.68745

Cumulative Model Updates: 186,860
Cumulative Timesteps: 1,558,261,250

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,687.38140
Policy Entropy: 3.72902
Value Function Loss: 0.02599

Mean KL Divergence: 0.01687
SB3 Clip Fraction: 0.18948
Policy Update Magnitude: 0.38714
Value Function Update Magnitude: 0.37549

Collected Steps per Second: 22,694.04323
Overall Steps per Second: 10,821.07438

Timestep Collection Time: 2.20437
Timestep Consumption Time: 2.41865
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.62302

Cumulative Model Updates: 186,866
Cumulative Timesteps: 1,558,311,276

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1558311276...
Checkpoint 1558311276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,416.76071
Policy Entropy: 3.75271
Value Function Loss: 0.02280

Mean KL Divergence: 0.01984
SB3 Clip Fraction: 0.22589
Policy Update Magnitude: 0.43001
Value Function Update Magnitude: 0.48668

Collected Steps per Second: 22,648.06326
Overall Steps per Second: 10,739.03075

Timestep Collection Time: 2.20778
Timestep Consumption Time: 2.44832
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.65610

Cumulative Model Updates: 186,872
Cumulative Timesteps: 1,558,361,278

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,416.76071
Policy Entropy: 3.74605
Value Function Loss: 0.02268

Mean KL Divergence: 0.01461
SB3 Clip Fraction: 0.18031
Policy Update Magnitude: 0.35529
Value Function Update Magnitude: 0.51103

Collected Steps per Second: 22,850.41955
Overall Steps per Second: 10,859.00307

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.41884
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.60926

Cumulative Model Updates: 186,878
Cumulative Timesteps: 1,558,411,330

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1558411330...
Checkpoint 1558411330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,740.91860
Policy Entropy: 3.74798
Value Function Loss: 0.02568

Mean KL Divergence: 0.01444
SB3 Clip Fraction: 0.17901
Policy Update Magnitude: 0.33184
Value Function Update Magnitude: 0.47471

Collected Steps per Second: 22,527.84408
Overall Steps per Second: 10,696.10201

Timestep Collection Time: 2.22027
Timestep Consumption Time: 2.45601
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.67628

Cumulative Model Updates: 186,884
Cumulative Timesteps: 1,558,461,348

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,592.93164
Policy Entropy: 3.72686
Value Function Loss: 0.03144

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12622
Policy Update Magnitude: 0.51773
Value Function Update Magnitude: 0.56117

Collected Steps per Second: 22,194.74710
Overall Steps per Second: 10,843.40973

Timestep Collection Time: 2.25279
Timestep Consumption Time: 2.35831
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.61110

Cumulative Model Updates: 186,890
Cumulative Timesteps: 1,558,511,348

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1558511348...
Checkpoint 1558511348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,508.14182
Policy Entropy: 3.73872
Value Function Loss: 0.03357

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.09984
Policy Update Magnitude: 0.66112
Value Function Update Magnitude: 0.85594

Collected Steps per Second: 21,552.41893
Overall Steps per Second: 10,754.17323

Timestep Collection Time: 2.32020
Timestep Consumption Time: 2.32971
PPO Batch Consumption Time: 0.27582
Total Iteration Time: 4.64992

Cumulative Model Updates: 186,896
Cumulative Timesteps: 1,558,561,354

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,578.70594
Policy Entropy: 3.75770
Value Function Loss: 0.03613

Mean KL Divergence: 0.01539
SB3 Clip Fraction: 0.17972
Policy Update Magnitude: 0.64257
Value Function Update Magnitude: 1.04459

Collected Steps per Second: 22,399.69913
Overall Steps per Second: 10,810.83021

Timestep Collection Time: 2.23244
Timestep Consumption Time: 2.39311
PPO Batch Consumption Time: 0.28363
Total Iteration Time: 4.62555

Cumulative Model Updates: 186,902
Cumulative Timesteps: 1,558,611,360

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1558611360...
Checkpoint 1558611360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,689.00332
Policy Entropy: 3.77385
Value Function Loss: 0.03665

Mean KL Divergence: 0.01671
SB3 Clip Fraction: 0.19668
Policy Update Magnitude: 0.56242
Value Function Update Magnitude: 1.08017

Collected Steps per Second: 21,791.13186
Overall Steps per Second: 10,655.59707

Timestep Collection Time: 2.29488
Timestep Consumption Time: 2.39824
PPO Batch Consumption Time: 0.28624
Total Iteration Time: 4.69312

Cumulative Model Updates: 186,908
Cumulative Timesteps: 1,558,661,368

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,392.03361
Policy Entropy: 3.79389
Value Function Loss: 0.04556

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.18740
Policy Update Magnitude: 0.59691
Value Function Update Magnitude: 1.05549

Collected Steps per Second: 22,146.18751
Overall Steps per Second: 10,854.20878

Timestep Collection Time: 2.25827
Timestep Consumption Time: 2.34935
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.60761

Cumulative Model Updates: 186,914
Cumulative Timesteps: 1,558,711,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1558711380...
Checkpoint 1558711380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,958.38382
Policy Entropy: 3.78103
Value Function Loss: 0.04955

Mean KL Divergence: 0.01653
SB3 Clip Fraction: 0.19599
Policy Update Magnitude: 0.58656
Value Function Update Magnitude: 0.89378

Collected Steps per Second: 21,776.49307
Overall Steps per Second: 10,644.19678

Timestep Collection Time: 2.29624
Timestep Consumption Time: 2.40153
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.69777

Cumulative Model Updates: 186,920
Cumulative Timesteps: 1,558,761,384

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,320.72254
Policy Entropy: 3.75809
Value Function Loss: 0.04435

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.17025
Policy Update Magnitude: 0.59264
Value Function Update Magnitude: 0.81387

Collected Steps per Second: 23,184.33708
Overall Steps per Second: 10,948.10641

Timestep Collection Time: 2.15715
Timestep Consumption Time: 2.41095
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.56810

Cumulative Model Updates: 186,926
Cumulative Timesteps: 1,558,811,396

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1558811396...
Checkpoint 1558811396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810.27086
Policy Entropy: 3.73155
Value Function Loss: 0.03565

Mean KL Divergence: 0.01377
SB3 Clip Fraction: 0.16939
Policy Update Magnitude: 0.56774
Value Function Update Magnitude: 0.74361

Collected Steps per Second: 22,405.75486
Overall Steps per Second: 10,642.44056

Timestep Collection Time: 2.23166
Timestep Consumption Time: 2.46670
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.69836

Cumulative Model Updates: 186,932
Cumulative Timesteps: 1,558,861,398

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237.10490
Policy Entropy: 3.71055
Value Function Loss: 0.03299

Mean KL Divergence: 0.01289
SB3 Clip Fraction: 0.16226
Policy Update Magnitude: 0.49309
Value Function Update Magnitude: 0.64644

Collected Steps per Second: 22,940.90749
Overall Steps per Second: 10,969.92260

Timestep Collection Time: 2.18056
Timestep Consumption Time: 2.37955
PPO Batch Consumption Time: 0.27632
Total Iteration Time: 4.56011

Cumulative Model Updates: 186,938
Cumulative Timesteps: 1,558,911,422

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1558911422...
Checkpoint 1558911422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,430.12863
Policy Entropy: 3.70283
Value Function Loss: 0.03428

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.14864
Policy Update Magnitude: 0.51724
Value Function Update Magnitude: 0.69156

Collected Steps per Second: 22,541.70041
Overall Steps per Second: 10,613.70516

Timestep Collection Time: 2.21926
Timestep Consumption Time: 2.49408
PPO Batch Consumption Time: 0.28946
Total Iteration Time: 4.71334

Cumulative Model Updates: 186,944
Cumulative Timesteps: 1,558,961,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,277.02784
Policy Entropy: 3.71212
Value Function Loss: 0.03689

Mean KL Divergence: 0.01535
SB3 Clip Fraction: 0.17662
Policy Update Magnitude: 0.58024
Value Function Update Magnitude: 0.83479

Collected Steps per Second: 23,151.17898
Overall Steps per Second: 10,888.35972

Timestep Collection Time: 2.16067
Timestep Consumption Time: 2.43341
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.59408

Cumulative Model Updates: 186,950
Cumulative Timesteps: 1,559,011,470

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1559011470...
Checkpoint 1559011470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,187.33897
Policy Entropy: 3.71069
Value Function Loss: 0.03377

Mean KL Divergence: 0.01430
SB3 Clip Fraction: 0.17383
Policy Update Magnitude: 0.54532
Value Function Update Magnitude: 0.84970

Collected Steps per Second: 22,546.34897
Overall Steps per Second: 10,662.10786

Timestep Collection Time: 2.21827
Timestep Consumption Time: 2.47254
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.69082

Cumulative Model Updates: 186,956
Cumulative Timesteps: 1,559,061,484

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,966.34681
Policy Entropy: 3.70282
Value Function Loss: 0.02730

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.14777
Policy Update Magnitude: 0.58166
Value Function Update Magnitude: 0.93958

Collected Steps per Second: 22,938.77164
Overall Steps per Second: 10,861.90721

Timestep Collection Time: 2.18102
Timestep Consumption Time: 2.42498
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.60601

Cumulative Model Updates: 186,962
Cumulative Timesteps: 1,559,111,514

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1559111514...
Checkpoint 1559111514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,966.34681
Policy Entropy: 3.68556
Value Function Loss: 0.02188

Mean KL Divergence: 0.01310
SB3 Clip Fraction: 0.16674
Policy Update Magnitude: 0.47878
Value Function Update Magnitude: 0.79693

Collected Steps per Second: 22,087.92418
Overall Steps per Second: 10,668.70269

Timestep Collection Time: 2.26377
Timestep Consumption Time: 2.42302
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.68679

Cumulative Model Updates: 186,968
Cumulative Timesteps: 1,559,161,516

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,966.34681
Policy Entropy: 3.67119
Value Function Loss: 0.02803

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14499
Policy Update Magnitude: 0.50613
Value Function Update Magnitude: 0.77676

Collected Steps per Second: 22,625.80907
Overall Steps per Second: 10,680.98213

Timestep Collection Time: 2.21031
Timestep Consumption Time: 2.47185
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.68215

Cumulative Model Updates: 186,974
Cumulative Timesteps: 1,559,211,526

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1559211526...
Checkpoint 1559211526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,619.56761
Policy Entropy: 3.67531
Value Function Loss: 0.03420

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15456
Policy Update Magnitude: 0.60272
Value Function Update Magnitude: 0.92568

Collected Steps per Second: 22,336.30359
Overall Steps per Second: 10,585.26874

Timestep Collection Time: 2.23949
Timestep Consumption Time: 2.48613
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.72562

Cumulative Model Updates: 186,980
Cumulative Timesteps: 1,559,261,548

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,598.57696
Policy Entropy: 3.68421
Value Function Loss: 0.03639

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07525
Policy Update Magnitude: 0.72609
Value Function Update Magnitude: 0.88203

Collected Steps per Second: 23,078.11577
Overall Steps per Second: 10,749.02939

Timestep Collection Time: 2.16768
Timestep Consumption Time: 2.48632
PPO Batch Consumption Time: 0.28755
Total Iteration Time: 4.65400

Cumulative Model Updates: 186,986
Cumulative Timesteps: 1,559,311,574

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1559311574...
Checkpoint 1559311574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257,456.19756
Policy Entropy: 3.69589
Value Function Loss: 0.03195

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.66268
Value Function Update Magnitude: 0.83813

Collected Steps per Second: 22,545.88290
Overall Steps per Second: 10,626.37802

Timestep Collection Time: 2.21770
Timestep Consumption Time: 2.48757
PPO Batch Consumption Time: 0.28817
Total Iteration Time: 4.70527

Cumulative Model Updates: 186,992
Cumulative Timesteps: 1,559,361,574

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257,456.19756
Policy Entropy: 3.68787
Value Function Loss: 0.02444

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.51971
Value Function Update Magnitude: 0.74855

Collected Steps per Second: 23,041.73464
Overall Steps per Second: 10,876.26355

Timestep Collection Time: 2.17136
Timestep Consumption Time: 2.42874
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.60011

Cumulative Model Updates: 186,998
Cumulative Timesteps: 1,559,411,606

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1559411606...
Checkpoint 1559411606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257,456.19756
Policy Entropy: 3.67571
Value Function Loss: 0.02372

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11211
Policy Update Magnitude: 0.43246
Value Function Update Magnitude: 0.55205

Collected Steps per Second: 22,504.91997
Overall Steps per Second: 10,673.81361

Timestep Collection Time: 2.22263
Timestep Consumption Time: 2.46361
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.68624

Cumulative Model Updates: 187,004
Cumulative Timesteps: 1,559,461,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 173,253.18358
Policy Entropy: 3.68583
Value Function Loss: 0.02259

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.42411
Value Function Update Magnitude: 0.46342

Collected Steps per Second: 22,657.14732
Overall Steps per Second: 10,693.88447

Timestep Collection Time: 2.20760
Timestep Consumption Time: 2.46965
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.67725

Cumulative Model Updates: 187,010
Cumulative Timesteps: 1,559,511,644

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1559511644...
Checkpoint 1559511644 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,918.58109
Policy Entropy: 3.69420
Value Function Loss: 0.02543

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.41914
Value Function Update Magnitude: 0.53740

Collected Steps per Second: 22,799.97456
Overall Steps per Second: 10,856.12024

Timestep Collection Time: 2.19342
Timestep Consumption Time: 2.41319
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.60662

Cumulative Model Updates: 187,016
Cumulative Timesteps: 1,559,561,654

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,088.35266
Policy Entropy: 3.70719
Value Function Loss: 0.02632

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05181
Policy Update Magnitude: 0.51774
Value Function Update Magnitude: 0.72396

Collected Steps per Second: 23,135.31853
Overall Steps per Second: 10,874.93434

Timestep Collection Time: 2.16206
Timestep Consumption Time: 2.43751
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.59957

Cumulative Model Updates: 187,022
Cumulative Timesteps: 1,559,611,674

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1559611674...
Checkpoint 1559611674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,088.35266
Policy Entropy: 3.69435
Value Function Loss: 0.02669

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05967
Policy Update Magnitude: 0.63097
Value Function Update Magnitude: 0.78712

Collected Steps per Second: 22,637.25055
Overall Steps per Second: 10,666.80632

Timestep Collection Time: 2.20981
Timestep Consumption Time: 2.47988
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.68969

Cumulative Model Updates: 187,028
Cumulative Timesteps: 1,559,661,698

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,088.35266
Policy Entropy: 3.67510
Value Function Loss: 0.02193

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08294
Policy Update Magnitude: 0.58467
Value Function Update Magnitude: 0.77640

Collected Steps per Second: 22,877.49363
Overall Steps per Second: 10,852.69918

Timestep Collection Time: 2.18555
Timestep Consumption Time: 2.42159
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.60715

Cumulative Model Updates: 187,034
Cumulative Timesteps: 1,559,711,698

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1559711698...
Checkpoint 1559711698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,496.72402
Policy Entropy: 3.66973
Value Function Loss: 0.02125

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.05926
Policy Update Magnitude: 0.51214
Value Function Update Magnitude: 0.71752

Collected Steps per Second: 22,285.04411
Overall Steps per Second: 10,750.80234

Timestep Collection Time: 2.24402
Timestep Consumption Time: 2.40754
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.65156

Cumulative Model Updates: 187,040
Cumulative Timesteps: 1,559,761,706

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,496.72402
Policy Entropy: 3.66386
Value Function Loss: 0.02156

Mean KL Divergence: 0.01740
SB3 Clip Fraction: 0.20562
Policy Update Magnitude: 0.46783
Value Function Update Magnitude: 0.60056

Collected Steps per Second: 22,584.58447
Overall Steps per Second: 10,776.50721

Timestep Collection Time: 2.21408
Timestep Consumption Time: 2.42602
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.64009

Cumulative Model Updates: 187,046
Cumulative Timesteps: 1,559,811,710

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1559811710...
Checkpoint 1559811710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,153.70724
Policy Entropy: 3.62395
Value Function Loss: 0.05895

Mean KL Divergence: 0.02962
SB3 Clip Fraction: 0.26790
Policy Update Magnitude: 0.45541
Value Function Update Magnitude: 0.55420

Collected Steps per Second: 22,384.80848
Overall Steps per Second: 10,771.84268

Timestep Collection Time: 2.23384
Timestep Consumption Time: 2.40827
PPO Batch Consumption Time: 0.27574
Total Iteration Time: 4.64210

Cumulative Model Updates: 187,052
Cumulative Timesteps: 1,559,861,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,669.34110
Policy Entropy: 3.60659
Value Function Loss: 0.08678

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.18507
Policy Update Magnitude: 0.61063
Value Function Update Magnitude: 0.53314

Collected Steps per Second: 22,443.39654
Overall Steps per Second: 10,856.64326

Timestep Collection Time: 2.22792
Timestep Consumption Time: 2.37774
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.60566

Cumulative Model Updates: 187,058
Cumulative Timesteps: 1,559,911,716

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1559911716...
Checkpoint 1559911716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,351.78821
Policy Entropy: 3.58459
Value Function Loss: 0.09384

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.17770
Policy Update Magnitude: 0.79739
Value Function Update Magnitude: 0.49937

Collected Steps per Second: 21,559.37682
Overall Steps per Second: 10,613.21095

Timestep Collection Time: 2.32001
Timestep Consumption Time: 2.39279
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.71281

Cumulative Model Updates: 187,064
Cumulative Timesteps: 1,559,961,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,865.73226
Policy Entropy: 3.62228
Value Function Loss: 0.09168

Mean KL Divergence: 0.01252
SB3 Clip Fraction: 0.15026
Policy Update Magnitude: 0.72870
Value Function Update Magnitude: 0.48967

Collected Steps per Second: 22,092.57678
Overall Steps per Second: 10,831.81879

Timestep Collection Time: 2.26375
Timestep Consumption Time: 2.35339
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.61714

Cumulative Model Updates: 187,070
Cumulative Timesteps: 1,560,011,746

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1560011746...
Checkpoint 1560011746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,644.95522
Policy Entropy: 3.67900
Value Function Loss: 0.08240

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.91410
Value Function Update Magnitude: 0.46215

Collected Steps per Second: 21,927.60821
Overall Steps per Second: 10,692.30860

Timestep Collection Time: 2.28169
Timestep Consumption Time: 2.39756
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.67925

Cumulative Model Updates: 187,076
Cumulative Timesteps: 1,560,061,778

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,441.13501
Policy Entropy: 3.70363
Value Function Loss: 0.06989

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.11792
Policy Update Magnitude: 1.12641
Value Function Update Magnitude: 0.46910

Collected Steps per Second: 22,266.20529
Overall Steps per Second: 10,874.81951

Timestep Collection Time: 2.24672
Timestep Consumption Time: 2.35345
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.60017

Cumulative Model Updates: 187,082
Cumulative Timesteps: 1,560,111,804

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1560111804...
Checkpoint 1560111804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,230.85874
Policy Entropy: 3.69414
Value Function Loss: 0.06271

Mean KL Divergence: 0.01864
SB3 Clip Fraction: 0.21616
Policy Update Magnitude: 0.88518
Value Function Update Magnitude: 0.53137

Collected Steps per Second: 21,575.20844
Overall Steps per Second: 10,796.10052

Timestep Collection Time: 2.31868
Timestep Consumption Time: 2.31503
PPO Batch Consumption Time: 0.27439
Total Iteration Time: 4.63371

Cumulative Model Updates: 187,088
Cumulative Timesteps: 1,560,161,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,639.96189
Policy Entropy: 3.66051
Value Function Loss: 0.07228

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.14820
Policy Update Magnitude: 0.83791
Value Function Update Magnitude: 0.49071

Collected Steps per Second: 22,661.13119
Overall Steps per Second: 10,868.21261

Timestep Collection Time: 2.20722
Timestep Consumption Time: 2.39501
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.60223

Cumulative Model Updates: 187,094
Cumulative Timesteps: 1,560,211,848

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1560211848...
Checkpoint 1560211848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268,062.31736
Policy Entropy: 3.61293
Value Function Loss: 0.09403

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.12356
Policy Update Magnitude: 0.96826
Value Function Update Magnitude: 0.41421

Collected Steps per Second: 22,891.01065
Overall Steps per Second: 10,798.96381

Timestep Collection Time: 2.18557
Timestep Consumption Time: 2.44728
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.63285

Cumulative Model Updates: 187,100
Cumulative Timesteps: 1,560,261,878

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207,094.91719
Policy Entropy: 3.61997
Value Function Loss: 0.08437

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.13605
Policy Update Magnitude: 0.96010
Value Function Update Magnitude: 0.33236

Collected Steps per Second: 23,195.20350
Overall Steps per Second: 10,833.35214

Timestep Collection Time: 2.15674
Timestep Consumption Time: 2.46104
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.61778

Cumulative Model Updates: 187,106
Cumulative Timesteps: 1,560,311,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1560311904...
Checkpoint 1560311904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,497.93493
Policy Entropy: 3.63915
Value Function Loss: 0.07308

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.15732
Policy Update Magnitude: 0.75616
Value Function Update Magnitude: 0.33701

Collected Steps per Second: 22,778.32110
Overall Steps per Second: 10,711.23193

Timestep Collection Time: 2.19533
Timestep Consumption Time: 2.47322
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.66856

Cumulative Model Updates: 187,112
Cumulative Timesteps: 1,560,361,910

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,684.69446
Policy Entropy: 3.69750
Value Function Loss: 0.06472

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16380
Policy Update Magnitude: 0.59752
Value Function Update Magnitude: 0.33047

Collected Steps per Second: 23,202.03916
Overall Steps per Second: 10,746.55413

Timestep Collection Time: 2.15524
Timestep Consumption Time: 2.49797
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.65321

Cumulative Model Updates: 187,118
Cumulative Timesteps: 1,560,411,916

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1560411916...
Checkpoint 1560411916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,995.84019
Policy Entropy: 3.67502
Value Function Loss: 0.05260

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12739
Policy Update Magnitude: 0.52986
Value Function Update Magnitude: 0.37378

Collected Steps per Second: 22,807.80089
Overall Steps per Second: 10,649.14046

Timestep Collection Time: 2.19302
Timestep Consumption Time: 2.50388
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.69690

Cumulative Model Updates: 187,124
Cumulative Timesteps: 1,560,461,934

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,995.84019
Policy Entropy: 3.69210
Value Function Loss: 0.04038

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.49285
Value Function Update Magnitude: 0.36614

Collected Steps per Second: 23,157.53617
Overall Steps per Second: 10,907.83445

Timestep Collection Time: 2.15947
Timestep Consumption Time: 2.42512
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.58459

Cumulative Model Updates: 187,130
Cumulative Timesteps: 1,560,511,942

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1560511942...
Checkpoint 1560511942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,995.84019
Policy Entropy: 3.65456
Value Function Loss: 0.03670

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.41145
Value Function Update Magnitude: 0.37285

Collected Steps per Second: 22,665.81927
Overall Steps per Second: 10,659.20412

Timestep Collection Time: 2.20614
Timestep Consumption Time: 2.48502
PPO Batch Consumption Time: 0.29275
Total Iteration Time: 4.69116

Cumulative Model Updates: 187,136
Cumulative Timesteps: 1,560,561,946

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,995.84019
Policy Entropy: 3.68690
Value Function Loss: 0.02844

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14180
Policy Update Magnitude: 0.37373
Value Function Update Magnitude: 0.31343

Collected Steps per Second: 23,122.56382
Overall Steps per Second: 10,897.29095

Timestep Collection Time: 2.16369
Timestep Consumption Time: 2.42736
PPO Batch Consumption Time: 0.27637
Total Iteration Time: 4.59105

Cumulative Model Updates: 187,142
Cumulative Timesteps: 1,560,611,976

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1560611976...
Checkpoint 1560611976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,652.57476
Policy Entropy: 3.66662
Value Function Loss: 0.03553

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13951
Policy Update Magnitude: 0.33791
Value Function Update Magnitude: 0.27910

Collected Steps per Second: 22,804.75405
Overall Steps per Second: 10,697.29635

Timestep Collection Time: 2.19331
Timestep Consumption Time: 2.48245
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.67576

Cumulative Model Updates: 187,148
Cumulative Timesteps: 1,560,661,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,699.50804
Policy Entropy: 3.69260
Value Function Loss: 0.03497

Mean KL Divergence: 0.01118
SB3 Clip Fraction: 0.14349
Policy Update Magnitude: 0.40233
Value Function Update Magnitude: 0.29349

Collected Steps per Second: 23,117.93712
Overall Steps per Second: 10,821.39447

Timestep Collection Time: 2.16326
Timestep Consumption Time: 2.45815
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.62140

Cumulative Model Updates: 187,154
Cumulative Timesteps: 1,560,712,004

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1560712004...
Checkpoint 1560712004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,452.43610
Policy Entropy: 3.65993
Value Function Loss: 0.04162

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.15211
Policy Update Magnitude: 0.42235
Value Function Update Magnitude: 0.40241

Collected Steps per Second: 22,137.43770
Overall Steps per Second: 10,623.84247

Timestep Collection Time: 2.25880
Timestep Consumption Time: 2.44797
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.70677

Cumulative Model Updates: 187,160
Cumulative Timesteps: 1,560,762,008

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,569.17191
Policy Entropy: 3.68520
Value Function Loss: 0.04013

Mean KL Divergence: 0.01448
SB3 Clip Fraction: 0.16562
Policy Update Magnitude: 0.52672
Value Function Update Magnitude: 0.53285

Collected Steps per Second: 22,874.65129
Overall Steps per Second: 10,812.00851

Timestep Collection Time: 2.18696
Timestep Consumption Time: 2.43993
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.62689

Cumulative Model Updates: 187,166
Cumulative Timesteps: 1,560,812,034

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1560812034...
Checkpoint 1560812034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,569.17191
Policy Entropy: 3.67758
Value Function Loss: 0.04931

Mean KL Divergence: 0.01867
SB3 Clip Fraction: 0.21013
Policy Update Magnitude: 0.58172
Value Function Update Magnitude: 0.49329

Collected Steps per Second: 22,308.05239
Overall Steps per Second: 10,643.43083

Timestep Collection Time: 2.24179
Timestep Consumption Time: 2.45688
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.69867

Cumulative Model Updates: 187,172
Cumulative Timesteps: 1,560,862,044

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 85,918.64416
Policy Entropy: 3.66537
Value Function Loss: 0.05296

Mean KL Divergence: 0.02341
SB3 Clip Fraction: 0.23800
Policy Update Magnitude: 0.57186
Value Function Update Magnitude: 0.54302

Collected Steps per Second: 22,319.48253
Overall Steps per Second: 10,524.63841

Timestep Collection Time: 2.24127
Timestep Consumption Time: 2.51177
PPO Batch Consumption Time: 0.29315
Total Iteration Time: 4.75304

Cumulative Model Updates: 187,178
Cumulative Timesteps: 1,560,912,068

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1560912068...
Checkpoint 1560912068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,564.58199
Policy Entropy: 3.67721
Value Function Loss: 0.05650

Mean KL Divergence: 0.01516
SB3 Clip Fraction: 0.17664
Policy Update Magnitude: 0.58020
Value Function Update Magnitude: 0.49480

Collected Steps per Second: 22,204.51122
Overall Steps per Second: 10,642.64084

Timestep Collection Time: 2.25234
Timestep Consumption Time: 2.44687
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.69921

Cumulative Model Updates: 187,184
Cumulative Timesteps: 1,560,962,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,774.66449
Policy Entropy: 3.69693
Value Function Loss: 0.05367

Mean KL Divergence: 0.01434
SB3 Clip Fraction: 0.17193
Policy Update Magnitude: 0.59746
Value Function Update Magnitude: 0.51290

Collected Steps per Second: 22,574.09905
Overall Steps per Second: 10,686.85375

Timestep Collection Time: 2.21555
Timestep Consumption Time: 2.46441
PPO Batch Consumption Time: 0.28567
Total Iteration Time: 4.67996

Cumulative Model Updates: 187,190
Cumulative Timesteps: 1,561,012,094

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1561012094...
Checkpoint 1561012094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,714.64871
Policy Entropy: 3.69927
Value Function Loss: 0.05509

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.11732
Policy Update Magnitude: 0.73665
Value Function Update Magnitude: 0.43405

Collected Steps per Second: 22,554.87120
Overall Steps per Second: 10,798.54511

Timestep Collection Time: 2.21788
Timestep Consumption Time: 2.41460
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.63248

Cumulative Model Updates: 187,196
Cumulative Timesteps: 1,561,062,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,830.12018
Policy Entropy: 3.70904
Value Function Loss: 0.04761

Mean KL Divergence: 0.01114
SB3 Clip Fraction: 0.13701
Policy Update Magnitude: 0.75859
Value Function Update Magnitude: 0.35012

Collected Steps per Second: 22,301.15483
Overall Steps per Second: 10,921.47846

Timestep Collection Time: 2.24329
Timestep Consumption Time: 2.33741
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.58070

Cumulative Model Updates: 187,202
Cumulative Timesteps: 1,561,112,146

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1561112146...
Checkpoint 1561112146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,830.12018
Policy Entropy: 3.71367
Value Function Loss: 0.03944

Mean KL Divergence: 0.01456
SB3 Clip Fraction: 0.18891
Policy Update Magnitude: 0.56726
Value Function Update Magnitude: 0.34117

Collected Steps per Second: 21,701.16906
Overall Steps per Second: 10,700.63798

Timestep Collection Time: 2.30412
Timestep Consumption Time: 2.36869
PPO Batch Consumption Time: 0.28197
Total Iteration Time: 4.67281

Cumulative Model Updates: 187,208
Cumulative Timesteps: 1,561,162,148

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,830.12018
Policy Entropy: 3.71829
Value Function Loss: 0.03167

Mean KL Divergence: 0.01215
SB3 Clip Fraction: 0.16166
Policy Update Magnitude: 0.42276
Value Function Update Magnitude: 0.31500

Collected Steps per Second: 22,496.45741
Overall Steps per Second: 10,869.24380

Timestep Collection Time: 2.22373
Timestep Consumption Time: 2.37880
PPO Batch Consumption Time: 0.28269
Total Iteration Time: 4.60253

Cumulative Model Updates: 187,214
Cumulative Timesteps: 1,561,212,174

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1561212174...
Checkpoint 1561212174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,830.12018
Policy Entropy: 3.71321
Value Function Loss: 0.02717

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.34182
Value Function Update Magnitude: 0.27299

Collected Steps per Second: 21,808.66943
Overall Steps per Second: 10,648.05030

Timestep Collection Time: 2.29358
Timestep Consumption Time: 2.40399
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.69757

Cumulative Model Updates: 187,220
Cumulative Timesteps: 1,561,262,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,830.12018
Policy Entropy: 3.71107
Value Function Loss: 0.02784

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12310
Policy Update Magnitude: 0.32557
Value Function Update Magnitude: 0.25805

Collected Steps per Second: 23,093.10323
Overall Steps per Second: 10,992.14375

Timestep Collection Time: 2.16524
Timestep Consumption Time: 2.38365
PPO Batch Consumption Time: 0.27598
Total Iteration Time: 4.54889

Cumulative Model Updates: 187,226
Cumulative Timesteps: 1,561,312,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1561312196...
Checkpoint 1561312196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,830.12018
Policy Entropy: 3.70612
Value Function Loss: 0.02362

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.30038
Value Function Update Magnitude: 0.21405

Collected Steps per Second: 22,513.78554
Overall Steps per Second: 10,703.16169

Timestep Collection Time: 2.22184
Timestep Consumption Time: 2.45173
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.67357

Cumulative Model Updates: 187,232
Cumulative Timesteps: 1,561,362,218

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,830.12018
Policy Entropy: 3.69313
Value Function Loss: 0.01968

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.26482
Value Function Update Magnitude: 0.22908

Collected Steps per Second: 22,840.10194
Overall Steps per Second: 10,843.29578

Timestep Collection Time: 2.19036
Timestep Consumption Time: 2.42337
PPO Batch Consumption Time: 0.27641
Total Iteration Time: 4.61373

Cumulative Model Updates: 187,238
Cumulative Timesteps: 1,561,412,246

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1561412246...
Checkpoint 1561412246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,830.12018
Policy Entropy: 3.69231
Value Function Loss: 0.01884

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.14074
Policy Update Magnitude: 0.24498
Value Function Update Magnitude: 0.25902

Collected Steps per Second: 22,373.51262
Overall Steps per Second: 10,595.75192

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.48558
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.72170

Cumulative Model Updates: 187,244
Cumulative Timesteps: 1,561,462,276

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,830.12018
Policy Entropy: 3.68724
Value Function Loss: 0.01990

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12333
Policy Update Magnitude: 0.25985
Value Function Update Magnitude: 0.27046

Collected Steps per Second: 23,136.95442
Overall Steps per Second: 10,916.84975

Timestep Collection Time: 2.16226
Timestep Consumption Time: 2.42039
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.58264

Cumulative Model Updates: 187,250
Cumulative Timesteps: 1,561,512,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1561512304...
Checkpoint 1561512304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210,451.07368
Policy Entropy: 3.69997
Value Function Loss: 0.02099

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.30010
Value Function Update Magnitude: 0.33538

Collected Steps per Second: 22,361.97838
Overall Steps per Second: 10,655.48107

Timestep Collection Time: 2.23612
Timestep Consumption Time: 2.45668
PPO Batch Consumption Time: 0.28491
Total Iteration Time: 4.69280

Cumulative Model Updates: 187,256
Cumulative Timesteps: 1,561,562,308

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144,793.71336
Policy Entropy: 3.68424
Value Function Loss: 0.02385

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13194
Policy Update Magnitude: 0.30985
Value Function Update Magnitude: 0.37812

Collected Steps per Second: 22,897.96901
Overall Steps per Second: 10,858.08700

Timestep Collection Time: 2.18543
Timestep Consumption Time: 2.42330
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.60873

Cumulative Model Updates: 187,262
Cumulative Timesteps: 1,561,612,350

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1561612350...
Checkpoint 1561612350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,973.26099
Policy Entropy: 3.69991
Value Function Loss: 0.02250

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12576
Policy Update Magnitude: 0.30697
Value Function Update Magnitude: 0.50439

Collected Steps per Second: 22,567.82449
Overall Steps per Second: 10,680.20118

Timestep Collection Time: 2.21661
Timestep Consumption Time: 2.46720
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.68381

Cumulative Model Updates: 187,268
Cumulative Timesteps: 1,561,662,374

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,973.26099
Policy Entropy: 3.69072
Value Function Loss: 0.02164

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13713
Policy Update Magnitude: 0.31260
Value Function Update Magnitude: 0.53917

Collected Steps per Second: 22,330.50088
Overall Steps per Second: 10,927.84812

Timestep Collection Time: 2.23945
Timestep Consumption Time: 2.33675
PPO Batch Consumption Time: 0.27664
Total Iteration Time: 4.57620

Cumulative Model Updates: 187,274
Cumulative Timesteps: 1,561,712,382

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1561712382...
Checkpoint 1561712382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,973.26099
Policy Entropy: 3.70477
Value Function Loss: 0.01708

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.29793
Value Function Update Magnitude: 0.49000

Collected Steps per Second: 21,551.45661
Overall Steps per Second: 10,627.20736

Timestep Collection Time: 2.32012
Timestep Consumption Time: 2.38497
PPO Batch Consumption Time: 0.28561
Total Iteration Time: 4.70509

Cumulative Model Updates: 187,280
Cumulative Timesteps: 1,561,762,384

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,973.26099
Policy Entropy: 3.70228
Value Function Loss: 0.01516

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.27034
Value Function Update Magnitude: 0.40609

Collected Steps per Second: 22,305.16162
Overall Steps per Second: 10,914.88673

Timestep Collection Time: 2.24244
Timestep Consumption Time: 2.34011
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.58255

Cumulative Model Updates: 187,286
Cumulative Timesteps: 1,561,812,402

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1561812402...
Checkpoint 1561812402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,973.26099
Policy Entropy: 3.69911
Value Function Loss: 0.01319

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12436
Policy Update Magnitude: 0.27315
Value Function Update Magnitude: 0.35228

Collected Steps per Second: 22,286.32848
Overall Steps per Second: 10,632.89222

Timestep Collection Time: 2.24416
Timestep Consumption Time: 2.45955
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.70371

Cumulative Model Updates: 187,292
Cumulative Timesteps: 1,561,862,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,973.26099
Policy Entropy: 3.68596
Value Function Loss: 0.01361

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12330
Policy Update Magnitude: 0.28264
Value Function Update Magnitude: 0.34256

Collected Steps per Second: 22,735.29650
Overall Steps per Second: 10,898.22350

Timestep Collection Time: 2.20028
Timestep Consumption Time: 2.38983
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.59011

Cumulative Model Updates: 187,298
Cumulative Timesteps: 1,561,912,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1561912440...
Checkpoint 1561912440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 221,649.28613
Policy Entropy: 3.68603
Value Function Loss: 0.02042

Mean KL Divergence: 0.00514
SB3 Clip Fraction: 0.06091
Policy Update Magnitude: 0.44809
Value Function Update Magnitude: 0.58054

Collected Steps per Second: 22,198.54535
Overall Steps per Second: 10,669.76495

Timestep Collection Time: 2.25330
Timestep Consumption Time: 2.43471
PPO Batch Consumption Time: 0.27623
Total Iteration Time: 4.68801

Cumulative Model Updates: 187,304
Cumulative Timesteps: 1,561,962,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,408.74062
Policy Entropy: 3.69507
Value Function Loss: 0.02315

Mean KL Divergence: 0.00484
SB3 Clip Fraction: 0.05360
Policy Update Magnitude: 0.56395
Value Function Update Magnitude: 0.82107

Collected Steps per Second: 22,811.41835
Overall Steps per Second: 10,814.64672

Timestep Collection Time: 2.19206
Timestep Consumption Time: 2.43167
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.62373

Cumulative Model Updates: 187,310
Cumulative Timesteps: 1,562,012,464

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1562012464...
Checkpoint 1562012464 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,408.74062
Policy Entropy: 3.68386
Value Function Loss: 0.02577

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11274
Policy Update Magnitude: 0.54053
Value Function Update Magnitude: 0.82280

Collected Steps per Second: 22,313.89485
Overall Steps per Second: 10,730.25998

Timestep Collection Time: 2.24111
Timestep Consumption Time: 2.41935
PPO Batch Consumption Time: 0.27613
Total Iteration Time: 4.66046

Cumulative Model Updates: 187,316
Cumulative Timesteps: 1,562,062,472

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,408.74062
Policy Entropy: 3.66560
Value Function Loss: 0.02623

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.48299
Value Function Update Magnitude: 0.69993

Collected Steps per Second: 22,867.93227
Overall Steps per Second: 10,852.52662

Timestep Collection Time: 2.18691
Timestep Consumption Time: 2.42124
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.60814

Cumulative Model Updates: 187,322
Cumulative Timesteps: 1,562,112,482

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1562112482...
Checkpoint 1562112482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,408.74062
Policy Entropy: 3.65315
Value Function Loss: 0.02702

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14213
Policy Update Magnitude: 0.49046
Value Function Update Magnitude: 0.53450

Collected Steps per Second: 22,409.07702
Overall Steps per Second: 10,665.60096

Timestep Collection Time: 2.23231
Timestep Consumption Time: 2.45791
PPO Batch Consumption Time: 0.28529
Total Iteration Time: 4.69022

Cumulative Model Updates: 187,328
Cumulative Timesteps: 1,562,162,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,408.74062
Policy Entropy: 3.65637
Value Function Loss: 0.03000

Mean KL Divergence: 0.01431
SB3 Clip Fraction: 0.17895
Policy Update Magnitude: 0.47891
Value Function Update Magnitude: 0.42332

Collected Steps per Second: 23,001.14316
Overall Steps per Second: 10,858.07218

Timestep Collection Time: 2.17381
Timestep Consumption Time: 2.43106
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.60487

Cumulative Model Updates: 187,334
Cumulative Timesteps: 1,562,212,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1562212506...
Checkpoint 1562212506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349,175.39926
Policy Entropy: 3.66782
Value Function Loss: 0.03708

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.10937
Policy Update Magnitude: 0.53839
Value Function Update Magnitude: 0.40730

Collected Steps per Second: 21,611.24853
Overall Steps per Second: 10,680.19580

Timestep Collection Time: 2.31389
Timestep Consumption Time: 2.36824
PPO Batch Consumption Time: 0.28182
Total Iteration Time: 4.68212

Cumulative Model Updates: 187,340
Cumulative Timesteps: 1,562,262,512

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,784.97336
Policy Entropy: 3.68528
Value Function Loss: 0.03660

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.18890
Policy Update Magnitude: 0.58288
Value Function Update Magnitude: 0.43989

Collected Steps per Second: 22,005.01213
Overall Steps per Second: 10,805.33055

Timestep Collection Time: 2.27385
Timestep Consumption Time: 2.35683
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.63068

Cumulative Model Updates: 187,346
Cumulative Timesteps: 1,562,312,548

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1562312548...
Checkpoint 1562312548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,732.87262
Policy Entropy: 3.69590
Value Function Loss: 0.03625

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14426
Policy Update Magnitude: 0.54700
Value Function Update Magnitude: 0.45839

Collected Steps per Second: 21,580.30246
Overall Steps per Second: 10,470.46514

Timestep Collection Time: 2.31804
Timestep Consumption Time: 2.45959
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.77763

Cumulative Model Updates: 187,352
Cumulative Timesteps: 1,562,362,572

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,732.87262
Policy Entropy: 3.71561
Value Function Loss: 0.02841

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.15431
Policy Update Magnitude: 0.50651
Value Function Update Magnitude: 0.48190

Collected Steps per Second: 23,072.90696
Overall Steps per Second: 10,793.40852

Timestep Collection Time: 2.16800
Timestep Consumption Time: 2.46650
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.63450

Cumulative Model Updates: 187,358
Cumulative Timesteps: 1,562,412,594

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1562412594...
Checkpoint 1562412594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,732.87262
Policy Entropy: 3.69596
Value Function Loss: 0.02561

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16053
Policy Update Magnitude: 0.43514
Value Function Update Magnitude: 0.41694

Collected Steps per Second: 22,631.67129
Overall Steps per Second: 10,702.01743

Timestep Collection Time: 2.21027
Timestep Consumption Time: 2.46381
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.67407

Cumulative Model Updates: 187,364
Cumulative Timesteps: 1,562,462,616

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,732.87262
Policy Entropy: 3.70317
Value Function Loss: 0.02530

Mean KL Divergence: 0.01163
SB3 Clip Fraction: 0.15523
Policy Update Magnitude: 0.37887
Value Function Update Magnitude: 0.33695

Collected Steps per Second: 23,066.88271
Overall Steps per Second: 10,786.22549

Timestep Collection Time: 2.16848
Timestep Consumption Time: 2.46892
PPO Batch Consumption Time: 0.28344
Total Iteration Time: 4.63740

Cumulative Model Updates: 187,370
Cumulative Timesteps: 1,562,512,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1562512636...
Checkpoint 1562512636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,732.87262
Policy Entropy: 3.70264
Value Function Loss: 0.02358

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14703
Policy Update Magnitude: 0.38422
Value Function Update Magnitude: 0.37752

Collected Steps per Second: 22,487.86647
Overall Steps per Second: 10,648.25755

Timestep Collection Time: 2.22404
Timestep Consumption Time: 2.47287
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.69692

Cumulative Model Updates: 187,376
Cumulative Timesteps: 1,562,562,650

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,732.87262
Policy Entropy: 3.70598
Value Function Loss: 0.02175

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.36135
Value Function Update Magnitude: 0.44652

Collected Steps per Second: 22,990.12445
Overall Steps per Second: 10,843.16254

Timestep Collection Time: 2.17572
Timestep Consumption Time: 2.43733
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.61305

Cumulative Model Updates: 187,382
Cumulative Timesteps: 1,562,612,670

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1562612670...
Checkpoint 1562612670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,732.87262
Policy Entropy: 3.70036
Value Function Loss: 0.01960

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13414
Policy Update Magnitude: 0.31975
Value Function Update Magnitude: 0.38394

Collected Steps per Second: 22,468.14329
Overall Steps per Second: 10,691.19049

Timestep Collection Time: 2.22582
Timestep Consumption Time: 2.45186
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.67768

Cumulative Model Updates: 187,388
Cumulative Timesteps: 1,562,662,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 64,732.87262
Policy Entropy: 3.69431
Value Function Loss: 0.01917

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13788
Policy Update Magnitude: 0.30364
Value Function Update Magnitude: 0.35560

Collected Steps per Second: 22,781.94882
Overall Steps per Second: 10,834.11508

Timestep Collection Time: 2.19516
Timestep Consumption Time: 2.42082
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.61597

Cumulative Model Updates: 187,394
Cumulative Timesteps: 1,562,712,690

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1562712690...
Checkpoint 1562712690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,632.82694
Policy Entropy: 3.69653
Value Function Loss: 0.01811

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.29812
Value Function Update Magnitude: 0.44556

Collected Steps per Second: 22,621.91463
Overall Steps per Second: 10,829.73340

Timestep Collection Time: 2.21148
Timestep Consumption Time: 2.40802
PPO Batch Consumption Time: 0.27590
Total Iteration Time: 4.61950

Cumulative Model Updates: 187,400
Cumulative Timesteps: 1,562,762,718

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,054.03262
Policy Entropy: 3.71160
Value Function Loss: 0.01957

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.31576
Value Function Update Magnitude: 0.59801

Collected Steps per Second: 22,351.76365
Overall Steps per Second: 10,830.75145

Timestep Collection Time: 2.23839
Timestep Consumption Time: 2.38105
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.61944

Cumulative Model Updates: 187,406
Cumulative Timesteps: 1,562,812,750

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1562812750...
Checkpoint 1562812750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,030.95473
Policy Entropy: 3.72339
Value Function Loss: 0.01972

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12062
Policy Update Magnitude: 0.36244
Value Function Update Magnitude: 0.78834

Collected Steps per Second: 22,234.77096
Overall Steps per Second: 10,724.63616

Timestep Collection Time: 2.24954
Timestep Consumption Time: 2.41430
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.66384

Cumulative Model Updates: 187,412
Cumulative Timesteps: 1,562,862,768

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,909.95354
Policy Entropy: 3.71901
Value Function Loss: 0.01923

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.38979
Value Function Update Magnitude: 0.87727

Collected Steps per Second: 22,356.86716
Overall Steps per Second: 10,770.09981

Timestep Collection Time: 2.23752
Timestep Consumption Time: 2.40719
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.64471

Cumulative Model Updates: 187,418
Cumulative Timesteps: 1,562,912,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1562912792...
Checkpoint 1562912792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,866.96641
Policy Entropy: 3.71475
Value Function Loss: 0.01872

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.40594
Value Function Update Magnitude: 0.84920

Collected Steps per Second: 22,458.67010
Overall Steps per Second: 10,726.33253

Timestep Collection Time: 2.22631
Timestep Consumption Time: 2.43511
PPO Batch Consumption Time: 0.28488
Total Iteration Time: 4.66143

Cumulative Model Updates: 187,424
Cumulative Timesteps: 1,562,962,792

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,866.96641
Policy Entropy: 3.70326
Value Function Loss: 0.01628

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12735
Policy Update Magnitude: 0.38197
Value Function Update Magnitude: 0.80152

Collected Steps per Second: 22,829.42168
Overall Steps per Second: 10,874.17035

Timestep Collection Time: 2.19121
Timestep Consumption Time: 2.40905
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.60026

Cumulative Model Updates: 187,430
Cumulative Timesteps: 1,563,012,816

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1563012816...
Checkpoint 1563012816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,866.96641
Policy Entropy: 3.70560
Value Function Loss: 0.01543

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13289
Policy Update Magnitude: 0.37139
Value Function Update Magnitude: 0.67255

Collected Steps per Second: 22,532.08735
Overall Steps per Second: 10,636.71008

Timestep Collection Time: 2.22003
Timestep Consumption Time: 2.48274
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.70277

Cumulative Model Updates: 187,436
Cumulative Timesteps: 1,563,062,838

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 133,643.69065
Policy Entropy: 3.69650
Value Function Loss: 0.01616

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.32688
Value Function Update Magnitude: 0.54037

Collected Steps per Second: 23,033.07165
Overall Steps per Second: 10,879.79066

Timestep Collection Time: 2.17253
Timestep Consumption Time: 2.42682
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.59935

Cumulative Model Updates: 187,442
Cumulative Timesteps: 1,563,112,878

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1563112878...
Checkpoint 1563112878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.67929
Value Function Loss: 0.02153

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.11989
Policy Update Magnitude: 0.35514
Value Function Update Magnitude: 0.54921

Collected Steps per Second: 22,338.51916
Overall Steps per Second: 10,743.29582

Timestep Collection Time: 2.23847
Timestep Consumption Time: 2.41597
PPO Batch Consumption Time: 0.27596
Total Iteration Time: 4.65444

Cumulative Model Updates: 187,448
Cumulative Timesteps: 1,563,162,882

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.68200
Value Function Loss: 0.02432

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.44892
Value Function Update Magnitude: 0.58460

Collected Steps per Second: 22,783.50754
Overall Steps per Second: 10,818.79230

Timestep Collection Time: 2.19562
Timestep Consumption Time: 2.42818
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.62381

Cumulative Model Updates: 187,454
Cumulative Timesteps: 1,563,212,906

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1563212906...
Checkpoint 1563212906 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.68958
Value Function Loss: 0.02263

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12414
Policy Update Magnitude: 0.47241
Value Function Update Magnitude: 0.60667

Collected Steps per Second: 22,470.99595
Overall Steps per Second: 10,696.59576

Timestep Collection Time: 2.22714
Timestep Consumption Time: 2.45155
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.67868

Cumulative Model Updates: 187,460
Cumulative Timesteps: 1,563,262,952

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.70336
Value Function Loss: 0.01935

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.05793
Policy Update Magnitude: 0.47234
Value Function Update Magnitude: 0.45134

Collected Steps per Second: 22,751.90920
Overall Steps per Second: 10,816.67099

Timestep Collection Time: 2.19815
Timestep Consumption Time: 2.42546
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.62360

Cumulative Model Updates: 187,466
Cumulative Timesteps: 1,563,312,964

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1563312964...
Checkpoint 1563312964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.68972
Value Function Loss: 0.01757

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05675
Policy Update Magnitude: 0.49092
Value Function Update Magnitude: 0.39105

Collected Steps per Second: 22,324.85082
Overall Steps per Second: 10,722.31805

Timestep Collection Time: 2.24046
Timestep Consumption Time: 2.42439
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.66485

Cumulative Model Updates: 187,472
Cumulative Timesteps: 1,563,362,982

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.69142
Value Function Loss: 0.01827

Mean KL Divergence: 0.00397
SB3 Clip Fraction: 0.04163
Policy Update Magnitude: 0.52003
Value Function Update Magnitude: 0.50767

Collected Steps per Second: 22,821.60611
Overall Steps per Second: 10,825.59688

Timestep Collection Time: 2.19169
Timestep Consumption Time: 2.42865
PPO Batch Consumption Time: 0.27875
Total Iteration Time: 4.62035

Cumulative Model Updates: 187,478
Cumulative Timesteps: 1,563,413,000

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1563413000...
Checkpoint 1563413000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.69808
Value Function Loss: 0.01634

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04636
Policy Update Magnitude: 0.52302
Value Function Update Magnitude: 0.55253

Collected Steps per Second: 22,438.59427
Overall Steps per Second: 10,787.94619

Timestep Collection Time: 2.22946
Timestep Consumption Time: 2.40775
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.63721

Cumulative Model Updates: 187,484
Cumulative Timesteps: 1,563,463,026

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.70555
Value Function Loss: 0.01692

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06198
Policy Update Magnitude: 0.49597
Value Function Update Magnitude: 0.47858

Collected Steps per Second: 23,065.61916
Overall Steps per Second: 10,915.42780

Timestep Collection Time: 2.16868
Timestep Consumption Time: 2.41401
PPO Batch Consumption Time: 0.27609
Total Iteration Time: 4.58269

Cumulative Model Updates: 187,490
Cumulative Timesteps: 1,563,513,048

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1563513048...
Checkpoint 1563513048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.72216
Value Function Loss: 0.01502

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05165
Policy Update Magnitude: 0.49497
Value Function Update Magnitude: 0.45216

Collected Steps per Second: 22,913.66386
Overall Steps per Second: 10,745.60761

Timestep Collection Time: 2.18324
Timestep Consumption Time: 2.47224
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.65548

Cumulative Model Updates: 187,496
Cumulative Timesteps: 1,563,563,074

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.71153
Value Function Loss: 0.01639

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06094
Policy Update Magnitude: 0.47444
Value Function Update Magnitude: 0.46645

Collected Steps per Second: 22,367.48955
Overall Steps per Second: 10,735.74269

Timestep Collection Time: 2.23592
Timestep Consumption Time: 2.42253
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.65846

Cumulative Model Updates: 187,502
Cumulative Timesteps: 1,563,613,086

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1563613086...
Checkpoint 1563613086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.71763
Value Function Loss: 0.01441

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05745
Policy Update Magnitude: 0.42325
Value Function Update Magnitude: 0.40827

Collected Steps per Second: 22,124.07386
Overall Steps per Second: 10,709.73032

Timestep Collection Time: 2.26089
Timestep Consumption Time: 2.40963
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.67052

Cumulative Model Updates: 187,508
Cumulative Timesteps: 1,563,663,106

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.70731
Value Function Loss: 0.01350

Mean KL Divergence: 0.00373
SB3 Clip Fraction: 0.03794
Policy Update Magnitude: 0.37919
Value Function Update Magnitude: 0.34266

Collected Steps per Second: 22,433.88797
Overall Steps per Second: 10,800.64145

Timestep Collection Time: 2.22904
Timestep Consumption Time: 2.40087
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.62991

Cumulative Model Updates: 187,514
Cumulative Timesteps: 1,563,713,112

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1563713112...
Checkpoint 1563713112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.72311
Value Function Loss: 0.01190

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03951
Policy Update Magnitude: 0.36277
Value Function Update Magnitude: 0.28728

Collected Steps per Second: 22,470.21571
Overall Steps per Second: 10,676.91573

Timestep Collection Time: 2.22543
Timestep Consumption Time: 2.45813
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.68356

Cumulative Model Updates: 187,520
Cumulative Timesteps: 1,563,763,118

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.73534
Value Function Loss: 0.01207

Mean KL Divergence: 0.00360
SB3 Clip Fraction: 0.03656
Policy Update Magnitude: 0.37201
Value Function Update Magnitude: 0.38314

Collected Steps per Second: 22,582.31582
Overall Steps per Second: 10,841.21403

Timestep Collection Time: 2.21412
Timestep Consumption Time: 2.39791
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.61203

Cumulative Model Updates: 187,526
Cumulative Timesteps: 1,563,813,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1563813118...
Checkpoint 1563813118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.73383
Value Function Loss: 0.01253

Mean KL Divergence: 0.00425
SB3 Clip Fraction: 0.04733
Policy Update Magnitude: 0.39074
Value Function Update Magnitude: 0.43784

Collected Steps per Second: 22,613.21373
Overall Steps per Second: 10,690.27673

Timestep Collection Time: 2.21110
Timestep Consumption Time: 2.46605
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.67715

Cumulative Model Updates: 187,532
Cumulative Timesteps: 1,563,863,118

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.72573
Value Function Loss: 0.01253

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04873
Policy Update Magnitude: 0.39654
Value Function Update Magnitude: 0.43053

Collected Steps per Second: 22,832.68690
Overall Steps per Second: 10,857.38328

Timestep Collection Time: 2.19011
Timestep Consumption Time: 2.41561
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.60571

Cumulative Model Updates: 187,538
Cumulative Timesteps: 1,563,913,124

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1563913124...
Checkpoint 1563913124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,274.92406
Policy Entropy: 3.71746
Value Function Loss: 0.01377

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05311
Policy Update Magnitude: 0.41017
Value Function Update Magnitude: 0.42300

Collected Steps per Second: 22,615.75857
Overall Steps per Second: 10,709.49528

Timestep Collection Time: 2.21138
Timestep Consumption Time: 2.45850
PPO Batch Consumption Time: 0.28420
Total Iteration Time: 4.66987

Cumulative Model Updates: 187,544
Cumulative Timesteps: 1,563,963,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 467,459.83534
Policy Entropy: 3.71290
Value Function Loss: 0.01930

Mean KL Divergence: 0.00624
SB3 Clip Fraction: 0.07640
Policy Update Magnitude: 0.49792
Value Function Update Magnitude: 0.49619

Collected Steps per Second: 22,567.72641
Overall Steps per Second: 10,785.64836

Timestep Collection Time: 2.21688
Timestep Consumption Time: 2.42169
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.63857

Cumulative Model Updates: 187,550
Cumulative Timesteps: 1,564,013,166

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1564013166...
Checkpoint 1564013166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,430.52368
Policy Entropy: 3.71218
Value Function Loss: 0.02504

Mean KL Divergence: 0.01119
SB3 Clip Fraction: 0.14414
Policy Update Magnitude: 0.49046
Value Function Update Magnitude: 0.53921

Collected Steps per Second: 22,499.48257
Overall Steps per Second: 10,723.41400

Timestep Collection Time: 2.22254
Timestep Consumption Time: 2.44071
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.66325

Cumulative Model Updates: 187,556
Cumulative Timesteps: 1,564,063,172

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,430.52368
Policy Entropy: 3.69492
Value Function Loss: 0.03302

Mean KL Divergence: 0.01515
SB3 Clip Fraction: 0.18424
Policy Update Magnitude: 0.48754
Value Function Update Magnitude: 0.51145

Collected Steps per Second: 22,575.66400
Overall Steps per Second: 10,657.22941

Timestep Collection Time: 2.21557
Timestep Consumption Time: 2.47777
PPO Batch Consumption Time: 0.28803
Total Iteration Time: 4.69334

Cumulative Model Updates: 187,562
Cumulative Timesteps: 1,564,113,190

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1564113190...
Checkpoint 1564113190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,430.52368
Policy Entropy: 3.68465
Value Function Loss: 0.04013

Mean KL Divergence: 0.01547
SB3 Clip Fraction: 0.18725
Policy Update Magnitude: 0.46855
Value Function Update Magnitude: 0.40360

Collected Steps per Second: 22,475.81697
Overall Steps per Second: 10,647.46974

Timestep Collection Time: 2.22541
Timestep Consumption Time: 2.47223
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.69764

Cumulative Model Updates: 187,568
Cumulative Timesteps: 1,564,163,208

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,430.52368
Policy Entropy: 3.67371
Value Function Loss: 0.03915

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.16414
Policy Update Magnitude: 0.49320
Value Function Update Magnitude: 0.33362

Collected Steps per Second: 22,783.98631
Overall Steps per Second: 10,705.19681

Timestep Collection Time: 2.19540
Timestep Consumption Time: 2.47710
PPO Batch Consumption Time: 0.28495
Total Iteration Time: 4.67250

Cumulative Model Updates: 187,574
Cumulative Timesteps: 1,564,213,228

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1564213228...
Checkpoint 1564213228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,430.52368
Policy Entropy: 3.68122
Value Function Loss: 0.03898

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.50385
Value Function Update Magnitude: 0.35811

Collected Steps per Second: 22,396.23609
Overall Steps per Second: 10,653.98598

Timestep Collection Time: 2.23368
Timestep Consumption Time: 2.46184
PPO Batch Consumption Time: 0.28432
Total Iteration Time: 4.69552

Cumulative Model Updates: 187,580
Cumulative Timesteps: 1,564,263,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,430.52368
Policy Entropy: 3.67817
Value Function Loss: 0.03525

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15007
Policy Update Magnitude: 0.50366
Value Function Update Magnitude: 0.36296

Collected Steps per Second: 22,702.08769
Overall Steps per Second: 10,831.42292

Timestep Collection Time: 2.20306
Timestep Consumption Time: 2.41443
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.61749

Cumulative Model Updates: 187,586
Cumulative Timesteps: 1,564,313,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1564313268...
Checkpoint 1564313268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,430.52368
Policy Entropy: 3.67455
Value Function Loss: 0.03365

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.16441
Policy Update Magnitude: 0.52962
Value Function Update Magnitude: 0.44633

Collected Steps per Second: 22,706.77655
Overall Steps per Second: 10,745.36128

Timestep Collection Time: 2.20207
Timestep Consumption Time: 2.45128
PPO Batch Consumption Time: 0.28600
Total Iteration Time: 4.65336

Cumulative Model Updates: 187,592
Cumulative Timesteps: 1,564,363,270

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,870.53587
Policy Entropy: 3.67510
Value Function Loss: 0.03728

Mean KL Divergence: 0.01459
SB3 Clip Fraction: 0.17611
Policy Update Magnitude: 0.51877
Value Function Update Magnitude: 0.47563

Collected Steps per Second: 22,742.30464
Overall Steps per Second: 10,824.94310

Timestep Collection Time: 2.19986
Timestep Consumption Time: 2.42187
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.62173

Cumulative Model Updates: 187,598
Cumulative Timesteps: 1,564,413,300

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1564413300...
Checkpoint 1564413300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 321,724.80745
Policy Entropy: 3.67858
Value Function Loss: 0.04199

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.16825
Policy Update Magnitude: 0.50014
Value Function Update Magnitude: 0.43762

Collected Steps per Second: 22,006.97680
Overall Steps per Second: 10,683.11055

Timestep Collection Time: 2.27273
Timestep Consumption Time: 2.40905
PPO Batch Consumption Time: 0.28736
Total Iteration Time: 4.68178

Cumulative Model Updates: 187,604
Cumulative Timesteps: 1,564,463,316

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 321,724.80745
Policy Entropy: 3.67499
Value Function Loss: 0.04626

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15135
Policy Update Magnitude: 0.48917
Value Function Update Magnitude: 0.50589

Collected Steps per Second: 22,331.45554
Overall Steps per Second: 10,914.02507

Timestep Collection Time: 2.24105
Timestep Consumption Time: 2.34442
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.58548

Cumulative Model Updates: 187,610
Cumulative Timesteps: 1,564,513,362

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1564513362...
Checkpoint 1564513362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,019,540.11512
Policy Entropy: 3.67454
Value Function Loss: 0.04466

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.13853
Policy Update Magnitude: 0.50129
Value Function Update Magnitude: 0.41538

Collected Steps per Second: 21,791.23328
Overall Steps per Second: 10,672.71785

Timestep Collection Time: 2.29588
Timestep Consumption Time: 2.39178
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.68765

Cumulative Model Updates: 187,616
Cumulative Timesteps: 1,564,563,392

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 965,386.08757
Policy Entropy: 3.67850
Value Function Loss: 0.03865

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13494
Policy Update Magnitude: 0.50786
Value Function Update Magnitude: 0.45792

Collected Steps per Second: 22,598.93847
Overall Steps per Second: 10,823.66470

Timestep Collection Time: 2.21329
Timestep Consumption Time: 2.40788
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.62117

Cumulative Model Updates: 187,622
Cumulative Timesteps: 1,564,613,410

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1564613410...
Checkpoint 1564613410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 513,053.82317
Policy Entropy: 3.68945
Value Function Loss: 0.03359

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.47586
Value Function Update Magnitude: 0.45325

Collected Steps per Second: 22,460.84386
Overall Steps per Second: 10,720.60759

Timestep Collection Time: 2.22663
Timestep Consumption Time: 2.43840
PPO Batch Consumption Time: 0.28530
Total Iteration Time: 4.66503

Cumulative Model Updates: 187,628
Cumulative Timesteps: 1,564,663,422

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 323,272.42897
Policy Entropy: 3.69610
Value Function Loss: 0.02812

Mean KL Divergence: 0.01045
SB3 Clip Fraction: 0.13847
Policy Update Magnitude: 0.45384
Value Function Update Magnitude: 0.61836

Collected Steps per Second: 22,644.41154
Overall Steps per Second: 10,702.11510

Timestep Collection Time: 2.20920
Timestep Consumption Time: 2.46520
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.67440

Cumulative Model Updates: 187,634
Cumulative Timesteps: 1,564,713,448

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1564713448...
Checkpoint 1564713448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 591,019.19037
Policy Entropy: 3.68993
Value Function Loss: 0.03346

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12949
Policy Update Magnitude: 0.47582
Value Function Update Magnitude: 0.72234

Collected Steps per Second: 22,672.21700
Overall Steps per Second: 10,821.66681

Timestep Collection Time: 2.20640
Timestep Consumption Time: 2.41618
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.62258

Cumulative Model Updates: 187,640
Cumulative Timesteps: 1,564,763,472

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,088.07352
Policy Entropy: 3.68854
Value Function Loss: 0.03501

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12864
Policy Update Magnitude: 0.48209
Value Function Update Magnitude: 0.70768

Collected Steps per Second: 22,472.68277
Overall Steps per Second: 10,612.10269

Timestep Collection Time: 2.22492
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.71160

Cumulative Model Updates: 187,646
Cumulative Timesteps: 1,564,813,472

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1564813472...
Checkpoint 1564813472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,931.94758
Policy Entropy: 3.69145
Value Function Loss: 0.03838

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.46598
Value Function Update Magnitude: 0.57374

Collected Steps per Second: 22,527.13155
Overall Steps per Second: 10,609.70271

Timestep Collection Time: 2.22097
Timestep Consumption Time: 2.49472
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.71568

Cumulative Model Updates: 187,652
Cumulative Timesteps: 1,564,863,504

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,325.99043
Policy Entropy: 3.70362
Value Function Loss: 0.03345

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.44300
Value Function Update Magnitude: 0.54264

Collected Steps per Second: 22,917.61028
Overall Steps per Second: 10,765.36386

Timestep Collection Time: 2.18243
Timestep Consumption Time: 2.46358
PPO Batch Consumption Time: 0.28262
Total Iteration Time: 4.64601

Cumulative Model Updates: 187,658
Cumulative Timesteps: 1,564,913,520

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1564913520...
Checkpoint 1564913520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,843.63026
Policy Entropy: 3.69655
Value Function Loss: 0.02947

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.44307
Value Function Update Magnitude: 0.62820

Collected Steps per Second: 22,743.92317
Overall Steps per Second: 10,680.71434

Timestep Collection Time: 2.20032
Timestep Consumption Time: 2.48513
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.68545

Cumulative Model Updates: 187,664
Cumulative Timesteps: 1,564,963,564

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 112,843.63026
Policy Entropy: 3.68802
Value Function Loss: 0.02674

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.43732
Value Function Update Magnitude: 0.61402

Collected Steps per Second: 21,961.06399
Overall Steps per Second: 10,828.90213

Timestep Collection Time: 2.27712
Timestep Consumption Time: 2.34089
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.61801

Cumulative Model Updates: 187,670
Cumulative Timesteps: 1,565,013,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1565013572...
Checkpoint 1565013572 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,843.63026
Policy Entropy: 3.68922
Value Function Loss: 0.02478

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.14047
Policy Update Magnitude: 0.44921
Value Function Update Magnitude: 0.66651

Collected Steps per Second: 22,170.29019
Overall Steps per Second: 10,690.69632

Timestep Collection Time: 2.25581
Timestep Consumption Time: 2.42227
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.67809

Cumulative Model Updates: 187,676
Cumulative Timesteps: 1,565,063,584

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214,655.72780
Policy Entropy: 3.68673
Value Function Loss: 0.02749

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13340
Policy Update Magnitude: 0.45740
Value Function Update Magnitude: 0.62928

Collected Steps per Second: 22,030.41471
Overall Steps per Second: 10,859.83261

Timestep Collection Time: 2.27122
Timestep Consumption Time: 2.33621
PPO Batch Consumption Time: 0.27704
Total Iteration Time: 4.60744

Cumulative Model Updates: 187,682
Cumulative Timesteps: 1,565,113,620

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1565113620...
Checkpoint 1565113620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,647.15600
Policy Entropy: 3.70262
Value Function Loss: 0.02952

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.45768
Value Function Update Magnitude: 0.68591

Collected Steps per Second: 22,065.46629
Overall Steps per Second: 10,733.41606

Timestep Collection Time: 2.26762
Timestep Consumption Time: 2.39409
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.66170

Cumulative Model Updates: 187,688
Cumulative Timesteps: 1,565,163,656

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,131.23325
Policy Entropy: 3.68993
Value Function Loss: 0.03140

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12859
Policy Update Magnitude: 0.48156
Value Function Update Magnitude: 0.66737

Collected Steps per Second: 22,945.04229
Overall Steps per Second: 10,944.60642

Timestep Collection Time: 2.17956
Timestep Consumption Time: 2.38982
PPO Batch Consumption Time: 0.27646
Total Iteration Time: 4.56937

Cumulative Model Updates: 187,694
Cumulative Timesteps: 1,565,213,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1565213666...
Checkpoint 1565213666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,138.68786
Policy Entropy: 3.69558
Value Function Loss: 0.03372

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.48685
Value Function Update Magnitude: 0.58128

Collected Steps per Second: 22,667.01282
Overall Steps per Second: 10,737.76051

Timestep Collection Time: 2.20594
Timestep Consumption Time: 2.45071
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.65665

Cumulative Model Updates: 187,700
Cumulative Timesteps: 1,565,263,668

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.69667
Value Function Loss: 0.02944

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13045
Policy Update Magnitude: 0.49344
Value Function Update Magnitude: 0.55796

Collected Steps per Second: 22,972.65473
Overall Steps per Second: 10,759.46623

Timestep Collection Time: 2.17789
Timestep Consumption Time: 2.47215
PPO Batch Consumption Time: 0.28571
Total Iteration Time: 4.65004

Cumulative Model Updates: 187,706
Cumulative Timesteps: 1,565,313,700

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1565313700...
Checkpoint 1565313700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.69244
Value Function Loss: 0.02848

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13641
Policy Update Magnitude: 0.50841
Value Function Update Magnitude: 0.53736

Collected Steps per Second: 22,762.21939
Overall Steps per Second: 10,673.52603

Timestep Collection Time: 2.19776
Timestep Consumption Time: 2.48916
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.68692

Cumulative Model Updates: 187,712
Cumulative Timesteps: 1,565,363,726

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.68426
Value Function Loss: 0.02629

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14201
Policy Update Magnitude: 0.45514
Value Function Update Magnitude: 0.50132

Collected Steps per Second: 22,703.12363
Overall Steps per Second: 10,790.30516

Timestep Collection Time: 2.20260
Timestep Consumption Time: 2.43174
PPO Batch Consumption Time: 0.27832
Total Iteration Time: 4.63435

Cumulative Model Updates: 187,718
Cumulative Timesteps: 1,565,413,732

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1565413732...
Checkpoint 1565413732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.66323
Value Function Loss: 0.02849

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.13540
Policy Update Magnitude: 0.43083
Value Function Update Magnitude: 0.45388

Collected Steps per Second: 22,768.51281
Overall Steps per Second: 10,691.94768

Timestep Collection Time: 2.19733
Timestep Consumption Time: 2.48189
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.67922

Cumulative Model Updates: 187,724
Cumulative Timesteps: 1,565,463,762

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.67645
Value Function Loss: 0.02831

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.44687
Value Function Update Magnitude: 0.46656

Collected Steps per Second: 22,104.53135
Overall Steps per Second: 10,477.81620

Timestep Collection Time: 2.26261
Timestep Consumption Time: 2.51071
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.77332

Cumulative Model Updates: 187,730
Cumulative Timesteps: 1,565,513,776

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1565513776...
Checkpoint 1565513776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.65446
Value Function Loss: 0.03223

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13458
Policy Update Magnitude: 0.46482
Value Function Update Magnitude: 0.47769

Collected Steps per Second: 22,695.54475
Overall Steps per Second: 10,657.62980

Timestep Collection Time: 2.20360
Timestep Consumption Time: 2.48900
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.69260

Cumulative Model Updates: 187,736
Cumulative Timesteps: 1,565,563,788

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.65231
Value Function Loss: 0.03223

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13495
Policy Update Magnitude: 0.46541
Value Function Update Magnitude: 0.48375

Collected Steps per Second: 22,876.99614
Overall Steps per Second: 10,843.52738

Timestep Collection Time: 2.18586
Timestep Consumption Time: 2.42574
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.61160

Cumulative Model Updates: 187,742
Cumulative Timesteps: 1,565,613,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1565613794...
Checkpoint 1565613794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.66012
Value Function Loss: 0.02893

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13291
Policy Update Magnitude: 0.47232
Value Function Update Magnitude: 0.45566

Collected Steps per Second: 22,769.03610
Overall Steps per Second: 10,712.57166

Timestep Collection Time: 2.19728
Timestep Consumption Time: 2.47293
PPO Batch Consumption Time: 0.28888
Total Iteration Time: 4.67021

Cumulative Model Updates: 187,748
Cumulative Timesteps: 1,565,663,824

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.67994
Value Function Loss: 0.02336

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12618
Policy Update Magnitude: 0.45515
Value Function Update Magnitude: 0.40495

Collected Steps per Second: 22,126.05294
Overall Steps per Second: 10,848.66851

Timestep Collection Time: 2.26041
Timestep Consumption Time: 2.34974
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.61015

Cumulative Model Updates: 187,754
Cumulative Timesteps: 1,565,713,838

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1565713838...
Checkpoint 1565713838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.69099
Value Function Loss: 0.02008

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12376
Policy Update Magnitude: 0.43320
Value Function Update Magnitude: 0.43724

Collected Steps per Second: 21,969.29545
Overall Steps per Second: 10,701.84860

Timestep Collection Time: 2.27599
Timestep Consumption Time: 2.39628
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.67228

Cumulative Model Updates: 187,760
Cumulative Timesteps: 1,565,763,840

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.68439
Value Function Loss: 0.01986

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.42866
Value Function Update Magnitude: 0.53816

Collected Steps per Second: 21,945.47861
Overall Steps per Second: 10,514.13405

Timestep Collection Time: 2.27983
Timestep Consumption Time: 2.47872
PPO Batch Consumption Time: 0.29002
Total Iteration Time: 4.75855

Cumulative Model Updates: 187,766
Cumulative Timesteps: 1,565,813,872

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1565813872...
Checkpoint 1565813872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.67336
Value Function Loss: 0.02086

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13530
Policy Update Magnitude: 0.39578
Value Function Update Magnitude: 0.53994

Collected Steps per Second: 22,810.35090
Overall Steps per Second: 10,898.80586

Timestep Collection Time: 2.19251
Timestep Consumption Time: 2.39625
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.58876

Cumulative Model Updates: 187,772
Cumulative Timesteps: 1,565,863,884

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.67448
Value Function Loss: 0.01991

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.37524
Value Function Update Magnitude: 0.44413

Collected Steps per Second: 22,931.71968
Overall Steps per Second: 10,796.64258

Timestep Collection Time: 2.18222
Timestep Consumption Time: 2.45274
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.63496

Cumulative Model Updates: 187,778
Cumulative Timesteps: 1,565,913,926

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1565913926...
Checkpoint 1565913926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.65843
Value Function Loss: 0.02160

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13107
Policy Update Magnitude: 0.37216
Value Function Update Magnitude: 0.37900

Collected Steps per Second: 22,469.79552
Overall Steps per Second: 10,799.09481

Timestep Collection Time: 2.22637
Timestep Consumption Time: 2.40606
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.63243

Cumulative Model Updates: 187,784
Cumulative Timesteps: 1,565,963,952

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.66218
Value Function Loss: 0.02093

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13312
Policy Update Magnitude: 0.39684
Value Function Update Magnitude: 0.47203

Collected Steps per Second: 22,580.37099
Overall Steps per Second: 10,603.94470

Timestep Collection Time: 2.21431
Timestep Consumption Time: 2.50091
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.71523

Cumulative Model Updates: 187,790
Cumulative Timesteps: 1,566,013,952

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1566013952...
Checkpoint 1566013952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 118,671.38908
Policy Entropy: 3.65587
Value Function Loss: 0.02466

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13964
Policy Update Magnitude: 0.45105
Value Function Update Magnitude: 0.65272

Collected Steps per Second: 22,410.65228
Overall Steps per Second: 10,579.05328

Timestep Collection Time: 2.23135
Timestep Consumption Time: 2.49554
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.72689

Cumulative Model Updates: 187,796
Cumulative Timesteps: 1,566,063,958

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,265.26772
Policy Entropy: 3.66126
Value Function Loss: 0.02792

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13222
Policy Update Magnitude: 0.50917
Value Function Update Magnitude: 0.77928

Collected Steps per Second: 22,857.05093
Overall Steps per Second: 10,823.76978

Timestep Collection Time: 2.18803
Timestep Consumption Time: 2.43254
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.62057

Cumulative Model Updates: 187,802
Cumulative Timesteps: 1,566,113,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1566113970...
Checkpoint 1566113970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,265.26772
Policy Entropy: 3.65808
Value Function Loss: 0.03010

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11336
Policy Update Magnitude: 0.62220
Value Function Update Magnitude: 0.76216

Collected Steps per Second: 22,470.59254
Overall Steps per Second: 10,708.29595

Timestep Collection Time: 2.22575
Timestep Consumption Time: 2.44483
PPO Batch Consumption Time: 0.28179
Total Iteration Time: 4.67058

Cumulative Model Updates: 187,808
Cumulative Timesteps: 1,566,163,984

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,265.26772
Policy Entropy: 3.66882
Value Function Loss: 0.02574

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.55899
Value Function Update Magnitude: 0.73416

Collected Steps per Second: 22,803.93896
Overall Steps per Second: 10,822.13290

Timestep Collection Time: 2.19348
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.62201

Cumulative Model Updates: 187,814
Cumulative Timesteps: 1,566,214,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1566214004...
Checkpoint 1566214004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 499,265.26772
Policy Entropy: 3.67624
Value Function Loss: 0.02162

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14470
Policy Update Magnitude: 0.52992
Value Function Update Magnitude: 0.71341

Collected Steps per Second: 22,328.84197
Overall Steps per Second: 10,754.65375

Timestep Collection Time: 2.24015
Timestep Consumption Time: 2.41086
PPO Batch Consumption Time: 0.27570
Total Iteration Time: 4.65101

Cumulative Model Updates: 187,820
Cumulative Timesteps: 1,566,264,024

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 499,265.26772
Policy Entropy: 3.68215
Value Function Loss: 0.02290

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15754
Policy Update Magnitude: 0.49266
Value Function Update Magnitude: 0.58929

Collected Steps per Second: 22,812.08646
Overall Steps per Second: 10,839.07780

Timestep Collection Time: 2.19200
Timestep Consumption Time: 2.42131
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.61331

Cumulative Model Updates: 187,826
Cumulative Timesteps: 1,566,314,028

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1566314028...
Checkpoint 1566314028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 757,028.39059
Policy Entropy: 3.68024
Value Function Loss: 0.02483

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.15118
Policy Update Magnitude: 0.48545
Value Function Update Magnitude: 0.50959

Collected Steps per Second: 22,576.31140
Overall Steps per Second: 10,664.60841

Timestep Collection Time: 2.21524
Timestep Consumption Time: 2.47429
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.68953

Cumulative Model Updates: 187,832
Cumulative Timesteps: 1,566,364,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782,653.81887
Policy Entropy: 3.69307
Value Function Loss: 0.02296

Mean KL Divergence: 0.01773
SB3 Clip Fraction: 0.21111
Policy Update Magnitude: 0.48113
Value Function Update Magnitude: 0.54024

Collected Steps per Second: 23,111.60634
Overall Steps per Second: 10,879.55616

Timestep Collection Time: 2.16393
Timestep Consumption Time: 2.43294
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.59688

Cumulative Model Updates: 187,838
Cumulative Timesteps: 1,566,414,052

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1566414052...
Checkpoint 1566414052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 782,653.81887
Policy Entropy: 3.66795
Value Function Loss: 0.02652

Mean KL Divergence: 0.02685
SB3 Clip Fraction: 0.27930
Policy Update Magnitude: 0.41976
Value Function Update Magnitude: 0.52522

Collected Steps per Second: 22,488.01638
Overall Steps per Second: 10,633.84424

Timestep Collection Time: 2.22483
Timestep Consumption Time: 2.48015
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.70498

Cumulative Model Updates: 187,844
Cumulative Timesteps: 1,566,464,084

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 782,653.81887
Policy Entropy: 3.68126
Value Function Loss: 0.03501

Mean KL Divergence: 0.01664
SB3 Clip Fraction: 0.19624
Policy Update Magnitude: 0.45426
Value Function Update Magnitude: 0.41729

Collected Steps per Second: 22,475.97316
Overall Steps per Second: 10,616.78714

Timestep Collection Time: 2.22504
Timestep Consumption Time: 2.48542
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.71046

Cumulative Model Updates: 187,850
Cumulative Timesteps: 1,566,514,094

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1566514094...
Checkpoint 1566514094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 373,952.07114
Policy Entropy: 3.67243
Value Function Loss: 0.03976

Mean KL Divergence: 0.01308
SB3 Clip Fraction: 0.15367
Policy Update Magnitude: 0.60572
Value Function Update Magnitude: 0.43305

Collected Steps per Second: 22,481.18067
Overall Steps per Second: 10,668.34496

Timestep Collection Time: 2.22524
Timestep Consumption Time: 2.46396
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.68920

Cumulative Model Updates: 187,856
Cumulative Timesteps: 1,566,564,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 245,361.14376
Policy Entropy: 3.71410
Value Function Loss: 0.03869

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15321
Policy Update Magnitude: 0.65928
Value Function Update Magnitude: 0.55192

Collected Steps per Second: 22,960.04934
Overall Steps per Second: 10,731.34429

Timestep Collection Time: 2.17804
Timestep Consumption Time: 2.48195
PPO Batch Consumption Time: 0.28902
Total Iteration Time: 4.65999

Cumulative Model Updates: 187,862
Cumulative Timesteps: 1,566,614,128

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1566614128...
Checkpoint 1566614128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 270,774.35984
Policy Entropy: 3.72616
Value Function Loss: 0.03689

Mean KL Divergence: 0.01100
SB3 Clip Fraction: 0.14175
Policy Update Magnitude: 0.56122
Value Function Update Magnitude: 0.53932

Collected Steps per Second: 22,788.16870
Overall Steps per Second: 10,674.00549

Timestep Collection Time: 2.19517
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.68653

Cumulative Model Updates: 187,868
Cumulative Timesteps: 1,566,664,152

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,656.62911
Policy Entropy: 3.71703
Value Function Loss: 0.03476

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15669
Policy Update Magnitude: 0.47888
Value Function Update Magnitude: 0.45647

Collected Steps per Second: 21,850.52721
Overall Steps per Second: 10,792.89279

Timestep Collection Time: 2.28855
Timestep Consumption Time: 2.34469
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.63323

Cumulative Model Updates: 187,874
Cumulative Timesteps: 1,566,714,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1566714158...
Checkpoint 1566714158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,656.62911
Policy Entropy: 3.70036
Value Function Loss: 0.03329

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13807
Policy Update Magnitude: 0.47926
Value Function Update Magnitude: 0.36796

Collected Steps per Second: 21,953.79280
Overall Steps per Second: 10,760.68940

Timestep Collection Time: 2.27952
Timestep Consumption Time: 2.37112
PPO Batch Consumption Time: 0.28219
Total Iteration Time: 4.65063

Cumulative Model Updates: 187,880
Cumulative Timesteps: 1,566,764,202

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,656.62911
Policy Entropy: 3.69695
Value Function Loss: 0.02995

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.46421
Value Function Update Magnitude: 0.28754

Collected Steps per Second: 22,184.04849
Overall Steps per Second: 10,862.51434

Timestep Collection Time: 2.25495
Timestep Consumption Time: 2.35024
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.60520

Cumulative Model Updates: 187,886
Cumulative Timesteps: 1,566,814,226

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1566814226...
Checkpoint 1566814226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,656.62911
Policy Entropy: 3.69639
Value Function Loss: 0.02911

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.44889
Value Function Update Magnitude: 0.27691

Collected Steps per Second: 22,237.09753
Overall Steps per Second: 10,658.21702

Timestep Collection Time: 2.24966
Timestep Consumption Time: 2.44399
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.69366

Cumulative Model Updates: 187,892
Cumulative Timesteps: 1,566,864,252

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 670,786.95539
Policy Entropy: 3.69109
Value Function Loss: 0.03064

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.45398
Value Function Update Magnitude: 0.30658

Collected Steps per Second: 22,827.96003
Overall Steps per Second: 10,880.60610

Timestep Collection Time: 2.19135
Timestep Consumption Time: 2.40619
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.59754

Cumulative Model Updates: 187,898
Cumulative Timesteps: 1,566,914,276

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1566914276...
Checkpoint 1566914276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,476.63861
Policy Entropy: 3.70577
Value Function Loss: 0.03000

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.46038
Value Function Update Magnitude: 0.42024

Collected Steps per Second: 22,926.34854
Overall Steps per Second: 10,710.12044

Timestep Collection Time: 2.18116
Timestep Consumption Time: 2.48788
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.66904

Cumulative Model Updates: 187,904
Cumulative Timesteps: 1,566,964,282

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 450,557.20428
Policy Entropy: 3.71430
Value Function Loss: 0.02975

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12872
Policy Update Magnitude: 0.49179
Value Function Update Magnitude: 0.57840

Collected Steps per Second: 22,902.87615
Overall Steps per Second: 10,875.67155

Timestep Collection Time: 2.18444
Timestep Consumption Time: 2.41573
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.60018

Cumulative Model Updates: 187,910
Cumulative Timesteps: 1,567,014,312

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1567014312...
Checkpoint 1567014312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 169,260.89548
Policy Entropy: 3.74111
Value Function Loss: 0.02802

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.11774
Policy Update Magnitude: 0.47878
Value Function Update Magnitude: 0.81149

Collected Steps per Second: 22,560.10958
Overall Steps per Second: 10,660.02770

Timestep Collection Time: 2.21666
Timestep Consumption Time: 2.47451
PPO Batch Consumption Time: 0.28818
Total Iteration Time: 4.69117

Cumulative Model Updates: 187,916
Cumulative Timesteps: 1,567,064,320

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,882.36406
Policy Entropy: 3.73994
Value Function Loss: 0.02563

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12849
Policy Update Magnitude: 0.43663
Value Function Update Magnitude: 0.91488

Collected Steps per Second: 22,761.08743
Overall Steps per Second: 10,819.36314

Timestep Collection Time: 2.19673
Timestep Consumption Time: 2.42461
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.62134

Cumulative Model Updates: 187,922
Cumulative Timesteps: 1,567,114,320

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1567114320...
Checkpoint 1567114320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.72869
Value Function Loss: 0.02373

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.39351
Value Function Update Magnitude: 0.94006

Collected Steps per Second: 22,921.93513
Overall Steps per Second: 10,707.20886

Timestep Collection Time: 2.18280
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.67293

Cumulative Model Updates: 187,928
Cumulative Timesteps: 1,567,164,354

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.72063
Value Function Loss: 0.02043

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.12017
Policy Update Magnitude: 0.37796
Value Function Update Magnitude: 0.82236

Collected Steps per Second: 22,693.87961
Overall Steps per Second: 10,805.62639

Timestep Collection Time: 2.20500
Timestep Consumption Time: 2.42592
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.63092

Cumulative Model Updates: 187,934
Cumulative Timesteps: 1,567,214,394

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1567214394...
Checkpoint 1567214394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.69637
Value Function Loss: 0.01975

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.39120
Value Function Update Magnitude: 0.67819

Collected Steps per Second: 22,680.84896
Overall Steps per Second: 10,683.28403

Timestep Collection Time: 2.20547
Timestep Consumption Time: 2.47680
PPO Batch Consumption Time: 0.28519
Total Iteration Time: 4.68227

Cumulative Model Updates: 187,940
Cumulative Timesteps: 1,567,264,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.70796
Value Function Loss: 0.01660

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.40500
Value Function Update Magnitude: 0.58171

Collected Steps per Second: 22,866.62991
Overall Steps per Second: 10,769.25886

Timestep Collection Time: 2.18764
Timestep Consumption Time: 2.45743
PPO Batch Consumption Time: 0.28569
Total Iteration Time: 4.64507

Cumulative Model Updates: 187,946
Cumulative Timesteps: 1,567,314,440

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1567314440...
Checkpoint 1567314440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.70241
Value Function Loss: 0.01566

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.12221
Policy Update Magnitude: 0.36458
Value Function Update Magnitude: 0.52896

Collected Steps per Second: 22,635.43181
Overall Steps per Second: 10,848.06426

Timestep Collection Time: 2.20928
Timestep Consumption Time: 2.40057
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.60985

Cumulative Model Updates: 187,952
Cumulative Timesteps: 1,567,364,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.71948
Value Function Loss: 0.01404

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11780
Policy Update Magnitude: 0.32085
Value Function Update Magnitude: 0.43484

Collected Steps per Second: 22,647.57415
Overall Steps per Second: 10,822.83336

Timestep Collection Time: 2.20801
Timestep Consumption Time: 2.41241
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.62042

Cumulative Model Updates: 187,958
Cumulative Timesteps: 1,567,414,454

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1567414454...
Checkpoint 1567414454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.71426
Value Function Loss: 0.01322

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10488
Policy Update Magnitude: 0.31508
Value Function Update Magnitude: 0.37992

Collected Steps per Second: 22,668.02233
Overall Steps per Second: 10,721.48926

Timestep Collection Time: 2.20654
Timestep Consumption Time: 2.45867
PPO Batch Consumption Time: 0.28339
Total Iteration Time: 4.66521

Cumulative Model Updates: 187,964
Cumulative Timesteps: 1,567,464,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.70596
Value Function Loss: 0.01357

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.30983
Value Function Update Magnitude: 0.34063

Collected Steps per Second: 23,011.04846
Overall Steps per Second: 10,896.48999

Timestep Collection Time: 2.17365
Timestep Consumption Time: 2.41663
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.59029

Cumulative Model Updates: 187,970
Cumulative Timesteps: 1,567,514,490

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1567514490...
Checkpoint 1567514490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.70183
Value Function Loss: 0.01460

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.16294
Policy Update Magnitude: 0.31476
Value Function Update Magnitude: 0.34074

Collected Steps per Second: 22,955.23449
Overall Steps per Second: 10,716.96289

Timestep Collection Time: 2.17902
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.66737

Cumulative Model Updates: 187,976
Cumulative Timesteps: 1,567,564,510

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.68644
Value Function Loss: 0.01989

Mean KL Divergence: 0.01358
SB3 Clip Fraction: 0.17638
Policy Update Magnitude: 0.35269
Value Function Update Magnitude: 0.47224

Collected Steps per Second: 22,276.10378
Overall Steps per Second: 10,860.02518

Timestep Collection Time: 2.24501
Timestep Consumption Time: 2.35996
PPO Batch Consumption Time: 0.28026
Total Iteration Time: 4.60496

Cumulative Model Updates: 187,982
Cumulative Timesteps: 1,567,614,520

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1567614520...
Checkpoint 1567614520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.69908
Value Function Loss: 0.02131

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.16516
Policy Update Magnitude: 0.39094
Value Function Update Magnitude: 0.69677

Collected Steps per Second: 22,022.51079
Overall Steps per Second: 10,659.21915

Timestep Collection Time: 2.27122
Timestep Consumption Time: 2.42124
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.69246

Cumulative Model Updates: 187,988
Cumulative Timesteps: 1,567,664,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.69029
Value Function Loss: 0.02023

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11322
Policy Update Magnitude: 0.47142
Value Function Update Magnitude: 0.69520

Collected Steps per Second: 22,243.87750
Overall Steps per Second: 10,670.09908

Timestep Collection Time: 2.24826
Timestep Consumption Time: 2.43867
PPO Batch Consumption Time: 0.28489
Total Iteration Time: 4.68693

Cumulative Model Updates: 187,994
Cumulative Timesteps: 1,567,714,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1567714548...
Checkpoint 1567714548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.69723
Value Function Loss: 0.01734

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10499
Policy Update Magnitude: 0.45180
Value Function Update Magnitude: 0.47153

Collected Steps per Second: 22,621.01544
Overall Steps per Second: 10,913.03326

Timestep Collection Time: 2.21086
Timestep Consumption Time: 2.37191
PPO Batch Consumption Time: 0.27509
Total Iteration Time: 4.58278

Cumulative Model Updates: 188,000
Cumulative Timesteps: 1,567,764,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.70383
Value Function Loss: 0.01341

Mean KL Divergence: 0.00742
SB3 Clip Fraction: 0.09870
Policy Update Magnitude: 0.36790
Value Function Update Magnitude: 0.31526

Collected Steps per Second: 22,745.12002
Overall Steps per Second: 10,881.03480

Timestep Collection Time: 2.19845
Timestep Consumption Time: 2.39707
PPO Batch Consumption Time: 0.27618
Total Iteration Time: 4.59552

Cumulative Model Updates: 188,006
Cumulative Timesteps: 1,567,814,564

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1567814564...
Checkpoint 1567814564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.70160
Value Function Loss: 0.01341

Mean KL Divergence: 0.00809
SB3 Clip Fraction: 0.10689
Policy Update Magnitude: 0.29664
Value Function Update Magnitude: 0.24944

Collected Steps per Second: 22,510.42089
Overall Steps per Second: 10,591.94897

Timestep Collection Time: 2.22217
Timestep Consumption Time: 2.50047
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.72264

Cumulative Model Updates: 188,012
Cumulative Timesteps: 1,567,864,586

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,107.19319
Policy Entropy: 3.71499
Value Function Loss: 0.01357

Mean KL Divergence: 0.00789
SB3 Clip Fraction: 0.10899
Policy Update Magnitude: 0.29425
Value Function Update Magnitude: 0.23624

Collected Steps per Second: 22,927.34244
Overall Steps per Second: 10,856.90725

Timestep Collection Time: 2.18202
Timestep Consumption Time: 2.42592
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.60794

Cumulative Model Updates: 188,018
Cumulative Timesteps: 1,567,914,614

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1567914614...
Checkpoint 1567914614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 142,618.43437
Policy Entropy: 3.69635
Value Function Loss: 0.01861

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12048
Policy Update Magnitude: 0.36698
Value Function Update Magnitude: 0.60278

Collected Steps per Second: 22,533.51299
Overall Steps per Second: 10,725.12974

Timestep Collection Time: 2.21998
Timestep Consumption Time: 2.44420
PPO Batch Consumption Time: 0.28129
Total Iteration Time: 4.66419

Cumulative Model Updates: 188,024
Cumulative Timesteps: 1,567,964,638

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,092.56374
Policy Entropy: 3.71961
Value Function Loss: 0.02029

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.45876
Value Function Update Magnitude: 0.85062

Collected Steps per Second: 23,063.69445
Overall Steps per Second: 10,876.43487

Timestep Collection Time: 2.16791
Timestep Consumption Time: 2.42919
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.59709

Cumulative Model Updates: 188,030
Cumulative Timesteps: 1,568,014,638

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1568014638...
Checkpoint 1568014638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,636.49898
Policy Entropy: 3.72245
Value Function Loss: 0.02187

Mean KL Divergence: 0.00769
SB3 Clip Fraction: 0.09905
Policy Update Magnitude: 0.53142
Value Function Update Magnitude: 0.96802

Collected Steps per Second: 22,490.87598
Overall Steps per Second: 10,628.73429

Timestep Collection Time: 2.22339
Timestep Consumption Time: 2.48140
PPO Batch Consumption Time: 0.28712
Total Iteration Time: 4.70479

Cumulative Model Updates: 188,036
Cumulative Timesteps: 1,568,064,644

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,636.49898
Policy Entropy: 3.73119
Value Function Loss: 0.01918

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13166
Policy Update Magnitude: 0.47539
Value Function Update Magnitude: 0.79919

Collected Steps per Second: 23,299.99857
Overall Steps per Second: 10,980.40514

Timestep Collection Time: 2.14644
Timestep Consumption Time: 2.40822
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.55466

Cumulative Model Updates: 188,042
Cumulative Timesteps: 1,568,114,656

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1568114656...
Checkpoint 1568114656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,636.49898
Policy Entropy: 3.71434
Value Function Loss: 0.01828

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11901
Policy Update Magnitude: 0.41846
Value Function Update Magnitude: 0.58433

Collected Steps per Second: 22,947.49473
Overall Steps per Second: 10,745.28112

Timestep Collection Time: 2.17985
Timestep Consumption Time: 2.47541
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.65525

Cumulative Model Updates: 188,048
Cumulative Timesteps: 1,568,164,678

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,636.49898
Policy Entropy: 3.71163
Value Function Loss: 0.01594

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14596
Policy Update Magnitude: 0.36302
Value Function Update Magnitude: 0.42919

Collected Steps per Second: 22,825.11447
Overall Steps per Second: 10,742.76896

Timestep Collection Time: 2.19127
Timestep Consumption Time: 2.46451
PPO Batch Consumption Time: 0.28416
Total Iteration Time: 4.65578

Cumulative Model Updates: 188,054
Cumulative Timesteps: 1,568,214,694

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1568214694...
Checkpoint 1568214694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,636.49898
Policy Entropy: 3.70621
Value Function Loss: 0.01588

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13678
Policy Update Magnitude: 0.33564
Value Function Update Magnitude: 0.38951

Collected Steps per Second: 22,730.38526
Overall Steps per Second: 10,648.77391

Timestep Collection Time: 2.20005
Timestep Consumption Time: 2.49608
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.69613

Cumulative Model Updates: 188,060
Cumulative Timesteps: 1,568,264,702

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,636.49898
Policy Entropy: 3.70474
Value Function Loss: 0.01510

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.34895
Value Function Update Magnitude: 0.36008

Collected Steps per Second: 22,942.91308
Overall Steps per Second: 10,881.08502

Timestep Collection Time: 2.17967
Timestep Consumption Time: 2.41619
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.59587

Cumulative Model Updates: 188,066
Cumulative Timesteps: 1,568,314,710

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1568314710...
Checkpoint 1568314710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,636.49898
Policy Entropy: 3.68049
Value Function Loss: 0.02082

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.11813
Policy Update Magnitude: 0.45679
Value Function Update Magnitude: 0.40352

Collected Steps per Second: 22,814.29326
Overall Steps per Second: 10,712.79182

Timestep Collection Time: 2.19196
Timestep Consumption Time: 2.47610
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.66806

Cumulative Model Updates: 188,072
Cumulative Timesteps: 1,568,364,718

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 143,139.06257
Policy Entropy: 3.71135
Value Function Loss: 0.02167

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15656
Policy Update Magnitude: 0.48467
Value Function Update Magnitude: 0.40691

Collected Steps per Second: 22,790.57909
Overall Steps per Second: 10,804.09356

Timestep Collection Time: 2.19442
Timestep Consumption Time: 2.43457
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.62899

Cumulative Model Updates: 188,078
Cumulative Timesteps: 1,568,414,730

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1568414730...
Checkpoint 1568414730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257,470.30750
Policy Entropy: 3.71651
Value Function Loss: 0.02158

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.46111
Value Function Update Magnitude: 0.49226

Collected Steps per Second: 22,391.93088
Overall Steps per Second: 10,719.20259

Timestep Collection Time: 2.23330
Timestep Consumption Time: 2.43197
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.66527

Cumulative Model Updates: 188,084
Cumulative Timesteps: 1,568,464,738

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,852.93984
Policy Entropy: 3.74634
Value Function Loss: 0.01840

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08128
Policy Update Magnitude: 0.46253
Value Function Update Magnitude: 0.56317

Collected Steps per Second: 22,724.61829
Overall Steps per Second: 10,833.77353

Timestep Collection Time: 2.20043
Timestep Consumption Time: 2.41513
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.61557

Cumulative Model Updates: 188,090
Cumulative Timesteps: 1,568,514,742

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1568514742...
Checkpoint 1568514742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 914,503.78989
Policy Entropy: 3.72969
Value Function Loss: 0.01817

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07748
Policy Update Magnitude: 0.50086
Value Function Update Magnitude: 0.67531

Collected Steps per Second: 22,789.63167
Overall Steps per Second: 10,722.85039

Timestep Collection Time: 2.19521
Timestep Consumption Time: 2.47034
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.66555

Cumulative Model Updates: 188,096
Cumulative Timesteps: 1,568,564,770

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 796,525.82058
Policy Entropy: 3.73376
Value Function Loss: 0.01878

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06245
Policy Update Magnitude: 0.54734
Value Function Update Magnitude: 0.79256

Collected Steps per Second: 22,866.23672
Overall Steps per Second: 10,865.08426

Timestep Collection Time: 2.18672
Timestep Consumption Time: 2.41536
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.60208

Cumulative Model Updates: 188,102
Cumulative Timesteps: 1,568,614,772

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1568614772...
Checkpoint 1568614772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277,757.76293
Policy Entropy: 3.73030
Value Function Loss: 0.01902

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07119
Policy Update Magnitude: 0.56964
Value Function Update Magnitude: 0.77302

Collected Steps per Second: 22,018.93879
Overall Steps per Second: 10,630.82063

Timestep Collection Time: 2.27086
Timestep Consumption Time: 2.43263
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.70349

Cumulative Model Updates: 188,108
Cumulative Timesteps: 1,568,664,774

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,608.74055
Policy Entropy: 3.72659
Value Function Loss: 0.01857

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06935
Policy Update Magnitude: 0.57022
Value Function Update Magnitude: 0.81561

Collected Steps per Second: 22,012.24476
Overall Steps per Second: 10,727.92981

Timestep Collection Time: 2.27283
Timestep Consumption Time: 2.39070
PPO Batch Consumption Time: 0.28651
Total Iteration Time: 4.66353

Cumulative Model Updates: 188,114
Cumulative Timesteps: 1,568,714,804

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1568714804...
Checkpoint 1568714804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,511.25724
Policy Entropy: 3.73735
Value Function Loss: 0.01793

Mean KL Divergence: 0.00621
SB3 Clip Fraction: 0.07556
Policy Update Magnitude: 0.53800
Value Function Update Magnitude: 0.88478

Collected Steps per Second: 21,925.44542
Overall Steps per Second: 10,819.91860

Timestep Collection Time: 2.28055
Timestep Consumption Time: 2.34075
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.62129

Cumulative Model Updates: 188,120
Cumulative Timesteps: 1,568,764,806

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,511.25724
Policy Entropy: 3.72979
Value Function Loss: 0.01873

Mean KL Divergence: 0.01133
SB3 Clip Fraction: 0.14989
Policy Update Magnitude: 0.48729
Value Function Update Magnitude: 0.86800

Collected Steps per Second: 22,521.70124
Overall Steps per Second: 10,648.07957

Timestep Collection Time: 2.22132
Timestep Consumption Time: 2.47699
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.69831

Cumulative Model Updates: 188,126
Cumulative Timesteps: 1,568,814,834

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1568814834...
Checkpoint 1568814834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,475.59153
Policy Entropy: 3.73359
Value Function Loss: 0.01855

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15065
Policy Update Magnitude: 0.48276
Value Function Update Magnitude: 0.82575

Collected Steps per Second: 22,597.93871
Overall Steps per Second: 10,858.53165

Timestep Collection Time: 2.21295
Timestep Consumption Time: 2.39247
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.60541

Cumulative Model Updates: 188,132
Cumulative Timesteps: 1,568,864,842

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,749.87959
Policy Entropy: 3.72136
Value Function Loss: 0.01802

Mean KL Divergence: 0.01159
SB3 Clip Fraction: 0.15050
Policy Update Magnitude: 0.42921
Value Function Update Magnitude: 0.71344

Collected Steps per Second: 23,038.46751
Overall Steps per Second: 10,956.19928

Timestep Collection Time: 2.17072
Timestep Consumption Time: 2.39382
PPO Batch Consumption Time: 0.27755
Total Iteration Time: 4.56454

Cumulative Model Updates: 188,138
Cumulative Timesteps: 1,568,914,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1568914852...
Checkpoint 1568914852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 486,967.24777
Policy Entropy: 3.70452
Value Function Loss: 0.02594

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.16036
Policy Update Magnitude: 0.40352
Value Function Update Magnitude: 0.62385

Collected Steps per Second: 22,850.78820
Overall Steps per Second: 10,689.57231

Timestep Collection Time: 2.18872
Timestep Consumption Time: 2.49004
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.67877

Cumulative Model Updates: 188,144
Cumulative Timesteps: 1,568,964,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 169,805.11732
Policy Entropy: 3.69528
Value Function Loss: 0.02829

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.43522
Value Function Update Magnitude: 0.57515

Collected Steps per Second: 23,042.57648
Overall Steps per Second: 10,858.29883

Timestep Collection Time: 2.17068
Timestep Consumption Time: 2.43575
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.60643

Cumulative Model Updates: 188,150
Cumulative Timesteps: 1,569,014,884

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1569014884...
Checkpoint 1569014884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 59,212.55989
Policy Entropy: 3.67612
Value Function Loss: 0.03334

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.48128
Value Function Update Magnitude: 0.47572

Collected Steps per Second: 22,381.87558
Overall Steps per Second: 10,620.61039

Timestep Collection Time: 2.23502
Timestep Consumption Time: 2.47506
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.71009

Cumulative Model Updates: 188,156
Cumulative Timesteps: 1,569,064,908

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,723.22273
Policy Entropy: 3.69592
Value Function Loss: 0.03434

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.51344
Value Function Update Magnitude: 0.43828

Collected Steps per Second: 22,987.08119
Overall Steps per Second: 10,882.11389

Timestep Collection Time: 2.17531
Timestep Consumption Time: 2.41975
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.59506

Cumulative Model Updates: 188,162
Cumulative Timesteps: 1,569,114,912

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1569114912...
Checkpoint 1569114912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,934.95369
Policy Entropy: 3.68795
Value Function Loss: 0.03956

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12435
Policy Update Magnitude: 0.53605
Value Function Update Magnitude: 0.43777

Collected Steps per Second: 22,411.99999
Overall Steps per Second: 10,784.44704

Timestep Collection Time: 2.23211
Timestep Consumption Time: 2.40661
PPO Batch Consumption Time: 0.27583
Total Iteration Time: 4.63872

Cumulative Model Updates: 188,168
Cumulative Timesteps: 1,569,164,938

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,205.39942
Policy Entropy: 3.70437
Value Function Loss: 0.03671

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.54322
Value Function Update Magnitude: 0.50362

Collected Steps per Second: 23,119.99881
Overall Steps per Second: 10,828.75672

Timestep Collection Time: 2.16315
Timestep Consumption Time: 2.45529
PPO Batch Consumption Time: 0.28217
Total Iteration Time: 4.61844

Cumulative Model Updates: 188,174
Cumulative Timesteps: 1,569,214,950

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1569214950...
Checkpoint 1569214950 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,742.34789
Policy Entropy: 3.71027
Value Function Loss: 0.03583

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12096
Policy Update Magnitude: 0.52115
Value Function Update Magnitude: 0.51372

Collected Steps per Second: 22,318.20776
Overall Steps per Second: 10,646.81566

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.45621
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.69680

Cumulative Model Updates: 188,180
Cumulative Timesteps: 1,569,264,956

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,742.34789
Policy Entropy: 3.70835
Value Function Loss: 0.03048

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12559
Policy Update Magnitude: 0.49311
Value Function Update Magnitude: 0.49065

Collected Steps per Second: 23,012.79348
Overall Steps per Second: 10,864.44863

Timestep Collection Time: 2.17375
Timestep Consumption Time: 2.43063
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.60438

Cumulative Model Updates: 188,186
Cumulative Timesteps: 1,569,314,980

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1569314980...
Checkpoint 1569314980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,742.34789
Policy Entropy: 3.69462
Value Function Loss: 0.02570

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.46136
Value Function Update Magnitude: 0.43102

Collected Steps per Second: 22,536.73081
Overall Steps per Second: 10,712.82953

Timestep Collection Time: 2.21860
Timestep Consumption Time: 2.44870
PPO Batch Consumption Time: 0.28406
Total Iteration Time: 4.66730

Cumulative Model Updates: 188,192
Cumulative Timesteps: 1,569,364,980

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,742.34789
Policy Entropy: 3.68134
Value Function Loss: 0.02192

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.44925
Value Function Update Magnitude: 0.43085

Collected Steps per Second: 23,286.54335
Overall Steps per Second: 10,938.78889

Timestep Collection Time: 2.14854
Timestep Consumption Time: 2.42528
PPO Batch Consumption Time: 0.27597
Total Iteration Time: 4.57382

Cumulative Model Updates: 188,198
Cumulative Timesteps: 1,569,415,012

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1569415012...
Checkpoint 1569415012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,742.34789
Policy Entropy: 3.67988
Value Function Loss: 0.02388

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.41368
Value Function Update Magnitude: 0.37864

Collected Steps per Second: 22,769.53585
Overall Steps per Second: 10,653.75206

Timestep Collection Time: 2.19706
Timestep Consumption Time: 2.49856
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.69562

Cumulative Model Updates: 188,204
Cumulative Timesteps: 1,569,465,038

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,742.34789
Policy Entropy: 3.67445
Value Function Loss: 0.02616

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.41181
Value Function Update Magnitude: 0.37465

Collected Steps per Second: 22,296.38103
Overall Steps per Second: 10,914.65998

Timestep Collection Time: 2.24332
Timestep Consumption Time: 2.33932
PPO Batch Consumption Time: 0.27570
Total Iteration Time: 4.58264

Cumulative Model Updates: 188,210
Cumulative Timesteps: 1,569,515,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1569515056...
Checkpoint 1569515056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,742.34789
Policy Entropy: 3.67240
Value Function Loss: 0.02715

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.43003
Value Function Update Magnitude: 0.38959

Collected Steps per Second: 22,020.09857
Overall Steps per Second: 10,709.95364

Timestep Collection Time: 2.27111
Timestep Consumption Time: 2.39838
PPO Batch Consumption Time: 0.28913
Total Iteration Time: 4.66949

Cumulative Model Updates: 188,216
Cumulative Timesteps: 1,569,565,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,742.34789
Policy Entropy: 3.65425
Value Function Loss: 0.03054

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12982
Policy Update Magnitude: 0.44947
Value Function Update Magnitude: 0.37066

Collected Steps per Second: 22,524.99117
Overall Steps per Second: 10,808.49136

Timestep Collection Time: 2.22064
Timestep Consumption Time: 2.40720
PPO Batch Consumption Time: 0.27632
Total Iteration Time: 4.62784

Cumulative Model Updates: 188,222
Cumulative Timesteps: 1,569,615,086

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1569615086...
Checkpoint 1569615086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,742.34789
Policy Entropy: 3.66979
Value Function Loss: 0.02525

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13221
Policy Update Magnitude: 0.46758
Value Function Update Magnitude: 0.35675

Collected Steps per Second: 22,593.98767
Overall Steps per Second: 10,703.80756

Timestep Collection Time: 2.21342
Timestep Consumption Time: 2.45875
PPO Batch Consumption Time: 0.29069
Total Iteration Time: 4.67217

Cumulative Model Updates: 188,228
Cumulative Timesteps: 1,569,665,096

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482,722.46186
Policy Entropy: 3.67332
Value Function Loss: 0.02611

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.46228
Value Function Update Magnitude: 0.30562

Collected Steps per Second: 22,651.26577
Overall Steps per Second: 10,812.63433

Timestep Collection Time: 2.20853
Timestep Consumption Time: 2.41809
PPO Batch Consumption Time: 0.28174
Total Iteration Time: 4.62662

Cumulative Model Updates: 188,234
Cumulative Timesteps: 1,569,715,122

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1569715122...
Checkpoint 1569715122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316,725.46523
Policy Entropy: 3.70972
Value Function Loss: 0.02235

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.45566
Value Function Update Magnitude: 0.36299

Collected Steps per Second: 22,644.14252
Overall Steps per Second: 10,640.80121

Timestep Collection Time: 2.20905
Timestep Consumption Time: 2.49191
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.70096

Cumulative Model Updates: 188,240
Cumulative Timesteps: 1,569,765,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,501.60852
Policy Entropy: 3.70954
Value Function Loss: 0.02700

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12395
Policy Update Magnitude: 0.45704
Value Function Update Magnitude: 0.45802

Collected Steps per Second: 23,083.74857
Overall Steps per Second: 10,892.33002

Timestep Collection Time: 2.16620
Timestep Consumption Time: 2.42455
PPO Batch Consumption Time: 0.27884
Total Iteration Time: 4.59075

Cumulative Model Updates: 188,246
Cumulative Timesteps: 1,569,815,148

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1569815148...
Checkpoint 1569815148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,501.60852
Policy Entropy: 3.72169
Value Function Loss: 0.02315

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12202
Policy Update Magnitude: 0.47414
Value Function Update Magnitude: 0.42053

Collected Steps per Second: 22,325.41725
Overall Steps per Second: 10,650.09659

Timestep Collection Time: 2.23960
Timestep Consumption Time: 2.45519
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.69479

Cumulative Model Updates: 188,252
Cumulative Timesteps: 1,569,865,148

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,501.60852
Policy Entropy: 3.70597
Value Function Loss: 0.02305

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.45574
Value Function Update Magnitude: 0.38926

Collected Steps per Second: 23,051.29198
Overall Steps per Second: 10,897.35354

Timestep Collection Time: 2.17029
Timestep Consumption Time: 2.42055
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.59084

Cumulative Model Updates: 188,258
Cumulative Timesteps: 1,569,915,176

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1569915176...
Checkpoint 1569915176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,501.60852
Policy Entropy: 3.70902
Value Function Loss: 0.02011

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12551
Policy Update Magnitude: 0.46497
Value Function Update Magnitude: 0.34090

Collected Steps per Second: 22,941.74099
Overall Steps per Second: 10,716.33064

Timestep Collection Time: 2.18039
Timestep Consumption Time: 2.48744
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.66783

Cumulative Model Updates: 188,264
Cumulative Timesteps: 1,569,965,198

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 472,501.60852
Policy Entropy: 3.70918
Value Function Loss: 0.02066

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12044
Policy Update Magnitude: 0.45909
Value Function Update Magnitude: 0.31689

Collected Steps per Second: 23,192.00401
Overall Steps per Second: 10,814.24307

Timestep Collection Time: 2.15695
Timestep Consumption Time: 2.46880
PPO Batch Consumption Time: 0.28390
Total Iteration Time: 4.62575

Cumulative Model Updates: 188,270
Cumulative Timesteps: 1,570,015,222

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1570015222...
Checkpoint 1570015222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,501.60852
Policy Entropy: 3.69909
Value Function Loss: 0.02137

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.11892
Policy Update Magnitude: 0.43379
Value Function Update Magnitude: 0.28311

Collected Steps per Second: 22,308.53911
Overall Steps per Second: 10,757.73723

Timestep Collection Time: 2.24228
Timestep Consumption Time: 2.40758
PPO Batch Consumption Time: 0.27574
Total Iteration Time: 4.64986

Cumulative Model Updates: 188,276
Cumulative Timesteps: 1,570,065,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 561,327.58831
Policy Entropy: 3.69897
Value Function Loss: 0.02212

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07472
Policy Update Magnitude: 0.50547
Value Function Update Magnitude: 0.33148

Collected Steps per Second: 22,787.90163
Overall Steps per Second: 10,879.03556

Timestep Collection Time: 2.19450
Timestep Consumption Time: 2.40223
PPO Batch Consumption Time: 0.27569
Total Iteration Time: 4.59673

Cumulative Model Updates: 188,282
Cumulative Timesteps: 1,570,115,252

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1570115252...
Checkpoint 1570115252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 582,211.24083
Policy Entropy: 3.70666
Value Function Loss: 0.02293

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11424
Policy Update Magnitude: 0.51742
Value Function Update Magnitude: 0.34339

Collected Steps per Second: 22,772.77130
Overall Steps per Second: 10,704.74884

Timestep Collection Time: 2.19692
Timestep Consumption Time: 2.47670
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.67363

Cumulative Model Updates: 188,288
Cumulative Timesteps: 1,570,165,282

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,597.68771
Policy Entropy: 3.71937
Value Function Loss: 0.02168

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.10494
Policy Update Magnitude: 0.51985
Value Function Update Magnitude: 0.38813

Collected Steps per Second: 22,942.86600
Overall Steps per Second: 10,802.04341

Timestep Collection Time: 2.17959
Timestep Consumption Time: 2.44972
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.62931

Cumulative Model Updates: 188,294
Cumulative Timesteps: 1,570,215,288

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1570215288...
Checkpoint 1570215288 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,597.68771
Policy Entropy: 3.71796
Value Function Loss: 0.01981

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.42733
Value Function Update Magnitude: 0.43635

Collected Steps per Second: 21,790.43792
Overall Steps per Second: 10,640.54932

Timestep Collection Time: 2.29486
Timestep Consumption Time: 2.40471
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.69957

Cumulative Model Updates: 188,300
Cumulative Timesteps: 1,570,265,294

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,597.68771
Policy Entropy: 3.73066
Value Function Loss: 0.01676

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12338
Policy Update Magnitude: 0.36171
Value Function Update Magnitude: 0.36876

Collected Steps per Second: 22,217.34526
Overall Steps per Second: 10,890.76885

Timestep Collection Time: 2.25094
Timestep Consumption Time: 2.34102
PPO Batch Consumption Time: 0.27678
Total Iteration Time: 4.59196

Cumulative Model Updates: 188,306
Cumulative Timesteps: 1,570,315,304

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1570315304...
Checkpoint 1570315304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 471,597.68771
Policy Entropy: 3.71792
Value Function Loss: 0.01379

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11864
Policy Update Magnitude: 0.33600
Value Function Update Magnitude: 0.29568

Collected Steps per Second: 21,491.80835
Overall Steps per Second: 10,600.57118

Timestep Collection Time: 2.32758
Timestep Consumption Time: 2.39141
PPO Batch Consumption Time: 0.27639
Total Iteration Time: 4.71899

Cumulative Model Updates: 188,312
Cumulative Timesteps: 1,570,365,328

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,597.68771
Policy Entropy: 3.71770
Value Function Loss: 0.01260

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.10031
Policy Update Magnitude: 0.32497
Value Function Update Magnitude: 0.27347

Collected Steps per Second: 23,269.45414
Overall Steps per Second: 11,031.78046

Timestep Collection Time: 2.14960
Timestep Consumption Time: 2.38457
PPO Batch Consumption Time: 0.27555
Total Iteration Time: 4.53417

Cumulative Model Updates: 188,318
Cumulative Timesteps: 1,570,415,348

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1570415348...
Checkpoint 1570415348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 392,129.57508
Policy Entropy: 3.70332
Value Function Loss: 0.01671

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.11063
Policy Update Magnitude: 0.38560
Value Function Update Magnitude: 0.53959

Collected Steps per Second: 22,471.24682
Overall Steps per Second: 10,657.87546

Timestep Collection Time: 2.22587
Timestep Consumption Time: 2.46719
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.69306

Cumulative Model Updates: 188,324
Cumulative Timesteps: 1,570,465,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,736.73709
Policy Entropy: 3.72375
Value Function Loss: 0.01948

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11230
Policy Update Magnitude: 0.48097
Value Function Update Magnitude: 0.61966

Collected Steps per Second: 23,205.78487
Overall Steps per Second: 10,856.92859

Timestep Collection Time: 2.15558
Timestep Consumption Time: 2.45180
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.60738

Cumulative Model Updates: 188,330
Cumulative Timesteps: 1,570,515,388

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1570515388...
Checkpoint 1570515388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 277,478.06503
Policy Entropy: 3.72403
Value Function Loss: 0.02620

Mean KL Divergence: 0.00541
SB3 Clip Fraction: 0.06380
Policy Update Magnitude: 0.58467
Value Function Update Magnitude: 0.61592

Collected Steps per Second: 22,486.84891
Overall Steps per Second: 10,643.30514

Timestep Collection Time: 2.22406
Timestep Consumption Time: 2.47486
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.69892

Cumulative Model Updates: 188,336
Cumulative Timesteps: 1,570,565,400

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 224,754.31120
Policy Entropy: 3.72171
Value Function Loss: 0.02684

Mean KL Divergence: 0.00510
SB3 Clip Fraction: 0.05899
Policy Update Magnitude: 0.66025
Value Function Update Magnitude: 0.55649

Collected Steps per Second: 23,067.24857
Overall Steps per Second: 10,937.45319

Timestep Collection Time: 2.16827
Timestep Consumption Time: 2.40464
PPO Batch Consumption Time: 0.27578
Total Iteration Time: 4.57291

Cumulative Model Updates: 188,342
Cumulative Timesteps: 1,570,615,416

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1570615416...
Checkpoint 1570615416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 810,226.40755
Policy Entropy: 3.71680
Value Function Loss: 0.02682

Mean KL Divergence: 0.00638
SB3 Clip Fraction: 0.07538
Policy Update Magnitude: 0.67049
Value Function Update Magnitude: 0.50003

Collected Steps per Second: 22,652.20349
Overall Steps per Second: 10,648.02333

Timestep Collection Time: 2.20817
Timestep Consumption Time: 2.48941
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.69759

Cumulative Model Updates: 188,348
Cumulative Timesteps: 1,570,665,436

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 810,226.40755
Policy Entropy: 3.70492
Value Function Loss: 0.02183

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10647
Policy Update Magnitude: 0.59471
Value Function Update Magnitude: 0.49236

Collected Steps per Second: 23,043.58549
Overall Steps per Second: 10,926.54029

Timestep Collection Time: 2.17006
Timestep Consumption Time: 2.40650
PPO Batch Consumption Time: 0.27560
Total Iteration Time: 4.57656

Cumulative Model Updates: 188,354
Cumulative Timesteps: 1,570,715,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1570715442...
Checkpoint 1570715442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 631,612.51124
Policy Entropy: 3.71816
Value Function Loss: 0.02521

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13511
Policy Update Magnitude: 0.50622
Value Function Update Magnitude: 0.45043

Collected Steps per Second: 22,467.55585
Overall Steps per Second: 10,618.77560

Timestep Collection Time: 2.22641
Timestep Consumption Time: 2.48430
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.71071

Cumulative Model Updates: 188,360
Cumulative Timesteps: 1,570,765,464

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 414,404.49005
Policy Entropy: 3.70362
Value Function Loss: 0.02669

Mean KL Divergence: 0.02631
SB3 Clip Fraction: 0.27604
Policy Update Magnitude: 0.44623
Value Function Update Magnitude: 0.38056

Collected Steps per Second: 22,426.96805
Overall Steps per Second: 10,909.00285

Timestep Collection Time: 2.22964
Timestep Consumption Time: 2.35410
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.58374

Cumulative Model Updates: 188,366
Cumulative Timesteps: 1,570,815,468

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1570815468...
Checkpoint 1570815468 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 816,919.53009
Policy Entropy: 3.71173
Value Function Loss: 0.03347

Mean KL Divergence: 0.02485
SB3 Clip Fraction: 0.25460
Policy Update Magnitude: 0.39557
Value Function Update Magnitude: 0.45928

Collected Steps per Second: 21,504.83822
Overall Steps per Second: 10,594.68758

Timestep Collection Time: 2.32590
Timestep Consumption Time: 2.39515
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.72105

Cumulative Model Updates: 188,372
Cumulative Timesteps: 1,570,865,486

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,902.27799
Policy Entropy: 3.69593
Value Function Loss: 0.03304

Mean KL Divergence: 0.02780
SB3 Clip Fraction: 0.28138
Policy Update Magnitude: 0.43101
Value Function Update Magnitude: 0.43598

Collected Steps per Second: 22,555.30939
Overall Steps per Second: 10,991.80287

Timestep Collection Time: 2.21757
Timestep Consumption Time: 2.33291
PPO Batch Consumption Time: 0.27536
Total Iteration Time: 4.55048

Cumulative Model Updates: 188,378
Cumulative Timesteps: 1,570,915,504

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1570915504...
Checkpoint 1570915504 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.70940
Value Function Loss: 0.03386

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.16618
Policy Update Magnitude: 0.49013
Value Function Update Magnitude: 0.39869

Collected Steps per Second: 22,114.13676
Overall Steps per Second: 10,587.01292

Timestep Collection Time: 2.26226
Timestep Consumption Time: 2.46315
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.72541

Cumulative Model Updates: 188,384
Cumulative Timesteps: 1,570,965,532

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.71469
Value Function Loss: 0.02422

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13477
Policy Update Magnitude: 0.48797
Value Function Update Magnitude: 0.41667

Collected Steps per Second: 22,919.63610
Overall Steps per Second: 10,882.11064

Timestep Collection Time: 2.18223
Timestep Consumption Time: 2.41393
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.59617

Cumulative Model Updates: 188,390
Cumulative Timesteps: 1,571,015,548

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1571015548...
Checkpoint 1571015548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.71146
Value Function Loss: 0.02066

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13229
Policy Update Magnitude: 0.46220
Value Function Update Magnitude: 0.48749

Collected Steps per Second: 22,681.71939
Overall Steps per Second: 10,700.07364

Timestep Collection Time: 2.20601
Timestep Consumption Time: 2.47022
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.67623

Cumulative Model Updates: 188,396
Cumulative Timesteps: 1,571,065,584

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.69728
Value Function Loss: 0.01924

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05710
Policy Update Magnitude: 0.51106
Value Function Update Magnitude: 0.52292

Collected Steps per Second: 22,991.90838
Overall Steps per Second: 10,867.44872

Timestep Collection Time: 2.17546
Timestep Consumption Time: 2.42709
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.60255

Cumulative Model Updates: 188,402
Cumulative Timesteps: 1,571,115,602

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1571115602...
Checkpoint 1571115602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.70205
Value Function Loss: 0.01803

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.06020
Policy Update Magnitude: 0.57897
Value Function Update Magnitude: 0.45543

Collected Steps per Second: 22,409.59851
Overall Steps per Second: 10,684.24168

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.44988
PPO Batch Consumption Time: 0.28419
Total Iteration Time: 4.68222

Cumulative Model Updates: 188,408
Cumulative Timesteps: 1,571,165,628

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.72227
Value Function Loss: 0.01530

Mean KL Divergence: 0.00577
SB3 Clip Fraction: 0.06791
Policy Update Magnitude: 0.52329
Value Function Update Magnitude: 0.42329

Collected Steps per Second: 23,013.26248
Overall Steps per Second: 10,867.70041

Timestep Collection Time: 2.17370
Timestep Consumption Time: 2.42929
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.60300

Cumulative Model Updates: 188,414
Cumulative Timesteps: 1,571,215,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1571215652...
Checkpoint 1571215652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.73547
Value Function Loss: 0.01189

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05627
Policy Update Magnitude: 0.41686
Value Function Update Magnitude: 0.33989

Collected Steps per Second: 22,296.45956
Overall Steps per Second: 10,598.11821

Timestep Collection Time: 2.24341
Timestep Consumption Time: 2.47630
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.71971

Cumulative Model Updates: 188,420
Cumulative Timesteps: 1,571,265,672

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.72619
Value Function Loss: 0.01207

Mean KL Divergence: 0.00701
SB3 Clip Fraction: 0.09131
Policy Update Magnitude: 0.38477
Value Function Update Magnitude: 0.29606

Collected Steps per Second: 22,725.02237
Overall Steps per Second: 10,699.13922

Timestep Collection Time: 2.20066
Timestep Consumption Time: 2.47355
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.67421

Cumulative Model Updates: 188,426
Cumulative Timesteps: 1,571,315,682

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1571315682...
Checkpoint 1571315682 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.70602
Value Function Loss: 0.01505

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06598
Policy Update Magnitude: 0.45672
Value Function Update Magnitude: 0.36855

Collected Steps per Second: 22,596.41601
Overall Steps per Second: 10,825.18701

Timestep Collection Time: 2.21380
Timestep Consumption Time: 2.40727
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.62107

Cumulative Model Updates: 188,432
Cumulative Timesteps: 1,571,365,706

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.68884
Value Function Loss: 0.01760

Mean KL Divergence: 0.00700
SB3 Clip Fraction: 0.08575
Policy Update Magnitude: 0.54835
Value Function Update Magnitude: 0.38025

Collected Steps per Second: 22,793.72779
Overall Steps per Second: 10,745.86949

Timestep Collection Time: 2.19499
Timestep Consumption Time: 2.46094
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.65593

Cumulative Model Updates: 188,438
Cumulative Timesteps: 1,571,415,738

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1571415738...
Checkpoint 1571415738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.69419
Value Function Loss: 0.01688

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09036
Policy Update Magnitude: 0.52819
Value Function Update Magnitude: 0.34878

Collected Steps per Second: 21,677.81465
Overall Steps per Second: 10,660.45469

Timestep Collection Time: 2.30687
Timestep Consumption Time: 2.38411
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.69098

Cumulative Model Updates: 188,444
Cumulative Timesteps: 1,571,465,746

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.71617
Value Function Loss: 0.01487

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14087
Policy Update Magnitude: 0.44859
Value Function Update Magnitude: 0.30066

Collected Steps per Second: 22,026.92246
Overall Steps per Second: 10,670.47396

Timestep Collection Time: 2.27113
Timestep Consumption Time: 2.41713
PPO Batch Consumption Time: 0.28825
Total Iteration Time: 4.68826

Cumulative Model Updates: 188,450
Cumulative Timesteps: 1,571,515,772

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1571515772...
Checkpoint 1571515772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.72152
Value Function Loss: 0.01425

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13627
Policy Update Magnitude: 0.37353
Value Function Update Magnitude: 0.25871

Collected Steps per Second: 22,089.34710
Overall Steps per Second: 10,652.13255

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.43075
PPO Batch Consumption Time: 0.28475
Total Iteration Time: 4.69465

Cumulative Model Updates: 188,456
Cumulative Timesteps: 1,571,565,780

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.70882
Value Function Loss: 0.01575

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.34788
Value Function Update Magnitude: 0.28358

Collected Steps per Second: 22,892.58830
Overall Steps per Second: 10,917.92882

Timestep Collection Time: 2.18464
Timestep Consumption Time: 2.39609
PPO Batch Consumption Time: 0.27700
Total Iteration Time: 4.58072

Cumulative Model Updates: 188,462
Cumulative Timesteps: 1,571,615,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1571615792...
Checkpoint 1571615792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.69545
Value Function Loss: 0.01841

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.37712
Value Function Update Magnitude: 0.25511

Collected Steps per Second: 22,435.42123
Overall Steps per Second: 10,621.01124

Timestep Collection Time: 2.22915
Timestep Consumption Time: 2.47963
PPO Batch Consumption Time: 0.29346
Total Iteration Time: 4.70878

Cumulative Model Updates: 188,468
Cumulative Timesteps: 1,571,665,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.69146
Value Function Loss: 0.01776

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.37339
Value Function Update Magnitude: 0.27700

Collected Steps per Second: 22,837.48935
Overall Steps per Second: 10,832.03126

Timestep Collection Time: 2.19052
Timestep Consumption Time: 2.42782
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.61834

Cumulative Model Updates: 188,474
Cumulative Timesteps: 1,571,715,830

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1571715830...
Checkpoint 1571715830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.70963
Value Function Loss: 0.01581

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.16163
Policy Update Magnitude: 0.38214
Value Function Update Magnitude: 0.32459

Collected Steps per Second: 22,556.38182
Overall Steps per Second: 10,731.90009

Timestep Collection Time: 2.21738
Timestep Consumption Time: 2.44312
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.66050

Cumulative Model Updates: 188,480
Cumulative Timesteps: 1,571,765,846

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.71525
Value Function Loss: 0.01380

Mean KL Divergence: 0.00710
SB3 Clip Fraction: 0.09106
Policy Update Magnitude: 0.35340
Value Function Update Magnitude: 0.28818

Collected Steps per Second: 23,012.05798
Overall Steps per Second: 10,865.21858

Timestep Collection Time: 2.17321
Timestep Consumption Time: 2.42955
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.60276

Cumulative Model Updates: 188,486
Cumulative Timesteps: 1,571,815,856

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1571815856...
Checkpoint 1571815856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,336.27094
Policy Entropy: 3.71093
Value Function Loss: 0.01334

Mean KL Divergence: 0.01266
SB3 Clip Fraction: 0.16244
Policy Update Magnitude: 0.32788
Value Function Update Magnitude: 0.25156

Collected Steps per Second: 22,677.46798
Overall Steps per Second: 10,670.33786

Timestep Collection Time: 2.20598
Timestep Consumption Time: 2.48235
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.68832

Cumulative Model Updates: 188,492
Cumulative Timesteps: 1,571,865,882

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,073,476.38228
Policy Entropy: 3.72783
Value Function Loss: 0.01259

Mean KL Divergence: 0.01545
SB3 Clip Fraction: 0.19893
Policy Update Magnitude: 0.29833
Value Function Update Magnitude: 0.45593

Collected Steps per Second: 23,055.47150
Overall Steps per Second: 10,884.61649

Timestep Collection Time: 2.16886
Timestep Consumption Time: 2.42515
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.59401

Cumulative Model Updates: 188,498
Cumulative Timesteps: 1,571,915,886

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1571915886...
Checkpoint 1571915886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,306.55066
Policy Entropy: 3.72552
Value Function Loss: 0.01280

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14130
Policy Update Magnitude: 0.32316
Value Function Update Magnitude: 0.62168

Collected Steps per Second: 22,709.00419
Overall Steps per Second: 10,680.47582

Timestep Collection Time: 2.20212
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.28903
Total Iteration Time: 4.68219

Cumulative Model Updates: 188,504
Cumulative Timesteps: 1,571,965,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 704,306.55066
Policy Entropy: 3.71546
Value Function Loss: 0.01206

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.30924
Value Function Update Magnitude: 0.58064

Collected Steps per Second: 23,251.45960
Overall Steps per Second: 10,959.74352

Timestep Collection Time: 2.15075
Timestep Consumption Time: 2.41213
PPO Batch Consumption Time: 0.27564
Total Iteration Time: 4.56288

Cumulative Model Updates: 188,510
Cumulative Timesteps: 1,572,015,902

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1572015902...
Checkpoint 1572015902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 704,306.55066
Policy Entropy: 3.69542
Value Function Loss: 0.01351

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.31465
Value Function Update Magnitude: 0.50561

Collected Steps per Second: 22,803.07307
Overall Steps per Second: 10,708.92061

Timestep Collection Time: 2.19365
Timestep Consumption Time: 2.47741
PPO Batch Consumption Time: 0.29046
Total Iteration Time: 4.67106

Cumulative Model Updates: 188,516
Cumulative Timesteps: 1,572,065,924

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 867,104.54498
Policy Entropy: 3.67496
Value Function Loss: 0.01876

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14752
Policy Update Magnitude: 0.36705
Value Function Update Magnitude: 0.56474

Collected Steps per Second: 23,308.46653
Overall Steps per Second: 10,788.12085

Timestep Collection Time: 2.14566
Timestep Consumption Time: 2.49018
PPO Batch Consumption Time: 0.28875
Total Iteration Time: 4.63584

Cumulative Model Updates: 188,522
Cumulative Timesteps: 1,572,115,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1572115936...
Checkpoint 1572115936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,909.70499
Policy Entropy: 3.68257
Value Function Loss: 0.01978

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.46461
Value Function Update Magnitude: 0.64533

Collected Steps per Second: 22,494.12634
Overall Steps per Second: 10,654.29454

Timestep Collection Time: 2.22289
Timestep Consumption Time: 2.47024
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.69313

Cumulative Model Updates: 188,528
Cumulative Timesteps: 1,572,165,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 568,909.70499
Policy Entropy: 3.66740
Value Function Loss: 0.02298

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13504
Policy Update Magnitude: 0.48457
Value Function Update Magnitude: 0.64453

Collected Steps per Second: 22,926.96065
Overall Steps per Second: 10,871.19370

Timestep Collection Time: 2.18093
Timestep Consumption Time: 2.41857
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.59949

Cumulative Model Updates: 188,534
Cumulative Timesteps: 1,572,215,940

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1572215940...
Checkpoint 1572215940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 568,909.70499
Policy Entropy: 3.68193
Value Function Loss: 0.02117

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.49306
Value Function Update Magnitude: 0.63011

Collected Steps per Second: 22,747.05663
Overall Steps per Second: 10,663.05498

Timestep Collection Time: 2.20002
Timestep Consumption Time: 2.49319
PPO Batch Consumption Time: 0.29270
Total Iteration Time: 4.69321

Cumulative Model Updates: 188,540
Cumulative Timesteps: 1,572,265,984

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846,932.43505
Policy Entropy: 3.67036
Value Function Loss: 0.02363

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.14075
Policy Update Magnitude: 0.49066
Value Function Update Magnitude: 0.64162

Collected Steps per Second: 22,371.98018
Overall Steps per Second: 10,951.29348

Timestep Collection Time: 2.23521
Timestep Consumption Time: 2.33101
PPO Batch Consumption Time: 0.27560
Total Iteration Time: 4.56622

Cumulative Model Updates: 188,546
Cumulative Timesteps: 1,572,315,990

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1572315990...
Checkpoint 1572315990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 846,932.43505
Policy Entropy: 3.67393
Value Function Loss: 0.02614

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13366
Policy Update Magnitude: 0.49177
Value Function Update Magnitude: 0.60892

Collected Steps per Second: 22,063.10788
Overall Steps per Second: 10,680.72430

Timestep Collection Time: 2.26731
Timestep Consumption Time: 2.41626
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.68358

Cumulative Model Updates: 188,552
Cumulative Timesteps: 1,572,366,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846,932.43505
Policy Entropy: 3.66423
Value Function Loss: 0.02528

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.14544
Policy Update Magnitude: 0.50111
Value Function Update Magnitude: 0.53485

Collected Steps per Second: 22,415.34582
Overall Steps per Second: 10,762.15409

Timestep Collection Time: 2.23169
Timestep Consumption Time: 2.41645
PPO Batch Consumption Time: 0.27852
Total Iteration Time: 4.64814

Cumulative Model Updates: 188,558
Cumulative Timesteps: 1,572,416,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1572416038...
Checkpoint 1572416038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 846,932.43505
Policy Entropy: 3.66171
Value Function Loss: 0.02491

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13412
Policy Update Magnitude: 0.46622
Value Function Update Magnitude: 0.46899

Collected Steps per Second: 22,542.89926
Overall Steps per Second: 10,702.27655

Timestep Collection Time: 2.21835
Timestep Consumption Time: 2.45430
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.67265

Cumulative Model Updates: 188,564
Cumulative Timesteps: 1,572,466,046

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846,932.43505
Policy Entropy: 3.67283
Value Function Loss: 0.02315

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13048
Policy Update Magnitude: 0.48202
Value Function Update Magnitude: 0.49080

Collected Steps per Second: 22,999.58000
Overall Steps per Second: 10,973.66030

Timestep Collection Time: 2.17404
Timestep Consumption Time: 2.38251
PPO Batch Consumption Time: 0.27555
Total Iteration Time: 4.55655

Cumulative Model Updates: 188,570
Cumulative Timesteps: 1,572,516,048

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1572516048...
Checkpoint 1572516048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 846,932.43505
Policy Entropy: 3.67431
Value Function Loss: 0.02554

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.50576
Value Function Update Magnitude: 0.48033

Collected Steps per Second: 22,308.63360
Overall Steps per Second: 10,574.20281

Timestep Collection Time: 2.24209
Timestep Consumption Time: 2.48810
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.73019

Cumulative Model Updates: 188,576
Cumulative Timesteps: 1,572,566,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 846,932.43505
Policy Entropy: 3.67425
Value Function Loss: 0.02506

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.50893
Value Function Update Magnitude: 0.43677

Collected Steps per Second: 22,820.32841
Overall Steps per Second: 10,823.42625

Timestep Collection Time: 2.19243
Timestep Consumption Time: 2.43013
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.62257

Cumulative Model Updates: 188,582
Cumulative Timesteps: 1,572,616,098

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1572616098...
Checkpoint 1572616098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 717,510.91652
Policy Entropy: 3.66024
Value Function Loss: 0.02975

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13154
Policy Update Magnitude: 0.51880
Value Function Update Magnitude: 0.53545

Collected Steps per Second: 22,682.49910
Overall Steps per Second: 10,721.28560

Timestep Collection Time: 2.20549
Timestep Consumption Time: 2.46056
PPO Batch Consumption Time: 0.28478
Total Iteration Time: 4.66604

Cumulative Model Updates: 188,588
Cumulative Timesteps: 1,572,666,124

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,860.50597
Policy Entropy: 3.66638
Value Function Loss: 0.03114

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.57444
Value Function Update Magnitude: 0.55090

Collected Steps per Second: 22,577.85418
Overall Steps per Second: 10,663.13668

Timestep Collection Time: 2.21474
Timestep Consumption Time: 2.47469
PPO Batch Consumption Time: 0.28797
Total Iteration Time: 4.68943

Cumulative Model Updates: 188,594
Cumulative Timesteps: 1,572,716,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1572716128...
Checkpoint 1572716128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,860.50597
Policy Entropy: 3.66843
Value Function Loss: 0.03334

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.55276
Value Function Update Magnitude: 0.49575

Collected Steps per Second: 22,615.36714
Overall Steps per Second: 10,804.85736

Timestep Collection Time: 2.21248
Timestep Consumption Time: 2.41840
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.63088

Cumulative Model Updates: 188,600
Cumulative Timesteps: 1,572,766,164

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,860.50597
Policy Entropy: 3.68422
Value Function Loss: 0.02868

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.51840
Value Function Update Magnitude: 0.39159

Collected Steps per Second: 22,717.01431
Overall Steps per Second: 10,656.67527

Timestep Collection Time: 2.20196
Timestep Consumption Time: 2.49200
PPO Batch Consumption Time: 0.29056
Total Iteration Time: 4.69396

Cumulative Model Updates: 188,606
Cumulative Timesteps: 1,572,816,186

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1572816186...
Checkpoint 1572816186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,860.50597
Policy Entropy: 3.67647
Value Function Loss: 0.03119

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.48772
Value Function Update Magnitude: 0.30241

Collected Steps per Second: 22,673.00734
Overall Steps per Second: 10,686.89274

Timestep Collection Time: 2.20641
Timestep Consumption Time: 2.47465
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.68106

Cumulative Model Updates: 188,612
Cumulative Timesteps: 1,572,866,212

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,860.50597
Policy Entropy: 3.67938
Value Function Loss: 0.02961

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.49570
Value Function Update Magnitude: 0.29645

Collected Steps per Second: 22,424.44576
Overall Steps per Second: 10,735.13773

Timestep Collection Time: 2.22980
Timestep Consumption Time: 2.42799
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.65779

Cumulative Model Updates: 188,618
Cumulative Timesteps: 1,572,916,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1572916214...
Checkpoint 1572916214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,860.50597
Policy Entropy: 3.67947
Value Function Loss: 0.02777

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13690
Policy Update Magnitude: 0.49386
Value Function Update Magnitude: 0.46050

Collected Steps per Second: 22,719.80693
Overall Steps per Second: 10,675.45179

Timestep Collection Time: 2.20125
Timestep Consumption Time: 2.48352
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.68477

Cumulative Model Updates: 188,624
Cumulative Timesteps: 1,572,966,226

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 308,860.50597
Policy Entropy: 3.68940
Value Function Loss: 0.02553

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12368
Policy Update Magnitude: 0.48437
Value Function Update Magnitude: 0.46418

Collected Steps per Second: 22,760.45851
Overall Steps per Second: 10,795.00249

Timestep Collection Time: 2.19679
Timestep Consumption Time: 2.43498
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.63177

Cumulative Model Updates: 188,630
Cumulative Timesteps: 1,573,016,226

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1573016226...
Checkpoint 1573016226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332,397.99289
Policy Entropy: 3.69930
Value Function Loss: 0.02317

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.50915
Value Function Update Magnitude: 0.51537

Collected Steps per Second: 22,774.75324
Overall Steps per Second: 10,687.98806

Timestep Collection Time: 2.19664
Timestep Consumption Time: 2.48413
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.68077

Cumulative Model Updates: 188,636
Cumulative Timesteps: 1,573,066,254

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332,397.99289
Policy Entropy: 3.69435
Value Function Loss: 0.02291

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.48981
Value Function Update Magnitude: 0.48974

Collected Steps per Second: 22,218.81160
Overall Steps per Second: 10,891.47123

Timestep Collection Time: 2.25179
Timestep Consumption Time: 2.34190
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.59369

Cumulative Model Updates: 188,642
Cumulative Timesteps: 1,573,116,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1573116286...
Checkpoint 1573116286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332,397.99289
Policy Entropy: 3.69692
Value Function Loss: 0.01899

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.44066
Value Function Update Magnitude: 0.44764

Collected Steps per Second: 22,129.39338
Overall Steps per Second: 10,672.33218

Timestep Collection Time: 2.26043
Timestep Consumption Time: 2.42664
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.68707

Cumulative Model Updates: 188,648
Cumulative Timesteps: 1,573,166,308

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332,397.99289
Policy Entropy: 3.68336
Value Function Loss: 0.01757

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13044
Policy Update Magnitude: 0.42213
Value Function Update Magnitude: 0.44400

Collected Steps per Second: 22,208.75654
Overall Steps per Second: 10,625.39196

Timestep Collection Time: 2.25181
Timestep Consumption Time: 2.45484
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.70665

Cumulative Model Updates: 188,654
Cumulative Timesteps: 1,573,216,318

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1573216318...
Checkpoint 1573216318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332,397.99289
Policy Entropy: 3.67972
Value Function Loss: 0.01744

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.40308
Value Function Update Magnitude: 0.38448

Collected Steps per Second: 22,455.62213
Overall Steps per Second: 10,682.57890

Timestep Collection Time: 2.22733
Timestep Consumption Time: 2.45469
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.68202

Cumulative Model Updates: 188,660
Cumulative Timesteps: 1,573,266,334

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 567,486.22023
Policy Entropy: 3.68243
Value Function Loss: 0.02103

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13118
Policy Update Magnitude: 0.40902
Value Function Update Magnitude: 0.37269

Collected Steps per Second: 23,034.88528
Overall Steps per Second: 10,816.10847

Timestep Collection Time: 2.17149
Timestep Consumption Time: 2.45309
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.62458

Cumulative Model Updates: 188,666
Cumulative Timesteps: 1,573,316,354

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1573316354...
Checkpoint 1573316354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,282.22117
Policy Entropy: 3.70098
Value Function Loss: 0.02275

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.44745
Value Function Update Magnitude: 0.45412

Collected Steps per Second: 22,854.58648
Overall Steps per Second: 10,800.44345

Timestep Collection Time: 2.18792
Timestep Consumption Time: 2.44189
PPO Batch Consumption Time: 0.28522
Total Iteration Time: 4.62981

Cumulative Model Updates: 188,672
Cumulative Timesteps: 1,573,366,358

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,191.53881
Policy Entropy: 3.70809
Value Function Loss: 0.02494

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.51039
Value Function Update Magnitude: 0.57670

Collected Steps per Second: 22,775.38365
Overall Steps per Second: 10,624.39371

Timestep Collection Time: 2.19535
Timestep Consumption Time: 2.51080
PPO Batch Consumption Time: 0.29184
Total Iteration Time: 4.70615

Cumulative Model Updates: 188,678
Cumulative Timesteps: 1,573,416,358

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1573416358...
Checkpoint 1573416358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 539,163.10921
Policy Entropy: 3.70674
Value Function Loss: 0.02399

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.52185
Value Function Update Magnitude: 0.60585

Collected Steps per Second: 22,632.37885
Overall Steps per Second: 10,640.76929

Timestep Collection Time: 2.21020
Timestep Consumption Time: 2.49078
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.70098

Cumulative Model Updates: 188,684
Cumulative Timesteps: 1,573,466,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,847.95187
Policy Entropy: 3.68183
Value Function Loss: 0.02688

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13200
Policy Update Magnitude: 0.52780
Value Function Update Magnitude: 0.56348

Collected Steps per Second: 22,982.11602
Overall Steps per Second: 10,894.77379

Timestep Collection Time: 2.17735
Timestep Consumption Time: 2.41568
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.59303

Cumulative Model Updates: 188,690
Cumulative Timesteps: 1,573,516,420

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1573516420...
Checkpoint 1573516420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,847.95187
Policy Entropy: 3.69086
Value Function Loss: 0.02447

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13314
Policy Update Magnitude: 0.51714
Value Function Update Magnitude: 0.51374

Collected Steps per Second: 22,705.43819
Overall Steps per Second: 10,693.42391

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.47375
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.67596

Cumulative Model Updates: 188,696
Cumulative Timesteps: 1,573,566,422

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,847.95187
Policy Entropy: 3.68917
Value Function Loss: 0.02286

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13274
Policy Update Magnitude: 0.50689
Value Function Update Magnitude: 0.48539

Collected Steps per Second: 23,222.37204
Overall Steps per Second: 10,949.16008

Timestep Collection Time: 2.15361
Timestep Consumption Time: 2.41404
PPO Batch Consumption Time: 0.27616
Total Iteration Time: 4.56766

Cumulative Model Updates: 188,702
Cumulative Timesteps: 1,573,616,434

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1573616434...
Checkpoint 1573616434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,847.95187
Policy Entropy: 3.70160
Value Function Loss: 0.02013

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13025
Policy Update Magnitude: 0.46569
Value Function Update Magnitude: 0.51621

Collected Steps per Second: 21,723.99414
Overall Steps per Second: 10,596.39486

Timestep Collection Time: 2.30169
Timestep Consumption Time: 2.41708
PPO Batch Consumption Time: 0.29174
Total Iteration Time: 4.71877

Cumulative Model Updates: 188,708
Cumulative Timesteps: 1,573,666,436

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,847.95187
Policy Entropy: 3.69159
Value Function Loss: 0.01965

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.52074
Value Function Update Magnitude: 0.57873

Collected Steps per Second: 22,388.04868
Overall Steps per Second: 10,967.78054

Timestep Collection Time: 2.23405
Timestep Consumption Time: 2.32622
PPO Batch Consumption Time: 0.27566
Total Iteration Time: 4.56027

Cumulative Model Updates: 188,714
Cumulative Timesteps: 1,573,716,452

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1573716452...
Checkpoint 1573716452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,847.95187
Policy Entropy: 3.69194
Value Function Loss: 0.01861

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06774
Policy Update Magnitude: 0.61087
Value Function Update Magnitude: 0.63784

Collected Steps per Second: 22,084.17076
Overall Steps per Second: 10,591.71603

Timestep Collection Time: 2.26452
Timestep Consumption Time: 2.45710
PPO Batch Consumption Time: 0.28924
Total Iteration Time: 4.72161

Cumulative Model Updates: 188,720
Cumulative Timesteps: 1,573,766,462

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 578,847.95187
Policy Entropy: 3.68814
Value Function Loss: 0.01513

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11596
Policy Update Magnitude: 0.58587
Value Function Update Magnitude: 0.56528

Collected Steps per Second: 22,972.24165
Overall Steps per Second: 10,926.89202

Timestep Collection Time: 2.17785
Timestep Consumption Time: 2.40077
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.57861

Cumulative Model Updates: 188,726
Cumulative Timesteps: 1,573,816,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1573816492...
Checkpoint 1573816492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,847.95187
Policy Entropy: 3.67918
Value Function Loss: 0.01641

Mean KL Divergence: 0.01881
SB3 Clip Fraction: 0.22653
Policy Update Magnitude: 0.44250
Value Function Update Magnitude: 0.49622

Collected Steps per Second: 23,095.53630
Overall Steps per Second: 10,975.88817

Timestep Collection Time: 2.16492
Timestep Consumption Time: 2.39052
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.55544

Cumulative Model Updates: 188,732
Cumulative Timesteps: 1,573,866,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 656,609.16315
Policy Entropy: 3.63547
Value Function Loss: 0.05025

Mean KL Divergence: 0.02349
SB3 Clip Fraction: 0.24376
Policy Update Magnitude: 0.42046
Value Function Update Magnitude: 0.46428

Collected Steps per Second: 22,683.13750
Overall Steps per Second: 10,668.63224

Timestep Collection Time: 2.20552
Timestep Consumption Time: 2.48375
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.68926

Cumulative Model Updates: 188,738
Cumulative Timesteps: 1,573,916,520

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1573916520...
Checkpoint 1573916520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 677,683.56125
Policy Entropy: 3.64358
Value Function Loss: 0.08440

Mean KL Divergence: 0.01909
SB3 Clip Fraction: 0.20229
Policy Update Magnitude: 0.53967
Value Function Update Magnitude: 0.52259

Collected Steps per Second: 22,734.07886
Overall Steps per Second: 10,904.92784

Timestep Collection Time: 2.20022
Timestep Consumption Time: 2.38670
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.58692

Cumulative Model Updates: 188,744
Cumulative Timesteps: 1,573,966,540

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,647.54704
Policy Entropy: 3.71107
Value Function Loss: 0.10535

Mean KL Divergence: 0.01750
SB3 Clip Fraction: 0.17715
Policy Update Magnitude: 0.70692
Value Function Update Magnitude: 0.65838

Collected Steps per Second: 22,857.51692
Overall Steps per Second: 10,902.70099

Timestep Collection Time: 2.18755
Timestep Consumption Time: 2.39865
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.58620

Cumulative Model Updates: 188,750
Cumulative Timesteps: 1,574,016,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1574016542...
Checkpoint 1574016542 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,234.14521
Policy Entropy: 3.80990
Value Function Loss: 0.09913

Mean KL Divergence: 0.01498
SB3 Clip Fraction: 0.16226
Policy Update Magnitude: 1.01494
Value Function Update Magnitude: 0.67306

Collected Steps per Second: 22,475.65227
Overall Steps per Second: 10,719.21141

Timestep Collection Time: 2.22668
Timestep Consumption Time: 2.44214
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.66881

Cumulative Model Updates: 188,756
Cumulative Timesteps: 1,574,066,588

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 273.61026
Policy Entropy: 3.91466
Value Function Loss: 0.07345

Mean KL Divergence: 0.02233
SB3 Clip Fraction: 0.21090
Policy Update Magnitude: 1.14131
Value Function Update Magnitude: 0.71706

Collected Steps per Second: 22,453.67706
Overall Steps per Second: 10,961.10974

Timestep Collection Time: 2.22734
Timestep Consumption Time: 2.33534
PPO Batch Consumption Time: 0.27654
Total Iteration Time: 4.56268

Cumulative Model Updates: 188,762
Cumulative Timesteps: 1,574,116,600

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1574116600...
Checkpoint 1574116600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,847.60748
Policy Entropy: 3.97719
Value Function Loss: 0.05913

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.16666
Policy Update Magnitude: 1.47954
Value Function Update Magnitude: 0.93055

Collected Steps per Second: 22,010.23595
Overall Steps per Second: 10,684.76209

Timestep Collection Time: 2.27258
Timestep Consumption Time: 2.40885
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.68143

Cumulative Model Updates: 188,768
Cumulative Timesteps: 1,574,166,620

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,860.93008
Policy Entropy: 4.02679
Value Function Loss: 0.04617

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.14518
Policy Update Magnitude: 1.54949
Value Function Update Magnitude: 1.11576

Collected Steps per Second: 22,711.00283
Overall Steps per Second: 10,855.25902

Timestep Collection Time: 2.20290
Timestep Consumption Time: 2.40593
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.60883

Cumulative Model Updates: 188,774
Cumulative Timesteps: 1,574,216,650

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1574216650...
Checkpoint 1574216650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 792.36000
Policy Entropy: 3.98602
Value Function Loss: 0.05124

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.13084
Policy Update Magnitude: 1.46002
Value Function Update Magnitude: 1.26095

Collected Steps per Second: 22,591.59319
Overall Steps per Second: 10,635.90504

Timestep Collection Time: 2.21428
Timestep Consumption Time: 2.48904
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.70331

Cumulative Model Updates: 188,780
Cumulative Timesteps: 1,574,266,674

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,467.34333
Policy Entropy: 3.94509
Value Function Loss: 0.05589

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11326
Policy Update Magnitude: 1.34308
Value Function Update Magnitude: 1.20573

Collected Steps per Second: 22,717.15323
Overall Steps per Second: 10,809.99175

Timestep Collection Time: 2.20142
Timestep Consumption Time: 2.42486
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.62628

Cumulative Model Updates: 188,786
Cumulative Timesteps: 1,574,316,684

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1574316684...
Checkpoint 1574316684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,636.35176
Policy Entropy: 3.89916
Value Function Loss: 0.06418

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 1.14443
Value Function Update Magnitude: 1.08601

Collected Steps per Second: 22,641.63137
Overall Steps per Second: 10,715.78730

Timestep Collection Time: 2.20956
Timestep Consumption Time: 2.45907
PPO Batch Consumption Time: 0.28434
Total Iteration Time: 4.66863

Cumulative Model Updates: 188,792
Cumulative Timesteps: 1,574,366,712

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,765.02437
Policy Entropy: 3.90448
Value Function Loss: 0.06299

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.10711
Policy Update Magnitude: 1.04961
Value Function Update Magnitude: 0.86040

Collected Steps per Second: 21,011.59304
Overall Steps per Second: 10,078.49392

Timestep Collection Time: 2.38097
Timestep Consumption Time: 2.58287
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.96384

Cumulative Model Updates: 188,798
Cumulative Timesteps: 1,574,416,740

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1574416740...
Checkpoint 1574416740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,445.49209
Policy Entropy: 3.85396
Value Function Loss: 0.06091

Mean KL Divergence: 0.01314
SB3 Clip Fraction: 0.16295
Policy Update Magnitude: 0.87323
Value Function Update Magnitude: 0.71366

Collected Steps per Second: 21,613.21063
Overall Steps per Second: 10,504.92407

Timestep Collection Time: 2.31460
Timestep Consumption Time: 2.44754
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.76215

Cumulative Model Updates: 188,804
Cumulative Timesteps: 1,574,466,766

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,686.46245
Policy Entropy: 3.82181
Value Function Loss: 0.06124

Mean KL Divergence: 0.01917
SB3 Clip Fraction: 0.20796
Policy Update Magnitude: 0.61181
Value Function Update Magnitude: 0.62894

Collected Steps per Second: 22,712.19906
Overall Steps per Second: 10,696.37452

Timestep Collection Time: 2.20252
Timestep Consumption Time: 2.47421
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.67672

Cumulative Model Updates: 188,810
Cumulative Timesteps: 1,574,516,790

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1574516790...
Checkpoint 1574516790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,326.99506
Policy Entropy: 3.79698
Value Function Loss: 0.06922

Mean KL Divergence: 0.01775
SB3 Clip Fraction: 0.18746
Policy Update Magnitude: 0.49428
Value Function Update Magnitude: 0.52865

Collected Steps per Second: 22,737.75894
Overall Steps per Second: 10,862.55272

Timestep Collection Time: 2.19943
Timestep Consumption Time: 2.40446
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.60389

Cumulative Model Updates: 188,816
Cumulative Timesteps: 1,574,566,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,708.62385
Policy Entropy: 3.86202
Value Function Loss: 0.07549

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.59416
Value Function Update Magnitude: 0.47995

Collected Steps per Second: 22,702.99854
Overall Steps per Second: 10,692.81092

Timestep Collection Time: 2.20464
Timestep Consumption Time: 2.47626
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.68090

Cumulative Model Updates: 188,822
Cumulative Timesteps: 1,574,616,852

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1574616852...
Checkpoint 1574616852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161.35871
Policy Entropy: 3.92861
Value Function Loss: 0.07373

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.11776
Policy Update Magnitude: 0.78924
Value Function Update Magnitude: 0.58399

Collected Steps per Second: 22,702.52388
Overall Steps per Second: 10,724.23551

Timestep Collection Time: 2.20240
Timestep Consumption Time: 2.45994
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.66234

Cumulative Model Updates: 188,828
Cumulative Timesteps: 1,574,666,852

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 761.72152
Policy Entropy: 3.96393
Value Function Loss: 0.06132

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08668
Policy Update Magnitude: 0.97466
Value Function Update Magnitude: 0.60264

Collected Steps per Second: 22,589.37306
Overall Steps per Second: 10,685.70031

Timestep Collection Time: 2.21396
Timestep Consumption Time: 2.46631
PPO Batch Consumption Time: 0.28540
Total Iteration Time: 4.68027

Cumulative Model Updates: 188,834
Cumulative Timesteps: 1,574,716,864

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1574716864...
Checkpoint 1574716864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116.10600
Policy Entropy: 3.94504
Value Function Loss: 0.05581

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10309
Policy Update Magnitude: 0.93580
Value Function Update Magnitude: 0.65090

Collected Steps per Second: 22,635.93386
Overall Steps per Second: 10,637.69818

Timestep Collection Time: 2.20923
Timestep Consumption Time: 2.49179
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.70102

Cumulative Model Updates: 188,840
Cumulative Timesteps: 1,574,766,872

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,833.40004
Policy Entropy: 3.89341
Value Function Loss: 0.05076

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12073
Policy Update Magnitude: 0.71617
Value Function Update Magnitude: 0.73396

Collected Steps per Second: 22,561.02411
Overall Steps per Second: 10,782.45049

Timestep Collection Time: 2.21630
Timestep Consumption Time: 2.42105
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.63735

Cumulative Model Updates: 188,846
Cumulative Timesteps: 1,574,816,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1574816874...
Checkpoint 1574816874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,992.93057
Policy Entropy: 3.82881
Value Function Loss: 0.04650

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.55319
Value Function Update Magnitude: 0.70827

Collected Steps per Second: 22,902.84964
Overall Steps per Second: 10,723.25218

Timestep Collection Time: 2.18366
Timestep Consumption Time: 2.48023
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.66388

Cumulative Model Updates: 188,852
Cumulative Timesteps: 1,574,866,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,410.61491
Policy Entropy: 3.79347
Value Function Loss: 0.03794

Mean KL Divergence: 0.01135
SB3 Clip Fraction: 0.14828
Policy Update Magnitude: 0.42160
Value Function Update Magnitude: 0.59801

Collected Steps per Second: 22,745.93606
Overall Steps per Second: 10,705.86283

Timestep Collection Time: 2.19828
Timestep Consumption Time: 2.47224
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.67053

Cumulative Model Updates: 188,858
Cumulative Timesteps: 1,574,916,888

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1574916888...
Checkpoint 1574916888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 755.92660
Policy Entropy: 3.74722
Value Function Loss: 0.03473

Mean KL Divergence: 0.01153
SB3 Clip Fraction: 0.15148
Policy Update Magnitude: 0.35402
Value Function Update Magnitude: 0.48382

Collected Steps per Second: 22,641.48757
Overall Steps per Second: 10,803.53546

Timestep Collection Time: 2.20948
Timestep Consumption Time: 2.42104
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.63052

Cumulative Model Updates: 188,864
Cumulative Timesteps: 1,574,966,914

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,353.33349
Policy Entropy: 3.72876
Value Function Loss: 0.03298

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14353
Policy Update Magnitude: 0.34281
Value Function Update Magnitude: 0.42454

Collected Steps per Second: 22,891.56174
Overall Steps per Second: 10,708.95991

Timestep Collection Time: 2.18465
Timestep Consumption Time: 2.48527
PPO Batch Consumption Time: 0.28756
Total Iteration Time: 4.66992

Cumulative Model Updates: 188,870
Cumulative Timesteps: 1,575,016,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1575016924...
Checkpoint 1575016924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,318.33029
Policy Entropy: 3.72499
Value Function Loss: 0.03128

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.34517
Value Function Update Magnitude: 0.46121

Collected Steps per Second: 22,762.64038
Overall Steps per Second: 10,833.19057

Timestep Collection Time: 2.19737
Timestep Consumption Time: 2.41973
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.61711

Cumulative Model Updates: 188,876
Cumulative Timesteps: 1,575,066,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,099.91531
Policy Entropy: 3.72000
Value Function Loss: 0.03318

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.37910
Value Function Update Magnitude: 0.47920

Collected Steps per Second: 22,664.90266
Overall Steps per Second: 10,694.84462

Timestep Collection Time: 2.20702
Timestep Consumption Time: 2.47018
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.67721

Cumulative Model Updates: 188,882
Cumulative Timesteps: 1,575,116,964

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1575116964...
Checkpoint 1575116964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,022.12649
Policy Entropy: 3.72718
Value Function Loss: 0.03256

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13487
Policy Update Magnitude: 0.40479
Value Function Update Magnitude: 0.61119

Collected Steps per Second: 22,911.65026
Overall Steps per Second: 10,881.12131

Timestep Collection Time: 2.18317
Timestep Consumption Time: 2.41378
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.59695

Cumulative Model Updates: 188,888
Cumulative Timesteps: 1,575,166,984

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,886.13747
Policy Entropy: 3.72253
Value Function Loss: 0.03362

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.39251
Value Function Update Magnitude: 0.55111

Collected Steps per Second: 22,783.52793
Overall Steps per Second: 10,829.96338

Timestep Collection Time: 2.19580
Timestep Consumption Time: 2.42361
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.61941

Cumulative Model Updates: 188,894
Cumulative Timesteps: 1,575,217,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1575217012...
Checkpoint 1575217012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,886.13747
Policy Entropy: 3.73145
Value Function Loss: 0.02994

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.13097
Policy Update Magnitude: 0.38503
Value Function Update Magnitude: 0.52091

Collected Steps per Second: 22,309.03160
Overall Steps per Second: 10,694.33856

Timestep Collection Time: 2.24205
Timestep Consumption Time: 2.43500
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.67705

Cumulative Model Updates: 188,900
Cumulative Timesteps: 1,575,267,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,886.13747
Policy Entropy: 3.71289
Value Function Loss: 0.02462

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14367
Policy Update Magnitude: 0.39634
Value Function Update Magnitude: 0.54852

Collected Steps per Second: 22,730.78901
Overall Steps per Second: 10,679.57774

Timestep Collection Time: 2.20080
Timestep Consumption Time: 2.48346
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.68427

Cumulative Model Updates: 188,906
Cumulative Timesteps: 1,575,317,056

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1575317056...
Checkpoint 1575317056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,726.96375
Policy Entropy: 3.72400
Value Function Loss: 0.02160

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13728
Policy Update Magnitude: 0.38136
Value Function Update Magnitude: 0.52280

Collected Steps per Second: 22,636.46179
Overall Steps per Second: 10,676.92685

Timestep Collection Time: 2.20989
Timestep Consumption Time: 2.47536
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.68524

Cumulative Model Updates: 188,912
Cumulative Timesteps: 1,575,367,080

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 54,221.82458
Policy Entropy: 3.72380
Value Function Loss: 0.02012

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.33785
Value Function Update Magnitude: 0.53382

Collected Steps per Second: 22,570.99370
Overall Steps per Second: 10,681.24607

Timestep Collection Time: 2.21568
Timestep Consumption Time: 2.46636
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.68204

Cumulative Model Updates: 188,918
Cumulative Timesteps: 1,575,417,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1575417090...
Checkpoint 1575417090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,335.61625
Policy Entropy: 3.71930
Value Function Loss: 0.02165

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13197
Policy Update Magnitude: 0.34249
Value Function Update Magnitude: 0.53504

Collected Steps per Second: 22,603.13937
Overall Steps per Second: 10,638.07764

Timestep Collection Time: 2.21208
Timestep Consumption Time: 2.48802
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.70010

Cumulative Model Updates: 188,924
Cumulative Timesteps: 1,575,467,090

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,335.61625
Policy Entropy: 3.71235
Value Function Loss: 0.01760

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13626
Policy Update Magnitude: 0.33446
Value Function Update Magnitude: 0.49246

Collected Steps per Second: 22,836.50866
Overall Steps per Second: 10,839.52564

Timestep Collection Time: 2.18965
Timestep Consumption Time: 2.42347
PPO Batch Consumption Time: 0.27708
Total Iteration Time: 4.61312

Cumulative Model Updates: 188,930
Cumulative Timesteps: 1,575,517,094

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1575517094...
Checkpoint 1575517094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,335.61625
Policy Entropy: 3.68911
Value Function Loss: 0.01708

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13595
Policy Update Magnitude: 0.29431
Value Function Update Magnitude: 0.44470

Collected Steps per Second: 22,627.60265
Overall Steps per Second: 10,728.51590

Timestep Collection Time: 2.21084
Timestep Consumption Time: 2.45206
PPO Batch Consumption Time: 0.28230
Total Iteration Time: 4.66290

Cumulative Model Updates: 188,936
Cumulative Timesteps: 1,575,567,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,335.61625
Policy Entropy: 3.69114
Value Function Loss: 0.01435

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14496
Policy Update Magnitude: 0.27522
Value Function Update Magnitude: 0.38374

Collected Steps per Second: 22,970.79697
Overall Steps per Second: 10,869.31625

Timestep Collection Time: 2.17737
Timestep Consumption Time: 2.42420
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.60158

Cumulative Model Updates: 188,942
Cumulative Timesteps: 1,575,617,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1575617136...
Checkpoint 1575617136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 125,921.95461
Policy Entropy: 3.69067
Value Function Loss: 0.01741

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.28808
Value Function Update Magnitude: 0.45222

Collected Steps per Second: 23,021.08813
Overall Steps per Second: 10,722.01543

Timestep Collection Time: 2.17253
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.66461

Cumulative Model Updates: 188,948
Cumulative Timesteps: 1,575,667,150

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,623.91648
Policy Entropy: 3.70566
Value Function Loss: 0.01736

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.31036
Value Function Update Magnitude: 0.57890

Collected Steps per Second: 22,398.69507
Overall Steps per Second: 10,867.75275

Timestep Collection Time: 2.23326
Timestep Consumption Time: 2.36954
PPO Batch Consumption Time: 0.28131
Total Iteration Time: 4.60279

Cumulative Model Updates: 188,954
Cumulative Timesteps: 1,575,717,172

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1575717172...
Checkpoint 1575717172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,623.91648
Policy Entropy: 3.69742
Value Function Loss: 0.01780

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13942
Policy Update Magnitude: 0.31257
Value Function Update Magnitude: 0.56459

Collected Steps per Second: 22,189.69662
Overall Steps per Second: 10,721.87116

Timestep Collection Time: 2.25402
Timestep Consumption Time: 2.41084
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.66486

Cumulative Model Updates: 188,960
Cumulative Timesteps: 1,575,767,188

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,623.91648
Policy Entropy: 3.68809
Value Function Loss: 0.01524

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13800
Policy Update Magnitude: 0.30959
Value Function Update Magnitude: 0.45015

Collected Steps per Second: 22,565.93764
Overall Steps per Second: 10,831.05390

Timestep Collection Time: 2.21697
Timestep Consumption Time: 2.40197
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.61894

Cumulative Model Updates: 188,966
Cumulative Timesteps: 1,575,817,216

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1575817216...
Checkpoint 1575817216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,569.09905
Policy Entropy: 3.67700
Value Function Loss: 0.01614

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.29788
Value Function Update Magnitude: 0.43692

Collected Steps per Second: 22,213.55893
Overall Steps per Second: 10,595.14430

Timestep Collection Time: 2.25088
Timestep Consumption Time: 2.46827
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.71914

Cumulative Model Updates: 188,972
Cumulative Timesteps: 1,575,867,216

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,929.76660
Policy Entropy: 3.67813
Value Function Loss: 0.01636

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12846
Policy Update Magnitude: 0.30824
Value Function Update Magnitude: 0.50281

Collected Steps per Second: 22,720.95830
Overall Steps per Second: 10,872.82385

Timestep Collection Time: 2.20167
Timestep Consumption Time: 2.39916
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.60083

Cumulative Model Updates: 188,978
Cumulative Timesteps: 1,575,917,240

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1575917240...
Checkpoint 1575917240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,929.76660
Policy Entropy: 3.66183
Value Function Loss: 0.01861

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13593
Policy Update Magnitude: 0.31626
Value Function Update Magnitude: 0.57671

Collected Steps per Second: 22,473.79723
Overall Steps per Second: 10,685.76674

Timestep Collection Time: 2.22561
Timestep Consumption Time: 2.45519
PPO Batch Consumption Time: 0.28313
Total Iteration Time: 4.68081

Cumulative Model Updates: 188,984
Cumulative Timesteps: 1,575,967,258

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,929.76660
Policy Entropy: 3.67095
Value Function Loss: 0.01698

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.32679
Value Function Update Magnitude: 0.59628

Collected Steps per Second: 23,108.71772
Overall Steps per Second: 10,885.17822

Timestep Collection Time: 2.16403
Timestep Consumption Time: 2.43011
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.59414

Cumulative Model Updates: 188,990
Cumulative Timesteps: 1,576,017,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1576017266...
Checkpoint 1576017266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,929.76660
Policy Entropy: 3.65000
Value Function Loss: 0.01756

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.34975
Value Function Update Magnitude: 0.58603

Collected Steps per Second: 22,806.82044
Overall Steps per Second: 10,646.79401

Timestep Collection Time: 2.19408
Timestep Consumption Time: 2.50593
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.70001

Cumulative Model Updates: 188,996
Cumulative Timesteps: 1,576,067,306

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,929.76660
Policy Entropy: 3.66513
Value Function Loss: 0.01544

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.35900
Value Function Update Magnitude: 0.54932

Collected Steps per Second: 22,501.75154
Overall Steps per Second: 10,624.38483

Timestep Collection Time: 2.22276
Timestep Consumption Time: 2.48490
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.70766

Cumulative Model Updates: 189,002
Cumulative Timesteps: 1,576,117,322

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1576117322...
Checkpoint 1576117322 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,929.76660
Policy Entropy: 3.65443
Value Function Loss: 0.01604

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12881
Policy Update Magnitude: 0.35052
Value Function Update Magnitude: 0.48850

Collected Steps per Second: 22,544.06303
Overall Steps per Second: 10,658.88559

Timestep Collection Time: 2.21832
Timestep Consumption Time: 2.47354
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.69186

Cumulative Model Updates: 189,008
Cumulative Timesteps: 1,576,167,332

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,929.76660
Policy Entropy: 3.66409
Value Function Loss: 0.01580

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.36803
Value Function Update Magnitude: 0.48600

Collected Steps per Second: 22,848.01482
Overall Steps per Second: 10,782.89776

Timestep Collection Time: 2.19030
Timestep Consumption Time: 2.45075
PPO Batch Consumption Time: 0.28464
Total Iteration Time: 4.64105

Cumulative Model Updates: 189,014
Cumulative Timesteps: 1,576,217,376

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1576217376...
Checkpoint 1576217376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,929.76660
Policy Entropy: 3.65520
Value Function Loss: 0.01624

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.37798
Value Function Update Magnitude: 0.53680

Collected Steps per Second: 22,019.64536
Overall Steps per Second: 10,674.86996

Timestep Collection Time: 2.27134
Timestep Consumption Time: 2.41387
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.68521

Cumulative Model Updates: 189,020
Cumulative Timesteps: 1,576,267,390

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,101.58413
Policy Entropy: 3.66828
Value Function Loss: 0.01759

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.37114
Value Function Update Magnitude: 0.54195

Collected Steps per Second: 22,258.24604
Overall Steps per Second: 10,925.70316

Timestep Collection Time: 2.24654
Timestep Consumption Time: 2.33019
PPO Batch Consumption Time: 0.27554
Total Iteration Time: 4.57673

Cumulative Model Updates: 189,026
Cumulative Timesteps: 1,576,317,394

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1576317394...
Checkpoint 1576317394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183,011.91370
Policy Entropy: 3.65518
Value Function Loss: 0.02424

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12766
Policy Update Magnitude: 0.38403
Value Function Update Magnitude: 0.55988

Collected Steps per Second: 22,104.76463
Overall Steps per Second: 10,580.57253

Timestep Collection Time: 2.26268
Timestep Consumption Time: 2.46447
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.72715

Cumulative Model Updates: 189,032
Cumulative Timesteps: 1,576,367,410

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,159.20417
Policy Entropy: 3.66035
Value Function Loss: 0.02482

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.44365
Value Function Update Magnitude: 0.66978

Collected Steps per Second: 22,663.93002
Overall Steps per Second: 10,835.17991

Timestep Collection Time: 2.20747
Timestep Consumption Time: 2.40989
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.61737

Cumulative Model Updates: 189,038
Cumulative Timesteps: 1,576,417,440

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1576417440...
Checkpoint 1576417440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,159.20417
Policy Entropy: 3.64739
Value Function Loss: 0.02505

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13493
Policy Update Magnitude: 0.43255
Value Function Update Magnitude: 0.59552

Collected Steps per Second: 22,920.24886
Overall Steps per Second: 10,746.83752

Timestep Collection Time: 2.18209
Timestep Consumption Time: 2.47175
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.65383

Cumulative Model Updates: 189,044
Cumulative Timesteps: 1,576,467,454

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,159.20417
Policy Entropy: 3.65529
Value Function Loss: 0.02326

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.39025
Value Function Update Magnitude: 0.46568

Collected Steps per Second: 22,834.08190
Overall Steps per Second: 10,823.92924

Timestep Collection Time: 2.18997
Timestep Consumption Time: 2.42998
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.61995

Cumulative Model Updates: 189,050
Cumulative Timesteps: 1,576,517,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1576517460...
Checkpoint 1576517460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,159.20417
Policy Entropy: 3.64292
Value Function Loss: 0.02455

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.39969
Value Function Update Magnitude: 0.43869

Collected Steps per Second: 22,635.08611
Overall Steps per Second: 10,678.31469

Timestep Collection Time: 2.20940
Timestep Consumption Time: 2.47392
PPO Batch Consumption Time: 0.28855
Total Iteration Time: 4.68332

Cumulative Model Updates: 189,056
Cumulative Timesteps: 1,576,567,470

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,159.20417
Policy Entropy: 3.64218
Value Function Loss: 0.02156

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.42957
Value Function Update Magnitude: 0.50397

Collected Steps per Second: 22,778.94470
Overall Steps per Second: 10,817.08211

Timestep Collection Time: 2.19519
Timestep Consumption Time: 2.42750
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.62269

Cumulative Model Updates: 189,062
Cumulative Timesteps: 1,576,617,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1576617474...
Checkpoint 1576617474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,159.20417
Policy Entropy: 3.65007
Value Function Loss: 0.02078

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.40649
Value Function Update Magnitude: 0.49660

Collected Steps per Second: 22,935.52218
Overall Steps per Second: 10,712.97638

Timestep Collection Time: 2.18107
Timestep Consumption Time: 2.48841
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.66948

Cumulative Model Updates: 189,068
Cumulative Timesteps: 1,576,667,498

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,159.20417
Policy Entropy: 3.65534
Value Function Loss: 0.01827

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.40296
Value Function Update Magnitude: 0.44847

Collected Steps per Second: 22,828.45800
Overall Steps per Second: 10,862.42257

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.41297
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.60339

Cumulative Model Updates: 189,074
Cumulative Timesteps: 1,576,717,502

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1576717502...
Checkpoint 1576717502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,159.20417
Policy Entropy: 3.64809
Value Function Loss: 0.02113

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13541
Policy Update Magnitude: 0.40008
Value Function Update Magnitude: 0.46284

Collected Steps per Second: 22,495.00358
Overall Steps per Second: 10,669.78713

Timestep Collection Time: 2.22369
Timestep Consumption Time: 2.46450
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.68819

Cumulative Model Updates: 189,080
Cumulative Timesteps: 1,576,767,524

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 120,159.20417
Policy Entropy: 3.65085
Value Function Loss: 0.02284

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12600
Policy Update Magnitude: 0.44825
Value Function Update Magnitude: 0.45497

Collected Steps per Second: 22,380.78634
Overall Steps per Second: 10,919.28302

Timestep Collection Time: 2.23531
Timestep Consumption Time: 2.34631
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.58162

Cumulative Model Updates: 189,086
Cumulative Timesteps: 1,576,817,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1576817552...
Checkpoint 1576817552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220,841.97376
Policy Entropy: 3.65970
Value Function Loss: 0.02479

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.45734
Value Function Update Magnitude: 0.45303

Collected Steps per Second: 22,193.74875
Overall Steps per Second: 10,721.63728

Timestep Collection Time: 2.25325
Timestep Consumption Time: 2.41097
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.66421

Cumulative Model Updates: 189,092
Cumulative Timesteps: 1,576,867,560

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.67022
Value Function Loss: 0.02464

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.44674
Value Function Update Magnitude: 0.49239

Collected Steps per Second: 22,550.96969
Overall Steps per Second: 10,821.22489

Timestep Collection Time: 2.21835
Timestep Consumption Time: 2.40460
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.62295

Cumulative Model Updates: 189,098
Cumulative Timesteps: 1,576,917,586

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1576917586...
Checkpoint 1576917586 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.67083
Value Function Loss: 0.02519

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12723
Policy Update Magnitude: 0.44794
Value Function Update Magnitude: 0.57091

Collected Steps per Second: 22,606.95800
Overall Steps per Second: 10,699.82050

Timestep Collection Time: 2.21268
Timestep Consumption Time: 2.46235
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.67503

Cumulative Model Updates: 189,104
Cumulative Timesteps: 1,576,967,608

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.67387
Value Function Loss: 0.02296

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.45935
Value Function Update Magnitude: 0.60939

Collected Steps per Second: 23,000.33838
Overall Steps per Second: 10,840.45600

Timestep Collection Time: 2.17536
Timestep Consumption Time: 2.44013
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.61549

Cumulative Model Updates: 189,110
Cumulative Timesteps: 1,577,017,642

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1577017642...
Checkpoint 1577017642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.68201
Value Function Loss: 0.01972

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12474
Policy Update Magnitude: 0.45729
Value Function Update Magnitude: 0.57696

Collected Steps per Second: 22,684.97474
Overall Steps per Second: 10,650.01122

Timestep Collection Time: 2.20454
Timestep Consumption Time: 2.49123
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.69577

Cumulative Model Updates: 189,116
Cumulative Timesteps: 1,577,067,652

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.70018
Value Function Loss: 0.01595

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12946
Policy Update Magnitude: 0.40955
Value Function Update Magnitude: 0.50036

Collected Steps per Second: 22,940.39428
Overall Steps per Second: 10,853.33883

Timestep Collection Time: 2.18052
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.27850
Total Iteration Time: 4.60890

Cumulative Model Updates: 189,122
Cumulative Timesteps: 1,577,117,674

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1577117674...
Checkpoint 1577117674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.69166
Value Function Loss: 0.01550

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12500
Policy Update Magnitude: 0.37918
Value Function Update Magnitude: 0.44402

Collected Steps per Second: 22,983.88495
Overall Steps per Second: 10,721.71966

Timestep Collection Time: 2.17657
Timestep Consumption Time: 2.48929
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.66586

Cumulative Model Updates: 189,128
Cumulative Timesteps: 1,577,167,700

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.69076
Value Function Loss: 0.01494

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.36918
Value Function Update Magnitude: 0.43559

Collected Steps per Second: 22,740.70980
Overall Steps per Second: 10,636.66038

Timestep Collection Time: 2.19914
Timestep Consumption Time: 2.50252
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.70166

Cumulative Model Updates: 189,134
Cumulative Timesteps: 1,577,217,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1577217710...
Checkpoint 1577217710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.67547
Value Function Loss: 0.01566

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.13088
Policy Update Magnitude: 0.37436
Value Function Update Magnitude: 0.40957

Collected Steps per Second: 22,845.06099
Overall Steps per Second: 10,815.13928

Timestep Collection Time: 2.18944
Timestep Consumption Time: 2.43537
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.62481

Cumulative Model Updates: 189,140
Cumulative Timesteps: 1,577,267,728

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.69559
Value Function Loss: 0.01458

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.33864
Value Function Update Magnitude: 0.35350

Collected Steps per Second: 22,926.60348
Overall Steps per Second: 10,747.94108

Timestep Collection Time: 2.18227
Timestep Consumption Time: 2.47276
PPO Batch Consumption Time: 0.28820
Total Iteration Time: 4.65503

Cumulative Model Updates: 189,146
Cumulative Timesteps: 1,577,317,760

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1577317760...
Checkpoint 1577317760 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.68285
Value Function Loss: 0.01585

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13241
Policy Update Magnitude: 0.30854
Value Function Update Magnitude: 0.31141

Collected Steps per Second: 22,677.92698
Overall Steps per Second: 10,857.95721

Timestep Collection Time: 2.20646
Timestep Consumption Time: 2.40195
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.60842

Cumulative Model Updates: 189,152
Cumulative Timesteps: 1,577,367,798

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,746.61120
Policy Entropy: 3.69003
Value Function Loss: 0.01506

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.11721
Policy Update Magnitude: 0.33259
Value Function Update Magnitude: 0.32936

Collected Steps per Second: 22,991.08913
Overall Steps per Second: 10,904.54227

Timestep Collection Time: 2.17571
Timestep Consumption Time: 2.41155
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.58726

Cumulative Model Updates: 189,158
Cumulative Timesteps: 1,577,417,820

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1577417820...
Checkpoint 1577417820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 368,744.81703
Policy Entropy: 3.67735
Value Function Loss: 0.01986

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15158
Policy Update Magnitude: 0.33070
Value Function Update Magnitude: 0.32073

Collected Steps per Second: 22,380.31155
Overall Steps per Second: 10,755.69591

Timestep Collection Time: 2.23491
Timestep Consumption Time: 2.41546
PPO Batch Consumption Time: 0.27522
Total Iteration Time: 4.65037

Cumulative Model Updates: 189,164
Cumulative Timesteps: 1,577,467,838

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 368,744.81703
Policy Entropy: 3.68925
Value Function Loss: 0.02043

Mean KL Divergence: 0.02239
SB3 Clip Fraction: 0.25441
Policy Update Magnitude: 0.36163
Value Function Update Magnitude: 0.35256

Collected Steps per Second: 23,374.90081
Overall Steps per Second: 10,864.26944

Timestep Collection Time: 2.14042
Timestep Consumption Time: 2.46477
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.60519

Cumulative Model Updates: 189,170
Cumulative Timesteps: 1,577,517,870

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1577517870...
Checkpoint 1577517870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 480,465.99196
Policy Entropy: 3.64175
Value Function Loss: 0.03920

Mean KL Divergence: 0.01576
SB3 Clip Fraction: 0.19486
Policy Update Magnitude: 0.42055
Value Function Update Magnitude: 0.49662

Collected Steps per Second: 21,915.51695
Overall Steps per Second: 10,645.59149

Timestep Collection Time: 2.28240
Timestep Consumption Time: 2.41626
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.69866

Cumulative Model Updates: 189,176
Cumulative Timesteps: 1,577,567,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 631,908.00099
Policy Entropy: 3.60258
Value Function Loss: 0.06332

Mean KL Divergence: 0.02070
SB3 Clip Fraction: 0.22764
Policy Update Magnitude: 0.49897
Value Function Update Magnitude: 0.58242

Collected Steps per Second: 22,166.19755
Overall Steps per Second: 10,870.12182

Timestep Collection Time: 2.25623
Timestep Consumption Time: 2.34464
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.60087

Cumulative Model Updates: 189,182
Cumulative Timesteps: 1,577,617,902

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1577617902...
Checkpoint 1577617902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 508,186.21963
Policy Entropy: 3.55724
Value Function Loss: 0.07419

Mean KL Divergence: 0.02450
SB3 Clip Fraction: 0.23729
Policy Update Magnitude: 0.54528
Value Function Update Magnitude: 0.61615

Collected Steps per Second: 21,949.60606
Overall Steps per Second: 10,683.16729

Timestep Collection Time: 2.27840
Timestep Consumption Time: 2.40280
PPO Batch Consumption Time: 0.28895
Total Iteration Time: 4.68120

Cumulative Model Updates: 189,188
Cumulative Timesteps: 1,577,667,912

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 508,186.21963
Policy Entropy: 3.58382
Value Function Loss: 0.06548

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.23040
Policy Update Magnitude: 0.59563
Value Function Update Magnitude: 0.60370

Collected Steps per Second: 22,072.73905
Overall Steps per Second: 10,595.89862

Timestep Collection Time: 2.26551
Timestep Consumption Time: 2.45386
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.71937

Cumulative Model Updates: 189,194
Cumulative Timesteps: 1,577,717,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1577717918...
Checkpoint 1577717918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337,131.62817
Policy Entropy: 3.59477
Value Function Loss: 0.05982

Mean KL Divergence: 0.01948
SB3 Clip Fraction: 0.21885
Policy Update Magnitude: 0.51068
Value Function Update Magnitude: 0.48951

Collected Steps per Second: 22,953.69309
Overall Steps per Second: 10,969.52679

Timestep Collection Time: 2.17882
Timestep Consumption Time: 2.38035
PPO Batch Consumption Time: 0.27673
Total Iteration Time: 4.55918

Cumulative Model Updates: 189,200
Cumulative Timesteps: 1,577,767,930

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,841.77688
Policy Entropy: 3.59149
Value Function Loss: 0.06175

Mean KL Divergence: 0.01748
SB3 Clip Fraction: 0.20913
Policy Update Magnitude: 0.44545
Value Function Update Magnitude: 0.44836

Collected Steps per Second: 22,980.53021
Overall Steps per Second: 10,894.81941

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.41503
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.59209

Cumulative Model Updates: 189,206
Cumulative Timesteps: 1,577,817,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1577817960...
Checkpoint 1577817960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,651.39986
Policy Entropy: 3.61316
Value Function Loss: 0.07041

Mean KL Divergence: 0.01623
SB3 Clip Fraction: 0.19071
Policy Update Magnitude: 0.45367
Value Function Update Magnitude: 0.46258

Collected Steps per Second: 22,303.67112
Overall Steps per Second: 10,624.29097

Timestep Collection Time: 2.24214
Timestep Consumption Time: 2.46481
PPO Batch Consumption Time: 0.28413
Total Iteration Time: 4.70695

Cumulative Model Updates: 189,212
Cumulative Timesteps: 1,577,867,968

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 255,669.44342
Policy Entropy: 3.62528
Value Function Loss: 0.07549

Mean KL Divergence: 0.01549
SB3 Clip Fraction: 0.17988
Policy Update Magnitude: 0.48768
Value Function Update Magnitude: 0.49533

Collected Steps per Second: 22,681.91331
Overall Steps per Second: 10,646.16240

Timestep Collection Time: 2.20466
Timestep Consumption Time: 2.49243
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.69709

Cumulative Model Updates: 189,218
Cumulative Timesteps: 1,577,917,974

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1577917974...
Checkpoint 1577917974 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 222,152.94999
Policy Entropy: 3.63276
Value Function Loss: 0.07451

Mean KL Divergence: 0.01722
SB3 Clip Fraction: 0.18741
Policy Update Magnitude: 0.50018
Value Function Update Magnitude: 0.44323

Collected Steps per Second: 22,704.03371
Overall Steps per Second: 10,845.09588

Timestep Collection Time: 2.20349
Timestep Consumption Time: 2.40948
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.61296

Cumulative Model Updates: 189,224
Cumulative Timesteps: 1,577,968,002

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,585.39271
Policy Entropy: 3.64867
Value Function Loss: 0.06492

Mean KL Divergence: 0.01678
SB3 Clip Fraction: 0.20123
Policy Update Magnitude: 0.46788
Value Function Update Magnitude: 0.43517

Collected Steps per Second: 23,083.02150
Overall Steps per Second: 10,886.11544

Timestep Collection Time: 2.16739
Timestep Consumption Time: 2.42837
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.59576

Cumulative Model Updates: 189,230
Cumulative Timesteps: 1,578,018,032

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1578018032...
Checkpoint 1578018032 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,135.09009
Policy Entropy: 3.67466
Value Function Loss: 0.05881

Mean KL Divergence: 0.01706
SB3 Clip Fraction: 0.19233
Policy Update Magnitude: 0.42132
Value Function Update Magnitude: 0.44164

Collected Steps per Second: 22,688.41778
Overall Steps per Second: 10,725.92480

Timestep Collection Time: 2.20377
Timestep Consumption Time: 2.45784
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.66160

Cumulative Model Updates: 189,236
Cumulative Timesteps: 1,578,068,032

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,188.39746
Policy Entropy: 3.69771
Value Function Loss: 0.05507

Mean KL Divergence: 0.01561
SB3 Clip Fraction: 0.19159
Policy Update Magnitude: 0.42004
Value Function Update Magnitude: 0.52538

Collected Steps per Second: 22,774.08404
Overall Steps per Second: 10,854.42788

Timestep Collection Time: 2.19741
Timestep Consumption Time: 2.41306
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.61047

Cumulative Model Updates: 189,242
Cumulative Timesteps: 1,578,118,076

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1578118076...
Checkpoint 1578118076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,856.04585
Policy Entropy: 3.69860
Value Function Loss: 0.05377

Mean KL Divergence: 0.01641
SB3 Clip Fraction: 0.19903
Policy Update Magnitude: 0.45240
Value Function Update Magnitude: 0.54174

Collected Steps per Second: 22,753.53422
Overall Steps per Second: 10,712.85543

Timestep Collection Time: 2.19869
Timestep Consumption Time: 2.47121
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.66990

Cumulative Model Updates: 189,248
Cumulative Timesteps: 1,578,168,104

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 250,812.31829
Policy Entropy: 3.67149
Value Function Loss: 0.05743

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.19086
Policy Update Magnitude: 0.48543
Value Function Update Magnitude: 0.52974

Collected Steps per Second: 22,367.52280
Overall Steps per Second: 10,881.70019

Timestep Collection Time: 2.23547
Timestep Consumption Time: 2.35958
PPO Batch Consumption Time: 0.27885
Total Iteration Time: 4.59505

Cumulative Model Updates: 189,254
Cumulative Timesteps: 1,578,218,106

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1578218106...
Checkpoint 1578218106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,479.98133
Policy Entropy: 3.65866
Value Function Loss: 0.06186

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.18965
Policy Update Magnitude: 0.45795
Value Function Update Magnitude: 0.48606

Collected Steps per Second: 21,925.26229
Overall Steps per Second: 10,624.22494

Timestep Collection Time: 2.28130
Timestep Consumption Time: 2.42662
PPO Batch Consumption Time: 0.29021
Total Iteration Time: 4.70792

Cumulative Model Updates: 189,260
Cumulative Timesteps: 1,578,268,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,537.82402
Policy Entropy: 3.67159
Value Function Loss: 0.06695

Mean KL Divergence: 0.01580
SB3 Clip Fraction: 0.18857
Policy Update Magnitude: 0.46626
Value Function Update Magnitude: 0.44507

Collected Steps per Second: 22,340.82442
Overall Steps per Second: 10,914.06351

Timestep Collection Time: 2.23895
Timestep Consumption Time: 2.34413
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.58308

Cumulative Model Updates: 189,266
Cumulative Timesteps: 1,578,318,144

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1578318144...
Checkpoint 1578318144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 173,033.07588
Policy Entropy: 3.68872
Value Function Loss: 0.06602

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.18010
Policy Update Magnitude: 0.53113
Value Function Update Magnitude: 0.45083

Collected Steps per Second: 22,017.16480
Overall Steps per Second: 10,698.83405

Timestep Collection Time: 2.27159
Timestep Consumption Time: 2.40312
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.67472

Cumulative Model Updates: 189,272
Cumulative Timesteps: 1,578,368,158

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,489.54612
Policy Entropy: 3.71008
Value Function Loss: 0.05657

Mean KL Divergence: 0.01915
SB3 Clip Fraction: 0.21950
Policy Update Magnitude: 0.66032
Value Function Update Magnitude: 0.43174

Collected Steps per Second: 22,568.46295
Overall Steps per Second: 10,804.39106

Timestep Collection Time: 2.21566
Timestep Consumption Time: 2.41246
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.62812

Cumulative Model Updates: 189,278
Cumulative Timesteps: 1,578,418,162

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1578418162...
Checkpoint 1578418162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,317.07658
Policy Entropy: 3.71122
Value Function Loss: 0.06286

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.18484
Policy Update Magnitude: 0.58558
Value Function Update Magnitude: 0.45980

Collected Steps per Second: 22,616.99696
Overall Steps per Second: 10,729.31421

Timestep Collection Time: 2.21090
Timestep Consumption Time: 2.44960
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.66050

Cumulative Model Updates: 189,284
Cumulative Timesteps: 1,578,468,166

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,317.07658
Policy Entropy: 3.73086
Value Function Loss: 0.04567

Mean KL Divergence: 0.01378
SB3 Clip Fraction: 0.16106
Policy Update Magnitude: 0.62984
Value Function Update Magnitude: 0.34885

Collected Steps per Second: 22,881.94927
Overall Steps per Second: 10,896.02004

Timestep Collection Time: 2.18644
Timestep Consumption Time: 2.40515
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.59158

Cumulative Model Updates: 189,290
Cumulative Timesteps: 1,578,518,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1578518196...
Checkpoint 1578518196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,317.07658
Policy Entropy: 3.74349
Value Function Loss: 0.03484

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.15491
Policy Update Magnitude: 0.63625
Value Function Update Magnitude: 0.38133

Collected Steps per Second: 22,600.20766
Overall Steps per Second: 10,673.55920

Timestep Collection Time: 2.21325
Timestep Consumption Time: 2.47309
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.68635

Cumulative Model Updates: 189,296
Cumulative Timesteps: 1,578,568,216

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,317.07658
Policy Entropy: 3.76157
Value Function Loss: 0.02025

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12172
Policy Update Magnitude: 0.54545
Value Function Update Magnitude: 0.41715

Collected Steps per Second: 23,333.65030
Overall Steps per Second: 10,891.03141

Timestep Collection Time: 2.14326
Timestep Consumption Time: 2.44860
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.59185

Cumulative Model Updates: 189,302
Cumulative Timesteps: 1,578,618,226

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1578618226...
Checkpoint 1578618226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,317.07658
Policy Entropy: 3.74194
Value Function Loss: 0.01819

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10337
Policy Update Magnitude: 0.48285
Value Function Update Magnitude: 0.39961

Collected Steps per Second: 22,649.37686
Overall Steps per Second: 10,616.98820

Timestep Collection Time: 2.20916
Timestep Consumption Time: 2.50367
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.71282

Cumulative Model Updates: 189,308
Cumulative Timesteps: 1,578,668,262

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,317.07658
Policy Entropy: 3.70809
Value Function Loss: 0.02157

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12555
Policy Update Magnitude: 0.51316
Value Function Update Magnitude: 0.46370

Collected Steps per Second: 22,989.62659
Overall Steps per Second: 10,887.23382

Timestep Collection Time: 2.17611
Timestep Consumption Time: 2.41899
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.59511

Cumulative Model Updates: 189,314
Cumulative Timesteps: 1,578,718,290

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1578718290...
Checkpoint 1578718290 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 268,722.62251
Policy Entropy: 3.70616
Value Function Loss: 0.02679

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.17231
Policy Update Magnitude: 0.45771
Value Function Update Magnitude: 0.65280

Collected Steps per Second: 22,599.42159
Overall Steps per Second: 10,710.59705

Timestep Collection Time: 2.21262
Timestep Consumption Time: 2.45602
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.66865

Cumulative Model Updates: 189,320
Cumulative Timesteps: 1,578,768,294

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,322.13348
Policy Entropy: 3.73312
Value Function Loss: 0.02570

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15160
Policy Update Magnitude: 0.42621
Value Function Update Magnitude: 0.60864

Collected Steps per Second: 22,910.78422
Overall Steps per Second: 10,820.44774

Timestep Collection Time: 2.18369
Timestep Consumption Time: 2.43997
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.62365

Cumulative Model Updates: 189,326
Cumulative Timesteps: 1,578,818,324

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1578818324...
Checkpoint 1578818324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,322.13348
Policy Entropy: 3.74625
Value Function Loss: 0.02315

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.14987
Policy Update Magnitude: 0.39045
Value Function Update Magnitude: 0.47512

Collected Steps per Second: 22,734.02823
Overall Steps per Second: 10,697.52344

Timestep Collection Time: 2.20023
Timestep Consumption Time: 2.47562
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.67585

Cumulative Model Updates: 189,332
Cumulative Timesteps: 1,578,868,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,322.13348
Policy Entropy: 3.74102
Value Function Loss: 0.01747

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.37467
Value Function Update Magnitude: 0.40299

Collected Steps per Second: 23,019.28160
Overall Steps per Second: 10,859.59020

Timestep Collection Time: 2.17322
Timestep Consumption Time: 2.43340
PPO Batch Consumption Time: 0.27712
Total Iteration Time: 4.60662

Cumulative Model Updates: 189,338
Cumulative Timesteps: 1,578,918,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1578918370...
Checkpoint 1578918370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,322.13348
Policy Entropy: 3.73693
Value Function Loss: 0.01781

Mean KL Divergence: 0.00493
SB3 Clip Fraction: 0.05762
Policy Update Magnitude: 0.43424
Value Function Update Magnitude: 0.36711

Collected Steps per Second: 22,451.44504
Overall Steps per Second: 10,792.95746

Timestep Collection Time: 2.22819
Timestep Consumption Time: 2.40687
PPO Batch Consumption Time: 0.27589
Total Iteration Time: 4.63506

Cumulative Model Updates: 189,344
Cumulative Timesteps: 1,578,968,396

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,322.13348
Policy Entropy: 3.74226
Value Function Loss: 0.01572

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05059
Policy Update Magnitude: 0.49299
Value Function Update Magnitude: 0.36525

Collected Steps per Second: 22,995.73711
Overall Steps per Second: 10,895.19302

Timestep Collection Time: 2.17571
Timestep Consumption Time: 2.41641
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.59212

Cumulative Model Updates: 189,350
Cumulative Timesteps: 1,579,018,428

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1579018428...
Checkpoint 1579018428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,322.13348
Policy Entropy: 3.73093
Value Function Loss: 0.01594

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.07029
Policy Update Magnitude: 0.48404
Value Function Update Magnitude: 0.38863

Collected Steps per Second: 22,633.16128
Overall Steps per Second: 10,625.26465

Timestep Collection Time: 2.20932
Timestep Consumption Time: 2.49682
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.70614

Cumulative Model Updates: 189,356
Cumulative Timesteps: 1,579,068,432

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,322.13348
Policy Entropy: 3.72814
Value Function Loss: 0.01602

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12438
Policy Update Magnitude: 0.41214
Value Function Update Magnitude: 0.32705

Collected Steps per Second: 22,969.86459
Overall Steps per Second: 10,910.06496

Timestep Collection Time: 2.17711
Timestep Consumption Time: 2.40654
PPO Batch Consumption Time: 0.27564
Total Iteration Time: 4.58366

Cumulative Model Updates: 189,362
Cumulative Timesteps: 1,579,118,440

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1579118440...
Checkpoint 1579118440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,322.13348
Policy Entropy: 3.73884
Value Function Loss: 0.01702

Mean KL Divergence: 0.01343
SB3 Clip Fraction: 0.16550
Policy Update Magnitude: 0.35942
Value Function Update Magnitude: 0.26205

Collected Steps per Second: 22,601.09994
Overall Steps per Second: 10,654.14971

Timestep Collection Time: 2.21237
Timestep Consumption Time: 2.48082
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.69319

Cumulative Model Updates: 189,368
Cumulative Timesteps: 1,579,168,442

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,322.13348
Policy Entropy: 3.72703
Value Function Loss: 0.01491

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.15455
Policy Update Magnitude: 0.31031
Value Function Update Magnitude: 0.19320

Collected Steps per Second: 22,417.92501
Overall Steps per Second: 10,842.43443

Timestep Collection Time: 2.23054
Timestep Consumption Time: 2.38134
PPO Batch Consumption Time: 0.28252
Total Iteration Time: 4.61188

Cumulative Model Updates: 189,374
Cumulative Timesteps: 1,579,218,446

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1579218446...
Checkpoint 1579218446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 240,498.42447
Policy Entropy: 3.73858
Value Function Loss: 0.01346

Mean KL Divergence: 0.00695
SB3 Clip Fraction: 0.08929
Policy Update Magnitude: 0.31235
Value Function Update Magnitude: 0.29107

Collected Steps per Second: 21,919.77913
Overall Steps per Second: 10,625.09638

Timestep Collection Time: 2.28196
Timestep Consumption Time: 2.42576
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.70772

Cumulative Model Updates: 189,380
Cumulative Timesteps: 1,579,268,466

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,533.86025
Policy Entropy: 3.72295
Value Function Loss: 0.01404

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07240
Policy Update Magnitude: 0.35526
Value Function Update Magnitude: 0.43999

Collected Steps per Second: 22,327.24366
Overall Steps per Second: 10,913.86984

Timestep Collection Time: 2.24094
Timestep Consumption Time: 2.34350
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.58444

Cumulative Model Updates: 189,386
Cumulative Timesteps: 1,579,318,500

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1579318500...
Checkpoint 1579318500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,533.86025
Policy Entropy: 3.71870
Value Function Loss: 0.01275

Mean KL Divergence: 0.00476
SB3 Clip Fraction: 0.05383
Policy Update Magnitude: 0.38417
Value Function Update Magnitude: 0.47807

Collected Steps per Second: 21,654.99822
Overall Steps per Second: 10,620.50189

Timestep Collection Time: 2.30931
Timestep Consumption Time: 2.39932
PPO Batch Consumption Time: 0.27689
Total Iteration Time: 4.70863

Cumulative Model Updates: 189,392
Cumulative Timesteps: 1,579,368,508

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,533.86025
Policy Entropy: 3.70707
Value Function Loss: 0.01235

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05864
Policy Update Magnitude: 0.38635
Value Function Update Magnitude: 0.45319

Collected Steps per Second: 22,753.59224
Overall Steps per Second: 10,894.62301

Timestep Collection Time: 2.19833
Timestep Consumption Time: 2.39292
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.59126

Cumulative Model Updates: 189,398
Cumulative Timesteps: 1,579,418,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1579418528...
Checkpoint 1579418528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,533.86025
Policy Entropy: 3.71335
Value Function Loss: 0.01192

Mean KL Divergence: 0.00487
SB3 Clip Fraction: 0.05618
Policy Update Magnitude: 0.38175
Value Function Update Magnitude: 0.47092

Collected Steps per Second: 22,649.92430
Overall Steps per Second: 10,693.13801

Timestep Collection Time: 2.20804
Timestep Consumption Time: 2.46898
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.67702

Cumulative Model Updates: 189,404
Cumulative Timesteps: 1,579,468,540

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,533.86025
Policy Entropy: 3.71461
Value Function Loss: 0.01536

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05798
Policy Update Magnitude: 0.41704
Value Function Update Magnitude: 0.54155

Collected Steps per Second: 23,019.70152
Overall Steps per Second: 10,861.53448

Timestep Collection Time: 2.17249
Timestep Consumption Time: 2.43183
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.60432

Cumulative Model Updates: 189,410
Cumulative Timesteps: 1,579,518,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1579518550...
Checkpoint 1579518550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,533.86025
Policy Entropy: 3.71455
Value Function Loss: 0.01628

Mean KL Divergence: 0.01149
SB3 Clip Fraction: 0.14441
Policy Update Magnitude: 0.46451
Value Function Update Magnitude: 0.56920

Collected Steps per Second: 22,389.64291
Overall Steps per Second: 10,776.17830

Timestep Collection Time: 2.23380
Timestep Consumption Time: 2.40736
PPO Batch Consumption Time: 0.27575
Total Iteration Time: 4.64116

Cumulative Model Updates: 189,416
Cumulative Timesteps: 1,579,568,564

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178,747.26890
Policy Entropy: 3.70219
Value Function Loss: 0.02115

Mean KL Divergence: 0.02352
SB3 Clip Fraction: 0.25520
Policy Update Magnitude: 0.42044
Value Function Update Magnitude: 0.54472

Collected Steps per Second: 22,829.27191
Overall Steps per Second: 10,869.52647

Timestep Collection Time: 2.19026
Timestep Consumption Time: 2.40994
PPO Batch Consumption Time: 0.27643
Total Iteration Time: 4.60020

Cumulative Model Updates: 189,422
Cumulative Timesteps: 1,579,618,566

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1579618566...
Checkpoint 1579618566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 210,746.93362
Policy Entropy: 3.66942
Value Function Loss: 0.04143

Mean KL Divergence: 0.02423
SB3 Clip Fraction: 0.25422
Policy Update Magnitude: 0.43291
Value Function Update Magnitude: 0.46763

Collected Steps per Second: 21,900.99517
Overall Steps per Second: 10,581.95819

Timestep Collection Time: 2.28355
Timestep Consumption Time: 2.44261
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.72616

Cumulative Model Updates: 189,428
Cumulative Timesteps: 1,579,668,578

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,265.65328
Policy Entropy: 3.65281
Value Function Loss: 0.06152

Mean KL Divergence: 0.01966
SB3 Clip Fraction: 0.20952
Policy Update Magnitude: 0.52438
Value Function Update Magnitude: 0.49362

Collected Steps per Second: 22,502.79317
Overall Steps per Second: 10,630.96858

Timestep Collection Time: 2.22310
Timestep Consumption Time: 2.48258
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.70569

Cumulative Model Updates: 189,434
Cumulative Timesteps: 1,579,718,604

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1579718604...
Checkpoint 1579718604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,265.65328
Policy Entropy: 3.61974
Value Function Loss: 0.07779

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.18963
Policy Update Magnitude: 0.51876
Value Function Update Magnitude: 0.44418

Collected Steps per Second: 21,694.30953
Overall Steps per Second: 10,597.97692

Timestep Collection Time: 2.30613
Timestep Consumption Time: 2.41458
PPO Batch Consumption Time: 0.28974
Total Iteration Time: 4.72071

Cumulative Model Updates: 189,440
Cumulative Timesteps: 1,579,768,634

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,265.65328
Policy Entropy: 3.61413
Value Function Loss: 0.07249

Mean KL Divergence: 0.01819
SB3 Clip Fraction: 0.19008
Policy Update Magnitude: 0.50518
Value Function Update Magnitude: 0.37696

Collected Steps per Second: 21,983.13431
Overall Steps per Second: 10,847.16248

Timestep Collection Time: 2.27547
Timestep Consumption Time: 2.33606
PPO Batch Consumption Time: 0.27656
Total Iteration Time: 4.61153

Cumulative Model Updates: 189,446
Cumulative Timesteps: 1,579,818,656

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1579818656...
Checkpoint 1579818656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273,443.54502
Policy Entropy: 3.59904
Value Function Loss: 0.07194

Mean KL Divergence: 0.01855
SB3 Clip Fraction: 0.19937
Policy Update Magnitude: 0.52828
Value Function Update Magnitude: 0.40130

Collected Steps per Second: 21,339.49317
Overall Steps per Second: 10,533.13695

Timestep Collection Time: 2.34448
Timestep Consumption Time: 2.40529
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.74977

Cumulative Model Updates: 189,452
Cumulative Timesteps: 1,579,868,686

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274,819.66197
Policy Entropy: 3.62215
Value Function Loss: 0.06912

Mean KL Divergence: 0.01600
SB3 Clip Fraction: 0.18949
Policy Update Magnitude: 0.54182
Value Function Update Magnitude: 0.47744

Collected Steps per Second: 22,503.02910
Overall Steps per Second: 10,715.74734

Timestep Collection Time: 2.22228
Timestep Consumption Time: 2.44450
PPO Batch Consumption Time: 0.28753
Total Iteration Time: 4.66678

Cumulative Model Updates: 189,458
Cumulative Timesteps: 1,579,918,694

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1579918694...
Checkpoint 1579918694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,150.35375
Policy Entropy: 3.63590
Value Function Loss: 0.06172

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.17721
Policy Update Magnitude: 0.54854
Value Function Update Magnitude: 0.52728

Collected Steps per Second: 21,782.84905
Overall Steps per Second: 10,513.51233

Timestep Collection Time: 2.29685
Timestep Consumption Time: 2.46198
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.75883

Cumulative Model Updates: 189,464
Cumulative Timesteps: 1,579,968,726

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,495.94639
Policy Entropy: 3.62891
Value Function Loss: 0.06536

Mean KL Divergence: 0.01468
SB3 Clip Fraction: 0.16851
Policy Update Magnitude: 0.59812
Value Function Update Magnitude: 0.56056

Collected Steps per Second: 22,795.63996
Overall Steps per Second: 10,810.62545

Timestep Collection Time: 2.19340
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.28278
Total Iteration Time: 4.62508

Cumulative Model Updates: 189,470
Cumulative Timesteps: 1,580,018,726

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1580018726...
Checkpoint 1580018726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 83,038.56637
Policy Entropy: 3.61155
Value Function Loss: 0.06480

Mean KL Divergence: 0.01652
SB3 Clip Fraction: 0.18634
Policy Update Magnitude: 0.66414
Value Function Update Magnitude: 0.63633

Collected Steps per Second: 22,544.70481
Overall Steps per Second: 10,644.55707

Timestep Collection Time: 2.21790
Timestep Consumption Time: 2.47952
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.69742

Cumulative Model Updates: 189,476
Cumulative Timesteps: 1,580,068,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,749.03613
Policy Entropy: 3.61103
Value Function Loss: 0.06464

Mean KL Divergence: 0.01443
SB3 Clip Fraction: 0.17800
Policy Update Magnitude: 0.64299
Value Function Update Magnitude: 0.67295

Collected Steps per Second: 22,765.44807
Overall Steps per Second: 10,831.94875

Timestep Collection Time: 2.19728
Timestep Consumption Time: 2.42073
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.61801

Cumulative Model Updates: 189,482
Cumulative Timesteps: 1,580,118,750

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1580118750...
Checkpoint 1580118750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,865.78432
Policy Entropy: 3.61086
Value Function Loss: 0.06565

Mean KL Divergence: 0.01526
SB3 Clip Fraction: 0.18560
Policy Update Magnitude: 0.60181
Value Function Update Magnitude: 0.59488

Collected Steps per Second: 22,244.53721
Overall Steps per Second: 10,703.93534

Timestep Collection Time: 2.24891
Timestep Consumption Time: 2.42470
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.67361

Cumulative Model Updates: 189,488
Cumulative Timesteps: 1,580,168,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,971.04322
Policy Entropy: 3.62355
Value Function Loss: 0.06662

Mean KL Divergence: 0.01385
SB3 Clip Fraction: 0.17186
Policy Update Magnitude: 0.59488
Value Function Update Magnitude: 0.53658

Collected Steps per Second: 22,711.13556
Overall Steps per Second: 10,802.07981

Timestep Collection Time: 2.20200
Timestep Consumption Time: 2.42766
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.62966

Cumulative Model Updates: 189,494
Cumulative Timesteps: 1,580,218,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1580218786...
Checkpoint 1580218786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,122.13711
Policy Entropy: 3.61430
Value Function Loss: 0.06929

Mean KL Divergence: 0.01369
SB3 Clip Fraction: 0.16791
Policy Update Magnitude: 0.61879
Value Function Update Magnitude: 0.53217

Collected Steps per Second: 22,303.57606
Overall Steps per Second: 10,785.94381

Timestep Collection Time: 2.24233
Timestep Consumption Time: 2.39444
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.63678

Cumulative Model Updates: 189,500
Cumulative Timesteps: 1,580,268,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,472.41284
Policy Entropy: 3.63914
Value Function Loss: 0.07647

Mean KL Divergence: 0.01334
SB3 Clip Fraction: 0.16746
Policy Update Magnitude: 0.67201
Value Function Update Magnitude: 0.50268

Collected Steps per Second: 23,107.34134
Overall Steps per Second: 10,916.17147

Timestep Collection Time: 2.16416
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.58109

Cumulative Model Updates: 189,506
Cumulative Timesteps: 1,580,318,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1580318806...
Checkpoint 1580318806 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,582.93479
Policy Entropy: 3.65786
Value Function Loss: 0.06977

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.16260
Policy Update Magnitude: 0.76234
Value Function Update Magnitude: 0.76204

Collected Steps per Second: 22,750.35307
Overall Steps per Second: 10,764.31247

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.44731
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.64516

Cumulative Model Updates: 189,512
Cumulative Timesteps: 1,580,368,808

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,802.98423
Policy Entropy: 3.72630
Value Function Loss: 0.06701

Mean KL Divergence: 0.01383
SB3 Clip Fraction: 0.16538
Policy Update Magnitude: 0.83731
Value Function Update Magnitude: 0.80314

Collected Steps per Second: 22,916.98099
Overall Steps per Second: 10,702.19076

Timestep Collection Time: 2.18196
Timestep Consumption Time: 2.49035
PPO Batch Consumption Time: 0.29273
Total Iteration Time: 4.67231

Cumulative Model Updates: 189,518
Cumulative Timesteps: 1,580,418,812

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1580418812...
Checkpoint 1580418812 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,881.14076
Policy Entropy: 3.79146
Value Function Loss: 0.06261

Mean KL Divergence: 0.01582
SB3 Clip Fraction: 0.18039
Policy Update Magnitude: 0.97297
Value Function Update Magnitude: 0.68453

Collected Steps per Second: 22,384.44895
Overall Steps per Second: 10,663.41102

Timestep Collection Time: 2.23503
Timestep Consumption Time: 2.45671
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.69174

Cumulative Model Updates: 189,524
Cumulative Timesteps: 1,580,468,842

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,555.04861
Policy Entropy: 3.83578
Value Function Loss: 0.06236

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.11810
Policy Update Magnitude: 1.13861
Value Function Update Magnitude: 0.64277

Collected Steps per Second: 22,844.72050
Overall Steps per Second: 10,919.76005

Timestep Collection Time: 2.18886
Timestep Consumption Time: 2.39036
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.57922

Cumulative Model Updates: 189,530
Cumulative Timesteps: 1,580,518,846

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1580518846...
Checkpoint 1580518846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,237.56664
Policy Entropy: 3.83597
Value Function Loss: 0.05680

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 1.27331
Value Function Update Magnitude: 0.82342

Collected Steps per Second: 22,731.02141
Overall Steps per Second: 10,740.91134

Timestep Collection Time: 2.20017
Timestep Consumption Time: 2.45605
PPO Batch Consumption Time: 0.29108
Total Iteration Time: 4.65622

Cumulative Model Updates: 189,536
Cumulative Timesteps: 1,580,568,858

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,376.12684
Policy Entropy: 3.82359
Value Function Loss: 0.06010

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.10667
Policy Update Magnitude: 1.26855
Value Function Update Magnitude: 0.90713

Collected Steps per Second: 23,268.18601
Overall Steps per Second: 10,790.61851

Timestep Collection Time: 2.14963
Timestep Consumption Time: 2.48569
PPO Batch Consumption Time: 0.29159
Total Iteration Time: 4.63532

Cumulative Model Updates: 189,542
Cumulative Timesteps: 1,580,618,876

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1580618876...
Checkpoint 1580618876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,100.46387
Policy Entropy: 3.83883
Value Function Loss: 0.05644

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 1.16808
Value Function Update Magnitude: 0.86033

Collected Steps per Second: 22,787.80532
Overall Steps per Second: 10,744.31910

Timestep Collection Time: 2.19626
Timestep Consumption Time: 2.46183
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.65809

Cumulative Model Updates: 189,548
Cumulative Timesteps: 1,580,668,924

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.03334
Policy Entropy: 3.85003
Value Function Loss: 0.05318

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 1.00993
Value Function Update Magnitude: 0.87870

Collected Steps per Second: 22,979.92869
Overall Steps per Second: 10,814.23606

Timestep Collection Time: 2.17581
Timestep Consumption Time: 2.44772
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.62354

Cumulative Model Updates: 189,554
Cumulative Timesteps: 1,580,718,924

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1580718924...
Checkpoint 1580718924 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,586.29680
Policy Entropy: 3.84490
Value Function Loss: 0.05148

Mean KL Divergence: 0.01231
SB3 Clip Fraction: 0.15515
Policy Update Magnitude: 0.74630
Value Function Update Magnitude: 0.76073

Collected Steps per Second: 22,608.57522
Overall Steps per Second: 10,702.14781

Timestep Collection Time: 2.21235
Timestep Consumption Time: 2.46129
PPO Batch Consumption Time: 0.29267
Total Iteration Time: 4.67364

Cumulative Model Updates: 189,560
Cumulative Timesteps: 1,580,768,942

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 299.65222
Policy Entropy: 3.83003
Value Function Loss: 0.04663

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.14523
Policy Update Magnitude: 0.59508
Value Function Update Magnitude: 0.76554

Collected Steps per Second: 23,196.78072
Overall Steps per Second: 10,829.10620

Timestep Collection Time: 2.15633
Timestep Consumption Time: 2.46270
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.61903

Cumulative Model Updates: 189,566
Cumulative Timesteps: 1,580,818,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1580818962...
Checkpoint 1580818962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,614.04155
Policy Entropy: 3.78392
Value Function Loss: 0.04318

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.16016
Policy Update Magnitude: 0.53023
Value Function Update Magnitude: 0.73151

Collected Steps per Second: 22,660.55952
Overall Steps per Second: 10,657.47879

Timestep Collection Time: 2.20745
Timestep Consumption Time: 2.48616
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.69361

Cumulative Model Updates: 189,572
Cumulative Timesteps: 1,580,868,984

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,328.38678
Policy Entropy: 3.77730
Value Function Loss: 0.03589

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13639
Policy Update Magnitude: 0.46829
Value Function Update Magnitude: 0.66325

Collected Steps per Second: 23,383.12056
Overall Steps per Second: 10,980.11992

Timestep Collection Time: 2.13915
Timestep Consumption Time: 2.41636
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.55551

Cumulative Model Updates: 189,578
Cumulative Timesteps: 1,580,919,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1580919004...
Checkpoint 1580919004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,248.56269
Policy Entropy: 3.76548
Value Function Loss: 0.02986

Mean KL Divergence: 0.01400
SB3 Clip Fraction: 0.17677
Policy Update Magnitude: 0.41912
Value Function Update Magnitude: 0.55539

Collected Steps per Second: 22,663.59781
Overall Steps per Second: 10,667.32796

Timestep Collection Time: 2.20777
Timestep Consumption Time: 2.48281
PPO Batch Consumption Time: 0.29260
Total Iteration Time: 4.69058

Cumulative Model Updates: 189,584
Cumulative Timesteps: 1,580,969,040

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,248.56269
Policy Entropy: 3.78453
Value Function Loss: 0.02550

Mean KL Divergence: 0.01297
SB3 Clip Fraction: 0.15874
Policy Update Magnitude: 0.36640
Value Function Update Magnitude: 0.50149

Collected Steps per Second: 23,019.90324
Overall Steps per Second: 10,845.95499

Timestep Collection Time: 2.17229
Timestep Consumption Time: 2.43827
PPO Batch Consumption Time: 0.28155
Total Iteration Time: 4.61057

Cumulative Model Updates: 189,590
Cumulative Timesteps: 1,581,019,046

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1581019046...
Checkpoint 1581019046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,248.56269
Policy Entropy: 3.78870
Value Function Loss: 0.02214

Mean KL Divergence: 0.01316
SB3 Clip Fraction: 0.16076
Policy Update Magnitude: 0.32741
Value Function Update Magnitude: 0.44805

Collected Steps per Second: 22,770.67116
Overall Steps per Second: 10,673.11251

Timestep Collection Time: 2.19625
Timestep Consumption Time: 2.48936
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.68561

Cumulative Model Updates: 189,596
Cumulative Timesteps: 1,581,069,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,248.56269
Policy Entropy: 3.77318
Value Function Loss: 0.01925

Mean KL Divergence: 0.01225
SB3 Clip Fraction: 0.15598
Policy Update Magnitude: 0.29783
Value Function Update Magnitude: 0.38043

Collected Steps per Second: 22,500.67733
Overall Steps per Second: 10,872.31097

Timestep Collection Time: 2.22233
Timestep Consumption Time: 2.37687
PPO Batch Consumption Time: 0.28288
Total Iteration Time: 4.59921

Cumulative Model Updates: 189,602
Cumulative Timesteps: 1,581,119,060

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1581119060...
Checkpoint 1581119060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,248.56269
Policy Entropy: 3.75861
Value Function Loss: 0.01677

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15741
Policy Update Magnitude: 0.25933
Value Function Update Magnitude: 0.29923

Collected Steps per Second: 22,095.85866
Overall Steps per Second: 10,678.91222

Timestep Collection Time: 2.26423
Timestep Consumption Time: 2.42071
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.68493

Cumulative Model Updates: 189,608
Cumulative Timesteps: 1,581,169,090

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,248.56269
Policy Entropy: 3.74105
Value Function Loss: 0.01655

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.14877
Policy Update Magnitude: 0.25608
Value Function Update Magnitude: 0.28916

Collected Steps per Second: 22,520.75983
Overall Steps per Second: 10,794.95525

Timestep Collection Time: 2.22071
Timestep Consumption Time: 2.41220
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.63290

Cumulative Model Updates: 189,614
Cumulative Timesteps: 1,581,219,102

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1581219102...
Checkpoint 1581219102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,248.56269
Policy Entropy: 3.74633
Value Function Loss: 0.01708

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13736
Policy Update Magnitude: 0.30709
Value Function Update Magnitude: 0.31975

Collected Steps per Second: 22,514.96337
Overall Steps per Second: 10,677.74193

Timestep Collection Time: 2.22092
Timestep Consumption Time: 2.46209
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.68301

Cumulative Model Updates: 189,620
Cumulative Timesteps: 1,581,269,106

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,248.56269
Policy Entropy: 3.73542
Value Function Loss: 0.01649

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.33373
Value Function Update Magnitude: 0.38559

Collected Steps per Second: 23,009.16461
Overall Steps per Second: 10,965.46739

Timestep Collection Time: 2.17357
Timestep Consumption Time: 2.38729
PPO Batch Consumption Time: 0.27603
Total Iteration Time: 4.56086

Cumulative Model Updates: 189,626
Cumulative Timesteps: 1,581,319,118

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1581319118...
Checkpoint 1581319118 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 170,818.81365
Policy Entropy: 3.74682
Value Function Loss: 0.01775

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12886
Policy Update Magnitude: 0.33133
Value Function Update Magnitude: 0.44224

Collected Steps per Second: 22,647.39374
Overall Steps per Second: 10,653.57787

Timestep Collection Time: 2.20811
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.69401

Cumulative Model Updates: 189,632
Cumulative Timesteps: 1,581,369,126

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,617.74476
Policy Entropy: 3.73154
Value Function Loss: 0.02219

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.36159
Value Function Update Magnitude: 0.57631

Collected Steps per Second: 23,126.70413
Overall Steps per Second: 10,893.38335

Timestep Collection Time: 2.16218
Timestep Consumption Time: 2.42813
PPO Batch Consumption Time: 0.27654
Total Iteration Time: 4.59031

Cumulative Model Updates: 189,638
Cumulative Timesteps: 1,581,419,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1581419130...
Checkpoint 1581419130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,617.74476
Policy Entropy: 3.72272
Value Function Loss: 0.02479

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.43988
Value Function Update Magnitude: 0.68900

Collected Steps per Second: 22,080.95261
Overall Steps per Second: 10,584.62843

Timestep Collection Time: 2.26612
Timestep Consumption Time: 2.46131
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.72742

Cumulative Model Updates: 189,644
Cumulative Timesteps: 1,581,469,168

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41,617.74476
Policy Entropy: 3.68343
Value Function Loss: 0.03180

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.51347
Value Function Update Magnitude: 0.69683

Collected Steps per Second: 23,308.36313
Overall Steps per Second: 10,970.03944

Timestep Collection Time: 2.14541
Timestep Consumption Time: 2.41301
PPO Batch Consumption Time: 0.27600
Total Iteration Time: 4.55842

Cumulative Model Updates: 189,650
Cumulative Timesteps: 1,581,519,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1581519174...
Checkpoint 1581519174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,469.47594
Policy Entropy: 3.68990
Value Function Loss: 0.03385

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.60673
Value Function Update Magnitude: 0.64660

Collected Steps per Second: 22,022.57340
Overall Steps per Second: 10,606.77386

Timestep Collection Time: 2.27040
Timestep Consumption Time: 2.44357
PPO Batch Consumption Time: 0.28282
Total Iteration Time: 4.71397

Cumulative Model Updates: 189,656
Cumulative Timesteps: 1,581,569,174

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,287.32009
Policy Entropy: 3.71255
Value Function Loss: 0.03152

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.58301
Value Function Update Magnitude: 0.52447

Collected Steps per Second: 23,198.77964
Overall Steps per Second: 10,916.91310

Timestep Collection Time: 2.15615
Timestep Consumption Time: 2.42573
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.58188

Cumulative Model Updates: 189,662
Cumulative Timesteps: 1,581,619,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1581619194...
Checkpoint 1581619194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,438.16080
Policy Entropy: 3.70578
Value Function Loss: 0.03551

Mean KL Divergence: 0.02398
SB3 Clip Fraction: 0.26094
Policy Update Magnitude: 0.47242
Value Function Update Magnitude: 0.51384

Collected Steps per Second: 22,105.29773
Overall Steps per Second: 10,682.22643

Timestep Collection Time: 2.26199
Timestep Consumption Time: 2.41887
PPO Batch Consumption Time: 0.29070
Total Iteration Time: 4.68086

Cumulative Model Updates: 189,668
Cumulative Timesteps: 1,581,669,196

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,070.37553
Policy Entropy: 3.69788
Value Function Loss: 0.04808

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16629
Policy Update Magnitude: 0.48306
Value Function Update Magnitude: 0.49704

Collected Steps per Second: 22,607.11122
Overall Steps per Second: 10,845.43924

Timestep Collection Time: 2.21240
Timestep Consumption Time: 2.39931
PPO Batch Consumption Time: 0.28497
Total Iteration Time: 4.61171

Cumulative Model Updates: 189,674
Cumulative Timesteps: 1,581,719,212

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1581719212...
Checkpoint 1581719212 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,933.33716
Policy Entropy: 3.65410
Value Function Loss: 0.06114

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.56788
Value Function Update Magnitude: 0.55760

Collected Steps per Second: 21,950.91585
Overall Steps per Second: 10,633.71764

Timestep Collection Time: 2.27790
Timestep Consumption Time: 2.42431
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.70221

Cumulative Model Updates: 189,680
Cumulative Timesteps: 1,581,769,214

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,708.60909
Policy Entropy: 3.67097
Value Function Loss: 0.05611

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.12852
Policy Update Magnitude: 0.54695
Value Function Update Magnitude: 0.47869

Collected Steps per Second: 22,370.46715
Overall Steps per Second: 10,886.19760

Timestep Collection Time: 2.23589
Timestep Consumption Time: 2.35873
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.59463

Cumulative Model Updates: 189,686
Cumulative Timesteps: 1,581,819,232

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1581819232...
Checkpoint 1581819232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,708.60909
Policy Entropy: 3.66808
Value Function Loss: 0.04369

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.48470
Value Function Update Magnitude: 0.43259

Collected Steps per Second: 21,941.30162
Overall Steps per Second: 10,652.37196

Timestep Collection Time: 2.27972
Timestep Consumption Time: 2.41595
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.69567

Cumulative Model Updates: 189,692
Cumulative Timesteps: 1,581,869,252

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,708.60909
Policy Entropy: 3.68868
Value Function Loss: 0.03136

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11632
Policy Update Magnitude: 0.45987
Value Function Update Magnitude: 0.41282

Collected Steps per Second: 22,990.26992
Overall Steps per Second: 10,909.71368

Timestep Collection Time: 2.17483
Timestep Consumption Time: 2.40824
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.58307

Cumulative Model Updates: 189,698
Cumulative Timesteps: 1,581,919,252

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1581919252...
Checkpoint 1581919252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,708.60909
Policy Entropy: 3.68177
Value Function Loss: 0.02797

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12911
Policy Update Magnitude: 0.39889
Value Function Update Magnitude: 0.36185

Collected Steps per Second: 22,341.62732
Overall Steps per Second: 10,669.14112

Timestep Collection Time: 2.23869
Timestep Consumption Time: 2.44922
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.68791

Cumulative Model Updates: 189,704
Cumulative Timesteps: 1,581,969,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,708.60909
Policy Entropy: 3.71256
Value Function Loss: 0.01965

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.33649
Value Function Update Magnitude: 0.31740

Collected Steps per Second: 23,172.96783
Overall Steps per Second: 10,891.01431

Timestep Collection Time: 2.15993
Timestep Consumption Time: 2.43578
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.59572

Cumulative Model Updates: 189,710
Cumulative Timesteps: 1,582,019,320

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1582019320...
Checkpoint 1582019320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,708.60909
Policy Entropy: 3.71203
Value Function Loss: 0.01612

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13061
Policy Update Magnitude: 0.28675
Value Function Update Magnitude: 0.29601

Collected Steps per Second: 22,545.96947
Overall Steps per Second: 10,652.92022

Timestep Collection Time: 2.21787
Timestep Consumption Time: 2.47606
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.69392

Cumulative Model Updates: 189,716
Cumulative Timesteps: 1,582,069,324

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,708.60909
Policy Entropy: 3.71774
Value Function Loss: 0.01179

Mean KL Divergence: 0.00820
SB3 Clip Fraction: 0.11617
Policy Update Magnitude: 0.24805
Value Function Update Magnitude: 0.29807

Collected Steps per Second: 23,025.66224
Overall Steps per Second: 10,903.14105

Timestep Collection Time: 2.17236
Timestep Consumption Time: 2.41531
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.58767

Cumulative Model Updates: 189,722
Cumulative Timesteps: 1,582,119,344

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1582119344...
Checkpoint 1582119344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,708.60909
Policy Entropy: 3.70601
Value Function Loss: 0.01162

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12579
Policy Update Magnitude: 0.24980
Value Function Update Magnitude: 0.29063

Collected Steps per Second: 22,436.94403
Overall Steps per Second: 10,683.12363

Timestep Collection Time: 2.22945
Timestep Consumption Time: 2.45289
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.68234

Cumulative Model Updates: 189,728
Cumulative Timesteps: 1,582,169,366

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,708.60909
Policy Entropy: 3.71238
Value Function Loss: 0.01124

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11878
Policy Update Magnitude: 0.28154
Value Function Update Magnitude: 0.31406

Collected Steps per Second: 23,196.05254
Overall Steps per Second: 10,947.43017

Timestep Collection Time: 2.15683
Timestep Consumption Time: 2.41319
PPO Batch Consumption Time: 0.27629
Total Iteration Time: 4.57002

Cumulative Model Updates: 189,734
Cumulative Timesteps: 1,582,219,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1582219396...
Checkpoint 1582219396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.70458
Value Function Loss: 0.01509

Mean KL Divergence: 0.00829
SB3 Clip Fraction: 0.11412
Policy Update Magnitude: 0.31369
Value Function Update Magnitude: 0.36703

Collected Steps per Second: 22,898.07467
Overall Steps per Second: 10,697.53467

Timestep Collection Time: 2.18359
Timestep Consumption Time: 2.49038
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.67397

Cumulative Model Updates: 189,740
Cumulative Timesteps: 1,582,269,396

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.69662
Value Function Loss: 0.01576

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11858
Policy Update Magnitude: 0.35868
Value Function Update Magnitude: 0.48061

Collected Steps per Second: 22,233.06892
Overall Steps per Second: 10,807.16847

Timestep Collection Time: 2.24953
Timestep Consumption Time: 2.37832
PPO Batch Consumption Time: 0.28266
Total Iteration Time: 4.62785

Cumulative Model Updates: 189,746
Cumulative Timesteps: 1,582,319,410

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1582319410...
Checkpoint 1582319410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.69082
Value Function Loss: 0.02158

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.41377
Value Function Update Magnitude: 0.48510

Collected Steps per Second: 21,883.19208
Overall Steps per Second: 10,632.23935

Timestep Collection Time: 2.28513
Timestep Consumption Time: 2.41811
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.70324

Cumulative Model Updates: 189,752
Cumulative Timesteps: 1,582,369,416

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.70355
Value Function Loss: 0.01961

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.43963
Value Function Update Magnitude: 0.40411

Collected Steps per Second: 22,495.38222
Overall Steps per Second: 10,813.12635

Timestep Collection Time: 2.22401
Timestep Consumption Time: 2.40277
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.62678

Cumulative Model Updates: 189,758
Cumulative Timesteps: 1,582,419,446

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1582419446...
Checkpoint 1582419446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.70748
Value Function Loss: 0.01732

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11865
Policy Update Magnitude: 0.43384
Value Function Update Magnitude: 0.43356

Collected Steps per Second: 22,590.73749
Overall Steps per Second: 10,686.53398

Timestep Collection Time: 2.21471
Timestep Consumption Time: 2.46707
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.68178

Cumulative Model Updates: 189,764
Cumulative Timesteps: 1,582,469,478

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.70681
Value Function Loss: 0.01451

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10682
Policy Update Magnitude: 0.37193
Value Function Update Magnitude: 0.38712

Collected Steps per Second: 23,130.41122
Overall Steps per Second: 10,946.38980

Timestep Collection Time: 2.16252
Timestep Consumption Time: 2.40702
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.56954

Cumulative Model Updates: 189,770
Cumulative Timesteps: 1,582,519,498

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1582519498...
Checkpoint 1582519498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.70424
Value Function Loss: 0.01510

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05574
Policy Update Magnitude: 0.41302
Value Function Update Magnitude: 0.41502

Collected Steps per Second: 22,743.44046
Overall Steps per Second: 10,664.39605

Timestep Collection Time: 2.19967
Timestep Consumption Time: 2.49146
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.69112

Cumulative Model Updates: 189,776
Cumulative Timesteps: 1,582,569,526

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.69911
Value Function Loss: 0.01444

Mean KL Divergence: 0.00573
SB3 Clip Fraction: 0.06845
Policy Update Magnitude: 0.46484
Value Function Update Magnitude: 0.44173

Collected Steps per Second: 22,999.64080
Overall Steps per Second: 10,865.48236

Timestep Collection Time: 2.17456
Timestep Consumption Time: 2.42846
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.60302

Cumulative Model Updates: 189,782
Cumulative Timesteps: 1,582,619,540

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1582619540...
Checkpoint 1582619540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.71192
Value Function Loss: 0.01418

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06288
Policy Update Magnitude: 0.43151
Value Function Update Magnitude: 0.35149

Collected Steps per Second: 22,867.22604
Overall Steps per Second: 10,667.46916

Timestep Collection Time: 2.18820
Timestep Consumption Time: 2.50251
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.69071

Cumulative Model Updates: 189,788
Cumulative Timesteps: 1,582,669,578

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.71251
Value Function Loss: 0.01285

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05720
Policy Update Magnitude: 0.38977
Value Function Update Magnitude: 0.26625

Collected Steps per Second: 23,038.51280
Overall Steps per Second: 10,903.95895

Timestep Collection Time: 2.17123
Timestep Consumption Time: 2.41627
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.58751

Cumulative Model Updates: 189,794
Cumulative Timesteps: 1,582,719,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1582719600...
Checkpoint 1582719600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.70847
Value Function Loss: 0.01376

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05447
Policy Update Magnitude: 0.43784
Value Function Update Magnitude: 0.33026

Collected Steps per Second: 22,492.06971
Overall Steps per Second: 10,664.78245

Timestep Collection Time: 2.22416
Timestep Consumption Time: 2.46660
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.69077

Cumulative Model Updates: 189,800
Cumulative Timesteps: 1,582,769,626

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145,117.28015
Policy Entropy: 3.69637
Value Function Loss: 0.01659

Mean KL Divergence: 0.00553
SB3 Clip Fraction: 0.06618
Policy Update Magnitude: 0.50704
Value Function Update Magnitude: 0.52099

Collected Steps per Second: 22,811.54218
Overall Steps per Second: 10,819.97921

Timestep Collection Time: 2.19275
Timestep Consumption Time: 2.43018
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.62293

Cumulative Model Updates: 189,806
Cumulative Timesteps: 1,582,819,646

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1582819646...
Checkpoint 1582819646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,970.27369
Policy Entropy: 3.70225
Value Function Loss: 0.01933

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.50047
Value Function Update Magnitude: 0.63999

Collected Steps per Second: 22,677.79567
Overall Steps per Second: 10,711.74690

Timestep Collection Time: 2.20621
Timestep Consumption Time: 2.46455
PPO Batch Consumption Time: 0.28602
Total Iteration Time: 4.67076

Cumulative Model Updates: 189,812
Cumulative Timesteps: 1,582,869,678

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,970.27369
Policy Entropy: 3.69901
Value Function Loss: 0.01986

Mean KL Divergence: 0.01217
SB3 Clip Fraction: 0.15547
Policy Update Magnitude: 0.47463
Value Function Update Magnitude: 0.66168

Collected Steps per Second: 22,869.11635
Overall Steps per Second: 10,853.64734

Timestep Collection Time: 2.18845
Timestep Consumption Time: 2.42272
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.61117

Cumulative Model Updates: 189,818
Cumulative Timesteps: 1,582,919,726

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1582919726...
Checkpoint 1582919726 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,970.27369
Policy Entropy: 3.70997
Value Function Loss: 0.01956

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.16080
Policy Update Magnitude: 0.45467
Value Function Update Magnitude: 0.65721

Collected Steps per Second: 22,563.79839
Overall Steps per Second: 10,736.05672

Timestep Collection Time: 2.21603
Timestep Consumption Time: 2.44136
PPO Batch Consumption Time: 0.28384
Total Iteration Time: 4.65739

Cumulative Model Updates: 189,824
Cumulative Timesteps: 1,582,969,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,751.55146
Policy Entropy: 3.70569
Value Function Loss: 0.02312

Mean KL Divergence: 0.02049
SB3 Clip Fraction: 0.23373
Policy Update Magnitude: 0.39405
Value Function Update Magnitude: 0.60154

Collected Steps per Second: 22,862.14283
Overall Steps per Second: 10,851.36297

Timestep Collection Time: 2.18790
Timestep Consumption Time: 2.42166
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.60956

Cumulative Model Updates: 189,830
Cumulative Timesteps: 1,583,019,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1583019748...
Checkpoint 1583019748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,188.97136
Policy Entropy: 3.71726
Value Function Loss: 0.02386

Mean KL Divergence: 0.01274
SB3 Clip Fraction: 0.15876
Policy Update Magnitude: 0.46909
Value Function Update Magnitude: 0.61443

Collected Steps per Second: 21,995.80422
Overall Steps per Second: 10,661.11439

Timestep Collection Time: 2.27452
Timestep Consumption Time: 2.41823
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.69276

Cumulative Model Updates: 189,836
Cumulative Timesteps: 1,583,069,778

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.70545
Value Function Loss: 0.02618

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14273
Policy Update Magnitude: 0.52178
Value Function Update Magnitude: 0.64413

Collected Steps per Second: 22,334.84858
Overall Steps per Second: 10,902.25025

Timestep Collection Time: 2.23946
Timestep Consumption Time: 2.34840
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.58786

Cumulative Model Updates: 189,842
Cumulative Timesteps: 1,583,119,796

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1583119796...
Checkpoint 1583119796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.69659
Value Function Loss: 0.02296

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13733
Policy Update Magnitude: 0.45163
Value Function Update Magnitude: 0.55240

Collected Steps per Second: 22,127.58676
Overall Steps per Second: 10,707.04472

Timestep Collection Time: 2.26035
Timestep Consumption Time: 2.41097
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.67132

Cumulative Model Updates: 189,848
Cumulative Timesteps: 1,583,169,812

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.66684
Value Function Loss: 0.02481

Mean KL Divergence: 0.01052
SB3 Clip Fraction: 0.14092
Policy Update Magnitude: 0.45701
Value Function Update Magnitude: 0.54151

Collected Steps per Second: 22,372.73783
Overall Steps per Second: 10,746.38764

Timestep Collection Time: 2.23522
Timestep Consumption Time: 2.41825
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.65347

Cumulative Model Updates: 189,854
Cumulative Timesteps: 1,583,219,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1583219820...
Checkpoint 1583219820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.67644
Value Function Loss: 0.02759

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13182
Policy Update Magnitude: 0.51346
Value Function Update Magnitude: 0.59615

Collected Steps per Second: 22,658.29936
Overall Steps per Second: 10,786.84370

Timestep Collection Time: 2.20820
Timestep Consumption Time: 2.43023
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.63843

Cumulative Model Updates: 189,860
Cumulative Timesteps: 1,583,269,854

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.66707
Value Function Loss: 0.02810

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.56251
Value Function Update Magnitude: 0.76689

Collected Steps per Second: 22,993.72972
Overall Steps per Second: 10,868.16670

Timestep Collection Time: 2.17477
Timestep Consumption Time: 2.42638
PPO Batch Consumption Time: 0.27715
Total Iteration Time: 4.60114

Cumulative Model Updates: 189,866
Cumulative Timesteps: 1,583,319,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1583319860...
Checkpoint 1583319860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.69698
Value Function Loss: 0.02349

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13442
Policy Update Magnitude: 0.52817
Value Function Update Magnitude: 0.74654

Collected Steps per Second: 22,877.34808
Overall Steps per Second: 10,665.03369

Timestep Collection Time: 2.18670
Timestep Consumption Time: 2.50395
PPO Batch Consumption Time: 0.29323
Total Iteration Time: 4.69066

Cumulative Model Updates: 189,872
Cumulative Timesteps: 1,583,369,886

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.69732
Value Function Loss: 0.02096

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.43431
Value Function Update Magnitude: 0.55060

Collected Steps per Second: 23,051.35620
Overall Steps per Second: 10,876.85686

Timestep Collection Time: 2.16924
Timestep Consumption Time: 2.42804
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.59728

Cumulative Model Updates: 189,878
Cumulative Timesteps: 1,583,419,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1583419890...
Checkpoint 1583419890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.70002
Value Function Loss: 0.01700

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12742
Policy Update Magnitude: 0.38078
Value Function Update Magnitude: 0.40687

Collected Steps per Second: 22,807.32711
Overall Steps per Second: 10,651.99278

Timestep Collection Time: 2.19263
Timestep Consumption Time: 2.50208
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.69471

Cumulative Model Updates: 189,884
Cumulative Timesteps: 1,583,469,898

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.69475
Value Function Loss: 0.01852

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.38272
Value Function Update Magnitude: 0.37883

Collected Steps per Second: 23,354.90878
Overall Steps per Second: 11,003.26941

Timestep Collection Time: 2.14148
Timestep Consumption Time: 2.40390
PPO Batch Consumption Time: 0.27545
Total Iteration Time: 4.54538

Cumulative Model Updates: 189,890
Cumulative Timesteps: 1,583,519,912

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1583519912...
Checkpoint 1583519912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.68347
Value Function Loss: 0.02263

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.42014
Value Function Update Magnitude: 0.38732

Collected Steps per Second: 22,492.39039
Overall Steps per Second: 10,647.75013

Timestep Collection Time: 2.22324
Timestep Consumption Time: 2.47315
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.69639

Cumulative Model Updates: 189,896
Cumulative Timesteps: 1,583,569,918

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.68790
Value Function Loss: 0.02265

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12961
Policy Update Magnitude: 0.45524
Value Function Update Magnitude: 0.46014

Collected Steps per Second: 22,192.11436
Overall Steps per Second: 10,882.25591

Timestep Collection Time: 2.25404
Timestep Consumption Time: 2.34261
PPO Batch Consumption Time: 0.27655
Total Iteration Time: 4.59666

Cumulative Model Updates: 189,902
Cumulative Timesteps: 1,583,619,940

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1583619940...
Checkpoint 1583619940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.67494
Value Function Loss: 0.02211

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.42582
Value Function Update Magnitude: 0.62104

Collected Steps per Second: 21,916.79332
Overall Steps per Second: 10,658.85270

Timestep Collection Time: 2.28163
Timestep Consumption Time: 2.40987
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.69150

Cumulative Model Updates: 189,908
Cumulative Timesteps: 1,583,669,946

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.69161
Value Function Loss: 0.01956

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.39731
Value Function Update Magnitude: 0.55931

Collected Steps per Second: 22,373.88644
Overall Steps per Second: 10,787.22827

Timestep Collection Time: 2.23555
Timestep Consumption Time: 2.40123
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.63678

Cumulative Model Updates: 189,914
Cumulative Timesteps: 1,583,719,964

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1583719964...
Checkpoint 1583719964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.67284
Value Function Loss: 0.02243

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12661
Policy Update Magnitude: 0.37434
Value Function Update Magnitude: 0.47703

Collected Steps per Second: 22,771.03269
Overall Steps per Second: 10,708.92171

Timestep Collection Time: 2.19612
Timestep Consumption Time: 2.47363
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.66975

Cumulative Model Updates: 189,920
Cumulative Timesteps: 1,583,769,972

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.67984
Value Function Loss: 0.02349

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11886
Policy Update Magnitude: 0.41388
Value Function Update Magnitude: 0.47420

Collected Steps per Second: 22,385.64597
Overall Steps per Second: 10,798.57598

Timestep Collection Time: 2.23411
Timestep Consumption Time: 2.39724
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.63135

Cumulative Model Updates: 189,926
Cumulative Timesteps: 1,583,819,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1583819984...
Checkpoint 1583819984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.66560
Value Function Loss: 0.02583

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.45238
Value Function Update Magnitude: 0.37353

Collected Steps per Second: 22,725.99902
Overall Steps per Second: 10,742.09455

Timestep Collection Time: 2.20188
Timestep Consumption Time: 2.45643
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.65831

Cumulative Model Updates: 189,932
Cumulative Timesteps: 1,583,870,024

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.67089
Value Function Loss: 0.02085

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13334
Policy Update Magnitude: 0.45488
Value Function Update Magnitude: 0.40510

Collected Steps per Second: 22,869.03732
Overall Steps per Second: 10,860.18152

Timestep Collection Time: 2.18724
Timestep Consumption Time: 2.41858
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.60582

Cumulative Model Updates: 189,938
Cumulative Timesteps: 1,583,920,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1583920044...
Checkpoint 1583920044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.68675
Value Function Loss: 0.01787

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.15252
Policy Update Magnitude: 0.46031
Value Function Update Magnitude: 0.52025

Collected Steps per Second: 22,655.73497
Overall Steps per Second: 10,678.63197

Timestep Collection Time: 2.20783
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28666
Total Iteration Time: 4.68412

Cumulative Model Updates: 189,944
Cumulative Timesteps: 1,583,970,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.69361
Value Function Loss: 0.01933

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.15209
Policy Update Magnitude: 0.42087
Value Function Update Magnitude: 0.53881

Collected Steps per Second: 23,029.00977
Overall Steps per Second: 10,870.04915

Timestep Collection Time: 2.17126
Timestep Consumption Time: 2.42872
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.59998

Cumulative Model Updates: 189,950
Cumulative Timesteps: 1,584,020,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1584020066...
Checkpoint 1584020066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.70145
Value Function Loss: 0.01837

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12691
Policy Update Magnitude: 0.43118
Value Function Update Magnitude: 0.47477

Collected Steps per Second: 22,729.23198
Overall Steps per Second: 10,669.83917

Timestep Collection Time: 2.20051
Timestep Consumption Time: 2.48709
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.68761

Cumulative Model Updates: 189,956
Cumulative Timesteps: 1,584,070,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.68938
Value Function Loss: 0.01873

Mean KL Divergence: 0.00760
SB3 Clip Fraction: 0.09742
Policy Update Magnitude: 0.44579
Value Function Update Magnitude: 0.40291

Collected Steps per Second: 22,932.96636
Overall Steps per Second: 10,878.94194

Timestep Collection Time: 2.18070
Timestep Consumption Time: 2.41625
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.59695

Cumulative Model Updates: 189,962
Cumulative Timesteps: 1,584,120,092

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1584120092...
Checkpoint 1584120092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.68416
Value Function Loss: 0.02044

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13150
Policy Update Magnitude: 0.46432
Value Function Update Magnitude: 0.39490

Collected Steps per Second: 22,608.68323
Overall Steps per Second: 10,697.18686

Timestep Collection Time: 2.21172
Timestep Consumption Time: 2.46278
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.67450

Cumulative Model Updates: 189,968
Cumulative Timesteps: 1,584,170,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.67988
Value Function Loss: 0.02331

Mean KL Divergence: 0.01244
SB3 Clip Fraction: 0.15929
Policy Update Magnitude: 0.48874
Value Function Update Magnitude: 0.36490

Collected Steps per Second: 22,061.94532
Overall Steps per Second: 10,799.99735

Timestep Collection Time: 2.26798
Timestep Consumption Time: 2.36499
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.63296

Cumulative Model Updates: 189,974
Cumulative Timesteps: 1,584,220,132

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1584220132...
Checkpoint 1584220132 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.67956
Value Function Loss: 0.02489

Mean KL Divergence: 0.01178
SB3 Clip Fraction: 0.15098
Policy Update Magnitude: 0.50890
Value Function Update Magnitude: 0.41932

Collected Steps per Second: 22,030.50008
Overall Steps per Second: 10,712.95188

Timestep Collection Time: 2.26958
Timestep Consumption Time: 2.39767
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.66725

Cumulative Model Updates: 189,980
Cumulative Timesteps: 1,584,270,132

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.70729
Value Function Loss: 0.02199

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14789
Policy Update Magnitude: 0.54966
Value Function Update Magnitude: 0.49250

Collected Steps per Second: 22,067.46029
Overall Steps per Second: 10,559.97231

Timestep Collection Time: 2.26741
Timestep Consumption Time: 2.47086
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.73827

Cumulative Model Updates: 189,986
Cumulative Timesteps: 1,584,320,168

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1584320168...
Checkpoint 1584320168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.71332
Value Function Loss: 0.01887

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14290
Policy Update Magnitude: 0.53970
Value Function Update Magnitude: 0.44504

Collected Steps per Second: 22,626.32826
Overall Steps per Second: 10,746.07306

Timestep Collection Time: 2.21123
Timestep Consumption Time: 2.44461
PPO Batch Consumption Time: 0.28779
Total Iteration Time: 4.65584

Cumulative Model Updates: 189,992
Cumulative Timesteps: 1,584,370,200

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.72298
Value Function Loss: 0.01504

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.45314
Value Function Update Magnitude: 0.43145

Collected Steps per Second: 22,838.39266
Overall Steps per Second: 10,736.18674

Timestep Collection Time: 2.19000
Timestep Consumption Time: 2.46864
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.65864

Cumulative Model Updates: 189,998
Cumulative Timesteps: 1,584,420,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1584420216...
Checkpoint 1584420216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.70475
Value Function Loss: 0.01635

Mean KL Divergence: 0.00683
SB3 Clip Fraction: 0.08562
Policy Update Magnitude: 0.45777
Value Function Update Magnitude: 0.41702

Collected Steps per Second: 22,638.16834
Overall Steps per Second: 10,634.35743

Timestep Collection Time: 2.20875
Timestep Consumption Time: 2.49318
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.70193

Cumulative Model Updates: 190,004
Cumulative Timesteps: 1,584,470,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.70692
Value Function Loss: 0.01474

Mean KL Divergence: 0.00500
SB3 Clip Fraction: 0.05756
Policy Update Magnitude: 0.51880
Value Function Update Magnitude: 0.43309

Collected Steps per Second: 23,074.21329
Overall Steps per Second: 10,913.47677

Timestep Collection Time: 2.16735
Timestep Consumption Time: 2.41505
PPO Batch Consumption Time: 0.27598
Total Iteration Time: 4.58241

Cumulative Model Updates: 190,010
Cumulative Timesteps: 1,584,520,228

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1584520228...
Checkpoint 1584520228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.69266
Value Function Loss: 0.01524

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.09857
Policy Update Magnitude: 0.49706
Value Function Update Magnitude: 0.46702

Collected Steps per Second: 22,870.98181
Overall Steps per Second: 10,707.86425

Timestep Collection Time: 2.18679
Timestep Consumption Time: 2.48398
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.67077

Cumulative Model Updates: 190,016
Cumulative Timesteps: 1,584,570,242

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.70150
Value Function Loss: 0.01624

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.41106
Value Function Update Magnitude: 0.50564

Collected Steps per Second: 22,897.23355
Overall Steps per Second: 10,844.55108

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.42733
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.61135

Cumulative Model Updates: 190,022
Cumulative Timesteps: 1,584,620,250

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1584620250...
Checkpoint 1584620250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.66986
Value Function Loss: 0.01651

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.14217
Policy Update Magnitude: 0.40547
Value Function Update Magnitude: 0.48231

Collected Steps per Second: 22,297.24599
Overall Steps per Second: 10,572.19908

Timestep Collection Time: 2.24252
Timestep Consumption Time: 2.48706
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.72957

Cumulative Model Updates: 190,028
Cumulative Timesteps: 1,584,670,252

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,937.14028
Policy Entropy: 3.65496
Value Function Loss: 0.02782

Mean KL Divergence: 0.01144
SB3 Clip Fraction: 0.14261
Policy Update Magnitude: 0.46521
Value Function Update Magnitude: 0.44322

Collected Steps per Second: 22,668.01051
Overall Steps per Second: 10,675.13687

Timestep Collection Time: 2.20610
Timestep Consumption Time: 2.47843
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.68453

Cumulative Model Updates: 190,034
Cumulative Timesteps: 1,584,720,260

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1584720260...
Checkpoint 1584720260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 310,517.96083
Policy Entropy: 3.65921
Value Function Loss: 0.03745

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 0.59274
Value Function Update Magnitude: 0.52152

Collected Steps per Second: 22,599.23045
Overall Steps per Second: 10,800.43500

Timestep Collection Time: 2.21353
Timestep Consumption Time: 2.41814
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.63167

Cumulative Model Updates: 190,040
Cumulative Timesteps: 1,584,770,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 322,286.27387
Policy Entropy: 3.66229
Value Function Loss: 0.05830

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13304
Policy Update Magnitude: 0.64839
Value Function Update Magnitude: 0.48320

Collected Steps per Second: 21,997.92341
Overall Steps per Second: 10,513.77524

Timestep Collection Time: 2.27440
Timestep Consumption Time: 2.48431
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.75871

Cumulative Model Updates: 190,046
Cumulative Timesteps: 1,584,820,316

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1584820316...
Checkpoint 1584820316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,452.35508
Policy Entropy: 3.68919
Value Function Loss: 0.04790

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.71138
Value Function Update Magnitude: 0.46322

Collected Steps per Second: 22,781.90639
Overall Steps per Second: 10,555.64913

Timestep Collection Time: 2.19508
Timestep Consumption Time: 2.54248
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.73756

Cumulative Model Updates: 190,052
Cumulative Timesteps: 1,584,870,324

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,452.35508
Policy Entropy: 3.68911
Value Function Loss: 0.04252

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14001
Policy Update Magnitude: 0.65096
Value Function Update Magnitude: 0.43552

Collected Steps per Second: 22,659.41424
Overall Steps per Second: 10,629.51995

Timestep Collection Time: 2.20676
Timestep Consumption Time: 2.49749
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.70426

Cumulative Model Updates: 190,058
Cumulative Timesteps: 1,584,920,328

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1584920328...
Checkpoint 1584920328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,452.35508
Policy Entropy: 3.69458
Value Function Loss: 0.03011

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13556
Policy Update Magnitude: 0.58276
Value Function Update Magnitude: 0.43010

Collected Steps per Second: 22,609.83168
Overall Steps per Second: 10,641.80953

Timestep Collection Time: 2.21152
Timestep Consumption Time: 2.48712
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.69864

Cumulative Model Updates: 190,064
Cumulative Timesteps: 1,584,970,330

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 211,452.35508
Policy Entropy: 3.67611
Value Function Loss: 0.03024

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13874
Policy Update Magnitude: 0.59756
Value Function Update Magnitude: 0.42854

Collected Steps per Second: 22,765.27359
Overall Steps per Second: 10,824.13260

Timestep Collection Time: 2.19756
Timestep Consumption Time: 2.42434
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.62189

Cumulative Model Updates: 190,070
Cumulative Timesteps: 1,585,020,358

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1585020358...
Checkpoint 1585020358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 211,452.35508
Policy Entropy: 3.68607
Value Function Loss: 0.03023

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.61315
Value Function Update Magnitude: 0.41059

Collected Steps per Second: 22,541.07216
Overall Steps per Second: 10,655.79084

Timestep Collection Time: 2.21915
Timestep Consumption Time: 2.47520
PPO Batch Consumption Time: 0.28670
Total Iteration Time: 4.69435

Cumulative Model Updates: 190,076
Cumulative Timesteps: 1,585,070,380

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262,819.84445
Policy Entropy: 3.68094
Value Function Loss: 0.03448

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12945
Policy Update Magnitude: 0.58536
Value Function Update Magnitude: 0.41543

Collected Steps per Second: 22,399.66711
Overall Steps per Second: 10,963.56594

Timestep Collection Time: 2.23307
Timestep Consumption Time: 2.32932
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.56238

Cumulative Model Updates: 190,082
Cumulative Timesteps: 1,585,120,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1585120400...
Checkpoint 1585120400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,438.18839
Policy Entropy: 3.68760
Value Function Loss: 0.03311

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.56860
Value Function Update Magnitude: 0.45829

Collected Steps per Second: 22,154.49104
Overall Steps per Second: 10,723.24135

Timestep Collection Time: 2.25814
Timestep Consumption Time: 2.40724
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.66538

Cumulative Model Updates: 190,088
Cumulative Timesteps: 1,585,170,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,438.18839
Policy Entropy: 3.69000
Value Function Loss: 0.02978

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.52833
Value Function Update Magnitude: 0.42594

Collected Steps per Second: 22,156.30526
Overall Steps per Second: 10,771.96221

Timestep Collection Time: 2.25823
Timestep Consumption Time: 2.38661
PPO Batch Consumption Time: 0.28392
Total Iteration Time: 4.64484

Cumulative Model Updates: 190,094
Cumulative Timesteps: 1,585,220,462

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1585220462...
Checkpoint 1585220462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,438.18839
Policy Entropy: 3.70168
Value Function Loss: 0.02335

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12667
Policy Update Magnitude: 0.46868
Value Function Update Magnitude: 0.34122

Collected Steps per Second: 22,103.07652
Overall Steps per Second: 10,627.71419

Timestep Collection Time: 2.26231
Timestep Consumption Time: 2.44275
PPO Batch Consumption Time: 0.28411
Total Iteration Time: 4.70506

Cumulative Model Updates: 190,100
Cumulative Timesteps: 1,585,270,466

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,438.18839
Policy Entropy: 3.71932
Value Function Loss: 0.01920

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.40214
Value Function Update Magnitude: 0.29179

Collected Steps per Second: 22,841.66070
Overall Steps per Second: 10,899.53460

Timestep Collection Time: 2.19091
Timestep Consumption Time: 2.40048
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.59139

Cumulative Model Updates: 190,106
Cumulative Timesteps: 1,585,320,510

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1585320510...
Checkpoint 1585320510 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 737,064.47024
Policy Entropy: 3.71296
Value Function Loss: 0.01917

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12488
Policy Update Magnitude: 0.40141
Value Function Update Magnitude: 0.37242

Collected Steps per Second: 22,934.08694
Overall Steps per Second: 10,707.21651

Timestep Collection Time: 2.18129
Timestep Consumption Time: 2.49088
PPO Batch Consumption Time: 0.29234
Total Iteration Time: 4.67218

Cumulative Model Updates: 190,112
Cumulative Timesteps: 1,585,370,536

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 257,018.14386
Policy Entropy: 3.72329
Value Function Loss: 0.01978

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.42275
Value Function Update Magnitude: 0.47024

Collected Steps per Second: 22,564.54218
Overall Steps per Second: 10,780.47659

Timestep Collection Time: 2.21684
Timestep Consumption Time: 2.42321
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.64005

Cumulative Model Updates: 190,118
Cumulative Timesteps: 1,585,420,558

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1585420558...
Checkpoint 1585420558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.72893
Value Function Loss: 0.01939

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.40860
Value Function Update Magnitude: 0.53485

Collected Steps per Second: 22,521.91105
Overall Steps per Second: 10,791.63394

Timestep Collection Time: 2.22104
Timestep Consumption Time: 2.41422
PPO Batch Consumption Time: 0.27584
Total Iteration Time: 4.63526

Cumulative Model Updates: 190,124
Cumulative Timesteps: 1,585,470,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.71538
Value Function Loss: 0.01809

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11772
Policy Update Magnitude: 0.40778
Value Function Update Magnitude: 0.52478

Collected Steps per Second: 22,782.62361
Overall Steps per Second: 10,841.47013

Timestep Collection Time: 2.19562
Timestep Consumption Time: 2.41833
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.61395

Cumulative Model Updates: 190,130
Cumulative Timesteps: 1,585,520,602

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1585520602...
Checkpoint 1585520602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.70043
Value Function Loss: 0.01673

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.42220
Value Function Update Magnitude: 0.53433

Collected Steps per Second: 22,858.75996
Overall Steps per Second: 10,689.47567

Timestep Collection Time: 2.18805
Timestep Consumption Time: 2.49095
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.67899

Cumulative Model Updates: 190,136
Cumulative Timesteps: 1,585,570,618

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.69597
Value Function Loss: 0.01692

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.39270
Value Function Update Magnitude: 0.53609

Collected Steps per Second: 22,726.89476
Overall Steps per Second: 10,832.06413

Timestep Collection Time: 2.20074
Timestep Consumption Time: 2.41666
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.61740

Cumulative Model Updates: 190,142
Cumulative Timesteps: 1,585,620,634

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1585620634...
Checkpoint 1585620634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.69568
Value Function Loss: 0.01679

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12026
Policy Update Magnitude: 0.35227
Value Function Update Magnitude: 0.46572

Collected Steps per Second: 22,024.34865
Overall Steps per Second: 10,689.75138

Timestep Collection Time: 2.27130
Timestep Consumption Time: 2.40832
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.67962

Cumulative Model Updates: 190,148
Cumulative Timesteps: 1,585,670,658

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.70968
Value Function Loss: 0.01629

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.32726
Value Function Update Magnitude: 0.38457

Collected Steps per Second: 22,453.28242
Overall Steps per Second: 10,856.53804

Timestep Collection Time: 2.22720
Timestep Consumption Time: 2.37905
PPO Batch Consumption Time: 0.28342
Total Iteration Time: 4.60626

Cumulative Model Updates: 190,154
Cumulative Timesteps: 1,585,720,666

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1585720666...
Checkpoint 1585720666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.70992
Value Function Loss: 0.01613

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.12309
Policy Update Magnitude: 0.32604
Value Function Update Magnitude: 0.36426

Collected Steps per Second: 22,050.02636
Overall Steps per Second: 10,752.27158

Timestep Collection Time: 2.26802
Timestep Consumption Time: 2.38309
PPO Batch Consumption Time: 0.27563
Total Iteration Time: 4.65111

Cumulative Model Updates: 190,160
Cumulative Timesteps: 1,585,770,676

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.71087
Value Function Loss: 0.01571

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11463
Policy Update Magnitude: 0.32493
Value Function Update Magnitude: 0.36849

Collected Steps per Second: 22,963.55982
Overall Steps per Second: 10,855.44637

Timestep Collection Time: 2.17832
Timestep Consumption Time: 2.42969
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.60801

Cumulative Model Updates: 190,166
Cumulative Timesteps: 1,585,820,698

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1585820698...
Checkpoint 1585820698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.70402
Value Function Loss: 0.01579

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11937
Policy Update Magnitude: 0.36234
Value Function Update Magnitude: 0.40193

Collected Steps per Second: 22,966.45551
Overall Steps per Second: 10,838.84651

Timestep Collection Time: 2.17831
Timestep Consumption Time: 2.43731
PPO Batch Consumption Time: 0.28771
Total Iteration Time: 4.61562

Cumulative Model Updates: 190,172
Cumulative Timesteps: 1,585,870,726

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.69270
Value Function Loss: 0.01609

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11935
Policy Update Magnitude: 0.36584
Value Function Update Magnitude: 0.45588

Collected Steps per Second: 22,804.59183
Overall Steps per Second: 10,727.43694

Timestep Collection Time: 2.19324
Timestep Consumption Time: 2.46919
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.66244

Cumulative Model Updates: 190,178
Cumulative Timesteps: 1,585,920,742

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1585920742...
Checkpoint 1585920742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.69532
Value Function Loss: 0.01670

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12589
Policy Update Magnitude: 0.34455
Value Function Update Magnitude: 0.43327

Collected Steps per Second: 23,029.17167
Overall Steps per Second: 10,733.40077

Timestep Collection Time: 2.17211
Timestep Consumption Time: 2.48829
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.66041

Cumulative Model Updates: 190,184
Cumulative Timesteps: 1,585,970,764

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.68632
Value Function Loss: 0.01844

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12339
Policy Update Magnitude: 0.38443
Value Function Update Magnitude: 0.48218

Collected Steps per Second: 22,911.00929
Overall Steps per Second: 10,757.23542

Timestep Collection Time: 2.18288
Timestep Consumption Time: 2.46627
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.64915

Cumulative Model Updates: 190,190
Cumulative Timesteps: 1,586,020,776

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1586020776...
Checkpoint 1586020776 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.69856
Value Function Loss: 0.01765

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.43110
Value Function Update Magnitude: 0.59624

Collected Steps per Second: 22,534.46782
Overall Steps per Second: 10,667.25106

Timestep Collection Time: 2.21882
Timestep Consumption Time: 2.46842
PPO Batch Consumption Time: 0.28726
Total Iteration Time: 4.68724

Cumulative Model Updates: 190,196
Cumulative Timesteps: 1,586,070,776

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.70948
Value Function Loss: 0.01681

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.39324
Value Function Update Magnitude: 0.51200

Collected Steps per Second: 23,138.65256
Overall Steps per Second: 10,944.66058

Timestep Collection Time: 2.16158
Timestep Consumption Time: 2.40832
PPO Batch Consumption Time: 0.27570
Total Iteration Time: 4.56990

Cumulative Model Updates: 190,202
Cumulative Timesteps: 1,586,120,792

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1586120792...
Checkpoint 1586120792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.70509
Value Function Loss: 0.01717

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.35866
Value Function Update Magnitude: 0.37186

Collected Steps per Second: 22,608.01938
Overall Steps per Second: 10,654.37033

Timestep Collection Time: 2.21214
Timestep Consumption Time: 2.48190
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.69404

Cumulative Model Updates: 190,208
Cumulative Timesteps: 1,586,170,804

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.69984
Value Function Loss: 0.01771

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11819
Policy Update Magnitude: 0.36532
Value Function Update Magnitude: 0.35581

Collected Steps per Second: 22,804.70212
Overall Steps per Second: 10,800.81800

Timestep Collection Time: 2.19376
Timestep Consumption Time: 2.43811
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.63187

Cumulative Model Updates: 190,214
Cumulative Timesteps: 1,586,220,832

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1586220832...
Checkpoint 1586220832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.68993
Value Function Loss: 0.01787

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.34787
Value Function Update Magnitude: 0.35828

Collected Steps per Second: 22,362.35172
Overall Steps per Second: 10,710.00266

Timestep Collection Time: 2.23715
Timestep Consumption Time: 2.43399
PPO Batch Consumption Time: 0.28051
Total Iteration Time: 4.67115

Cumulative Model Updates: 190,220
Cumulative Timesteps: 1,586,270,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.71050
Value Function Loss: 0.01737

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12021
Policy Update Magnitude: 0.32286
Value Function Update Magnitude: 0.27877

Collected Steps per Second: 22,798.76913
Overall Steps per Second: 10,853.37446

Timestep Collection Time: 2.19328
Timestep Consumption Time: 2.41395
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.60723

Cumulative Model Updates: 190,226
Cumulative Timesteps: 1,586,320,864

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1586320864...
Checkpoint 1586320864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.71729
Value Function Loss: 0.01925

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.11260
Policy Update Magnitude: 0.32303
Value Function Update Magnitude: 0.24730

Collected Steps per Second: 22,653.37625
Overall Steps per Second: 10,667.36278

Timestep Collection Time: 2.20726
Timestep Consumption Time: 2.48012
PPO Batch Consumption Time: 0.28909
Total Iteration Time: 4.68738

Cumulative Model Updates: 190,232
Cumulative Timesteps: 1,586,370,866

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.71752
Value Function Loss: 0.01781

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12024
Policy Update Magnitude: 0.32943
Value Function Update Magnitude: 0.24946

Collected Steps per Second: 22,039.57480
Overall Steps per Second: 10,823.16133

Timestep Collection Time: 2.26883
Timestep Consumption Time: 2.35126
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.62009

Cumulative Model Updates: 190,238
Cumulative Timesteps: 1,586,420,870

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1586420870...
Checkpoint 1586420870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.70311
Value Function Loss: 0.01824

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.33368
Value Function Update Magnitude: 0.26989

Collected Steps per Second: 22,167.84167
Overall Steps per Second: 10,731.00699

Timestep Collection Time: 2.25579
Timestep Consumption Time: 2.40416
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.65995

Cumulative Model Updates: 190,244
Cumulative Timesteps: 1,586,470,876

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.71216
Value Function Loss: 0.01473

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.35361
Value Function Update Magnitude: 0.27385

Collected Steps per Second: 22,396.07467
Overall Steps per Second: 10,808.16821

Timestep Collection Time: 2.23370
Timestep Consumption Time: 2.39484
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.62854

Cumulative Model Updates: 190,250
Cumulative Timesteps: 1,586,520,902

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1586520902...
Checkpoint 1586520902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.71246
Value Function Loss: 0.01457

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.12142
Policy Update Magnitude: 0.34133
Value Function Update Magnitude: 0.26603

Collected Steps per Second: 22,586.03762
Overall Steps per Second: 10,720.76074

Timestep Collection Time: 2.21402
Timestep Consumption Time: 2.45039
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.66441

Cumulative Model Updates: 190,256
Cumulative Timesteps: 1,586,570,908

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.70333
Value Function Loss: 0.01428

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.11445
Policy Update Magnitude: 0.34041
Value Function Update Magnitude: 0.27427

Collected Steps per Second: 22,984.59212
Overall Steps per Second: 10,914.67547

Timestep Collection Time: 2.17572
Timestep Consumption Time: 2.40600
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.58172

Cumulative Model Updates: 190,262
Cumulative Timesteps: 1,586,620,916

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1586620916...
Checkpoint 1586620916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.69263
Value Function Loss: 0.01609

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12160
Policy Update Magnitude: 0.35856
Value Function Update Magnitude: 0.27614

Collected Steps per Second: 22,880.72469
Overall Steps per Second: 10,685.76654

Timestep Collection Time: 2.18551
Timestep Consumption Time: 2.49418
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.67968

Cumulative Model Updates: 190,268
Cumulative Timesteps: 1,586,670,922

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.68907
Value Function Loss: 0.01813

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12657
Policy Update Magnitude: 0.35516
Value Function Update Magnitude: 0.25919

Collected Steps per Second: 22,894.98799
Overall Steps per Second: 10,838.70894

Timestep Collection Time: 2.18406
Timestep Consumption Time: 2.42941
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.61346

Cumulative Model Updates: 190,274
Cumulative Timesteps: 1,586,720,926

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1586720926...
Checkpoint 1586720926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.68585
Value Function Loss: 0.01848

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12373
Policy Update Magnitude: 0.35336
Value Function Update Magnitude: 0.23985

Collected Steps per Second: 22,962.07350
Overall Steps per Second: 10,712.77123

Timestep Collection Time: 2.17750
Timestep Consumption Time: 2.48982
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.66733

Cumulative Model Updates: 190,280
Cumulative Timesteps: 1,586,770,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.68522
Value Function Loss: 0.02138

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12198
Policy Update Magnitude: 0.38574
Value Function Update Magnitude: 0.25865

Collected Steps per Second: 22,672.35570
Overall Steps per Second: 10,801.92150

Timestep Collection Time: 2.20771
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.63381

Cumulative Model Updates: 190,286
Cumulative Timesteps: 1,586,820,980

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1586820980...
Checkpoint 1586820980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.66580
Value Function Loss: 0.02231

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12037
Policy Update Magnitude: 0.44481
Value Function Update Magnitude: 0.34491

Collected Steps per Second: 22,802.62609
Overall Steps per Second: 10,684.32661

Timestep Collection Time: 2.19369
Timestep Consumption Time: 2.48812
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.68181

Cumulative Model Updates: 190,292
Cumulative Timesteps: 1,586,871,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.67498
Value Function Loss: 0.02115

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.45058
Value Function Update Magnitude: 0.37820

Collected Steps per Second: 22,960.59001
Overall Steps per Second: 10,871.41510

Timestep Collection Time: 2.17782
Timestep Consumption Time: 2.42177
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.59959

Cumulative Model Updates: 190,298
Cumulative Timesteps: 1,586,921,006

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1586921006...
Checkpoint 1586921006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.67140
Value Function Loss: 0.02169

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.43858
Value Function Update Magnitude: 0.35486

Collected Steps per Second: 22,622.50480
Overall Steps per Second: 10,704.48711

Timestep Collection Time: 2.21134
Timestep Consumption Time: 2.46203
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.67337

Cumulative Model Updates: 190,304
Cumulative Timesteps: 1,586,971,032

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.69075
Value Function Loss: 0.02082

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12134
Policy Update Magnitude: 0.43801
Value Function Update Magnitude: 0.35968

Collected Steps per Second: 22,915.17724
Overall Steps per Second: 10,863.47111

Timestep Collection Time: 2.18275
Timestep Consumption Time: 2.42149
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.60424

Cumulative Model Updates: 190,310
Cumulative Timesteps: 1,587,021,050

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1587021050...
Checkpoint 1587021050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.68279
Value Function Loss: 0.02211

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12336
Policy Update Magnitude: 0.43822
Value Function Update Magnitude: 0.35754

Collected Steps per Second: 22,834.55111
Overall Steps per Second: 10,675.62970

Timestep Collection Time: 2.18993
Timestep Consumption Time: 2.49420
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.68413

Cumulative Model Updates: 190,316
Cumulative Timesteps: 1,587,071,056

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,188.97907
Policy Entropy: 3.68750
Value Function Loss: 0.01961

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11849
Policy Update Magnitude: 0.42037
Value Function Update Magnitude: 0.30514

Collected Steps per Second: 23,140.54115
Overall Steps per Second: 10,935.46532

Timestep Collection Time: 2.16114
Timestep Consumption Time: 2.41205
PPO Batch Consumption Time: 0.27665
Total Iteration Time: 4.57319

Cumulative Model Updates: 190,322
Cumulative Timesteps: 1,587,121,066

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1587121066...
Checkpoint 1587121066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 706,210.05256
Policy Entropy: 3.68618
Value Function Loss: 0.02173

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11790
Policy Update Magnitude: 0.43151
Value Function Update Magnitude: 0.39722

Collected Steps per Second: 22,167.53321
Overall Steps per Second: 10,681.86229

Timestep Collection Time: 2.25627
Timestep Consumption Time: 2.42606
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.68233

Cumulative Model Updates: 190,328
Cumulative Timesteps: 1,587,171,082

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 344,296.50768
Policy Entropy: 3.68759
Value Function Loss: 0.03006

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12082
Policy Update Magnitude: 0.54028
Value Function Update Magnitude: 0.59560

Collected Steps per Second: 22,028.30662
Overall Steps per Second: 10,825.09542

Timestep Collection Time: 2.27090
Timestep Consumption Time: 2.35022
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.62111

Cumulative Model Updates: 190,334
Cumulative Timesteps: 1,587,221,106

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1587221106...
Checkpoint 1587221106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204,769.41492
Policy Entropy: 3.69351
Value Function Loss: 0.03744

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12098
Policy Update Magnitude: 0.60130
Value Function Update Magnitude: 0.59414

Collected Steps per Second: 22,065.47779
Overall Steps per Second: 10,643.66699

Timestep Collection Time: 2.26734
Timestep Consumption Time: 2.43310
PPO Batch Consumption Time: 0.29106
Total Iteration Time: 4.70045

Cumulative Model Updates: 190,340
Cumulative Timesteps: 1,587,271,136

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,955.33996
Policy Entropy: 3.69055
Value Function Loss: 0.03832

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.61868
Value Function Update Magnitude: 0.59476

Collected Steps per Second: 22,300.71827
Overall Steps per Second: 10,621.56369

Timestep Collection Time: 2.24235
Timestep Consumption Time: 2.46562
PPO Batch Consumption Time: 0.28860
Total Iteration Time: 4.70797

Cumulative Model Updates: 190,346
Cumulative Timesteps: 1,587,321,142

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1587321142...
Checkpoint 1587321142 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,955.33996
Policy Entropy: 3.69748
Value Function Loss: 0.03091

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12800
Policy Update Magnitude: 0.56505
Value Function Update Magnitude: 0.56105

Collected Steps per Second: 22,860.29135
Overall Steps per Second: 10,915.72692

Timestep Collection Time: 2.18807
Timestep Consumption Time: 2.39431
PPO Batch Consumption Time: 0.27782
Total Iteration Time: 4.58238

Cumulative Model Updates: 190,352
Cumulative Timesteps: 1,587,371,162

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,442.90526
Policy Entropy: 3.69488
Value Function Loss: 0.02697

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12751
Policy Update Magnitude: 0.49745
Value Function Update Magnitude: 0.53176

Collected Steps per Second: 22,646.99062
Overall Steps per Second: 10,850.23325

Timestep Collection Time: 2.20886
Timestep Consumption Time: 2.40155
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.61041

Cumulative Model Updates: 190,358
Cumulative Timesteps: 1,587,421,186

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1587421186...
Checkpoint 1587421186 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,724.21207
Policy Entropy: 3.69704
Value Function Loss: 0.02286

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12556
Policy Update Magnitude: 0.46591
Value Function Update Magnitude: 0.56406

Collected Steps per Second: 22,207.23287
Overall Steps per Second: 10,693.63524

Timestep Collection Time: 2.25197
Timestep Consumption Time: 2.42464
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.67661

Cumulative Model Updates: 190,364
Cumulative Timesteps: 1,587,471,196

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,724.21207
Policy Entropy: 3.68747
Value Function Loss: 0.02530

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.47001
Value Function Update Magnitude: 0.64227

Collected Steps per Second: 22,939.22541
Overall Steps per Second: 10,869.24864

Timestep Collection Time: 2.18002
Timestep Consumption Time: 2.42085
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.60087

Cumulative Model Updates: 190,370
Cumulative Timesteps: 1,587,521,204

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1587521204...
Checkpoint 1587521204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,724.21207
Policy Entropy: 3.67375
Value Function Loss: 0.02554

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.46343
Value Function Update Magnitude: 0.63398

Collected Steps per Second: 22,663.28481
Overall Steps per Second: 10,723.71944

Timestep Collection Time: 2.20727
Timestep Consumption Time: 2.45753
PPO Batch Consumption Time: 0.28361
Total Iteration Time: 4.66480

Cumulative Model Updates: 190,376
Cumulative Timesteps: 1,587,571,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,724.21207
Policy Entropy: 3.66969
Value Function Loss: 0.02575

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.13503
Policy Update Magnitude: 0.44668
Value Function Update Magnitude: 0.61583

Collected Steps per Second: 23,069.44055
Overall Steps per Second: 10,881.17144

Timestep Collection Time: 2.16772
Timestep Consumption Time: 2.42811
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.59583

Cumulative Model Updates: 190,382
Cumulative Timesteps: 1,587,621,236

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1587621236...
Checkpoint 1587621236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 585,944.56311
Policy Entropy: 3.67249
Value Function Loss: 0.02502

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13382
Policy Update Magnitude: 0.44863
Value Function Update Magnitude: 0.44708

Collected Steps per Second: 22,494.12502
Overall Steps per Second: 10,669.18638

Timestep Collection Time: 2.22414
Timestep Consumption Time: 2.46507
PPO Batch Consumption Time: 0.28622
Total Iteration Time: 4.68920

Cumulative Model Updates: 190,388
Cumulative Timesteps: 1,587,671,266

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 765,921.91307
Policy Entropy: 3.69112
Value Function Loss: 0.02523

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12655
Policy Update Magnitude: 0.43373
Value Function Update Magnitude: 0.38154

Collected Steps per Second: 22,972.04942
Overall Steps per Second: 10,910.85033

Timestep Collection Time: 2.17769
Timestep Consumption Time: 2.40729
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.58498

Cumulative Model Updates: 190,394
Cumulative Timesteps: 1,587,721,292

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1587721292...
Checkpoint 1587721292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,392.97159
Policy Entropy: 3.70414
Value Function Loss: 0.02550

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13390
Policy Update Magnitude: 0.44362
Value Function Update Magnitude: 0.42147

Collected Steps per Second: 21,957.13994
Overall Steps per Second: 10,669.16114

Timestep Collection Time: 2.27789
Timestep Consumption Time: 2.41001
PPO Batch Consumption Time: 0.29142
Total Iteration Time: 4.68790

Cumulative Model Updates: 190,400
Cumulative Timesteps: 1,587,771,308

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 620,392.97159
Policy Entropy: 3.70618
Value Function Loss: 0.02325

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13486
Policy Update Magnitude: 0.45245
Value Function Update Magnitude: 0.43329

Collected Steps per Second: 22,037.51708
Overall Steps per Second: 10,840.65641

Timestep Collection Time: 2.27013
Timestep Consumption Time: 2.34472
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.61485

Cumulative Model Updates: 190,406
Cumulative Timesteps: 1,587,821,336

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1587821336...
Checkpoint 1587821336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 620,392.97159
Policy Entropy: 3.69519
Value Function Loss: 0.02387

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12734
Policy Update Magnitude: 0.45197
Value Function Update Magnitude: 0.42313

Collected Steps per Second: 21,882.57913
Overall Steps per Second: 10,666.93945

Timestep Collection Time: 2.28547
Timestep Consumption Time: 2.40303
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.68851

Cumulative Model Updates: 190,412
Cumulative Timesteps: 1,587,871,348

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,990.73526
Policy Entropy: 3.70539
Value Function Loss: 0.02193

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13316
Policy Update Magnitude: 0.50981
Value Function Update Magnitude: 0.45727

Collected Steps per Second: 22,744.97621
Overall Steps per Second: 10,890.63264

Timestep Collection Time: 2.19846
Timestep Consumption Time: 2.39301
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.59147

Cumulative Model Updates: 190,418
Cumulative Timesteps: 1,587,921,352

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1587921352...
Checkpoint 1587921352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330,990.73526
Policy Entropy: 3.68518
Value Function Loss: 0.02732

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.16245
Policy Update Magnitude: 0.52454
Value Function Update Magnitude: 0.45208

Collected Steps per Second: 22,731.63460
Overall Steps per Second: 10,736.54714

Timestep Collection Time: 2.20037
Timestep Consumption Time: 2.45830
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.65867

Cumulative Model Updates: 190,424
Cumulative Timesteps: 1,587,971,370

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 330,990.73526
Policy Entropy: 3.66324
Value Function Loss: 0.03571

Mean KL Divergence: 0.01332
SB3 Clip Fraction: 0.17091
Policy Update Magnitude: 0.50711
Value Function Update Magnitude: 0.44203

Collected Steps per Second: 22,817.47923
Overall Steps per Second: 10,818.62384

Timestep Collection Time: 2.19209
Timestep Consumption Time: 2.43123
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.62332

Cumulative Model Updates: 190,430
Cumulative Timesteps: 1,588,021,388

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1588021388...
Checkpoint 1588021388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 330,990.73526
Policy Entropy: 3.65293
Value Function Loss: 0.03984

Mean KL Divergence: 0.01287
SB3 Clip Fraction: 0.16024
Policy Update Magnitude: 0.53873
Value Function Update Magnitude: 0.36344

Collected Steps per Second: 22,442.37612
Overall Steps per Second: 10,640.72884

Timestep Collection Time: 2.22802
Timestep Consumption Time: 2.47110
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.69911

Cumulative Model Updates: 190,436
Cumulative Timesteps: 1,588,071,390

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 998,651.44582
Policy Entropy: 3.65702
Value Function Loss: 0.03937

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14760
Policy Update Magnitude: 0.56814
Value Function Update Magnitude: 0.38369

Collected Steps per Second: 22,652.77771
Overall Steps per Second: 10,817.55361

Timestep Collection Time: 2.20750
Timestep Consumption Time: 2.41517
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.62267

Cumulative Model Updates: 190,442
Cumulative Timesteps: 1,588,121,396

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1588121396...
Checkpoint 1588121396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 545,085.40161
Policy Entropy: 3.69180
Value Function Loss: 0.04090

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13233
Policy Update Magnitude: 0.60676
Value Function Update Magnitude: 0.42869

Collected Steps per Second: 22,291.63003
Overall Steps per Second: 10,710.58795

Timestep Collection Time: 2.24326
Timestep Consumption Time: 2.42557
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.66884

Cumulative Model Updates: 190,448
Cumulative Timesteps: 1,588,171,402

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 346,351.94465
Policy Entropy: 3.70070
Value Function Loss: 0.04090

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.59724
Value Function Update Magnitude: 0.46795

Collected Steps per Second: 22,887.59935
Overall Steps per Second: 10,844.62912

Timestep Collection Time: 2.18564
Timestep Consumption Time: 2.42715
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.61279

Cumulative Model Updates: 190,454
Cumulative Timesteps: 1,588,221,426

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1588221426...
Checkpoint 1588221426 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.70370
Value Function Loss: 0.03694

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.59770
Value Function Update Magnitude: 0.54514

Collected Steps per Second: 22,521.18695
Overall Steps per Second: 10,792.97906

Timestep Collection Time: 2.22093
Timestep Consumption Time: 2.41338
PPO Batch Consumption Time: 0.27649
Total Iteration Time: 4.63431

Cumulative Model Updates: 190,460
Cumulative Timesteps: 1,588,271,444

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.69300
Value Function Loss: 0.03039

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13081
Policy Update Magnitude: 0.60710
Value Function Update Magnitude: 0.61664

Collected Steps per Second: 22,887.91252
Overall Steps per Second: 10,891.14060

Timestep Collection Time: 2.18508
Timestep Consumption Time: 2.40691
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.59199

Cumulative Model Updates: 190,466
Cumulative Timesteps: 1,588,321,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1588321456...
Checkpoint 1588321456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.69802
Value Function Loss: 0.02334

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12785
Policy Update Magnitude: 0.52572
Value Function Update Magnitude: 0.63563

Collected Steps per Second: 22,629.29181
Overall Steps per Second: 10,632.10707

Timestep Collection Time: 2.20961
Timestep Consumption Time: 2.49331
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.70292

Cumulative Model Updates: 190,472
Cumulative Timesteps: 1,588,371,458

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.70157
Value Function Loss: 0.02234

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12070
Policy Update Magnitude: 0.45836
Value Function Update Magnitude: 0.56736

Collected Steps per Second: 22,862.40889
Overall Steps per Second: 10,849.70124

Timestep Collection Time: 2.18717
Timestep Consumption Time: 2.42162
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.60879

Cumulative Model Updates: 190,478
Cumulative Timesteps: 1,588,421,462

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1588421462...
Checkpoint 1588421462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.69734
Value Function Loss: 0.02160

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11718
Policy Update Magnitude: 0.46286
Value Function Update Magnitude: 0.49771

Collected Steps per Second: 22,698.13509
Overall Steps per Second: 10,664.41974

Timestep Collection Time: 2.20388
Timestep Consumption Time: 2.48686
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.69074

Cumulative Model Updates: 190,484
Cumulative Timesteps: 1,588,471,486

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.67453
Value Function Loss: 0.02456

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.48374
Value Function Update Magnitude: 0.47599

Collected Steps per Second: 22,819.42010
Overall Steps per Second: 10,839.47438

Timestep Collection Time: 2.19199
Timestep Consumption Time: 2.42262
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.61461

Cumulative Model Updates: 190,490
Cumulative Timesteps: 1,588,521,506

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1588521506...
Checkpoint 1588521506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.68636
Value Function Loss: 0.02304

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.44176
Value Function Update Magnitude: 0.53096

Collected Steps per Second: 22,799.46353
Overall Steps per Second: 10,728.57227

Timestep Collection Time: 2.19321
Timestep Consumption Time: 2.46762
PPO Batch Consumption Time: 0.28730
Total Iteration Time: 4.66083

Cumulative Model Updates: 190,496
Cumulative Timesteps: 1,588,571,510

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.70531
Value Function Loss: 0.02027

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15742
Policy Update Magnitude: 0.43930
Value Function Update Magnitude: 0.56546

Collected Steps per Second: 23,221.77524
Overall Steps per Second: 10,870.43741

Timestep Collection Time: 2.15384
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.60110

Cumulative Model Updates: 190,502
Cumulative Timesteps: 1,588,621,526

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1588621526...
Checkpoint 1588621526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.73036
Value Function Loss: 0.01734

Mean KL Divergence: 0.01009
SB3 Clip Fraction: 0.13726
Policy Update Magnitude: 0.38964
Value Function Update Magnitude: 0.44845

Collected Steps per Second: 22,761.13405
Overall Steps per Second: 10,660.16686

Timestep Collection Time: 2.19673
Timestep Consumption Time: 2.49363
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.69036

Cumulative Model Updates: 190,508
Cumulative Timesteps: 1,588,671,526

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.73884
Value Function Loss: 0.01411

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13415
Policy Update Magnitude: 0.34094
Value Function Update Magnitude: 0.34019

Collected Steps per Second: 23,238.64673
Overall Steps per Second: 10,983.31891

Timestep Collection Time: 2.15202
Timestep Consumption Time: 2.40125
PPO Batch Consumption Time: 0.27545
Total Iteration Time: 4.55327

Cumulative Model Updates: 190,514
Cumulative Timesteps: 1,588,721,536

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1588721536...
Checkpoint 1588721536 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.71526
Value Function Loss: 0.01363

Mean KL Divergence: 0.01093
SB3 Clip Fraction: 0.14608
Policy Update Magnitude: 0.30859
Value Function Update Magnitude: 0.31482

Collected Steps per Second: 22,793.61070
Overall Steps per Second: 10,754.13686

Timestep Collection Time: 2.19465
Timestep Consumption Time: 2.45696
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.65161

Cumulative Model Updates: 190,520
Cumulative Timesteps: 1,588,771,560

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 227,241.75286
Policy Entropy: 3.70684
Value Function Loss: 0.01528

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12943
Policy Update Magnitude: 0.35428
Value Function Update Magnitude: 0.45844

Collected Steps per Second: 22,553.68757
Overall Steps per Second: 10,771.86953

Timestep Collection Time: 2.21720
Timestep Consumption Time: 2.42508
PPO Batch Consumption Time: 0.29157
Total Iteration Time: 4.64228

Cumulative Model Updates: 190,526
Cumulative Timesteps: 1,588,821,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1588821566...
Checkpoint 1588821566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 780,939.71461
Policy Entropy: 3.69267
Value Function Loss: 0.02040

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.44447
Value Function Update Magnitude: 0.72250

Collected Steps per Second: 21,812.63046
Overall Steps per Second: 10,619.71563

Timestep Collection Time: 2.29225
Timestep Consumption Time: 2.41597
PPO Batch Consumption Time: 0.29176
Total Iteration Time: 4.70822

Cumulative Model Updates: 190,532
Cumulative Timesteps: 1,588,871,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,579.53932
Policy Entropy: 3.70540
Value Function Loss: 0.02088

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11994
Policy Update Magnitude: 0.49841
Value Function Update Magnitude: 0.79924

Collected Steps per Second: 22,436.75428
Overall Steps per Second: 10,796.97265

Timestep Collection Time: 2.22866
Timestep Consumption Time: 2.40263
PPO Batch Consumption Time: 0.27721
Total Iteration Time: 4.63130

Cumulative Model Updates: 190,538
Cumulative Timesteps: 1,588,921,570

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1588921570...
Checkpoint 1588921570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,579.53932
Policy Entropy: 3.70432
Value Function Loss: 0.02388

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.47462
Value Function Update Magnitude: 0.64233

Collected Steps per Second: 22,253.91804
Overall Steps per Second: 10,713.12316

Timestep Collection Time: 2.24733
Timestep Consumption Time: 2.42096
PPO Batch Consumption Time: 0.28292
Total Iteration Time: 4.66829

Cumulative Model Updates: 190,544
Cumulative Timesteps: 1,588,971,582

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,579.53932
Policy Entropy: 3.71429
Value Function Loss: 0.02111

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12844
Policy Update Magnitude: 0.46737
Value Function Update Magnitude: 0.50569

Collected Steps per Second: 22,917.27593
Overall Steps per Second: 10,958.93725

Timestep Collection Time: 2.18228
Timestep Consumption Time: 2.38130
PPO Batch Consumption Time: 0.27611
Total Iteration Time: 4.56358

Cumulative Model Updates: 190,550
Cumulative Timesteps: 1,589,021,594

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1589021594...
Checkpoint 1589021594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,579.53932
Policy Entropy: 3.70542
Value Function Loss: 0.02006

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13076
Policy Update Magnitude: 0.46106
Value Function Update Magnitude: 0.53939

Collected Steps per Second: 22,567.85669
Overall Steps per Second: 10,610.64448

Timestep Collection Time: 2.21563
Timestep Consumption Time: 2.49681
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.71244

Cumulative Model Updates: 190,556
Cumulative Timesteps: 1,589,071,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,579.53932
Policy Entropy: 3.72198
Value Function Loss: 0.01759

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.41781
Value Function Update Magnitude: 0.44340

Collected Steps per Second: 23,367.58015
Overall Steps per Second: 10,887.70181

Timestep Collection Time: 2.14074
Timestep Consumption Time: 2.45380
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.59454

Cumulative Model Updates: 190,562
Cumulative Timesteps: 1,589,121,620

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1589121620...
Checkpoint 1589121620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,579.53932
Policy Entropy: 3.72053
Value Function Loss: 0.01668

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12788
Policy Update Magnitude: 0.35539
Value Function Update Magnitude: 0.32981

Collected Steps per Second: 22,479.65882
Overall Steps per Second: 10,637.11708

Timestep Collection Time: 2.22494
Timestep Consumption Time: 2.47708
PPO Batch Consumption Time: 0.28560
Total Iteration Time: 4.70203

Cumulative Model Updates: 190,568
Cumulative Timesteps: 1,589,171,636

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,579.53932
Policy Entropy: 3.73513
Value Function Loss: 0.01414

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11822
Policy Update Magnitude: 0.34067
Value Function Update Magnitude: 0.29128

Collected Steps per Second: 23,169.09064
Overall Steps per Second: 10,907.54004

Timestep Collection Time: 2.15891
Timestep Consumption Time: 2.42691
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.58582

Cumulative Model Updates: 190,574
Cumulative Timesteps: 1,589,221,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1589221656...
Checkpoint 1589221656 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 632,579.53932
Policy Entropy: 3.72633
Value Function Loss: 0.01432

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12838
Policy Update Magnitude: 0.34707
Value Function Update Magnitude: 0.32281

Collected Steps per Second: 22,330.35914
Overall Steps per Second: 10,640.68654

Timestep Collection Time: 2.24000
Timestep Consumption Time: 2.46082
PPO Batch Consumption Time: 0.28415
Total Iteration Time: 4.70082

Cumulative Model Updates: 190,580
Cumulative Timesteps: 1,589,271,676

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 632,579.53932
Policy Entropy: 3.71795
Value Function Loss: 0.01542

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11795
Policy Update Magnitude: 0.35716
Value Function Update Magnitude: 0.33736

Collected Steps per Second: 23,168.46499
Overall Steps per Second: 10,911.16875

Timestep Collection Time: 2.15897
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.58429

Cumulative Model Updates: 190,586
Cumulative Timesteps: 1,589,321,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1589321696...
Checkpoint 1589321696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 676,237.12176
Policy Entropy: 3.71168
Value Function Loss: 0.01774

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.11947
Policy Update Magnitude: 0.41147
Value Function Update Magnitude: 0.45327

Collected Steps per Second: 23,066.73453
Overall Steps per Second: 10,718.87610

Timestep Collection Time: 2.16797
Timestep Consumption Time: 2.49744
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.66541

Cumulative Model Updates: 190,592
Cumulative Timesteps: 1,589,371,704

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 547,762.03340
Policy Entropy: 3.71091
Value Function Loss: 0.01848

Mean KL Divergence: 0.01039
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.43659
Value Function Update Magnitude: 0.60755

Collected Steps per Second: 23,187.04501
Overall Steps per Second: 10,816.41197

Timestep Collection Time: 2.15646
Timestep Consumption Time: 2.46633
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.62279

Cumulative Model Updates: 190,598
Cumulative Timesteps: 1,589,421,706

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1589421706...
Checkpoint 1589421706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,793.41706
Policy Entropy: 3.70834
Value Function Loss: 0.01866

Mean KL Divergence: 0.02242
SB3 Clip Fraction: 0.25841
Policy Update Magnitude: 0.39396
Value Function Update Magnitude: 0.66148

Collected Steps per Second: 22,560.17871
Overall Steps per Second: 10,648.67535

Timestep Collection Time: 2.21629
Timestep Consumption Time: 2.47913
PPO Batch Consumption Time: 0.28631
Total Iteration Time: 4.69542

Cumulative Model Updates: 190,604
Cumulative Timesteps: 1,589,471,706

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 587,793.41706
Policy Entropy: 3.66815
Value Function Loss: 0.03673

Mean KL Divergence: 0.01505
SB3 Clip Fraction: 0.18152
Policy Update Magnitude: 0.42206
Value Function Update Magnitude: 0.53536

Collected Steps per Second: 22,515.92155
Overall Steps per Second: 10,461.14412

Timestep Collection Time: 2.22189
Timestep Consumption Time: 2.56037
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.78227

Cumulative Model Updates: 190,610
Cumulative Timesteps: 1,589,521,734

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1589521734...
Checkpoint 1589521734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 587,793.41706
Policy Entropy: 3.63374
Value Function Loss: 0.04811

Mean KL Divergence: 0.03280
SB3 Clip Fraction: 0.30193
Policy Update Magnitude: 0.51618
Value Function Update Magnitude: 0.38651

Collected Steps per Second: 22,611.09246
Overall Steps per Second: 10,716.52897

Timestep Collection Time: 2.21192
Timestep Consumption Time: 2.45507
PPO Batch Consumption Time: 0.28487
Total Iteration Time: 4.66700

Cumulative Model Updates: 190,616
Cumulative Timesteps: 1,589,571,748

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 994,233.18916
Policy Entropy: 3.60653
Value Function Loss: 0.08590

Mean KL Divergence: 0.02899
SB3 Clip Fraction: 0.26336
Policy Update Magnitude: 0.62168
Value Function Update Magnitude: 0.45071

Collected Steps per Second: 22,302.12163
Overall Steps per Second: 10,561.56919

Timestep Collection Time: 2.24221
Timestep Consumption Time: 2.49250
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.73471

Cumulative Model Updates: 190,622
Cumulative Timesteps: 1,589,621,754

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1589621754...
Checkpoint 1589621754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 420,241.53129
Policy Entropy: 3.64086
Value Function Loss: 0.09181

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.17469
Policy Update Magnitude: 1.14754
Value Function Update Magnitude: 0.61372

Collected Steps per Second: 22,561.21172
Overall Steps per Second: 10,627.33191

Timestep Collection Time: 2.21708
Timestep Consumption Time: 2.48965
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.70673

Cumulative Model Updates: 190,628
Cumulative Timesteps: 1,589,671,774

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 253,028.91022
Policy Entropy: 3.64665
Value Function Loss: 0.08534

Mean KL Divergence: 0.01610
SB3 Clip Fraction: 0.18398
Policy Update Magnitude: 1.37900
Value Function Update Magnitude: 0.71665

Collected Steps per Second: 22,875.90699
Overall Steps per Second: 10,814.19926

Timestep Collection Time: 2.18606
Timestep Consumption Time: 2.43824
PPO Batch Consumption Time: 0.28119
Total Iteration Time: 4.62429

Cumulative Model Updates: 190,634
Cumulative Timesteps: 1,589,721,782

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1589721782...
Checkpoint 1589721782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,096.10187
Policy Entropy: 3.71591
Value Function Loss: 0.05868

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.19990
Policy Update Magnitude: 1.19663
Value Function Update Magnitude: 0.90893

Collected Steps per Second: 22,392.20845
Overall Steps per Second: 10,634.49435

Timestep Collection Time: 2.23319
Timestep Consumption Time: 2.46906
PPO Batch Consumption Time: 0.28762
Total Iteration Time: 4.70225

Cumulative Model Updates: 190,640
Cumulative Timesteps: 1,589,771,788

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,644.06386
Policy Entropy: 3.74691
Value Function Loss: 0.04205

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.16379
Policy Update Magnitude: 0.99693
Value Function Update Magnitude: 0.95835

Collected Steps per Second: 23,010.87492
Overall Steps per Second: 10,882.48094

Timestep Collection Time: 2.17315
Timestep Consumption Time: 2.42195
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.59509

Cumulative Model Updates: 190,646
Cumulative Timesteps: 1,589,821,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1589821794...
Checkpoint 1589821794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 482.31485
Policy Entropy: 3.75319
Value Function Loss: 0.03469

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.16673
Policy Update Magnitude: 0.79232
Value Function Update Magnitude: 0.77793

Collected Steps per Second: 22,476.49853
Overall Steps per Second: 10,665.89880

Timestep Collection Time: 2.22544
Timestep Consumption Time: 2.46428
PPO Batch Consumption Time: 0.28634
Total Iteration Time: 4.68971

Cumulative Model Updates: 190,652
Cumulative Timesteps: 1,589,871,814

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421.53477
Policy Entropy: 3.72629
Value Function Loss: 0.02884

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.16496
Policy Update Magnitude: 0.66253
Value Function Update Magnitude: 0.67435

Collected Steps per Second: 23,081.59563
Overall Steps per Second: 10,899.62012

Timestep Collection Time: 2.16666
Timestep Consumption Time: 2.42157
PPO Batch Consumption Time: 0.27788
Total Iteration Time: 4.58823

Cumulative Model Updates: 190,658
Cumulative Timesteps: 1,589,921,824

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1589921824...
Checkpoint 1589921824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 403,046.62023
Policy Entropy: 3.68829
Value Function Loss: 0.03024

Mean KL Divergence: 0.01186
SB3 Clip Fraction: 0.15497
Policy Update Magnitude: 0.54575
Value Function Update Magnitude: 0.66303

Collected Steps per Second: 22,061.53169
Overall Steps per Second: 10,687.77868

Timestep Collection Time: 2.26766
Timestep Consumption Time: 2.41320
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.68086

Cumulative Model Updates: 190,664
Cumulative Timesteps: 1,589,971,852

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,849.02363
Policy Entropy: 3.68652
Value Function Loss: 0.03000

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13321
Policy Update Magnitude: 0.51036
Value Function Update Magnitude: 0.61270

Collected Steps per Second: 22,565.12412
Overall Steps per Second: 10,863.34816

Timestep Collection Time: 2.21643
Timestep Consumption Time: 2.38749
PPO Batch Consumption Time: 0.28273
Total Iteration Time: 4.60392

Cumulative Model Updates: 190,670
Cumulative Timesteps: 1,590,021,866

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1590021866...
Checkpoint 1590021866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,239.63844
Policy Entropy: 3.68474
Value Function Loss: 0.03215

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12058
Policy Update Magnitude: 0.55837
Value Function Update Magnitude: 0.48605

Collected Steps per Second: 22,059.08581
Overall Steps per Second: 10,658.11870

Timestep Collection Time: 2.26800
Timestep Consumption Time: 2.42607
PPO Batch Consumption Time: 0.29179
Total Iteration Time: 4.69407

Cumulative Model Updates: 190,676
Cumulative Timesteps: 1,590,071,896

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223,768.57918
Policy Entropy: 3.70718
Value Function Loss: 0.03022

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.16306
Policy Update Magnitude: 0.50113
Value Function Update Magnitude: 0.44054

Collected Steps per Second: 22,224.86441
Overall Steps per Second: 10,627.12017

Timestep Collection Time: 2.24982
Timestep Consumption Time: 2.45531
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.70513

Cumulative Model Updates: 190,682
Cumulative Timesteps: 1,590,121,898

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1590121898...
Checkpoint 1590121898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,351.47195
Policy Entropy: 3.70829
Value Function Loss: 0.02665

Mean KL Divergence: 0.01181
SB3 Clip Fraction: 0.15869
Policy Update Magnitude: 0.42914
Value Function Update Magnitude: 0.42096

Collected Steps per Second: 22,912.22321
Overall Steps per Second: 10,983.98270

Timestep Collection Time: 2.18233
Timestep Consumption Time: 2.36994
PPO Batch Consumption Time: 0.27581
Total Iteration Time: 4.55227

Cumulative Model Updates: 190,688
Cumulative Timesteps: 1,590,171,900

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,598.02852
Policy Entropy: 3.71789
Value Function Loss: 0.02141

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11622
Policy Update Magnitude: 0.38340
Value Function Update Magnitude: 0.44373

Collected Steps per Second: 23,211.33633
Overall Steps per Second: 10,812.77059

Timestep Collection Time: 2.15421
Timestep Consumption Time: 2.47014
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.62435

Cumulative Model Updates: 190,694
Cumulative Timesteps: 1,590,221,902

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1590221902...
Checkpoint 1590221902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,598.02852
Policy Entropy: 3.72163
Value Function Loss: 0.01833

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05191
Policy Update Magnitude: 0.41084
Value Function Update Magnitude: 0.47794

Collected Steps per Second: 22,691.50556
Overall Steps per Second: 10,638.34311

Timestep Collection Time: 2.20479
Timestep Consumption Time: 2.49801
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.70280

Cumulative Model Updates: 190,700
Cumulative Timesteps: 1,590,271,932

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,598.02852
Policy Entropy: 3.71980
Value Function Loss: 0.01524

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.38199
Value Function Update Magnitude: 0.40011

Collected Steps per Second: 23,021.26308
Overall Steps per Second: 10,892.27975

Timestep Collection Time: 2.17321
Timestep Consumption Time: 2.41995
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.59316

Cumulative Model Updates: 190,706
Cumulative Timesteps: 1,590,321,962

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1590321962...
Checkpoint 1590321962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,598.02852
Policy Entropy: 3.72700
Value Function Loss: 0.01344

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13935
Policy Update Magnitude: 0.29456
Value Function Update Magnitude: 0.31606

Collected Steps per Second: 22,846.75876
Overall Steps per Second: 10,690.38223

Timestep Collection Time: 2.18928
Timestep Consumption Time: 2.48950
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.67879

Cumulative Model Updates: 190,712
Cumulative Timesteps: 1,590,371,980

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,598.02852
Policy Entropy: 3.72085
Value Function Loss: 0.01314

Mean KL Divergence: 0.01129
SB3 Clip Fraction: 0.15241
Policy Update Magnitude: 0.28894
Value Function Update Magnitude: 0.31639

Collected Steps per Second: 22,850.74908
Overall Steps per Second: 10,831.21225

Timestep Collection Time: 2.18820
Timestep Consumption Time: 2.42827
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.61647

Cumulative Model Updates: 190,718
Cumulative Timesteps: 1,590,421,982

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1590421982...
Checkpoint 1590421982 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,598.02852
Policy Entropy: 3.69210
Value Function Loss: 0.02533

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15454
Policy Update Magnitude: 0.37959
Value Function Update Magnitude: 0.46437

Collected Steps per Second: 22,239.51597
Overall Steps per Second: 10,720.45984

Timestep Collection Time: 2.24834
Timestep Consumption Time: 2.41583
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.66417

Cumulative Model Updates: 190,724
Cumulative Timesteps: 1,590,471,984

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,598.02852
Policy Entropy: 3.68083
Value Function Loss: 0.02856

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13190
Policy Update Magnitude: 0.48715
Value Function Update Magnitude: 0.65297

Collected Steps per Second: 22,579.49518
Overall Steps per Second: 10,830.99431

Timestep Collection Time: 2.21546
Timestep Consumption Time: 2.40314
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.61860

Cumulative Model Updates: 190,730
Cumulative Timesteps: 1,590,522,008

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1590522008...
Checkpoint 1590522008 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,125.77670
Policy Entropy: 3.66700
Value Function Loss: 0.03975

Mean KL Divergence: 0.01254
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.57063
Value Function Update Magnitude: 0.70038

Collected Steps per Second: 22,522.14629
Overall Steps per Second: 10,709.96192

Timestep Collection Time: 2.22093
Timestep Consumption Time: 2.44949
PPO Batch Consumption Time: 0.28173
Total Iteration Time: 4.67042

Cumulative Model Updates: 190,736
Cumulative Timesteps: 1,590,572,028

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,693.39273
Policy Entropy: 3.67155
Value Function Loss: 0.04618

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.15676
Policy Update Magnitude: 0.65381
Value Function Update Magnitude: 0.61674

Collected Steps per Second: 22,848.35029
Overall Steps per Second: 10,842.27168

Timestep Collection Time: 2.18834
Timestep Consumption Time: 2.42324
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.61158

Cumulative Model Updates: 190,742
Cumulative Timesteps: 1,590,622,028

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1590622028...
Checkpoint 1590622028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 204,337.31201
Policy Entropy: 3.66632
Value Function Loss: 0.04979

Mean KL Divergence: 0.01685
SB3 Clip Fraction: 0.19779
Policy Update Magnitude: 0.64482
Value Function Update Magnitude: 0.43984

Collected Steps per Second: 21,600.79211
Overall Steps per Second: 10,760.82338

Timestep Collection Time: 2.31584
Timestep Consumption Time: 2.33287
PPO Batch Consumption Time: 0.27599
Total Iteration Time: 4.64871

Cumulative Model Updates: 190,748
Cumulative Timesteps: 1,590,672,052

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 71,249.83164
Policy Entropy: 3.67690
Value Function Loss: 0.04900

Mean KL Divergence: 0.01529
SB3 Clip Fraction: 0.18013
Policy Update Magnitude: 0.58843
Value Function Update Magnitude: 0.36738

Collected Steps per Second: 22,045.38663
Overall Steps per Second: 10,839.01228

Timestep Collection Time: 2.26877
Timestep Consumption Time: 2.34567
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.61444

Cumulative Model Updates: 190,754
Cumulative Timesteps: 1,590,722,068

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1590722068...
Checkpoint 1590722068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,881.21058
Policy Entropy: 3.69146
Value Function Loss: 0.04541

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14249
Policy Update Magnitude: 0.59361
Value Function Update Magnitude: 0.36382

Collected Steps per Second: 21,486.80938
Overall Steps per Second: 10,641.80196

Timestep Collection Time: 2.32822
Timestep Consumption Time: 2.37268
PPO Batch Consumption Time: 0.28221
Total Iteration Time: 4.70090

Cumulative Model Updates: 190,760
Cumulative Timesteps: 1,590,772,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239,050.13449
Policy Entropy: 3.66699
Value Function Loss: 0.05337

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.13582
Policy Update Magnitude: 0.62216
Value Function Update Magnitude: 0.43627

Collected Steps per Second: 22,481.71496
Overall Steps per Second: 10,808.74270

Timestep Collection Time: 2.22545
Timestep Consumption Time: 2.40339
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.62885

Cumulative Model Updates: 190,766
Cumulative Timesteps: 1,590,822,126

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1590822126...
Checkpoint 1590822126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,729.83184
Policy Entropy: 3.68581
Value Function Loss: 0.04957

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13052
Policy Update Magnitude: 0.67523
Value Function Update Magnitude: 0.51595

Collected Steps per Second: 22,188.90632
Overall Steps per Second: 10,765.52879

Timestep Collection Time: 2.25338
Timestep Consumption Time: 2.39108
PPO Batch Consumption Time: 0.27615
Total Iteration Time: 4.64445

Cumulative Model Updates: 190,772
Cumulative Timesteps: 1,590,872,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,566.62024
Policy Entropy: 3.70849
Value Function Loss: 0.04535

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.12942
Policy Update Magnitude: 0.67106
Value Function Update Magnitude: 0.57739

Collected Steps per Second: 22,876.30143
Overall Steps per Second: 10,941.88154

Timestep Collection Time: 2.18567
Timestep Consumption Time: 2.38393
PPO Batch Consumption Time: 0.27629
Total Iteration Time: 4.56960

Cumulative Model Updates: 190,778
Cumulative Timesteps: 1,590,922,126

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1590922126...
Checkpoint 1590922126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 148,566.62024
Policy Entropy: 3.71227
Value Function Loss: 0.03402

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.60347
Value Function Update Magnitude: 0.63073

Collected Steps per Second: 22,874.31061
Overall Steps per Second: 10,724.20641

Timestep Collection Time: 2.18656
Timestep Consumption Time: 2.47728
PPO Batch Consumption Time: 0.28991
Total Iteration Time: 4.66384

Cumulative Model Updates: 190,784
Cumulative Timesteps: 1,590,972,142

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963,873.86460
Policy Entropy: 3.71633
Value Function Loss: 0.02956

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.49812
Value Function Update Magnitude: 0.53454

Collected Steps per Second: 22,935.46953
Overall Steps per Second: 10,736.01003

Timestep Collection Time: 2.18055
Timestep Consumption Time: 2.47779
PPO Batch Consumption Time: 0.28668
Total Iteration Time: 4.65834

Cumulative Model Updates: 190,790
Cumulative Timesteps: 1,591,022,154

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1591022154...
Checkpoint 1591022154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963,873.86460
Policy Entropy: 3.70906
Value Function Loss: 0.02835

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.12106
Policy Update Magnitude: 0.43850
Value Function Update Magnitude: 0.42760

Collected Steps per Second: 22,282.38721
Overall Steps per Second: 10,630.32522

Timestep Collection Time: 2.24401
Timestep Consumption Time: 2.45970
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.70371

Cumulative Model Updates: 190,796
Cumulative Timesteps: 1,591,072,156

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963,873.86460
Policy Entropy: 3.72327
Value Function Loss: 0.02397

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13298
Policy Update Magnitude: 0.37345
Value Function Update Magnitude: 0.33917

Collected Steps per Second: 23,128.59485
Overall Steps per Second: 10,923.94581

Timestep Collection Time: 2.16183
Timestep Consumption Time: 2.41527
PPO Batch Consumption Time: 0.27742
Total Iteration Time: 4.57710

Cumulative Model Updates: 190,802
Cumulative Timesteps: 1,591,122,156

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1591122156...
Checkpoint 1591122156 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 963,873.86460
Policy Entropy: 3.70636
Value Function Loss: 0.02476

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.34261
Value Function Update Magnitude: 0.31236

Collected Steps per Second: 22,721.82384
Overall Steps per Second: 10,633.85333

Timestep Collection Time: 2.20062
Timestep Consumption Time: 2.50154
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.70215

Cumulative Model Updates: 190,808
Cumulative Timesteps: 1,591,172,158

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 963,873.86460
Policy Entropy: 3.70832
Value Function Loss: 0.02091

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.14162
Policy Update Magnitude: 0.33800
Value Function Update Magnitude: 0.33139

Collected Steps per Second: 23,188.87620
Overall Steps per Second: 10,909.59543

Timestep Collection Time: 2.15664
Timestep Consumption Time: 2.42740
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.58404

Cumulative Model Updates: 190,814
Cumulative Timesteps: 1,591,222,168

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1591222168...
Checkpoint 1591222168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 578,992.38691
Policy Entropy: 3.70454
Value Function Loss: 0.02288

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12184
Policy Update Magnitude: 0.35663
Value Function Update Magnitude: 0.43320

Collected Steps per Second: 22,644.43857
Overall Steps per Second: 10,629.15061

Timestep Collection Time: 2.20814
Timestep Consumption Time: 2.49610
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.70423

Cumulative Model Updates: 190,820
Cumulative Timesteps: 1,591,272,170

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254,354.26210
Policy Entropy: 3.72220
Value Function Loss: 0.02027

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12825
Policy Update Magnitude: 0.37296
Value Function Update Magnitude: 0.55838

Collected Steps per Second: 22,332.54664
Overall Steps per Second: 10,920.43811

Timestep Collection Time: 2.23996
Timestep Consumption Time: 2.34081
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.58077

Cumulative Model Updates: 190,826
Cumulative Timesteps: 1,591,322,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1591322194...
Checkpoint 1591322194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206,029.25931
Policy Entropy: 3.71193
Value Function Loss: 0.02306

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.38427
Value Function Update Magnitude: 0.67698

Collected Steps per Second: 21,936.25463
Overall Steps per Second: 10,653.70674

Timestep Collection Time: 2.28061
Timestep Consumption Time: 2.41522
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.69583

Cumulative Model Updates: 190,832
Cumulative Timesteps: 1,591,372,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 559,045.92069
Policy Entropy: 3.73207
Value Function Loss: 0.02079

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.39884
Value Function Update Magnitude: 0.65217

Collected Steps per Second: 22,256.09686
Overall Steps per Second: 10,861.52673

Timestep Collection Time: 2.24855
Timestep Consumption Time: 2.35890
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.60746

Cumulative Model Updates: 190,838
Cumulative Timesteps: 1,591,422,266

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1591422266...
Checkpoint 1591422266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 194,932.65619
Policy Entropy: 3.72445
Value Function Loss: 0.02183

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.13301
Policy Update Magnitude: 0.37111
Value Function Update Magnitude: 0.59672

Collected Steps per Second: 21,895.64553
Overall Steps per Second: 10,652.42628

Timestep Collection Time: 2.28383
Timestep Consumption Time: 2.41050
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.69433

Cumulative Model Updates: 190,844
Cumulative Timesteps: 1,591,472,272

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.74774
Value Function Loss: 0.01807

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11200
Policy Update Magnitude: 0.35217
Value Function Update Magnitude: 0.58447

Collected Steps per Second: 23,066.11827
Overall Steps per Second: 10,936.83213

Timestep Collection Time: 2.16777
Timestep Consumption Time: 2.40412
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.57189

Cumulative Model Updates: 190,850
Cumulative Timesteps: 1,591,522,274

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1591522274...
Checkpoint 1591522274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.72916
Value Function Loss: 0.01843

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05916
Policy Update Magnitude: 0.43340
Value Function Update Magnitude: 0.61212

Collected Steps per Second: 22,353.69551
Overall Steps per Second: 10,677.88815

Timestep Collection Time: 2.23775
Timestep Consumption Time: 2.44688
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.68463

Cumulative Model Updates: 190,856
Cumulative Timesteps: 1,591,572,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.71033
Value Function Loss: 0.01607

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06094
Policy Update Magnitude: 0.50187
Value Function Update Magnitude: 0.56474

Collected Steps per Second: 23,123.74514
Overall Steps per Second: 10,932.64425

Timestep Collection Time: 2.16323
Timestep Consumption Time: 2.41224
PPO Batch Consumption Time: 0.27600
Total Iteration Time: 4.57547

Cumulative Model Updates: 190,862
Cumulative Timesteps: 1,591,622,318

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1591622318...
Checkpoint 1591622318 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.68554
Value Function Loss: 0.01612

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06120
Policy Update Magnitude: 0.52757
Value Function Update Magnitude: 0.50773

Collected Steps per Second: 22,699.38222
Overall Steps per Second: 10,635.47834

Timestep Collection Time: 2.20358
Timestep Consumption Time: 2.49954
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.70313

Cumulative Model Updates: 190,868
Cumulative Timesteps: 1,591,672,338

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.69059
Value Function Loss: 0.01663

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07526
Policy Update Magnitude: 0.49002
Value Function Update Magnitude: 0.40355

Collected Steps per Second: 23,231.51497
Overall Steps per Second: 10,952.99219

Timestep Collection Time: 2.15388
Timestep Consumption Time: 2.41455
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.56843

Cumulative Model Updates: 190,874
Cumulative Timesteps: 1,591,722,376

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1591722376...
Checkpoint 1591722376 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.70885
Value Function Loss: 0.01642

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05488
Policy Update Magnitude: 0.48122
Value Function Update Magnitude: 0.30954

Collected Steps per Second: 22,636.25614
Overall Steps per Second: 10,636.07402

Timestep Collection Time: 2.20929
Timestep Consumption Time: 2.49264
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.70192

Cumulative Model Updates: 190,880
Cumulative Timesteps: 1,591,772,386

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.72754
Value Function Loss: 0.01506

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07635
Policy Update Magnitude: 0.47661
Value Function Update Magnitude: 0.28279

Collected Steps per Second: 23,145.12597
Overall Steps per Second: 10,859.70493

Timestep Collection Time: 2.16149
Timestep Consumption Time: 2.44526
PPO Batch Consumption Time: 0.28220
Total Iteration Time: 4.60676

Cumulative Model Updates: 190,886
Cumulative Timesteps: 1,591,822,414

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1591822414...
Checkpoint 1591822414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.73346
Value Function Loss: 0.01234

Mean KL Divergence: 0.00543
SB3 Clip Fraction: 0.06355
Policy Update Magnitude: 0.40750
Value Function Update Magnitude: 0.26576

Collected Steps per Second: 22,364.42856
Overall Steps per Second: 10,613.64843

Timestep Collection Time: 2.23614
Timestep Consumption Time: 2.47572
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.71186

Cumulative Model Updates: 190,892
Cumulative Timesteps: 1,591,872,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.73255
Value Function Loss: 0.01052

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06941
Policy Update Magnitude: 0.34761
Value Function Update Magnitude: 0.21203

Collected Steps per Second: 22,305.45122
Overall Steps per Second: 10,903.80831

Timestep Collection Time: 2.24187
Timestep Consumption Time: 2.34423
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.58610

Cumulative Model Updates: 190,898
Cumulative Timesteps: 1,591,922,430

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1591922430...
Checkpoint 1591922430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.72946
Value Function Loss: 0.01068

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.30458
Value Function Update Magnitude: 0.27206

Collected Steps per Second: 22,251.19704
Overall Steps per Second: 10,763.92024

Timestep Collection Time: 2.24770
Timestep Consumption Time: 2.39875
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.64645

Cumulative Model Updates: 190,904
Cumulative Timesteps: 1,591,972,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.72399
Value Function Loss: 0.01113

Mean KL Divergence: 0.00819
SB3 Clip Fraction: 0.11008
Policy Update Magnitude: 0.32813
Value Function Update Magnitude: 0.37682

Collected Steps per Second: 22,465.46987
Overall Steps per Second: 10,777.98626

Timestep Collection Time: 2.22617
Timestep Consumption Time: 2.41403
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.64020

Cumulative Model Updates: 190,910
Cumulative Timesteps: 1,592,022,456

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1592022456...
Checkpoint 1592022456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.71609
Value Function Loss: 0.01368

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.36538
Value Function Update Magnitude: 0.41270

Collected Steps per Second: 22,271.29438
Overall Steps per Second: 10,676.14701

Timestep Collection Time: 2.24549
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.28383
Total Iteration Time: 4.68427

Cumulative Model Updates: 190,916
Cumulative Timesteps: 1,592,072,466

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.71061
Value Function Loss: 0.01649

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.39836
Value Function Update Magnitude: 0.49097

Collected Steps per Second: 23,227.30403
Overall Steps per Second: 10,943.26416

Timestep Collection Time: 2.15298
Timestep Consumption Time: 2.41677
PPO Batch Consumption Time: 0.28140
Total Iteration Time: 4.56975

Cumulative Model Updates: 190,922
Cumulative Timesteps: 1,592,122,474

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1592122474...
Checkpoint 1592122474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.70449
Value Function Loss: 0.01765

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.15886
Policy Update Magnitude: 0.40814
Value Function Update Magnitude: 0.50046

Collected Steps per Second: 22,336.36722
Overall Steps per Second: 10,625.09887

Timestep Collection Time: 2.23967
Timestep Consumption Time: 2.46862
PPO Batch Consumption Time: 0.28595
Total Iteration Time: 4.70829

Cumulative Model Updates: 190,928
Cumulative Timesteps: 1,592,172,500

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.68713
Value Function Loss: 0.02036

Mean KL Divergence: 0.01075
SB3 Clip Fraction: 0.13215
Policy Update Magnitude: 0.41343
Value Function Update Magnitude: 0.42173

Collected Steps per Second: 23,164.86252
Overall Steps per Second: 10,888.00578

Timestep Collection Time: 2.15896
Timestep Consumption Time: 2.43435
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.59331

Cumulative Model Updates: 190,934
Cumulative Timesteps: 1,592,222,512

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1592222512...
Checkpoint 1592222512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.68273
Value Function Loss: 0.02054

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14016
Policy Update Magnitude: 0.41740
Value Function Update Magnitude: 0.34115

Collected Steps per Second: 22,649.34713
Overall Steps per Second: 10,649.37431

Timestep Collection Time: 2.20916
Timestep Consumption Time: 2.48933
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.69849

Cumulative Model Updates: 190,940
Cumulative Timesteps: 1,592,272,548

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,615.37689
Policy Entropy: 3.68053
Value Function Loss: 0.02015

Mean KL Divergence: 0.01790
SB3 Clip Fraction: 0.20842
Policy Update Magnitude: 0.43009
Value Function Update Magnitude: 0.38430

Collected Steps per Second: 23,049.07736
Overall Steps per Second: 10,879.71582

Timestep Collection Time: 2.16937
Timestep Consumption Time: 2.42652
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.59589

Cumulative Model Updates: 190,946
Cumulative Timesteps: 1,592,322,550

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1592322550...
Checkpoint 1592322550 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,016,358.95704
Policy Entropy: 3.63188
Value Function Loss: 0.05515

Mean KL Divergence: 0.03075
SB3 Clip Fraction: 0.27577
Policy Update Magnitude: 0.42948
Value Function Update Magnitude: 0.42111

Collected Steps per Second: 22,488.10559
Overall Steps per Second: 10,661.75441

Timestep Collection Time: 2.22340
Timestep Consumption Time: 2.46626
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.68966

Cumulative Model Updates: 190,952
Cumulative Timesteps: 1,592,372,550

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,829.71870
Policy Entropy: 3.62874
Value Function Loss: 0.07980

Mean KL Divergence: 0.01878
SB3 Clip Fraction: 0.20103
Policy Update Magnitude: 0.66055
Value Function Update Magnitude: 0.44275

Collected Steps per Second: 22,723.05088
Overall Steps per Second: 10,860.80302

Timestep Collection Time: 2.20067
Timestep Consumption Time: 2.40359
PPO Batch Consumption Time: 0.27878
Total Iteration Time: 4.60426

Cumulative Model Updates: 190,958
Cumulative Timesteps: 1,592,422,556

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1592422556...
Checkpoint 1592422556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,475.15350
Policy Entropy: 3.63803
Value Function Loss: 0.10509

Mean KL Divergence: 0.01588
SB3 Clip Fraction: 0.18351
Policy Update Magnitude: 0.82735
Value Function Update Magnitude: 0.50222

Collected Steps per Second: 22,360.21057
Overall Steps per Second: 10,701.68344

Timestep Collection Time: 2.23692
Timestep Consumption Time: 2.43692
PPO Batch Consumption Time: 0.28619
Total Iteration Time: 4.67384

Cumulative Model Updates: 190,964
Cumulative Timesteps: 1,592,472,574

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,522.69771
Policy Entropy: 3.72389
Value Function Loss: 0.08233

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.15717
Policy Update Magnitude: 0.98682
Value Function Update Magnitude: 0.53071

Collected Steps per Second: 23,212.41996
Overall Steps per Second: 10,936.03795

Timestep Collection Time: 2.15462
Timestep Consumption Time: 2.41870
PPO Batch Consumption Time: 0.27665
Total Iteration Time: 4.57332

Cumulative Model Updates: 190,970
Cumulative Timesteps: 1,592,522,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1592522588...
Checkpoint 1592522588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 308,788.91211
Policy Entropy: 3.71231
Value Function Loss: 0.06989

Mean KL Divergence: 0.01268
SB3 Clip Fraction: 0.15416
Policy Update Magnitude: 0.94436
Value Function Update Magnitude: 0.60239

Collected Steps per Second: 22,874.53868
Overall Steps per Second: 10,712.18791

Timestep Collection Time: 2.18706
Timestep Consumption Time: 2.48313
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.67019

Cumulative Model Updates: 190,976
Cumulative Timesteps: 1,592,572,616

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,369.21207
Policy Entropy: 3.70657
Value Function Loss: 0.05619

Mean KL Divergence: 0.00766
SB3 Clip Fraction: 0.09757
Policy Update Magnitude: 0.83277
Value Function Update Magnitude: 0.50842

Collected Steps per Second: 22,975.94953
Overall Steps per Second: 10,802.27774

Timestep Collection Time: 2.17706
Timestep Consumption Time: 2.45345
PPO Batch Consumption Time: 0.28224
Total Iteration Time: 4.63050

Cumulative Model Updates: 190,982
Cumulative Timesteps: 1,592,622,636

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1592622636...
Checkpoint 1592622636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,393.55339
Policy Entropy: 3.69165
Value Function Loss: 0.04121

Mean KL Divergence: 0.00707
SB3 Clip Fraction: 0.08882
Policy Update Magnitude: 0.81544
Value Function Update Magnitude: 0.48307

Collected Steps per Second: 22,325.45432
Overall Steps per Second: 10,631.95887

Timestep Collection Time: 2.24004
Timestep Consumption Time: 2.46370
PPO Batch Consumption Time: 0.28536
Total Iteration Time: 4.70374

Cumulative Model Updates: 190,988
Cumulative Timesteps: 1,592,672,646

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,850.86972
Policy Entropy: 3.72028
Value Function Loss: 0.02521

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07128
Policy Update Magnitude: 0.73166
Value Function Update Magnitude: 0.48026

Collected Steps per Second: 23,037.76948
Overall Steps per Second: 10,883.24518

Timestep Collection Time: 2.17096
Timestep Consumption Time: 2.42455
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.59550

Cumulative Model Updates: 190,994
Cumulative Timesteps: 1,592,722,660

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1592722660...
Checkpoint 1592722660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,850.86972
Policy Entropy: 3.72059
Value Function Loss: 0.01698

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06996
Policy Update Magnitude: 0.60555
Value Function Update Magnitude: 0.52972

Collected Steps per Second: 22,744.44137
Overall Steps per Second: 10,681.45861

Timestep Collection Time: 2.19957
Timestep Consumption Time: 2.48406
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.68363

Cumulative Model Updates: 191,000
Cumulative Timesteps: 1,592,772,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,850.86972
Policy Entropy: 3.71381
Value Function Loss: 0.01502

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06378
Policy Update Magnitude: 0.50474
Value Function Update Magnitude: 0.45062

Collected Steps per Second: 22,566.30120
Overall Steps per Second: 10,829.02436

Timestep Collection Time: 2.21667
Timestep Consumption Time: 2.40258
PPO Batch Consumption Time: 0.27682
Total Iteration Time: 4.61925

Cumulative Model Updates: 191,006
Cumulative Timesteps: 1,592,822,710

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1592822710...
Checkpoint 1592822710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,850.86972
Policy Entropy: 3.71264
Value Function Loss: 0.01292

Mean KL Divergence: 0.00470
SB3 Clip Fraction: 0.05128
Policy Update Magnitude: 0.42871
Value Function Update Magnitude: 0.34746

Collected Steps per Second: 22,930.05915
Overall Steps per Second: 10,699.78680

Timestep Collection Time: 2.18185
Timestep Consumption Time: 2.49394
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.67579

Cumulative Model Updates: 191,012
Cumulative Timesteps: 1,592,872,740

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,850.86972
Policy Entropy: 3.72618
Value Function Loss: 0.01211

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06758
Policy Update Magnitude: 0.38956
Value Function Update Magnitude: 0.27038

Collected Steps per Second: 22,236.35776
Overall Steps per Second: 10,869.43201

Timestep Collection Time: 2.24965
Timestep Consumption Time: 2.35262
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.60226

Cumulative Model Updates: 191,018
Cumulative Timesteps: 1,592,922,764

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1592922764...
Checkpoint 1592922764 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,944.81279
Policy Entropy: 3.73879
Value Function Loss: 0.01330

Mean KL Divergence: 0.00636
SB3 Clip Fraction: 0.08082
Policy Update Magnitude: 0.36395
Value Function Update Magnitude: 0.32503

Collected Steps per Second: 22,082.31037
Overall Steps per Second: 10,695.82180

Timestep Collection Time: 2.26435
Timestep Consumption Time: 2.41056
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.67491

Cumulative Model Updates: 191,024
Cumulative Timesteps: 1,592,972,766

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,299.98566
Policy Entropy: 3.73822
Value Function Loss: 0.01357

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13400
Policy Update Magnitude: 0.31811
Value Function Update Magnitude: 0.44325

Collected Steps per Second: 22,390.07213
Overall Steps per Second: 10,934.14824

Timestep Collection Time: 2.23313
Timestep Consumption Time: 2.33970
PPO Batch Consumption Time: 0.27626
Total Iteration Time: 4.57283

Cumulative Model Updates: 191,030
Cumulative Timesteps: 1,593,022,766

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1593022766...
Checkpoint 1593022766 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,430.39445
Policy Entropy: 3.72701
Value Function Loss: 0.01506

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.12969
Policy Update Magnitude: 0.28022
Value Function Update Magnitude: 0.55394

Collected Steps per Second: 22,126.06814
Overall Steps per Second: 10,613.53230

Timestep Collection Time: 2.25987
Timestep Consumption Time: 2.45129
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.71116

Cumulative Model Updates: 191,036
Cumulative Timesteps: 1,593,072,768

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,430.39445
Policy Entropy: 3.72615
Value Function Loss: 0.01392

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13962
Policy Update Magnitude: 0.29038
Value Function Update Magnitude: 0.53506

Collected Steps per Second: 22,853.43256
Overall Steps per Second: 10,915.32443

Timestep Collection Time: 2.18943
Timestep Consumption Time: 2.39458
PPO Batch Consumption Time: 0.27698
Total Iteration Time: 4.58401

Cumulative Model Updates: 191,042
Cumulative Timesteps: 1,593,122,804

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1593122804...
Checkpoint 1593122804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,430.39445
Policy Entropy: 3.71206
Value Function Loss: 0.01469

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.09220
Policy Update Magnitude: 0.33846
Value Function Update Magnitude: 0.48165

Collected Steps per Second: 22,986.17772
Overall Steps per Second: 10,729.81220

Timestep Collection Time: 2.17539
Timestep Consumption Time: 2.48489
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.66029

Cumulative Model Updates: 191,048
Cumulative Timesteps: 1,593,172,808

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,430.39445
Policy Entropy: 3.72065
Value Function Loss: 0.01486

Mean KL Divergence: 0.00851
SB3 Clip Fraction: 0.11395
Policy Update Magnitude: 0.36365
Value Function Update Magnitude: 0.47258

Collected Steps per Second: 22,865.97492
Overall Steps per Second: 10,784.12415

Timestep Collection Time: 2.18735
Timestep Consumption Time: 2.45057
PPO Batch Consumption Time: 0.28298
Total Iteration Time: 4.63793

Cumulative Model Updates: 191,054
Cumulative Timesteps: 1,593,222,824

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1593222824...
Checkpoint 1593222824 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,430.39445
Policy Entropy: 3.71816
Value Function Loss: 0.01514

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.39206
Value Function Update Magnitude: 0.49163

Collected Steps per Second: 22,658.29896
Overall Steps per Second: 10,651.28439

Timestep Collection Time: 2.20776
Timestep Consumption Time: 2.48877
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.69652

Cumulative Model Updates: 191,060
Cumulative Timesteps: 1,593,272,848

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,430.39445
Policy Entropy: 3.73583
Value Function Loss: 0.01325

Mean KL Divergence: 0.01161
SB3 Clip Fraction: 0.15068
Policy Update Magnitude: 0.36179
Value Function Update Magnitude: 0.51347

Collected Steps per Second: 23,139.53564
Overall Steps per Second: 10,950.26897

Timestep Collection Time: 2.16201
Timestep Consumption Time: 2.40664
PPO Batch Consumption Time: 0.27593
Total Iteration Time: 4.56865

Cumulative Model Updates: 191,066
Cumulative Timesteps: 1,593,322,876

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1593322876...
Checkpoint 1593322876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,430.39445
Policy Entropy: 3.72691
Value Function Loss: 0.01227

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12733
Policy Update Magnitude: 0.35098
Value Function Update Magnitude: 0.42822

Collected Steps per Second: 23,041.32715
Overall Steps per Second: 10,770.97071

Timestep Collection Time: 2.17132
Timestep Consumption Time: 2.47358
PPO Batch Consumption Time: 0.28933
Total Iteration Time: 4.64489

Cumulative Model Updates: 191,072
Cumulative Timesteps: 1,593,372,906

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,788.25609
Policy Entropy: 3.70962
Value Function Loss: 0.01453

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.36541
Value Function Update Magnitude: 0.43161

Collected Steps per Second: 23,065.95917
Overall Steps per Second: 10,781.99703

Timestep Collection Time: 2.16830
Timestep Consumption Time: 2.47035
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.63866

Cumulative Model Updates: 191,078
Cumulative Timesteps: 1,593,422,920

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1593422920...
Checkpoint 1593422920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,191.20151
Policy Entropy: 3.70910
Value Function Loss: 0.01622

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15916
Policy Update Magnitude: 0.34440
Value Function Update Magnitude: 0.53308

Collected Steps per Second: 21,989.02325
Overall Steps per Second: 10,681.06627

Timestep Collection Time: 2.27486
Timestep Consumption Time: 2.40838
PPO Batch Consumption Time: 0.29120
Total Iteration Time: 4.68324

Cumulative Model Updates: 191,084
Cumulative Timesteps: 1,593,472,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,095.57343
Policy Entropy: 3.71311
Value Function Loss: 0.01751

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.13147
Policy Update Magnitude: 0.36515
Value Function Update Magnitude: 0.58827

Collected Steps per Second: 22,101.55062
Overall Steps per Second: 10,852.38139

Timestep Collection Time: 2.26238
Timestep Consumption Time: 2.34509
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.60747

Cumulative Model Updates: 191,090
Cumulative Timesteps: 1,593,522,944

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1593522944...
Checkpoint 1593522944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,095.57343
Policy Entropy: 3.70052
Value Function Loss: 0.02414

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14333
Policy Update Magnitude: 0.38985
Value Function Update Magnitude: 0.52207

Collected Steps per Second: 21,740.07977
Overall Steps per Second: 10,638.51752

Timestep Collection Time: 2.30137
Timestep Consumption Time: 2.40154
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.70291

Cumulative Model Updates: 191,096
Cumulative Timesteps: 1,593,572,976

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,095.57343
Policy Entropy: 3.68272
Value Function Loss: 0.02407

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14658
Policy Update Magnitude: 0.45419
Value Function Update Magnitude: 0.46193

Collected Steps per Second: 22,665.82212
Overall Steps per Second: 10,858.31426

Timestep Collection Time: 2.20632
Timestep Consumption Time: 2.39919
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.60550

Cumulative Model Updates: 191,102
Cumulative Timesteps: 1,593,622,984

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1593622984...
Checkpoint 1593622984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,095.57343
Policy Entropy: 3.65629
Value Function Loss: 0.02853

Mean KL Divergence: 0.01760
SB3 Clip Fraction: 0.19960
Policy Update Magnitude: 0.52412
Value Function Update Magnitude: 0.42496

Collected Steps per Second: 22,301.88213
Overall Steps per Second: 10,672.38887

Timestep Collection Time: 2.24340
Timestep Consumption Time: 2.44459
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.68799

Cumulative Model Updates: 191,108
Cumulative Timesteps: 1,593,673,016

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334,826.03705
Policy Entropy: 3.63758
Value Function Loss: 0.05767

Mean KL Divergence: 0.03364
SB3 Clip Fraction: 0.28178
Policy Update Magnitude: 0.53205
Value Function Update Magnitude: 0.42393

Collected Steps per Second: 22,398.55047
Overall Steps per Second: 10,667.33606

Timestep Collection Time: 2.23345
Timestep Consumption Time: 2.45620
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.68964

Cumulative Model Updates: 191,114
Cumulative Timesteps: 1,593,723,042

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1593723042...
Checkpoint 1593723042 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,783.68045
Policy Entropy: 3.65519
Value Function Loss: 0.07990

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.17253
Policy Update Magnitude: 0.72880
Value Function Update Magnitude: 0.44158

Collected Steps per Second: 22,575.81184
Overall Steps per Second: 10,711.93757

Timestep Collection Time: 2.21547
Timestep Consumption Time: 2.45371
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.66918

Cumulative Model Updates: 191,120
Cumulative Timesteps: 1,593,773,058

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,522.77567
Policy Entropy: 3.67622
Value Function Loss: 0.08945

Mean KL Divergence: 0.01479
SB3 Clip Fraction: 0.16917
Policy Update Magnitude: 0.91256
Value Function Update Magnitude: 0.46305

Collected Steps per Second: 23,100.25331
Overall Steps per Second: 10,845.66293

Timestep Collection Time: 2.16543
Timestep Consumption Time: 2.44674
PPO Batch Consumption Time: 0.28754
Total Iteration Time: 4.61217

Cumulative Model Updates: 191,126
Cumulative Timesteps: 1,593,823,080

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1593823080...
Checkpoint 1593823080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,467.74325
Policy Entropy: 3.68427
Value Function Loss: 0.06372

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.81166
Value Function Update Magnitude: 0.50673

Collected Steps per Second: 22,679.89290
Overall Steps per Second: 10,807.97490

Timestep Collection Time: 2.20486
Timestep Consumption Time: 2.42191
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.62677

Cumulative Model Updates: 191,132
Cumulative Timesteps: 1,593,873,086

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,075.75081
Policy Entropy: 3.69456
Value Function Loss: 0.04413

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12893
Policy Update Magnitude: 0.73476
Value Function Update Magnitude: 0.57614

Collected Steps per Second: 23,020.65814
Overall Steps per Second: 10,768.36966

Timestep Collection Time: 2.17370
Timestep Consumption Time: 2.47324
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.64694

Cumulative Model Updates: 191,138
Cumulative Timesteps: 1,593,923,126

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1593923126...
Checkpoint 1593923126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,075.75081
Policy Entropy: 3.65289
Value Function Loss: 0.03741

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13179
Policy Update Magnitude: 0.61354
Value Function Update Magnitude: 0.56676

Collected Steps per Second: 22,646.63233
Overall Steps per Second: 10,808.02728

Timestep Collection Time: 2.20925
Timestep Consumption Time: 2.41991
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.62915

Cumulative Model Updates: 191,144
Cumulative Timesteps: 1,593,973,158

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,958.52517
Policy Entropy: 3.67688
Value Function Loss: 0.03037

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13491
Policy Update Magnitude: 0.57046
Value Function Update Magnitude: 0.73268

Collected Steps per Second: 23,012.83020
Overall Steps per Second: 10,751.27662

Timestep Collection Time: 2.17340
Timestep Consumption Time: 2.47870
PPO Batch Consumption Time: 0.28565
Total Iteration Time: 4.65210

Cumulative Model Updates: 191,150
Cumulative Timesteps: 1,594,023,174

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1594023174...
Checkpoint 1594023174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,867.38838
Policy Entropy: 3.68658
Value Function Loss: 0.03436

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13539
Policy Update Magnitude: 0.53834
Value Function Update Magnitude: 0.83530

Collected Steps per Second: 22,818.84137
Overall Steps per Second: 10,841.70083

Timestep Collection Time: 2.19187
Timestep Consumption Time: 2.42143
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.61330

Cumulative Model Updates: 191,156
Cumulative Timesteps: 1,594,073,190

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,168.81606
Policy Entropy: 3.72756
Value Function Loss: 0.02999

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12297
Policy Update Magnitude: 0.53744
Value Function Update Magnitude: 0.80201

Collected Steps per Second: 22,736.12907
Overall Steps per Second: 10,691.18967

Timestep Collection Time: 2.19976
Timestep Consumption Time: 2.47830
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.67806

Cumulative Model Updates: 191,162
Cumulative Timesteps: 1,594,123,204

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1594123204...
Checkpoint 1594123204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 127,431.50652
Policy Entropy: 3.72499
Value Function Loss: 0.03125

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08684
Policy Update Magnitude: 0.54509
Value Function Update Magnitude: 0.67355

Collected Steps per Second: 22,953.17583
Overall Steps per Second: 10,870.52443

Timestep Collection Time: 2.17887
Timestep Consumption Time: 2.42183
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.60070

Cumulative Model Updates: 191,168
Cumulative Timesteps: 1,594,173,216

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,247.53012
Policy Entropy: 3.74164
Value Function Loss: 0.02656

Mean KL Divergence: 0.00578
SB3 Clip Fraction: 0.07041
Policy Update Magnitude: 0.57488
Value Function Update Magnitude: 0.78603

Collected Steps per Second: 22,832.41502
Overall Steps per Second: 10,828.55124

Timestep Collection Time: 2.19145
Timestep Consumption Time: 2.42930
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.62075

Cumulative Model Updates: 191,174
Cumulative Timesteps: 1,594,223,252

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1594223252...
Checkpoint 1594223252 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,544.00731
Policy Entropy: 3.75405
Value Function Loss: 0.02433

Mean KL Divergence: 0.00521
SB3 Clip Fraction: 0.06027
Policy Update Magnitude: 0.55394
Value Function Update Magnitude: 0.87202

Collected Steps per Second: 23,025.52318
Overall Steps per Second: 10,735.46177

Timestep Collection Time: 2.17220
Timestep Consumption Time: 2.48675
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.65895

Cumulative Model Updates: 191,180
Cumulative Timesteps: 1,594,273,268

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.48666
Policy Entropy: 3.75454
Value Function Loss: 0.02027

Mean KL Divergence: 0.00680
SB3 Clip Fraction: 0.08597
Policy Update Magnitude: 0.50006
Value Function Update Magnitude: 0.79378

Collected Steps per Second: 22,802.23125
Overall Steps per Second: 10,846.13284

Timestep Collection Time: 2.19303
Timestep Consumption Time: 2.41746
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.61049

Cumulative Model Updates: 191,186
Cumulative Timesteps: 1,594,323,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1594323274...
Checkpoint 1594323274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 551.48666
Policy Entropy: 3.71674
Value Function Loss: 0.01819

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.39012
Value Function Update Magnitude: 0.66701

Collected Steps per Second: 22,955.60136
Overall Steps per Second: 10,718.70983

Timestep Collection Time: 2.17908
Timestep Consumption Time: 2.48772
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.66679

Cumulative Model Updates: 191,192
Cumulative Timesteps: 1,594,373,296

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 551.48666
Policy Entropy: 3.68546
Value Function Loss: 0.02050

Mean KL Divergence: 0.01171
SB3 Clip Fraction: 0.15529
Policy Update Magnitude: 0.40265
Value Function Update Magnitude: 0.53562

Collected Steps per Second: 22,995.88884
Overall Steps per Second: 10,899.79356

Timestep Collection Time: 2.17552
Timestep Consumption Time: 2.41429
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.58981

Cumulative Model Updates: 191,198
Cumulative Timesteps: 1,594,423,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1594423324...
Checkpoint 1594423324 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,712.63264
Policy Entropy: 3.65279
Value Function Loss: 0.03336

Mean KL Divergence: 0.01559
SB3 Clip Fraction: 0.18909
Policy Update Magnitude: 0.47308
Value Function Update Magnitude: 0.52929

Collected Steps per Second: 22,511.74426
Overall Steps per Second: 10,626.48665

Timestep Collection Time: 2.22106
Timestep Consumption Time: 2.48416
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.70522

Cumulative Model Updates: 191,204
Cumulative Timesteps: 1,594,473,324

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207,178.84768
Policy Entropy: 3.67512
Value Function Loss: 0.05384

Mean KL Divergence: 0.01035
SB3 Clip Fraction: 0.13377
Policy Update Magnitude: 0.63659
Value Function Update Magnitude: 0.44486

Collected Steps per Second: 22,686.74287
Overall Steps per Second: 10,675.19783

Timestep Collection Time: 2.20455
Timestep Consumption Time: 2.48052
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.68507

Cumulative Model Updates: 191,210
Cumulative Timesteps: 1,594,523,338

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1594523338...
Checkpoint 1594523338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,514.22416
Policy Entropy: 3.69403
Value Function Loss: 0.05359

Mean KL Divergence: 0.01224
SB3 Clip Fraction: 0.16234
Policy Update Magnitude: 0.69106
Value Function Update Magnitude: 0.55776

Collected Steps per Second: 22,840.69729
Overall Steps per Second: 10,868.37113

Timestep Collection Time: 2.19126
Timestep Consumption Time: 2.41384
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.60511

Cumulative Model Updates: 191,216
Cumulative Timesteps: 1,594,573,388

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 870.31782
Policy Entropy: 3.74756
Value Function Loss: 0.04325

Mean KL Divergence: 0.00827
SB3 Clip Fraction: 0.10380
Policy Update Magnitude: 0.80517
Value Function Update Magnitude: 0.69218

Collected Steps per Second: 22,795.49976
Overall Steps per Second: 10,696.76529

Timestep Collection Time: 2.19368
Timestep Consumption Time: 2.48119
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.67487

Cumulative Model Updates: 191,222
Cumulative Timesteps: 1,594,623,394

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1594623394...
Checkpoint 1594623394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102.19926
Policy Entropy: 3.75480
Value Function Loss: 0.03123

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.12631
Policy Update Magnitude: 0.73938
Value Function Update Magnitude: 0.66410

Collected Steps per Second: 22,534.76001
Overall Steps per Second: 10,782.29887

Timestep Collection Time: 2.21977
Timestep Consumption Time: 2.41950
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.63927

Cumulative Model Updates: 191,228
Cumulative Timesteps: 1,594,673,416

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,435.74593
Policy Entropy: 3.73578
Value Function Loss: 0.02917

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.62487
Value Function Update Magnitude: 0.72999

Collected Steps per Second: 23,064.47124
Overall Steps per Second: 10,741.14410

Timestep Collection Time: 2.16792
Timestep Consumption Time: 2.48726
PPO Batch Consumption Time: 0.28786
Total Iteration Time: 4.65518

Cumulative Model Updates: 191,234
Cumulative Timesteps: 1,594,723,418

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1594723418...
Checkpoint 1594723418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,154.32511
Policy Entropy: 3.72072
Value Function Loss: 0.03497

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12491
Policy Update Magnitude: 0.67888
Value Function Update Magnitude: 0.70226

Collected Steps per Second: 22,910.28584
Overall Steps per Second: 10,861.24493

Timestep Collection Time: 2.18382
Timestep Consumption Time: 2.42265
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.60647

Cumulative Model Updates: 191,240
Cumulative Timesteps: 1,594,773,450

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 124,736.17560
Policy Entropy: 3.69895
Value Function Loss: 0.04426

Mean KL Divergence: 0.01403
SB3 Clip Fraction: 0.16817
Policy Update Magnitude: 0.63845
Value Function Update Magnitude: 0.67589

Collected Steps per Second: 22,823.52444
Overall Steps per Second: 10,837.28469

Timestep Collection Time: 2.19125
Timestep Consumption Time: 2.42356
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.61481

Cumulative Model Updates: 191,246
Cumulative Timesteps: 1,594,823,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1594823462...
Checkpoint 1594823462 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,627.48979
Policy Entropy: 3.76630
Value Function Loss: 0.05180

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09697
Policy Update Magnitude: 0.72478
Value Function Update Magnitude: 0.62755

Collected Steps per Second: 22,489.60109
Overall Steps per Second: 10,798.72186

Timestep Collection Time: 2.22458
Timestep Consumption Time: 2.40837
PPO Batch Consumption Time: 0.27608
Total Iteration Time: 4.63296

Cumulative Model Updates: 191,252
Cumulative Timesteps: 1,594,873,492

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47.33728
Policy Entropy: 3.82553
Value Function Loss: 0.04746

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09227
Policy Update Magnitude: 0.83196
Value Function Update Magnitude: 0.67510

Collected Steps per Second: 22,725.22224
Overall Steps per Second: 10,817.59820

Timestep Collection Time: 2.20125
Timestep Consumption Time: 2.42306
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.62432

Cumulative Model Updates: 191,258
Cumulative Timesteps: 1,594,923,516

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1594923516...
Checkpoint 1594923516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28.76938
Policy Entropy: 3.88030
Value Function Loss: 0.03748

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.70694
Value Function Update Magnitude: 0.88658

Collected Steps per Second: 22,420.16538
Overall Steps per Second: 10,680.46161

Timestep Collection Time: 2.23014
Timestep Consumption Time: 2.45131
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.68145

Cumulative Model Updates: 191,264
Cumulative Timesteps: 1,594,973,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,437.81651
Policy Entropy: 3.88393
Value Function Loss: 0.03066

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.11524
Policy Update Magnitude: 0.55444
Value Function Update Magnitude: 1.07030

Collected Steps per Second: 23,157.28738
Overall Steps per Second: 10,885.87651

Timestep Collection Time: 2.15949
Timestep Consumption Time: 2.43435
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.59384

Cumulative Model Updates: 191,270
Cumulative Timesteps: 1,595,023,524

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1595023524...
Checkpoint 1595023524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,741.25436
Policy Entropy: 3.83864
Value Function Loss: 0.03429

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13000
Policy Update Magnitude: 0.50875
Value Function Update Magnitude: 1.14669

Collected Steps per Second: 22,896.46035
Overall Steps per Second: 10,719.29848

Timestep Collection Time: 2.18523
Timestep Consumption Time: 2.48243
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.66766

Cumulative Model Updates: 191,276
Cumulative Timesteps: 1,595,073,558

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948.36233
Policy Entropy: 3.80568
Value Function Loss: 0.03685

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13130
Policy Update Magnitude: 0.55219
Value Function Update Magnitude: 1.14380

Collected Steps per Second: 22,876.49460
Overall Steps per Second: 10,861.19584

Timestep Collection Time: 2.18617
Timestep Consumption Time: 2.41848
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.60465

Cumulative Model Updates: 191,282
Cumulative Timesteps: 1,595,123,570

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1595123570...
Checkpoint 1595123570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 316.49632
Policy Entropy: 3.76431
Value Function Loss: 0.03349

Mean KL Divergence: 0.01094
SB3 Clip Fraction: 0.13910
Policy Update Magnitude: 0.56442
Value Function Update Magnitude: 1.01479

Collected Steps per Second: 22,587.07437
Overall Steps per Second: 10,615.73085

Timestep Collection Time: 2.21454
Timestep Consumption Time: 2.49733
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.71188

Cumulative Model Updates: 191,288
Cumulative Timesteps: 1,595,173,590

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,835.80954
Policy Entropy: 3.76163
Value Function Loss: 0.02768

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13476
Policy Update Magnitude: 0.51870
Value Function Update Magnitude: 0.88292

Collected Steps per Second: 22,886.42418
Overall Steps per Second: 10,849.05387

Timestep Collection Time: 2.18523
Timestep Consumption Time: 2.42458
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.60980

Cumulative Model Updates: 191,294
Cumulative Timesteps: 1,595,223,602

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1595223602...
Checkpoint 1595223602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 781,672.77303
Policy Entropy: 3.76093
Value Function Loss: 0.02567

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14629
Policy Update Magnitude: 0.48340
Value Function Update Magnitude: 0.86987

Collected Steps per Second: 22,049.49257
Overall Steps per Second: 10,640.12949

Timestep Collection Time: 2.26799
Timestep Consumption Time: 2.43195
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.69994

Cumulative Model Updates: 191,300
Cumulative Timesteps: 1,595,273,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254,299.94830
Policy Entropy: 3.77427
Value Function Loss: 0.02810

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12022
Policy Update Magnitude: 0.52410
Value Function Update Magnitude: 0.98395

Collected Steps per Second: 22,923.90877
Overall Steps per Second: 10,903.21052

Timestep Collection Time: 2.18209
Timestep Consumption Time: 2.40573
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.58782

Cumulative Model Updates: 191,306
Cumulative Timesteps: 1,595,323,632

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1595323632...
Checkpoint 1595323632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,553.70132
Policy Entropy: 3.76323
Value Function Loss: 0.03985

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.16585
Policy Update Magnitude: 0.50643
Value Function Update Magnitude: 1.02295

Collected Steps per Second: 22,203.55206
Overall Steps per Second: 10,701.84529

Timestep Collection Time: 2.25279
Timestep Consumption Time: 2.42117
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.67396

Cumulative Model Updates: 191,312
Cumulative Timesteps: 1,595,373,652

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,282.97192
Policy Entropy: 3.77129
Value Function Loss: 0.04595

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13925
Policy Update Magnitude: 0.54906
Value Function Update Magnitude: 0.94564

Collected Steps per Second: 22,830.23205
Overall Steps per Second: 10,809.38192

Timestep Collection Time: 2.19052
Timestep Consumption Time: 2.43602
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.62654

Cumulative Model Updates: 191,318
Cumulative Timesteps: 1,595,423,662

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1595423662...
Checkpoint 1595423662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,975.80006
Policy Entropy: 3.80439
Value Function Loss: 0.05192

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11354
Policy Update Magnitude: 0.76783
Value Function Update Magnitude: 0.97099

Collected Steps per Second: 22,641.40593
Overall Steps per Second: 10,812.14485

Timestep Collection Time: 2.20932
Timestep Consumption Time: 2.41715
PPO Batch Consumption Time: 0.27640
Total Iteration Time: 4.62646

Cumulative Model Updates: 191,324
Cumulative Timesteps: 1,595,473,684

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32.83377
Policy Entropy: 3.85072
Value Function Loss: 0.04670

Mean KL Divergence: 0.00651
SB3 Clip Fraction: 0.08022
Policy Update Magnitude: 0.82322
Value Function Update Magnitude: 1.05163

Collected Steps per Second: 22,928.20346
Overall Steps per Second: 10,919.18942

Timestep Collection Time: 2.18116
Timestep Consumption Time: 2.39885
PPO Batch Consumption Time: 0.27648
Total Iteration Time: 4.58001

Cumulative Model Updates: 191,330
Cumulative Timesteps: 1,595,523,694

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1595523694...
Checkpoint 1595523694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22.50521
Policy Entropy: 3.86292
Value Function Loss: 0.04277

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07328
Policy Update Magnitude: 0.75664
Value Function Update Magnitude: 1.15846

Collected Steps per Second: 22,762.87283
Overall Steps per Second: 10,681.74097

Timestep Collection Time: 2.19656
Timestep Consumption Time: 2.48433
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.68088

Cumulative Model Updates: 191,336
Cumulative Timesteps: 1,595,573,694

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.54038
Policy Entropy: 3.86150
Value Function Loss: 0.03493

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.10085
Policy Update Magnitude: 0.60561
Value Function Update Magnitude: 0.98777

Collected Steps per Second: 22,859.94603
Overall Steps per Second: 10,810.71690

Timestep Collection Time: 2.18854
Timestep Consumption Time: 2.43927
PPO Batch Consumption Time: 0.28115
Total Iteration Time: 4.62782

Cumulative Model Updates: 191,342
Cumulative Timesteps: 1,595,623,724

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1595623724...
Checkpoint 1595623724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19.10318
Policy Entropy: 3.83080
Value Function Loss: 0.02987

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05739
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 1.01624

Collected Steps per Second: 22,908.47145
Overall Steps per Second: 10,722.97354

Timestep Collection Time: 2.18260
Timestep Consumption Time: 2.48029
PPO Batch Consumption Time: 0.28963
Total Iteration Time: 4.66289

Cumulative Model Updates: 191,348
Cumulative Timesteps: 1,595,673,724

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.36440
Policy Entropy: 3.81679
Value Function Loss: 0.02330

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06845
Policy Update Magnitude: 0.54857
Value Function Update Magnitude: 1.04156

Collected Steps per Second: 23,380.95707
Overall Steps per Second: 10,811.48147

Timestep Collection Time: 2.13926
Timestep Consumption Time: 2.48712
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.62638

Cumulative Model Updates: 191,354
Cumulative Timesteps: 1,595,723,742

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1595723742...
Checkpoint 1595723742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.13551
Policy Entropy: 3.79177
Value Function Loss: 0.02084

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.11085
Policy Update Magnitude: 0.43935
Value Function Update Magnitude: 0.92317

Collected Steps per Second: 22,817.26873
Overall Steps per Second: 10,694.19785

Timestep Collection Time: 2.19141
Timestep Consumption Time: 2.48421
PPO Batch Consumption Time: 0.29192
Total Iteration Time: 4.67562

Cumulative Model Updates: 191,360
Cumulative Timesteps: 1,595,773,744

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.86815
Policy Entropy: 3.77328
Value Function Loss: 0.01771

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05360
Policy Update Magnitude: 0.41351
Value Function Update Magnitude: 0.79135

Collected Steps per Second: 22,440.00737
Overall Steps per Second: 10,864.06762

Timestep Collection Time: 2.22897
Timestep Consumption Time: 2.37502
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.60398

Cumulative Model Updates: 191,366
Cumulative Timesteps: 1,595,823,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1595823762...
Checkpoint 1595823762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.86815
Policy Entropy: 3.74810
Value Function Loss: 0.01615

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06366
Policy Update Magnitude: 0.45340
Value Function Update Magnitude: 0.66601

Collected Steps per Second: 21,965.37581
Overall Steps per Second: 10,650.00126

Timestep Collection Time: 2.27667
Timestep Consumption Time: 2.41891
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.69559

Cumulative Model Updates: 191,372
Cumulative Timesteps: 1,595,873,770

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.86815
Policy Entropy: 3.72832
Value Function Loss: 0.01667

Mean KL Divergence: 0.00559
SB3 Clip Fraction: 0.06728
Policy Update Magnitude: 0.45462
Value Function Update Magnitude: 0.61892

Collected Steps per Second: 22,031.95550
Overall Steps per Second: 10,804.31965

Timestep Collection Time: 2.27052
Timestep Consumption Time: 2.35948
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.63000

Cumulative Model Updates: 191,378
Cumulative Timesteps: 1,595,923,794

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1595923794...
Checkpoint 1595923794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.86815
Policy Entropy: 3.72594
Value Function Loss: 0.01452

Mean KL Divergence: 0.00498
SB3 Clip Fraction: 0.05610
Policy Update Magnitude: 0.44646
Value Function Update Magnitude: 0.56878

Collected Steps per Second: 21,986.68015
Overall Steps per Second: 10,713.91849

Timestep Collection Time: 2.27620
Timestep Consumption Time: 2.39492
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.67112

Cumulative Model Updates: 191,384
Cumulative Timesteps: 1,595,973,840

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.86815
Policy Entropy: 3.73030
Value Function Loss: 0.01417

Mean KL Divergence: 0.00507
SB3 Clip Fraction: 0.05861
Policy Update Magnitude: 0.42976
Value Function Update Magnitude: 0.51456

Collected Steps per Second: 22,503.79378
Overall Steps per Second: 10,841.78802

Timestep Collection Time: 2.22318
Timestep Consumption Time: 2.39137
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.61455

Cumulative Model Updates: 191,390
Cumulative Timesteps: 1,596,023,870

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1596023870...
Checkpoint 1596023870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,155.42725
Policy Entropy: 3.73490
Value Function Loss: 0.01439

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05908
Policy Update Magnitude: 0.43591
Value Function Update Magnitude: 0.48216

Collected Steps per Second: 22,655.57489
Overall Steps per Second: 10,732.22136

Timestep Collection Time: 2.20785
Timestep Consumption Time: 2.45289
PPO Batch Consumption Time: 0.28794
Total Iteration Time: 4.66073

Cumulative Model Updates: 191,396
Cumulative Timesteps: 1,596,073,890

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,526.20254
Policy Entropy: 3.73389
Value Function Loss: 0.01564

Mean KL Divergence: 0.00467
SB3 Clip Fraction: 0.05070
Policy Update Magnitude: 0.42804
Value Function Update Magnitude: 0.48040

Collected Steps per Second: 22,592.74872
Overall Steps per Second: 10,817.25274

Timestep Collection Time: 2.21398
Timestep Consumption Time: 2.41011
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.62409

Cumulative Model Updates: 191,402
Cumulative Timesteps: 1,596,123,910

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1596123910...
Checkpoint 1596123910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,278.10219
Policy Entropy: 3.73146
Value Function Loss: 0.02009

Mean KL Divergence: 0.00454
SB3 Clip Fraction: 0.04918
Policy Update Magnitude: 0.48528
Value Function Update Magnitude: 0.52582

Collected Steps per Second: 22,401.49691
Overall Steps per Second: 10,789.66636

Timestep Collection Time: 2.23244
Timestep Consumption Time: 2.40255
PPO Batch Consumption Time: 0.27571
Total Iteration Time: 4.63499

Cumulative Model Updates: 191,408
Cumulative Timesteps: 1,596,173,920

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,922.70111
Policy Entropy: 3.74982
Value Function Loss: 0.02240

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14288
Policy Update Magnitude: 0.46261
Value Function Update Magnitude: 0.62338

Collected Steps per Second: 23,129.06069
Overall Steps per Second: 10,806.63873

Timestep Collection Time: 2.16317
Timestep Consumption Time: 2.46658
PPO Batch Consumption Time: 0.28408
Total Iteration Time: 4.62975

Cumulative Model Updates: 191,414
Cumulative Timesteps: 1,596,223,952

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1596223952...
Checkpoint 1596223952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.63009
Policy Entropy: 3.77297
Value Function Loss: 0.02379

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.16013
Policy Update Magnitude: 0.38213
Value Function Update Magnitude: 0.76390

Collected Steps per Second: 22,880.31224
Overall Steps per Second: 10,669.46067

Timestep Collection Time: 2.18633
Timestep Consumption Time: 2.50219
PPO Batch Consumption Time: 0.29221
Total Iteration Time: 4.68852

Cumulative Model Updates: 191,420
Cumulative Timesteps: 1,596,273,976

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122.95419
Policy Entropy: 3.75585
Value Function Loss: 0.02334

Mean KL Divergence: 0.02738
SB3 Clip Fraction: 0.25993
Policy Update Magnitude: 0.30519
Value Function Update Magnitude: 0.82111

Collected Steps per Second: 22,720.98929
Overall Steps per Second: 10,663.86641

Timestep Collection Time: 2.20131
Timestep Consumption Time: 2.48892
PPO Batch Consumption Time: 0.28718
Total Iteration Time: 4.69023

Cumulative Model Updates: 191,426
Cumulative Timesteps: 1,596,323,992

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1596323992...
Checkpoint 1596323992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 79,845.05211
Policy Entropy: 3.75689
Value Function Loss: 0.02757

Mean KL Divergence: 0.01359
SB3 Clip Fraction: 0.16706
Policy Update Magnitude: 0.32530
Value Function Update Magnitude: 0.80657

Collected Steps per Second: 22,831.99374
Overall Steps per Second: 10,885.35040

Timestep Collection Time: 2.18991
Timestep Consumption Time: 2.40342
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.59333

Cumulative Model Updates: 191,432
Cumulative Timesteps: 1,596,373,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,428.76198
Policy Entropy: 3.76298
Value Function Loss: 0.02842

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14170
Policy Update Magnitude: 0.38277
Value Function Update Magnitude: 0.80876

Collected Steps per Second: 23,110.25696
Overall Steps per Second: 10,907.86796

Timestep Collection Time: 2.16354
Timestep Consumption Time: 2.42031
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.58385

Cumulative Model Updates: 191,438
Cumulative Timesteps: 1,596,423,992

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1596423992...
Checkpoint 1596423992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 299.26766
Policy Entropy: 3.77338
Value Function Loss: 0.03242

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14152
Policy Update Magnitude: 0.41411
Value Function Update Magnitude: 0.65811

Collected Steps per Second: 22,670.36916
Overall Steps per Second: 10,638.44426

Timestep Collection Time: 2.20640
Timestep Consumption Time: 2.49541
PPO Batch Consumption Time: 0.29052
Total Iteration Time: 4.70182

Cumulative Model Updates: 191,444
Cumulative Timesteps: 1,596,474,012

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23.34423
Policy Entropy: 3.81180
Value Function Loss: 0.02791

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.13380
Policy Update Magnitude: 0.44236
Value Function Update Magnitude: 0.60190

Collected Steps per Second: 22,836.63947
Overall Steps per Second: 10,848.82015

Timestep Collection Time: 2.18946
Timestep Consumption Time: 2.41933
PPO Batch Consumption Time: 0.27699
Total Iteration Time: 4.60880

Cumulative Model Updates: 191,450
Cumulative Timesteps: 1,596,524,012

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1596524012...
Checkpoint 1596524012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,410.97386
Policy Entropy: 3.79284
Value Function Loss: 0.03182

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12760
Policy Update Magnitude: 0.42025
Value Function Update Magnitude: 0.57701

Collected Steps per Second: 22,661.66375
Overall Steps per Second: 10,733.12853

Timestep Collection Time: 2.20663
Timestep Consumption Time: 2.45240
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.65903

Cumulative Model Updates: 191,456
Cumulative Timesteps: 1,596,574,018

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 711.20314
Policy Entropy: 3.81299
Value Function Loss: 0.02898

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.44851
Value Function Update Magnitude: 0.67217

Collected Steps per Second: 22,993.18528
Overall Steps per Second: 10,877.70711

Timestep Collection Time: 2.17578
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.59913

Cumulative Model Updates: 191,462
Cumulative Timesteps: 1,596,624,046

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1596624046...
Checkpoint 1596624046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.67694
Policy Entropy: 3.79157
Value Function Loss: 0.03021

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12290
Policy Update Magnitude: 0.41726
Value Function Update Magnitude: 0.77872

Collected Steps per Second: 22,487.80026
Overall Steps per Second: 10,655.00337

Timestep Collection Time: 2.22369
Timestep Consumption Time: 2.46950
PPO Batch Consumption Time: 0.28605
Total Iteration Time: 4.69319

Cumulative Model Updates: 191,468
Cumulative Timesteps: 1,596,674,052

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,544.96135
Policy Entropy: 3.78901
Value Function Loss: 0.02839

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12218
Policy Update Magnitude: 0.39304
Value Function Update Magnitude: 0.75272

Collected Steps per Second: 22,345.04076
Overall Steps per Second: 10,603.82586

Timestep Collection Time: 2.23808
Timestep Consumption Time: 2.47814
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.71622

Cumulative Model Updates: 191,474
Cumulative Timesteps: 1,596,724,062

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1596724062...
Checkpoint 1596724062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,231.70089
Policy Entropy: 3.77909
Value Function Loss: 0.02874

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11909
Policy Update Magnitude: 0.36817
Value Function Update Magnitude: 0.75067

Collected Steps per Second: 22,700.56271
Overall Steps per Second: 10,685.74445

Timestep Collection Time: 2.20329
Timestep Consumption Time: 2.47734
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.68063

Cumulative Model Updates: 191,480
Cumulative Timesteps: 1,596,774,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,219.13344
Policy Entropy: 3.76268
Value Function Loss: 0.02853

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11837
Policy Update Magnitude: 0.37002
Value Function Update Magnitude: 0.74539

Collected Steps per Second: 23,072.65071
Overall Steps per Second: 10,709.01367

Timestep Collection Time: 2.16741
Timestep Consumption Time: 2.50230
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.66971

Cumulative Model Updates: 191,486
Cumulative Timesteps: 1,596,824,086

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1596824086...
Checkpoint 1596824086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,105.88362
Policy Entropy: 3.75159
Value Function Loss: 0.02681

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12747
Policy Update Magnitude: 0.36367
Value Function Update Magnitude: 0.75171

Collected Steps per Second: 22,821.77845
Overall Steps per Second: 10,666.71923

Timestep Collection Time: 2.19106
Timestep Consumption Time: 2.49679
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.68785

Cumulative Model Updates: 191,492
Cumulative Timesteps: 1,596,874,090

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,181.64129
Policy Entropy: 3.72962
Value Function Loss: 0.02482

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12858
Policy Update Magnitude: 0.38488
Value Function Update Magnitude: 0.76043

Collected Steps per Second: 22,979.50561
Overall Steps per Second: 10,921.22164

Timestep Collection Time: 2.17672
Timestep Consumption Time: 2.40335
PPO Batch Consumption Time: 0.27572
Total Iteration Time: 4.58007

Cumulative Model Updates: 191,498
Cumulative Timesteps: 1,596,924,110

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1596924110...
Checkpoint 1596924110 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,118.86135
Policy Entropy: 3.72734
Value Function Loss: 0.02203

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12192
Policy Update Magnitude: 0.42651
Value Function Update Magnitude: 0.63745

Collected Steps per Second: 23,044.22908
Overall Steps per Second: 10,804.58102

Timestep Collection Time: 2.17078
Timestep Consumption Time: 2.45911
PPO Batch Consumption Time: 0.28776
Total Iteration Time: 4.62989

Cumulative Model Updates: 191,504
Cumulative Timesteps: 1,596,974,134

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,920.95426
Policy Entropy: 3.72015
Value Function Loss: 0.02445

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.40730
Value Function Update Magnitude: 0.52611

Collected Steps per Second: 22,611.72527
Overall Steps per Second: 10,852.86804

Timestep Collection Time: 2.21133
Timestep Consumption Time: 2.39593
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.60726

Cumulative Model Updates: 191,510
Cumulative Timesteps: 1,597,024,136

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1597024136...
Checkpoint 1597024136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,748.35991
Policy Entropy: 3.71626
Value Function Loss: 0.02274

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12958
Policy Update Magnitude: 0.38528
Value Function Update Magnitude: 0.48544

Collected Steps per Second: 22,307.80518
Overall Steps per Second: 10,927.12270

Timestep Collection Time: 2.24289
Timestep Consumption Time: 2.33599
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.57888

Cumulative Model Updates: 191,516
Cumulative Timesteps: 1,597,074,170

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,543.64490
Policy Entropy: 3.68172
Value Function Loss: 0.02548

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.39213
Value Function Update Magnitude: 0.50874

Collected Steps per Second: 22,190.82127
Overall Steps per Second: 10,892.87695

Timestep Collection Time: 2.25336
Timestep Consumption Time: 2.33716
PPO Batch Consumption Time: 0.27670
Total Iteration Time: 4.59052

Cumulative Model Updates: 191,522
Cumulative Timesteps: 1,597,124,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1597124174...
Checkpoint 1597124174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,401.35663
Policy Entropy: 3.68999
Value Function Loss: 0.02389

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12507
Policy Update Magnitude: 0.40909
Value Function Update Magnitude: 0.52990

Collected Steps per Second: 22,145.22441
Overall Steps per Second: 10,747.74705

Timestep Collection Time: 2.25827
Timestep Consumption Time: 2.39479
PPO Batch Consumption Time: 0.27554
Total Iteration Time: 4.65307

Cumulative Model Updates: 191,528
Cumulative Timesteps: 1,597,174,184

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,339.08602
Policy Entropy: 3.69332
Value Function Loss: 0.02553

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.39809
Value Function Update Magnitude: 0.55223

Collected Steps per Second: 22,916.91307
Overall Steps per Second: 10,822.33009

Timestep Collection Time: 2.18310
Timestep Consumption Time: 2.43975
PPO Batch Consumption Time: 0.28283
Total Iteration Time: 4.62285

Cumulative Model Updates: 191,534
Cumulative Timesteps: 1,597,224,214

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1597224214...
Checkpoint 1597224214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,241.87142
Policy Entropy: 3.71948
Value Function Loss: 0.02144

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13140
Policy Update Magnitude: 0.40655
Value Function Update Magnitude: 0.59563

Collected Steps per Second: 22,913.99219
Overall Steps per Second: 10,782.02436

Timestep Collection Time: 2.18329
Timestep Consumption Time: 2.45665
PPO Batch Consumption Time: 0.29034
Total Iteration Time: 4.63994

Cumulative Model Updates: 191,540
Cumulative Timesteps: 1,597,274,242

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,414.86314
Policy Entropy: 3.71526
Value Function Loss: 0.02381

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11677
Policy Update Magnitude: 0.40395
Value Function Update Magnitude: 0.55292

Collected Steps per Second: 22,869.27194
Overall Steps per Second: 10,867.93383

Timestep Collection Time: 2.18695
Timestep Consumption Time: 2.41503
PPO Batch Consumption Time: 0.27583
Total Iteration Time: 4.60198

Cumulative Model Updates: 191,546
Cumulative Timesteps: 1,597,324,256

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1597324256...
Checkpoint 1597324256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 188,086.22967
Policy Entropy: 3.72762
Value Function Loss: 0.02747

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13153
Policy Update Magnitude: 0.40703
Value Function Update Magnitude: 0.58136

Collected Steps per Second: 22,738.13035
Overall Steps per Second: 10,681.91523

Timestep Collection Time: 2.19913
Timestep Consumption Time: 2.48206
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.68118

Cumulative Model Updates: 191,552
Cumulative Timesteps: 1,597,374,260

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,767.34331
Policy Entropy: 3.73776
Value Function Loss: 0.03270

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.42091
Value Function Update Magnitude: 0.53432

Collected Steps per Second: 22,860.18503
Overall Steps per Second: 10,866.81349

Timestep Collection Time: 2.18791
Timestep Consumption Time: 2.41473
PPO Batch Consumption Time: 0.27630
Total Iteration Time: 4.60264

Cumulative Model Updates: 191,558
Cumulative Timesteps: 1,597,424,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1597424276...
Checkpoint 1597424276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,125.24611
Policy Entropy: 3.78326
Value Function Loss: 0.02784

Mean KL Divergence: 0.00797
SB3 Clip Fraction: 0.10981
Policy Update Magnitude: 0.42681
Value Function Update Magnitude: 0.70609

Collected Steps per Second: 22,630.27096
Overall Steps per Second: 10,646.49493

Timestep Collection Time: 2.21067
Timestep Consumption Time: 2.48834
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.69901

Cumulative Model Updates: 191,564
Cumulative Timesteps: 1,597,474,304

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,272.38557
Policy Entropy: 3.79250
Value Function Loss: 0.02787

Mean KL Divergence: 0.00815
SB3 Clip Fraction: 0.11233
Policy Update Magnitude: 0.45000
Value Function Update Magnitude: 0.82771

Collected Steps per Second: 23,070.82049
Overall Steps per Second: 10,912.48333

Timestep Collection Time: 2.16793
Timestep Consumption Time: 2.41544
PPO Batch Consumption Time: 0.27553
Total Iteration Time: 4.58337

Cumulative Model Updates: 191,570
Cumulative Timesteps: 1,597,524,320

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1597524320...
Checkpoint 1597524320 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,292.03058
Policy Entropy: 3.79054
Value Function Loss: 0.02727

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11443
Policy Update Magnitude: 0.43564
Value Function Update Magnitude: 0.68513

Collected Steps per Second: 22,848.27240
Overall Steps per Second: 10,681.57480

Timestep Collection Time: 2.18922
Timestep Consumption Time: 2.49361
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.68283

Cumulative Model Updates: 191,576
Cumulative Timesteps: 1,597,574,340

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208.50010
Policy Entropy: 3.76090
Value Function Loss: 0.03216

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11894
Policy Update Magnitude: 0.44475
Value Function Update Magnitude: 0.60190

Collected Steps per Second: 23,196.90953
Overall Steps per Second: 10,801.61742

Timestep Collection Time: 2.15667
Timestep Consumption Time: 2.47486
PPO Batch Consumption Time: 0.28629
Total Iteration Time: 4.63153

Cumulative Model Updates: 191,582
Cumulative Timesteps: 1,597,624,368

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1597624368...
Checkpoint 1597624368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,041.01326
Policy Entropy: 3.74699
Value Function Loss: 0.02840

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.43090
Value Function Update Magnitude: 0.73237

Collected Steps per Second: 22,858.85830
Overall Steps per Second: 10,689.55449

Timestep Collection Time: 2.18786
Timestep Consumption Time: 2.49073
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.67859

Cumulative Model Updates: 191,588
Cumulative Timesteps: 1,597,674,380

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,336.38152
Policy Entropy: 3.71870
Value Function Loss: 0.03376

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.45605
Value Function Update Magnitude: 0.69380

Collected Steps per Second: 22,896.37286
Overall Steps per Second: 10,845.83741

Timestep Collection Time: 2.18463
Timestep Consumption Time: 2.42728
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.61191

Cumulative Model Updates: 191,594
Cumulative Timesteps: 1,597,724,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1597724400...
Checkpoint 1597724400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24,626.49167
Policy Entropy: 3.73864
Value Function Loss: 0.03314

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.51213
Value Function Update Magnitude: 0.75152

Collected Steps per Second: 22,593.30462
Overall Steps per Second: 10,650.12731

Timestep Collection Time: 2.21464
Timestep Consumption Time: 2.48352
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.69816

Cumulative Model Updates: 191,600
Cumulative Timesteps: 1,597,774,436

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,306.87091
Policy Entropy: 3.74317
Value Function Loss: 0.03662

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.51484
Value Function Update Magnitude: 0.89047

Collected Steps per Second: 22,728.85116
Overall Steps per Second: 10,814.44543

Timestep Collection Time: 2.20011
Timestep Consumption Time: 2.42389
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.62400

Cumulative Model Updates: 191,606
Cumulative Timesteps: 1,597,824,442

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1597824442...
Checkpoint 1597824442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.64180
Policy Entropy: 3.78352
Value Function Loss: 0.03340

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.11752
Policy Update Magnitude: 0.49609
Value Function Update Magnitude: 0.83779

Collected Steps per Second: 22,350.06552
Overall Steps per Second: 10,736.67248

Timestep Collection Time: 2.23838
Timestep Consumption Time: 2.42116
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.65954

Cumulative Model Updates: 191,612
Cumulative Timesteps: 1,597,874,470

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,742.15240
Policy Entropy: 3.78011
Value Function Loss: 0.03603

Mean KL Divergence: 0.00816
SB3 Clip Fraction: 0.10944
Policy Update Magnitude: 0.46734
Value Function Update Magnitude: 0.74357

Collected Steps per Second: 22,973.27566
Overall Steps per Second: 10,862.58292

Timestep Collection Time: 2.17688
Timestep Consumption Time: 2.42700
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.60388

Cumulative Model Updates: 191,618
Cumulative Timesteps: 1,597,924,480

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1597924480...
Checkpoint 1597924480 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,815.87110
Policy Entropy: 3.78261
Value Function Loss: 0.03266

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.11713
Policy Update Magnitude: 0.51214
Value Function Update Magnitude: 0.85154

Collected Steps per Second: 22,526.88343
Overall Steps per Second: 10,707.04609

Timestep Collection Time: 2.22028
Timestep Consumption Time: 2.45104
PPO Batch Consumption Time: 0.28331
Total Iteration Time: 4.67132

Cumulative Model Updates: 191,624
Cumulative Timesteps: 1,597,974,496

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,978.04697
Policy Entropy: 3.75156
Value Function Loss: 0.03093

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.09872
Policy Update Magnitude: 0.48721
Value Function Update Magnitude: 0.75259

Collected Steps per Second: 22,993.65486
Overall Steps per Second: 10,837.23374

Timestep Collection Time: 2.17469
Timestep Consumption Time: 2.43941
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.61409

Cumulative Model Updates: 191,630
Cumulative Timesteps: 1,598,024,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1598024500...
Checkpoint 1598024500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,978.04697
Policy Entropy: 3.71354
Value Function Loss: 0.02579

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13174
Policy Update Magnitude: 0.42832
Value Function Update Magnitude: 0.61044

Collected Steps per Second: 22,658.31706
Overall Steps per Second: 10,719.43710

Timestep Collection Time: 2.20758
Timestep Consumption Time: 2.45871
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.66629

Cumulative Model Updates: 191,636
Cumulative Timesteps: 1,598,074,520

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,978.04697
Policy Entropy: 3.70006
Value Function Loss: 0.02036

Mean KL Divergence: 0.01138
SB3 Clip Fraction: 0.15377
Policy Update Magnitude: 0.37707
Value Function Update Magnitude: 0.60490

Collected Steps per Second: 22,983.12067
Overall Steps per Second: 10,906.80652

Timestep Collection Time: 2.17673
Timestep Consumption Time: 2.41013
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.58686

Cumulative Model Updates: 191,642
Cumulative Timesteps: 1,598,124,548

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1598124548...
Checkpoint 1598124548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,978.04697
Policy Entropy: 3.68833
Value Function Loss: 0.01774

Mean KL Divergence: 0.01125
SB3 Clip Fraction: 0.15003
Policy Update Magnitude: 0.33381
Value Function Update Magnitude: 0.51546

Collected Steps per Second: 22,626.87669
Overall Steps per Second: 10,627.41349

Timestep Collection Time: 2.21029
Timestep Consumption Time: 2.49565
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 4.70594

Cumulative Model Updates: 191,648
Cumulative Timesteps: 1,598,174,560

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,978.04697
Policy Entropy: 3.70337
Value Function Loss: 0.01466

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.29189
Value Function Update Magnitude: 0.38584

Collected Steps per Second: 23,040.46739
Overall Steps per Second: 10,900.95530

Timestep Collection Time: 2.17088
Timestep Consumption Time: 2.41753
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.58841

Cumulative Model Updates: 191,654
Cumulative Timesteps: 1,598,224,578

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1598224578...
Checkpoint 1598224578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,978.04697
Policy Entropy: 3.69070
Value Function Loss: 0.01448

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.28386
Value Function Update Magnitude: 0.34137

Collected Steps per Second: 22,427.65993
Overall Steps per Second: 10,630.06632

Timestep Collection Time: 2.23073
Timestep Consumption Time: 2.47573
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.70646

Cumulative Model Updates: 191,660
Cumulative Timesteps: 1,598,274,608

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,978.04697
Policy Entropy: 3.68215
Value Function Loss: 0.01786

Mean KL Divergence: 0.00873
SB3 Clip Fraction: 0.12194
Policy Update Magnitude: 0.32158
Value Function Update Magnitude: 0.45613

Collected Steps per Second: 23,069.88368
Overall Steps per Second: 10,908.45569

Timestep Collection Time: 2.16845
Timestep Consumption Time: 2.41753
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.58598

Cumulative Model Updates: 191,666
Cumulative Timesteps: 1,598,324,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1598324634...
Checkpoint 1598324634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,978.04697
Policy Entropy: 3.69681
Value Function Loss: 0.01733

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.39140
Value Function Update Magnitude: 0.60375

Collected Steps per Second: 22,099.02093
Overall Steps per Second: 10,693.33918

Timestep Collection Time: 2.26390
Timestep Consumption Time: 2.41471
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.67861

Cumulative Model Updates: 191,672
Cumulative Timesteps: 1,598,374,664

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,978.04697
Policy Entropy: 3.69920
Value Function Loss: 0.01729

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.38045
Value Function Update Magnitude: 0.57120

Collected Steps per Second: 22,564.88962
Overall Steps per Second: 10,887.03140

Timestep Collection Time: 2.21636
Timestep Consumption Time: 2.37736
PPO Batch Consumption Time: 0.28334
Total Iteration Time: 4.59372

Cumulative Model Updates: 191,678
Cumulative Timesteps: 1,598,424,676

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1598424676...
Checkpoint 1598424676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,264.99688
Policy Entropy: 3.71836
Value Function Loss: 0.01746

Mean KL Divergence: 0.00863
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.36549
Value Function Update Magnitude: 0.55306

Collected Steps per Second: 22,026.51708
Overall Steps per Second: 10,671.12423

Timestep Collection Time: 2.27072
Timestep Consumption Time: 2.41632
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.68704

Cumulative Model Updates: 191,684
Cumulative Timesteps: 1,598,474,692

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,760.55865
Policy Entropy: 3.70991
Value Function Loss: 0.01855

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12656
Policy Update Magnitude: 0.38381
Value Function Update Magnitude: 0.59536

Collected Steps per Second: 22,444.49551
Overall Steps per Second: 10,839.21745

Timestep Collection Time: 2.22870
Timestep Consumption Time: 2.38621
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.61491

Cumulative Model Updates: 191,690
Cumulative Timesteps: 1,598,524,714

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1598524714...
Checkpoint 1598524714 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,760.55865
Policy Entropy: 3.70959
Value Function Loss: 0.01822

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.38264
Value Function Update Magnitude: 0.65261

Collected Steps per Second: 22,476.85164
Overall Steps per Second: 10,668.30567

Timestep Collection Time: 2.22558
Timestep Consumption Time: 2.46345
PPO Batch Consumption Time: 0.28975
Total Iteration Time: 4.68903

Cumulative Model Updates: 191,696
Cumulative Timesteps: 1,598,574,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,460.64491
Policy Entropy: 3.72138
Value Function Loss: 0.01802

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.12094
Policy Update Magnitude: 0.38863
Value Function Update Magnitude: 0.66500

Collected Steps per Second: 22,793.62089
Overall Steps per Second: 10,829.31732

Timestep Collection Time: 2.19421
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.61839

Cumulative Model Updates: 191,702
Cumulative Timesteps: 1,598,624,752

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1598624752...
Checkpoint 1598624752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,953.95043
Policy Entropy: 3.72877
Value Function Loss: 0.01698

Mean KL Divergence: 0.00874
SB3 Clip Fraction: 0.12367
Policy Update Magnitude: 0.39521
Value Function Update Magnitude: 0.62938

Collected Steps per Second: 22,537.91608
Overall Steps per Second: 10,709.01201

Timestep Collection Time: 2.21910
Timestep Consumption Time: 2.45117
PPO Batch Consumption Time: 0.28271
Total Iteration Time: 4.67027

Cumulative Model Updates: 191,708
Cumulative Timesteps: 1,598,674,766

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,273.29469
Policy Entropy: 3.74675
Value Function Loss: 0.02006

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12260
Policy Update Magnitude: 0.39815
Value Function Update Magnitude: 0.66981

Collected Steps per Second: 22,979.41835
Overall Steps per Second: 10,890.13165

Timestep Collection Time: 2.17682
Timestep Consumption Time: 2.41652
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.59333

Cumulative Model Updates: 191,714
Cumulative Timesteps: 1,598,724,788

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1598724788...
Checkpoint 1598724788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,535.22151
Policy Entropy: 3.73795
Value Function Loss: 0.02165

Mean KL Divergence: 0.00857
SB3 Clip Fraction: 0.12038
Policy Update Magnitude: 0.42691
Value Function Update Magnitude: 0.76725

Collected Steps per Second: 22,026.47344
Overall Steps per Second: 10,647.07477

Timestep Collection Time: 2.27027
Timestep Consumption Time: 2.42642
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.69669

Cumulative Model Updates: 191,720
Cumulative Timesteps: 1,598,774,794

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,535.22151
Policy Entropy: 3.72863
Value Function Loss: 0.02194

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12653
Policy Update Magnitude: 0.46386
Value Function Update Magnitude: 0.83153

Collected Steps per Second: 23,181.60078
Overall Steps per Second: 10,900.57531

Timestep Collection Time: 2.15749
Timestep Consumption Time: 2.43071
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.58820

Cumulative Model Updates: 191,726
Cumulative Timesteps: 1,598,824,808

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1598824808...
Checkpoint 1598824808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,725.42319
Policy Entropy: 3.72291
Value Function Loss: 0.02110

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12382
Policy Update Magnitude: 0.49193
Value Function Update Magnitude: 0.75328

Collected Steps per Second: 22,724.34314
Overall Steps per Second: 10,656.10400

Timestep Collection Time: 2.20090
Timestep Consumption Time: 2.49256
PPO Batch Consumption Time: 0.28931
Total Iteration Time: 4.69346

Cumulative Model Updates: 191,732
Cumulative Timesteps: 1,598,874,822

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 115,752.46779
Policy Entropy: 3.72966
Value Function Loss: 0.02123

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.45762
Value Function Update Magnitude: 0.65354

Collected Steps per Second: 22,282.15100
Overall Steps per Second: 10,892.27359

Timestep Collection Time: 2.24529
Timestep Consumption Time: 2.34787
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.59316

Cumulative Model Updates: 191,738
Cumulative Timesteps: 1,598,924,852

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1598924852...
Checkpoint 1598924852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,425.02595
Policy Entropy: 3.74047
Value Function Loss: 0.02202

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.11614
Policy Update Magnitude: 0.42105
Value Function Update Magnitude: 0.69932

Collected Steps per Second: 21,856.18527
Overall Steps per Second: 10,704.87316

Timestep Collection Time: 2.28988
Timestep Consumption Time: 2.38538
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.67525

Cumulative Model Updates: 191,744
Cumulative Timesteps: 1,598,974,900

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 105,956.24794
Policy Entropy: 3.75853
Value Function Loss: 0.02423

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.42340
Value Function Update Magnitude: 0.81596

Collected Steps per Second: 22,406.43078
Overall Steps per Second: 10,916.33448

Timestep Collection Time: 2.23266
Timestep Consumption Time: 2.35001
PPO Batch Consumption Time: 0.27684
Total Iteration Time: 4.58267

Cumulative Model Updates: 191,750
Cumulative Timesteps: 1,599,024,926

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1599024926...
Checkpoint 1599024926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,956.85273
Policy Entropy: 3.76373
Value Function Loss: 0.02400

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.43138
Value Function Update Magnitude: 0.82168

Collected Steps per Second: 21,827.99505
Overall Steps per Second: 10,599.54391

Timestep Collection Time: 2.29064
Timestep Consumption Time: 2.42655
PPO Batch Consumption Time: 0.29028
Total Iteration Time: 4.71718

Cumulative Model Updates: 191,756
Cumulative Timesteps: 1,599,074,926

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262.67465
Policy Entropy: 3.77752
Value Function Loss: 0.02441

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11617
Policy Update Magnitude: 0.42829
Value Function Update Magnitude: 0.84037

Collected Steps per Second: 22,434.96048
Overall Steps per Second: 10,930.02616

Timestep Collection Time: 2.23000
Timestep Consumption Time: 2.34730
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.57730

Cumulative Model Updates: 191,762
Cumulative Timesteps: 1,599,124,956

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1599124956...
Checkpoint 1599124956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176.35583
Policy Entropy: 3.75340
Value Function Loss: 0.02531

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.11745
Policy Update Magnitude: 0.43196
Value Function Update Magnitude: 0.85627

Collected Steps per Second: 22,033.66821
Overall Steps per Second: 10,610.51830

Timestep Collection Time: 2.27098
Timestep Consumption Time: 2.44491
PPO Batch Consumption Time: 0.28496
Total Iteration Time: 4.71589

Cumulative Model Updates: 191,768
Cumulative Timesteps: 1,599,174,994

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,434.42825
Policy Entropy: 3.74149
Value Function Loss: 0.02241

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.10873
Policy Update Magnitude: 0.46053
Value Function Update Magnitude: 0.78465

Collected Steps per Second: 23,203.29753
Overall Steps per Second: 11,014.75634

Timestep Collection Time: 2.15538
Timestep Consumption Time: 2.38507
PPO Batch Consumption Time: 0.27587
Total Iteration Time: 4.54045

Cumulative Model Updates: 191,774
Cumulative Timesteps: 1,599,225,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1599225006...
Checkpoint 1599225006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,434.42825
Policy Entropy: 3.71642
Value Function Loss: 0.01896

Mean KL Divergence: 0.00850
SB3 Clip Fraction: 0.11136
Policy Update Magnitude: 0.45680
Value Function Update Magnitude: 0.65852

Collected Steps per Second: 22,660.57750
Overall Steps per Second: 10,667.50505

Timestep Collection Time: 2.20648
Timestep Consumption Time: 2.48066
PPO Batch Consumption Time: 0.29050
Total Iteration Time: 4.68713

Cumulative Model Updates: 191,780
Cumulative Timesteps: 1,599,275,006

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,434.42825
Policy Entropy: 3.71202
Value Function Loss: 0.01587

Mean KL Divergence: 0.01128
SB3 Clip Fraction: 0.14860
Policy Update Magnitude: 0.40200
Value Function Update Magnitude: 0.59840

Collected Steps per Second: 23,154.26375
Overall Steps per Second: 10,798.46355

Timestep Collection Time: 2.15978
Timestep Consumption Time: 2.47125
PPO Batch Consumption Time: 0.28585
Total Iteration Time: 4.63103

Cumulative Model Updates: 191,786
Cumulative Timesteps: 1,599,325,014

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1599325014...
Checkpoint 1599325014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 231,284.81038
Policy Entropy: 3.71664
Value Function Loss: 0.01597

Mean KL Divergence: 0.01989
SB3 Clip Fraction: 0.23465
Policy Update Magnitude: 0.38889
Value Function Update Magnitude: 0.65290

Collected Steps per Second: 22,489.92951
Overall Steps per Second: 10,685.63412

Timestep Collection Time: 2.22482
Timestep Consumption Time: 2.45773
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.68255

Cumulative Model Updates: 191,792
Cumulative Timesteps: 1,599,375,050

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203,807.59789
Policy Entropy: 3.73582
Value Function Loss: 0.01917

Mean KL Divergence: 0.01895
SB3 Clip Fraction: 0.21209
Policy Update Magnitude: 0.38430
Value Function Update Magnitude: 0.61785

Collected Steps per Second: 23,152.00865
Overall Steps per Second: 10,936.11351

Timestep Collection Time: 2.15981
Timestep Consumption Time: 2.41256
PPO Batch Consumption Time: 0.27671
Total Iteration Time: 4.57237

Cumulative Model Updates: 191,798
Cumulative Timesteps: 1,599,425,054

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1599425054...
Checkpoint 1599425054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,979.96844
Policy Entropy: 3.74302
Value Function Loss: 0.02235

Mean KL Divergence: 0.01227
SB3 Clip Fraction: 0.14350
Policy Update Magnitude: 0.41229
Value Function Update Magnitude: 0.51871

Collected Steps per Second: 23,005.27678
Overall Steps per Second: 10,775.80542

Timestep Collection Time: 2.17411
Timestep Consumption Time: 2.46740
PPO Batch Consumption Time: 0.28688
Total Iteration Time: 4.64151

Cumulative Model Updates: 191,804
Cumulative Timesteps: 1,599,475,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 55,654.67456
Policy Entropy: 3.74458
Value Function Loss: 0.02343

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.46185
Value Function Update Magnitude: 0.51999

Collected Steps per Second: 23,195.37862
Overall Steps per Second: 10,797.94289

Timestep Collection Time: 2.15595
Timestep Consumption Time: 2.47531
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.63125

Cumulative Model Updates: 191,810
Cumulative Timesteps: 1,599,525,078

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1599525078...
Checkpoint 1599525078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,766.41112
Policy Entropy: 3.74278
Value Function Loss: 0.02154

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08395
Policy Update Magnitude: 0.48548
Value Function Update Magnitude: 0.66501

Collected Steps per Second: 22,091.97135
Overall Steps per Second: 10,754.05732

Timestep Collection Time: 2.26399
Timestep Consumption Time: 2.38691
PPO Batch Consumption Time: 0.28759
Total Iteration Time: 4.65090

Cumulative Model Updates: 191,816
Cumulative Timesteps: 1,599,575,094

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,374.15809
Policy Entropy: 3.75580
Value Function Loss: 0.02069

Mean KL Divergence: 0.00703
SB3 Clip Fraction: 0.08820
Policy Update Magnitude: 0.49647
Value Function Update Magnitude: 0.77446

Collected Steps per Second: 22,487.76964
Overall Steps per Second: 10,789.88162

Timestep Collection Time: 2.22459
Timestep Consumption Time: 2.41179
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.63638

Cumulative Model Updates: 191,822
Cumulative Timesteps: 1,599,625,120

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1599625120...
Checkpoint 1599625120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 842.09990
Policy Entropy: 3.75029
Value Function Loss: 0.02110

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09560
Policy Update Magnitude: 0.54357
Value Function Update Magnitude: 0.82761

Collected Steps per Second: 21,982.05862
Overall Steps per Second: 10,701.08976

Timestep Collection Time: 2.27531
Timestep Consumption Time: 2.39861
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.67392

Cumulative Model Updates: 191,828
Cumulative Timesteps: 1,599,675,136

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,545.09849
Policy Entropy: 3.73883
Value Function Loss: 0.02478

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07244
Policy Update Magnitude: 0.60196
Value Function Update Magnitude: 0.84365

Collected Steps per Second: 22,462.82632
Overall Steps per Second: 10,786.93802

Timestep Collection Time: 2.22795
Timestep Consumption Time: 2.41155
PPO Batch Consumption Time: 0.28777
Total Iteration Time: 4.63950

Cumulative Model Updates: 191,834
Cumulative Timesteps: 1,599,725,182

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1599725182...
Checkpoint 1599725182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,846.16166
Policy Entropy: 3.73136
Value Function Loss: 0.02497

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13665
Policy Update Magnitude: 0.55867
Value Function Update Magnitude: 0.85941

Collected Steps per Second: 21,889.19013
Overall Steps per Second: 10,603.94816

Timestep Collection Time: 2.28460
Timestep Consumption Time: 2.43138
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.71598

Cumulative Model Updates: 191,840
Cumulative Timesteps: 1,599,775,190

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,773.52108
Policy Entropy: 3.72837
Value Function Loss: 0.02362

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13507
Policy Update Magnitude: 0.48817
Value Function Update Magnitude: 0.82420

Collected Steps per Second: 22,623.43423
Overall Steps per Second: 10,847.18768

Timestep Collection Time: 2.21231
Timestep Consumption Time: 2.40179
PPO Batch Consumption Time: 0.27795
Total Iteration Time: 4.61410

Cumulative Model Updates: 191,846
Cumulative Timesteps: 1,599,825,240

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1599825240...
Checkpoint 1599825240 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,951.26894
Policy Entropy: 3.72755
Value Function Loss: 0.02075

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.43679
Value Function Update Magnitude: 0.71443

Collected Steps per Second: 22,299.70477
Overall Steps per Second: 10,695.14942

Timestep Collection Time: 2.24254
Timestep Consumption Time: 2.43322
PPO Batch Consumption Time: 0.28364
Total Iteration Time: 4.67576

Cumulative Model Updates: 191,852
Cumulative Timesteps: 1,599,875,248

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.36217
Policy Entropy: 3.72905
Value Function Loss: 0.02188

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12906
Policy Update Magnitude: 0.41126
Value Function Update Magnitude: 0.50157

Collected Steps per Second: 23,028.46616
Overall Steps per Second: 10,899.61013

Timestep Collection Time: 2.17175
Timestep Consumption Time: 2.41667
PPO Batch Consumption Time: 0.27668
Total Iteration Time: 4.58842

Cumulative Model Updates: 191,858
Cumulative Timesteps: 1,599,925,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1599925260...
Checkpoint 1599925260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.36217
Policy Entropy: 3.72967
Value Function Loss: 0.02170

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13252
Policy Update Magnitude: 0.40032
Value Function Update Magnitude: 0.43481

Collected Steps per Second: 22,410.91341
Overall Steps per Second: 10,677.60811

Timestep Collection Time: 2.23132
Timestep Consumption Time: 2.45194
PPO Batch Consumption Time: 0.28357
Total Iteration Time: 4.68326

Cumulative Model Updates: 191,864
Cumulative Timesteps: 1,599,975,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,247.36217
Policy Entropy: 3.71242
Value Function Loss: 0.02117

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.39355
Value Function Update Magnitude: 0.46427

Collected Steps per Second: 23,225.44492
Overall Steps per Second: 10,896.47432

Timestep Collection Time: 2.15359
Timestep Consumption Time: 2.43671
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.59029

Cumulative Model Updates: 191,870
Cumulative Timesteps: 1,600,025,284

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1600025284...
Checkpoint 1600025284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285,587.58685
Policy Entropy: 3.69851
Value Function Loss: 0.02366

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13547
Policy Update Magnitude: 0.43892
Value Function Update Magnitude: 0.54573

Collected Steps per Second: 22,696.29664
Overall Steps per Second: 10,663.41998

Timestep Collection Time: 2.20485
Timestep Consumption Time: 2.48801
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.69287

Cumulative Model Updates: 191,876
Cumulative Timesteps: 1,600,075,326

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 123,122.64296
Policy Entropy: 3.70191
Value Function Loss: 0.02425

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13170
Policy Update Magnitude: 0.51686
Value Function Update Magnitude: 0.68797

Collected Steps per Second: 23,084.32367
Overall Steps per Second: 10,861.55930

Timestep Collection Time: 2.16719
Timestep Consumption Time: 2.43878
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.60597

Cumulative Model Updates: 191,882
Cumulative Timesteps: 1,600,125,354

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1600125354...
Checkpoint 1600125354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,732.27614
Policy Entropy: 3.70306
Value Function Loss: 0.02565

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13508
Policy Update Magnitude: 0.53418
Value Function Update Magnitude: 0.83477

Collected Steps per Second: 22,100.22364
Overall Steps per Second: 10,687.26109

Timestep Collection Time: 2.26369
Timestep Consumption Time: 2.41740
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.68109

Cumulative Model Updates: 191,888
Cumulative Timesteps: 1,600,175,382

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,720.92415
Policy Entropy: 3.70755
Value Function Loss: 0.02732

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13217
Policy Update Magnitude: 0.50780
Value Function Update Magnitude: 0.80935

Collected Steps per Second: 22,900.20899
Overall Steps per Second: 10,843.64311

Timestep Collection Time: 2.18391
Timestep Consumption Time: 2.42819
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.61210

Cumulative Model Updates: 191,894
Cumulative Timesteps: 1,600,225,394

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1600225394...
Checkpoint 1600225394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 183,720.92415
Policy Entropy: 3.69199
Value Function Loss: 0.02922

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.54125
Value Function Update Magnitude: 0.64267

Collected Steps per Second: 22,570.16285
Overall Steps per Second: 10,686.16393

Timestep Collection Time: 2.21531
Timestep Consumption Time: 2.46363
PPO Batch Consumption Time: 0.28642
Total Iteration Time: 4.67895

Cumulative Model Updates: 191,900
Cumulative Timesteps: 1,600,275,394

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 183,720.92415
Policy Entropy: 3.70434
Value Function Loss: 0.02899

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15175
Policy Update Magnitude: 0.54697
Value Function Update Magnitude: 0.52388

Collected Steps per Second: 22,374.04410
Overall Steps per Second: 10,903.23090

Timestep Collection Time: 2.23509
Timestep Consumption Time: 2.35144
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.58653

Cumulative Model Updates: 191,906
Cumulative Timesteps: 1,600,325,402

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1600325402...
Checkpoint 1600325402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158,948.86122
Policy Entropy: 3.69706
Value Function Loss: 0.03183

Mean KL Divergence: 0.02868
SB3 Clip Fraction: 0.28249
Policy Update Magnitude: 0.45463
Value Function Update Magnitude: 0.46288

Collected Steps per Second: 21,457.59052
Overall Steps per Second: 10,724.48100

Timestep Collection Time: 2.33083
Timestep Consumption Time: 2.33271
PPO Batch Consumption Time: 0.27608
Total Iteration Time: 4.66354

Cumulative Model Updates: 191,912
Cumulative Timesteps: 1,600,375,416

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,357.88721
Policy Entropy: 3.69471
Value Function Loss: 0.03946

Mean KL Divergence: 0.01931
SB3 Clip Fraction: 0.21550
Policy Update Magnitude: 0.48801
Value Function Update Magnitude: 0.46999

Collected Steps per Second: 22,114.28070
Overall Steps per Second: 10,839.56992

Timestep Collection Time: 2.26162
Timestep Consumption Time: 2.35241
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.61402

Cumulative Model Updates: 191,918
Cumulative Timesteps: 1,600,425,430

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1600425430...
Checkpoint 1600425430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 349,213.19022
Policy Entropy: 3.68515
Value Function Loss: 0.04556

Mean KL Divergence: 0.01761
SB3 Clip Fraction: 0.18986
Policy Update Magnitude: 0.66624
Value Function Update Magnitude: 0.44628

Collected Steps per Second: 21,540.36160
Overall Steps per Second: 10,667.21169

Timestep Collection Time: 2.32122
Timestep Consumption Time: 2.36604
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.68726

Cumulative Model Updates: 191,924
Cumulative Timesteps: 1,600,475,430

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219,904.04413
Policy Entropy: 3.69993
Value Function Loss: 0.04495

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.11930
Policy Update Magnitude: 0.86170
Value Function Update Magnitude: 0.46184

Collected Steps per Second: 22,256.24150
Overall Steps per Second: 10,662.47176

Timestep Collection Time: 2.24755
Timestep Consumption Time: 2.44386
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.69141

Cumulative Model Updates: 191,930
Cumulative Timesteps: 1,600,525,452

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1600525452...
Checkpoint 1600525452 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 219,904.04413
Policy Entropy: 3.72782
Value Function Loss: 0.03445

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.11826
Policy Update Magnitude: 0.87554
Value Function Update Magnitude: 0.52466

Collected Steps per Second: 22,481.65793
Overall Steps per Second: 10,807.43350

Timestep Collection Time: 2.22510
Timestep Consumption Time: 2.40356
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.62867

Cumulative Model Updates: 191,936
Cumulative Timesteps: 1,600,575,476

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 228,929.05032
Policy Entropy: 3.73525
Value Function Loss: 0.02667

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.13938
Policy Update Magnitude: 0.69751
Value Function Update Magnitude: 0.53263

Collected Steps per Second: 22,881.40836
Overall Steps per Second: 10,894.68226

Timestep Collection Time: 2.18544
Timestep Consumption Time: 2.40450
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.58995

Cumulative Model Updates: 191,942
Cumulative Timesteps: 1,600,625,482

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1600625482...
Checkpoint 1600625482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228,929.05032
Policy Entropy: 3.73951
Value Function Loss: 0.01885

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15188
Policy Update Magnitude: 0.52083
Value Function Update Magnitude: 0.47799

Collected Steps per Second: 22,655.77681
Overall Steps per Second: 10,717.95676

Timestep Collection Time: 2.20791
Timestep Consumption Time: 2.45921
PPO Batch Consumption Time: 0.28562
Total Iteration Time: 4.66712

Cumulative Model Updates: 191,948
Cumulative Timesteps: 1,600,675,504

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207,774.33416
Policy Entropy: 3.72121
Value Function Loss: 0.01957

Mean KL Divergence: 0.01140
SB3 Clip Fraction: 0.14981
Policy Update Magnitude: 0.40130
Value Function Update Magnitude: 0.44619

Collected Steps per Second: 23,061.34621
Overall Steps per Second: 10,878.26926

Timestep Collection Time: 2.16830
Timestep Consumption Time: 2.42838
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.59669

Cumulative Model Updates: 191,954
Cumulative Timesteps: 1,600,725,508

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1600725508...
Checkpoint 1600725508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,438.33723
Policy Entropy: 3.72064
Value Function Loss: 0.02090

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13212
Policy Update Magnitude: 0.41093
Value Function Update Magnitude: 0.45271

Collected Steps per Second: 22,412.03839
Overall Steps per Second: 10,692.46893

Timestep Collection Time: 2.23193
Timestep Consumption Time: 2.44632
PPO Batch Consumption Time: 0.28227
Total Iteration Time: 4.67825

Cumulative Model Updates: 191,960
Cumulative Timesteps: 1,600,775,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,438.33723
Policy Entropy: 3.72636
Value Function Loss: 0.01953

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14268
Policy Update Magnitude: 0.45835
Value Function Update Magnitude: 0.55533

Collected Steps per Second: 23,163.15818
Overall Steps per Second: 10,908.83694

Timestep Collection Time: 2.15920
Timestep Consumption Time: 2.42552
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.58472

Cumulative Model Updates: 191,966
Cumulative Timesteps: 1,600,825,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1600825544...
Checkpoint 1600825544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,438.33723
Policy Entropy: 3.73088
Value Function Loss: 0.01729

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12111
Policy Update Magnitude: 0.43649
Value Function Update Magnitude: 0.56530

Collected Steps per Second: 22,669.09970
Overall Steps per Second: 10,623.77607

Timestep Collection Time: 2.20565
Timestep Consumption Time: 2.50078
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.70642

Cumulative Model Updates: 191,972
Cumulative Timesteps: 1,600,875,544

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 336,918.42464
Policy Entropy: 3.72754
Value Function Loss: 0.01572

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05802
Policy Update Magnitude: 0.42258
Value Function Update Magnitude: 0.49083

Collected Steps per Second: 22,920.16463
Overall Steps per Second: 10,874.55871

Timestep Collection Time: 2.18192
Timestep Consumption Time: 2.41689
PPO Batch Consumption Time: 0.27703
Total Iteration Time: 4.59881

Cumulative Model Updates: 191,978
Cumulative Timesteps: 1,600,925,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1600925554...
Checkpoint 1600925554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 145,085.60530
Policy Entropy: 3.73124
Value Function Loss: 0.01634

Mean KL Divergence: 0.00576
SB3 Clip Fraction: 0.07100
Policy Update Magnitude: 0.42994
Value Function Update Magnitude: 0.46380

Collected Steps per Second: 22,559.97931
Overall Steps per Second: 10,661.67450

Timestep Collection Time: 2.21667
Timestep Consumption Time: 2.47378
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.69045

Cumulative Model Updates: 191,984
Cumulative Timesteps: 1,600,975,562

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,658.58410
Policy Entropy: 3.73777
Value Function Loss: 0.01714

Mean KL Divergence: 0.00424
SB3 Clip Fraction: 0.04661
Policy Update Magnitude: 0.43881
Value Function Update Magnitude: 0.46381

Collected Steps per Second: 23,258.24629
Overall Steps per Second: 10,956.13122

Timestep Collection Time: 2.15029
Timestep Consumption Time: 2.41446
PPO Batch Consumption Time: 0.27593
Total Iteration Time: 4.56475

Cumulative Model Updates: 191,990
Cumulative Timesteps: 1,601,025,574

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1601025574...
Checkpoint 1601025574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,835.71212
Policy Entropy: 3.75474
Value Function Loss: 0.01529

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05455
Policy Update Magnitude: 0.43876
Value Function Update Magnitude: 0.49976

Collected Steps per Second: 22,452.06386
Overall Steps per Second: 10,592.77379

Timestep Collection Time: 2.22723
Timestep Consumption Time: 2.49353
PPO Batch Consumption Time: 0.29131
Total Iteration Time: 4.72077

Cumulative Model Updates: 191,996
Cumulative Timesteps: 1,601,075,580

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,468.30386
Policy Entropy: 3.75326
Value Function Loss: 0.01577

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04623
Policy Update Magnitude: 0.42978
Value Function Update Magnitude: 0.57573

Collected Steps per Second: 22,725.79753
Overall Steps per Second: 10,944.95411

Timestep Collection Time: 2.20155
Timestep Consumption Time: 2.36969
PPO Batch Consumption Time: 0.28079
Total Iteration Time: 4.57124

Cumulative Model Updates: 192,002
Cumulative Timesteps: 1,601,125,612

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1601125612...
Checkpoint 1601125612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,040.05521
Policy Entropy: 3.76649
Value Function Loss: 0.01592

Mean KL Divergence: 0.00375
SB3 Clip Fraction: 0.03707
Policy Update Magnitude: 0.43143
Value Function Update Magnitude: 0.63686

Collected Steps per Second: 21,302.72440
Overall Steps per Second: 10,685.53552

Timestep Collection Time: 2.34853
Timestep Consumption Time: 2.33350
PPO Batch Consumption Time: 0.27557
Total Iteration Time: 4.68203

Cumulative Model Updates: 192,008
Cumulative Timesteps: 1,601,175,642

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 187,723.15130
Policy Entropy: 3.76822
Value Function Loss: 0.01753

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03838
Policy Update Magnitude: 0.43104
Value Function Update Magnitude: 0.65596

Collected Steps per Second: 22,401.14966
Overall Steps per Second: 10,813.67030

Timestep Collection Time: 2.23203
Timestep Consumption Time: 2.39175
PPO Batch Consumption Time: 0.28369
Total Iteration Time: 4.62378

Cumulative Model Updates: 192,014
Cumulative Timesteps: 1,601,225,642

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1601225642...
Checkpoint 1601225642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,462.74038
Policy Entropy: 3.76846
Value Function Loss: 0.01669

Mean KL Divergence: 0.00346
SB3 Clip Fraction: 0.03354
Policy Update Magnitude: 0.43934
Value Function Update Magnitude: 0.61375

Collected Steps per Second: 21,861.38894
Overall Steps per Second: 10,651.93682

Timestep Collection Time: 2.28833
Timestep Consumption Time: 2.40810
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.69642

Cumulative Model Updates: 192,020
Cumulative Timesteps: 1,601,275,668

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,959.58131
Policy Entropy: 3.76296
Value Function Loss: 0.01620

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05446
Policy Update Magnitude: 0.42828
Value Function Update Magnitude: 0.52821

Collected Steps per Second: 22,944.48437
Overall Steps per Second: 10,913.65025

Timestep Collection Time: 2.18013
Timestep Consumption Time: 2.40330
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.58343

Cumulative Model Updates: 192,026
Cumulative Timesteps: 1,601,325,690

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1601325690...
Checkpoint 1601325690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,959.58131
Policy Entropy: 3.75134
Value Function Loss: 0.01305

Mean KL Divergence: 0.00837
SB3 Clip Fraction: 0.11036
Policy Update Magnitude: 0.37535
Value Function Update Magnitude: 0.45227

Collected Steps per Second: 22,539.61262
Overall Steps per Second: 10,649.98914

Timestep Collection Time: 2.21929
Timestep Consumption Time: 2.47761
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.69691

Cumulative Model Updates: 192,032
Cumulative Timesteps: 1,601,375,712

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,325.83869
Policy Entropy: 3.72502
Value Function Loss: 0.02010

Mean KL Divergence: 0.01137
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.33865
Value Function Update Magnitude: 0.46012

Collected Steps per Second: 22,924.84013
Overall Steps per Second: 10,824.09289

Timestep Collection Time: 2.18148
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.62025

Cumulative Model Updates: 192,038
Cumulative Timesteps: 1,601,425,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1601425722...
Checkpoint 1601425722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 233,624.58745
Policy Entropy: 3.73745
Value Function Loss: 0.02491

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.14938
Policy Update Magnitude: 0.36486
Value Function Update Magnitude: 0.48154

Collected Steps per Second: 22,571.84069
Overall Steps per Second: 10,725.19091

Timestep Collection Time: 2.21621
Timestep Consumption Time: 2.44795
PPO Batch Consumption Time: 0.28330
Total Iteration Time: 4.66416

Cumulative Model Updates: 192,044
Cumulative Timesteps: 1,601,475,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,426.73072
Policy Entropy: 3.71621
Value Function Loss: 0.03131

Mean KL Divergence: 0.01375
SB3 Clip Fraction: 0.16086
Policy Update Magnitude: 0.40841
Value Function Update Magnitude: 0.51587

Collected Steps per Second: 23,010.91679
Overall Steps per Second: 10,888.22740

Timestep Collection Time: 2.17288
Timestep Consumption Time: 2.41923
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.59212

Cumulative Model Updates: 192,050
Cumulative Timesteps: 1,601,525,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1601525746...
Checkpoint 1601525746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,280.09354
Policy Entropy: 3.73979
Value Function Loss: 0.02718

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.41704
Value Function Update Magnitude: 0.55836

Collected Steps per Second: 22,627.32097
Overall Steps per Second: 10,673.75366

Timestep Collection Time: 2.21104
Timestep Consumption Time: 2.47615
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.68720

Cumulative Model Updates: 192,056
Cumulative Timesteps: 1,601,575,776

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,167.69089
Policy Entropy: 3.71827
Value Function Loss: 0.03404

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.14028
Policy Update Magnitude: 0.40658
Value Function Update Magnitude: 0.44578

Collected Steps per Second: 22,714.56339
Overall Steps per Second: 10,817.46094

Timestep Collection Time: 2.20150
Timestep Consumption Time: 2.42122
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.62271

Cumulative Model Updates: 192,062
Cumulative Timesteps: 1,601,625,782

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1601625782...
Checkpoint 1601625782 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 161,246.14931
Policy Entropy: 3.75199
Value Function Loss: 0.03681

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12671
Policy Update Magnitude: 0.42121
Value Function Update Magnitude: 0.46831

Collected Steps per Second: 22,734.29989
Overall Steps per Second: 10,731.29641

Timestep Collection Time: 2.20055
Timestep Consumption Time: 2.46133
PPO Batch Consumption Time: 0.28395
Total Iteration Time: 4.66188

Cumulative Model Updates: 192,068
Cumulative Timesteps: 1,601,675,810

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,916.38628
Policy Entropy: 3.76799
Value Function Loss: 0.04287

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.43718
Value Function Update Magnitude: 0.48052

Collected Steps per Second: 23,035.70590
Overall Steps per Second: 10,874.37677

Timestep Collection Time: 2.17124
Timestep Consumption Time: 2.42820
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.59944

Cumulative Model Updates: 192,074
Cumulative Timesteps: 1,601,725,826

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1601725826...
Checkpoint 1601725826 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323.17021
Policy Entropy: 3.80169
Value Function Loss: 0.03750

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11650
Policy Update Magnitude: 0.43325
Value Function Update Magnitude: 0.66485

Collected Steps per Second: 22,480.95769
Overall Steps per Second: 10,688.71358

Timestep Collection Time: 2.22544
Timestep Consumption Time: 2.45520
PPO Batch Consumption Time: 0.28508
Total Iteration Time: 4.68064

Cumulative Model Updates: 192,080
Cumulative Timesteps: 1,601,775,856

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.97307
Policy Entropy: 3.79342
Value Function Loss: 0.03104

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.42052
Value Function Update Magnitude: 0.85629

Collected Steps per Second: 22,754.04128
Overall Steps per Second: 10,834.81245

Timestep Collection Time: 2.19873
Timestep Consumption Time: 2.41879
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.61752

Cumulative Model Updates: 192,086
Cumulative Timesteps: 1,601,825,886

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1601825886...
Checkpoint 1601825886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 24.49673
Policy Entropy: 3.76947
Value Function Loss: 0.02281

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12914
Policy Update Magnitude: 0.39680
Value Function Update Magnitude: 0.89442

Collected Steps per Second: 22,778.71765
Overall Steps per Second: 10,702.62060

Timestep Collection Time: 2.19652
Timestep Consumption Time: 2.47841
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.67493

Cumulative Model Updates: 192,092
Cumulative Timesteps: 1,601,875,920

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,576.38074
Policy Entropy: 3.75752
Value Function Loss: 0.02327

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.39053
Value Function Update Magnitude: 0.91891

Collected Steps per Second: 22,756.19542
Overall Steps per Second: 10,849.16984

Timestep Collection Time: 2.19826
Timestep Consumption Time: 2.41260
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.61086

Cumulative Model Updates: 192,098
Cumulative Timesteps: 1,601,925,944

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1601925944...
Checkpoint 1601925944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,112.68028
Policy Entropy: 3.74480
Value Function Loss: 0.02521

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12403
Policy Update Magnitude: 0.43368
Value Function Update Magnitude: 0.96811

Collected Steps per Second: 22,432.20088
Overall Steps per Second: 10,693.36055

Timestep Collection Time: 2.22930
Timestep Consumption Time: 2.44725
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.67655

Cumulative Model Updates: 192,104
Cumulative Timesteps: 1,601,975,952

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,386.05545
Policy Entropy: 3.76233
Value Function Loss: 0.02726

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.44309
Value Function Update Magnitude: 0.97357

Collected Steps per Second: 23,130.35775
Overall Steps per Second: 10,873.96752

Timestep Collection Time: 2.16201
Timestep Consumption Time: 2.43687
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.59887

Cumulative Model Updates: 192,110
Cumulative Timesteps: 1,602,025,960

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1602025960...
Checkpoint 1602025960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,890.46253
Policy Entropy: 3.75550
Value Function Loss: 0.02495

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.12169
Policy Update Magnitude: 0.41461
Value Function Update Magnitude: 0.89914

Collected Steps per Second: 22,447.86278
Overall Steps per Second: 10,680.73088

Timestep Collection Time: 2.22810
Timestep Consumption Time: 2.45473
PPO Batch Consumption Time: 0.28355
Total Iteration Time: 4.68283

Cumulative Model Updates: 192,116
Cumulative Timesteps: 1,602,075,976

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 627.14057
Policy Entropy: 3.77003
Value Function Loss: 0.02409

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12232
Policy Update Magnitude: 0.42129
Value Function Update Magnitude: 0.74747

Collected Steps per Second: 22,859.90381
Overall Steps per Second: 10,832.43282

Timestep Collection Time: 2.18724
Timestep Consumption Time: 2.42853
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.61577

Cumulative Model Updates: 192,122
Cumulative Timesteps: 1,602,125,976

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1602125976...
Checkpoint 1602125976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,173.18733
Policy Entropy: 3.76046
Value Function Loss: 0.02623

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12225
Policy Update Magnitude: 0.39467
Value Function Update Magnitude: 0.64053

Collected Steps per Second: 22,599.69697
Overall Steps per Second: 10,690.85791

Timestep Collection Time: 2.21366
Timestep Consumption Time: 2.46585
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.67951

Cumulative Model Updates: 192,128
Cumulative Timesteps: 1,602,176,004

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,525.33676
Policy Entropy: 3.76559
Value Function Loss: 0.02681

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11670
Policy Update Magnitude: 0.41542
Value Function Update Magnitude: 0.66880

Collected Steps per Second: 23,085.75357
Overall Steps per Second: 10,883.63746

Timestep Collection Time: 2.16636
Timestep Consumption Time: 2.42880
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.59515

Cumulative Model Updates: 192,134
Cumulative Timesteps: 1,602,226,016

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1602226016...
Checkpoint 1602226016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,311.55092
Policy Entropy: 3.77607
Value Function Loss: 0.03060

Mean KL Divergence: 0.00865
SB3 Clip Fraction: 0.11433
Policy Update Magnitude: 0.46553
Value Function Update Magnitude: 0.87861

Collected Steps per Second: 22,824.88084
Overall Steps per Second: 10,692.22461

Timestep Collection Time: 2.19156
Timestep Consumption Time: 2.48680
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.67835

Cumulative Model Updates: 192,140
Cumulative Timesteps: 1,602,276,038

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,125.34668
Policy Entropy: 3.81636
Value Function Loss: 0.03246

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06177
Policy Update Magnitude: 0.56946
Value Function Update Magnitude: 1.05928

Collected Steps per Second: 22,966.39525
Overall Steps per Second: 10,938.68860

Timestep Collection Time: 2.17840
Timestep Consumption Time: 2.39527
PPO Batch Consumption Time: 0.27697
Total Iteration Time: 4.57367

Cumulative Model Updates: 192,146
Cumulative Timesteps: 1,602,326,068

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1602326068...
Checkpoint 1602326068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 422.70725
Policy Entropy: 3.81805
Value Function Loss: 0.03737

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.11946
Policy Update Magnitude: 0.58656
Value Function Update Magnitude: 1.00227

Collected Steps per Second: 22,645.26463
Overall Steps per Second: 10,623.89931

Timestep Collection Time: 2.20876
Timestep Consumption Time: 2.49930
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.70806

Cumulative Model Updates: 192,152
Cumulative Timesteps: 1,602,376,086

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,259.26967
Policy Entropy: 3.80237
Value Function Loss: 0.03681

Mean KL Divergence: 0.00805
SB3 Clip Fraction: 0.10481
Policy Update Magnitude: 0.56135
Value Function Update Magnitude: 0.80066

Collected Steps per Second: 22,586.01112
Overall Steps per Second: 10,678.43092

Timestep Collection Time: 2.21456
Timestep Consumption Time: 2.46946
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.68402

Cumulative Model Updates: 192,158
Cumulative Timesteps: 1,602,426,104

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1602426104...
Checkpoint 1602426104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,390.79387
Policy Entropy: 3.76101
Value Function Loss: 0.04019

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11877
Policy Update Magnitude: 0.55851
Value Function Update Magnitude: 0.69190

Collected Steps per Second: 22,565.28220
Overall Steps per Second: 10,795.46699

Timestep Collection Time: 2.21677
Timestep Consumption Time: 2.41684
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.63361

Cumulative Model Updates: 192,164
Cumulative Timesteps: 1,602,476,126

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 94,572.65665
Policy Entropy: 3.76703
Value Function Loss: 0.03765

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12357
Policy Update Magnitude: 0.58483
Value Function Update Magnitude: 0.68754

Collected Steps per Second: 22,787.95826
Overall Steps per Second: 10,720.47281

Timestep Collection Time: 2.19563
Timestep Consumption Time: 2.47151
PPO Batch Consumption Time: 0.28798
Total Iteration Time: 4.66714

Cumulative Model Updates: 192,170
Cumulative Timesteps: 1,602,526,160

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1602526160...
Checkpoint 1602526160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 303,597.32964
Policy Entropy: 3.74159
Value Function Loss: 0.04300

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.60579
Value Function Update Magnitude: 0.67286

Collected Steps per Second: 22,627.08482
Overall Steps per Second: 10,826.14886

Timestep Collection Time: 2.21001
Timestep Consumption Time: 2.40900
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.61900

Cumulative Model Updates: 192,176
Cumulative Timesteps: 1,602,576,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,858.93057
Policy Entropy: 3.76461
Value Function Loss: 0.03668

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.61823
Value Function Update Magnitude: 0.59886

Collected Steps per Second: 22,681.30288
Overall Steps per Second: 10,664.35998

Timestep Collection Time: 2.20446
Timestep Consumption Time: 2.48406
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.68851

Cumulative Model Updates: 192,182
Cumulative Timesteps: 1,602,626,166

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1602626166...
Checkpoint 1602626166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167,284.13333
Policy Entropy: 3.72680
Value Function Loss: 0.04380

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.15792
Policy Update Magnitude: 0.64308
Value Function Update Magnitude: 0.68532

Collected Steps per Second: 22,380.97719
Overall Steps per Second: 10,631.48160

Timestep Collection Time: 2.23422
Timestep Consumption Time: 2.46917
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.70339

Cumulative Model Updates: 192,188
Cumulative Timesteps: 1,602,676,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,297.46439
Policy Entropy: 3.70984
Value Function Loss: 0.06738

Mean KL Divergence: 0.01463
SB3 Clip Fraction: 0.18165
Policy Update Magnitude: 0.65018
Value Function Update Magnitude: 0.59091

Collected Steps per Second: 22,662.32050
Overall Steps per Second: 10,851.85099

Timestep Collection Time: 2.20648
Timestep Consumption Time: 2.40140
PPO Batch Consumption Time: 0.27584
Total Iteration Time: 4.60788

Cumulative Model Updates: 192,194
Cumulative Timesteps: 1,602,726,174

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1602726174...
Checkpoint 1602726174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,271.39736
Policy Entropy: 3.68807
Value Function Loss: 0.06300

Mean KL Divergence: 0.01622
SB3 Clip Fraction: 0.19059
Policy Update Magnitude: 0.77534
Value Function Update Magnitude: 0.45280

Collected Steps per Second: 22,370.91441
Overall Steps per Second: 10,600.18448

Timestep Collection Time: 2.23594
Timestep Consumption Time: 2.48285
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.71879

Cumulative Model Updates: 192,200
Cumulative Timesteps: 1,602,776,194

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,098.49977
Policy Entropy: 3.71580
Value Function Loss: 0.06940

Mean KL Divergence: 0.01352
SB3 Clip Fraction: 0.16273
Policy Update Magnitude: 0.76157
Value Function Update Magnitude: 0.43200

Collected Steps per Second: 22,857.66632
Overall Steps per Second: 10,811.99898

Timestep Collection Time: 2.18762
Timestep Consumption Time: 2.43724
PPO Batch Consumption Time: 0.27919
Total Iteration Time: 4.62486

Cumulative Model Updates: 192,206
Cumulative Timesteps: 1,602,826,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1602826198...
Checkpoint 1602826198 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,032.65022
Policy Entropy: 3.75270
Value Function Loss: 0.05760

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.13858
Policy Update Magnitude: 0.79018
Value Function Update Magnitude: 0.52316

Collected Steps per Second: 22,686.96375
Overall Steps per Second: 10,671.51319

Timestep Collection Time: 2.20541
Timestep Consumption Time: 2.48315
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.68856

Cumulative Model Updates: 192,212
Cumulative Timesteps: 1,602,876,232

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,183.87560
Policy Entropy: 3.73550
Value Function Loss: 0.06650

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.15053
Policy Update Magnitude: 0.77512
Value Function Update Magnitude: 0.58357

Collected Steps per Second: 22,912.14394
Overall Steps per Second: 10,940.10459

Timestep Collection Time: 2.18277
Timestep Consumption Time: 2.38866
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.57144

Cumulative Model Updates: 192,218
Cumulative Timesteps: 1,602,926,244

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1602926244...
Checkpoint 1602926244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,285.29439
Policy Entropy: 3.73245
Value Function Loss: 0.07281

Mean KL Divergence: 0.01195
SB3 Clip Fraction: 0.14524
Policy Update Magnitude: 0.79715
Value Function Update Magnitude: 0.50167

Collected Steps per Second: 22,638.26879
Overall Steps per Second: 10,708.47935

Timestep Collection Time: 2.20874
Timestep Consumption Time: 2.46065
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.66938

Cumulative Model Updates: 192,224
Cumulative Timesteps: 1,602,976,246

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 77,900.99673
Policy Entropy: 3.72000
Value Function Loss: 0.07117

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.74994
Value Function Update Magnitude: 0.43593

Collected Steps per Second: 22,481.59746
Overall Steps per Second: 10,750.70636

Timestep Collection Time: 2.22484
Timestep Consumption Time: 2.42769
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.65253

Cumulative Model Updates: 192,230
Cumulative Timesteps: 1,603,026,264

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1603026264...
Checkpoint 1603026264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,166.17392
Policy Entropy: 3.75355
Value Function Loss: 0.05666

Mean KL Divergence: 0.00724
SB3 Clip Fraction: 0.08970
Policy Update Magnitude: 0.90870
Value Function Update Magnitude: 0.59733

Collected Steps per Second: 22,574.27536
Overall Steps per Second: 10,712.39069

Timestep Collection Time: 2.21544
Timestep Consumption Time: 2.45317
PPO Batch Consumption Time: 0.28916
Total Iteration Time: 4.66861

Cumulative Model Updates: 192,236
Cumulative Timesteps: 1,603,076,276

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,090.75563
Policy Entropy: 3.77578
Value Function Loss: 0.05223

Mean KL Divergence: 0.00861
SB3 Clip Fraction: 0.11033
Policy Update Magnitude: 0.94401
Value Function Update Magnitude: 0.70792

Collected Steps per Second: 22,666.63989
Overall Steps per Second: 10,816.48522

Timestep Collection Time: 2.20624
Timestep Consumption Time: 2.41708
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.62331

Cumulative Model Updates: 192,242
Cumulative Timesteps: 1,603,126,284

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1603126284...
Checkpoint 1603126284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.75950
Policy Entropy: 3.83237
Value Function Loss: 0.04339

Mean KL Divergence: 0.00626
SB3 Clip Fraction: 0.07506
Policy Update Magnitude: 0.89181
Value Function Update Magnitude: 0.79524

Collected Steps per Second: 22,643.98568
Overall Steps per Second: 10,736.39680

Timestep Collection Time: 2.20906
Timestep Consumption Time: 2.45004
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.65911

Cumulative Model Updates: 192,248
Cumulative Timesteps: 1,603,176,306

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 419.88329
Policy Entropy: 3.85453
Value Function Loss: 0.03492

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07576
Policy Update Magnitude: 0.83645
Value Function Update Magnitude: 0.96856

Collected Steps per Second: 23,028.69556
Overall Steps per Second: 10,969.40704

Timestep Collection Time: 2.17251
Timestep Consumption Time: 2.38836
PPO Batch Consumption Time: 0.27667
Total Iteration Time: 4.56087

Cumulative Model Updates: 192,254
Cumulative Timesteps: 1,603,226,336

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1603226336...
Checkpoint 1603226336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27.99827
Policy Entropy: 3.84329
Value Function Loss: 0.02868

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05793
Policy Update Magnitude: 0.73563
Value Function Update Magnitude: 0.93899

Collected Steps per Second: 22,714.05224
Overall Steps per Second: 10,757.90957

Timestep Collection Time: 2.20216
Timestep Consumption Time: 2.44744
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.64960

Cumulative Model Updates: 192,260
Cumulative Timesteps: 1,603,276,356

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.21956
Policy Entropy: 3.78680
Value Function Loss: 0.02457

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.09054
Policy Update Magnitude: 0.62578
Value Function Update Magnitude: 0.80537

Collected Steps per Second: 23,144.58802
Overall Steps per Second: 10,763.92910

Timestep Collection Time: 2.16128
Timestep Consumption Time: 2.48590
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.64719

Cumulative Model Updates: 192,266
Cumulative Timesteps: 1,603,326,378

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1603326378...
Checkpoint 1603326378 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,697.94419
Policy Entropy: 3.74989
Value Function Loss: 0.02168

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06617
Policy Update Magnitude: 0.55581
Value Function Update Magnitude: 0.66567

Collected Steps per Second: 22,683.98389
Overall Steps per Second: 10,649.60345

Timestep Collection Time: 2.20490
Timestep Consumption Time: 2.49161
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.69651

Cumulative Model Updates: 192,272
Cumulative Timesteps: 1,603,376,394

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,329.06263
Policy Entropy: 3.73818
Value Function Loss: 0.01785

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09832
Policy Update Magnitude: 0.48080
Value Function Update Magnitude: 0.57874

Collected Steps per Second: 22,998.80081
Overall Steps per Second: 10,912.43325

Timestep Collection Time: 2.17446
Timestep Consumption Time: 2.40838
PPO Batch Consumption Time: 0.27641
Total Iteration Time: 4.58285

Cumulative Model Updates: 192,278
Cumulative Timesteps: 1,603,426,404

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1603426404...
Checkpoint 1603426404 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 171,510.60744
Policy Entropy: 3.74454
Value Function Loss: 0.01863

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.17155
Policy Update Magnitude: 0.37306
Value Function Update Magnitude: 0.59950

Collected Steps per Second: 23,041.56700
Overall Steps per Second: 10,757.70012

Timestep Collection Time: 2.17069
Timestep Consumption Time: 2.47864
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.64932

Cumulative Model Updates: 192,284
Cumulative Timesteps: 1,603,476,420

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 113,731.62718
Policy Entropy: 3.73425
Value Function Loss: 0.02315

Mean KL Divergence: 0.01148
SB3 Clip Fraction: 0.15370
Policy Update Magnitude: 0.36213
Value Function Update Magnitude: 0.71005

Collected Steps per Second: 23,212.34657
Overall Steps per Second: 10,737.36418

Timestep Collection Time: 2.15532
Timestep Consumption Time: 2.50411
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.65943

Cumulative Model Updates: 192,290
Cumulative Timesteps: 1,603,526,450

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1603526450...
Checkpoint 1603526450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,126.29894
Policy Entropy: 3.71629
Value Function Loss: 0.02438

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.14297
Policy Update Magnitude: 0.42044
Value Function Update Magnitude: 0.69686

Collected Steps per Second: 22,856.46388
Overall Steps per Second: 10,743.38331

Timestep Collection Time: 2.18818
Timestep Consumption Time: 2.46715
PPO Batch Consumption Time: 0.28866
Total Iteration Time: 4.65533

Cumulative Model Updates: 192,296
Cumulative Timesteps: 1,603,576,464

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 375,071.96077
Policy Entropy: 3.71751
Value Function Loss: 0.02574

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13915
Policy Update Magnitude: 0.42190
Value Function Update Magnitude: 0.54127

Collected Steps per Second: 22,865.78223
Overall Steps per Second: 10,846.03755

Timestep Collection Time: 2.18746
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.27652
Total Iteration Time: 4.61164

Cumulative Model Updates: 192,302
Cumulative Timesteps: 1,603,626,482

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1603626482...
Checkpoint 1603626482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,099.70645
Policy Entropy: 3.72385
Value Function Loss: 0.02231

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13551
Policy Update Magnitude: 0.39979
Value Function Update Magnitude: 0.43792

Collected Steps per Second: 22,841.74341
Overall Steps per Second: 10,662.19959

Timestep Collection Time: 2.18976
Timestep Consumption Time: 2.50139
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.69115

Cumulative Model Updates: 192,308
Cumulative Timesteps: 1,603,676,500

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,099.70645
Policy Entropy: 3.72872
Value Function Loss: 0.01989

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12303
Policy Update Magnitude: 0.37193
Value Function Update Magnitude: 0.40254

Collected Steps per Second: 22,915.61146
Overall Steps per Second: 10,886.90073

Timestep Collection Time: 2.18323
Timestep Consumption Time: 2.41220
PPO Batch Consumption Time: 0.27959
Total Iteration Time: 4.59543

Cumulative Model Updates: 192,314
Cumulative Timesteps: 1,603,726,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1603726530...
Checkpoint 1603726530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,099.70645
Policy Entropy: 3.72658
Value Function Loss: 0.01897

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.11505
Policy Update Magnitude: 0.34211
Value Function Update Magnitude: 0.30299

Collected Steps per Second: 22,740.54047
Overall Steps per Second: 10,679.18694

Timestep Collection Time: 2.20083
Timestep Consumption Time: 2.48567
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.68650

Cumulative Model Updates: 192,320
Cumulative Timesteps: 1,603,776,578

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,099.70645
Policy Entropy: 3.71716
Value Function Loss: 0.02091

Mean KL Divergence: 0.00839
SB3 Clip Fraction: 0.11411
Policy Update Magnitude: 0.33724
Value Function Update Magnitude: 0.25296

Collected Steps per Second: 22,482.45362
Overall Steps per Second: 10,833.16768

Timestep Collection Time: 2.22449
Timestep Consumption Time: 2.39207
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.61656

Cumulative Model Updates: 192,326
Cumulative Timesteps: 1,603,826,590

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1603826590...
Checkpoint 1603826590 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 246,099.70645
Policy Entropy: 3.71181
Value Function Loss: 0.01982

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.34737
Value Function Update Magnitude: 0.31578

Collected Steps per Second: 21,951.34403
Overall Steps per Second: 10,622.17441

Timestep Collection Time: 2.27813
Timestep Consumption Time: 2.42976
PPO Batch Consumption Time: 0.28985
Total Iteration Time: 4.70789

Cumulative Model Updates: 192,332
Cumulative Timesteps: 1,603,876,598

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,099.70645
Policy Entropy: 3.70952
Value Function Loss: 0.02270

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12470
Policy Update Magnitude: 0.35481
Value Function Update Magnitude: 0.38387

Collected Steps per Second: 22,364.57730
Overall Steps per Second: 10,896.29912

Timestep Collection Time: 2.23702
Timestep Consumption Time: 2.35445
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.59147

Cumulative Model Updates: 192,338
Cumulative Timesteps: 1,603,926,628

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1603926628...
Checkpoint 1603926628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 153,565.81214
Policy Entropy: 3.71527
Value Function Loss: 0.02489

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12378
Policy Update Magnitude: 0.41557
Value Function Update Magnitude: 0.51846

Collected Steps per Second: 22,112.72735
Overall Steps per Second: 10,752.96530

Timestep Collection Time: 2.26223
Timestep Consumption Time: 2.38989
PPO Batch Consumption Time: 0.27618
Total Iteration Time: 4.65211

Cumulative Model Updates: 192,344
Cumulative Timesteps: 1,603,976,652

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,231.49857
Policy Entropy: 3.72413
Value Function Loss: 0.02730

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12248
Policy Update Magnitude: 0.45932
Value Function Update Magnitude: 0.70879

Collected Steps per Second: 22,850.72794
Overall Steps per Second: 10,881.91974

Timestep Collection Time: 2.18811
Timestep Consumption Time: 2.40666
PPO Batch Consumption Time: 0.27631
Total Iteration Time: 4.59478

Cumulative Model Updates: 192,350
Cumulative Timesteps: 1,604,026,652

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1604026652...
Checkpoint 1604026652 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,415.14014
Policy Entropy: 3.72220
Value Function Loss: 0.02979

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.46936
Value Function Update Magnitude: 0.70952

Collected Steps per Second: 22,814.54049
Overall Steps per Second: 10,779.59517

Timestep Collection Time: 2.19229
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.63988

Cumulative Model Updates: 192,356
Cumulative Timesteps: 1,604,076,668

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,590.19724
Policy Entropy: 3.72941
Value Function Loss: 0.02769

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.45941
Value Function Update Magnitude: 0.62631

Collected Steps per Second: 22,948.33331
Overall Steps per Second: 10,733.15415

Timestep Collection Time: 2.18003
Timestep Consumption Time: 2.48104
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.66107

Cumulative Model Updates: 192,362
Cumulative Timesteps: 1,604,126,696

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1604126696...
Checkpoint 1604126696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,110.59265
Policy Entropy: 3.71512
Value Function Loss: 0.02647

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12433
Policy Update Magnitude: 0.44028
Value Function Update Magnitude: 0.69057

Collected Steps per Second: 22,737.39243
Overall Steps per Second: 10,649.87868

Timestep Collection Time: 2.20025
Timestep Consumption Time: 2.49727
PPO Batch Consumption Time: 0.29295
Total Iteration Time: 4.69752

Cumulative Model Updates: 192,368
Cumulative Timesteps: 1,604,176,724

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 162,694.55512
Policy Entropy: 3.72067
Value Function Loss: 0.02470

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12282
Policy Update Magnitude: 0.44726
Value Function Update Magnitude: 0.74475

Collected Steps per Second: 22,958.67512
Overall Steps per Second: 10,863.47328

Timestep Collection Time: 2.17905
Timestep Consumption Time: 2.42611
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.60516

Cumulative Model Updates: 192,374
Cumulative Timesteps: 1,604,226,752

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1604226752...
Checkpoint 1604226752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,047.29315
Policy Entropy: 3.71221
Value Function Loss: 0.02450

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12042
Policy Update Magnitude: 0.46827
Value Function Update Magnitude: 0.67547

Collected Steps per Second: 22,703.87082
Overall Steps per Second: 10,665.05974

Timestep Collection Time: 2.20359
Timestep Consumption Time: 2.48743
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.69102

Cumulative Model Updates: 192,380
Cumulative Timesteps: 1,604,276,782

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,047.29315
Policy Entropy: 3.71344
Value Function Loss: 0.02385

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.47835
Value Function Update Magnitude: 0.52490

Collected Steps per Second: 22,836.51799
Overall Steps per Second: 10,848.35625

Timestep Collection Time: 2.19009
Timestep Consumption Time: 2.42020
PPO Batch Consumption Time: 0.27725
Total Iteration Time: 4.61028

Cumulative Model Updates: 192,386
Cumulative Timesteps: 1,604,326,796

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1604326796...
Checkpoint 1604326796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,047.29315
Policy Entropy: 3.70016
Value Function Loss: 0.02329

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13135
Policy Update Magnitude: 0.43893
Value Function Update Magnitude: 0.43258

Collected Steps per Second: 22,827.57203
Overall Steps per Second: 10,707.79988

Timestep Collection Time: 2.19042
Timestep Consumption Time: 2.47926
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.66968

Cumulative Model Updates: 192,392
Cumulative Timesteps: 1,604,376,798

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,284.02356
Policy Entropy: 3.69736
Value Function Loss: 0.02449

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.41298
Value Function Update Magnitude: 0.38965

Collected Steps per Second: 23,017.73825
Overall Steps per Second: 10,860.28908

Timestep Collection Time: 2.17267
Timestep Consumption Time: 2.43218
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.60485

Cumulative Model Updates: 192,398
Cumulative Timesteps: 1,604,426,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1604426808...
Checkpoint 1604426808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 181,284.02356
Policy Entropy: 3.68976
Value Function Loss: 0.02435

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.44588
Value Function Update Magnitude: 0.31301

Collected Steps per Second: 22,744.99657
Overall Steps per Second: 10,680.82015

Timestep Collection Time: 2.19837
Timestep Consumption Time: 2.48310
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.68148

Cumulative Model Updates: 192,404
Cumulative Timesteps: 1,604,476,810

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 181,284.02356
Policy Entropy: 3.68045
Value Function Loss: 0.02592

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12678
Policy Update Magnitude: 0.45280
Value Function Update Magnitude: 0.37766

Collected Steps per Second: 23,059.52871
Overall Steps per Second: 10,881.83350

Timestep Collection Time: 2.16847
Timestep Consumption Time: 2.42671
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.59518

Cumulative Model Updates: 192,410
Cumulative Timesteps: 1,604,526,814

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1604526814...
Checkpoint 1604526814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,069.55465
Policy Entropy: 3.68480
Value Function Loss: 0.02737

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12296
Policy Update Magnitude: 0.46456
Value Function Update Magnitude: 0.44253

Collected Steps per Second: 22,670.03923
Overall Steps per Second: 10,675.77293

Timestep Collection Time: 2.20679
Timestep Consumption Time: 2.47934
PPO Batch Consumption Time: 0.28945
Total Iteration Time: 4.68612

Cumulative Model Updates: 192,416
Cumulative Timesteps: 1,604,576,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,552.68530
Policy Entropy: 3.70275
Value Function Loss: 0.02963

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.45894
Value Function Update Magnitude: 0.44609

Collected Steps per Second: 22,620.53274
Overall Steps per Second: 10,805.75841

Timestep Collection Time: 2.21162
Timestep Consumption Time: 2.41813
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.62975

Cumulative Model Updates: 192,422
Cumulative Timesteps: 1,604,626,870

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1604626870...
Checkpoint 1604626870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,552.68530
Policy Entropy: 3.72178
Value Function Loss: 0.02276

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.41151
Value Function Update Magnitude: 0.45845

Collected Steps per Second: 22,408.77436
Overall Steps per Second: 10,767.05969

Timestep Collection Time: 2.23225
Timestep Consumption Time: 2.41359
PPO Batch Consumption Time: 0.27649
Total Iteration Time: 4.64584

Cumulative Model Updates: 192,428
Cumulative Timesteps: 1,604,676,892

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,552.68530
Policy Entropy: 3.71686
Value Function Loss: 0.01707

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.11926
Policy Update Magnitude: 0.36123
Value Function Update Magnitude: 0.39153

Collected Steps per Second: 22,850.16167
Overall Steps per Second: 10,867.62336

Timestep Collection Time: 2.18939
Timestep Consumption Time: 2.41400
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.60340

Cumulative Model Updates: 192,434
Cumulative Timesteps: 1,604,726,920

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1604726920...
Checkpoint 1604726920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,586.71180
Policy Entropy: 3.71758
Value Function Loss: 0.01812

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.13066
Policy Update Magnitude: 0.33478
Value Function Update Magnitude: 0.32538

Collected Steps per Second: 22,872.57222
Overall Steps per Second: 10,687.80097

Timestep Collection Time: 2.18804
Timestep Consumption Time: 2.49450
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.68253

Cumulative Model Updates: 192,440
Cumulative Timesteps: 1,604,776,966

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,523.11479
Policy Entropy: 3.72253
Value Function Loss: 0.01850

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12455
Policy Update Magnitude: 0.35420
Value Function Update Magnitude: 0.37246

Collected Steps per Second: 22,099.03168
Overall Steps per Second: 10,841.03643

Timestep Collection Time: 2.26399
Timestep Consumption Time: 2.35107
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.61506

Cumulative Model Updates: 192,446
Cumulative Timesteps: 1,604,826,998

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1604826998...
Checkpoint 1604826998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,869.20976
Policy Entropy: 3.70585
Value Function Loss: 0.02639

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12209
Policy Update Magnitude: 0.39894
Value Function Update Magnitude: 0.38729

Collected Steps per Second: 22,230.85239
Overall Steps per Second: 10,737.98004

Timestep Collection Time: 2.24922
Timestep Consumption Time: 2.40734
PPO Batch Consumption Time: 0.29140
Total Iteration Time: 4.65656

Cumulative Model Updates: 192,452
Cumulative Timesteps: 1,604,877,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,225.99148
Policy Entropy: 3.71316
Value Function Loss: 0.02674

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12141
Policy Update Magnitude: 0.46686
Value Function Update Magnitude: 0.48185

Collected Steps per Second: 22,353.18297
Overall Steps per Second: 10,944.70766

Timestep Collection Time: 2.23816
Timestep Consumption Time: 2.33300
PPO Batch Consumption Time: 0.27575
Total Iteration Time: 4.57116

Cumulative Model Updates: 192,458
Cumulative Timesteps: 1,604,927,030

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1604927030...
Checkpoint 1604927030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,225.99148
Policy Entropy: 3.70108
Value Function Loss: 0.02718

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.48471
Value Function Update Magnitude: 0.53079

Collected Steps per Second: 22,200.96149
Overall Steps per Second: 10,568.86131

Timestep Collection Time: 2.25288
Timestep Consumption Time: 2.47952
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.73239

Cumulative Model Updates: 192,464
Cumulative Timesteps: 1,604,977,046

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,225.99148
Policy Entropy: 3.71615
Value Function Loss: 0.01920

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12789
Policy Update Magnitude: 0.45905
Value Function Update Magnitude: 0.50683

Collected Steps per Second: 22,961.31555
Overall Steps per Second: 10,916.25759

Timestep Collection Time: 2.17819
Timestep Consumption Time: 2.40342
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.58161

Cumulative Model Updates: 192,470
Cumulative Timesteps: 1,605,027,060

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1605027060...
Checkpoint 1605027060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,225.99148
Policy Entropy: 3.70859
Value Function Loss: 0.01629

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12421
Policy Update Magnitude: 0.39180
Value Function Update Magnitude: 0.40019

Collected Steps per Second: 22,687.44435
Overall Steps per Second: 10,711.79790

Timestep Collection Time: 2.20474
Timestep Consumption Time: 2.46487
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.66962

Cumulative Model Updates: 192,476
Cumulative Timesteps: 1,605,077,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,225.99148
Policy Entropy: 3.72622
Value Function Loss: 0.01243

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12381
Policy Update Magnitude: 0.32129
Value Function Update Magnitude: 0.28291

Collected Steps per Second: 23,107.75251
Overall Steps per Second: 10,817.10276

Timestep Collection Time: 2.16481
Timestep Consumption Time: 2.45971
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.62453

Cumulative Model Updates: 192,482
Cumulative Timesteps: 1,605,127,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1605127104...
Checkpoint 1605127104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,225.99148
Policy Entropy: 3.69197
Value Function Loss: 0.01990

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.11758
Policy Update Magnitude: 0.35353
Value Function Update Magnitude: 0.28235

Collected Steps per Second: 22,722.12183
Overall Steps per Second: 10,694.11998

Timestep Collection Time: 2.20085
Timestep Consumption Time: 2.47536
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.67621

Cumulative Model Updates: 192,488
Cumulative Timesteps: 1,605,177,112

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,318.31219
Policy Entropy: 3.69739
Value Function Loss: 0.02221

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.15570
Policy Update Magnitude: 0.44469
Value Function Update Magnitude: 0.26901

Collected Steps per Second: 22,792.72919
Overall Steps per Second: 10,826.30106

Timestep Collection Time: 2.19403
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.61912

Cumulative Model Updates: 192,494
Cumulative Timesteps: 1,605,227,120

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1605227120...
Checkpoint 1605227120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,318.31219
Policy Entropy: 3.68097
Value Function Loss: 0.02493

Mean KL Divergence: 0.00876
SB3 Clip Fraction: 0.11154
Policy Update Magnitude: 0.51156
Value Function Update Magnitude: 0.32822

Collected Steps per Second: 22,774.56594
Overall Steps per Second: 10,679.75948

Timestep Collection Time: 2.19684
Timestep Consumption Time: 2.48791
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.68475

Cumulative Model Updates: 192,500
Cumulative Timesteps: 1,605,277,152

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,318.31219
Policy Entropy: 3.71030
Value Function Loss: 0.01898

Mean KL Divergence: 0.01150
SB3 Clip Fraction: 0.15258
Policy Update Magnitude: 0.51465
Value Function Update Magnitude: 0.40959

Collected Steps per Second: 22,967.76092
Overall Steps per Second: 10,874.76645

Timestep Collection Time: 2.17775
Timestep Consumption Time: 2.42171
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.59946

Cumulative Model Updates: 192,506
Cumulative Timesteps: 1,605,327,170

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1605327170...
Checkpoint 1605327170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,318.31219
Policy Entropy: 3.71801
Value Function Loss: 0.01615

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.41014
Value Function Update Magnitude: 0.37289

Collected Steps per Second: 22,854.40582
Overall Steps per Second: 10,689.34067

Timestep Collection Time: 2.18881
Timestep Consumption Time: 2.49099
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.67980

Cumulative Model Updates: 192,512
Cumulative Timesteps: 1,605,377,194

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,318.31219
Policy Entropy: 3.73419
Value Function Loss: 0.01269

Mean KL Divergence: 0.00698
SB3 Clip Fraction: 0.08912
Policy Update Magnitude: 0.34863
Value Function Update Magnitude: 0.28305

Collected Steps per Second: 22,891.96414
Overall Steps per Second: 10,849.11289

Timestep Collection Time: 2.18540
Timestep Consumption Time: 2.42586
PPO Batch Consumption Time: 0.27889
Total Iteration Time: 4.61125

Cumulative Model Updates: 192,518
Cumulative Timesteps: 1,605,427,222

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1605427222...
Checkpoint 1605427222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,318.31219
Policy Entropy: 3.71023
Value Function Loss: 0.01246

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.15406
Policy Update Magnitude: 0.31459
Value Function Update Magnitude: 0.22310

Collected Steps per Second: 22,728.24001
Overall Steps per Second: 10,693.17175

Timestep Collection Time: 2.20158
Timestep Consumption Time: 2.47786
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.67943

Cumulative Model Updates: 192,524
Cumulative Timesteps: 1,605,477,260

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 151,318.31219
Policy Entropy: 3.70404
Value Function Loss: 0.01312

Mean KL Divergence: 0.00810
SB3 Clip Fraction: 0.10716
Policy Update Magnitude: 0.30629
Value Function Update Magnitude: 0.22017

Collected Steps per Second: 22,706.43941
Overall Steps per Second: 10,715.63548

Timestep Collection Time: 2.20255
Timestep Consumption Time: 2.46465
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.66720

Cumulative Model Updates: 192,530
Cumulative Timesteps: 1,605,527,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1605527272...
Checkpoint 1605527272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,318.31219
Policy Entropy: 3.70027
Value Function Loss: 0.01619

Mean KL Divergence: 0.00840
SB3 Clip Fraction: 0.10782
Policy Update Magnitude: 0.41434
Value Function Update Magnitude: 0.35373

Collected Steps per Second: 21,998.37367
Overall Steps per Second: 10,863.33975

Timestep Collection Time: 2.27408
Timestep Consumption Time: 2.33095
PPO Batch Consumption Time: 0.27638
Total Iteration Time: 4.60503

Cumulative Model Updates: 192,536
Cumulative Timesteps: 1,605,577,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,897.26224
Policy Entropy: 3.69917
Value Function Loss: 0.01716

Mean KL Divergence: 0.01167
SB3 Clip Fraction: 0.15275
Policy Update Magnitude: 0.44675
Value Function Update Magnitude: 0.47126

Collected Steps per Second: 22,216.18361
Overall Steps per Second: 10,878.02869

Timestep Collection Time: 2.25070
Timestep Consumption Time: 2.34590
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.59660

Cumulative Model Updates: 192,542
Cumulative Timesteps: 1,605,627,300

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1605627300...
Checkpoint 1605627300 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,897.26224
Policy Entropy: 3.69021
Value Function Loss: 0.02092

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15174
Policy Update Magnitude: 0.41611
Value Function Update Magnitude: 0.51492

Collected Steps per Second: 22,237.10090
Overall Steps per Second: 10,635.87218

Timestep Collection Time: 2.24930
Timestep Consumption Time: 2.45346
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.70276

Cumulative Model Updates: 192,548
Cumulative Timesteps: 1,605,677,318

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,897.26224
Policy Entropy: 3.69313
Value Function Loss: 0.02331

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.46456
Value Function Update Magnitude: 0.53503

Collected Steps per Second: 23,102.87450
Overall Steps per Second: 10,987.02334

Timestep Collection Time: 2.16467
Timestep Consumption Time: 2.38707
PPO Batch Consumption Time: 0.27564
Total Iteration Time: 4.55173

Cumulative Model Updates: 192,554
Cumulative Timesteps: 1,605,727,328

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1605727328...
Checkpoint 1605727328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,897.26224
Policy Entropy: 3.68974
Value Function Loss: 0.02515

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15130
Policy Update Magnitude: 0.48509
Value Function Update Magnitude: 0.53816

Collected Steps per Second: 22,641.31400
Overall Steps per Second: 10,754.05904

Timestep Collection Time: 2.20888
Timestep Consumption Time: 2.44164
PPO Batch Consumption Time: 0.28841
Total Iteration Time: 4.65052

Cumulative Model Updates: 192,560
Cumulative Timesteps: 1,605,777,340

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,401.93166
Policy Entropy: 3.71482
Value Function Loss: 0.02695

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.13825
Policy Update Magnitude: 0.48915
Value Function Update Magnitude: 0.50804

Collected Steps per Second: 23,242.00940
Overall Steps per Second: 10,747.35292

Timestep Collection Time: 2.15214
Timestep Consumption Time: 2.50203
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.65417

Cumulative Model Updates: 192,566
Cumulative Timesteps: 1,605,827,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1605827360...
Checkpoint 1605827360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,150.39344
Policy Entropy: 3.73066
Value Function Loss: 0.02608

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09829
Policy Update Magnitude: 0.56449
Value Function Update Magnitude: 0.57691

Collected Steps per Second: 22,725.43454
Overall Steps per Second: 10,618.50894

Timestep Collection Time: 2.20203
Timestep Consumption Time: 2.51069
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.71271

Cumulative Model Updates: 192,572
Cumulative Timesteps: 1,605,877,402

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,385.74449
Policy Entropy: 3.73073
Value Function Loss: 0.02652

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.14653
Policy Update Magnitude: 0.55754
Value Function Update Magnitude: 0.59752

Collected Steps per Second: 23,031.42912
Overall Steps per Second: 10,882.19671

Timestep Collection Time: 2.17260
Timestep Consumption Time: 2.42556
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.59815

Cumulative Model Updates: 192,578
Cumulative Timesteps: 1,605,927,440

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1605927440...
Checkpoint 1605927440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,174.55982
Policy Entropy: 3.73040
Value Function Loss: 0.02493

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.16535
Policy Update Magnitude: 0.49704
Value Function Update Magnitude: 0.71312

Collected Steps per Second: 22,662.20369
Overall Steps per Second: 10,720.20403

Timestep Collection Time: 2.20738
Timestep Consumption Time: 2.45895
PPO Batch Consumption Time: 0.28555
Total Iteration Time: 4.66633

Cumulative Model Updates: 192,584
Cumulative Timesteps: 1,605,977,464

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,276.61354
Policy Entropy: 3.73648
Value Function Loss: 0.02607

Mean KL Divergence: 0.01319
SB3 Clip Fraction: 0.16949
Policy Update Magnitude: 0.45529
Value Function Update Magnitude: 0.66899

Collected Steps per Second: 22,732.07340
Overall Steps per Second: 10,815.84098

Timestep Collection Time: 2.19998
Timestep Consumption Time: 2.42380
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.62377

Cumulative Model Updates: 192,590
Cumulative Timesteps: 1,606,027,474

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1606027474...
Checkpoint 1606027474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,010.42295
Policy Entropy: 3.73786
Value Function Loss: 0.02816

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14203
Policy Update Magnitude: 0.42394
Value Function Update Magnitude: 0.52370

Collected Steps per Second: 22,762.54941
Overall Steps per Second: 10,682.90334

Timestep Collection Time: 2.19782
Timestep Consumption Time: 2.48518
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.68300

Cumulative Model Updates: 192,596
Cumulative Timesteps: 1,606,077,502

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 571.37104
Policy Entropy: 3.71314
Value Function Loss: 0.03241

Mean KL Divergence: 0.01349
SB3 Clip Fraction: 0.17609
Policy Update Magnitude: 0.45789
Value Function Update Magnitude: 0.50147

Collected Steps per Second: 23,098.37991
Overall Steps per Second: 10,935.76420

Timestep Collection Time: 2.16578
Timestep Consumption Time: 2.40875
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.57453

Cumulative Model Updates: 192,602
Cumulative Timesteps: 1,606,127,528

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1606127528...
Checkpoint 1606127528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 571.37104
Policy Entropy: 3.69281
Value Function Loss: 0.03210

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.57106
Value Function Update Magnitude: 0.53265

Collected Steps per Second: 22,584.19429
Overall Steps per Second: 10,670.50438

Timestep Collection Time: 2.21527
Timestep Consumption Time: 2.47336
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.68863

Cumulative Model Updates: 192,608
Cumulative Timesteps: 1,606,177,558

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 106,098.61638
Policy Entropy: 3.68262
Value Function Loss: 0.03387

Mean KL Divergence: 0.00830
SB3 Clip Fraction: 0.10534
Policy Update Magnitude: 0.68593
Value Function Update Magnitude: 0.49331

Collected Steps per Second: 22,348.70693
Overall Steps per Second: 10,882.47159

Timestep Collection Time: 2.23825
Timestep Consumption Time: 2.35832
PPO Batch Consumption Time: 0.27830
Total Iteration Time: 4.59657

Cumulative Model Updates: 192,614
Cumulative Timesteps: 1,606,227,580

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1606227580...
Checkpoint 1606227580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,179.05963
Policy Entropy: 3.71617
Value Function Loss: 0.03341

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.16532
Policy Update Magnitude: 0.63516
Value Function Update Magnitude: 0.39623

Collected Steps per Second: 22,041.48081
Overall Steps per Second: 10,689.76962

Timestep Collection Time: 2.26981
Timestep Consumption Time: 2.41036
PPO Batch Consumption Time: 0.29079
Total Iteration Time: 4.68018

Cumulative Model Updates: 192,620
Cumulative Timesteps: 1,606,277,610

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,179.05963
Policy Entropy: 3.74204
Value Function Loss: 0.02756

Mean KL Divergence: 0.01162
SB3 Clip Fraction: 0.15563
Policy Update Magnitude: 0.55733
Value Function Update Magnitude: 0.41246

Collected Steps per Second: 22,606.10333
Overall Steps per Second: 10,840.00085

Timestep Collection Time: 2.21356
Timestep Consumption Time: 2.40267
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.61624

Cumulative Model Updates: 192,626
Cumulative Timesteps: 1,606,327,650

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1606327650...
Checkpoint 1606327650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,179.05963
Policy Entropy: 3.72395
Value Function Loss: 0.02504

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.12638
Policy Update Magnitude: 0.51011
Value Function Update Magnitude: 0.40168

Collected Steps per Second: 22,625.67390
Overall Steps per Second: 10,702.79749

Timestep Collection Time: 2.21041
Timestep Consumption Time: 2.46239
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.67280

Cumulative Model Updates: 192,632
Cumulative Timesteps: 1,606,377,662

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,896.36118
Policy Entropy: 3.72661
Value Function Loss: 0.02604

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13724
Policy Update Magnitude: 0.48877
Value Function Update Magnitude: 0.38268

Collected Steps per Second: 22,761.17110
Overall Steps per Second: 10,928.91971

Timestep Collection Time: 2.19708
Timestep Consumption Time: 2.37867
PPO Batch Consumption Time: 0.27575
Total Iteration Time: 4.57575

Cumulative Model Updates: 192,638
Cumulative Timesteps: 1,606,427,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1606427670...
Checkpoint 1606427670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,534.00803
Policy Entropy: 3.74399
Value Function Loss: 0.02819

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12890
Policy Update Magnitude: 0.46659
Value Function Update Magnitude: 0.40617

Collected Steps per Second: 22,851.82624
Overall Steps per Second: 10,690.31583

Timestep Collection Time: 2.18915
Timestep Consumption Time: 2.49042
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.67956

Cumulative Model Updates: 192,644
Cumulative Timesteps: 1,606,477,696

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,672.63298
Policy Entropy: 3.77296
Value Function Loss: 0.02313

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13911
Policy Update Magnitude: 0.46794
Value Function Update Magnitude: 0.61827

Collected Steps per Second: 23,137.08733
Overall Steps per Second: 10,808.96499

Timestep Collection Time: 2.16103
Timestep Consumption Time: 2.46476
PPO Batch Consumption Time: 0.28446
Total Iteration Time: 4.62579

Cumulative Model Updates: 192,650
Cumulative Timesteps: 1,606,527,696

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1606527696...
Checkpoint 1606527696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,354.81188
Policy Entropy: 3.77898
Value Function Loss: 0.01921

Mean KL Divergence: 0.01158
SB3 Clip Fraction: 0.15231
Policy Update Magnitude: 0.47622
Value Function Update Magnitude: 0.70786

Collected Steps per Second: 22,743.35527
Overall Steps per Second: 10,664.40843

Timestep Collection Time: 2.19888
Timestep Consumption Time: 2.49055
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.68943

Cumulative Model Updates: 192,656
Cumulative Timesteps: 1,606,577,706

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,354.81188
Policy Entropy: 3.75722
Value Function Loss: 0.01731

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.13505
Policy Update Magnitude: 0.49712
Value Function Update Magnitude: 0.70473

Collected Steps per Second: 22,821.51996
Overall Steps per Second: 10,804.52726

Timestep Collection Time: 2.19153
Timestep Consumption Time: 2.43746
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.62899

Cumulative Model Updates: 192,662
Cumulative Timesteps: 1,606,627,720

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1606627720...
Checkpoint 1606627720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,354.81188
Policy Entropy: 3.76820
Value Function Loss: 0.01624

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15663
Policy Update Magnitude: 0.48704
Value Function Update Magnitude: 0.64406

Collected Steps per Second: 22,248.40461
Overall Steps per Second: 10,681.44173

Timestep Collection Time: 2.24816
Timestep Consumption Time: 2.43454
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.68270

Cumulative Model Updates: 192,668
Cumulative Timesteps: 1,606,677,738

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339,757.12071
Policy Entropy: 3.75757
Value Function Loss: 0.01801

Mean KL Divergence: 0.01392
SB3 Clip Fraction: 0.17489
Policy Update Magnitude: 0.52209
Value Function Update Magnitude: 0.63892

Collected Steps per Second: 22,711.16740
Overall Steps per Second: 10,805.36315

Timestep Collection Time: 2.20226
Timestep Consumption Time: 2.42655
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.62881

Cumulative Model Updates: 192,674
Cumulative Timesteps: 1,606,727,754

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1606727754...
Checkpoint 1606727754 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339,757.12071
Policy Entropy: 3.77016
Value Function Loss: 0.01858

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.24122
Policy Update Magnitude: 0.51466
Value Function Update Magnitude: 0.61889

Collected Steps per Second: 22,104.75321
Overall Steps per Second: 10,696.60976

Timestep Collection Time: 2.26214
Timestep Consumption Time: 2.41261
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.67475

Cumulative Model Updates: 192,680
Cumulative Timesteps: 1,606,777,758

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339,757.12071
Policy Entropy: 3.78471
Value Function Loss: 0.02959

Mean KL Divergence: 0.01715
SB3 Clip Fraction: 0.19673
Policy Update Magnitude: 0.57482
Value Function Update Magnitude: 0.57390

Collected Steps per Second: 22,305.36283
Overall Steps per Second: 10,546.57406

Timestep Collection Time: 2.24260
Timestep Consumption Time: 2.50036
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.74296

Cumulative Model Updates: 192,686
Cumulative Timesteps: 1,606,827,780

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1606827780...
Checkpoint 1606827780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 400,694.88391
Policy Entropy: 3.81047
Value Function Loss: 0.03047

Mean KL Divergence: 0.01556
SB3 Clip Fraction: 0.18068
Policy Update Magnitude: 0.69101
Value Function Update Magnitude: 0.53573

Collected Steps per Second: 22,334.24814
Overall Steps per Second: 10,613.16407

Timestep Collection Time: 2.23988
Timestep Consumption Time: 2.47370
PPO Batch Consumption Time: 0.28667
Total Iteration Time: 4.71358

Cumulative Model Updates: 192,692
Cumulative Timesteps: 1,606,877,806

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,509.89761
Policy Entropy: 3.81252
Value Function Loss: 0.02819

Mean KL Divergence: 0.01599
SB3 Clip Fraction: 0.19058
Policy Update Magnitude: 0.65878
Value Function Update Magnitude: 0.50982

Collected Steps per Second: 22,001.02914
Overall Steps per Second: 10,811.70725

Timestep Collection Time: 2.27335
Timestep Consumption Time: 2.35275
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.62610

Cumulative Model Updates: 192,698
Cumulative Timesteps: 1,606,927,822

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1606927822...
Checkpoint 1606927822 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,509.89761
Policy Entropy: 3.77256
Value Function Loss: 0.02400

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.15515
Policy Update Magnitude: 0.61645
Value Function Update Magnitude: 0.46727

Collected Steps per Second: 21,682.33258
Overall Steps per Second: 10,686.23825

Timestep Collection Time: 2.30658
Timestep Consumption Time: 2.37346
PPO Batch Consumption Time: 0.27907
Total Iteration Time: 4.68004

Cumulative Model Updates: 192,704
Cumulative Timesteps: 1,606,977,834

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,509.89761
Policy Entropy: 3.74723
Value Function Loss: 0.01942

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15352
Policy Update Magnitude: 0.53197
Value Function Update Magnitude: 0.36101

Collected Steps per Second: 22,058.97502
Overall Steps per Second: 10,856.16800

Timestep Collection Time: 2.26665
Timestep Consumption Time: 2.33903
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.60568

Cumulative Model Updates: 192,710
Cumulative Timesteps: 1,607,027,834

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1607027834...
Checkpoint 1607027834 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,509.89761
Policy Entropy: 3.72080
Value Function Loss: 0.01623

Mean KL Divergence: 0.01226
SB3 Clip Fraction: 0.15667
Policy Update Magnitude: 0.45420
Value Function Update Magnitude: 0.33767

Collected Steps per Second: 21,822.14329
Overall Steps per Second: 10,639.73995

Timestep Collection Time: 2.29153
Timestep Consumption Time: 2.40840
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.69993

Cumulative Model Updates: 192,716
Cumulative Timesteps: 1,607,077,840

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 172,509.89761
Policy Entropy: 3.70886
Value Function Loss: 0.01537

Mean KL Divergence: 0.00845
SB3 Clip Fraction: 0.11076
Policy Update Magnitude: 0.40786
Value Function Update Magnitude: 0.32228

Collected Steps per Second: 22,884.76557
Overall Steps per Second: 10,923.40570

Timestep Collection Time: 2.18503
Timestep Consumption Time: 2.39266
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.57769

Cumulative Model Updates: 192,722
Cumulative Timesteps: 1,607,127,844

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1607127844...
Checkpoint 1607127844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 172,509.89761
Policy Entropy: 3.68981
Value Function Loss: 0.01608

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.08119
Policy Update Magnitude: 0.46617
Value Function Update Magnitude: 0.45480

Collected Steps per Second: 22,532.65308
Overall Steps per Second: 10,722.03813

Timestep Collection Time: 2.21900
Timestep Consumption Time: 2.44429
PPO Batch Consumption Time: 0.28135
Total Iteration Time: 4.66329

Cumulative Model Updates: 192,728
Cumulative Timesteps: 1,607,177,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 277,588.03807
Policy Entropy: 3.70328
Value Function Loss: 0.01547

Mean KL Divergence: 0.00774
SB3 Clip Fraction: 0.10155
Policy Update Magnitude: 0.49157
Value Function Update Magnitude: 0.58607

Collected Steps per Second: 22,922.96714
Overall Steps per Second: 10,790.92867

Timestep Collection Time: 2.18122
Timestep Consumption Time: 2.45230
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.63352

Cumulative Model Updates: 192,734
Cumulative Timesteps: 1,607,227,844

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1607227844...
Checkpoint 1607227844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,802.99689
Policy Entropy: 3.71085
Value Function Loss: 0.01581

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12010
Policy Update Magnitude: 0.41846
Value Function Update Magnitude: 0.51024

Collected Steps per Second: 22,492.19797
Overall Steps per Second: 10,795.29437

Timestep Collection Time: 2.22317
Timestep Consumption Time: 2.40885
PPO Batch Consumption Time: 0.27543
Total Iteration Time: 4.63202

Cumulative Model Updates: 192,740
Cumulative Timesteps: 1,607,277,848

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,802.99689
Policy Entropy: 3.71635
Value Function Loss: 0.01902

Mean KL Divergence: 0.00579
SB3 Clip Fraction: 0.07028
Policy Update Magnitude: 0.56157
Value Function Update Magnitude: 0.53747

Collected Steps per Second: 22,673.05542
Overall Steps per Second: 10,820.37603

Timestep Collection Time: 2.20623
Timestep Consumption Time: 2.41671
PPO Batch Consumption Time: 0.27702
Total Iteration Time: 4.62294

Cumulative Model Updates: 192,746
Cumulative Timesteps: 1,607,327,870

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1607327870...
Checkpoint 1607327870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,802.99689
Policy Entropy: 3.68962
Value Function Loss: 0.02163

Mean KL Divergence: 0.01207
SB3 Clip Fraction: 0.15519
Policy Update Magnitude: 0.56701
Value Function Update Magnitude: 0.61057

Collected Steps per Second: 22,546.32057
Overall Steps per Second: 10,631.76731

Timestep Collection Time: 2.21837
Timestep Consumption Time: 2.48603
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.70439

Cumulative Model Updates: 192,752
Cumulative Timesteps: 1,607,377,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,802.99689
Policy Entropy: 3.68976
Value Function Loss: 0.02173

Mean KL Divergence: 0.00725
SB3 Clip Fraction: 0.08800
Policy Update Magnitude: 0.62766
Value Function Update Magnitude: 0.51720

Collected Steps per Second: 22,931.40076
Overall Steps per Second: 10,841.08874

Timestep Collection Time: 2.18146
Timestep Consumption Time: 2.43283
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.61430

Cumulative Model Updates: 192,758
Cumulative Timesteps: 1,607,427,910

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1607427910...
Checkpoint 1607427910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,802.99689
Policy Entropy: 3.68901
Value Function Loss: 0.02288

Mean KL Divergence: 0.00754
SB3 Clip Fraction: 0.09645
Policy Update Magnitude: 0.67889
Value Function Update Magnitude: 0.37922

Collected Steps per Second: 21,289.38628
Overall Steps per Second: 10,648.49677

Timestep Collection Time: 2.34981
Timestep Consumption Time: 2.34813
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.69794

Cumulative Model Updates: 192,764
Cumulative Timesteps: 1,607,477,936

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,802.99689
Policy Entropy: 3.69636
Value Function Loss: 0.02208

Mean KL Divergence: 0.00753
SB3 Clip Fraction: 0.09408
Policy Update Magnitude: 0.64514
Value Function Update Magnitude: 0.36029

Collected Steps per Second: 22,048.16912
Overall Steps per Second: 10,724.53151

Timestep Collection Time: 2.26867
Timestep Consumption Time: 2.39540
PPO Batch Consumption Time: 0.28806
Total Iteration Time: 4.66407

Cumulative Model Updates: 192,770
Cumulative Timesteps: 1,607,527,956

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1607527956...
Checkpoint 1607527956 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,938.75686
Policy Entropy: 3.70434
Value Function Loss: 0.02282

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13296
Policy Update Magnitude: 0.54823
Value Function Update Magnitude: 0.32971

Collected Steps per Second: 22,087.92022
Overall Steps per Second: 10,602.54946

Timestep Collection Time: 2.26395
Timestep Consumption Time: 2.45246
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.71641

Cumulative Model Updates: 192,776
Cumulative Timesteps: 1,607,577,962

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,232.11409
Policy Entropy: 3.71259
Value Function Loss: 0.02286

Mean KL Divergence: 0.01476
SB3 Clip Fraction: 0.18987
Policy Update Magnitude: 0.45542
Value Function Update Magnitude: 0.33993

Collected Steps per Second: 22,908.20569
Overall Steps per Second: 10,719.06474

Timestep Collection Time: 2.18402
Timestep Consumption Time: 2.48355
PPO Batch Consumption Time: 0.28978
Total Iteration Time: 4.66757

Cumulative Model Updates: 192,782
Cumulative Timesteps: 1,607,627,994

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1607627994...
Checkpoint 1607627994 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,937.00194
Policy Entropy: 3.70268
Value Function Loss: 0.02715

Mean KL Divergence: 0.01151
SB3 Clip Fraction: 0.14667
Policy Update Magnitude: 0.45486
Value Function Update Magnitude: 0.40949

Collected Steps per Second: 22,430.87398
Overall Steps per Second: 10,621.32455

Timestep Collection Time: 2.22961
Timestep Consumption Time: 2.47904
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.70864

Cumulative Model Updates: 192,788
Cumulative Timesteps: 1,607,678,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,712.97550
Policy Entropy: 3.69732
Value Function Loss: 0.02909

Mean KL Divergence: 0.01173
SB3 Clip Fraction: 0.14914
Policy Update Magnitude: 0.49032
Value Function Update Magnitude: 0.45687

Collected Steps per Second: 22,915.66450
Overall Steps per Second: 10,895.67577

Timestep Collection Time: 2.18340
Timestep Consumption Time: 2.40870
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.59210

Cumulative Model Updates: 192,794
Cumulative Timesteps: 1,607,728,040

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1607728040...
Checkpoint 1607728040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,559.57547
Policy Entropy: 3.69946
Value Function Loss: 0.03321

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13089
Policy Update Magnitude: 0.52273
Value Function Update Magnitude: 0.47864

Collected Steps per Second: 22,416.13510
Overall Steps per Second: 10,773.97990

Timestep Collection Time: 2.23277
Timestep Consumption Time: 2.41268
PPO Batch Consumption Time: 0.27627
Total Iteration Time: 4.64545

Cumulative Model Updates: 192,800
Cumulative Timesteps: 1,607,778,090

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,976.12648
Policy Entropy: 3.70781
Value Function Loss: 0.03269

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.55033
Value Function Update Magnitude: 0.50206

Collected Steps per Second: 22,633.98996
Overall Steps per Second: 10,789.13191

Timestep Collection Time: 2.20951
Timestep Consumption Time: 2.42571
PPO Batch Consumption Time: 0.27768
Total Iteration Time: 4.63522

Cumulative Model Updates: 192,806
Cumulative Timesteps: 1,607,828,100

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1607828100...
Checkpoint 1607828100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,476.91837
Policy Entropy: 3.71252
Value Function Loss: 0.03250

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.57189
Value Function Update Magnitude: 0.50320

Collected Steps per Second: 22,295.25872
Overall Steps per Second: 10,748.43155

Timestep Collection Time: 2.24299
Timestep Consumption Time: 2.40960
PPO Batch Consumption Time: 0.27610
Total Iteration Time: 4.65259

Cumulative Model Updates: 192,812
Cumulative Timesteps: 1,607,878,108

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,254.63203
Policy Entropy: 3.72860
Value Function Loss: 0.02792

Mean KL Divergence: 0.01106
SB3 Clip Fraction: 0.13851
Policy Update Magnitude: 0.55992
Value Function Update Magnitude: 0.47840

Collected Steps per Second: 22,948.01808
Overall Steps per Second: 10,875.82783

Timestep Collection Time: 2.18014
Timestep Consumption Time: 2.41996
PPO Batch Consumption Time: 0.27695
Total Iteration Time: 4.60011

Cumulative Model Updates: 192,818
Cumulative Timesteps: 1,607,928,138

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1607928138...
Checkpoint 1607928138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,596.83465
Policy Entropy: 3.73571
Value Function Loss: 0.02819

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13104
Policy Update Magnitude: 0.51103
Value Function Update Magnitude: 0.43973

Collected Steps per Second: 22,897.14950
Overall Steps per Second: 10,702.80955

Timestep Collection Time: 2.18455
Timestep Consumption Time: 2.48899
PPO Batch Consumption Time: 0.29168
Total Iteration Time: 4.67354

Cumulative Model Updates: 192,824
Cumulative Timesteps: 1,607,978,158

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,596.83465
Policy Entropy: 3.72615
Value Function Loss: 0.02603

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.13273
Policy Update Magnitude: 0.51052
Value Function Update Magnitude: 0.39494

Collected Steps per Second: 22,617.01576
Overall Steps per Second: 10,780.13494

Timestep Collection Time: 2.21285
Timestep Consumption Time: 2.42977
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.64261

Cumulative Model Updates: 192,830
Cumulative Timesteps: 1,608,028,206

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1608028206...
Checkpoint 1608028206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,596.83465
Policy Entropy: 3.70272
Value Function Loss: 0.02751

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15099
Policy Update Magnitude: 0.52974
Value Function Update Magnitude: 0.39779

Collected Steps per Second: 22,236.39887
Overall Steps per Second: 10,713.76564

Timestep Collection Time: 2.24893
Timestep Consumption Time: 2.41871
PPO Batch Consumption Time: 0.27635
Total Iteration Time: 4.66764

Cumulative Model Updates: 192,836
Cumulative Timesteps: 1,608,078,214

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,596.83465
Policy Entropy: 3.68306
Value Function Loss: 0.02214

Mean KL Divergence: 0.00705
SB3 Clip Fraction: 0.08542
Policy Update Magnitude: 0.53213
Value Function Update Magnitude: 0.42018

Collected Steps per Second: 22,779.17714
Overall Steps per Second: 10,827.71169

Timestep Collection Time: 2.19516
Timestep Consumption Time: 2.42299
PPO Batch Consumption Time: 0.27813
Total Iteration Time: 4.61815

Cumulative Model Updates: 192,842
Cumulative Timesteps: 1,608,128,218

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1608128218...
Checkpoint 1608128218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 190,596.83465
Policy Entropy: 3.68480
Value Function Loss: 0.01962

Mean KL Divergence: 0.00582
SB3 Clip Fraction: 0.06862
Policy Update Magnitude: 0.61225
Value Function Update Magnitude: 0.55328

Collected Steps per Second: 22,582.40406
Overall Steps per Second: 10,705.21864

Timestep Collection Time: 2.21473
Timestep Consumption Time: 2.45719
PPO Batch Consumption Time: 0.28563
Total Iteration Time: 4.67193

Cumulative Model Updates: 192,848
Cumulative Timesteps: 1,608,178,232

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 190,596.83465
Policy Entropy: 3.69005
Value Function Loss: 0.01665

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08321
Policy Update Magnitude: 0.60986
Value Function Update Magnitude: 0.64156

Collected Steps per Second: 22,955.34848
Overall Steps per Second: 10,851.38802

Timestep Collection Time: 2.17840
Timestep Consumption Time: 2.42986
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.60826

Cumulative Model Updates: 192,854
Cumulative Timesteps: 1,608,228,238

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1608228238...
Checkpoint 1608228238 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.70500
Value Function Loss: 0.01602

Mean KL Divergence: 0.00525
SB3 Clip Fraction: 0.05971
Policy Update Magnitude: 0.55540
Value Function Update Magnitude: 0.66781

Collected Steps per Second: 21,751.32677
Overall Steps per Second: 10,655.59302

Timestep Collection Time: 2.29880
Timestep Consumption Time: 2.39376
PPO Batch Consumption Time: 0.28424
Total Iteration Time: 4.69256

Cumulative Model Updates: 192,860
Cumulative Timesteps: 1,608,278,240

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.68633
Value Function Loss: 0.01907

Mean KL Divergence: 0.00512
SB3 Clip Fraction: 0.05734
Policy Update Magnitude: 0.59892
Value Function Update Magnitude: 0.60854

Collected Steps per Second: 22,119.13064
Overall Steps per Second: 10,877.18295

Timestep Collection Time: 2.26248
Timestep Consumption Time: 2.33835
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.60082

Cumulative Model Updates: 192,866
Cumulative Timesteps: 1,608,328,284

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1608328284...
Checkpoint 1608328284 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.69796
Value Function Loss: 0.02098

Mean KL Divergence: 0.00495
SB3 Clip Fraction: 0.05254
Policy Update Magnitude: 0.64856
Value Function Update Magnitude: 0.51105

Collected Steps per Second: 21,826.53362
Overall Steps per Second: 10,652.70528

Timestep Collection Time: 2.29116
Timestep Consumption Time: 2.40324
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.69439

Cumulative Model Updates: 192,872
Cumulative Timesteps: 1,608,378,292

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.69380
Value Function Loss: 0.02301

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.06829
Policy Update Magnitude: 0.64947
Value Function Update Magnitude: 0.37756

Collected Steps per Second: 22,741.22701
Overall Steps per Second: 10,864.49241

Timestep Collection Time: 2.19874
Timestep Consumption Time: 2.40359
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.60233

Cumulative Model Updates: 192,878
Cumulative Timesteps: 1,608,428,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1608428294...
Checkpoint 1608428294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.70477
Value Function Loss: 0.01730

Mean KL Divergence: 0.00759
SB3 Clip Fraction: 0.09595
Policy Update Magnitude: 0.58808
Value Function Update Magnitude: 0.32152

Collected Steps per Second: 22,508.53171
Overall Steps per Second: 10,734.80258

Timestep Collection Time: 2.22218
Timestep Consumption Time: 2.43724
PPO Batch Consumption Time: 0.28431
Total Iteration Time: 4.65942

Cumulative Model Updates: 192,884
Cumulative Timesteps: 1,608,478,312

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.69303
Value Function Loss: 0.01781

Mean KL Divergence: 0.00623
SB3 Clip Fraction: 0.07372
Policy Update Magnitude: 0.55537
Value Function Update Magnitude: 0.33585

Collected Steps per Second: 22,866.52233
Overall Steps per Second: 10,838.70557

Timestep Collection Time: 2.18739
Timestep Consumption Time: 2.42737
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.61476

Cumulative Model Updates: 192,890
Cumulative Timesteps: 1,608,528,330

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1608528330...
Checkpoint 1608528330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.69680
Value Function Loss: 0.01519

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07542
Policy Update Magnitude: 0.56714
Value Function Update Magnitude: 0.36866

Collected Steps per Second: 22,888.38037
Overall Steps per Second: 10,729.48601

Timestep Collection Time: 2.18565
Timestep Consumption Time: 2.47683
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.66248

Cumulative Model Updates: 192,896
Cumulative Timesteps: 1,608,578,356

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.70491
Value Function Loss: 0.01371

Mean KL Divergence: 0.00757
SB3 Clip Fraction: 0.09749
Policy Update Magnitude: 0.50892
Value Function Update Magnitude: 0.40459

Collected Steps per Second: 22,761.53505
Overall Steps per Second: 10,820.80409

Timestep Collection Time: 2.19669
Timestep Consumption Time: 2.42404
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.62073

Cumulative Model Updates: 192,902
Cumulative Timesteps: 1,608,628,356

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1608628356...
Checkpoint 1608628356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.71109
Value Function Loss: 0.01324

Mean KL Divergence: 0.00634
SB3 Clip Fraction: 0.07778
Policy Update Magnitude: 0.44032
Value Function Update Magnitude: 0.35756

Collected Steps per Second: 22,203.92122
Overall Steps per Second: 10,730.39467

Timestep Collection Time: 2.25221
Timestep Consumption Time: 2.40819
PPO Batch Consumption Time: 0.27613
Total Iteration Time: 4.66041

Cumulative Model Updates: 192,908
Cumulative Timesteps: 1,608,678,364

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.70092
Value Function Loss: 0.01652

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06450
Policy Update Magnitude: 0.49355
Value Function Update Magnitude: 0.42946

Collected Steps per Second: 23,292.39145
Overall Steps per Second: 10,936.37939

Timestep Collection Time: 2.14765
Timestep Consumption Time: 2.42644
PPO Batch Consumption Time: 0.28083
Total Iteration Time: 4.57409

Cumulative Model Updates: 192,914
Cumulative Timesteps: 1,608,728,388

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1608728388...
Checkpoint 1608728388 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.70543
Value Function Loss: 0.01628

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07907
Policy Update Magnitude: 0.54199
Value Function Update Magnitude: 0.47244

Collected Steps per Second: 22,364.00504
Overall Steps per Second: 10,598.11725

Timestep Collection Time: 2.23574
Timestep Consumption Time: 2.48208
PPO Batch Consumption Time: 0.28801
Total Iteration Time: 4.71782

Cumulative Model Updates: 192,920
Cumulative Timesteps: 1,608,778,388

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.69643
Value Function Loss: 0.01771

Mean KL Divergence: 0.01143
SB3 Clip Fraction: 0.15154
Policy Update Magnitude: 0.42892
Value Function Update Magnitude: 0.42490

Collected Steps per Second: 22,398.98354
Overall Steps per Second: 10,968.68971

Timestep Collection Time: 2.23269
Timestep Consumption Time: 2.32665
PPO Batch Consumption Time: 0.27515
Total Iteration Time: 4.55934

Cumulative Model Updates: 192,926
Cumulative Timesteps: 1,608,828,398

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1608828398...
Checkpoint 1608828398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.70327
Value Function Loss: 0.01685

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.07104
Policy Update Magnitude: 0.42477
Value Function Update Magnitude: 0.41888

Collected Steps per Second: 21,864.14067
Overall Steps per Second: 10,621.06613

Timestep Collection Time: 2.28804
Timestep Consumption Time: 2.42203
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.71007

Cumulative Model Updates: 192,932
Cumulative Timesteps: 1,608,878,424

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.69363
Value Function Loss: 0.01763

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12236
Policy Update Magnitude: 0.47057
Value Function Update Magnitude: 0.36984

Collected Steps per Second: 22,428.70444
Overall Steps per Second: 10,800.94901

Timestep Collection Time: 2.22973
Timestep Consumption Time: 2.40042
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.63015

Cumulative Model Updates: 192,938
Cumulative Timesteps: 1,608,928,434

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1608928434...
Checkpoint 1608928434 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,495.53903
Policy Entropy: 3.70943
Value Function Loss: 0.01470

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08541
Policy Update Magnitude: 0.45130
Value Function Update Magnitude: 0.33379

Collected Steps per Second: 22,593.34562
Overall Steps per Second: 10,699.33997

Timestep Collection Time: 2.21348
Timestep Consumption Time: 2.46064
PPO Batch Consumption Time: 0.28830
Total Iteration Time: 4.67412

Cumulative Model Updates: 192,944
Cumulative Timesteps: 1,608,978,444

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 283,869.82702
Policy Entropy: 3.71745
Value Function Loss: 0.01625

Mean KL Divergence: 0.01518
SB3 Clip Fraction: 0.18960
Policy Update Magnitude: 0.40910
Value Function Update Magnitude: 0.44385

Collected Steps per Second: 22,975.16224
Overall Steps per Second: 10,947.22689

Timestep Collection Time: 2.17696
Timestep Consumption Time: 2.39187
PPO Batch Consumption Time: 0.27636
Total Iteration Time: 4.56883

Cumulative Model Updates: 192,950
Cumulative Timesteps: 1,609,028,460

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1609028460...
Checkpoint 1609028460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237,936.44570
Policy Entropy: 3.72758
Value Function Loss: 0.02138

Mean KL Divergence: 0.01381
SB3 Clip Fraction: 0.17926
Policy Update Magnitude: 0.43692
Value Function Update Magnitude: 0.68908

Collected Steps per Second: 22,323.62327
Overall Steps per Second: 10,614.14358

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.47181
PPO Batch Consumption Time: 0.28702
Total Iteration Time: 4.71239

Cumulative Model Updates: 192,956
Cumulative Timesteps: 1,609,078,478

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 320,060.09297
Policy Entropy: 3.73197
Value Function Loss: 0.02488

Mean KL Divergence: 0.00755
SB3 Clip Fraction: 0.09776
Policy Update Magnitude: 0.54249
Value Function Update Magnitude: 0.68613

Collected Steps per Second: 22,953.42622
Overall Steps per Second: 10,871.98357

Timestep Collection Time: 2.17850
Timestep Consumption Time: 2.42085
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.59934

Cumulative Model Updates: 192,962
Cumulative Timesteps: 1,609,128,482

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1609128482...
Checkpoint 1609128482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 323,399.28624
Policy Entropy: 3.72525
Value Function Loss: 0.02510

Mean KL Divergence: 0.00593
SB3 Clip Fraction: 0.06994
Policy Update Magnitude: 0.66702
Value Function Update Magnitude: 0.65988

Collected Steps per Second: 22,445.72505
Overall Steps per Second: 10,681.29190

Timestep Collection Time: 2.22822
Timestep Consumption Time: 2.45417
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.68239

Cumulative Model Updates: 192,968
Cumulative Timesteps: 1,609,178,496

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,345.01493
Policy Entropy: 3.71874
Value Function Loss: 0.02328

Mean KL Divergence: 0.00563
SB3 Clip Fraction: 0.06412
Policy Update Magnitude: 0.67264
Value Function Update Magnitude: 0.64053

Collected Steps per Second: 23,315.71526
Overall Steps per Second: 10,956.26315

Timestep Collection Time: 2.14551
Timestep Consumption Time: 2.42028
PPO Batch Consumption Time: 0.27619
Total Iteration Time: 4.56579

Cumulative Model Updates: 192,974
Cumulative Timesteps: 1,609,228,520

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1609228520...
Checkpoint 1609228520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 141,345.01493
Policy Entropy: 3.72233
Value Function Loss: 0.02077

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13515
Policy Update Magnitude: 0.61857
Value Function Update Magnitude: 0.59693

Collected Steps per Second: 22,588.35405
Overall Steps per Second: 10,623.67524

Timestep Collection Time: 2.21433
Timestep Consumption Time: 2.49384
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.70816

Cumulative Model Updates: 192,980
Cumulative Timesteps: 1,609,278,538

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 153,679.36904
Policy Entropy: 3.71047
Value Function Loss: 0.02042

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12427
Policy Update Magnitude: 0.48878
Value Function Update Magnitude: 0.55033

Collected Steps per Second: 23,170.25365
Overall Steps per Second: 10,955.34503

Timestep Collection Time: 2.15863
Timestep Consumption Time: 2.40681
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.56544

Cumulative Model Updates: 192,986
Cumulative Timesteps: 1,609,328,554

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1609328554...
Checkpoint 1609328554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,250.49995
Policy Entropy: 3.70309
Value Function Loss: 0.02218

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.12796
Policy Update Magnitude: 0.46887
Value Function Update Magnitude: 0.59973

Collected Steps per Second: 22,732.15439
Overall Steps per Second: 10,704.63657

Timestep Collection Time: 2.19979
Timestep Consumption Time: 2.47164
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.67143

Cumulative Model Updates: 192,992
Cumulative Timesteps: 1,609,378,560

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,060.58774
Policy Entropy: 3.70037
Value Function Loss: 0.02602

Mean KL Divergence: 0.00684
SB3 Clip Fraction: 0.08426
Policy Update Magnitude: 0.52657
Value Function Update Magnitude: 0.75119

Collected Steps per Second: 22,802.05414
Overall Steps per Second: 10,738.21906

Timestep Collection Time: 2.19278
Timestep Consumption Time: 2.46348
PPO Batch Consumption Time: 0.28307
Total Iteration Time: 4.65627

Cumulative Model Updates: 192,998
Cumulative Timesteps: 1,609,428,560

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1609428560...
Checkpoint 1609428560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,060.58774
Policy Entropy: 3.71166
Value Function Loss: 0.02426

Mean KL Divergence: 0.00706
SB3 Clip Fraction: 0.08749
Policy Update Magnitude: 0.65093
Value Function Update Magnitude: 0.68896

Collected Steps per Second: 22,353.80828
Overall Steps per Second: 10,647.62606

Timestep Collection Time: 2.23747
Timestep Consumption Time: 2.45991
PPO Batch Consumption Time: 0.28449
Total Iteration Time: 4.69739

Cumulative Model Updates: 193,004
Cumulative Timesteps: 1,609,478,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,060.58774
Policy Entropy: 3.71042
Value Function Loss: 0.02075

Mean KL Divergence: 0.00702
SB3 Clip Fraction: 0.08835
Policy Update Magnitude: 0.60957
Value Function Update Magnitude: 0.50449

Collected Steps per Second: 22,844.95234
Overall Steps per Second: 10,863.86772

Timestep Collection Time: 2.18981
Timestep Consumption Time: 2.41500
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.60481

Cumulative Model Updates: 193,010
Cumulative Timesteps: 1,609,528,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1609528602...
Checkpoint 1609528602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,060.58774
Policy Entropy: 3.71391
Value Function Loss: 0.01507

Mean KL Divergence: 0.00678
SB3 Clip Fraction: 0.08555
Policy Update Magnitude: 0.48275
Value Function Update Magnitude: 0.38353

Collected Steps per Second: 22,383.44840
Overall Steps per Second: 10,727.43353

Timestep Collection Time: 2.23478
Timestep Consumption Time: 2.42822
PPO Batch Consumption Time: 0.28074
Total Iteration Time: 4.66300

Cumulative Model Updates: 193,016
Cumulative Timesteps: 1,609,578,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,060.58774
Policy Entropy: 3.70928
Value Function Loss: 0.01353

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08153
Policy Update Magnitude: 0.42831
Value Function Update Magnitude: 0.33661

Collected Steps per Second: 23,300.65963
Overall Steps per Second: 10,861.30501

Timestep Collection Time: 2.14612
Timestep Consumption Time: 2.45793
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.60405

Cumulative Model Updates: 193,022
Cumulative Timesteps: 1,609,628,630

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1609628630...
Checkpoint 1609628630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 393,060.58774
Policy Entropy: 3.70344
Value Function Loss: 0.01214

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.04866
Policy Update Magnitude: 0.39455
Value Function Update Magnitude: 0.31651

Collected Steps per Second: 22,820.61132
Overall Steps per Second: 10,701.50338

Timestep Collection Time: 2.19214
Timestep Consumption Time: 2.48253
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.67467

Cumulative Model Updates: 193,028
Cumulative Timesteps: 1,609,678,656

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 393,060.58774
Policy Entropy: 3.70426
Value Function Loss: 0.01236

Mean KL Divergence: 0.00370
SB3 Clip Fraction: 0.03680
Policy Update Magnitude: 0.39723
Value Function Update Magnitude: 0.36652

Collected Steps per Second: 22,301.18360
Overall Steps per Second: 10,925.24134

Timestep Collection Time: 2.24284
Timestep Consumption Time: 2.33536
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.57821

Cumulative Model Updates: 193,034
Cumulative Timesteps: 1,609,728,674

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1609728674...
Checkpoint 1609728674 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 195,628.25753
Policy Entropy: 3.72463
Value Function Loss: 0.01305

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04688
Policy Update Magnitude: 0.40662
Value Function Update Magnitude: 0.46881

Collected Steps per Second: 22,071.28324
Overall Steps per Second: 10,711.42940

Timestep Collection Time: 2.26548
Timestep Consumption Time: 2.40262
PPO Batch Consumption Time: 0.29068
Total Iteration Time: 4.66810

Cumulative Model Updates: 193,040
Cumulative Timesteps: 1,609,778,676

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,228.53681
Policy Entropy: 3.73276
Value Function Loss: 0.01358

Mean KL Divergence: 0.00376
SB3 Clip Fraction: 0.03683
Policy Update Magnitude: 0.43797
Value Function Update Magnitude: 0.51652

Collected Steps per Second: 22,151.79012
Overall Steps per Second: 10,710.11708

Timestep Collection Time: 2.25797
Timestep Consumption Time: 2.41220
PPO Batch Consumption Time: 0.27883
Total Iteration Time: 4.67016

Cumulative Model Updates: 193,046
Cumulative Timesteps: 1,609,828,694

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1609828694...
Checkpoint 1609828694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,789.27351
Policy Entropy: 3.73862
Value Function Loss: 0.01465

Mean KL Divergence: 0.00392
SB3 Clip Fraction: 0.04106
Policy Update Magnitude: 0.45278
Value Function Update Magnitude: 0.51634

Collected Steps per Second: 22,573.25745
Overall Steps per Second: 10,705.62632

Timestep Collection Time: 2.21519
Timestep Consumption Time: 2.45563
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.67082

Cumulative Model Updates: 193,052
Cumulative Timesteps: 1,609,878,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 23,789.27351
Policy Entropy: 3.72869
Value Function Loss: 0.01428

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03751
Policy Update Magnitude: 0.47461
Value Function Update Magnitude: 0.51830

Collected Steps per Second: 23,135.50446
Overall Steps per Second: 10,949.19889

Timestep Collection Time: 2.16127
Timestep Consumption Time: 2.40546
PPO Batch Consumption Time: 0.28086
Total Iteration Time: 4.56673

Cumulative Model Updates: 193,058
Cumulative Timesteps: 1,609,928,700

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1609928700...
Checkpoint 1609928700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,789.27351
Policy Entropy: 3.73003
Value Function Loss: 0.01495

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05369
Policy Update Magnitude: 0.48854
Value Function Update Magnitude: 0.50949

Collected Steps per Second: 22,682.44858
Overall Steps per Second: 10,648.49673

Timestep Collection Time: 2.20452
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.69587

Cumulative Model Updates: 193,064
Cumulative Timesteps: 1,609,978,704

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,653.19042
Policy Entropy: 3.70124
Value Function Loss: 0.01747

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.44533
Value Function Update Magnitude: 0.50153

Collected Steps per Second: 23,019.88582
Overall Steps per Second: 10,847.26348

Timestep Collection Time: 2.17204
Timestep Consumption Time: 2.43742
PPO Batch Consumption Time: 0.27943
Total Iteration Time: 4.60946

Cumulative Model Updates: 193,070
Cumulative Timesteps: 1,610,028,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1610028704...
Checkpoint 1610028704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,653.19042
Policy Entropy: 3.67571
Value Function Loss: 0.01817

Mean KL Divergence: 0.01342
SB3 Clip Fraction: 0.17390
Policy Update Magnitude: 0.37363
Value Function Update Magnitude: 0.47417

Collected Steps per Second: 22,472.68032
Overall Steps per Second: 10,638.65395

Timestep Collection Time: 2.22617
Timestep Consumption Time: 2.47630
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.70247

Cumulative Model Updates: 193,076
Cumulative Timesteps: 1,610,078,732

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,653.19042
Policy Entropy: 3.67463
Value Function Loss: 0.02065

Mean KL Divergence: 0.04151
SB3 Clip Fraction: 0.35626
Policy Update Magnitude: 0.33994
Value Function Update Magnitude: 0.43224

Collected Steps per Second: 22,970.19492
Overall Steps per Second: 10,854.28006

Timestep Collection Time: 2.17734
Timestep Consumption Time: 2.43042
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.60777

Cumulative Model Updates: 193,082
Cumulative Timesteps: 1,610,128,746

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1610128746...
Checkpoint 1610128746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,095,021.68726
Policy Entropy: 3.65035
Value Function Loss: 0.03733

Mean KL Divergence: 0.02597
SB3 Clip Fraction: 0.25745
Policy Update Magnitude: 0.44508
Value Function Update Magnitude: 0.42789

Collected Steps per Second: 21,952.11180
Overall Steps per Second: 10,634.37055

Timestep Collection Time: 2.27778
Timestep Consumption Time: 2.42415
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.70192

Cumulative Model Updates: 193,088
Cumulative Timesteps: 1,610,178,748

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,869.19272
Policy Entropy: 3.68446
Value Function Loss: 0.06512

Mean KL Divergence: 0.01242
SB3 Clip Fraction: 0.15303
Policy Update Magnitude: 0.71365
Value Function Update Magnitude: 0.47282

Collected Steps per Second: 22,605.00231
Overall Steps per Second: 10,593.32558

Timestep Collection Time: 2.21225
Timestep Consumption Time: 2.50845
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.72071

Cumulative Model Updates: 193,094
Cumulative Timesteps: 1,610,228,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1610228756...
Checkpoint 1610228756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,936.26712
Policy Entropy: 3.70403
Value Function Loss: 0.06995

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.16932
Policy Update Magnitude: 1.02179
Value Function Update Magnitude: 0.65042

Collected Steps per Second: 22,030.43830
Overall Steps per Second: 10,543.29525

Timestep Collection Time: 2.27050
Timestep Consumption Time: 2.47375
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.74425

Cumulative Model Updates: 193,100
Cumulative Timesteps: 1,610,278,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86.29579
Policy Entropy: 3.75986
Value Function Loss: 0.06573

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.14024
Policy Update Magnitude: 1.03301
Value Function Update Magnitude: 0.66646

Collected Steps per Second: 22,971.96396
Overall Steps per Second: 10,875.24829

Timestep Collection Time: 2.17700
Timestep Consumption Time: 2.42151
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.59852

Cumulative Model Updates: 193,106
Cumulative Timesteps: 1,610,328,786

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1610328786...
Checkpoint 1610328786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,189.62144
Policy Entropy: 3.78436
Value Function Loss: 0.04866

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.12606
Policy Update Magnitude: 0.98231
Value Function Update Magnitude: 0.62505

Collected Steps per Second: 22,626.23872
Overall Steps per Second: 10,693.88127

Timestep Collection Time: 2.21062
Timestep Consumption Time: 2.46663
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.67725

Cumulative Model Updates: 193,112
Cumulative Timesteps: 1,610,378,804

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178,591.09175
Policy Entropy: 3.75333
Value Function Loss: 0.04542

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.90725
Value Function Update Magnitude: 0.73864

Collected Steps per Second: 22,925.86663
Overall Steps per Second: 10,839.05663

Timestep Collection Time: 2.18155
Timestep Consumption Time: 2.43269
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.61424

Cumulative Model Updates: 193,118
Cumulative Timesteps: 1,610,428,818

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1610428818...
Checkpoint 1610428818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 76,957.55077
Policy Entropy: 3.74739
Value Function Loss: 0.04075

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12613
Policy Update Magnitude: 0.83018
Value Function Update Magnitude: 0.88442

Collected Steps per Second: 22,282.17419
Overall Steps per Second: 10,695.45362

Timestep Collection Time: 2.24457
Timestep Consumption Time: 2.43162
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.67619

Cumulative Model Updates: 193,124
Cumulative Timesteps: 1,610,478,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,559.68074
Policy Entropy: 3.75498
Value Function Loss: 0.03290

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15391
Policy Update Magnitude: 0.64984
Value Function Update Magnitude: 0.74185

Collected Steps per Second: 23,336.76456
Overall Steps per Second: 10,994.50275

Timestep Collection Time: 2.14374
Timestep Consumption Time: 2.40653
PPO Batch Consumption Time: 0.27615
Total Iteration Time: 4.55027

Cumulative Model Updates: 193,130
Cumulative Timesteps: 1,610,528,860

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1610528860...
Checkpoint 1610528860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,547.97762
Policy Entropy: 3.74872
Value Function Loss: 0.02739

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13256
Policy Update Magnitude: 0.53122
Value Function Update Magnitude: 0.64066

Collected Steps per Second: 22,555.05165
Overall Steps per Second: 10,627.34744

Timestep Collection Time: 2.21804
Timestep Consumption Time: 2.48944
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.70748

Cumulative Model Updates: 193,136
Cumulative Timesteps: 1,610,578,888

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,307.11451
Policy Entropy: 3.75340
Value Function Loss: 0.03962

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13345
Policy Update Magnitude: 0.50215
Value Function Update Magnitude: 0.65172

Collected Steps per Second: 23,056.89899
Overall Steps per Second: 10,908.64698

Timestep Collection Time: 2.16950
Timestep Consumption Time: 2.41603
PPO Batch Consumption Time: 0.27669
Total Iteration Time: 4.58554

Cumulative Model Updates: 193,142
Cumulative Timesteps: 1,610,628,910

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1610628910...
Checkpoint 1610628910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645.04982
Policy Entropy: 3.79268
Value Function Loss: 0.05098

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.15554
Policy Update Magnitude: 0.63491
Value Function Update Magnitude: 0.67263

Collected Steps per Second: 22,306.91115
Overall Steps per Second: 10,609.01457

Timestep Collection Time: 2.24253
Timestep Consumption Time: 2.47270
PPO Batch Consumption Time: 0.28611
Total Iteration Time: 4.71524

Cumulative Model Updates: 193,148
Cumulative Timesteps: 1,610,678,934

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,142.99446
Policy Entropy: 3.81298
Value Function Loss: 0.05998

Mean KL Divergence: 0.01558
SB3 Clip Fraction: 0.18566
Policy Update Magnitude: 0.62569
Value Function Update Magnitude: 0.72125

Collected Steps per Second: 22,827.46731
Overall Steps per Second: 10,842.38744

Timestep Collection Time: 2.19140
Timestep Consumption Time: 2.42235
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.61374

Cumulative Model Updates: 193,154
Cumulative Timesteps: 1,610,728,958

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1610728958...
Checkpoint 1610728958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,356.74745
Policy Entropy: 3.87472
Value Function Loss: 0.05720

Mean KL Divergence: 0.01633
SB3 Clip Fraction: 0.18779
Policy Update Magnitude: 0.67284
Value Function Update Magnitude: 0.80529

Collected Steps per Second: 22,554.28545
Overall Steps per Second: 10,724.14107

Timestep Collection Time: 2.21794
Timestep Consumption Time: 2.44668
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.66462

Cumulative Model Updates: 193,160
Cumulative Timesteps: 1,610,778,982

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,864.42683
Policy Entropy: 3.87555
Value Function Loss: 0.05603

Mean KL Divergence: 0.01278
SB3 Clip Fraction: 0.15516
Policy Update Magnitude: 0.74347
Value Function Update Magnitude: 0.67301

Collected Steps per Second: 23,398.29476
Overall Steps per Second: 10,918.94078

Timestep Collection Time: 2.13785
Timestep Consumption Time: 2.44337
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.58121

Cumulative Model Updates: 193,166
Cumulative Timesteps: 1,610,829,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1610829004...
Checkpoint 1610829004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,833.26309
Policy Entropy: 3.89191
Value Function Loss: 0.05270

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.12987
Policy Update Magnitude: 0.72694
Value Function Update Magnitude: 0.62064

Collected Steps per Second: 22,631.33025
Overall Steps per Second: 10,689.97770

Timestep Collection Time: 2.21065
Timestep Consumption Time: 2.46943
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.68008

Cumulative Model Updates: 193,172
Cumulative Timesteps: 1,610,879,034

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 579.32295
Policy Entropy: 3.86946
Value Function Loss: 0.05262

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11206
Policy Update Magnitude: 0.61861
Value Function Update Magnitude: 0.65775

Collected Steps per Second: 22,971.96634
Overall Steps per Second: 10,422.31615

Timestep Collection Time: 2.17718
Timestep Consumption Time: 2.62157
PPO Batch Consumption Time: 0.31591
Total Iteration Time: 4.79874

Cumulative Model Updates: 193,178
Cumulative Timesteps: 1,610,929,048

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1610929048...
Checkpoint 1610929048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134.25779
Policy Entropy: 3.86666
Value Function Loss: 0.04631

Mean KL Divergence: 0.00853
SB3 Clip Fraction: 0.11442
Policy Update Magnitude: 0.52650
Value Function Update Magnitude: 0.67085

Collected Steps per Second: 11,397.13040
Overall Steps per Second: 7,224.40955

Timestep Collection Time: 4.38830
Timestep Consumption Time: 2.53462
PPO Batch Consumption Time: 0.28106
Total Iteration Time: 6.92292

Cumulative Model Updates: 193,184
Cumulative Timesteps: 1,610,979,062

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,477.06301
Policy Entropy: 3.82821
Value Function Loss: 0.04558

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.48328
Value Function Update Magnitude: 0.62025

Collected Steps per Second: 21,995.12920
Overall Steps per Second: 10,406.85831

Timestep Collection Time: 2.27396
Timestep Consumption Time: 2.53210
PPO Batch Consumption Time: 0.29472
Total Iteration Time: 4.80606

Cumulative Model Updates: 193,190
Cumulative Timesteps: 1,611,029,078

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1611029078...
Checkpoint 1611029078 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,529.73586
Policy Entropy: 3.81819
Value Function Loss: 0.03766

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.48486
Value Function Update Magnitude: 0.66720

Collected Steps per Second: 22,090.86411
Overall Steps per Second: 10,678.22761

Timestep Collection Time: 2.26365
Timestep Consumption Time: 2.41934
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.68299

Cumulative Model Updates: 193,196
Cumulative Timesteps: 1,611,079,084

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,550.08072
Policy Entropy: 3.77877
Value Function Loss: 0.03899

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.48818
Value Function Update Magnitude: 0.69643

Collected Steps per Second: 22,656.61795
Overall Steps per Second: 10,751.69819

Timestep Collection Time: 2.20863
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.28616
Total Iteration Time: 4.65415

Cumulative Model Updates: 193,202
Cumulative Timesteps: 1,611,129,124

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1611129124...
Checkpoint 1611129124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 406.66059
Policy Entropy: 3.78520
Value Function Loss: 0.03654

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.48653
Value Function Update Magnitude: 0.73700

Collected Steps per Second: 22,356.38597
Overall Steps per Second: 10,614.55655

Timestep Collection Time: 2.23703
Timestep Consumption Time: 2.47461
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.71164

Cumulative Model Updates: 193,208
Cumulative Timesteps: 1,611,179,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,944.38742
Policy Entropy: 3.78157
Value Function Loss: 0.04398

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13817
Policy Update Magnitude: 0.44017
Value Function Update Magnitude: 0.67576

Collected Steps per Second: 22,919.65758
Overall Steps per Second: 10,700.08877

Timestep Collection Time: 2.18258
Timestep Consumption Time: 2.49252
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.67510

Cumulative Model Updates: 193,214
Cumulative Timesteps: 1,611,229,160

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1611229160...
Checkpoint 1611229160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,172.06967
Policy Entropy: 3.82559
Value Function Loss: 0.03931

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11945
Policy Update Magnitude: 0.42232
Value Function Update Magnitude: 0.58038

Collected Steps per Second: 22,258.78965
Overall Steps per Second: 10,636.00245

Timestep Collection Time: 2.24711
Timestep Consumption Time: 2.45559
PPO Batch Consumption Time: 0.28696
Total Iteration Time: 4.70271

Cumulative Model Updates: 193,220
Cumulative Timesteps: 1,611,279,178

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,761.02353
Policy Entropy: 3.83903
Value Function Loss: 0.04441

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12457
Policy Update Magnitude: 0.43277
Value Function Update Magnitude: 0.55985

Collected Steps per Second: 22,755.83871
Overall Steps per Second: 10,833.22736

Timestep Collection Time: 2.19794
Timestep Consumption Time: 2.41897
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.61691

Cumulative Model Updates: 193,226
Cumulative Timesteps: 1,611,329,194

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1611329194...
Checkpoint 1611329194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,570.91103
Policy Entropy: 3.84252
Value Function Loss: 0.03929

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.11712
Policy Update Magnitude: 0.41992
Value Function Update Magnitude: 0.52762

Collected Steps per Second: 22,569.50606
Overall Steps per Second: 10,748.58467

Timestep Collection Time: 2.21733
Timestep Consumption Time: 2.43854
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.65587

Cumulative Model Updates: 193,232
Cumulative Timesteps: 1,611,379,238

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,023.86924
Policy Entropy: 3.80931
Value Function Loss: 0.04004

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12797
Policy Update Magnitude: 0.43087
Value Function Update Magnitude: 0.70333

Collected Steps per Second: 22,585.44596
Overall Steps per Second: 10,786.26538

Timestep Collection Time: 2.21408
Timestep Consumption Time: 2.42200
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.63608

Cumulative Model Updates: 193,238
Cumulative Timesteps: 1,611,429,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1611429244...
Checkpoint 1611429244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,810.30968
Policy Entropy: 3.76998
Value Function Loss: 0.03557

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12856
Policy Update Magnitude: 0.43124
Value Function Update Magnitude: 0.76732

Collected Steps per Second: 21,987.63220
Overall Steps per Second: 10,656.87260

Timestep Collection Time: 2.27528
Timestep Consumption Time: 2.41916
PPO Batch Consumption Time: 0.27714
Total Iteration Time: 4.69444

Cumulative Model Updates: 193,244
Cumulative Timesteps: 1,611,479,272

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,552.09158
Policy Entropy: 3.76762
Value Function Loss: 0.02825

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13645
Policy Update Magnitude: 0.41486
Value Function Update Magnitude: 0.75478

Collected Steps per Second: 22,309.92004
Overall Steps per Second: 10,527.14400

Timestep Collection Time: 2.24116
Timestep Consumption Time: 2.50847
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.74963

Cumulative Model Updates: 193,250
Cumulative Timesteps: 1,611,529,272

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1611529272...
Checkpoint 1611529272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 477,341.62337
Policy Entropy: 3.75051
Value Function Loss: 0.02846

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.39942
Value Function Update Magnitude: 0.63429

Collected Steps per Second: 22,448.68754
Overall Steps per Second: 10,654.63654

Timestep Collection Time: 2.22846
Timestep Consumption Time: 2.46677
PPO Batch Consumption Time: 0.28633
Total Iteration Time: 4.69523

Cumulative Model Updates: 193,256
Cumulative Timesteps: 1,611,579,298

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,155.77488
Policy Entropy: 3.77322
Value Function Loss: 0.03052

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12716
Policy Update Magnitude: 0.42859
Value Function Update Magnitude: 0.59810

Collected Steps per Second: 23,153.33369
Overall Steps per Second: 10,823.44836

Timestep Collection Time: 2.16012
Timestep Consumption Time: 2.46077
PPO Batch Consumption Time: 0.27847
Total Iteration Time: 4.62089

Cumulative Model Updates: 193,262
Cumulative Timesteps: 1,611,629,312

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1611629312...
Checkpoint 1611629312 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,967.11973
Policy Entropy: 3.77089
Value Function Loss: 0.03456

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.12201
Policy Update Magnitude: 0.44837
Value Function Update Magnitude: 0.62815

Collected Steps per Second: 22,511.04658
Overall Steps per Second: 10,566.96268

Timestep Collection Time: 2.22184
Timestep Consumption Time: 2.51140
PPO Batch Consumption Time: 0.28951
Total Iteration Time: 4.73324

Cumulative Model Updates: 193,268
Cumulative Timesteps: 1,611,679,328

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,409.98592
Policy Entropy: 3.79236
Value Function Loss: 0.03418

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11774
Policy Update Magnitude: 0.45908
Value Function Update Magnitude: 0.58474

Collected Steps per Second: 22,881.26492
Overall Steps per Second: 10,692.33751

Timestep Collection Time: 2.18546
Timestep Consumption Time: 2.49135
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.67681

Cumulative Model Updates: 193,274
Cumulative Timesteps: 1,611,729,334

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1611729334...
Checkpoint 1611729334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,594.39119
Policy Entropy: 3.78539
Value Function Loss: 0.02967

Mean KL Divergence: 0.00882
SB3 Clip Fraction: 0.12243
Policy Update Magnitude: 0.45822
Value Function Update Magnitude: 0.74202

Collected Steps per Second: 22,382.93128
Overall Steps per Second: 10,596.19839

Timestep Collection Time: 2.23527
Timestep Consumption Time: 2.48642
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.72169

Cumulative Model Updates: 193,280
Cumulative Timesteps: 1,611,779,366

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279.17921
Policy Entropy: 3.78758
Value Function Loss: 0.02913

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12396
Policy Update Magnitude: 0.46494
Value Function Update Magnitude: 0.66265

Collected Steps per Second: 22,242.11082
Overall Steps per Second: 10,815.31027

Timestep Collection Time: 2.24808
Timestep Consumption Time: 2.37518
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.62326

Cumulative Model Updates: 193,286
Cumulative Timesteps: 1,611,829,368

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1611829368...
Checkpoint 1611829368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,067.37485
Policy Entropy: 3.77569
Value Function Loss: 0.02784

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.43901
Value Function Update Magnitude: 0.61050

Collected Steps per Second: 21,717.11017
Overall Steps per Second: 10,682.01762

Timestep Collection Time: 2.30242
Timestep Consumption Time: 2.37853
PPO Batch Consumption Time: 0.28396
Total Iteration Time: 4.68095

Cumulative Model Updates: 193,292
Cumulative Timesteps: 1,611,879,370

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,466.67000
Policy Entropy: 3.77166
Value Function Loss: 0.02758

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12344
Policy Update Magnitude: 0.44241
Value Function Update Magnitude: 0.51492

Collected Steps per Second: 21,935.83503
Overall Steps per Second: 10,834.70404

Timestep Collection Time: 2.28074
Timestep Consumption Time: 2.33683
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.61757

Cumulative Model Updates: 193,298
Cumulative Timesteps: 1,611,929,400

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1611929400...
Checkpoint 1611929400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 15,580.00624
Policy Entropy: 3.77847
Value Function Loss: 0.02918

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12446
Policy Update Magnitude: 0.43150
Value Function Update Magnitude: 0.53134

Collected Steps per Second: 21,141.80456
Overall Steps per Second: 10,641.92740

Timestep Collection Time: 2.36546
Timestep Consumption Time: 2.33388
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.69934

Cumulative Model Updates: 193,304
Cumulative Timesteps: 1,611,979,410

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,028.42140
Policy Entropy: 3.78920
Value Function Loss: 0.02921

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.12040
Policy Update Magnitude: 0.43951
Value Function Update Magnitude: 0.58441

Collected Steps per Second: 22,251.01917
Overall Steps per Second: 10,563.32695

Timestep Collection Time: 2.24754
Timestep Consumption Time: 2.48677
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.73430

Cumulative Model Updates: 193,310
Cumulative Timesteps: 1,612,029,420

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1612029420...
Checkpoint 1612029420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212.32915
Policy Entropy: 3.77775
Value Function Loss: 0.02743

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.40974
Value Function Update Magnitude: 0.56659

Collected Steps per Second: 22,311.65826
Overall Steps per Second: 10,549.22827

Timestep Collection Time: 2.24098
Timestep Consumption Time: 2.49870
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.73968

Cumulative Model Updates: 193,316
Cumulative Timesteps: 1,612,079,420

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63.37236
Policy Entropy: 3.76927
Value Function Loss: 0.02246

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.37532
Value Function Update Magnitude: 0.54845

Collected Steps per Second: 23,112.68364
Overall Steps per Second: 10,969.23000

Timestep Collection Time: 2.16427
Timestep Consumption Time: 2.39594
PPO Batch Consumption Time: 0.27604
Total Iteration Time: 4.56021

Cumulative Model Updates: 193,322
Cumulative Timesteps: 1,612,129,442

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1612129442...
Checkpoint 1612129442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,232.21695
Policy Entropy: 3.75248
Value Function Loss: 0.01935

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.13083
Policy Update Magnitude: 0.35880
Value Function Update Magnitude: 0.58914

Collected Steps per Second: 22,614.07146
Overall Steps per Second: 10,709.94783

Timestep Collection Time: 2.21181
Timestep Consumption Time: 2.45843
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.67024

Cumulative Model Updates: 193,328
Cumulative Timesteps: 1,612,179,460

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,886.16837
Policy Entropy: 3.73167
Value Function Loss: 0.02339

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.38799
Value Function Update Magnitude: 0.63703

Collected Steps per Second: 23,107.01510
Overall Steps per Second: 10,812.21538

Timestep Collection Time: 2.16523
Timestep Consumption Time: 2.46213
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.62736

Cumulative Model Updates: 193,334
Cumulative Timesteps: 1,612,229,492

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1612229492...
Checkpoint 1612229492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,638.51273
Policy Entropy: 3.74826
Value Function Loss: 0.02539

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.40725
Value Function Update Magnitude: 0.63724

Collected Steps per Second: 22,566.36571
Overall Steps per Second: 10,603.46005

Timestep Collection Time: 2.21710
Timestep Consumption Time: 2.50135
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.71846

Cumulative Model Updates: 193,340
Cumulative Timesteps: 1,612,279,524

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,068.34327
Policy Entropy: 3.74968
Value Function Loss: 0.02826

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12512
Policy Update Magnitude: 0.44231
Value Function Update Magnitude: 0.55132

Collected Steps per Second: 23,053.60188
Overall Steps per Second: 10,873.53626

Timestep Collection Time: 2.16921
Timestep Consumption Time: 2.42985
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.59906

Cumulative Model Updates: 193,346
Cumulative Timesteps: 1,612,329,532

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1612329532...
Checkpoint 1612329532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,248.03693
Policy Entropy: 3.76964
Value Function Loss: 0.02201

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.47663
Value Function Update Magnitude: 0.58876

Collected Steps per Second: 22,383.71877
Overall Steps per Second: 10,704.49524

Timestep Collection Time: 2.23386
Timestep Consumption Time: 2.43727
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.67112

Cumulative Model Updates: 193,352
Cumulative Timesteps: 1,612,379,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 542.96558
Policy Entropy: 3.77081
Value Function Loss: 0.01957

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.43780
Value Function Update Magnitude: 0.53520

Collected Steps per Second: 22,514.34185
Overall Steps per Second: 10,631.64358

Timestep Collection Time: 2.22178
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.28882
Total Iteration Time: 4.70501

Cumulative Model Updates: 193,358
Cumulative Timesteps: 1,612,429,556

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1612429556...
Checkpoint 1612429556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 91.21831
Policy Entropy: 3.76388
Value Function Loss: 0.01844

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.41475
Value Function Update Magnitude: 0.62349

Collected Steps per Second: 22,114.57530
Overall Steps per Second: 10,505.14246

Timestep Collection Time: 2.26213
Timestep Consumption Time: 2.49992
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.76205

Cumulative Model Updates: 193,364
Cumulative Timesteps: 1,612,479,582

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,792.07557
Policy Entropy: 3.75871
Value Function Loss: 0.02260

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.43009
Value Function Update Magnitude: 0.66772

Collected Steps per Second: 22,587.25268
Overall Steps per Second: 10,796.79823

Timestep Collection Time: 2.21488
Timestep Consumption Time: 2.41872
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.63360

Cumulative Model Updates: 193,370
Cumulative Timesteps: 1,612,529,610

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1612529610...
Checkpoint 1612529610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,608.03329
Policy Entropy: 3.76415
Value Function Loss: 0.02466

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12217
Policy Update Magnitude: 0.41674
Value Function Update Magnitude: 0.56335

Collected Steps per Second: 22,226.13189
Overall Steps per Second: 10,687.12448

Timestep Collection Time: 2.24969
Timestep Consumption Time: 2.42902
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.67871

Cumulative Model Updates: 193,376
Cumulative Timesteps: 1,612,579,612

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,531.32777
Policy Entropy: 3.75923
Value Function Loss: 0.02725

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12744
Policy Update Magnitude: 0.40155
Value Function Update Magnitude: 0.59481

Collected Steps per Second: 22,886.66901
Overall Steps per Second: 10,596.27216

Timestep Collection Time: 2.18468
Timestep Consumption Time: 2.53396
PPO Batch Consumption Time: 0.29080
Total Iteration Time: 4.71864

Cumulative Model Updates: 193,382
Cumulative Timesteps: 1,612,629,612

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1612629612...
Checkpoint 1612629612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,342.59714
Policy Entropy: 3.74264
Value Function Loss: 0.02609

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12843
Policy Update Magnitude: 0.40450
Value Function Update Magnitude: 0.56874

Collected Steps per Second: 20,412.82644
Overall Steps per Second: 10,065.02127

Timestep Collection Time: 2.45081
Timestep Consumption Time: 2.51967
PPO Batch Consumption Time: 0.28459
Total Iteration Time: 4.97048

Cumulative Model Updates: 193,388
Cumulative Timesteps: 1,612,679,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,870.75177
Policy Entropy: 3.70976
Value Function Loss: 0.02823

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13142
Policy Update Magnitude: 0.40803
Value Function Update Magnitude: 0.48926

Collected Steps per Second: 22,116.15532
Overall Steps per Second: 10,493.65763

Timestep Collection Time: 2.26142
Timestep Consumption Time: 2.50469
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.76612

Cumulative Model Updates: 193,394
Cumulative Timesteps: 1,612,729,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1612729654...
Checkpoint 1612729654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,870.75177
Policy Entropy: 3.71128
Value Function Loss: 0.02278

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13431
Policy Update Magnitude: 0.42418
Value Function Update Magnitude: 0.50957

Collected Steps per Second: 22,751.35532
Overall Steps per Second: 10,655.55621

Timestep Collection Time: 2.19802
Timestep Consumption Time: 2.49512
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.69314

Cumulative Model Updates: 193,400
Cumulative Timesteps: 1,612,779,662

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 98,870.75177
Policy Entropy: 3.68982
Value Function Loss: 0.02083

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13249
Policy Update Magnitude: 0.40716
Value Function Update Magnitude: 0.52641

Collected Steps per Second: 22,341.94350
Overall Steps per Second: 10,876.86202

Timestep Collection Time: 2.23857
Timestep Consumption Time: 2.35963
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.59820

Cumulative Model Updates: 193,406
Cumulative Timesteps: 1,612,829,676

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1612829676...
Checkpoint 1612829676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,870.75177
Policy Entropy: 3.69257
Value Function Loss: 0.01761

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12898
Policy Update Magnitude: 0.38761
Value Function Update Magnitude: 0.50252

Collected Steps per Second: 21,667.41600
Overall Steps per Second: 10,582.95196

Timestep Collection Time: 2.30761
Timestep Consumption Time: 2.41697
PPO Batch Consumption Time: 0.28572
Total Iteration Time: 4.72458

Cumulative Model Updates: 193,412
Cumulative Timesteps: 1,612,879,676

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,896.23911
Policy Entropy: 3.70162
Value Function Loss: 0.02426

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.42484
Value Function Update Magnitude: 0.62604

Collected Steps per Second: 22,154.67843
Overall Steps per Second: 10,557.32095

Timestep Collection Time: 2.25812
Timestep Consumption Time: 2.48058
PPO Batch Consumption Time: 0.29111
Total Iteration Time: 4.73870

Cumulative Model Updates: 193,418
Cumulative Timesteps: 1,612,929,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1612929704...
Checkpoint 1612929704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,658.46049
Policy Entropy: 3.75086
Value Function Loss: 0.02937

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.11647
Policy Update Magnitude: 0.51386
Value Function Update Magnitude: 0.81697

Collected Steps per Second: 22,074.95973
Overall Steps per Second: 10,640.02903

Timestep Collection Time: 2.26619
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.70168

Cumulative Model Updates: 193,424
Cumulative Timesteps: 1,612,979,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,286.43213
Policy Entropy: 3.77776
Value Function Loss: 0.03436

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11481
Policy Update Magnitude: 0.54201
Value Function Update Magnitude: 0.95025

Collected Steps per Second: 22,713.86399
Overall Steps per Second: 10,829.72429

Timestep Collection Time: 2.20209
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.61858

Cumulative Model Updates: 193,430
Cumulative Timesteps: 1,613,029,748

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1613029748...
Checkpoint 1613029748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,004.36342
Policy Entropy: 3.79064
Value Function Loss: 0.03481

Mean KL Divergence: 0.00847
SB3 Clip Fraction: 0.11637
Policy Update Magnitude: 0.56667
Value Function Update Magnitude: 1.00768

Collected Steps per Second: 21,916.33591
Overall Steps per Second: 10,660.92241

Timestep Collection Time: 2.28213
Timestep Consumption Time: 2.40939
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.69153

Cumulative Model Updates: 193,436
Cumulative Timesteps: 1,613,079,764

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362.05847
Policy Entropy: 3.76970
Value Function Loss: 0.03373

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12840
Policy Update Magnitude: 0.53548
Value Function Update Magnitude: 0.97312

Collected Steps per Second: 22,809.21191
Overall Steps per Second: 10,671.63917

Timestep Collection Time: 2.19254
Timestep Consumption Time: 2.49372
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.68625

Cumulative Model Updates: 193,442
Cumulative Timesteps: 1,613,129,774

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1613129774...
Checkpoint 1613129774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,951.36102
Policy Entropy: 3.77404
Value Function Loss: 0.03038

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12979
Policy Update Magnitude: 0.48747
Value Function Update Magnitude: 0.81333

Collected Steps per Second: 22,915.45707
Overall Steps per Second: 10,842.74359

Timestep Collection Time: 2.18289
Timestep Consumption Time: 2.43051
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.61341

Cumulative Model Updates: 193,448
Cumulative Timesteps: 1,613,179,796

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,650.22109
Policy Entropy: 3.74646
Value Function Loss: 0.03002

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12580
Policy Update Magnitude: 0.46479
Value Function Update Magnitude: 0.61533

Collected Steps per Second: 22,709.41050
Overall Steps per Second: 10,630.33861

Timestep Collection Time: 2.20208
Timestep Consumption Time: 2.50219
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.70427

Cumulative Model Updates: 193,454
Cumulative Timesteps: 1,613,229,804

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1613229804...
Checkpoint 1613229804 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,727.69300
Policy Entropy: 3.74869
Value Function Loss: 0.02660

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.44759
Value Function Update Magnitude: 0.50986

Collected Steps per Second: 22,180.66063
Overall Steps per Second: 10,507.60810

Timestep Collection Time: 2.25593
Timestep Consumption Time: 2.50614
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.76207

Cumulative Model Updates: 193,460
Cumulative Timesteps: 1,613,279,842

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,668.57700
Policy Entropy: 3.71952
Value Function Loss: 0.02932

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.46514
Value Function Update Magnitude: 0.46655

Collected Steps per Second: 22,461.02055
Overall Steps per Second: 10,598.27902

Timestep Collection Time: 2.22706
Timestep Consumption Time: 2.49276
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.71982

Cumulative Model Updates: 193,466
Cumulative Timesteps: 1,613,329,864

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1613329864...
Checkpoint 1613329864 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.51618
Policy Entropy: 3.72489
Value Function Loss: 0.02614

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12829
Policy Update Magnitude: 0.50557
Value Function Update Magnitude: 0.44215

Collected Steps per Second: 22,646.70983
Overall Steps per Second: 10,638.25828

Timestep Collection Time: 2.20897
Timestep Consumption Time: 2.49349
PPO Batch Consumption Time: 0.29100
Total Iteration Time: 4.70246

Cumulative Model Updates: 193,472
Cumulative Timesteps: 1,613,379,890

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,100.51618
Policy Entropy: 3.69357
Value Function Loss: 0.03044

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13243
Policy Update Magnitude: 0.52516
Value Function Update Magnitude: 0.46181

Collected Steps per Second: 22,947.62305
Overall Steps per Second: 10,779.27211

Timestep Collection Time: 2.17966
Timestep Consumption Time: 2.46054
PPO Batch Consumption Time: 0.28302
Total Iteration Time: 4.64020

Cumulative Model Updates: 193,478
Cumulative Timesteps: 1,613,429,908

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1613429908...
Checkpoint 1613429908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 74,265.95777
Policy Entropy: 3.69511
Value Function Loss: 0.02421

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13164
Policy Update Magnitude: 0.48707
Value Function Update Magnitude: 0.47014

Collected Steps per Second: 21,855.71114
Overall Steps per Second: 10,628.73776

Timestep Collection Time: 2.28819
Timestep Consumption Time: 2.41698
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.70517

Cumulative Model Updates: 193,484
Cumulative Timesteps: 1,613,479,918

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,728.93571
Policy Entropy: 3.70509
Value Function Loss: 0.02170

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.43650
Value Function Update Magnitude: 0.49282

Collected Steps per Second: 22,487.21293
Overall Steps per Second: 10,614.68633

Timestep Collection Time: 2.22357
Timestep Consumption Time: 2.48707
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.71064

Cumulative Model Updates: 193,490
Cumulative Timesteps: 1,613,529,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1613529920...
Checkpoint 1613529920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,728.93571
Policy Entropy: 3.71656
Value Function Loss: 0.01769

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.37267
Value Function Update Magnitude: 0.38664

Collected Steps per Second: 22,498.27098
Overall Steps per Second: 10,588.61266

Timestep Collection Time: 2.22453
Timestep Consumption Time: 2.50206
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.72659

Cumulative Model Updates: 193,496
Cumulative Timesteps: 1,613,579,968

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 131,433.78678
Policy Entropy: 3.72837
Value Function Loss: 0.02042

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12928
Policy Update Magnitude: 0.35403
Value Function Update Magnitude: 0.37137

Collected Steps per Second: 22,621.31986
Overall Steps per Second: 10,560.07933

Timestep Collection Time: 2.21048
Timestep Consumption Time: 2.52471
PPO Batch Consumption Time: 0.28725
Total Iteration Time: 4.73519

Cumulative Model Updates: 193,502
Cumulative Timesteps: 1,613,629,972

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1613629972...
Checkpoint 1613629972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,838.78845
Policy Entropy: 3.71863
Value Function Loss: 0.02136

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12697
Policy Update Magnitude: 0.40108
Value Function Update Magnitude: 0.49358

Collected Steps per Second: 22,023.99647
Overall Steps per Second: 10,432.91313

Timestep Collection Time: 2.27116
Timestep Consumption Time: 2.52328
PPO Batch Consumption Time: 0.29330
Total Iteration Time: 4.79444

Cumulative Model Updates: 193,508
Cumulative Timesteps: 1,613,679,992

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45,838.78845
Policy Entropy: 3.72589
Value Function Loss: 0.02194

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12458
Policy Update Magnitude: 0.43919
Value Function Update Magnitude: 0.49501

Collected Steps per Second: 22,770.94157
Overall Steps per Second: 10,547.11882

Timestep Collection Time: 2.19701
Timestep Consumption Time: 2.54628
PPO Batch Consumption Time: 0.29075
Total Iteration Time: 4.74329

Cumulative Model Updates: 193,514
Cumulative Timesteps: 1,613,730,020

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1613730020...
Checkpoint 1613730020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,182.52137
Policy Entropy: 3.70501
Value Function Loss: 0.02055

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.44326
Value Function Update Magnitude: 0.54391

Collected Steps per Second: 22,605.27003
Overall Steps per Second: 10,621.16213

Timestep Collection Time: 2.21223
Timestep Consumption Time: 2.49611
PPO Batch Consumption Time: 0.29084
Total Iteration Time: 4.70834

Cumulative Model Updates: 193,520
Cumulative Timesteps: 1,613,780,028

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 39,827.16573
Policy Entropy: 3.72170
Value Function Loss: 0.02062

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12947
Policy Update Magnitude: 0.44618
Value Function Update Magnitude: 0.60665

Collected Steps per Second: 22,816.78604
Overall Steps per Second: 10,815.24116

Timestep Collection Time: 2.19312
Timestep Consumption Time: 2.43368
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.62680

Cumulative Model Updates: 193,526
Cumulative Timesteps: 1,613,830,068

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1613830068...
Checkpoint 1613830068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,255.64947
Policy Entropy: 3.72256
Value Function Loss: 0.02402

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.43167
Value Function Update Magnitude: 0.49252

Collected Steps per Second: 22,520.08850
Overall Steps per Second: 10,637.66769

Timestep Collection Time: 2.22077
Timestep Consumption Time: 2.48063
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.70141

Cumulative Model Updates: 193,532
Cumulative Timesteps: 1,613,880,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,729.86463
Policy Entropy: 3.72781
Value Function Loss: 0.02614

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.12083
Policy Update Magnitude: 0.43571
Value Function Update Magnitude: 0.38193

Collected Steps per Second: 22,805.10966
Overall Steps per Second: 10,859.19351

Timestep Collection Time: 2.19284
Timestep Consumption Time: 2.41229
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.60513

Cumulative Model Updates: 193,538
Cumulative Timesteps: 1,613,930,088

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1613930088...
Checkpoint 1613930088 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 92,729.86463
Policy Entropy: 3.70676
Value Function Loss: 0.02471

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13127
Policy Update Magnitude: 0.44001
Value Function Update Magnitude: 0.34718

Collected Steps per Second: 21,850.52173
Overall Steps per Second: 10,642.49536

Timestep Collection Time: 2.29011
Timestep Consumption Time: 2.41180
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.70190

Cumulative Model Updates: 193,544
Cumulative Timesteps: 1,613,980,128

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 92,729.86463
Policy Entropy: 3.69659
Value Function Loss: 0.02285

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.38354
Value Function Update Magnitude: 0.31899

Collected Steps per Second: 22,483.13888
Overall Steps per Second: 10,583.81222

Timestep Collection Time: 2.22522
Timestep Consumption Time: 2.50181
PPO Batch Consumption Time: 0.29187
Total Iteration Time: 4.72703

Cumulative Model Updates: 193,550
Cumulative Timesteps: 1,614,030,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1614030158...
Checkpoint 1614030158 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234,843.37840
Policy Entropy: 3.71863
Value Function Loss: 0.01911

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.35677
Value Function Update Magnitude: 0.27378

Collected Steps per Second: 22,011.94512
Overall Steps per Second: 10,605.76715

Timestep Collection Time: 2.27249
Timestep Consumption Time: 2.44400
PPO Batch Consumption Time: 0.28170
Total Iteration Time: 4.71649

Cumulative Model Updates: 193,556
Cumulative Timesteps: 1,614,080,180

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 81,897.44262
Policy Entropy: 3.72711
Value Function Loss: 0.02010

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12518
Policy Update Magnitude: 0.36534
Value Function Update Magnitude: 0.32973

Collected Steps per Second: 22,666.28377
Overall Steps per Second: 10,677.69067

Timestep Collection Time: 2.20636
Timestep Consumption Time: 2.47724
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.68360

Cumulative Model Updates: 193,562
Cumulative Timesteps: 1,614,130,190

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1614130190...
Checkpoint 1614130190 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,524.48906
Policy Entropy: 3.72619
Value Function Loss: 0.01850

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.40974
Value Function Update Magnitude: 0.48600

Collected Steps per Second: 21,927.86106
Overall Steps per Second: 10,424.88896

Timestep Collection Time: 2.28066
Timestep Consumption Time: 2.51651
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.79717

Cumulative Model Updates: 193,568
Cumulative Timesteps: 1,614,180,200

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,524.48906
Policy Entropy: 3.70142
Value Function Loss: 0.02182

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12675
Policy Update Magnitude: 0.46040
Value Function Update Magnitude: 0.56531

Collected Steps per Second: 23,025.66351
Overall Steps per Second: 10,819.75334

Timestep Collection Time: 2.17253
Timestep Consumption Time: 2.45086
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.62340

Cumulative Model Updates: 193,574
Cumulative Timesteps: 1,614,230,224

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1614230224...
Checkpoint 1614230224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,758.92222
Policy Entropy: 3.69465
Value Function Loss: 0.02264

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12442
Policy Update Magnitude: 0.49529
Value Function Update Magnitude: 0.52602

Collected Steps per Second: 21,897.18535
Overall Steps per Second: 10,606.37224

Timestep Collection Time: 2.28367
Timestep Consumption Time: 2.43104
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.71471

Cumulative Model Updates: 193,580
Cumulative Timesteps: 1,614,280,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,832.21377
Policy Entropy: 3.70447
Value Function Loss: 0.02715

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12778
Policy Update Magnitude: 0.52195
Value Function Update Magnitude: 0.48597

Collected Steps per Second: 22,764.90650
Overall Steps per Second: 10,679.48655

Timestep Collection Time: 2.19786
Timestep Consumption Time: 2.48720
PPO Batch Consumption Time: 0.29105
Total Iteration Time: 4.68506

Cumulative Model Updates: 193,586
Cumulative Timesteps: 1,614,330,264

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1614330264...
Checkpoint 1614330264 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,205.94271
Policy Entropy: 3.72123
Value Function Loss: 0.02753

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12271
Policy Update Magnitude: 0.51406
Value Function Update Magnitude: 0.61002

Collected Steps per Second: 22,556.86412
Overall Steps per Second: 10,599.32187

Timestep Collection Time: 2.21680
Timestep Consumption Time: 2.50086
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.71766

Cumulative Model Updates: 193,592
Cumulative Timesteps: 1,614,380,268

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 163,166.68205
Policy Entropy: 3.72193
Value Function Loss: 0.02874

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12781
Policy Update Magnitude: 0.51964
Value Function Update Magnitude: 0.73744

Collected Steps per Second: 23,074.69504
Overall Steps per Second: 10,796.97856

Timestep Collection Time: 2.16714
Timestep Consumption Time: 2.46435
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.63148

Cumulative Model Updates: 193,598
Cumulative Timesteps: 1,614,430,274

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1614430274...
Checkpoint 1614430274 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,908.68079
Policy Entropy: 3.72908
Value Function Loss: 0.02657

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12472
Policy Update Magnitude: 0.50406
Value Function Update Magnitude: 0.73743

Collected Steps per Second: 21,931.24132
Overall Steps per Second: 10,664.77548

Timestep Collection Time: 2.28004
Timestep Consumption Time: 2.40867
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.68871

Cumulative Model Updates: 193,604
Cumulative Timesteps: 1,614,480,278

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,094.61933
Policy Entropy: 3.71972
Value Function Loss: 0.02477

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12605
Policy Update Magnitude: 0.50863
Value Function Update Magnitude: 0.72679

Collected Steps per Second: 21,948.54896
Overall Steps per Second: 10,812.37290

Timestep Collection Time: 2.27878
Timestep Consumption Time: 2.34703
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.62581

Cumulative Model Updates: 193,610
Cumulative Timesteps: 1,614,530,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1614530294...
Checkpoint 1614530294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,528.78086
Policy Entropy: 3.73174
Value Function Loss: 0.02053

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13002
Policy Update Magnitude: 0.51248
Value Function Update Magnitude: 0.61933

Collected Steps per Second: 21,430.05959
Overall Steps per Second: 10,429.38247

Timestep Collection Time: 2.33317
Timestep Consumption Time: 2.46098
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.79415

Cumulative Model Updates: 193,616
Cumulative Timesteps: 1,614,580,294

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,854.56114
Policy Entropy: 3.71417
Value Function Loss: 0.02036

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12440
Policy Update Magnitude: 0.45061
Value Function Update Magnitude: 0.64430

Collected Steps per Second: 22,794.92725
Overall Steps per Second: 10,759.20871

Timestep Collection Time: 2.19487
Timestep Consumption Time: 2.45528
PPO Batch Consumption Time: 0.28788
Total Iteration Time: 4.65016

Cumulative Model Updates: 193,622
Cumulative Timesteps: 1,614,630,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1614630326...
Checkpoint 1614630326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 237,156.82077
Policy Entropy: 3.71738
Value Function Loss: 0.02240

Mean KL Divergence: 0.00868
SB3 Clip Fraction: 0.12136
Policy Update Magnitude: 0.44019
Value Function Update Magnitude: 0.63275

Collected Steps per Second: 22,278.44826
Overall Steps per Second: 10,613.71359

Timestep Collection Time: 2.24459
Timestep Consumption Time: 2.46686
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.71145

Cumulative Model Updates: 193,628
Cumulative Timesteps: 1,614,680,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 126,036.23944
Policy Entropy: 3.68645
Value Function Loss: 0.02806

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13087
Policy Update Magnitude: 0.46811
Value Function Update Magnitude: 0.62070

Collected Steps per Second: 23,249.25757
Overall Steps per Second: 10,861.96643

Timestep Collection Time: 2.15164
Timestep Consumption Time: 2.45379
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.60543

Cumulative Model Updates: 193,634
Cumulative Timesteps: 1,614,730,356

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1614730356...
Checkpoint 1614730356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,053.34335
Policy Entropy: 3.71626
Value Function Loss: 0.02660

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.49263
Value Function Update Magnitude: 0.65114

Collected Steps per Second: 22,637.32632
Overall Steps per Second: 10,699.40440

Timestep Collection Time: 2.21069
Timestep Consumption Time: 2.46658
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.67727

Cumulative Model Updates: 193,640
Cumulative Timesteps: 1,614,780,400

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 58,611.27224
Policy Entropy: 3.72062
Value Function Loss: 0.02467

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12508
Policy Update Magnitude: 0.47270
Value Function Update Magnitude: 0.73669

Collected Steps per Second: 22,889.67957
Overall Steps per Second: 10,864.81741

Timestep Collection Time: 2.18640
Timestep Consumption Time: 2.41984
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.60624

Cumulative Model Updates: 193,646
Cumulative Timesteps: 1,614,830,446

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1614830446...
Checkpoint 1614830446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,234.13588
Policy Entropy: 3.73129
Value Function Loss: 0.02274

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08895
Policy Update Magnitude: 0.48268
Value Function Update Magnitude: 0.71844

Collected Steps per Second: 22,446.31938
Overall Steps per Second: 10,713.56127

Timestep Collection Time: 2.22807
Timestep Consumption Time: 2.44003
PPO Batch Consumption Time: 0.28614
Total Iteration Time: 4.66810

Cumulative Model Updates: 193,652
Cumulative Timesteps: 1,614,880,458

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.83320
Policy Entropy: 3.72869
Value Function Loss: 0.02046

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.12847
Policy Update Magnitude: 0.46359
Value Function Update Magnitude: 0.74747

Collected Steps per Second: 22,774.15347
Overall Steps per Second: 10,850.85311

Timestep Collection Time: 2.19740
Timestep Consumption Time: 2.41458
PPO Batch Consumption Time: 0.27693
Total Iteration Time: 4.61199

Cumulative Model Updates: 193,658
Cumulative Timesteps: 1,614,930,502

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1614930502...
Checkpoint 1614930502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.83320
Policy Entropy: 3.72578
Value Function Loss: 0.01752

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.04919
Policy Update Magnitude: 0.47992
Value Function Update Magnitude: 0.65521

Collected Steps per Second: 22,411.41702
Overall Steps per Second: 10,711.17553

Timestep Collection Time: 2.23136
Timestep Consumption Time: 2.43741
PPO Batch Consumption Time: 0.28117
Total Iteration Time: 4.66877

Cumulative Model Updates: 193,664
Cumulative Timesteps: 1,614,980,510

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.83320
Policy Entropy: 3.72380
Value Function Loss: 0.01334

Mean KL Divergence: 0.00479
SB3 Clip Fraction: 0.05378
Policy Update Magnitude: 0.47511
Value Function Update Magnitude: 0.51036

Collected Steps per Second: 22,611.76355
Overall Steps per Second: 10,814.72974

Timestep Collection Time: 2.21248
Timestep Consumption Time: 2.41344
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.62591

Cumulative Model Updates: 193,670
Cumulative Timesteps: 1,615,030,538

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1615030538...
Checkpoint 1615030538 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.83320
Policy Entropy: 3.70944
Value Function Loss: 0.01300

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04669
Policy Update Magnitude: 0.47506
Value Function Update Magnitude: 0.43920

Collected Steps per Second: 21,783.33305
Overall Steps per Second: 10,424.82919

Timestep Collection Time: 2.29634
Timestep Consumption Time: 2.50201
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.79835

Cumulative Model Updates: 193,676
Cumulative Timesteps: 1,615,080,560

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.83320
Policy Entropy: 3.70190
Value Function Loss: 0.01629

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04834
Policy Update Magnitude: 0.56468
Value Function Update Magnitude: 0.54621

Collected Steps per Second: 22,514.61534
Overall Steps per Second: 10,733.88040

Timestep Collection Time: 2.22087
Timestep Consumption Time: 2.43747
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.65833

Cumulative Model Updates: 193,682
Cumulative Timesteps: 1,615,130,562

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1615130562...
Checkpoint 1615130562 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.83320
Policy Entropy: 3.69757
Value Function Loss: 0.01984

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06020
Policy Update Magnitude: 0.63774
Value Function Update Magnitude: 0.54136

Collected Steps per Second: 22,552.33414
Overall Steps per Second: 10,681.77229

Timestep Collection Time: 2.21866
Timestep Consumption Time: 2.46558
PPO Batch Consumption Time: 0.28161
Total Iteration Time: 4.68424

Cumulative Model Updates: 193,688
Cumulative Timesteps: 1,615,180,598

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.83320
Policy Entropy: 3.70304
Value Function Loss: 0.02356

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.06918
Policy Update Magnitude: 0.62789
Value Function Update Magnitude: 0.37629

Collected Steps per Second: 22,653.12272
Overall Steps per Second: 10,657.53107

Timestep Collection Time: 2.20879
Timestep Consumption Time: 2.48611
PPO Batch Consumption Time: 0.28680
Total Iteration Time: 4.69490

Cumulative Model Updates: 193,694
Cumulative Timesteps: 1,615,230,634

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1615230634...
Checkpoint 1615230634 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.83320
Policy Entropy: 3.70962
Value Function Loss: 0.01957

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13499
Policy Update Magnitude: 0.52597
Value Function Update Magnitude: 0.28558

Collected Steps per Second: 22,388.08209
Overall Steps per Second: 10,637.99661

Timestep Collection Time: 2.23333
Timestep Consumption Time: 2.46680
PPO Batch Consumption Time: 0.28687
Total Iteration Time: 4.70013

Cumulative Model Updates: 193,700
Cumulative Timesteps: 1,615,280,634

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,500.83320
Policy Entropy: 3.72776
Value Function Loss: 0.01660

Mean KL Divergence: 0.02729
SB3 Clip Fraction: 0.31288
Policy Update Magnitude: 0.37324
Value Function Update Magnitude: 0.28646

Collected Steps per Second: 22,198.84661
Overall Steps per Second: 10,717.63417

Timestep Collection Time: 2.25363
Timestep Consumption Time: 2.41419
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.66782

Cumulative Model Updates: 193,706
Cumulative Timesteps: 1,615,330,662

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1615330662...
Checkpoint 1615330662 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 88,701.31313
Policy Entropy: 3.70453
Value Function Loss: 0.03708

Mean KL Divergence: 0.01307
SB3 Clip Fraction: 0.16526
Policy Update Magnitude: 0.43177
Value Function Update Magnitude: 0.51633

Collected Steps per Second: 22,138.31931
Overall Steps per Second: 10,757.90316

Timestep Collection Time: 2.25970
Timestep Consumption Time: 2.39046
PPO Batch Consumption Time: 0.29025
Total Iteration Time: 4.65016

Cumulative Model Updates: 193,712
Cumulative Timesteps: 1,615,380,688

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 57,086.13366
Policy Entropy: 3.71667
Value Function Loss: 0.04446

Mean KL Divergence: 0.01700
SB3 Clip Fraction: 0.18686
Policy Update Magnitude: 0.65330
Value Function Update Magnitude: 0.61939

Collected Steps per Second: 22,077.94398
Overall Steps per Second: 10,725.05797

Timestep Collection Time: 2.26498
Timestep Consumption Time: 2.39756
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.66254

Cumulative Model Updates: 193,718
Cumulative Timesteps: 1,615,430,694

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1615430694...
Checkpoint 1615430694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,249.64921
Policy Entropy: 3.70301
Value Function Loss: 0.04251

Mean KL Divergence: 0.01857
SB3 Clip Fraction: 0.20772
Policy Update Magnitude: 0.76058
Value Function Update Magnitude: 0.68620

Collected Steps per Second: 21,807.50133
Overall Steps per Second: 10,702.11459

Timestep Collection Time: 2.29407
Timestep Consumption Time: 2.38052
PPO Batch Consumption Time: 0.28414
Total Iteration Time: 4.67459

Cumulative Model Updates: 193,724
Cumulative Timesteps: 1,615,480,722

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,720.08475
Policy Entropy: 3.73176
Value Function Loss: 0.03222

Mean KL Divergence: 0.01065
SB3 Clip Fraction: 0.13581
Policy Update Magnitude: 0.76470
Value Function Update Magnitude: 0.71543

Collected Steps per Second: 21,719.60883
Overall Steps per Second: 10,444.17689

Timestep Collection Time: 2.30336
Timestep Consumption Time: 2.48668
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.79004

Cumulative Model Updates: 193,730
Cumulative Timesteps: 1,615,530,750

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1615530750...
Checkpoint 1615530750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,991.01993
Policy Entropy: 3.73472
Value Function Loss: 0.02548

Mean KL Divergence: 0.01490
SB3 Clip Fraction: 0.18916
Policy Update Magnitude: 0.65011
Value Function Update Magnitude: 0.80796

Collected Steps per Second: 21,584.32298
Overall Steps per Second: 10,609.50796

Timestep Collection Time: 2.31650
Timestep Consumption Time: 2.39626
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.71275

Cumulative Model Updates: 193,736
Cumulative Timesteps: 1,615,580,750

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 389.61659
Policy Entropy: 3.75291
Value Function Loss: 0.02741

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.17251
Policy Update Magnitude: 0.53279
Value Function Update Magnitude: 0.84697

Collected Steps per Second: 22,127.65460
Overall Steps per Second: 10,575.39298

Timestep Collection Time: 2.26016
Timestep Consumption Time: 2.46893
PPO Batch Consumption Time: 0.29194
Total Iteration Time: 4.72909

Cumulative Model Updates: 193,742
Cumulative Timesteps: 1,615,630,762

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1615630762...
Checkpoint 1615630762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244,969.26110
Policy Entropy: 3.75672
Value Function Loss: 0.03040

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12587
Policy Update Magnitude: 0.53365
Value Function Update Magnitude: 0.82277

Collected Steps per Second: 22,118.95014
Overall Steps per Second: 10,571.57991

Timestep Collection Time: 2.26132
Timestep Consumption Time: 2.47005
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.73136

Cumulative Model Updates: 193,748
Cumulative Timesteps: 1,615,680,780

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,463.62416
Policy Entropy: 3.76901
Value Function Loss: 0.03393

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12383
Policy Update Magnitude: 0.56807
Value Function Update Magnitude: 0.76448

Collected Steps per Second: 22,413.90376
Overall Steps per Second: 10,669.30064

Timestep Collection Time: 2.23129
Timestep Consumption Time: 2.45617
PPO Batch Consumption Time: 0.28592
Total Iteration Time: 4.68747

Cumulative Model Updates: 193,754
Cumulative Timesteps: 1,615,730,792

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1615730792...
Checkpoint 1615730792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 45,110.83724
Policy Entropy: 3.78488
Value Function Loss: 0.03669

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.59884
Value Function Update Magnitude: 0.80201

Collected Steps per Second: 22,228.72590
Overall Steps per Second: 10,416.75385

Timestep Collection Time: 2.25069
Timestep Consumption Time: 2.55215
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.80284

Cumulative Model Updates: 193,760
Cumulative Timesteps: 1,615,780,822

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,084.34368
Policy Entropy: 3.79413
Value Function Loss: 0.03813

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.62296
Value Function Update Magnitude: 0.82083

Collected Steps per Second: 23,141.41682
Overall Steps per Second: 10,873.20094

Timestep Collection Time: 2.16270
Timestep Consumption Time: 2.44017
PPO Batch Consumption Time: 0.28329
Total Iteration Time: 4.60288

Cumulative Model Updates: 193,766
Cumulative Timesteps: 1,615,830,870

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1615830870...
Checkpoint 1615830870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,819.48367
Policy Entropy: 3.78655
Value Function Loss: 0.04873

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.66891
Value Function Update Magnitude: 0.85027

Collected Steps per Second: 22,192.76125
Overall Steps per Second: 10,651.47285

Timestep Collection Time: 2.25353
Timestep Consumption Time: 2.44179
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.69531

Cumulative Model Updates: 193,772
Cumulative Timesteps: 1,615,880,882

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,637.13451
Policy Entropy: 3.83073
Value Function Loss: 0.05059

Mean KL Divergence: 0.01711
SB3 Clip Fraction: 0.19226
Policy Update Magnitude: 0.71652
Value Function Update Magnitude: 0.79000

Collected Steps per Second: 22,822.12854
Overall Steps per Second: 10,903.56316

Timestep Collection Time: 2.19208
Timestep Consumption Time: 2.39614
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.58822

Cumulative Model Updates: 193,778
Cumulative Timesteps: 1,615,930,910

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1615930910...
Checkpoint 1615930910 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,476,209.45058
Policy Entropy: 3.88339
Value Function Loss: 0.06431

Mean KL Divergence: 0.01606
SB3 Clip Fraction: 0.17885
Policy Update Magnitude: 0.62987
Value Function Update Magnitude: 0.67307

Collected Steps per Second: 22,225.08280
Overall Steps per Second: 10,676.18173

Timestep Collection Time: 2.25052
Timestep Consumption Time: 2.43449
PPO Batch Consumption Time: 0.28365
Total Iteration Time: 4.68501

Cumulative Model Updates: 193,784
Cumulative Timesteps: 1,615,980,928

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 41.63926
Policy Entropy: 3.97552
Value Function Loss: 0.06634

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.69896
Value Function Update Magnitude: 0.56568

Collected Steps per Second: 22,701.63321
Overall Steps per Second: 10,898.68059

Timestep Collection Time: 2.20363
Timestep Consumption Time: 2.38647
PPO Batch Consumption Time: 0.28368
Total Iteration Time: 4.59010

Cumulative Model Updates: 193,790
Cumulative Timesteps: 1,616,030,954

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1616030954...
Checkpoint 1616030954 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.45245
Policy Entropy: 3.98712
Value Function Loss: 0.07146

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.13893
Policy Update Magnitude: 0.78539
Value Function Update Magnitude: 0.52631

Collected Steps per Second: 21,365.28657
Overall Steps per Second: 10,629.81347

Timestep Collection Time: 2.34156
Timestep Consumption Time: 2.36483
PPO Batch Consumption Time: 0.27859
Total Iteration Time: 4.70639

Cumulative Model Updates: 193,796
Cumulative Timesteps: 1,616,080,982

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,355.22466
Policy Entropy: 4.00319
Value Function Loss: 0.06855

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.10979
Policy Update Magnitude: 0.73573
Value Function Update Magnitude: 0.55973

Collected Steps per Second: 22,480.60552
Overall Steps per Second: 10,646.90539

Timestep Collection Time: 2.22512
Timestep Consumption Time: 2.47315
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.69827

Cumulative Model Updates: 193,802
Cumulative Timesteps: 1,616,131,004

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1616131004...
Checkpoint 1616131004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42.10541
Policy Entropy: 4.02579
Value Function Loss: 0.06292

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.12120
Policy Update Magnitude: 0.77034
Value Function Update Magnitude: 0.60097

Collected Steps per Second: 22,403.06146
Overall Steps per Second: 10,617.48211

Timestep Collection Time: 2.23193
Timestep Consumption Time: 2.47748
PPO Batch Consumption Time: 0.28970
Total Iteration Time: 4.70940

Cumulative Model Updates: 193,808
Cumulative Timesteps: 1,616,181,006

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 807.01439
Policy Entropy: 4.05592
Value Function Loss: 0.05693

Mean KL Divergence: 0.00803
SB3 Clip Fraction: 0.09469
Policy Update Magnitude: 0.85463
Value Function Update Magnitude: 0.67245

Collected Steps per Second: 22,422.51019
Overall Steps per Second: 10,739.36438

Timestep Collection Time: 2.23186
Timestep Consumption Time: 2.42800
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.65987

Cumulative Model Updates: 193,814
Cumulative Timesteps: 1,616,231,050

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1616231050...
Checkpoint 1616231050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 969.85237
Policy Entropy: 4.07307
Value Function Loss: 0.05628

Mean KL Divergence: 0.00642
SB3 Clip Fraction: 0.07864
Policy Update Magnitude: 1.00584
Value Function Update Magnitude: 0.77356

Collected Steps per Second: 22,481.43250
Overall Steps per Second: 10,677.39823

Timestep Collection Time: 2.22468
Timestep Consumption Time: 2.45942
PPO Batch Consumption Time: 0.28558
Total Iteration Time: 4.68410

Cumulative Model Updates: 193,820
Cumulative Timesteps: 1,616,281,064

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16.06658
Policy Entropy: 4.03711
Value Function Loss: 0.05747

Mean KL Divergence: 0.00628
SB3 Clip Fraction: 0.07279
Policy Update Magnitude: 1.02315
Value Function Update Magnitude: 0.91084

Collected Steps per Second: 22,884.93864
Overall Steps per Second: 10,877.61440

Timestep Collection Time: 2.18607
Timestep Consumption Time: 2.41310
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.59917

Cumulative Model Updates: 193,826
Cumulative Timesteps: 1,616,331,092

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1616331092...
Checkpoint 1616331092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,995.20821
Policy Entropy: 3.96920
Value Function Loss: 0.05863

Mean KL Divergence: 0.00613
SB3 Clip Fraction: 0.07421
Policy Update Magnitude: 0.95104
Value Function Update Magnitude: 0.87072

Collected Steps per Second: 22,752.47942
Overall Steps per Second: 11,026.94841

Timestep Collection Time: 2.19774
Timestep Consumption Time: 2.33697
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.53471

Cumulative Model Updates: 193,832
Cumulative Timesteps: 1,616,381,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 580.17779
Policy Entropy: 3.87600
Value Function Loss: 0.05573

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.11680
Policy Update Magnitude: 0.82803
Value Function Update Magnitude: 0.76768

Collected Steps per Second: 22,320.18571
Overall Steps per Second: 10,909.85790

Timestep Collection Time: 2.24138
Timestep Consumption Time: 2.34420
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.58558

Cumulative Model Updates: 193,838
Cumulative Timesteps: 1,616,431,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1616431124...
Checkpoint 1616431124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472.42760
Policy Entropy: 3.86901
Value Function Loss: 0.05011

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12128
Policy Update Magnitude: 0.72483
Value Function Update Magnitude: 0.74297

Collected Steps per Second: 21,463.28973
Overall Steps per Second: 10,695.83638

Timestep Collection Time: 2.33068
Timestep Consumption Time: 2.34628
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.67696

Cumulative Model Updates: 193,844
Cumulative Timesteps: 1,616,481,148

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,787.72768
Policy Entropy: 3.86691
Value Function Loss: 0.05567

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.10677
Policy Update Magnitude: 0.68769
Value Function Update Magnitude: 0.68825

Collected Steps per Second: 21,838.52796
Overall Steps per Second: 10,655.26719

Timestep Collection Time: 2.29054
Timestep Consumption Time: 2.40404
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.69458

Cumulative Model Updates: 193,850
Cumulative Timesteps: 1,616,531,170

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1616531170...
Checkpoint 1616531170 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 228.45711
Policy Entropy: 3.90326
Value Function Loss: 0.05220

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.69853
Value Function Update Magnitude: 0.69137

Collected Steps per Second: 21,702.45076
Overall Steps per Second: 10,622.04209

Timestep Collection Time: 2.30610
Timestep Consumption Time: 2.40561
PPO Batch Consumption Time: 0.29076
Total Iteration Time: 4.71171

Cumulative Model Updates: 193,856
Cumulative Timesteps: 1,616,581,218

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,214.08488
Policy Entropy: 3.87759
Value Function Loss: 0.05168

Mean KL Divergence: 0.00898
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.67011
Value Function Update Magnitude: 0.68423

Collected Steps per Second: 22,085.21146
Overall Steps per Second: 10,854.77113

Timestep Collection Time: 2.26505
Timestep Consumption Time: 2.34344
PPO Batch Consumption Time: 0.27649
Total Iteration Time: 4.60848

Cumulative Model Updates: 193,862
Cumulative Timesteps: 1,616,631,242

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1616631242...
Checkpoint 1616631242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,723.39006
Policy Entropy: 3.86580
Value Function Loss: 0.04067

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.59510
Value Function Update Magnitude: 0.66749

Collected Steps per Second: 21,644.83801
Overall Steps per Second: 10,557.62565

Timestep Collection Time: 2.31020
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.29286
Total Iteration Time: 4.73629

Cumulative Model Updates: 193,868
Cumulative Timesteps: 1,616,681,246

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 242.88367
Policy Entropy: 3.81611
Value Function Loss: 0.03911

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.48983
Value Function Update Magnitude: 0.58629

Collected Steps per Second: 20,750.07975
Overall Steps per Second: 10,528.61138

Timestep Collection Time: 2.41088
Timestep Consumption Time: 2.34055
PPO Batch Consumption Time: 0.27612
Total Iteration Time: 4.75143

Cumulative Model Updates: 193,874
Cumulative Timesteps: 1,616,731,272

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1616731272...
Checkpoint 1616731272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,553.38749
Policy Entropy: 3.79939
Value Function Loss: 0.03417

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.43658
Value Function Update Magnitude: 0.59321

Collected Steps per Second: 21,635.39634
Overall Steps per Second: 10,611.50888

Timestep Collection Time: 2.31195
Timestep Consumption Time: 2.40180
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.71375

Cumulative Model Updates: 193,880
Cumulative Timesteps: 1,616,781,292

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,274.26757
Policy Entropy: 3.79501
Value Function Loss: 0.03419

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.13970
Policy Update Magnitude: 0.40188
Value Function Update Magnitude: 0.65605

Collected Steps per Second: 21,916.26221
Overall Steps per Second: 10,793.94069

Timestep Collection Time: 2.28251
Timestep Consumption Time: 2.35195
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.63445

Cumulative Model Updates: 193,886
Cumulative Timesteps: 1,616,831,316

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1616831316...
Checkpoint 1616831316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,036.03524
Policy Entropy: 3.79686
Value Function Loss: 0.03120

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.48393
Value Function Update Magnitude: 0.62391

Collected Steps per Second: 21,861.24781
Overall Steps per Second: 10,486.95185

Timestep Collection Time: 2.28816
Timestep Consumption Time: 2.48177
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.76993

Cumulative Model Updates: 193,892
Cumulative Timesteps: 1,616,881,338

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165.56007
Policy Entropy: 3.79212
Value Function Loss: 0.02896

Mean KL Divergence: 0.01856
SB3 Clip Fraction: 0.22268
Policy Update Magnitude: 0.44277
Value Function Update Magnitude: 0.62265

Collected Steps per Second: 23,115.02324
Overall Steps per Second: 10,769.46666

Timestep Collection Time: 2.16353
Timestep Consumption Time: 2.48016
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.64368

Cumulative Model Updates: 193,898
Cumulative Timesteps: 1,616,931,348

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1616931348...
Checkpoint 1616931348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137.41070
Policy Entropy: 3.79254
Value Function Loss: 0.02844

Mean KL Divergence: 0.01650
SB3 Clip Fraction: 0.19867
Policy Update Magnitude: 0.43459
Value Function Update Magnitude: 0.59735

Collected Steps per Second: 22,480.70620
Overall Steps per Second: 10,680.76717

Timestep Collection Time: 2.22520
Timestep Consumption Time: 2.45836
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.68356

Cumulative Model Updates: 193,904
Cumulative Timesteps: 1,616,981,372

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.41070
Policy Entropy: 3.79022
Value Function Loss: 0.03276

Mean KL Divergence: 0.01393
SB3 Clip Fraction: 0.17260
Policy Update Magnitude: 0.59387
Value Function Update Magnitude: 0.56290

Collected Steps per Second: 22,698.40596
Overall Steps per Second: 10,759.05401

Timestep Collection Time: 2.20386
Timestep Consumption Time: 2.44562
PPO Batch Consumption Time: 0.27900
Total Iteration Time: 4.64948

Cumulative Model Updates: 193,910
Cumulative Timesteps: 1,617,031,396

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1617031396...
Checkpoint 1617031396 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 48,529.59184
Policy Entropy: 3.78078
Value Function Loss: 0.03580

Mean KL Divergence: 0.01638
SB3 Clip Fraction: 0.19610
Policy Update Magnitude: 0.67563
Value Function Update Magnitude: 0.53587

Collected Steps per Second: 22,463.98709
Overall Steps per Second: 10,662.17540

Timestep Collection Time: 2.22676
Timestep Consumption Time: 2.46477
PPO Batch Consumption Time: 0.28371
Total Iteration Time: 4.69154

Cumulative Model Updates: 193,916
Cumulative Timesteps: 1,617,081,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,921.30864
Policy Entropy: 3.75092
Value Function Loss: 0.03278

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.74505
Value Function Update Magnitude: 0.54021

Collected Steps per Second: 22,775.81588
Overall Steps per Second: 10,847.08418

Timestep Collection Time: 2.19575
Timestep Consumption Time: 2.41471
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.61046

Cumulative Model Updates: 193,922
Cumulative Timesteps: 1,617,131,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1617131428...
Checkpoint 1617131428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,442.50465
Policy Entropy: 3.72153
Value Function Loss: 0.02849

Mean KL Divergence: 0.00741
SB3 Clip Fraction: 0.09570
Policy Update Magnitude: 0.68819
Value Function Update Magnitude: 0.56064

Collected Steps per Second: 22,361.71930
Overall Steps per Second: 10,725.07089

Timestep Collection Time: 2.23659
Timestep Consumption Time: 2.42669
PPO Batch Consumption Time: 0.27723
Total Iteration Time: 4.66328

Cumulative Model Updates: 193,928
Cumulative Timesteps: 1,617,181,442

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,085.01063
Policy Entropy: 3.72589
Value Function Loss: 0.02499

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07224
Policy Update Magnitude: 0.58663
Value Function Update Magnitude: 0.59236

Collected Steps per Second: 22,363.80561
Overall Steps per Second: 10,588.94576

Timestep Collection Time: 2.23683
Timestep Consumption Time: 2.48734
PPO Batch Consumption Time: 0.28979
Total Iteration Time: 4.72417

Cumulative Model Updates: 193,934
Cumulative Timesteps: 1,617,231,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1617231466...
Checkpoint 1617231466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,313.97910
Policy Entropy: 3.73218
Value Function Loss: 0.02429

Mean KL Divergence: 0.00592
SB3 Clip Fraction: 0.06992
Policy Update Magnitude: 0.57095
Value Function Update Magnitude: 0.62255

Collected Steps per Second: 21,786.67927
Overall Steps per Second: 10,491.70845

Timestep Collection Time: 2.29645
Timestep Consumption Time: 2.47227
PPO Batch Consumption Time: 0.28581
Total Iteration Time: 4.76872

Cumulative Model Updates: 193,940
Cumulative Timesteps: 1,617,281,498

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,313.97910
Policy Entropy: 3.74056
Value Function Loss: 0.02076

Mean KL Divergence: 0.00546
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.54332
Value Function Update Magnitude: 0.52771

Collected Steps per Second: 22,136.81361
Overall Steps per Second: 10,499.24226

Timestep Collection Time: 2.25986
Timestep Consumption Time: 2.50487
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.76472

Cumulative Model Updates: 193,946
Cumulative Timesteps: 1,617,331,524

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1617331524...
Checkpoint 1617331524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,313.97910
Policy Entropy: 3.73815
Value Function Loss: 0.01686

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06529
Policy Update Magnitude: 0.47798
Value Function Update Magnitude: 0.41393

Collected Steps per Second: 22,319.22842
Overall Steps per Second: 10,642.67388

Timestep Collection Time: 2.24112
Timestep Consumption Time: 2.45883
PPO Batch Consumption Time: 0.28604
Total Iteration Time: 4.69995

Cumulative Model Updates: 193,952
Cumulative Timesteps: 1,617,381,544

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,313.97910
Policy Entropy: 3.74371
Value Function Loss: 0.01362

Mean KL Divergence: 0.00522
SB3 Clip Fraction: 0.06081
Policy Update Magnitude: 0.41688
Value Function Update Magnitude: 0.35375

Collected Steps per Second: 23,276.64218
Overall Steps per Second: 10,816.64549

Timestep Collection Time: 2.14825
Timestep Consumption Time: 2.47463
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.62288

Cumulative Model Updates: 193,958
Cumulative Timesteps: 1,617,431,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1617431548...
Checkpoint 1617431548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,313.97910
Policy Entropy: 3.73693
Value Function Loss: 0.01337

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05043
Policy Update Magnitude: 0.39296
Value Function Update Magnitude: 0.30053

Collected Steps per Second: 21,872.98390
Overall Steps per Second: 10,697.26958

Timestep Collection Time: 2.28675
Timestep Consumption Time: 2.38902
PPO Batch Consumption Time: 0.28358
Total Iteration Time: 4.67577

Cumulative Model Updates: 193,964
Cumulative Timesteps: 1,617,481,566

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,313.97910
Policy Entropy: 3.72918
Value Function Loss: 0.01506

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04368
Policy Update Magnitude: 0.42444
Value Function Update Magnitude: 0.35260

Collected Steps per Second: 22,384.93937
Overall Steps per Second: 10,905.58476

Timestep Collection Time: 2.23570
Timestep Consumption Time: 2.35333
PPO Batch Consumption Time: 0.27896
Total Iteration Time: 4.58902

Cumulative Model Updates: 193,970
Cumulative Timesteps: 1,617,531,612

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1617531612...
Checkpoint 1617531612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,506.52154
Policy Entropy: 3.74122
Value Function Loss: 0.01510

Mean KL Divergence: 0.00435
SB3 Clip Fraction: 0.04683
Policy Update Magnitude: 0.44223
Value Function Update Magnitude: 0.46092

Collected Steps per Second: 21,953.74171
Overall Steps per Second: 10,673.84071

Timestep Collection Time: 2.27879
Timestep Consumption Time: 2.40818
PPO Batch Consumption Time: 0.28071
Total Iteration Time: 4.68697

Cumulative Model Updates: 193,976
Cumulative Timesteps: 1,617,581,640

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,448.66677
Policy Entropy: 3.74440
Value Function Loss: 0.01420

Mean KL Divergence: 0.00432
SB3 Clip Fraction: 0.04498
Policy Update Magnitude: 0.41426
Value Function Update Magnitude: 0.47702

Collected Steps per Second: 22,961.76779
Overall Steps per Second: 10,947.53793

Timestep Collection Time: 2.17814
Timestep Consumption Time: 2.39037
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.56852

Cumulative Model Updates: 193,982
Cumulative Timesteps: 1,617,631,654

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1617631654...
Checkpoint 1617631654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.38738
Policy Entropy: 3.76200
Value Function Loss: 0.01389

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03903
Policy Update Magnitude: 0.37140
Value Function Update Magnitude: 0.44229

Collected Steps per Second: 22,688.67307
Overall Steps per Second: 10,701.04577

Timestep Collection Time: 2.20498
Timestep Consumption Time: 2.47008
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.67506

Cumulative Model Updates: 193,988
Cumulative Timesteps: 1,617,681,682

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.38738
Policy Entropy: 3.74602
Value Function Loss: 0.01354

Mean KL Divergence: 0.00378
SB3 Clip Fraction: 0.03873
Policy Update Magnitude: 0.37920
Value Function Update Magnitude: 0.45544

Collected Steps per Second: 22,591.58488
Overall Steps per Second: 10,772.99965

Timestep Collection Time: 2.21454
Timestep Consumption Time: 2.42948
PPO Batch Consumption Time: 0.27681
Total Iteration Time: 4.64402

Cumulative Model Updates: 193,994
Cumulative Timesteps: 1,617,731,712

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1617731712...
Checkpoint 1617731712 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.38738
Policy Entropy: 3.74464
Value Function Loss: 0.01313

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05477
Policy Update Magnitude: 0.39648
Value Function Update Magnitude: 0.41928

Collected Steps per Second: 22,018.05005
Overall Steps per Second: 10,637.24975

Timestep Collection Time: 2.27132
Timestep Consumption Time: 2.43008
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.70140

Cumulative Model Updates: 194,000
Cumulative Timesteps: 1,617,781,722

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.38738
Policy Entropy: 3.72890
Value Function Loss: 0.01208

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05163
Policy Update Magnitude: 0.41112
Value Function Update Magnitude: 0.40926

Collected Steps per Second: 22,538.12881
Overall Steps per Second: 10,603.58477

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.49722
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.71595

Cumulative Model Updates: 194,006
Cumulative Timesteps: 1,617,831,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1617831728...
Checkpoint 1617831728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.38738
Policy Entropy: 3.72333
Value Function Loss: 0.01182

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.08926
Policy Update Magnitude: 0.38476
Value Function Update Magnitude: 0.40373

Collected Steps per Second: 22,274.49291
Overall Steps per Second: 10,511.49100

Timestep Collection Time: 2.24562
Timestep Consumption Time: 2.51298
PPO Batch Consumption Time: 0.29083
Total Iteration Time: 4.75860

Cumulative Model Updates: 194,012
Cumulative Timesteps: 1,617,881,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.38738
Policy Entropy: 3.70646
Value Function Loss: 0.01455

Mean KL Divergence: 0.01327
SB3 Clip Fraction: 0.17031
Policy Update Magnitude: 0.34853
Value Function Update Magnitude: 0.42505

Collected Steps per Second: 22,908.98051
Overall Steps per Second: 10,688.98710

Timestep Collection Time: 2.18255
Timestep Consumption Time: 2.49516
PPO Batch Consumption Time: 0.28639
Total Iteration Time: 4.67771

Cumulative Model Updates: 194,018
Cumulative Timesteps: 1,617,931,748

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1617931748...
Checkpoint 1617931748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.38738
Policy Entropy: 3.69488
Value Function Loss: 0.01645

Mean KL Divergence: 0.01517
SB3 Clip Fraction: 0.18024
Policy Update Magnitude: 0.43401
Value Function Update Magnitude: 0.43785

Collected Steps per Second: 22,644.66278
Overall Steps per Second: 10,793.73098

Timestep Collection Time: 2.20838
Timestep Consumption Time: 2.42468
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.63306

Cumulative Model Updates: 194,024
Cumulative Timesteps: 1,617,981,756

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,012.38738
Policy Entropy: 3.66788
Value Function Loss: 0.02580

Mean KL Divergence: 0.02720
SB3 Clip Fraction: 0.28198
Policy Update Magnitude: 0.41489
Value Function Update Magnitude: 0.34882

Collected Steps per Second: 22,505.87718
Overall Steps per Second: 10,504.37615

Timestep Collection Time: 2.22271
Timestep Consumption Time: 2.53950
PPO Batch Consumption Time: 0.29265
Total Iteration Time: 4.76221

Cumulative Model Updates: 194,030
Cumulative Timesteps: 1,618,031,780

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1618031780...
Checkpoint 1618031780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,067.49214
Policy Entropy: 3.66171
Value Function Loss: 0.05972

Mean KL Divergence: 0.02281
SB3 Clip Fraction: 0.24675
Policy Update Magnitude: 0.47674
Value Function Update Magnitude: 0.34524

Collected Steps per Second: 22,392.85004
Overall Steps per Second: 10,674.99296

Timestep Collection Time: 2.23428
Timestep Consumption Time: 2.45256
PPO Batch Consumption Time: 0.28303
Total Iteration Time: 4.68684

Cumulative Model Updates: 194,036
Cumulative Timesteps: 1,618,081,812

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 88,501.20814
Policy Entropy: 3.67248
Value Function Loss: 0.08269

Mean KL Divergence: 0.02198
SB3 Clip Fraction: 0.23719
Policy Update Magnitude: 0.56292
Value Function Update Magnitude: 0.36253

Collected Steps per Second: 22,532.86264
Overall Steps per Second: 10,823.75582

Timestep Collection Time: 2.21934
Timestep Consumption Time: 2.40087
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.62021

Cumulative Model Updates: 194,042
Cumulative Timesteps: 1,618,131,820

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1618131820...
Checkpoint 1618131820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 974.15002
Policy Entropy: 3.74717
Value Function Loss: 0.08971

Mean KL Divergence: 0.01648
SB3 Clip Fraction: 0.18418
Policy Update Magnitude: 0.61640
Value Function Update Magnitude: 0.42490

Collected Steps per Second: 22,640.82659
Overall Steps per Second: 10,695.19836

Timestep Collection Time: 2.21052
Timestep Consumption Time: 2.46896
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.67948

Cumulative Model Updates: 194,048
Cumulative Timesteps: 1,618,181,868

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159,535.30464
Policy Entropy: 3.81174
Value Function Loss: 0.08655

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.14339
Policy Update Magnitude: 0.61473
Value Function Update Magnitude: 0.54436

Collected Steps per Second: 22,026.21158
Overall Steps per Second: 10,537.23535

Timestep Collection Time: 2.27129
Timestep Consumption Time: 2.47644
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.74773

Cumulative Model Updates: 194,054
Cumulative Timesteps: 1,618,231,896

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1618231896...
Checkpoint 1618231896 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 835.61484
Policy Entropy: 3.86218
Value Function Loss: 0.07607

Mean KL Divergence: 0.01209
SB3 Clip Fraction: 0.13667
Policy Update Magnitude: 0.67409
Value Function Update Magnitude: 0.60357

Collected Steps per Second: 21,859.51662
Overall Steps per Second: 10,564.97618

Timestep Collection Time: 2.28852
Timestep Consumption Time: 2.44656
PPO Batch Consumption Time: 0.28549
Total Iteration Time: 4.73508

Cumulative Model Updates: 194,060
Cumulative Timesteps: 1,618,281,922

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,160.00682
Policy Entropy: 3.87625
Value Function Loss: 0.07221

Mean KL Divergence: 0.01264
SB3 Clip Fraction: 0.14435
Policy Update Magnitude: 0.69171
Value Function Update Magnitude: 0.62817

Collected Steps per Second: 22,650.57268
Overall Steps per Second: 10,935.85924

Timestep Collection Time: 2.20771
Timestep Consumption Time: 2.36495
PPO Batch Consumption Time: 0.28175
Total Iteration Time: 4.57266

Cumulative Model Updates: 194,066
Cumulative Timesteps: 1,618,331,928

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1618331928...
Checkpoint 1618331928 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 167.50906
Policy Entropy: 3.92019
Value Function Loss: 0.06667

Mean KL Divergence: 0.01196
SB3 Clip Fraction: 0.13387
Policy Update Magnitude: 0.66760
Value Function Update Magnitude: 0.69845

Collected Steps per Second: 21,550.62343
Overall Steps per Second: 10,637.47927

Timestep Collection Time: 2.32021
Timestep Consumption Time: 2.38034
PPO Batch Consumption Time: 0.28599
Total Iteration Time: 4.70055

Cumulative Model Updates: 194,072
Cumulative Timesteps: 1,618,381,930

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,050.47589
Policy Entropy: 3.91699
Value Function Loss: 0.06020

Mean KL Divergence: 0.01184
SB3 Clip Fraction: 0.13689
Policy Update Magnitude: 0.63183
Value Function Update Magnitude: 0.72349

Collected Steps per Second: 23,027.88680
Overall Steps per Second: 10,803.30556

Timestep Collection Time: 2.17258
Timestep Consumption Time: 2.45841
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.63099

Cumulative Model Updates: 194,078
Cumulative Timesteps: 1,618,431,960

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1618431960...
Checkpoint 1618431960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 598.44316
Policy Entropy: 3.90235
Value Function Loss: 0.06402

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.12370
Policy Update Magnitude: 0.60722
Value Function Update Magnitude: 0.71779

Collected Steps per Second: 22,598.55967
Overall Steps per Second: 10,707.63603

Timestep Collection Time: 2.21342
Timestep Consumption Time: 2.45802
PPO Batch Consumption Time: 0.28493
Total Iteration Time: 4.67143

Cumulative Model Updates: 194,084
Cumulative Timesteps: 1,618,481,980

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137.15874
Policy Entropy: 3.90922
Value Function Loss: 0.06372

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.12081
Policy Update Magnitude: 0.62563
Value Function Update Magnitude: 0.65115

Collected Steps per Second: 22,583.65766
Overall Steps per Second: 10,662.54881

Timestep Collection Time: 2.21496
Timestep Consumption Time: 2.47641
PPO Batch Consumption Time: 0.28854
Total Iteration Time: 4.69137

Cumulative Model Updates: 194,090
Cumulative Timesteps: 1,618,532,002

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1618532002...
Checkpoint 1618532002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,910.39714
Policy Entropy: 3.92514
Value Function Loss: 0.06294

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.11862
Policy Update Magnitude: 0.67402
Value Function Update Magnitude: 0.69956

Collected Steps per Second: 22,410.60411
Overall Steps per Second: 10,641.50806

Timestep Collection Time: 2.23198
Timestep Consumption Time: 2.46848
PPO Batch Consumption Time: 0.28784
Total Iteration Time: 4.70046

Cumulative Model Updates: 194,096
Cumulative Timesteps: 1,618,582,022

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,694.07908
Policy Entropy: 3.97151
Value Function Loss: 0.05585

Mean KL Divergence: 0.01049
SB3 Clip Fraction: 0.11932
Policy Update Magnitude: 0.72875
Value Function Update Magnitude: 0.87905

Collected Steps per Second: 22,574.15678
Overall Steps per Second: 10,644.87461

Timestep Collection Time: 2.21652
Timestep Consumption Time: 2.48396
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.70048

Cumulative Model Updates: 194,102
Cumulative Timesteps: 1,618,632,058

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1618632058...
Checkpoint 1618632058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,748.61435
Policy Entropy: 4.00775
Value Function Loss: 0.05249

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.83920
Value Function Update Magnitude: 0.79375

Collected Steps per Second: 22,488.59078
Overall Steps per Second: 10,720.40914

Timestep Collection Time: 2.22379
Timestep Consumption Time: 2.44114
PPO Batch Consumption Time: 0.28551
Total Iteration Time: 4.66493

Cumulative Model Updates: 194,108
Cumulative Timesteps: 1,618,682,068

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 604.29718
Policy Entropy: 4.05259
Value Function Loss: 0.04679

Mean KL Divergence: 0.00758
SB3 Clip Fraction: 0.09249
Policy Update Magnitude: 0.86968
Value Function Update Magnitude: 0.85859

Collected Steps per Second: 22,538.12288
Overall Steps per Second: 10,928.70478

Timestep Collection Time: 2.21900
Timestep Consumption Time: 2.35721
PPO Batch Consumption Time: 0.28100
Total Iteration Time: 4.57621

Cumulative Model Updates: 194,114
Cumulative Timesteps: 1,618,732,080

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1618732080...
Checkpoint 1618732080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52.75861
Policy Entropy: 4.07780
Value Function Loss: 0.04147

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07299
Policy Update Magnitude: 0.99489
Value Function Update Magnitude: 0.84208

Collected Steps per Second: 21,944.17378
Overall Steps per Second: 10,653.45840

Timestep Collection Time: 2.27960
Timestep Consumption Time: 2.41596
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.69556

Cumulative Model Updates: 194,120
Cumulative Timesteps: 1,618,782,104

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 314.98628
Policy Entropy: 4.05754
Value Function Loss: 0.04172

Mean KL Divergence: 0.00595
SB3 Clip Fraction: 0.07411
Policy Update Magnitude: 1.03698
Value Function Update Magnitude: 0.80380

Collected Steps per Second: 22,378.67251
Overall Steps per Second: 10,751.39400

Timestep Collection Time: 2.23534
Timestep Consumption Time: 2.41745
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.65279

Cumulative Model Updates: 194,126
Cumulative Timesteps: 1,618,832,128

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1618832128...
Checkpoint 1618832128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.80078
Policy Entropy: 4.01664
Value Function Loss: 0.04365

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06600
Policy Update Magnitude: 0.98047
Value Function Update Magnitude: 0.78411

Collected Steps per Second: 21,972.29864
Overall Steps per Second: 10,656.75144

Timestep Collection Time: 2.27678
Timestep Consumption Time: 2.41753
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.69430

Cumulative Model Updates: 194,132
Cumulative Timesteps: 1,618,882,154

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 144.58989
Policy Entropy: 3.95488
Value Function Loss: 0.04541

Mean KL Divergence: 0.00538
SB3 Clip Fraction: 0.06515
Policy Update Magnitude: 0.91647
Value Function Update Magnitude: 0.69028

Collected Steps per Second: 22,392.22967
Overall Steps per Second: 10,537.59054

Timestep Collection Time: 2.23327
Timestep Consumption Time: 2.51240
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.74568

Cumulative Model Updates: 194,138
Cumulative Timesteps: 1,618,932,162

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1618932162...
Checkpoint 1618932162 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,892.04503
Policy Entropy: 3.90836
Value Function Loss: 0.04200

Mean KL Divergence: 0.00485
SB3 Clip Fraction: 0.05721
Policy Update Magnitude: 0.84232
Value Function Update Magnitude: 0.66975

Collected Steps per Second: 22,453.22719
Overall Steps per Second: 10,699.08077

Timestep Collection Time: 2.22747
Timestep Consumption Time: 2.44713
PPO Batch Consumption Time: 0.27587
Total Iteration Time: 4.67461

Cumulative Model Updates: 194,144
Cumulative Timesteps: 1,618,982,176

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 676.06545
Policy Entropy: 3.87657
Value Function Loss: 0.03952

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06711
Policy Update Magnitude: 0.74674
Value Function Update Magnitude: 0.67818

Collected Steps per Second: 23,007.63822
Overall Steps per Second: 10,834.67322

Timestep Collection Time: 2.17371
Timestep Consumption Time: 2.44221
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.61592

Cumulative Model Updates: 194,150
Cumulative Timesteps: 1,619,032,188

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1619032188...
Checkpoint 1619032188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20.79436
Policy Entropy: 3.85058
Value Function Loss: 0.03536

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.10881
Policy Update Magnitude: 0.63216
Value Function Update Magnitude: 0.64500

Collected Steps per Second: 22,464.27379
Overall Steps per Second: 10,673.62528

Timestep Collection Time: 2.22620
Timestep Consumption Time: 2.45918
PPO Batch Consumption Time: 0.28301
Total Iteration Time: 4.68538

Cumulative Model Updates: 194,156
Cumulative Timesteps: 1,619,082,198

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4.88216
Policy Entropy: 3.81559
Value Function Loss: 0.03283

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.12895
Policy Update Magnitude: 0.47680
Value Function Update Magnitude: 0.59831

Collected Steps per Second: 23,073.78661
Overall Steps per Second: 10,938.40241

Timestep Collection Time: 2.16731
Timestep Consumption Time: 2.40447
PPO Batch Consumption Time: 0.27658
Total Iteration Time: 4.57178

Cumulative Model Updates: 194,162
Cumulative Timesteps: 1,619,132,206

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1619132206...
Checkpoint 1619132206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,960.70614
Policy Entropy: 3.80037
Value Function Loss: 0.02698

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12750
Policy Update Magnitude: 0.41821
Value Function Update Magnitude: 0.57690

Collected Steps per Second: 22,579.35597
Overall Steps per Second: 10,633.34211

Timestep Collection Time: 2.21494
Timestep Consumption Time: 2.48838
PPO Batch Consumption Time: 0.29137
Total Iteration Time: 4.70332

Cumulative Model Updates: 194,168
Cumulative Timesteps: 1,619,182,218

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 28,956.35673
Policy Entropy: 3.79230
Value Function Loss: 0.02841

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12178
Policy Update Magnitude: 0.36901
Value Function Update Magnitude: 0.61416

Collected Steps per Second: 22,069.17317
Overall Steps per Second: 10,805.67687

Timestep Collection Time: 2.26642
Timestep Consumption Time: 2.36244
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.62886

Cumulative Model Updates: 194,174
Cumulative Timesteps: 1,619,232,236

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1619232236...
Checkpoint 1619232236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 460.81627
Policy Entropy: 3.81354
Value Function Loss: 0.02750

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.36235
Value Function Update Magnitude: 0.57144

Collected Steps per Second: 21,662.97670
Overall Steps per Second: 10,782.11833

Timestep Collection Time: 2.30892
Timestep Consumption Time: 2.33006
PPO Batch Consumption Time: 0.27580
Total Iteration Time: 4.63898

Cumulative Model Updates: 194,180
Cumulative Timesteps: 1,619,282,254

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,728.21109
Policy Entropy: 3.79770
Value Function Loss: 0.02892

Mean KL Divergence: 0.01074
SB3 Clip Fraction: 0.13723
Policy Update Magnitude: 0.34150
Value Function Update Magnitude: 0.57629

Collected Steps per Second: 21,650.25186
Overall Steps per Second: 10,761.37885

Timestep Collection Time: 2.31009
Timestep Consumption Time: 2.33746
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.64755

Cumulative Model Updates: 194,186
Cumulative Timesteps: 1,619,332,268

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1619332268...
Checkpoint 1619332268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,883.95664
Policy Entropy: 3.78868
Value Function Loss: 0.02807

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.35243
Value Function Update Magnitude: 0.61221

Collected Steps per Second: 21,445.87277
Overall Steps per Second: 10,690.66184

Timestep Collection Time: 2.33285
Timestep Consumption Time: 2.34694
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.67979

Cumulative Model Updates: 194,192
Cumulative Timesteps: 1,619,382,298

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 234.98885
Policy Entropy: 3.77328
Value Function Loss: 0.02972

Mean KL Divergence: 0.00859
SB3 Clip Fraction: 0.11667
Policy Update Magnitude: 0.40572
Value Function Update Magnitude: 0.64248

Collected Steps per Second: 21,985.53441
Overall Steps per Second: 10,712.75082

Timestep Collection Time: 2.27550
Timestep Consumption Time: 2.39445
PPO Batch Consumption Time: 0.28661
Total Iteration Time: 4.66995

Cumulative Model Updates: 194,198
Cumulative Timesteps: 1,619,432,326

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1619432326...
Checkpoint 1619432326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,074.92993
Policy Entropy: 3.75794
Value Function Loss: 0.02963

Mean KL Divergence: 0.00886
SB3 Clip Fraction: 0.12077
Policy Update Magnitude: 0.42304
Value Function Update Magnitude: 0.63766

Collected Steps per Second: 21,926.31088
Overall Steps per Second: 10,412.09502

Timestep Collection Time: 2.28119
Timestep Consumption Time: 2.52265
PPO Batch Consumption Time: 0.29228
Total Iteration Time: 4.80384

Cumulative Model Updates: 194,204
Cumulative Timesteps: 1,619,482,344

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,731.32190
Policy Entropy: 3.76426
Value Function Loss: 0.02853

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12863
Policy Update Magnitude: 0.40427
Value Function Update Magnitude: 0.63253

Collected Steps per Second: 22,978.91875
Overall Steps per Second: 10,856.75878

Timestep Collection Time: 2.17704
Timestep Consumption Time: 2.43078
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.60782

Cumulative Model Updates: 194,210
Cumulative Timesteps: 1,619,532,370

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1619532370...
Checkpoint 1619532370 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,506.61868
Policy Entropy: 3.73456
Value Function Loss: 0.02413

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13658
Policy Update Magnitude: 0.38027
Value Function Update Magnitude: 0.61446

Collected Steps per Second: 22,691.23408
Overall Steps per Second: 10,688.62748

Timestep Collection Time: 2.20420
Timestep Consumption Time: 2.47517
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.67937

Cumulative Model Updates: 194,216
Cumulative Timesteps: 1,619,582,386

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,506.61868
Policy Entropy: 3.72641
Value Function Loss: 0.02087

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13784
Policy Update Magnitude: 0.36222
Value Function Update Magnitude: 0.58747

Collected Steps per Second: 22,718.67302
Overall Steps per Second: 10,811.93673

Timestep Collection Time: 2.20251
Timestep Consumption Time: 2.42553
PPO Batch Consumption Time: 0.27815
Total Iteration Time: 4.62803

Cumulative Model Updates: 194,222
Cumulative Timesteps: 1,619,632,424

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1619632424...
Checkpoint 1619632424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,007.85531
Policy Entropy: 3.69868
Value Function Loss: 0.01929

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.32872
Value Function Update Magnitude: 0.53024

Collected Steps per Second: 22,328.44315
Overall Steps per Second: 10,696.79067

Timestep Collection Time: 2.24055
Timestep Consumption Time: 2.43637
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.67692

Cumulative Model Updates: 194,228
Cumulative Timesteps: 1,619,682,452

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,516.28341
Policy Entropy: 3.70472
Value Function Loss: 0.02160

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13367
Policy Update Magnitude: 0.32099
Value Function Update Magnitude: 0.44901

Collected Steps per Second: 22,626.35013
Overall Steps per Second: 10,661.13236

Timestep Collection Time: 2.21079
Timestep Consumption Time: 2.48121
PPO Batch Consumption Time: 0.28871
Total Iteration Time: 4.69200

Cumulative Model Updates: 194,234
Cumulative Timesteps: 1,619,732,474

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1619732474...
Checkpoint 1619732474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,516.28341
Policy Entropy: 3.70367
Value Function Loss: 0.02002

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.34359
Value Function Update Magnitude: 0.44562

Collected Steps per Second: 22,728.33958
Overall Steps per Second: 10,718.56748

Timestep Collection Time: 2.20060
Timestep Consumption Time: 2.46569
PPO Batch Consumption Time: 0.28705
Total Iteration Time: 4.66630

Cumulative Model Updates: 194,240
Cumulative Timesteps: 1,619,782,490

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,516.28341
Policy Entropy: 3.71588
Value Function Loss: 0.01908

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13119
Policy Update Magnitude: 0.35805
Value Function Update Magnitude: 0.46762

Collected Steps per Second: 22,181.13783
Overall Steps per Second: 10,702.69010

Timestep Collection Time: 2.25525
Timestep Consumption Time: 2.41872
PPO Batch Consumption Time: 0.27685
Total Iteration Time: 4.67397

Cumulative Model Updates: 194,246
Cumulative Timesteps: 1,619,832,514

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1619832514...
Checkpoint 1619832514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,516.28341
Policy Entropy: 3.69928
Value Function Loss: 0.01651

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12986
Policy Update Magnitude: 0.34823
Value Function Update Magnitude: 0.45464

Collected Steps per Second: 22,495.81211
Overall Steps per Second: 10,608.37021

Timestep Collection Time: 2.22397
Timestep Consumption Time: 2.49212
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.71609

Cumulative Model Updates: 194,252
Cumulative Timesteps: 1,619,882,544

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 32,516.28341
Policy Entropy: 3.69009
Value Function Loss: 0.01852

Mean KL Divergence: 0.00966
SB3 Clip Fraction: 0.13391
Policy Update Magnitude: 0.33320
Value Function Update Magnitude: 0.50240

Collected Steps per Second: 21,437.53980
Overall Steps per Second: 10,542.62665

Timestep Collection Time: 2.33376
Timestep Consumption Time: 2.41174
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.74550

Cumulative Model Updates: 194,258
Cumulative Timesteps: 1,619,932,574

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1619932574...
Checkpoint 1619932574 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,684.25563
Policy Entropy: 3.68634
Value Function Loss: 0.02079

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13518
Policy Update Magnitude: 0.33820
Value Function Update Magnitude: 0.55220

Collected Steps per Second: 21,778.35081
Overall Steps per Second: 10,623.12575

Timestep Collection Time: 2.29678
Timestep Consumption Time: 2.41182
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.70860

Cumulative Model Updates: 194,264
Cumulative Timesteps: 1,619,982,594

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119,020.70689
Policy Entropy: 3.67790
Value Function Loss: 0.02399

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.35356
Value Function Update Magnitude: 0.53079

Collected Steps per Second: 22,290.94195
Overall Steps per Second: 10,833.08837

Timestep Collection Time: 2.24315
Timestep Consumption Time: 2.37252
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.61567

Cumulative Model Updates: 194,270
Cumulative Timesteps: 1,620,032,596

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1620032596...
Checkpoint 1620032596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,411.52076
Policy Entropy: 3.67712
Value Function Loss: 0.02267

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13043
Policy Update Magnitude: 0.34654
Value Function Update Magnitude: 0.45747

Collected Steps per Second: 22,207.34610
Overall Steps per Second: 10,623.27262

Timestep Collection Time: 2.25268
Timestep Consumption Time: 2.45642
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.70910

Cumulative Model Updates: 194,276
Cumulative Timesteps: 1,620,082,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 96,411.52076
Policy Entropy: 3.68106
Value Function Loss: 0.02044

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.32430
Value Function Update Magnitude: 0.42732

Collected Steps per Second: 22,435.18719
Overall Steps per Second: 10,692.47672

Timestep Collection Time: 2.22927
Timestep Consumption Time: 2.44823
PPO Batch Consumption Time: 0.28698
Total Iteration Time: 4.67749

Cumulative Model Updates: 194,282
Cumulative Timesteps: 1,620,132,636

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1620132636...
Checkpoint 1620132636 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,411.52076
Policy Entropy: 3.68290
Value Function Loss: 0.01883

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.30933
Value Function Update Magnitude: 0.36859

Collected Steps per Second: 22,605.77725
Overall Steps per Second: 10,772.93667

Timestep Collection Time: 2.21271
Timestep Consumption Time: 2.43041
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.64312

Cumulative Model Updates: 194,288
Cumulative Timesteps: 1,620,182,656

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,922.06028
Policy Entropy: 3.69516
Value Function Loss: 0.01989

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12955
Policy Update Magnitude: 0.30908
Value Function Update Magnitude: 0.40800

Collected Steps per Second: 22,810.58528
Overall Steps per Second: 10,650.73278

Timestep Collection Time: 2.19319
Timestep Consumption Time: 2.50395
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.69714

Cumulative Model Updates: 194,294
Cumulative Timesteps: 1,620,232,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1620232684...
Checkpoint 1620232684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.69397
Value Function Loss: 0.02024

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13169
Policy Update Magnitude: 0.33103
Value Function Update Magnitude: 0.48207

Collected Steps per Second: 22,895.21280
Overall Steps per Second: 10,733.15674

Timestep Collection Time: 2.18491
Timestep Consumption Time: 2.47579
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.66070

Cumulative Model Updates: 194,300
Cumulative Timesteps: 1,620,282,708

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.69573
Value Function Loss: 0.02077

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13478
Policy Update Magnitude: 0.35105
Value Function Update Magnitude: 0.50838

Collected Steps per Second: 22,799.73050
Overall Steps per Second: 10,734.77302

Timestep Collection Time: 2.19353
Timestep Consumption Time: 2.46534
PPO Batch Consumption Time: 0.28394
Total Iteration Time: 4.65888

Cumulative Model Updates: 194,306
Cumulative Timesteps: 1,620,332,720

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1620332720...
Checkpoint 1620332720 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.68139
Value Function Loss: 0.01801

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13485
Policy Update Magnitude: 0.34836
Value Function Update Magnitude: 0.48938

Collected Steps per Second: 22,219.71269
Overall Steps per Second: 10,614.22011

Timestep Collection Time: 2.25097
Timestep Consumption Time: 2.46119
PPO Batch Consumption Time: 0.28375
Total Iteration Time: 4.71217

Cumulative Model Updates: 194,312
Cumulative Timesteps: 1,620,382,736

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.68438
Value Function Loss: 0.01567

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12878
Policy Update Magnitude: 0.31649
Value Function Update Magnitude: 0.43183

Collected Steps per Second: 22,390.49886
Overall Steps per Second: 10,615.01674

Timestep Collection Time: 2.23407
Timestep Consumption Time: 2.47831
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.71238

Cumulative Model Updates: 194,318
Cumulative Timesteps: 1,620,432,758

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1620432758...
Checkpoint 1620432758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.66906
Value Function Loss: 0.01625

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12476
Policy Update Magnitude: 0.30926
Value Function Update Magnitude: 0.36714

Collected Steps per Second: 21,711.64865
Overall Steps per Second: 10,589.84752

Timestep Collection Time: 2.30429
Timestep Consumption Time: 2.42004
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.72434

Cumulative Model Updates: 194,324
Cumulative Timesteps: 1,620,482,788

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.67224
Value Function Loss: 0.01884

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12332
Policy Update Magnitude: 0.34544
Value Function Update Magnitude: 0.41930

Collected Steps per Second: 22,121.72796
Overall Steps per Second: 10,868.21176

Timestep Collection Time: 2.26158
Timestep Consumption Time: 2.34176
PPO Batch Consumption Time: 0.27643
Total Iteration Time: 4.60333

Cumulative Model Updates: 194,330
Cumulative Timesteps: 1,620,532,818

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1620532818...
Checkpoint 1620532818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.67786
Value Function Loss: 0.01902

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13552
Policy Update Magnitude: 0.38717
Value Function Update Magnitude: 0.49249

Collected Steps per Second: 21,616.59976
Overall Steps per Second: 10,510.66544

Timestep Collection Time: 2.31378
Timestep Consumption Time: 2.44482
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.75859

Cumulative Model Updates: 194,336
Cumulative Timesteps: 1,620,582,834

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.69109
Value Function Loss: 0.01730

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12976
Policy Update Magnitude: 0.35259
Value Function Update Magnitude: 0.45260

Collected Steps per Second: 22,754.37491
Overall Steps per Second: 10,857.45311

Timestep Collection Time: 2.19799
Timestep Consumption Time: 2.40843
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.60642

Cumulative Model Updates: 194,342
Cumulative Timesteps: 1,620,632,848

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1620632848...
Checkpoint 1620632848 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.70603
Value Function Loss: 0.01447

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12505
Policy Update Magnitude: 0.30496
Value Function Update Magnitude: 0.34086

Collected Steps per Second: 22,689.03133
Overall Steps per Second: 10,733.98448

Timestep Collection Time: 2.20406
Timestep Consumption Time: 2.45479
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.65885

Cumulative Model Updates: 194,348
Cumulative Timesteps: 1,620,682,856

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.67662
Value Function Loss: 0.01558

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12552
Policy Update Magnitude: 0.28076
Value Function Update Magnitude: 0.33164

Collected Steps per Second: 22,925.67238
Overall Steps per Second: 10,856.28409

Timestep Collection Time: 2.18183
Timestep Consumption Time: 2.42564
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.60747

Cumulative Model Updates: 194,354
Cumulative Timesteps: 1,620,732,876

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1620732876...
Checkpoint 1620732876 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,028.21169
Policy Entropy: 3.67955
Value Function Loss: 0.01597

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13003
Policy Update Magnitude: 0.30394
Value Function Update Magnitude: 0.41022

Collected Steps per Second: 22,654.48500
Overall Steps per Second: 10,704.00339

Timestep Collection Time: 2.20804
Timestep Consumption Time: 2.46517
PPO Batch Consumption Time: 0.28274
Total Iteration Time: 4.67320

Cumulative Model Updates: 194,360
Cumulative Timesteps: 1,620,782,898

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,983.13026
Policy Entropy: 3.66265
Value Function Loss: 0.02146

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12590
Policy Update Magnitude: 0.34538
Value Function Update Magnitude: 0.40657

Collected Steps per Second: 22,884.98169
Overall Steps per Second: 10,837.22550

Timestep Collection Time: 2.18589
Timestep Consumption Time: 2.43005
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.61594

Cumulative Model Updates: 194,366
Cumulative Timesteps: 1,620,832,922

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1620832922...
Checkpoint 1620832922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,983.13026
Policy Entropy: 3.69388
Value Function Loss: 0.01955

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.37729
Value Function Update Magnitude: 0.40836

Collected Steps per Second: 22,069.43249
Overall Steps per Second: 10,660.71788

Timestep Collection Time: 2.26612
Timestep Consumption Time: 2.42512
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.69124

Cumulative Model Updates: 194,372
Cumulative Timesteps: 1,620,882,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,983.13026
Policy Entropy: 3.69538
Value Function Loss: 0.01908

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.35863
Value Function Update Magnitude: 0.46208

Collected Steps per Second: 22,603.85774
Overall Steps per Second: 10,654.94096

Timestep Collection Time: 2.21245
Timestep Consumption Time: 2.48114
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.69360

Cumulative Model Updates: 194,378
Cumulative Timesteps: 1,620,932,944

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1620932944...
Checkpoint 1620932944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,983.13026
Policy Entropy: 3.70358
Value Function Loss: 0.01510

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.32429
Value Function Update Magnitude: 0.39317

Collected Steps per Second: 22,494.13036
Overall Steps per Second: 10,599.74065

Timestep Collection Time: 2.22360
Timestep Consumption Time: 2.49519
PPO Batch Consumption Time: 0.29029
Total Iteration Time: 4.71879

Cumulative Model Updates: 194,384
Cumulative Timesteps: 1,620,982,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,983.13026
Policy Entropy: 3.69646
Value Function Loss: 0.01655

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.28739
Value Function Update Magnitude: 0.39721

Collected Steps per Second: 22,126.94018
Overall Steps per Second: 10,546.31884

Timestep Collection Time: 2.26005
Timestep Consumption Time: 2.48170
PPO Batch Consumption Time: 0.28708
Total Iteration Time: 4.74175

Cumulative Model Updates: 194,390
Cumulative Timesteps: 1,621,032,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1621032970...
Checkpoint 1621032970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 300,265.67812
Policy Entropy: 3.70205
Value Function Loss: 0.01854

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13413
Policy Update Magnitude: 0.29770
Value Function Update Magnitude: 0.44265

Collected Steps per Second: 22,674.68244
Overall Steps per Second: 10,803.02127

Timestep Collection Time: 2.20625
Timestep Consumption Time: 2.42449
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.63074

Cumulative Model Updates: 194,396
Cumulative Timesteps: 1,621,082,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,904.60698
Policy Entropy: 3.70900
Value Function Loss: 0.02065

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.32142
Value Function Update Magnitude: 0.50764

Collected Steps per Second: 22,756.82024
Overall Steps per Second: 10,664.85939

Timestep Collection Time: 2.19785
Timestep Consumption Time: 2.49195
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.68979

Cumulative Model Updates: 194,402
Cumulative Timesteps: 1,621,133,012

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1621133012...
Checkpoint 1621133012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,584.23657
Policy Entropy: 3.70691
Value Function Loss: 0.02025

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12701
Policy Update Magnitude: 0.34062
Value Function Update Magnitude: 0.48869

Collected Steps per Second: 22,640.16620
Overall Steps per Second: 10,699.90006

Timestep Collection Time: 2.20926
Timestep Consumption Time: 2.46536
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.67462

Cumulative Model Updates: 194,408
Cumulative Timesteps: 1,621,183,030

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,584.23657
Policy Entropy: 3.70749
Value Function Loss: 0.01859

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12752
Policy Update Magnitude: 0.33678
Value Function Update Magnitude: 0.40839

Collected Steps per Second: 22,353.86842
Overall Steps per Second: 10,715.94711

Timestep Collection Time: 2.23711
Timestep Consumption Time: 2.42958
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.66669

Cumulative Model Updates: 194,414
Cumulative Timesteps: 1,621,233,038

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1621233038...
Checkpoint 1621233038 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,584.23657
Policy Entropy: 3.69704
Value Function Loss: 0.01624

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12322
Policy Update Magnitude: 0.34827
Value Function Update Magnitude: 0.33947

Collected Steps per Second: 22,136.06817
Overall Steps per Second: 10,689.54262

Timestep Collection Time: 2.25921
Timestep Consumption Time: 2.41920
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.67840

Cumulative Model Updates: 194,420
Cumulative Timesteps: 1,621,283,048

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 150,584.23657
Policy Entropy: 3.68677
Value Function Loss: 0.01907

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12821
Policy Update Magnitude: 0.36829
Value Function Update Magnitude: 0.33199

Collected Steps per Second: 21,867.61211
Overall Steps per Second: 10,523.48688

Timestep Collection Time: 2.28740
Timestep Consumption Time: 2.46578
PPO Batch Consumption Time: 0.28988
Total Iteration Time: 4.75318

Cumulative Model Updates: 194,426
Cumulative Timesteps: 1,621,333,068

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1621333068...
Checkpoint 1621333068 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 150,584.23657
Policy Entropy: 3.68259
Value Function Loss: 0.02039

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13531
Policy Update Magnitude: 0.41246
Value Function Update Magnitude: 0.36933

Collected Steps per Second: 22,882.90561
Overall Steps per Second: 10,928.55972

Timestep Collection Time: 2.18504
Timestep Consumption Time: 2.39013
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.57517

Cumulative Model Updates: 194,432
Cumulative Timesteps: 1,621,383,068

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 339,841.23149
Policy Entropy: 3.68560
Value Function Loss: 0.02243

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13168
Policy Update Magnitude: 0.42430
Value Function Update Magnitude: 0.42892

Collected Steps per Second: 22,031.53611
Overall Steps per Second: 10,538.83674

Timestep Collection Time: 2.27065
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.29244
Total Iteration Time: 4.74682

Cumulative Model Updates: 194,438
Cumulative Timesteps: 1,621,433,094

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1621433094...
Checkpoint 1621433094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 351,428.99006
Policy Entropy: 3.69247
Value Function Loss: 0.02132

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12520
Policy Update Magnitude: 0.43666
Value Function Update Magnitude: 0.45673

Collected Steps per Second: 22,499.60217
Overall Steps per Second: 10,606.51030

Timestep Collection Time: 2.22333
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.71635

Cumulative Model Updates: 194,444
Cumulative Timesteps: 1,621,483,118

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,538.29408
Policy Entropy: 3.70643
Value Function Loss: 0.02015

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12795
Policy Update Magnitude: 0.43986
Value Function Update Magnitude: 0.50069

Collected Steps per Second: 22,237.49089
Overall Steps per Second: 10,523.28325

Timestep Collection Time: 2.24890
Timestep Consumption Time: 2.50341
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.75232

Cumulative Model Updates: 194,450
Cumulative Timesteps: 1,621,533,128

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1621533128...
Checkpoint 1621533128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 80,404.53574
Policy Entropy: 3.70783
Value Function Loss: 0.01998

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13278
Policy Update Magnitude: 0.39286
Value Function Update Magnitude: 0.51572

Collected Steps per Second: 22,241.07637
Overall Steps per Second: 10,569.58929

Timestep Collection Time: 2.25061
Timestep Consumption Time: 2.48524
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.73585

Cumulative Model Updates: 194,456
Cumulative Timesteps: 1,621,583,184

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,484.09738
Policy Entropy: 3.70789
Value Function Loss: 0.02133

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.12713
Policy Update Magnitude: 0.36342
Value Function Update Magnitude: 0.47248

Collected Steps per Second: 22,045.03670
Overall Steps per Second: 10,453.90753

Timestep Collection Time: 2.26954
Timestep Consumption Time: 2.51643
PPO Batch Consumption Time: 0.29103
Total Iteration Time: 4.78596

Cumulative Model Updates: 194,462
Cumulative Timesteps: 1,621,633,216

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1621633216...
Checkpoint 1621633216 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,081.21044
Policy Entropy: 3.69739
Value Function Loss: 0.02229

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12831
Policy Update Magnitude: 0.39459
Value Function Update Magnitude: 0.51007

Collected Steps per Second: 22,434.61392
Overall Steps per Second: 10,694.42766

Timestep Collection Time: 2.22995
Timestep Consumption Time: 2.44800
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.67795

Cumulative Model Updates: 194,468
Cumulative Timesteps: 1,621,683,244

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 334,400.41631
Policy Entropy: 3.68704
Value Function Loss: 0.02454

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12706
Policy Update Magnitude: 0.41133
Value Function Update Magnitude: 0.47421

Collected Steps per Second: 22,716.14965
Overall Steps per Second: 10,792.81179

Timestep Collection Time: 2.20161
Timestep Consumption Time: 2.43222
PPO Batch Consumption Time: 0.27798
Total Iteration Time: 4.63382

Cumulative Model Updates: 194,474
Cumulative Timesteps: 1,621,733,256

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1621733256...
Checkpoint 1621733256 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 116,607.27214
Policy Entropy: 3.70724
Value Function Loss: 0.02177

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12660
Policy Update Magnitude: 0.41874
Value Function Update Magnitude: 0.64996

Collected Steps per Second: 22,025.99712
Overall Steps per Second: 10,716.27724

Timestep Collection Time: 2.27059
Timestep Consumption Time: 2.39633
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.66692

Cumulative Model Updates: 194,480
Cumulative Timesteps: 1,621,783,268

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,662.57841
Policy Entropy: 3.72211
Value Function Loss: 0.02189

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12306
Policy Update Magnitude: 0.40781
Value Function Update Magnitude: 0.70245

Collected Steps per Second: 22,133.84715
Overall Steps per Second: 10,842.51220

Timestep Collection Time: 2.25944
Timestep Consumption Time: 2.35296
PPO Batch Consumption Time: 0.27845
Total Iteration Time: 4.61240

Cumulative Model Updates: 194,486
Cumulative Timesteps: 1,621,833,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1621833278...
Checkpoint 1621833278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,613.80613
Policy Entropy: 3.75046
Value Function Loss: 0.01971

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12049
Policy Update Magnitude: 0.38454
Value Function Update Magnitude: 0.60479

Collected Steps per Second: 22,371.94418
Overall Steps per Second: 10,668.86058

Timestep Collection Time: 2.23512
Timestep Consumption Time: 2.45179
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.68691

Cumulative Model Updates: 194,492
Cumulative Timesteps: 1,621,883,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,613.80613
Policy Entropy: 3.74875
Value Function Loss: 0.01601

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12749
Policy Update Magnitude: 0.34089
Value Function Update Magnitude: 0.50949

Collected Steps per Second: 22,485.86518
Overall Steps per Second: 10,824.05347

Timestep Collection Time: 2.22415
Timestep Consumption Time: 2.39630
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.62045

Cumulative Model Updates: 194,498
Cumulative Timesteps: 1,621,933,294

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1621933294...
Checkpoint 1621933294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,613.80613
Policy Entropy: 3.71699
Value Function Loss: 0.01390

Mean KL Divergence: 0.00920
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.29248
Value Function Update Magnitude: 0.36979

Collected Steps per Second: 21,874.13218
Overall Steps per Second: 10,675.63065

Timestep Collection Time: 2.28590
Timestep Consumption Time: 2.39785
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.68375

Cumulative Model Updates: 194,504
Cumulative Timesteps: 1,621,983,296

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,613.80613
Policy Entropy: 3.69662
Value Function Loss: 0.01526

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.12246
Policy Update Magnitude: 0.34680
Value Function Update Magnitude: 0.34125

Collected Steps per Second: 22,602.24683
Overall Steps per Second: 10,649.11655

Timestep Collection Time: 2.21252
Timestep Consumption Time: 2.48345
PPO Batch Consumption Time: 0.28971
Total Iteration Time: 4.69598

Cumulative Model Updates: 194,510
Cumulative Timesteps: 1,622,033,304

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1622033304...
Checkpoint 1622033304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,714.96018
Policy Entropy: 3.67704
Value Function Loss: 0.02022

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12607
Policy Update Magnitude: 0.42963
Value Function Update Magnitude: 0.44550

Collected Steps per Second: 22,502.15201
Overall Steps per Second: 10,601.86115

Timestep Collection Time: 2.22245
Timestep Consumption Time: 2.49464
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.71710

Cumulative Model Updates: 194,516
Cumulative Timesteps: 1,622,083,314

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,330.33252
Policy Entropy: 3.68538
Value Function Loss: 0.02363

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.12876
Policy Update Magnitude: 0.51271
Value Function Update Magnitude: 0.59247

Collected Steps per Second: 22,405.41572
Overall Steps per Second: 10,703.58638

Timestep Collection Time: 2.23214
Timestep Consumption Time: 2.44031
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.67245

Cumulative Model Updates: 194,522
Cumulative Timesteps: 1,622,133,326

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1622133326...
Checkpoint 1622133326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,659.56507
Policy Entropy: 3.69450
Value Function Loss: 0.02365

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12690
Policy Update Magnitude: 0.51361
Value Function Update Magnitude: 0.53363

Collected Steps per Second: 22,397.08272
Overall Steps per Second: 10,697.42916

Timestep Collection Time: 2.23243
Timestep Consumption Time: 2.44159
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.67402

Cumulative Model Updates: 194,528
Cumulative Timesteps: 1,622,183,326

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 548,161.47118
Policy Entropy: 3.72039
Value Function Loss: 0.02491

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.49355
Value Function Update Magnitude: 0.47647

Collected Steps per Second: 22,872.79151
Overall Steps per Second: 10,834.38077

Timestep Collection Time: 2.18644
Timestep Consumption Time: 2.42942
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.61586

Cumulative Model Updates: 194,534
Cumulative Timesteps: 1,622,233,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1622233336...
Checkpoint 1622233336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,720.50526
Policy Entropy: 3.73616
Value Function Loss: 0.02484

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12669
Policy Update Magnitude: 0.46951
Value Function Update Magnitude: 0.57138

Collected Steps per Second: 22,681.69053
Overall Steps per Second: 10,689.52089

Timestep Collection Time: 2.20566
Timestep Consumption Time: 2.47444
PPO Batch Consumption Time: 0.28543
Total Iteration Time: 4.68010

Cumulative Model Updates: 194,540
Cumulative Timesteps: 1,622,283,364

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,017.18763
Policy Entropy: 3.72896
Value Function Loss: 0.02785

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.51501
Value Function Update Magnitude: 0.64726

Collected Steps per Second: 22,854.65289
Overall Steps per Second: 10,861.27269

Timestep Collection Time: 2.18844
Timestep Consumption Time: 2.41655
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.60499

Cumulative Model Updates: 194,546
Cumulative Timesteps: 1,622,333,380

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1622333380...
Checkpoint 1622333380 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,017.18763
Policy Entropy: 3.71005
Value Function Loss: 0.02783

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12639
Policy Update Magnitude: 0.51445
Value Function Update Magnitude: 0.62168

Collected Steps per Second: 22,645.92389
Overall Steps per Second: 10,753.30424

Timestep Collection Time: 2.20870
Timestep Consumption Time: 2.44271
PPO Batch Consumption Time: 0.28322
Total Iteration Time: 4.65141

Cumulative Model Updates: 194,552
Cumulative Timesteps: 1,622,383,398

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,785.60277
Policy Entropy: 3.69922
Value Function Loss: 0.02743

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13446
Policy Update Magnitude: 0.49765
Value Function Update Magnitude: 0.47136

Collected Steps per Second: 22,593.41314
Overall Steps per Second: 10,647.74454

Timestep Collection Time: 2.21312
Timestep Consumption Time: 2.48290
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.69602

Cumulative Model Updates: 194,558
Cumulative Timesteps: 1,622,433,400

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1622433400...
Checkpoint 1622433400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,785.60277
Policy Entropy: 3.69464
Value Function Loss: 0.02491

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12767
Policy Update Magnitude: 0.46600
Value Function Update Magnitude: 0.40008

Collected Steps per Second: 20,632.98834
Overall Steps per Second: 10,323.59865

Timestep Collection Time: 2.42437
Timestep Consumption Time: 2.42103
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.84540

Cumulative Model Updates: 194,564
Cumulative Timesteps: 1,622,483,422

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,785.60277
Policy Entropy: 3.70732
Value Function Loss: 0.02423

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.44692
Value Function Update Magnitude: 0.33511

Collected Steps per Second: 22,165.68102
Overall Steps per Second: 10,564.87023

Timestep Collection Time: 2.25574
Timestep Consumption Time: 2.47693
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.73267

Cumulative Model Updates: 194,570
Cumulative Timesteps: 1,622,533,422

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1622533422...
Checkpoint 1622533422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 241,785.60277
Policy Entropy: 3.71202
Value Function Loss: 0.02076

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12588
Policy Update Magnitude: 0.42153
Value Function Update Magnitude: 0.32482

Collected Steps per Second: 20,573.61232
Overall Steps per Second: 10,233.64218

Timestep Collection Time: 2.43137
Timestep Consumption Time: 2.45663
PPO Batch Consumption Time: 0.29208
Total Iteration Time: 4.88800

Cumulative Model Updates: 194,576
Cumulative Timesteps: 1,622,583,444

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 241,785.60277
Policy Entropy: 3.70346
Value Function Loss: 0.02480

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13280
Policy Update Magnitude: 0.41841
Value Function Update Magnitude: 0.31354

Collected Steps per Second: 20,359.18021
Overall Steps per Second: 10,305.78175

Timestep Collection Time: 2.45599
Timestep Consumption Time: 2.39585
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.85184

Cumulative Model Updates: 194,582
Cumulative Timesteps: 1,622,633,446

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1622633446...
Checkpoint 1622633446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,684.16239
Policy Entropy: 3.70993
Value Function Loss: 0.02384

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12953
Policy Update Magnitude: 0.43956
Value Function Update Magnitude: 0.32629

Collected Steps per Second: 20,353.30658
Overall Steps per Second: 10,292.35731

Timestep Collection Time: 2.45768
Timestep Consumption Time: 2.40243
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.86011

Cumulative Model Updates: 194,588
Cumulative Timesteps: 1,622,683,468

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350,989.92864
Policy Entropy: 3.71095
Value Function Loss: 0.02431

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.42823
Value Function Update Magnitude: 0.38608

Collected Steps per Second: 21,731.62374
Overall Steps per Second: 10,470.88021

Timestep Collection Time: 2.30171
Timestep Consumption Time: 2.47534
PPO Batch Consumption Time: 0.28341
Total Iteration Time: 4.77706

Cumulative Model Updates: 194,594
Cumulative Timesteps: 1,622,733,488

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1622733488...
Checkpoint 1622733488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 350,989.92864
Policy Entropy: 3.74049
Value Function Loss: 0.01740

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12601
Policy Update Magnitude: 0.40264
Value Function Update Magnitude: 0.38617

Collected Steps per Second: 22,628.34257
Overall Steps per Second: 10,672.88651

Timestep Collection Time: 2.21024
Timestep Consumption Time: 2.47584
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.68608

Cumulative Model Updates: 194,600
Cumulative Timesteps: 1,622,783,502

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350,989.92864
Policy Entropy: 3.72991
Value Function Loss: 0.01576

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12566
Policy Update Magnitude: 0.36202
Value Function Update Magnitude: 0.37496

Collected Steps per Second: 22,666.14495
Overall Steps per Second: 10,835.39815

Timestep Collection Time: 2.20682
Timestep Consumption Time: 2.40954
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.61635

Cumulative Model Updates: 194,606
Cumulative Timesteps: 1,622,833,522

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1622833522...
Checkpoint 1622833522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 645,504.90437
Policy Entropy: 3.72263
Value Function Loss: 0.01577

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.39024
Value Function Update Magnitude: 0.47470

Collected Steps per Second: 22,745.89239
Overall Steps per Second: 10,697.98000

Timestep Collection Time: 2.19917
Timestep Consumption Time: 2.47667
PPO Batch Consumption Time: 0.28709
Total Iteration Time: 4.67584

Cumulative Model Updates: 194,612
Cumulative Timesteps: 1,622,883,544

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,524.62338
Policy Entropy: 3.70959
Value Function Loss: 0.01856

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12765
Policy Update Magnitude: 0.42213
Value Function Update Magnitude: 0.58124

Collected Steps per Second: 22,663.39209
Overall Steps per Second: 10,819.80938

Timestep Collection Time: 2.20735
Timestep Consumption Time: 2.41621
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.62356

Cumulative Model Updates: 194,618
Cumulative Timesteps: 1,622,933,570

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1622933570...
Checkpoint 1622933570 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,524.62338
Policy Entropy: 3.71321
Value Function Loss: 0.01965

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.44666
Value Function Update Magnitude: 0.56369

Collected Steps per Second: 22,801.64498
Overall Steps per Second: 10,731.46496

Timestep Collection Time: 2.19318
Timestep Consumption Time: 2.46677
PPO Batch Consumption Time: 0.28409
Total Iteration Time: 4.65994

Cumulative Model Updates: 194,624
Cumulative Timesteps: 1,622,983,578

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 423,524.62338
Policy Entropy: 3.70357
Value Function Loss: 0.02157

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12522
Policy Update Magnitude: 0.48827
Value Function Update Magnitude: 0.55712

Collected Steps per Second: 22,394.48774
Overall Steps per Second: 10,580.86861

Timestep Collection Time: 2.23287
Timestep Consumption Time: 2.49302
PPO Batch Consumption Time: 0.29072
Total Iteration Time: 4.72589

Cumulative Model Updates: 194,630
Cumulative Timesteps: 1,623,033,582

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1623033582...
Checkpoint 1623033582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 423,524.62338
Policy Entropy: 3.68620
Value Function Loss: 0.02012

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.51313
Value Function Update Magnitude: 0.56983

Collected Steps per Second: 22,412.01796
Overall Steps per Second: 10,588.94589

Timestep Collection Time: 2.23255
Timestep Consumption Time: 2.49275
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.72531

Cumulative Model Updates: 194,636
Cumulative Timesteps: 1,623,083,618

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.69612
Value Function Loss: 0.02398

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.50168
Value Function Update Magnitude: 0.50778

Collected Steps per Second: 22,340.99505
Overall Steps per Second: 10,583.07182

Timestep Collection Time: 2.23893
Timestep Consumption Time: 2.48748
PPO Batch Consumption Time: 0.28691
Total Iteration Time: 4.72642

Cumulative Model Updates: 194,642
Cumulative Timesteps: 1,623,133,638

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1623133638...
Checkpoint 1623133638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.69573
Value Function Loss: 0.02305

Mean KL Divergence: 0.01265
SB3 Clip Fraction: 0.15893
Policy Update Magnitude: 0.50181
Value Function Update Magnitude: 0.46580

Collected Steps per Second: 22,317.62836
Overall Steps per Second: 10,604.82244

Timestep Collection Time: 2.24083
Timestep Consumption Time: 2.47495
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.71578

Cumulative Model Updates: 194,648
Cumulative Timesteps: 1,623,183,648

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.70646
Value Function Loss: 0.02255

Mean KL Divergence: 0.01282
SB3 Clip Fraction: 0.16287
Policy Update Magnitude: 0.48772
Value Function Update Magnitude: 0.47556

Collected Steps per Second: 22,839.04463
Overall Steps per Second: 10,719.56368

Timestep Collection Time: 2.19046
Timestep Consumption Time: 2.47652
PPO Batch Consumption Time: 0.27877
Total Iteration Time: 4.66698

Cumulative Model Updates: 194,654
Cumulative Timesteps: 1,623,233,676

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1623233676...
Checkpoint 1623233676 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.70241
Value Function Loss: 0.02208

Mean KL Divergence: 0.01777
SB3 Clip Fraction: 0.21504
Policy Update Magnitude: 0.42948
Value Function Update Magnitude: 0.44988

Collected Steps per Second: 22,998.35833
Overall Steps per Second: 10,699.95999

Timestep Collection Time: 2.17529
Timestep Consumption Time: 2.50025
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.67553

Cumulative Model Updates: 194,660
Cumulative Timesteps: 1,623,283,704

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.72057
Value Function Loss: 0.01924

Mean KL Divergence: 0.01508
SB3 Clip Fraction: 0.19005
Policy Update Magnitude: 0.45025
Value Function Update Magnitude: 0.36975

Collected Steps per Second: 22,327.39417
Overall Steps per Second: 10,922.89674

Timestep Collection Time: 2.23940
Timestep Consumption Time: 2.33814
PPO Batch Consumption Time: 0.27665
Total Iteration Time: 4.57754

Cumulative Model Updates: 194,666
Cumulative Timesteps: 1,623,333,704

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1623333704...
Checkpoint 1623333704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.72043
Value Function Loss: 0.01858

Mean KL Divergence: 0.01023
SB3 Clip Fraction: 0.13601
Policy Update Magnitude: 0.43865
Value Function Update Magnitude: 0.29252

Collected Steps per Second: 22,155.07864
Overall Steps per Second: 10,707.88777

Timestep Collection Time: 2.25844
Timestep Consumption Time: 2.41437
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.67282

Cumulative Model Updates: 194,672
Cumulative Timesteps: 1,623,383,740

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.72779
Value Function Loss: 0.01421

Mean KL Divergence: 0.00687
SB3 Clip Fraction: 0.08571
Policy Update Magnitude: 0.41407
Value Function Update Magnitude: 0.25949

Collected Steps per Second: 22,173.90180
Overall Steps per Second: 10,717.24225

Timestep Collection Time: 2.25499
Timestep Consumption Time: 2.41057
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.66557

Cumulative Model Updates: 194,678
Cumulative Timesteps: 1,623,433,742

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1623433742...
Checkpoint 1623433742 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.72887
Value Function Loss: 0.01227

Mean KL Divergence: 0.00598
SB3 Clip Fraction: 0.07268
Policy Update Magnitude: 0.41558
Value Function Update Magnitude: 0.28084

Collected Steps per Second: 22,938.64950
Overall Steps per Second: 10,761.47402

Timestep Collection Time: 2.18034
Timestep Consumption Time: 2.46717
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.64750

Cumulative Model Updates: 194,684
Cumulative Timesteps: 1,623,483,756

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.74444
Value Function Loss: 0.01077

Mean KL Divergence: 0.00608
SB3 Clip Fraction: 0.07439
Policy Update Magnitude: 0.37727
Value Function Update Magnitude: 0.27928

Collected Steps per Second: 22,295.06022
Overall Steps per Second: 10,794.67642

Timestep Collection Time: 2.24346
Timestep Consumption Time: 2.39012
PPO Batch Consumption Time: 0.27650
Total Iteration Time: 4.63358

Cumulative Model Updates: 194,690
Cumulative Timesteps: 1,623,533,774

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1623533774...
Checkpoint 1623533774 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.73321
Value Function Loss: 0.01123

Mean KL Divergence: 0.00574
SB3 Clip Fraction: 0.07005
Policy Update Magnitude: 0.35992
Value Function Update Magnitude: 0.32114

Collected Steps per Second: 22,010.76186
Overall Steps per Second: 10,673.75234

Timestep Collection Time: 2.27252
Timestep Consumption Time: 2.41374
PPO Batch Consumption Time: 0.27666
Total Iteration Time: 4.68626

Cumulative Model Updates: 194,696
Cumulative Timesteps: 1,623,583,794

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 376,937.41377
Policy Entropy: 3.72493
Value Function Loss: 0.01218

Mean KL Divergence: 0.00610
SB3 Clip Fraction: 0.07597
Policy Update Magnitude: 0.39224
Value Function Update Magnitude: 0.33815

Collected Steps per Second: 22,447.51809
Overall Steps per Second: 10,571.10532

Timestep Collection Time: 2.22849
Timestep Consumption Time: 2.50366
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.73214

Cumulative Model Updates: 194,702
Cumulative Timesteps: 1,623,633,818

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1623633818...
Checkpoint 1623633818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 576,052.43851
Policy Entropy: 3.72966
Value Function Loss: 0.01482

Mean KL Divergence: 0.00499
SB3 Clip Fraction: 0.05799
Policy Update Magnitude: 0.48697
Value Function Update Magnitude: 0.46111

Collected Steps per Second: 22,772.25293
Overall Steps per Second: 10,609.14848

Timestep Collection Time: 2.19627
Timestep Consumption Time: 2.51796
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.71423

Cumulative Model Updates: 194,708
Cumulative Timesteps: 1,623,683,832

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 576,052.43851
Policy Entropy: 3.73621
Value Function Loss: 0.01513

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05835
Policy Update Magnitude: 0.55700
Value Function Update Magnitude: 0.58722

Collected Steps per Second: 22,690.59373
Overall Steps per Second: 10,759.16177

Timestep Collection Time: 2.20488
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.27792
Total Iteration Time: 4.64999

Cumulative Model Updates: 194,714
Cumulative Timesteps: 1,623,733,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1623733862...
Checkpoint 1623733862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,264.23677
Policy Entropy: 3.73326
Value Function Loss: 0.01923

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.18376
Policy Update Magnitude: 0.51068
Value Function Update Magnitude: 0.60883

Collected Steps per Second: 22,704.00713
Overall Steps per Second: 10,713.81109

Timestep Collection Time: 2.20331
Timestep Consumption Time: 2.46580
PPO Batch Consumption Time: 0.28499
Total Iteration Time: 4.66911

Cumulative Model Updates: 194,720
Cumulative Timesteps: 1,623,783,886

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290,831.32292
Policy Entropy: 3.70398
Value Function Loss: 0.02429

Mean KL Divergence: 0.01337
SB3 Clip Fraction: 0.17035
Policy Update Magnitude: 0.46257
Value Function Update Magnitude: 0.54212

Collected Steps per Second: 22,437.17662
Overall Steps per Second: 10,617.77705

Timestep Collection Time: 2.22898
Timestep Consumption Time: 2.48123
PPO Batch Consumption Time: 0.29051
Total Iteration Time: 4.71021

Cumulative Model Updates: 194,726
Cumulative Timesteps: 1,623,833,898

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1623833898...
Checkpoint 1623833898 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 290,831.32292
Policy Entropy: 3.71400
Value Function Loss: 0.02314

Mean KL Divergence: 0.02077
SB3 Clip Fraction: 0.23591
Policy Update Magnitude: 0.45470
Value Function Update Magnitude: 0.41568

Collected Steps per Second: 23,198.57212
Overall Steps per Second: 10,885.16413

Timestep Collection Time: 2.15625
Timestep Consumption Time: 2.43918
PPO Batch Consumption Time: 0.27924
Total Iteration Time: 4.59543

Cumulative Model Updates: 194,732
Cumulative Timesteps: 1,623,883,920

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290,831.32292
Policy Entropy: 3.72568
Value Function Loss: 0.02457

Mean KL Divergence: 0.01491
SB3 Clip Fraction: 0.18504
Policy Update Magnitude: 0.42544
Value Function Update Magnitude: 0.44917

Collected Steps per Second: 22,700.50533
Overall Steps per Second: 10,680.16026

Timestep Collection Time: 2.20400
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.68457

Cumulative Model Updates: 194,738
Cumulative Timesteps: 1,623,933,952

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1623933952...
Checkpoint 1623933952 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,982.80610
Policy Entropy: 3.74343
Value Function Loss: 0.02134

Mean KL Divergence: 0.01438
SB3 Clip Fraction: 0.17493
Policy Update Magnitude: 0.50069
Value Function Update Magnitude: 0.57902

Collected Steps per Second: 22,538.18535
Overall Steps per Second: 10,703.73634

Timestep Collection Time: 2.22050
Timestep Consumption Time: 2.45507
PPO Batch Consumption Time: 0.28783
Total Iteration Time: 4.67556

Cumulative Model Updates: 194,744
Cumulative Timesteps: 1,623,983,998

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,020.18314
Policy Entropy: 3.72098
Value Function Loss: 0.02186

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13666
Policy Update Magnitude: 0.53765
Value Function Update Magnitude: 0.61151

Collected Steps per Second: 22,722.38141
Overall Steps per Second: 10,711.35276

Timestep Collection Time: 2.20056
Timestep Consumption Time: 2.46757
PPO Batch Consumption Time: 0.28556
Total Iteration Time: 4.66813

Cumulative Model Updates: 194,750
Cumulative Timesteps: 1,624,034,000

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1624034000...
Checkpoint 1624034000 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 164,020.18314
Policy Entropy: 3.70977
Value Function Loss: 0.01757

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.48789
Value Function Update Magnitude: 0.48340

Collected Steps per Second: 22,264.03489
Overall Steps per Second: 10,604.83679

Timestep Collection Time: 2.24775
Timestep Consumption Time: 2.47123
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.71898

Cumulative Model Updates: 194,756
Cumulative Timesteps: 1,624,084,044

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,159.61289
Policy Entropy: 3.69685
Value Function Loss: 0.01888

Mean KL Divergence: 0.00831
SB3 Clip Fraction: 0.10889
Policy Update Magnitude: 0.46261
Value Function Update Magnitude: 0.38004

Collected Steps per Second: 22,313.09438
Overall Steps per Second: 10,587.03792

Timestep Collection Time: 2.24173
Timestep Consumption Time: 2.48291
PPO Batch Consumption Time: 0.29035
Total Iteration Time: 4.72465

Cumulative Model Updates: 194,762
Cumulative Timesteps: 1,624,134,064

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1624134064...
Checkpoint 1624134064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,159.61289
Policy Entropy: 3.69312
Value Function Loss: 0.02083

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07608
Policy Update Magnitude: 0.58155
Value Function Update Magnitude: 0.43481

Collected Steps per Second: 21,803.57353
Overall Steps per Second: 10,615.22153

Timestep Collection Time: 2.29329
Timestep Consumption Time: 2.41711
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.71041

Cumulative Model Updates: 194,768
Cumulative Timesteps: 1,624,184,066

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,159.61289
Policy Entropy: 3.70752
Value Function Loss: 0.01935

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.59654
Value Function Update Magnitude: 0.43427

Collected Steps per Second: 22,093.03867
Overall Steps per Second: 10,772.40496

Timestep Collection Time: 2.26379
Timestep Consumption Time: 2.37900
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.64279

Cumulative Model Updates: 194,774
Cumulative Timesteps: 1,624,234,080

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1624234080...
Checkpoint 1624234080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 484,159.61289
Policy Entropy: 3.72368
Value Function Loss: 0.01882

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15206
Policy Update Magnitude: 0.49027
Value Function Update Magnitude: 0.32726

Collected Steps per Second: 21,840.20162
Overall Steps per Second: 10,640.17281

Timestep Collection Time: 2.28991
Timestep Consumption Time: 2.41039
PPO Batch Consumption Time: 0.27828
Total Iteration Time: 4.70030

Cumulative Model Updates: 194,780
Cumulative Timesteps: 1,624,284,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 484,159.61289
Policy Entropy: 3.72783
Value Function Loss: 0.01593

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.15721
Policy Update Magnitude: 0.43117
Value Function Update Magnitude: 0.35869

Collected Steps per Second: 22,479.11757
Overall Steps per Second: 10,691.36000

Timestep Collection Time: 2.22429
Timestep Consumption Time: 2.45239
PPO Batch Consumption Time: 0.28791
Total Iteration Time: 4.67667

Cumulative Model Updates: 194,786
Cumulative Timesteps: 1,624,334,092

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1624334092...
Checkpoint 1624334092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 693,088.26505
Policy Entropy: 3.73587
Value Function Loss: 0.01622

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14148
Policy Update Magnitude: 0.44710
Value Function Update Magnitude: 0.40975

Collected Steps per Second: 21,182.81994
Overall Steps per Second: 10,490.63416

Timestep Collection Time: 2.36163
Timestep Consumption Time: 2.40700
PPO Batch Consumption Time: 0.27576
Total Iteration Time: 4.76863

Cumulative Model Updates: 194,792
Cumulative Timesteps: 1,624,384,118

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 843,158.32896
Policy Entropy: 3.73470
Value Function Loss: 0.01485

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11817
Policy Update Magnitude: 0.38592
Value Function Update Magnitude: 0.52756

Collected Steps per Second: 22,556.05797
Overall Steps per Second: 10,794.15773

Timestep Collection Time: 2.21723
Timestep Consumption Time: 2.41602
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.63325

Cumulative Model Updates: 194,798
Cumulative Timesteps: 1,624,434,130

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1624434130...
Checkpoint 1624434130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 293,998.08039
Policy Entropy: 3.73307
Value Function Loss: 0.01414

Mean KL Divergence: 0.00560
SB3 Clip Fraction: 0.06690
Policy Update Magnitude: 0.35845
Value Function Update Magnitude: 0.55186

Collected Steps per Second: 22,366.58240
Overall Steps per Second: 10,699.59626

Timestep Collection Time: 2.23655
Timestep Consumption Time: 2.43877
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.67532

Cumulative Model Updates: 194,804
Cumulative Timesteps: 1,624,484,154

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,040.70056
Policy Entropy: 3.72150
Value Function Loss: 0.01527

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05625
Policy Update Magnitude: 0.37826
Value Function Update Magnitude: 0.52342

Collected Steps per Second: 22,125.81650
Overall Steps per Second: 10,479.42182

Timestep Collection Time: 2.26107
Timestep Consumption Time: 2.51286
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.77393

Cumulative Model Updates: 194,810
Cumulative Timesteps: 1,624,534,182

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1624534182...
Checkpoint 1624534182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,759.89465
Policy Entropy: 3.73277
Value Function Loss: 0.01548

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05771
Policy Update Magnitude: 0.44229
Value Function Update Magnitude: 0.56392

Collected Steps per Second: 22,278.29999
Overall Steps per Second: 10,698.07437

Timestep Collection Time: 2.24541
Timestep Consumption Time: 2.43057
PPO Batch Consumption Time: 0.27624
Total Iteration Time: 4.67598

Cumulative Model Updates: 194,816
Cumulative Timesteps: 1,624,584,206

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,405.32739
Policy Entropy: 3.75223
Value Function Loss: 0.01493

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05957
Policy Update Magnitude: 0.45478
Value Function Update Magnitude: 0.56526

Collected Steps per Second: 22,656.43917
Overall Steps per Second: 10,798.07053

Timestep Collection Time: 2.20697
Timestep Consumption Time: 2.42368
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.63064

Cumulative Model Updates: 194,822
Cumulative Timesteps: 1,624,634,208

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1624634208...
Checkpoint 1624634208 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,197.94653
Policy Entropy: 3.75765
Value Function Loss: 0.01343

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04606
Policy Update Magnitude: 0.41739
Value Function Update Magnitude: 0.49267

Collected Steps per Second: 22,837.57927
Overall Steps per Second: 10,655.63999

Timestep Collection Time: 2.18972
Timestep Consumption Time: 2.50338
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.69310

Cumulative Model Updates: 194,828
Cumulative Timesteps: 1,624,684,216

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,197.94653
Policy Entropy: 3.76155
Value Function Loss: 0.01135

Mean KL Divergence: 0.00548
SB3 Clip Fraction: 0.06779
Policy Update Magnitude: 0.36534
Value Function Update Magnitude: 0.40635

Collected Steps per Second: 22,049.66880
Overall Steps per Second: 10,855.90404

Timestep Collection Time: 2.26851
Timestep Consumption Time: 2.33912
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.60763

Cumulative Model Updates: 194,834
Cumulative Timesteps: 1,624,734,236

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1624734236...
Checkpoint 1624734236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,197.94653
Policy Entropy: 3.75003
Value Function Loss: 0.01157

Mean KL Divergence: 0.00414
SB3 Clip Fraction: 0.04267
Policy Update Magnitude: 0.36734
Value Function Update Magnitude: 0.33908

Collected Steps per Second: 21,976.00316
Overall Steps per Second: 10,738.15068

Timestep Collection Time: 2.27530
Timestep Consumption Time: 2.38118
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.65648

Cumulative Model Updates: 194,840
Cumulative Timesteps: 1,624,784,238

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,064.00548
Policy Entropy: 3.74257
Value Function Loss: 0.01184

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05148
Policy Update Magnitude: 0.41228
Value Function Update Magnitude: 0.36811

Collected Steps per Second: 21,941.02373
Overall Steps per Second: 10,797.79595

Timestep Collection Time: 2.27911
Timestep Consumption Time: 2.35202
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.63113

Cumulative Model Updates: 194,846
Cumulative Timesteps: 1,624,834,244

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1624834244...
Checkpoint 1624834244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,786.99205
Policy Entropy: 3.75383
Value Function Loss: 0.01378

Mean KL Divergence: 0.00419
SB3 Clip Fraction: 0.04336
Policy Update Magnitude: 0.44607
Value Function Update Magnitude: 0.45011

Collected Steps per Second: 21,728.12083
Overall Steps per Second: 10,652.34016

Timestep Collection Time: 2.30135
Timestep Consumption Time: 2.39283
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.69418

Cumulative Model Updates: 194,852
Cumulative Timesteps: 1,624,884,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,113.50348
Policy Entropy: 3.76302
Value Function Loss: 0.01402

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05413
Policy Update Magnitude: 0.47495
Value Function Update Magnitude: 0.52929

Collected Steps per Second: 22,332.01751
Overall Steps per Second: 10,626.94086

Timestep Collection Time: 2.23974
Timestep Consumption Time: 2.46697
PPO Batch Consumption Time: 0.29119
Total Iteration Time: 4.70672

Cumulative Model Updates: 194,858
Cumulative Timesteps: 1,624,934,266

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1624934266...
Checkpoint 1624934266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 128,319.80644
Policy Entropy: 3.75043
Value Function Loss: 0.01624

Mean KL Divergence: 0.00503
SB3 Clip Fraction: 0.05562
Policy Update Magnitude: 0.52481
Value Function Update Magnitude: 0.57479

Collected Steps per Second: 22,297.31248
Overall Steps per Second: 10,522.14719

Timestep Collection Time: 2.24287
Timestep Consumption Time: 2.50996
PPO Batch Consumption Time: 0.29245
Total Iteration Time: 4.75283

Cumulative Model Updates: 194,864
Cumulative Timesteps: 1,624,984,276

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,746.18621
Policy Entropy: 3.73382
Value Function Loss: 0.01649

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06054
Policy Update Magnitude: 0.54987
Value Function Update Magnitude: 0.61229

Collected Steps per Second: 22,471.18396
Overall Steps per Second: 10,582.39715

Timestep Collection Time: 2.22507
Timestep Consumption Time: 2.49976
PPO Batch Consumption Time: 0.28993
Total Iteration Time: 4.72483

Cumulative Model Updates: 194,870
Cumulative Timesteps: 1,625,034,276

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1625034276...
Checkpoint 1625034276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,646.33623
Policy Entropy: 3.73906
Value Function Loss: 0.01696

Mean KL Divergence: 0.00641
SB3 Clip Fraction: 0.07787
Policy Update Magnitude: 0.51597
Value Function Update Magnitude: 0.61190

Collected Steps per Second: 22,417.89345
Overall Steps per Second: 10,516.74013

Timestep Collection Time: 2.23152
Timestep Consumption Time: 2.52528
PPO Batch Consumption Time: 0.29172
Total Iteration Time: 4.75680

Cumulative Model Updates: 194,876
Cumulative Timesteps: 1,625,084,302

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,469.85469
Policy Entropy: 3.71858
Value Function Loss: 0.02520

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.50641
Value Function Update Magnitude: 0.55827

Collected Steps per Second: 22,480.38459
Overall Steps per Second: 10,596.38219

Timestep Collection Time: 2.22558
Timestep Consumption Time: 2.49603
PPO Batch Consumption Time: 0.29030
Total Iteration Time: 4.72161

Cumulative Model Updates: 194,882
Cumulative Timesteps: 1,625,134,334

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1625134334...
Checkpoint 1625134334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,469.85469
Policy Entropy: 3.70683
Value Function Loss: 0.03058

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.11393
Policy Update Magnitude: 0.64710
Value Function Update Magnitude: 0.45109

Collected Steps per Second: 22,746.42242
Overall Steps per Second: 10,838.14864

Timestep Collection Time: 2.19859
Timestep Consumption Time: 2.41567
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61426

Cumulative Model Updates: 194,888
Cumulative Timesteps: 1,625,184,344

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,469.85469
Policy Entropy: 3.70614
Value Function Loss: 0.02638

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.66136
Value Function Update Magnitude: 0.36726

Collected Steps per Second: 22,766.42875
Overall Steps per Second: 10,668.49133

Timestep Collection Time: 2.19727
Timestep Consumption Time: 2.49168
PPO Batch Consumption Time: 0.29020
Total Iteration Time: 4.68895

Cumulative Model Updates: 194,894
Cumulative Timesteps: 1,625,234,368

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1625234368...
Checkpoint 1625234368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,469.85469
Policy Entropy: 3.70989
Value Function Loss: 0.01649

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05492
Policy Update Magnitude: 0.56475
Value Function Update Magnitude: 0.35442

Collected Steps per Second: 22,215.49151
Overall Steps per Second: 10,755.98354

Timestep Collection Time: 2.25203
Timestep Consumption Time: 2.39933
PPO Batch Consumption Time: 0.28750
Total Iteration Time: 4.65136

Cumulative Model Updates: 194,900
Cumulative Timesteps: 1,625,284,398

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 431,278.60371
Policy Entropy: 3.71157
Value Function Loss: 0.01742

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05022
Policy Update Magnitude: 0.54115
Value Function Update Magnitude: 0.38473

Collected Steps per Second: 21,919.37265
Overall Steps per Second: 10,700.44547

Timestep Collection Time: 2.28154
Timestep Consumption Time: 2.39209
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.67364

Cumulative Model Updates: 194,906
Cumulative Timesteps: 1,625,334,408

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1625334408...
Checkpoint 1625334408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 282,967.82453
Policy Entropy: 3.71079
Value Function Loss: 0.02039

Mean KL Divergence: 0.00669
SB3 Clip Fraction: 0.08277
Policy Update Magnitude: 0.56013
Value Function Update Magnitude: 0.41159

Collected Steps per Second: 21,958.80458
Overall Steps per Second: 10,628.43016

Timestep Collection Time: 2.27736
Timestep Consumption Time: 2.42776
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.70512

Cumulative Model Updates: 194,912
Cumulative Timesteps: 1,625,384,416

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 282,967.82453
Policy Entropy: 3.72160
Value Function Loss: 0.01848

Mean KL Divergence: 0.00555
SB3 Clip Fraction: 0.06472
Policy Update Magnitude: 0.56254
Value Function Update Magnitude: 0.41643

Collected Steps per Second: 22,043.71474
Overall Steps per Second: 10,534.52874

Timestep Collection Time: 2.26840
Timestep Consumption Time: 2.47827
PPO Batch Consumption Time: 0.29138
Total Iteration Time: 4.74668

Cumulative Model Updates: 194,918
Cumulative Timesteps: 1,625,434,420

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1625434420...
Checkpoint 1625434420 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 410,990.62021
Policy Entropy: 3.71936
Value Function Loss: 0.01890

Mean KL Divergence: 0.00657
SB3 Clip Fraction: 0.08141
Policy Update Magnitude: 0.56523
Value Function Update Magnitude: 0.46400

Collected Steps per Second: 22,297.11867
Overall Steps per Second: 10,603.38242

Timestep Collection Time: 2.24271
Timestep Consumption Time: 2.47333
PPO Batch Consumption Time: 0.29148
Total Iteration Time: 4.71604

Cumulative Model Updates: 194,924
Cumulative Timesteps: 1,625,484,426

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269,649.92495
Policy Entropy: 3.73010
Value Function Loss: 0.01513

Mean KL Divergence: 0.00584
SB3 Clip Fraction: 0.06970
Policy Update Magnitude: 0.57764
Value Function Update Magnitude: 0.48821

Collected Steps per Second: 22,187.41739
Overall Steps per Second: 10,558.66005

Timestep Collection Time: 2.25371
Timestep Consumption Time: 2.48212
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.73583

Cumulative Model Updates: 194,930
Cumulative Timesteps: 1,625,534,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1625534430...
Checkpoint 1625534430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269,649.92495
Policy Entropy: 3.73539
Value Function Loss: 0.01433

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06429
Policy Update Magnitude: 0.53073
Value Function Update Magnitude: 0.49051

Collected Steps per Second: 22,107.73128
Overall Steps per Second: 10,535.40412

Timestep Collection Time: 2.26283
Timestep Consumption Time: 2.48554
PPO Batch Consumption Time: 0.29147
Total Iteration Time: 4.74837

Cumulative Model Updates: 194,936
Cumulative Timesteps: 1,625,584,456

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269,649.92495
Policy Entropy: 3.74079
Value Function Loss: 0.01275

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06376
Policy Update Magnitude: 0.47151
Value Function Update Magnitude: 0.37188

Collected Steps per Second: 22,162.70330
Overall Steps per Second: 10,530.79855

Timestep Collection Time: 2.25740
Timestep Consumption Time: 2.49343
PPO Batch Consumption Time: 0.29031
Total Iteration Time: 4.75083

Cumulative Model Updates: 194,942
Cumulative Timesteps: 1,625,634,486

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1625634486...
Checkpoint 1625634486 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269,649.92495
Policy Entropy: 3.72641
Value Function Loss: 0.01237

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05897
Policy Update Magnitude: 0.44908
Value Function Update Magnitude: 0.29148

Collected Steps per Second: 22,668.32699
Overall Steps per Second: 10,533.69352

Timestep Collection Time: 2.20607
Timestep Consumption Time: 2.54136
PPO Batch Consumption Time: 0.29077
Total Iteration Time: 4.74743

Cumulative Model Updates: 194,948
Cumulative Timesteps: 1,625,684,494

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269,649.92495
Policy Entropy: 3.72846
Value Function Loss: 0.01190

Mean KL Divergence: 0.00497
SB3 Clip Fraction: 0.05513
Policy Update Magnitude: 0.43663
Value Function Update Magnitude: 0.27524

Collected Steps per Second: 22,688.63551
Overall Steps per Second: 10,756.07265

Timestep Collection Time: 2.20472
Timestep Consumption Time: 2.44587
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.65058

Cumulative Model Updates: 194,954
Cumulative Timesteps: 1,625,734,516

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1625734516...
Checkpoint 1625734516 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269,649.92495
Policy Entropy: 3.73217
Value Function Loss: 0.01352

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04528
Policy Update Magnitude: 0.47117
Value Function Update Magnitude: 0.31517

Collected Steps per Second: 22,560.41691
Overall Steps per Second: 10,822.76710

Timestep Collection Time: 2.21627
Timestep Consumption Time: 2.40362
PPO Batch Consumption Time: 0.27601
Total Iteration Time: 4.61989

Cumulative Model Updates: 194,960
Cumulative Timesteps: 1,625,784,516

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269,649.92495
Policy Entropy: 3.72768
Value Function Loss: 0.01491

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04458
Policy Update Magnitude: 0.52848
Value Function Update Magnitude: 0.37681

Collected Steps per Second: 22,027.18175
Overall Steps per Second: 10,794.63812

Timestep Collection Time: 2.27010
Timestep Consumption Time: 2.36220
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.63230

Cumulative Model Updates: 194,966
Cumulative Timesteps: 1,625,834,520

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1625834520...
Checkpoint 1625834520 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269,649.92495
Policy Entropy: 3.73015
Value Function Loss: 0.01639

Mean KL Divergence: 0.00716
SB3 Clip Fraction: 0.08844
Policy Update Magnitude: 0.51511
Value Function Update Magnitude: 0.36844

Collected Steps per Second: 22,025.11682
Overall Steps per Second: 10,676.94476

Timestep Collection Time: 2.27150
Timestep Consumption Time: 2.41430
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.68580

Cumulative Model Updates: 194,972
Cumulative Timesteps: 1,625,884,550

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301,185.94009
Policy Entropy: 3.72460
Value Function Loss: 0.02045

Mean KL Divergence: 0.02384
SB3 Clip Fraction: 0.24132
Policy Update Magnitude: 0.45327
Value Function Update Magnitude: 0.31176

Collected Steps per Second: 21,744.66877
Overall Steps per Second: 10,459.63648

Timestep Collection Time: 2.29978
Timestep Consumption Time: 2.48126
PPO Batch Consumption Time: 0.29071
Total Iteration Time: 4.78105

Cumulative Model Updates: 194,978
Cumulative Timesteps: 1,625,934,558

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1625934558...
Checkpoint 1625934558 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,659.96641
Policy Entropy: 3.69041
Value Function Loss: 0.04970

Mean KL Divergence: 0.02225
SB3 Clip Fraction: 0.24239
Policy Update Magnitude: 0.54859
Value Function Update Magnitude: 0.33255

Collected Steps per Second: 21,742.88946
Overall Steps per Second: 10,630.89859

Timestep Collection Time: 2.29997
Timestep Consumption Time: 2.40405
PPO Batch Consumption Time: 0.27867
Total Iteration Time: 4.70402

Cumulative Model Updates: 194,984
Cumulative Timesteps: 1,625,984,566

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316,813.54750
Policy Entropy: 3.67201
Value Function Loss: 0.06062

Mean KL Divergence: 0.01530
SB3 Clip Fraction: 0.17501
Policy Update Magnitude: 0.71173
Value Function Update Magnitude: 0.42915

Collected Steps per Second: 21,941.93304
Overall Steps per Second: 10,509.24943

Timestep Collection Time: 2.27874
Timestep Consumption Time: 2.47897
PPO Batch Consumption Time: 0.29171
Total Iteration Time: 4.75771

Cumulative Model Updates: 194,990
Cumulative Timesteps: 1,626,034,566

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1626034566...
Checkpoint 1626034566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,795.31464
Policy Entropy: 3.66324
Value Function Loss: 0.06352

Mean KL Divergence: 0.01472
SB3 Clip Fraction: 0.17488
Policy Update Magnitude: 0.82489
Value Function Update Magnitude: 0.65257

Collected Steps per Second: 21,375.33851
Overall Steps per Second: 10,573.75204

Timestep Collection Time: 2.34008
Timestep Consumption Time: 2.39050
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.73058

Cumulative Model Updates: 194,996
Cumulative Timesteps: 1,626,084,586

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,276.74927
Policy Entropy: 3.70228
Value Function Loss: 0.06291

Mean KL Divergence: 0.01469
SB3 Clip Fraction: 0.16664
Policy Update Magnitude: 0.88149
Value Function Update Magnitude: 0.60295

Collected Steps per Second: 21,500.07561
Overall Steps per Second: 10,515.21417

Timestep Collection Time: 2.32632
Timestep Consumption Time: 2.43022
PPO Batch Consumption Time: 0.28450
Total Iteration Time: 4.75654

Cumulative Model Updates: 195,002
Cumulative Timesteps: 1,626,134,602

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1626134602...
Checkpoint 1626134602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,295.55856
Policy Entropy: 3.75299
Value Function Loss: 0.05789

Mean KL Divergence: 0.01497
SB3 Clip Fraction: 0.16937
Policy Update Magnitude: 0.84383
Value Function Update Magnitude: 0.57520

Collected Steps per Second: 21,871.21736
Overall Steps per Second: 10,618.07528

Timestep Collection Time: 2.28776
Timestep Consumption Time: 2.42459
PPO Batch Consumption Time: 0.28237
Total Iteration Time: 4.71234

Cumulative Model Updates: 195,008
Cumulative Timesteps: 1,626,184,638

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 50,482.05449
Policy Entropy: 3.79694
Value Function Loss: 0.06302

Mean KL Divergence: 0.01126
SB3 Clip Fraction: 0.13614
Policy Update Magnitude: 0.84393
Value Function Update Magnitude: 0.60812

Collected Steps per Second: 22,301.77189
Overall Steps per Second: 10,532.99299

Timestep Collection Time: 2.24251
Timestep Consumption Time: 2.50562
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 4.74813

Cumulative Model Updates: 195,014
Cumulative Timesteps: 1,626,234,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1626234650...
Checkpoint 1626234650 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29.74916
Policy Entropy: 3.82285
Value Function Loss: 0.06242

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.86361
Value Function Update Magnitude: 0.62503

Collected Steps per Second: 20,931.26512
Overall Steps per Second: 10,195.13062

Timestep Collection Time: 2.38963
Timestep Consumption Time: 2.51644
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.90607

Cumulative Model Updates: 195,020
Cumulative Timesteps: 1,626,284,668

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 611,619.93595
Policy Entropy: 3.80495
Value Function Loss: 0.06526

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.12268
Policy Update Magnitude: 0.91084
Value Function Update Magnitude: 0.64138

Collected Steps per Second: 22,417.30090
Overall Steps per Second: 10,788.92539

Timestep Collection Time: 2.23060
Timestep Consumption Time: 2.40415
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.63475

Cumulative Model Updates: 195,026
Cumulative Timesteps: 1,626,334,672

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1626334672...
Checkpoint 1626334672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,022.41476
Policy Entropy: 3.81547
Value Function Loss: 0.06047

Mean KL Divergence: 0.00717
SB3 Clip Fraction: 0.08909
Policy Update Magnitude: 1.02426
Value Function Update Magnitude: 0.67435

Collected Steps per Second: 22,476.06359
Overall Steps per Second: 10,699.23711

Timestep Collection Time: 2.22583
Timestep Consumption Time: 2.45001
PPO Batch Consumption Time: 0.28635
Total Iteration Time: 4.67585

Cumulative Model Updates: 195,032
Cumulative Timesteps: 1,626,384,700

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212.82034
Policy Entropy: 3.78611
Value Function Loss: 0.05183

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.10685
Policy Update Magnitude: 1.07692
Value Function Update Magnitude: 0.81625

Collected Steps per Second: 22,830.68439
Overall Steps per Second: 10,830.16988

Timestep Collection Time: 2.19047
Timestep Consumption Time: 2.42718
PPO Batch Consumption Time: 0.27912
Total Iteration Time: 4.61766

Cumulative Model Updates: 195,038
Cumulative Timesteps: 1,626,434,710

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1626434710...
Checkpoint 1626434710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,501.99063
Policy Entropy: 3.79890
Value Function Loss: 0.04319

Mean KL Divergence: 0.00782
SB3 Clip Fraction: 0.09803
Policy Update Magnitude: 0.97888
Value Function Update Magnitude: 0.88991

Collected Steps per Second: 22,654.39539
Overall Steps per Second: 10,688.11565

Timestep Collection Time: 2.20822
Timestep Consumption Time: 2.47230
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.68053

Cumulative Model Updates: 195,044
Cumulative Timesteps: 1,626,484,736

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 667,808.63300
Policy Entropy: 3.77238
Value Function Loss: 0.04012

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.08013
Policy Update Magnitude: 0.86947
Value Function Update Magnitude: 0.79798

Collected Steps per Second: 22,738.97579
Overall Steps per Second: 10,856.81997

Timestep Collection Time: 2.19931
Timestep Consumption Time: 2.40701
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.60632

Cumulative Model Updates: 195,050
Cumulative Timesteps: 1,626,534,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1626534746...
Checkpoint 1626534746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,866.43084
Policy Entropy: 3.77966
Value Function Loss: 0.03598

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08124
Policy Update Magnitude: 0.79600
Value Function Update Magnitude: 0.68209

Collected Steps per Second: 22,293.10905
Overall Steps per Second: 10,690.42693

Timestep Collection Time: 2.24329
Timestep Consumption Time: 2.43472
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.67802

Cumulative Model Updates: 195,056
Cumulative Timesteps: 1,626,584,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,447.09473
Policy Entropy: 3.75207
Value Function Loss: 0.03275

Mean KL Divergence: 0.01384
SB3 Clip Fraction: 0.17551
Policy Update Magnitude: 0.70930
Value Function Update Magnitude: 0.67219

Collected Steps per Second: 22,463.99762
Overall Steps per Second: 10,631.52654

Timestep Collection Time: 2.22632
Timestep Consumption Time: 2.47780
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.70412

Cumulative Model Updates: 195,062
Cumulative Timesteps: 1,626,634,768

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1626634768...
Checkpoint 1626634768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,447.09473
Policy Entropy: 3.76048
Value Function Loss: 0.02586

Mean KL Divergence: 0.02587
SB3 Clip Fraction: 0.28157
Policy Update Magnitude: 0.53076
Value Function Update Magnitude: 0.65249

Collected Steps per Second: 22,105.67662
Overall Steps per Second: 10,508.94426

Timestep Collection Time: 2.26277
Timestep Consumption Time: 2.49699
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.75976

Cumulative Model Updates: 195,068
Cumulative Timesteps: 1,626,684,788

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,702.75203
Policy Entropy: 3.75515
Value Function Loss: 0.02438

Mean KL Divergence: 0.01872
SB3 Clip Fraction: 0.22243
Policy Update Magnitude: 0.42197
Value Function Update Magnitude: 0.56390

Collected Steps per Second: 22,502.37188
Overall Steps per Second: 10,784.08242

Timestep Collection Time: 2.22323
Timestep Consumption Time: 2.41583
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.63906

Cumulative Model Updates: 195,074
Cumulative Timesteps: 1,626,734,816

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1626734816...
Checkpoint 1626734816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 197,617.14260
Policy Entropy: 3.74876
Value Function Loss: 0.02915

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.17076
Policy Update Magnitude: 0.39446
Value Function Update Magnitude: 0.57146

Collected Steps per Second: 22,706.62869
Overall Steps per Second: 10,731.22686

Timestep Collection Time: 2.20359
Timestep Consumption Time: 2.45907
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.66265

Cumulative Model Updates: 195,080
Cumulative Timesteps: 1,626,784,852

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,668.80350
Policy Entropy: 3.75188
Value Function Loss: 0.03224

Mean KL Divergence: 0.01323
SB3 Clip Fraction: 0.17600
Policy Update Magnitude: 0.41837
Value Function Update Magnitude: 0.64508

Collected Steps per Second: 22,621.46313
Overall Steps per Second: 10,632.70891

Timestep Collection Time: 2.21047
Timestep Consumption Time: 2.49238
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.70285

Cumulative Model Updates: 195,086
Cumulative Timesteps: 1,626,834,856

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1626834856...
Checkpoint 1626834856 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,594.46100
Policy Entropy: 3.74279
Value Function Loss: 0.03482

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15476
Policy Update Magnitude: 0.38765
Value Function Update Magnitude: 0.67730

Collected Steps per Second: 22,754.69712
Overall Steps per Second: 10,827.01451

Timestep Collection Time: 2.19761
Timestep Consumption Time: 2.42102
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.61863

Cumulative Model Updates: 195,092
Cumulative Timesteps: 1,626,884,862

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,205.70838
Policy Entropy: 3.75204
Value Function Loss: 0.02773

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14264
Policy Update Magnitude: 0.39944
Value Function Update Magnitude: 0.61253

Collected Steps per Second: 22,575.67428
Overall Steps per Second: 10,641.74288

Timestep Collection Time: 2.21548
Timestep Consumption Time: 2.48450
PPO Batch Consumption Time: 0.29177
Total Iteration Time: 4.69998

Cumulative Model Updates: 195,098
Cumulative Timesteps: 1,626,934,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1626934878...
Checkpoint 1626934878 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 291,067.34393
Policy Entropy: 3.73020
Value Function Loss: 0.02816

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.40323
Value Function Update Magnitude: 0.54102

Collected Steps per Second: 22,592.44947
Overall Steps per Second: 10,606.05466

Timestep Collection Time: 2.21393
Timestep Consumption Time: 2.50206
PPO Batch Consumption Time: 0.29242
Total Iteration Time: 4.71599

Cumulative Model Updates: 195,104
Cumulative Timesteps: 1,626,984,896

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,621.73527
Policy Entropy: 3.73891
Value Function Loss: 0.02921

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.43620
Value Function Update Magnitude: 0.53731

Collected Steps per Second: 22,990.84798
Overall Steps per Second: 10,888.82957

Timestep Collection Time: 2.17495
Timestep Consumption Time: 2.41728
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.59223

Cumulative Model Updates: 195,110
Cumulative Timesteps: 1,627,034,900

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1627034900...
Checkpoint 1627034900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,709.84644
Policy Entropy: 3.73934
Value Function Loss: 0.03600

Mean KL Divergence: 0.01029
SB3 Clip Fraction: 0.13644
Policy Update Magnitude: 0.53050
Value Function Update Magnitude: 0.54205

Collected Steps per Second: 22,506.89397
Overall Steps per Second: 10,596.43920

Timestep Collection Time: 2.22234
Timestep Consumption Time: 2.49792
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.72026

Cumulative Model Updates: 195,116
Cumulative Timesteps: 1,627,084,918

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 25,760.93671
Policy Entropy: 3.75746
Value Function Loss: 0.03708

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.55216
Value Function Update Magnitude: 0.57811

Collected Steps per Second: 22,574.21031
Overall Steps per Second: 10,655.49924

Timestep Collection Time: 2.21501
Timestep Consumption Time: 2.47759
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.69260

Cumulative Model Updates: 195,122
Cumulative Timesteps: 1,627,134,920

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1627134920...
Checkpoint 1627134920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,175.15230
Policy Entropy: 3.78001
Value Function Loss: 0.04249

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.12991
Policy Update Magnitude: 0.49983
Value Function Update Magnitude: 0.55887

Collected Steps per Second: 22,730.77745
Overall Steps per Second: 10,842.66385

Timestep Collection Time: 2.20028
Timestep Consumption Time: 2.41243
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.61270

Cumulative Model Updates: 195,128
Cumulative Timesteps: 1,627,184,934

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,231.65820
Policy Entropy: 3.79372
Value Function Loss: 0.03712

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12677
Policy Update Magnitude: 0.50542
Value Function Update Magnitude: 0.62960

Collected Steps per Second: 21,924.07183
Overall Steps per Second: 10,503.96452

Timestep Collection Time: 2.28115
Timestep Consumption Time: 2.48010
PPO Batch Consumption Time: 0.28641
Total Iteration Time: 4.76125

Cumulative Model Updates: 195,134
Cumulative Timesteps: 1,627,234,946

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1627234946...
Checkpoint 1627234946 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,889.65606
Policy Entropy: 3.81246
Value Function Loss: 0.03558

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12108
Policy Update Magnitude: 0.49453
Value Function Update Magnitude: 0.76384

Collected Steps per Second: 22,437.56206
Overall Steps per Second: 10,661.37476

Timestep Collection Time: 2.22965
Timestep Consumption Time: 2.46280
PPO Batch Consumption Time: 0.28723
Total Iteration Time: 4.69245

Cumulative Model Updates: 195,140
Cumulative Timesteps: 1,627,284,974

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 203.97962
Policy Entropy: 3.82576
Value Function Loss: 0.02990

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12352
Policy Update Magnitude: 0.46654
Value Function Update Magnitude: 0.87152

Collected Steps per Second: 22,629.93059
Overall Steps per Second: 10,606.44863

Timestep Collection Time: 2.21008
Timestep Consumption Time: 2.50535
PPO Batch Consumption Time: 0.28912
Total Iteration Time: 4.71543

Cumulative Model Updates: 195,146
Cumulative Timesteps: 1,627,334,988

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1627334988...
Checkpoint 1627334988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,978.61456
Policy Entropy: 3.81425
Value Function Loss: 0.03137

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12341
Policy Update Magnitude: 0.43857
Value Function Update Magnitude: 0.81887

Collected Steps per Second: 22,157.57393
Overall Steps per Second: 10,854.55491

Timestep Collection Time: 2.25666
Timestep Consumption Time: 2.34989
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.60655

Cumulative Model Updates: 195,152
Cumulative Timesteps: 1,627,384,990

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,861.98370
Policy Entropy: 3.78478
Value Function Loss: 0.03155

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13059
Policy Update Magnitude: 0.43421
Value Function Update Magnitude: 0.66145

Collected Steps per Second: 21,959.90675
Overall Steps per Second: 10,663.92732

Timestep Collection Time: 2.27797
Timestep Consumption Time: 2.41299
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.69095

Cumulative Model Updates: 195,158
Cumulative Timesteps: 1,627,435,014

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1627435014...
Checkpoint 1627435014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,570.27818
Policy Entropy: 3.78035
Value Function Loss: 0.03525

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12839
Policy Update Magnitude: 0.43250
Value Function Update Magnitude: 0.59973

Collected Steps per Second: 21,804.92318
Overall Steps per Second: 10,644.81322

Timestep Collection Time: 2.29416
Timestep Consumption Time: 2.40522
PPO Batch Consumption Time: 0.28981
Total Iteration Time: 4.69938

Cumulative Model Updates: 195,164
Cumulative Timesteps: 1,627,485,038

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,821.26321
Policy Entropy: 3.76356
Value Function Loss: 0.03495

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12950
Policy Update Magnitude: 0.42661
Value Function Update Magnitude: 0.55496

Collected Steps per Second: 22,263.36792
Overall Steps per Second: 10,750.54600

Timestep Collection Time: 2.24665
Timestep Consumption Time: 2.40595
PPO Batch Consumption Time: 0.28676
Total Iteration Time: 4.65260

Cumulative Model Updates: 195,170
Cumulative Timesteps: 1,627,535,056

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1627535056...
Checkpoint 1627535056 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,574.51051
Policy Entropy: 3.75427
Value Function Loss: 0.03356

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.42527
Value Function Update Magnitude: 0.49845

Collected Steps per Second: 22,159.16567
Overall Steps per Second: 10,657.13758

Timestep Collection Time: 2.25649
Timestep Consumption Time: 2.43539
PPO Batch Consumption Time: 0.28388
Total Iteration Time: 4.69188

Cumulative Model Updates: 195,176
Cumulative Timesteps: 1,627,585,058

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36,574.51051
Policy Entropy: 3.71254
Value Function Loss: 0.03037

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.42224
Value Function Update Magnitude: 0.45582

Collected Steps per Second: 22,605.20182
Overall Steps per Second: 10,835.12379

Timestep Collection Time: 2.21215
Timestep Consumption Time: 2.40303
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.61518

Cumulative Model Updates: 195,182
Cumulative Timesteps: 1,627,635,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1627635064...
Checkpoint 1627635064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,129.90406
Policy Entropy: 3.71449
Value Function Loss: 0.02542

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.41468
Value Function Update Magnitude: 0.40717

Collected Steps per Second: 22,169.43279
Overall Steps per Second: 10,760.13769

Timestep Collection Time: 2.25563
Timestep Consumption Time: 2.39171
PPO Batch Consumption Time: 0.27639
Total Iteration Time: 4.64734

Cumulative Model Updates: 195,188
Cumulative Timesteps: 1,627,685,070

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 80,572.24141
Policy Entropy: 3.71578
Value Function Loss: 0.02564

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13354
Policy Update Magnitude: 0.40864
Value Function Update Magnitude: 0.51357

Collected Steps per Second: 22,216.43624
Overall Steps per Second: 10,543.61318

Timestep Collection Time: 2.25104
Timestep Consumption Time: 2.49212
PPO Batch Consumption Time: 0.28943
Total Iteration Time: 4.74316

Cumulative Model Updates: 195,194
Cumulative Timesteps: 1,627,735,080

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1627735080...
Checkpoint 1627735080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,096.78990
Policy Entropy: 3.73779
Value Function Loss: 0.02843

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13015
Policy Update Magnitude: 0.42312
Value Function Update Magnitude: 0.52057

Collected Steps per Second: 21,931.48793
Overall Steps per Second: 10,511.72088

Timestep Collection Time: 2.28083
Timestep Consumption Time: 2.47786
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.75869

Cumulative Model Updates: 195,200
Cumulative Timesteps: 1,627,785,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,539.00810
Policy Entropy: 3.71951
Value Function Loss: 0.02795

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.42400
Value Function Update Magnitude: 0.42516

Collected Steps per Second: 22,604.04758
Overall Steps per Second: 10,621.52918

Timestep Collection Time: 2.21208
Timestep Consumption Time: 2.49553
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.70761

Cumulative Model Updates: 195,206
Cumulative Timesteps: 1,627,835,104

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1627835104...
Checkpoint 1627835104 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,539.00810
Policy Entropy: 3.71084
Value Function Loss: 0.02694

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12652
Policy Update Magnitude: 0.42681
Value Function Update Magnitude: 0.51843

Collected Steps per Second: 22,562.08238
Overall Steps per Second: 10,797.00216

Timestep Collection Time: 2.21691
Timestep Consumption Time: 2.41568
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.63258

Cumulative Model Updates: 195,212
Cumulative Timesteps: 1,627,885,122

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,539.00810
Policy Entropy: 3.69438
Value Function Loss: 0.02353

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.42554
Value Function Update Magnitude: 0.43126

Collected Steps per Second: 22,596.59046
Overall Steps per Second: 10,598.13306

Timestep Collection Time: 2.21370
Timestep Consumption Time: 2.50619
PPO Batch Consumption Time: 0.29249
Total Iteration Time: 4.71989

Cumulative Model Updates: 195,218
Cumulative Timesteps: 1,627,935,144

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1627935144...
Checkpoint 1627935144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,539.00810
Policy Entropy: 3.69014
Value Function Loss: 0.02244

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.43459
Value Function Update Magnitude: 0.39872

Collected Steps per Second: 22,615.82814
Overall Steps per Second: 10,605.19006

Timestep Collection Time: 2.21217
Timestep Consumption Time: 2.50533
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.71750

Cumulative Model Updates: 195,224
Cumulative Timesteps: 1,627,985,174

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 208,040.12104
Policy Entropy: 3.67968
Value Function Loss: 0.02540

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12311
Policy Update Magnitude: 0.44090
Value Function Update Magnitude: 0.36121

Collected Steps per Second: 22,213.16469
Overall Steps per Second: 10,842.71285

Timestep Collection Time: 2.25227
Timestep Consumption Time: 2.36189
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.61416

Cumulative Model Updates: 195,230
Cumulative Timesteps: 1,628,035,204

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1628035204...
Checkpoint 1628035204 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 72,616.75312
Policy Entropy: 3.68426
Value Function Loss: 0.02757

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.46652
Value Function Update Magnitude: 0.37867

Collected Steps per Second: 21,835.44783
Overall Steps per Second: 10,742.41965

Timestep Collection Time: 2.29095
Timestep Consumption Time: 2.36573
PPO Batch Consumption Time: 0.28123
Total Iteration Time: 4.65668

Cumulative Model Updates: 195,236
Cumulative Timesteps: 1,628,085,228

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,872.83502
Policy Entropy: 3.68163
Value Function Loss: 0.03055

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.13466
Policy Update Magnitude: 0.46000
Value Function Update Magnitude: 0.38570

Collected Steps per Second: 21,554.05950
Overall Steps per Second: 10,454.89039

Timestep Collection Time: 2.32003
Timestep Consumption Time: 2.46300
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.78302

Cumulative Model Updates: 195,242
Cumulative Timesteps: 1,628,135,234

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1628135234...
Checkpoint 1628135234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,673.02211
Policy Entropy: 3.68559
Value Function Loss: 0.03450

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.44859
Value Function Update Magnitude: 0.39672

Collected Steps per Second: 21,964.26593
Overall Steps per Second: 10,586.05510

Timestep Collection Time: 2.27688
Timestep Consumption Time: 2.44726
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.72414

Cumulative Model Updates: 195,248
Cumulative Timesteps: 1,628,185,244

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,499.21396
Policy Entropy: 3.69315
Value Function Loss: 0.03146

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13251
Policy Update Magnitude: 0.46374
Value Function Update Magnitude: 0.47856

Collected Steps per Second: 22,181.19914
Overall Steps per Second: 10,602.23231

Timestep Collection Time: 2.25515
Timestep Consumption Time: 2.46291
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.71806

Cumulative Model Updates: 195,254
Cumulative Timesteps: 1,628,235,266

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1628235266...
Checkpoint 1628235266 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 177,073.06860
Policy Entropy: 3.69596
Value Function Loss: 0.03263

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.12817
Policy Update Magnitude: 0.46113
Value Function Update Magnitude: 0.49466

Collected Steps per Second: 22,203.62080
Overall Steps per Second: 10,515.80934

Timestep Collection Time: 2.25252
Timestep Consumption Time: 2.50356
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.75608

Cumulative Model Updates: 195,260
Cumulative Timesteps: 1,628,285,280

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,325.92389
Policy Entropy: 3.71682
Value Function Loss: 0.03033

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13160
Policy Update Magnitude: 0.43906
Value Function Update Magnitude: 0.47004

Collected Steps per Second: 22,206.30834
Overall Steps per Second: 10,502.98021

Timestep Collection Time: 2.25170
Timestep Consumption Time: 2.50904
PPO Batch Consumption Time: 0.29214
Total Iteration Time: 4.76074

Cumulative Model Updates: 195,266
Cumulative Timesteps: 1,628,335,282

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1628335282...
Checkpoint 1628335282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,918.38017
Policy Entropy: 3.72983
Value Function Loss: 0.02856

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12932
Policy Update Magnitude: 0.43632
Value Function Update Magnitude: 0.52836

Collected Steps per Second: 22,690.31337
Overall Steps per Second: 10,612.21681

Timestep Collection Time: 2.20482
Timestep Consumption Time: 2.50937
PPO Batch Consumption Time: 0.28671
Total Iteration Time: 4.71419

Cumulative Model Updates: 195,272
Cumulative Timesteps: 1,628,385,310

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 678.01476
Policy Entropy: 3.72635
Value Function Loss: 0.02500

Mean KL Divergence: 0.00913
SB3 Clip Fraction: 0.12185
Policy Update Magnitude: 0.40517
Value Function Update Magnitude: 0.52949

Collected Steps per Second: 22,799.30653
Overall Steps per Second: 10,783.73631

Timestep Collection Time: 2.19401
Timestep Consumption Time: 2.44464
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.63865

Cumulative Model Updates: 195,278
Cumulative Timesteps: 1,628,435,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1628435332...
Checkpoint 1628435332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,095.94909
Policy Entropy: 3.72434
Value Function Loss: 0.02428

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13492
Policy Update Magnitude: 0.39398
Value Function Update Magnitude: 0.50005

Collected Steps per Second: 22,367.08573
Overall Steps per Second: 10,695.01743

Timestep Collection Time: 2.23561
Timestep Consumption Time: 2.43984
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.67545

Cumulative Model Updates: 195,284
Cumulative Timesteps: 1,628,485,336

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,542.73505
Policy Entropy: 3.70323
Value Function Loss: 0.02347

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13525
Policy Update Magnitude: 0.38286
Value Function Update Magnitude: 0.53319

Collected Steps per Second: 22,921.61064
Overall Steps per Second: 10,873.76631

Timestep Collection Time: 2.18170
Timestep Consumption Time: 2.41726
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.59896

Cumulative Model Updates: 195,290
Cumulative Timesteps: 1,628,535,344

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1628535344...
Checkpoint 1628535344 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 101,936.79451
Policy Entropy: 3.70365
Value Function Loss: 0.02442

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13247
Policy Update Magnitude: 0.39842
Value Function Update Magnitude: 0.44892

Collected Steps per Second: 22,617.61206
Overall Steps per Second: 10,755.20320

Timestep Collection Time: 2.21093
Timestep Consumption Time: 2.43854
PPO Batch Consumption Time: 0.28095
Total Iteration Time: 4.64947

Cumulative Model Updates: 195,296
Cumulative Timesteps: 1,628,585,350

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,579.13248
Policy Entropy: 3.70384
Value Function Loss: 0.02146

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12780
Policy Update Magnitude: 0.39837
Value Function Update Magnitude: 0.37564

Collected Steps per Second: 22,556.42659
Overall Steps per Second: 10,784.28173

Timestep Collection Time: 2.21684
Timestep Consumption Time: 2.41991
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.63675

Cumulative Model Updates: 195,302
Cumulative Timesteps: 1,628,635,354

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1628635354...
Checkpoint 1628635354 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212,008.40760
Policy Entropy: 3.69288
Value Function Loss: 0.02548

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13892
Policy Update Magnitude: 0.41807
Value Function Update Magnitude: 0.37747

Collected Steps per Second: 21,902.22535
Overall Steps per Second: 10,616.56272

Timestep Collection Time: 2.28379
Timestep Consumption Time: 2.42772
PPO Batch Consumption Time: 0.27838
Total Iteration Time: 4.71151

Cumulative Model Updates: 195,308
Cumulative Timesteps: 1,628,685,374

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178,052.40215
Policy Entropy: 3.68443
Value Function Loss: 0.02673

Mean KL Divergence: 0.01058
SB3 Clip Fraction: 0.14235
Policy Update Magnitude: 0.46866
Value Function Update Magnitude: 0.42182

Collected Steps per Second: 22,217.55403
Overall Steps per Second: 10,573.91260

Timestep Collection Time: 2.25164
Timestep Consumption Time: 2.47943
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.73108

Cumulative Model Updates: 195,314
Cumulative Timesteps: 1,628,735,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1628735400...
Checkpoint 1628735400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,294.10595
Policy Entropy: 3.69947
Value Function Loss: 0.02440

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13844
Policy Update Magnitude: 0.46521
Value Function Update Magnitude: 0.54696

Collected Steps per Second: 22,345.40998
Overall Steps per Second: 10,650.65263

Timestep Collection Time: 2.23760
Timestep Consumption Time: 2.45695
PPO Batch Consumption Time: 0.28580
Total Iteration Time: 4.69455

Cumulative Model Updates: 195,320
Cumulative Timesteps: 1,628,785,400

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,538.87252
Policy Entropy: 3.70529
Value Function Loss: 0.02241

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13026
Policy Update Magnitude: 0.42262
Value Function Update Magnitude: 0.53730

Collected Steps per Second: 22,560.46383
Overall Steps per Second: 10,669.04018

Timestep Collection Time: 2.21751
Timestep Consumption Time: 2.47157
PPO Batch Consumption Time: 0.28647
Total Iteration Time: 4.68908

Cumulative Model Updates: 195,326
Cumulative Timesteps: 1,628,835,428

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1628835428...
Checkpoint 1628835428 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 67,875.20742
Policy Entropy: 3.71430
Value Function Loss: 0.02286

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.12597
Policy Update Magnitude: 0.37834
Value Function Update Magnitude: 0.53235

Collected Steps per Second: 21,473.89406
Overall Steps per Second: 10,520.75044

Timestep Collection Time: 2.32990
Timestep Consumption Time: 2.42566
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.75555

Cumulative Model Updates: 195,332
Cumulative Timesteps: 1,628,885,460

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,574.28663
Policy Entropy: 3.72274
Value Function Loss: 0.02363

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12882
Policy Update Magnitude: 0.38355
Value Function Update Magnitude: 0.66799

Collected Steps per Second: 22,274.32967
Overall Steps per Second: 10,854.06862

Timestep Collection Time: 2.24528
Timestep Consumption Time: 2.36240
PPO Batch Consumption Time: 0.27581
Total Iteration Time: 4.60767

Cumulative Model Updates: 195,338
Cumulative Timesteps: 1,628,935,472

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1628935472...
Checkpoint 1628935472 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,611.19096
Policy Entropy: 3.73470
Value Function Loss: 0.02749

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12567
Policy Update Magnitude: 0.42102
Value Function Update Magnitude: 0.69813

Collected Steps per Second: 22,222.03070
Overall Steps per Second: 10,779.43714

Timestep Collection Time: 2.25092
Timestep Consumption Time: 2.38940
PPO Batch Consumption Time: 0.28831
Total Iteration Time: 4.64032

Cumulative Model Updates: 195,344
Cumulative Timesteps: 1,628,985,492

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,891.16703
Policy Entropy: 3.73194
Value Function Loss: 0.02321

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.39816
Value Function Update Magnitude: 0.67582

Collected Steps per Second: 22,452.72066
Overall Steps per Second: 10,752.44912

Timestep Collection Time: 2.22735
Timestep Consumption Time: 2.42369
PPO Batch Consumption Time: 0.29169
Total Iteration Time: 4.65103

Cumulative Model Updates: 195,350
Cumulative Timesteps: 1,629,035,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1629035502...
Checkpoint 1629035502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 152,274.83191
Policy Entropy: 3.72506
Value Function Loss: 0.02686

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12392
Policy Update Magnitude: 0.36491
Value Function Update Magnitude: 0.60778

Collected Steps per Second: 22,261.30641
Overall Steps per Second: 10,562.35489

Timestep Collection Time: 2.24632
Timestep Consumption Time: 2.48804
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.73436

Cumulative Model Updates: 195,356
Cumulative Timesteps: 1,629,085,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,018.85426
Policy Entropy: 3.73953
Value Function Loss: 0.02323

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12425
Policy Update Magnitude: 0.39972
Value Function Update Magnitude: 0.62723

Collected Steps per Second: 22,453.35489
Overall Steps per Second: 10,662.97513

Timestep Collection Time: 2.22791
Timestep Consumption Time: 2.46347
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.69137

Cumulative Model Updates: 195,362
Cumulative Timesteps: 1,629,135,532

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1629135532...
Checkpoint 1629135532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,815.76838
Policy Entropy: 3.74719
Value Function Loss: 0.02354

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12375
Policy Update Magnitude: 0.42155
Value Function Update Magnitude: 0.70360

Collected Steps per Second: 22,771.93470
Overall Steps per Second: 10,898.36058

Timestep Collection Time: 2.19569
Timestep Consumption Time: 2.39216
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.58785

Cumulative Model Updates: 195,368
Cumulative Timesteps: 1,629,185,532

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 171,173.47045
Policy Entropy: 3.74207
Value Function Loss: 0.02441

Mean KL Divergence: 0.00870
SB3 Clip Fraction: 0.12155
Policy Update Magnitude: 0.43744
Value Function Update Magnitude: 0.75318

Collected Steps per Second: 22,693.90643
Overall Steps per Second: 10,671.03486

Timestep Collection Time: 2.20412
Timestep Consumption Time: 2.48334
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.68746

Cumulative Model Updates: 195,374
Cumulative Timesteps: 1,629,235,552

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1629235552...
Checkpoint 1629235552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220,918.21320
Policy Entropy: 3.73005
Value Function Loss: 0.02590

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13336
Policy Update Magnitude: 0.50814
Value Function Update Magnitude: 0.76426

Collected Steps per Second: 22,106.91096
Overall Steps per Second: 10,503.12707

Timestep Collection Time: 2.26400
Timestep Consumption Time: 2.50125
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.76525

Cumulative Model Updates: 195,380
Cumulative Timesteps: 1,629,285,602

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202,115.05155
Policy Entropy: 3.71610
Value Function Loss: 0.02642

Mean KL Divergence: 0.01064
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.51395
Value Function Update Magnitude: 0.71324

Collected Steps per Second: 22,085.48531
Overall Steps per Second: 10,525.15639

Timestep Collection Time: 2.26420
Timestep Consumption Time: 2.48689
PPO Batch Consumption Time: 0.29037
Total Iteration Time: 4.75109

Cumulative Model Updates: 195,386
Cumulative Timesteps: 1,629,335,608

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1629335608...
Checkpoint 1629335608 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,762.88737
Policy Entropy: 3.71295
Value Function Loss: 0.03310

Mean KL Divergence: 0.01402
SB3 Clip Fraction: 0.17501
Policy Update Magnitude: 0.49533
Value Function Update Magnitude: 0.67826

Collected Steps per Second: 22,270.22176
Overall Steps per Second: 10,566.05798

Timestep Collection Time: 2.24632
Timestep Consumption Time: 2.48828
PPO Batch Consumption Time: 0.29197
Total Iteration Time: 4.73459

Cumulative Model Updates: 195,392
Cumulative Timesteps: 1,629,385,634

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,363.15681
Policy Entropy: 3.73237
Value Function Loss: 0.04008

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.15927
Policy Update Magnitude: 0.53287
Value Function Update Magnitude: 0.61507

Collected Steps per Second: 22,504.83906
Overall Steps per Second: 10,600.17017

Timestep Collection Time: 2.22290
Timestep Consumption Time: 2.49646
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.71936

Cumulative Model Updates: 195,398
Cumulative Timesteps: 1,629,435,660

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1629435660...
Checkpoint 1629435660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,640.05191
Policy Entropy: 3.72593
Value Function Loss: 0.04610

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12154
Policy Update Magnitude: 0.63276
Value Function Update Magnitude: 0.59128

Collected Steps per Second: 22,792.80264
Overall Steps per Second: 10,777.52190

Timestep Collection Time: 2.19490
Timestep Consumption Time: 2.44698
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.64188

Cumulative Model Updates: 195,404
Cumulative Timesteps: 1,629,485,688

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.73323
Value Function Loss: 0.03939

Mean KL Divergence: 0.00709
SB3 Clip Fraction: 0.08724
Policy Update Magnitude: 0.75437
Value Function Update Magnitude: 0.55483

Collected Steps per Second: 22,753.43184
Overall Steps per Second: 10,658.11426

Timestep Collection Time: 2.19817
Timestep Consumption Time: 2.49459
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.69276

Cumulative Model Updates: 195,410
Cumulative Timesteps: 1,629,535,704

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1629535704...
Checkpoint 1629535704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.72509
Value Function Loss: 0.02660

Mean KL Divergence: 0.00746
SB3 Clip Fraction: 0.09162
Policy Update Magnitude: 0.72439
Value Function Update Magnitude: 0.60378

Collected Steps per Second: 22,682.47327
Overall Steps per Second: 10,672.88001

Timestep Collection Time: 2.20452
Timestep Consumption Time: 2.48062
PPO Batch Consumption Time: 0.29049
Total Iteration Time: 4.68515

Cumulative Model Updates: 195,416
Cumulative Timesteps: 1,629,585,708

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.72098
Value Function Loss: 0.01571

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05514
Policy Update Magnitude: 0.58367
Value Function Update Magnitude: 0.55950

Collected Steps per Second: 22,565.32870
Overall Steps per Second: 10,771.78760

Timestep Collection Time: 2.21668
Timestep Consumption Time: 2.42694
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.64361

Cumulative Model Updates: 195,422
Cumulative Timesteps: 1,629,635,728

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1629635728...
Checkpoint 1629635728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.72560
Value Function Loss: 0.01117

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05146
Policy Update Magnitude: 0.45095
Value Function Update Magnitude: 0.41250

Collected Steps per Second: 21,991.18998
Overall Steps per Second: 10,687.46180

Timestep Collection Time: 2.27391
Timestep Consumption Time: 2.40503
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.67894

Cumulative Model Updates: 195,428
Cumulative Timesteps: 1,629,685,734

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.72723
Value Function Loss: 0.01028

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05013
Policy Update Magnitude: 0.37140
Value Function Update Magnitude: 0.30482

Collected Steps per Second: 22,074.59051
Overall Steps per Second: 10,440.86708

Timestep Collection Time: 2.26604
Timestep Consumption Time: 2.52494
PPO Batch Consumption Time: 0.29067
Total Iteration Time: 4.79098

Cumulative Model Updates: 195,434
Cumulative Timesteps: 1,629,735,756

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1629735756...
Checkpoint 1629735756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.74506
Value Function Loss: 0.00945

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04282
Policy Update Magnitude: 0.31821
Value Function Update Magnitude: 0.21993

Collected Steps per Second: 22,291.23788
Overall Steps per Second: 10,684.72984

Timestep Collection Time: 2.24303
Timestep Consumption Time: 2.43654
PPO Batch Consumption Time: 0.28374
Total Iteration Time: 4.67958

Cumulative Model Updates: 195,440
Cumulative Timesteps: 1,629,785,756

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.73675
Value Function Loss: 0.00948

Mean KL Divergence: 0.00369
SB3 Clip Fraction: 0.03651
Policy Update Magnitude: 0.29416
Value Function Update Magnitude: 0.17118

Collected Steps per Second: 22,279.11102
Overall Steps per Second: 10,651.08380

Timestep Collection Time: 2.24551
Timestep Consumption Time: 2.45148
PPO Batch Consumption Time: 0.28701
Total Iteration Time: 4.69699

Cumulative Model Updates: 195,446
Cumulative Timesteps: 1,629,835,784

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1629835784...
Checkpoint 1629835784 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.73152
Value Function Loss: 0.00979

Mean KL Divergence: 0.00356
SB3 Clip Fraction: 0.03471
Policy Update Magnitude: 0.30739
Value Function Update Magnitude: 0.19037

Collected Steps per Second: 22,106.04974
Overall Steps per Second: 10,519.87370

Timestep Collection Time: 2.26309
Timestep Consumption Time: 2.49248
PPO Batch Consumption Time: 0.29123
Total Iteration Time: 4.75557

Cumulative Model Updates: 195,452
Cumulative Timesteps: 1,629,885,812

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.72644
Value Function Loss: 0.01076

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.05006
Policy Update Magnitude: 0.34937
Value Function Update Magnitude: 0.22103

Collected Steps per Second: 22,147.78737
Overall Steps per Second: 10,534.92839

Timestep Collection Time: 2.25910
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.28876
Total Iteration Time: 4.74934

Cumulative Model Updates: 195,458
Cumulative Timesteps: 1,629,935,846

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1629935846...
Checkpoint 1629935846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.74705
Value Function Loss: 0.00986

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06355
Policy Update Magnitude: 0.36871
Value Function Update Magnitude: 0.24223

Collected Steps per Second: 22,841.07527
Overall Steps per Second: 10,657.17581

Timestep Collection Time: 2.18904
Timestep Consumption Time: 2.50264
PPO Batch Consumption Time: 0.28810
Total Iteration Time: 4.69167

Cumulative Model Updates: 195,464
Cumulative Timesteps: 1,629,985,846

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.77287
Value Function Loss: 0.00883

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.08081
Policy Update Magnitude: 0.32311
Value Function Update Magnitude: 0.21177

Collected Steps per Second: 23,153.51569
Overall Steps per Second: 10,704.08852

Timestep Collection Time: 2.16019
Timestep Consumption Time: 2.51242
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.67261

Cumulative Model Updates: 195,470
Cumulative Timesteps: 1,630,035,862

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1630035862...
Checkpoint 1630035862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.78438
Value Function Loss: 0.00863

Mean KL Divergence: 0.00477
SB3 Clip Fraction: 0.05369
Policy Update Magnitude: 0.29175
Value Function Update Magnitude: 0.24207

Collected Steps per Second: 22,553.55624
Overall Steps per Second: 10,604.22724

Timestep Collection Time: 2.21765
Timestep Consumption Time: 2.49895
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.71661

Cumulative Model Updates: 195,476
Cumulative Timesteps: 1,630,085,878

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.77228
Value Function Loss: 0.00855

Mean KL Divergence: 0.00496
SB3 Clip Fraction: 0.05743
Policy Update Magnitude: 0.28994
Value Function Update Magnitude: 0.26707

Collected Steps per Second: 22,457.00843
Overall Steps per Second: 10,589.17253

Timestep Collection Time: 2.22763
Timestep Consumption Time: 2.49663
PPO Batch Consumption Time: 0.29109
Total Iteration Time: 4.72426

Cumulative Model Updates: 195,482
Cumulative Timesteps: 1,630,135,904

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1630135904...
Checkpoint 1630135904 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.74751
Value Function Loss: 0.00901

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04843
Policy Update Magnitude: 0.27334
Value Function Update Magnitude: 0.24581

Collected Steps per Second: 22,881.80455
Overall Steps per Second: 10,750.09300

Timestep Collection Time: 2.18602
Timestep Consumption Time: 2.46697
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.65298

Cumulative Model Updates: 195,488
Cumulative Timesteps: 1,630,185,924

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.72584
Value Function Loss: 0.00929

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05705
Policy Update Magnitude: 0.27959
Value Function Update Magnitude: 0.19361

Collected Steps per Second: 22,135.15878
Overall Steps per Second: 10,673.07481

Timestep Collection Time: 2.25894
Timestep Consumption Time: 2.42593
PPO Batch Consumption Time: 0.27864
Total Iteration Time: 4.68487

Cumulative Model Updates: 195,494
Cumulative Timesteps: 1,630,235,926

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1630235926...
Checkpoint 1630235926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.73006
Value Function Loss: 0.00915

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05231
Policy Update Magnitude: 0.30029
Value Function Update Magnitude: 0.18284

Collected Steps per Second: 22,313.76986
Overall Steps per Second: 10,673.03168

Timestep Collection Time: 2.24184
Timestep Consumption Time: 2.44511
PPO Batch Consumption Time: 0.28247
Total Iteration Time: 4.68695

Cumulative Model Updates: 195,500
Cumulative Timesteps: 1,630,285,950

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.71511
Value Function Loss: 0.00967

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04728
Policy Update Magnitude: 0.32659
Value Function Update Magnitude: 0.19766

Collected Steps per Second: 22,207.55864
Overall Steps per Second: 10,548.34750

Timestep Collection Time: 2.25275
Timestep Consumption Time: 2.48999
PPO Batch Consumption Time: 0.29085
Total Iteration Time: 4.74273

Cumulative Model Updates: 195,506
Cumulative Timesteps: 1,630,335,978

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1630335978...
Checkpoint 1630335978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.73039
Value Function Loss: 0.01063

Mean KL Divergence: 0.00501
SB3 Clip Fraction: 0.05645
Policy Update Magnitude: 0.36612
Value Function Update Magnitude: 0.24750

Collected Steps per Second: 22,458.55450
Overall Steps per Second: 10,545.31647

Timestep Collection Time: 2.22757
Timestep Consumption Time: 2.51653
PPO Batch Consumption Time: 0.29048
Total Iteration Time: 4.74410

Cumulative Model Updates: 195,512
Cumulative Timesteps: 1,630,386,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.71066
Value Function Loss: 0.01332

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04635
Policy Update Magnitude: 0.42069
Value Function Update Magnitude: 0.25110

Collected Steps per Second: 21,445.38977
Overall Steps per Second: 10,453.10671

Timestep Collection Time: 2.33253
Timestep Consumption Time: 2.45284
PPO Batch Consumption Time: 0.29264
Total Iteration Time: 4.78537

Cumulative Model Updates: 195,518
Cumulative Timesteps: 1,630,436,028

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1630436028...
Checkpoint 1630436028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.69320
Value Function Loss: 0.01708

Mean KL Divergence: 0.01240
SB3 Clip Fraction: 0.16493
Policy Update Magnitude: 0.41989
Value Function Update Magnitude: 0.22145

Collected Steps per Second: 21,995.00578
Overall Steps per Second: 10,617.49483

Timestep Collection Time: 2.27379
Timestep Consumption Time: 2.43655
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.71034

Cumulative Model Updates: 195,524
Cumulative Timesteps: 1,630,486,040

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,058.53669
Policy Entropy: 3.69642
Value Function Loss: 0.01897

Mean KL Divergence: 0.01587
SB3 Clip Fraction: 0.18849
Policy Update Magnitude: 0.39375
Value Function Update Magnitude: 0.25364

Collected Steps per Second: 21,975.15513
Overall Steps per Second: 10,534.31722

Timestep Collection Time: 2.27612
Timestep Consumption Time: 2.47198
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.74810

Cumulative Model Updates: 195,530
Cumulative Timesteps: 1,630,536,058

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1630536058...
Checkpoint 1630536058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 339,834.43964
Policy Entropy: 3.66223
Value Function Loss: 0.02991

Mean KL Divergence: 0.03828
SB3 Clip Fraction: 0.30412
Policy Update Magnitude: 0.34993
Value Function Update Magnitude: 0.32574

Collected Steps per Second: 22,587.44244
Overall Steps per Second: 10,701.69210

Timestep Collection Time: 2.21388
Timestep Consumption Time: 2.45883
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.67272

Cumulative Model Updates: 195,536
Cumulative Timesteps: 1,630,586,064

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 43,842.14247
Policy Entropy: 3.67402
Value Function Loss: 0.05094

Mean KL Divergence: 0.02521
SB3 Clip Fraction: 0.24057
Policy Update Magnitude: 0.49829
Value Function Update Magnitude: 0.38358

Collected Steps per Second: 22,523.25393
Overall Steps per Second: 10,850.62725

Timestep Collection Time: 2.22019
Timestep Consumption Time: 2.38839
PPO Batch Consumption Time: 0.27650
Total Iteration Time: 4.60858

Cumulative Model Updates: 195,542
Cumulative Timesteps: 1,630,636,070

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1630636070...
Checkpoint 1630636070 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 384,273.43153
Policy Entropy: 3.65339
Value Function Loss: 0.10007

Mean KL Divergence: 0.02129
SB3 Clip Fraction: 0.23022
Policy Update Magnitude: 0.52290
Value Function Update Magnitude: 0.41086

Collected Steps per Second: 22,563.93468
Overall Steps per Second: 10,680.98886

Timestep Collection Time: 2.21646
Timestep Consumption Time: 2.46588
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.68234

Cumulative Model Updates: 195,548
Cumulative Timesteps: 1,630,686,082

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 335,628.49652
Policy Entropy: 3.65271
Value Function Loss: 0.09014

Mean KL Divergence: 0.02117
SB3 Clip Fraction: 0.21859
Policy Update Magnitude: 0.52986
Value Function Update Magnitude: 0.45298

Collected Steps per Second: 22,193.34838
Overall Steps per Second: 10,745.04885

Timestep Collection Time: 2.25356
Timestep Consumption Time: 2.40105
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.65461

Cumulative Model Updates: 195,554
Cumulative Timesteps: 1,630,736,096

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1630736096...
Checkpoint 1630736096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 112,060.67921
Policy Entropy: 3.66326
Value Function Loss: 0.09132

Mean KL Divergence: 0.01416
SB3 Clip Fraction: 0.16369
Policy Update Magnitude: 0.61381
Value Function Update Magnitude: 0.49946

Collected Steps per Second: 21,630.61305
Overall Steps per Second: 10,611.06234

Timestep Collection Time: 2.31283
Timestep Consumption Time: 2.40187
PPO Batch Consumption Time: 0.27756
Total Iteration Time: 4.71470

Cumulative Model Updates: 195,560
Cumulative Timesteps: 1,630,786,124

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,572.60433
Policy Entropy: 3.70024
Value Function Loss: 0.07987

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.12516
Policy Update Magnitude: 0.80725
Value Function Update Magnitude: 0.59922

Collected Steps per Second: 22,383.41338
Overall Steps per Second: 10,612.75744

Timestep Collection Time: 2.23496
Timestep Consumption Time: 2.47880
PPO Batch Consumption Time: 0.29207
Total Iteration Time: 4.71376

Cumulative Model Updates: 195,566
Cumulative Timesteps: 1,630,836,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1630836150...
Checkpoint 1630836150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,476.70239
Policy Entropy: 3.72919
Value Function Loss: 0.07199

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.11601
Policy Update Magnitude: 1.16256
Value Function Update Magnitude: 0.67406

Collected Steps per Second: 22,522.84096
Overall Steps per Second: 10,548.40531

Timestep Collection Time: 2.22086
Timestep Consumption Time: 2.52109
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.74195

Cumulative Model Updates: 195,572
Cumulative Timesteps: 1,630,886,170

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,833.84940
Policy Entropy: 3.75964
Value Function Loss: 0.06141

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 1.23688
Value Function Update Magnitude: 0.74850

Collected Steps per Second: 22,139.69863
Overall Steps per Second: 10,525.06295

Timestep Collection Time: 2.25875
Timestep Consumption Time: 2.49258
PPO Batch Consumption Time: 0.29222
Total Iteration Time: 4.75133

Cumulative Model Updates: 195,578
Cumulative Timesteps: 1,630,936,178

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1630936178...
Checkpoint 1630936178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,030.93167
Policy Entropy: 3.74824
Value Function Loss: 0.05810

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15056
Policy Update Magnitude: 1.03430
Value Function Update Magnitude: 0.74826

Collected Steps per Second: 22,791.22431
Overall Steps per Second: 10,767.19191

Timestep Collection Time: 2.19506
Timestep Consumption Time: 2.45128
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.64634

Cumulative Model Updates: 195,584
Cumulative Timesteps: 1,630,986,206

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 254.80105
Policy Entropy: 3.76186
Value Function Loss: 0.04877

Mean KL Divergence: 0.01299
SB3 Clip Fraction: 0.16082
Policy Update Magnitude: 0.76532
Value Function Update Magnitude: 0.69264

Collected Steps per Second: 23,117.15253
Overall Steps per Second: 10,777.39723

Timestep Collection Time: 2.16376
Timestep Consumption Time: 2.47743
PPO Batch Consumption Time: 0.29246
Total Iteration Time: 4.64119

Cumulative Model Updates: 195,590
Cumulative Timesteps: 1,631,036,226

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1631036226...
Checkpoint 1631036226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,335.77842
Policy Entropy: 3.74992
Value Function Loss: 0.04489

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13750
Policy Update Magnitude: 0.57709
Value Function Update Magnitude: 0.65742

Collected Steps per Second: 23,020.08469
Overall Steps per Second: 10,758.12193

Timestep Collection Time: 2.17262
Timestep Consumption Time: 2.47633
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.64895

Cumulative Model Updates: 195,596
Cumulative Timesteps: 1,631,086,240

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 746.16546
Policy Entropy: 3.77178
Value Function Loss: 0.03661

Mean KL Divergence: 0.00918
SB3 Clip Fraction: 0.12128
Policy Update Magnitude: 0.53254
Value Function Update Magnitude: 0.51772

Collected Steps per Second: 22,898.83644
Overall Steps per Second: 10,714.39209

Timestep Collection Time: 2.18360
Timestep Consumption Time: 2.48320
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.66681

Cumulative Model Updates: 195,602
Cumulative Timesteps: 1,631,136,242

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1631136242...
Checkpoint 1631136242 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 285.28301
Policy Entropy: 3.75341
Value Function Loss: 0.03484

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.15264
Policy Update Magnitude: 0.47975
Value Function Update Magnitude: 0.46464

Collected Steps per Second: 22,744.94539
Overall Steps per Second: 10,649.68236

Timestep Collection Time: 2.19908
Timestep Consumption Time: 2.49758
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.69667

Cumulative Model Updates: 195,608
Cumulative Timesteps: 1,631,186,260

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,822.66905
Policy Entropy: 3.76947
Value Function Loss: 0.03921

Mean KL Divergence: 0.01078
SB3 Clip Fraction: 0.13850
Policy Update Magnitude: 0.44015
Value Function Update Magnitude: 0.35628

Collected Steps per Second: 21,921.13773
Overall Steps per Second: 10,487.18704

Timestep Collection Time: 2.28163
Timestep Consumption Time: 2.48762
PPO Batch Consumption Time: 0.28826
Total Iteration Time: 4.76925

Cumulative Model Updates: 195,614
Cumulative Timesteps: 1,631,236,276

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1631236276...
Checkpoint 1631236276 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,313.02787
Policy Entropy: 3.75034
Value Function Loss: 0.03159

Mean KL Divergence: 0.02023
SB3 Clip Fraction: 0.23382
Policy Update Magnitude: 0.38662
Value Function Update Magnitude: 0.45565

Collected Steps per Second: 22,092.17392
Overall Steps per Second: 10,691.47556

Timestep Collection Time: 2.26415
Timestep Consumption Time: 2.41434
PPO Batch Consumption Time: 0.27653
Total Iteration Time: 4.67849

Cumulative Model Updates: 195,620
Cumulative Timesteps: 1,631,286,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,209.73124
Policy Entropy: 3.76122
Value Function Loss: 0.03209

Mean KL Divergence: 0.01731
SB3 Clip Fraction: 0.21222
Policy Update Magnitude: 0.40921
Value Function Update Magnitude: 0.65473

Collected Steps per Second: 22,291.09208
Overall Steps per Second: 10,591.09621

Timestep Collection Time: 2.24439
Timestep Consumption Time: 2.47938
PPO Batch Consumption Time: 0.28766
Total Iteration Time: 4.72378

Cumulative Model Updates: 195,626
Cumulative Timesteps: 1,631,336,326

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1631336326...
Checkpoint 1631336326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,169.84473
Policy Entropy: 3.75635
Value Function Loss: 0.02853

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.15674
Policy Update Magnitude: 0.44089
Value Function Update Magnitude: 0.83807

Collected Steps per Second: 22,474.98125
Overall Steps per Second: 10,597.62937

Timestep Collection Time: 2.22514
Timestep Consumption Time: 2.49384
PPO Batch Consumption Time: 0.28953
Total Iteration Time: 4.71898

Cumulative Model Updates: 195,632
Cumulative Timesteps: 1,631,386,336

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,007.94240
Policy Entropy: 3.74383
Value Function Loss: 0.02842

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13918
Policy Update Magnitude: 0.41569
Value Function Update Magnitude: 0.81908

Collected Steps per Second: 22,236.76756
Overall Steps per Second: 10,656.97768

Timestep Collection Time: 2.24952
Timestep Consumption Time: 2.44431
PPO Batch Consumption Time: 0.27744
Total Iteration Time: 4.69383

Cumulative Model Updates: 195,638
Cumulative Timesteps: 1,631,436,358

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1631436358...
Checkpoint 1631436358 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,642.36944
Policy Entropy: 3.77788
Value Function Loss: 0.02819

Mean KL Divergence: 0.01206
SB3 Clip Fraction: 0.15759
Policy Update Magnitude: 0.46605
Value Function Update Magnitude: 0.75141

Collected Steps per Second: 22,089.28433
Overall Steps per Second: 10,632.77490

Timestep Collection Time: 2.26427
Timestep Consumption Time: 2.43968
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.70395

Cumulative Model Updates: 195,644
Cumulative Timesteps: 1,631,486,374

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,096.18147
Policy Entropy: 3.80270
Value Function Loss: 0.03126

Mean KL Divergence: 0.01524
SB3 Clip Fraction: 0.18377
Policy Update Magnitude: 0.41597
Value Function Update Magnitude: 0.72304

Collected Steps per Second: 22,438.39533
Overall Steps per Second: 10,558.63267

Timestep Collection Time: 2.22957
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29252
Total Iteration Time: 4.73811

Cumulative Model Updates: 195,650
Cumulative Timesteps: 1,631,536,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1631536402...
Checkpoint 1631536402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 41,816.04633
Policy Entropy: 3.77836
Value Function Loss: 0.03296

Mean KL Divergence: 0.02113
SB3 Clip Fraction: 0.24011
Policy Update Magnitude: 0.32946
Value Function Update Magnitude: 0.78965

Collected Steps per Second: 22,657.94733
Overall Steps per Second: 10,613.73136

Timestep Collection Time: 2.20797
Timestep Consumption Time: 2.50555
PPO Batch Consumption Time: 0.29258
Total Iteration Time: 4.71352

Cumulative Model Updates: 195,656
Cumulative Timesteps: 1,631,586,430

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,165.32830
Policy Entropy: 3.76609
Value Function Loss: 0.03789

Mean KL Divergence: 0.02125
SB3 Clip Fraction: 0.21688
Policy Update Magnitude: 0.32952
Value Function Update Magnitude: 0.86329

Collected Steps per Second: 22,772.97461
Overall Steps per Second: 10,801.45412

Timestep Collection Time: 2.19620
Timestep Consumption Time: 2.43410
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.63030

Cumulative Model Updates: 195,662
Cumulative Timesteps: 1,631,636,444

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1631636444...
Checkpoint 1631636444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,535.00792
Policy Entropy: 3.72459
Value Function Loss: 0.04004

Mean KL Divergence: 0.01821
SB3 Clip Fraction: 0.20675
Policy Update Magnitude: 0.39531
Value Function Update Magnitude: 0.83741

Collected Steps per Second: 22,137.47506
Overall Steps per Second: 10,660.82516

Timestep Collection Time: 2.25943
Timestep Consumption Time: 2.43233
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.69176

Cumulative Model Updates: 195,668
Cumulative Timesteps: 1,631,686,462

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,058.76075
Policy Entropy: 3.70154
Value Function Loss: 0.05161

Mean KL Divergence: 0.01619
SB3 Clip Fraction: 0.18310
Policy Update Magnitude: 0.40567
Value Function Update Magnitude: 0.73135

Collected Steps per Second: 22,295.67429
Overall Steps per Second: 10,537.63826

Timestep Collection Time: 2.24313
Timestep Consumption Time: 2.50291
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.74604

Cumulative Model Updates: 195,674
Cumulative Timesteps: 1,631,736,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1631736474...
Checkpoint 1631736474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 5,589.18509
Policy Entropy: 3.74227
Value Function Loss: 0.06108

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.17564
Policy Update Magnitude: 0.40938
Value Function Update Magnitude: 0.60134

Collected Steps per Second: 22,105.77899
Overall Steps per Second: 10,683.54274

Timestep Collection Time: 2.26249
Timestep Consumption Time: 2.41892
PPO Batch Consumption Time: 0.28209
Total Iteration Time: 4.68141

Cumulative Model Updates: 195,680
Cumulative Timesteps: 1,631,786,488

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 119.79095
Policy Entropy: 3.78827
Value Function Loss: 0.06822

Mean KL Divergence: 0.01548
SB3 Clip Fraction: 0.16941
Policy Update Magnitude: 0.45645
Value Function Update Magnitude: 0.63100

Collected Steps per Second: 22,376.32751
Overall Steps per Second: 10,803.03037

Timestep Collection Time: 2.23540
Timestep Consumption Time: 2.39478
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.63018

Cumulative Model Updates: 195,686
Cumulative Timesteps: 1,631,836,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1631836508...
Checkpoint 1631836508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,279.28079
Policy Entropy: 3.79235
Value Function Loss: 0.07086

Mean KL Divergence: 0.01555
SB3 Clip Fraction: 0.15451
Policy Update Magnitude: 0.49900
Value Function Update Magnitude: 0.55719

Collected Steps per Second: 22,076.16679
Overall Steps per Second: 10,682.32650

Timestep Collection Time: 2.26588
Timestep Consumption Time: 2.41681
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.68269

Cumulative Model Updates: 195,692
Cumulative Timesteps: 1,631,886,530

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 91,307.98652
Policy Entropy: 3.77954
Value Function Loss: 0.06819

Mean KL Divergence: 0.01474
SB3 Clip Fraction: 0.16115
Policy Update Magnitude: 0.50062
Value Function Update Magnitude: 0.48934

Collected Steps per Second: 22,677.33717
Overall Steps per Second: 10,659.85782

Timestep Collection Time: 2.20493
Timestep Consumption Time: 2.48575
PPO Batch Consumption Time: 0.28881
Total Iteration Time: 4.69068

Cumulative Model Updates: 195,698
Cumulative Timesteps: 1,631,936,532

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1631936532...
Checkpoint 1631936532 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,310.81750
Policy Entropy: 3.75733
Value Function Loss: 0.06551

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.15783
Policy Update Magnitude: 0.49602
Value Function Update Magnitude: 0.48948

Collected Steps per Second: 22,643.00091
Overall Steps per Second: 10,845.11729

Timestep Collection Time: 2.20828
Timestep Consumption Time: 2.40228
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.61055

Cumulative Model Updates: 195,704
Cumulative Timesteps: 1,631,986,534

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,213.31625
Policy Entropy: 3.78568
Value Function Loss: 0.06292

Mean KL Divergence: 0.01344
SB3 Clip Fraction: 0.14362
Policy Update Magnitude: 0.56201
Value Function Update Magnitude: 0.60909

Collected Steps per Second: 22,602.75928
Overall Steps per Second: 10,716.58904

Timestep Collection Time: 2.21327
Timestep Consumption Time: 2.45482
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.66809

Cumulative Model Updates: 195,710
Cumulative Timesteps: 1,632,036,560

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1632036560...
Checkpoint 1632036560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,732.68182
Policy Entropy: 3.82558
Value Function Loss: 0.06577

Mean KL Divergence: 0.01277
SB3 Clip Fraction: 0.14430
Policy Update Magnitude: 0.60556
Value Function Update Magnitude: 0.73759

Collected Steps per Second: 22,734.85341
Overall Steps per Second: 10,867.81606

Timestep Collection Time: 2.19997
Timestep Consumption Time: 2.40224
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.60221

Cumulative Model Updates: 195,716
Cumulative Timesteps: 1,632,086,576

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,480.50977
Policy Entropy: 3.81273
Value Function Loss: 0.06061

Mean KL Divergence: 0.01256
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.61678
Value Function Update Magnitude: 0.73758

Collected Steps per Second: 22,415.35186
Overall Steps per Second: 10,723.40305

Timestep Collection Time: 2.23133
Timestep Consumption Time: 2.43286
PPO Batch Consumption Time: 0.28677
Total Iteration Time: 4.66419

Cumulative Model Updates: 195,722
Cumulative Timesteps: 1,632,136,592

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1632136592...
Checkpoint 1632136592 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,881.40580
Policy Entropy: 3.81018
Value Function Loss: 0.06431

Mean KL Divergence: 0.01248
SB3 Clip Fraction: 0.14262
Policy Update Magnitude: 0.59769
Value Function Update Magnitude: 0.76376

Collected Steps per Second: 22,293.32867
Overall Steps per Second: 10,778.08669

Timestep Collection Time: 2.24327
Timestep Consumption Time: 2.39670
PPO Batch Consumption Time: 0.27754
Total Iteration Time: 4.63997

Cumulative Model Updates: 195,728
Cumulative Timesteps: 1,632,186,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,803.48058
Policy Entropy: 3.82321
Value Function Loss: 0.05815

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.13943
Policy Update Magnitude: 0.62768
Value Function Update Magnitude: 0.81454

Collected Steps per Second: 22,032.54961
Overall Steps per Second: 10,705.56826

Timestep Collection Time: 2.27037
Timestep Consumption Time: 2.40215
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.67252

Cumulative Model Updates: 195,734
Cumulative Timesteps: 1,632,236,624

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1632236624...
Checkpoint 1632236624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 334.26706
Policy Entropy: 3.89880
Value Function Loss: 0.04987

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.12249
Policy Update Magnitude: 0.70935
Value Function Update Magnitude: 0.90926

Collected Steps per Second: 21,733.10753
Overall Steps per Second: 10,625.39051

Timestep Collection Time: 2.30064
Timestep Consumption Time: 2.40507
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.70571

Cumulative Model Updates: 195,740
Cumulative Timesteps: 1,632,286,624

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,303.45179
Policy Entropy: 3.95488
Value Function Loss: 0.04178

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.10968
Policy Update Magnitude: 0.81661
Value Function Update Magnitude: 0.87394

Collected Steps per Second: 22,320.90161
Overall Steps per Second: 10,721.16168

Timestep Collection Time: 2.24077
Timestep Consumption Time: 2.42440
PPO Batch Consumption Time: 0.27807
Total Iteration Time: 4.66517

Cumulative Model Updates: 195,746
Cumulative Timesteps: 1,632,336,640

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1632336640...
Checkpoint 1632336640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.59563
Policy Entropy: 3.99454
Value Function Loss: 0.03823

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.09598
Policy Update Magnitude: 0.87866
Value Function Update Magnitude: 0.87673

Collected Steps per Second: 22,188.06172
Overall Steps per Second: 10,662.40426

Timestep Collection Time: 2.25446
Timestep Consumption Time: 2.43698
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.69144

Cumulative Model Updates: 195,752
Cumulative Timesteps: 1,632,386,662

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 478.16197
Policy Entropy: 4.01844
Value Function Loss: 0.03415

Mean KL Divergence: 0.00729
SB3 Clip Fraction: 0.08871
Policy Update Magnitude: 0.93472
Value Function Update Magnitude: 0.85864

Collected Steps per Second: 23,028.94021
Overall Steps per Second: 10,847.65410

Timestep Collection Time: 2.17153
Timestep Consumption Time: 2.43850
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.61003

Cumulative Model Updates: 195,758
Cumulative Timesteps: 1,632,436,670

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1632436670...
Checkpoint 1632436670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,774.02544
Policy Entropy: 4.05924
Value Function Loss: 0.03085

Mean KL Divergence: 0.00665
SB3 Clip Fraction: 0.08032
Policy Update Magnitude: 0.95126
Value Function Update Magnitude: 0.92471

Collected Steps per Second: 22,761.72295
Overall Steps per Second: 10,680.91575

Timestep Collection Time: 2.19711
Timestep Consumption Time: 2.48507
PPO Batch Consumption Time: 0.28853
Total Iteration Time: 4.68218

Cumulative Model Updates: 195,764
Cumulative Timesteps: 1,632,486,680

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 724.57735
Policy Entropy: 4.08355
Value Function Loss: 0.02681

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06563
Policy Update Magnitude: 0.97658
Value Function Update Magnitude: 0.99909

Collected Steps per Second: 22,639.98167
Overall Steps per Second: 10,841.83144

Timestep Collection Time: 2.21016
Timestep Consumption Time: 2.40511
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.61527

Cumulative Model Updates: 195,770
Cumulative Timesteps: 1,632,536,718

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1632536718...
Checkpoint 1632536718 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.89619
Policy Entropy: 4.09996
Value Function Loss: 0.02470

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05707
Policy Update Magnitude: 0.98628
Value Function Update Magnitude: 1.04296

Collected Steps per Second: 22,276.05248
Overall Steps per Second: 10,716.15738

Timestep Collection Time: 2.24537
Timestep Consumption Time: 2.42216
PPO Batch Consumption Time: 0.29151
Total Iteration Time: 4.66753

Cumulative Model Updates: 195,776
Cumulative Timesteps: 1,632,586,736

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 690.03443
Policy Entropy: 4.11956
Value Function Loss: 0.02112

Mean KL Divergence: 0.00441
SB3 Clip Fraction: 0.05342
Policy Update Magnitude: 0.96662
Value Function Update Magnitude: 1.04930

Collected Steps per Second: 22,739.66593
Overall Steps per Second: 10,854.35197

Timestep Collection Time: 2.19915
Timestep Consumption Time: 2.40803
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.60718

Cumulative Model Updates: 195,782
Cumulative Timesteps: 1,632,636,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1632636744...
Checkpoint 1632636744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 213.65120
Policy Entropy: 4.16234
Value Function Loss: 0.01878

Mean KL Divergence: 0.00377
SB3 Clip Fraction: 0.04537
Policy Update Magnitude: 0.91744
Value Function Update Magnitude: 1.06897

Collected Steps per Second: 22,547.19487
Overall Steps per Second: 10,734.46276

Timestep Collection Time: 2.21890
Timestep Consumption Time: 2.44179
PPO Batch Consumption Time: 0.28366
Total Iteration Time: 4.66069

Cumulative Model Updates: 195,788
Cumulative Timesteps: 1,632,686,774

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.93971
Policy Entropy: 4.19156
Value Function Loss: 0.01678

Mean KL Divergence: 0.00332
SB3 Clip Fraction: 0.03972
Policy Update Magnitude: 0.86278
Value Function Update Magnitude: 1.00460

Collected Steps per Second: 22,313.47565
Overall Steps per Second: 10,816.08875

Timestep Collection Time: 2.24143
Timestep Consumption Time: 2.38261
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.62404

Cumulative Model Updates: 195,794
Cumulative Timesteps: 1,632,736,788

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1632736788...
Checkpoint 1632736788 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 955.97606
Policy Entropy: 4.17822
Value Function Loss: 0.01717

Mean KL Divergence: 0.00325
SB3 Clip Fraction: 0.03905
Policy Update Magnitude: 0.84448
Value Function Update Magnitude: 0.95651

Collected Steps per Second: 22,189.94100
Overall Steps per Second: 10,796.22179

Timestep Collection Time: 2.25435
Timestep Consumption Time: 2.37912
PPO Batch Consumption Time: 0.27613
Total Iteration Time: 4.63347

Cumulative Model Updates: 195,800
Cumulative Timesteps: 1,632,786,812

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 912.41957
Policy Entropy: 4.16203
Value Function Loss: 0.01790

Mean KL Divergence: 0.00333
SB3 Clip Fraction: 0.03941
Policy Update Magnitude: 0.84060
Value Function Update Magnitude: 0.95193

Collected Steps per Second: 22,755.28224
Overall Steps per Second: 10,840.17350

Timestep Collection Time: 2.19747
Timestep Consumption Time: 2.41537
PPO Batch Consumption Time: 0.28315
Total Iteration Time: 4.61284

Cumulative Model Updates: 195,806
Cumulative Timesteps: 1,632,836,816

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1632836816...
Checkpoint 1632836816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 701.19645
Policy Entropy: 4.17583
Value Function Loss: 0.01669

Mean KL Divergence: 0.00315
SB3 Clip Fraction: 0.03768
Policy Update Magnitude: 0.83984
Value Function Update Magnitude: 0.94682

Collected Steps per Second: 22,387.03244
Overall Steps per Second: 10,611.44995

Timestep Collection Time: 2.23388
Timestep Consumption Time: 2.47895
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.71283

Cumulative Model Updates: 195,812
Cumulative Timesteps: 1,632,886,826

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 482.84859
Policy Entropy: 4.18147
Value Function Loss: 0.01663

Mean KL Divergence: 0.00294
SB3 Clip Fraction: 0.03466
Policy Update Magnitude: 0.81353
Value Function Update Magnitude: 0.92440

Collected Steps per Second: 22,596.60941
Overall Steps per Second: 10,670.82951

Timestep Collection Time: 2.21325
Timestep Consumption Time: 2.47354
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.68680

Cumulative Model Updates: 195,818
Cumulative Timesteps: 1,632,936,838

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1632936838...
Checkpoint 1632936838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 408.26461
Policy Entropy: 4.17135
Value Function Loss: 0.01622

Mean KL Divergence: 0.00275
SB3 Clip Fraction: 0.03222
Policy Update Magnitude: 0.78730
Value Function Update Magnitude: 0.89195

Collected Steps per Second: 22,724.81953
Overall Steps per Second: 10,915.49831

Timestep Collection Time: 2.20121
Timestep Consumption Time: 2.38145
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.58266

Cumulative Model Updates: 195,824
Cumulative Timesteps: 1,632,986,860

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22.24592
Policy Entropy: 4.17974
Value Function Loss: 0.01594

Mean KL Divergence: 0.00268
SB3 Clip Fraction: 0.03182
Policy Update Magnitude: 0.77178
Value Function Update Magnitude: 0.86651

Collected Steps per Second: 23,169.30974
Overall Steps per Second: 10,939.32998

Timestep Collection Time: 2.15855
Timestep Consumption Time: 2.41322
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.57176

Cumulative Model Updates: 195,830
Cumulative Timesteps: 1,633,036,872

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1633036872...
Checkpoint 1633036872 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217.73185
Policy Entropy: 4.21889
Value Function Loss: 0.01368

Mean KL Divergence: 0.00247
SB3 Clip Fraction: 0.02995
Policy Update Magnitude: 0.74698
Value Function Update Magnitude: 0.84634

Collected Steps per Second: 22,741.57674
Overall Steps per Second: 10,682.85886

Timestep Collection Time: 2.19932
Timestep Consumption Time: 2.48257
PPO Batch Consumption Time: 0.29175
Total Iteration Time: 4.68189

Cumulative Model Updates: 195,836
Cumulative Timesteps: 1,633,086,888

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 645.16575
Policy Entropy: 4.25683
Value Function Loss: 0.01262

Mean KL Divergence: 0.00210
SB3 Clip Fraction: 0.02469
Policy Update Magnitude: 0.70360
Value Function Update Magnitude: 0.84000

Collected Steps per Second: 22,149.36126
Overall Steps per Second: 10,588.78671

Timestep Collection Time: 2.25830
Timestep Consumption Time: 2.46556
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.72387

Cumulative Model Updates: 195,842
Cumulative Timesteps: 1,633,136,908

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1633136908...
Checkpoint 1633136908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,301.60468
Policy Entropy: 4.22636
Value Function Loss: 0.01642

Mean KL Divergence: 0.00231
SB3 Clip Fraction: 0.02776
Policy Update Magnitude: 0.70044
Value Function Update Magnitude: 0.83706

Collected Steps per Second: 21,711.80680
Overall Steps per Second: 10,511.64024

Timestep Collection Time: 2.30418
Timestep Consumption Time: 2.45511
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.75930

Cumulative Model Updates: 195,848
Cumulative Timesteps: 1,633,186,936

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,502.47206
Policy Entropy: 4.18071
Value Function Loss: 0.02144

Mean KL Divergence: 0.00270
SB3 Clip Fraction: 0.03217
Policy Update Magnitude: 0.72843
Value Function Update Magnitude: 0.86660

Collected Steps per Second: 22,611.00644
Overall Steps per Second: 10,838.64827

Timestep Collection Time: 2.21140
Timestep Consumption Time: 2.40190
PPO Batch Consumption Time: 0.28793
Total Iteration Time: 4.61331

Cumulative Model Updates: 195,854
Cumulative Timesteps: 1,633,236,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1633236938...
Checkpoint 1633236938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87.34487
Policy Entropy: 4.12998
Value Function Loss: 0.02935

Mean KL Divergence: 0.00337
SB3 Clip Fraction: 0.04085
Policy Update Magnitude: 0.75099
Value Function Update Magnitude: 0.86139

Collected Steps per Second: 22,803.04684
Overall Steps per Second: 10,635.27367

Timestep Collection Time: 2.19339
Timestep Consumption Time: 2.50945
PPO Batch Consumption Time: 0.28765
Total Iteration Time: 4.70284

Cumulative Model Updates: 195,860
Cumulative Timesteps: 1,633,286,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 854.35254
Policy Entropy: 4.08259
Value Function Loss: 0.03547

Mean KL Divergence: 0.00387
SB3 Clip Fraction: 0.04653
Policy Update Magnitude: 0.74233
Value Function Update Magnitude: 0.71544

Collected Steps per Second: 22,943.99578
Overall Steps per Second: 10,843.92012

Timestep Collection Time: 2.18053
Timestep Consumption Time: 2.43312
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.61365

Cumulative Model Updates: 195,866
Cumulative Timesteps: 1,633,336,984

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1633336984...
Checkpoint 1633336984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,123.02419
Policy Entropy: 4.05280
Value Function Loss: 0.04126

Mean KL Divergence: 0.00367
SB3 Clip Fraction: 0.04469
Policy Update Magnitude: 0.72336
Value Function Update Magnitude: 0.53714

Collected Steps per Second: 22,450.27210
Overall Steps per Second: 10,700.98946

Timestep Collection Time: 2.22839
Timestep Consumption Time: 2.44669
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.67508

Cumulative Model Updates: 195,872
Cumulative Timesteps: 1,633,387,012

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26.87099
Policy Entropy: 4.03989
Value Function Loss: 0.03958

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.06284
Policy Update Magnitude: 0.68984
Value Function Update Magnitude: 0.59068

Collected Steps per Second: 22,890.92904
Overall Steps per Second: 10,836.64105

Timestep Collection Time: 2.18436
Timestep Consumption Time: 2.42980
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.61416

Cumulative Model Updates: 195,878
Cumulative Timesteps: 1,633,437,014

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1633437014...
Checkpoint 1633437014 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 260.06562
Policy Entropy: 4.00504
Value Function Loss: 0.03940

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.10884
Policy Update Magnitude: 0.62284
Value Function Update Magnitude: 0.61987

Collected Steps per Second: 22,601.35945
Overall Steps per Second: 10,677.88450

Timestep Collection Time: 2.21323
Timestep Consumption Time: 2.47141
PPO Batch Consumption Time: 0.29219
Total Iteration Time: 4.68464

Cumulative Model Updates: 195,884
Cumulative Timesteps: 1,633,487,036

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,297.67610
Policy Entropy: 3.95267
Value Function Loss: 0.04081

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.11991
Policy Update Magnitude: 0.45253
Value Function Update Magnitude: 0.48118

Collected Steps per Second: 22,687.84302
Overall Steps per Second: 10,874.63327

Timestep Collection Time: 2.20444
Timestep Consumption Time: 2.39470
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.59914

Cumulative Model Updates: 195,890
Cumulative Timesteps: 1,633,537,050

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1633537050...
Checkpoint 1633537050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,041.87918
Policy Entropy: 3.89310
Value Function Loss: 0.04430

Mean KL Divergence: 0.01213
SB3 Clip Fraction: 0.15099
Policy Update Magnitude: 0.37527
Value Function Update Magnitude: 0.47788

Collected Steps per Second: 22,414.85213
Overall Steps per Second: 10,782.03324

Timestep Collection Time: 2.23156
Timestep Consumption Time: 2.40764
PPO Batch Consumption Time: 0.27601
Total Iteration Time: 4.63920

Cumulative Model Updates: 195,896
Cumulative Timesteps: 1,633,587,070

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,329.47456
Policy Entropy: 3.85847
Value Function Loss: 0.04642

Mean KL Divergence: 0.01025
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.35867
Value Function Update Magnitude: 0.49368

Collected Steps per Second: 22,356.29245
Overall Steps per Second: 10,612.83444

Timestep Collection Time: 2.23785
Timestep Consumption Time: 2.47625
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.71410

Cumulative Model Updates: 195,902
Cumulative Timesteps: 1,633,637,100

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1633637100...
Checkpoint 1633637100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,679.02489
Policy Entropy: 3.86787
Value Function Loss: 0.04013

Mean KL Divergence: 0.01160
SB3 Clip Fraction: 0.14995
Policy Update Magnitude: 0.35910
Value Function Update Magnitude: 0.45127

Collected Steps per Second: 21,933.56614
Overall Steps per Second: 10,562.97434

Timestep Collection Time: 2.27998
Timestep Consumption Time: 2.45430
PPO Batch Consumption Time: 0.28898
Total Iteration Time: 4.73427

Cumulative Model Updates: 195,908
Cumulative Timesteps: 1,633,687,108

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,752.88193
Policy Entropy: 3.85504
Value Function Loss: 0.03336

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.32643
Value Function Update Magnitude: 0.42980

Collected Steps per Second: 22,434.11543
Overall Steps per Second: 10,799.90468

Timestep Collection Time: 2.22937
Timestep Consumption Time: 2.40159
PPO Batch Consumption Time: 0.27583
Total Iteration Time: 4.63097

Cumulative Model Updates: 195,914
Cumulative Timesteps: 1,633,737,122

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1633737122...
Checkpoint 1633737122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32,286.19458
Policy Entropy: 3.85836
Value Function Loss: 0.02853

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.31119
Value Function Update Magnitude: 0.44864

Collected Steps per Second: 22,716.92414
Overall Steps per Second: 10,587.61249

Timestep Collection Time: 2.20100
Timestep Consumption Time: 2.52150
PPO Batch Consumption Time: 0.29276
Total Iteration Time: 4.72250

Cumulative Model Updates: 195,920
Cumulative Timesteps: 1,633,787,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,588.03409
Policy Entropy: 3.81562
Value Function Loss: 0.03008

Mean KL Divergence: 0.01026
SB3 Clip Fraction: 0.13587
Policy Update Magnitude: 0.28640
Value Function Update Magnitude: 0.44702

Collected Steps per Second: 22,772.46083
Overall Steps per Second: 10,828.10755

Timestep Collection Time: 2.19642
Timestep Consumption Time: 2.42285
PPO Batch Consumption Time: 0.27851
Total Iteration Time: 4.61927

Cumulative Model Updates: 195,926
Cumulative Timesteps: 1,633,837,140

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1633837140...
Checkpoint 1633837140 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,898.51270
Policy Entropy: 3.81143
Value Function Loss: 0.03049

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13437
Policy Update Magnitude: 0.28971
Value Function Update Magnitude: 0.45346

Collected Steps per Second: 22,680.65420
Overall Steps per Second: 10,695.30835

Timestep Collection Time: 2.20567
Timestep Consumption Time: 2.47171
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.67738

Cumulative Model Updates: 195,932
Cumulative Timesteps: 1,633,887,166

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,168.22405
Policy Entropy: 3.79867
Value Function Loss: 0.03168

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.13604
Policy Update Magnitude: 0.31830
Value Function Update Magnitude: 0.44354

Collected Steps per Second: 21,490.75412
Overall Steps per Second: 10,453.33841

Timestep Collection Time: 2.32714
Timestep Consumption Time: 2.45717
PPO Batch Consumption Time: 0.27917
Total Iteration Time: 4.78431

Cumulative Model Updates: 195,938
Cumulative Timesteps: 1,633,937,178

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1633937178...
Checkpoint 1633937178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,919.12370
Policy Entropy: 3.78527
Value Function Loss: 0.03574

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13205
Policy Update Magnitude: 0.35978
Value Function Update Magnitude: 0.45923

Collected Steps per Second: 22,479.94944
Overall Steps per Second: 10,641.15128

Timestep Collection Time: 2.22474
Timestep Consumption Time: 2.47513
PPO Batch Consumption Time: 0.28537
Total Iteration Time: 4.69987

Cumulative Model Updates: 195,944
Cumulative Timesteps: 1,633,987,190

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 72,165.81602
Policy Entropy: 3.77126
Value Function Loss: 0.04167

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12837
Policy Update Magnitude: 0.40597
Value Function Update Magnitude: 0.56280

Collected Steps per Second: 22,529.65248
Overall Steps per Second: 10,631.08735

Timestep Collection Time: 2.22036
Timestep Consumption Time: 2.48508
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.70545

Cumulative Model Updates: 195,950
Cumulative Timesteps: 1,634,037,214

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1634037214...
Checkpoint 1634037214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,503.55529
Policy Entropy: 3.79449
Value Function Loss: 0.04255

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12908
Policy Update Magnitude: 0.45099
Value Function Update Magnitude: 0.61204

Collected Steps per Second: 22,199.73789
Overall Steps per Second: 10,523.68119

Timestep Collection Time: 2.25273
Timestep Consumption Time: 2.49941
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.75214

Cumulative Model Updates: 195,956
Cumulative Timesteps: 1,634,087,224

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,713.65740
Policy Entropy: 3.79796
Value Function Loss: 0.04148

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.44626
Value Function Update Magnitude: 0.58414

Collected Steps per Second: 21,964.47176
Overall Steps per Second: 10,472.71752

Timestep Collection Time: 2.27741
Timestep Consumption Time: 2.49901
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.77641

Cumulative Model Updates: 195,962
Cumulative Timesteps: 1,634,137,246

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1634137246...
Checkpoint 1634137246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,978.68939
Policy Entropy: 3.78947
Value Function Loss: 0.03340

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.40622
Value Function Update Magnitude: 0.56562

Collected Steps per Second: 22,186.63474
Overall Steps per Second: 10,611.19796

Timestep Collection Time: 2.25460
Timestep Consumption Time: 2.45948
PPO Batch Consumption Time: 0.28554
Total Iteration Time: 4.71408

Cumulative Model Updates: 195,968
Cumulative Timesteps: 1,634,187,268

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,978.68939
Policy Entropy: 3.73524
Value Function Loss: 0.03282

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14379
Policy Update Magnitude: 0.37148
Value Function Update Magnitude: 0.48680

Collected Steps per Second: 22,507.08815
Overall Steps per Second: 10,623.65084

Timestep Collection Time: 2.22170
Timestep Consumption Time: 2.48516
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.70686

Cumulative Model Updates: 195,974
Cumulative Timesteps: 1,634,237,272

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1634237272...
Checkpoint 1634237272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,978.68939
Policy Entropy: 3.71217
Value Function Loss: 0.02724

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14644
Policy Update Magnitude: 0.35442
Value Function Update Magnitude: 0.47075

Collected Steps per Second: 22,759.44348
Overall Steps per Second: 10,767.60217

Timestep Collection Time: 2.19715
Timestep Consumption Time: 2.44696
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.64412

Cumulative Model Updates: 195,980
Cumulative Timesteps: 1,634,287,278

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,978.68939
Policy Entropy: 3.69568
Value Function Loss: 0.02551

Mean KL Divergence: 0.01087
SB3 Clip Fraction: 0.14715
Policy Update Magnitude: 0.34342
Value Function Update Magnitude: 0.53766

Collected Steps per Second: 22,716.25739
Overall Steps per Second: 10,629.88317

Timestep Collection Time: 2.20168
Timestep Consumption Time: 2.50335
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.70504

Cumulative Model Updates: 195,986
Cumulative Timesteps: 1,634,337,292

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1634337292...
Checkpoint 1634337292 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,978.68939
Policy Entropy: 3.70923
Value Function Loss: 0.01940

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13848
Policy Update Magnitude: 0.34854
Value Function Update Magnitude: 0.42816

Collected Steps per Second: 21,984.03812
Overall Steps per Second: 10,665.97087

Timestep Collection Time: 2.27447
Timestep Consumption Time: 2.41352
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.68799

Cumulative Model Updates: 195,992
Cumulative Timesteps: 1,634,387,294

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,292.36121
Policy Entropy: 3.69212
Value Function Loss: 0.02175

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13520
Policy Update Magnitude: 0.33912
Value Function Update Magnitude: 0.35832

Collected Steps per Second: 22,066.45572
Overall Steps per Second: 10,834.40788

Timestep Collection Time: 2.26797
Timestep Consumption Time: 2.35121
PPO Batch Consumption Time: 0.27717
Total Iteration Time: 4.61917

Cumulative Model Updates: 195,998
Cumulative Timesteps: 1,634,437,340

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1634437340...
Checkpoint 1634437340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,292.36121
Policy Entropy: 3.70089
Value Function Loss: 0.02146

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13903
Policy Update Magnitude: 0.36883
Value Function Update Magnitude: 0.40147

Collected Steps per Second: 21,969.64009
Overall Steps per Second: 10,603.69408

Timestep Collection Time: 2.27623
Timestep Consumption Time: 2.43986
PPO Batch Consumption Time: 0.28455
Total Iteration Time: 4.71609

Cumulative Model Updates: 196,004
Cumulative Timesteps: 1,634,487,348

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,292.36121
Policy Entropy: 3.69289
Value Function Loss: 0.02323

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13984
Policy Update Magnitude: 0.37116
Value Function Update Magnitude: 0.41082

Collected Steps per Second: 22,776.08063
Overall Steps per Second: 10,889.09360

Timestep Collection Time: 2.19590
Timestep Consumption Time: 2.39714
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.59304

Cumulative Model Updates: 196,010
Cumulative Timesteps: 1,634,537,362

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1634537362...
Checkpoint 1634537362 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 40,292.36121
Policy Entropy: 3.71440
Value Function Loss: 0.01836

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13632
Policy Update Magnitude: 0.34264
Value Function Update Magnitude: 0.39671

Collected Steps per Second: 22,179.59887
Overall Steps per Second: 10,687.47467

Timestep Collection Time: 2.25468
Timestep Consumption Time: 2.42444
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.67912

Cumulative Model Updates: 196,016
Cumulative Timesteps: 1,634,587,370

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 235,499.25154
Policy Entropy: 3.71924
Value Function Loss: 0.02306

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13057
Policy Update Magnitude: 0.32880
Value Function Update Magnitude: 0.48600

Collected Steps per Second: 22,686.89335
Overall Steps per Second: 10,820.65461

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.41862
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.62412

Cumulative Model Updates: 196,022
Cumulative Timesteps: 1,634,637,406

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1634637406...
Checkpoint 1634637406 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,658.66568
Policy Entropy: 3.72718
Value Function Loss: 0.02470

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.35495
Value Function Update Magnitude: 0.54358

Collected Steps per Second: 22,369.54908
Overall Steps per Second: 10,705.95923

Timestep Collection Time: 2.23643
Timestep Consumption Time: 2.43648
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.67291

Cumulative Model Updates: 196,028
Cumulative Timesteps: 1,634,687,434

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 15,227.16974
Policy Entropy: 3.72105
Value Function Loss: 0.02825

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12753
Policy Update Magnitude: 0.37985
Value Function Update Magnitude: 0.51624

Collected Steps per Second: 21,784.17318
Overall Steps per Second: 10,477.37742

Timestep Collection Time: 2.29589
Timestep Consumption Time: 2.47764
PPO Batch Consumption Time: 0.28606
Total Iteration Time: 4.77352

Cumulative Model Updates: 196,034
Cumulative Timesteps: 1,634,737,448

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1634737448...
Checkpoint 1634737448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,765.24827
Policy Entropy: 3.72190
Value Function Loss: 0.02726

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.38479
Value Function Update Magnitude: 0.51847

Collected Steps per Second: 21,678.21272
Overall Steps per Second: 10,587.27465

Timestep Collection Time: 2.30803
Timestep Consumption Time: 2.41783
PPO Batch Consumption Time: 0.27709
Total Iteration Time: 4.72586

Cumulative Model Updates: 196,040
Cumulative Timesteps: 1,634,787,482

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,931.61723
Policy Entropy: 3.71498
Value Function Loss: 0.03126

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.38994
Value Function Update Magnitude: 0.48818

Collected Steps per Second: 22,569.67092
Overall Steps per Second: 10,593.08412

Timestep Collection Time: 2.21545
Timestep Consumption Time: 2.50480
PPO Batch Consumption Time: 0.29211
Total Iteration Time: 4.72025

Cumulative Model Updates: 196,046
Cumulative Timesteps: 1,634,837,484

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1634837484...
Checkpoint 1634837484 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 30,263.62091
Policy Entropy: 3.71493
Value Function Loss: 0.03261

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13183
Policy Update Magnitude: 0.39817
Value Function Update Magnitude: 0.45190

Collected Steps per Second: 22,842.13101
Overall Steps per Second: 10,738.47127

Timestep Collection Time: 2.18981
Timestep Consumption Time: 2.46821
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 4.65802

Cumulative Model Updates: 196,052
Cumulative Timesteps: 1,634,887,504

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93,751.37389
Policy Entropy: 3.70918
Value Function Loss: 0.03106

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.42615
Value Function Update Magnitude: 0.50637

Collected Steps per Second: 22,104.58211
Overall Steps per Second: 10,729.40201

Timestep Collection Time: 2.26306
Timestep Consumption Time: 2.39927
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.66233

Cumulative Model Updates: 196,058
Cumulative Timesteps: 1,634,937,528

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1634937528...
Checkpoint 1634937528 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,940.72565
Policy Entropy: 3.70444
Value Function Loss: 0.03110

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.43289
Value Function Update Magnitude: 0.52147

Collected Steps per Second: 21,672.35854
Overall Steps per Second: 10,652.52282

Timestep Collection Time: 2.30782
Timestep Consumption Time: 2.38740
PPO Batch Consumption Time: 0.28646
Total Iteration Time: 4.69523

Cumulative Model Updates: 196,064
Cumulative Timesteps: 1,634,987,544

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,940.72565
Policy Entropy: 3.70161
Value Function Loss: 0.02954

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12873
Policy Update Magnitude: 0.45367
Value Function Update Magnitude: 0.57095

Collected Steps per Second: 22,002.27662
Overall Steps per Second: 10,805.47736

Timestep Collection Time: 2.27504
Timestep Consumption Time: 2.35743
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.63247

Cumulative Model Updates: 196,070
Cumulative Timesteps: 1,635,037,600

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1635037600...
Checkpoint 1635037600 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,187.38908
Policy Entropy: 3.71639
Value Function Loss: 0.02717

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13454
Policy Update Magnitude: 0.46338
Value Function Update Magnitude: 0.58249

Collected Steps per Second: 22,121.04092
Overall Steps per Second: 10,748.52841

Timestep Collection Time: 2.26056
Timestep Consumption Time: 2.39180
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.65236

Cumulative Model Updates: 196,076
Cumulative Timesteps: 1,635,087,606

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,996.39298
Policy Entropy: 3.72490
Value Function Loss: 0.02210

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13363
Policy Update Magnitude: 0.43341
Value Function Update Magnitude: 0.52015

Collected Steps per Second: 22,122.00523
Overall Steps per Second: 10,568.60940

Timestep Collection Time: 2.26092
Timestep Consumption Time: 2.47159
PPO Batch Consumption Time: 0.29193
Total Iteration Time: 4.73251

Cumulative Model Updates: 196,082
Cumulative Timesteps: 1,635,137,622

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1635137622...
Checkpoint 1635137622 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31,996.39298
Policy Entropy: 3.70985
Value Function Loss: 0.02027

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13223
Policy Update Magnitude: 0.37787
Value Function Update Magnitude: 0.46601

Collected Steps per Second: 22,058.71066
Overall Steps per Second: 10,569.72085

Timestep Collection Time: 2.26713
Timestep Consumption Time: 2.46431
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.73144

Cumulative Model Updates: 196,088
Cumulative Timesteps: 1,635,187,632

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,996.39298
Policy Entropy: 3.69410
Value Function Loss: 0.01845

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13638
Policy Update Magnitude: 0.37278
Value Function Update Magnitude: 0.36432

Collected Steps per Second: 22,746.77130
Overall Steps per Second: 10,797.74107

Timestep Collection Time: 2.19935
Timestep Consumption Time: 2.43385
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.63319

Cumulative Model Updates: 196,094
Cumulative Timesteps: 1,635,237,660

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1635237660...
Checkpoint 1635237660 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,423.43817
Policy Entropy: 3.69443
Value Function Loss: 0.01906

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13386
Policy Update Magnitude: 0.37406
Value Function Update Magnitude: 0.32965

Collected Steps per Second: 22,329.14506
Overall Steps per Second: 10,749.72048

Timestep Collection Time: 2.24039
Timestep Consumption Time: 2.41331
PPO Batch Consumption Time: 0.27603
Total Iteration Time: 4.65370

Cumulative Model Updates: 196,100
Cumulative Timesteps: 1,635,287,686

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,188.27249
Policy Entropy: 3.70317
Value Function Loss: 0.01966

Mean KL Divergence: 0.01020
SB3 Clip Fraction: 0.13722
Policy Update Magnitude: 0.37629
Value Function Update Magnitude: 0.45969

Collected Steps per Second: 22,875.13009
Overall Steps per Second: 10,770.30251

Timestep Collection Time: 2.18657
Timestep Consumption Time: 2.45750
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.64407

Cumulative Model Updates: 196,106
Cumulative Timesteps: 1,635,337,704

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1635337704...
Checkpoint 1635337704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,468.44464
Policy Entropy: 3.69160
Value Function Loss: 0.02359

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.13647
Policy Update Magnitude: 0.40399
Value Function Update Magnitude: 0.52439

Collected Steps per Second: 22,136.46447
Overall Steps per Second: 10,641.07227

Timestep Collection Time: 2.25944
Timestep Consumption Time: 2.44084
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.70028

Cumulative Model Updates: 196,112
Cumulative Timesteps: 1,635,387,720

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,714.72692
Policy Entropy: 3.68048
Value Function Loss: 0.02881

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14228
Policy Update Magnitude: 0.46336
Value Function Update Magnitude: 0.42814

Collected Steps per Second: 22,374.49058
Overall Steps per Second: 10,528.78942

Timestep Collection Time: 2.23576
Timestep Consumption Time: 2.51540
PPO Batch Consumption Time: 0.29375
Total Iteration Time: 4.75116

Cumulative Model Updates: 196,118
Cumulative Timesteps: 1,635,437,744

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1635437744...
Checkpoint 1635437744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,497.44046
Policy Entropy: 3.67140
Value Function Loss: 0.03300

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13757
Policy Update Magnitude: 0.51923
Value Function Update Magnitude: 0.41801

Collected Steps per Second: 22,331.61637
Overall Steps per Second: 10,629.96601

Timestep Collection Time: 2.23898
Timestep Consumption Time: 2.46471
PPO Batch Consumption Time: 0.28435
Total Iteration Time: 4.70368

Cumulative Model Updates: 196,124
Cumulative Timesteps: 1,635,487,744

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 184,497.44046
Policy Entropy: 3.66350
Value Function Loss: 0.03767

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14719
Policy Update Magnitude: 0.53896
Value Function Update Magnitude: 0.41846

Collected Steps per Second: 22,652.71929
Overall Steps per Second: 10,649.74697

Timestep Collection Time: 2.20830
Timestep Consumption Time: 2.48890
PPO Batch Consumption Time: 0.28858
Total Iteration Time: 4.69720

Cumulative Model Updates: 196,130
Cumulative Timesteps: 1,635,537,768

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1635537768...
Checkpoint 1635537768 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,131.47815
Policy Entropy: 3.66897
Value Function Loss: 0.03476

Mean KL Divergence: 0.01063
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.57406
Value Function Update Magnitude: 0.46417

Collected Steps per Second: 22,855.84057
Overall Steps per Second: 10,859.62210

Timestep Collection Time: 2.18867
Timestep Consumption Time: 2.41775
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.60642

Cumulative Model Updates: 196,136
Cumulative Timesteps: 1,635,587,792

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,131.47815
Policy Entropy: 3.67729
Value Function Loss: 0.02958

Mean KL Divergence: 0.01108
SB3 Clip Fraction: 0.14157
Policy Update Magnitude: 0.54629
Value Function Update Magnitude: 0.47540

Collected Steps per Second: 22,652.58368
Overall Steps per Second: 10,658.45828

Timestep Collection Time: 2.20849
Timestep Consumption Time: 2.48525
PPO Batch Consumption Time: 0.28901
Total Iteration Time: 4.69374

Cumulative Model Updates: 196,142
Cumulative Timesteps: 1,635,637,820

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1635637820...
Checkpoint 1635637820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,131.47815
Policy Entropy: 3.69651
Value Function Loss: 0.02164

Mean KL Divergence: 0.01296
SB3 Clip Fraction: 0.16435
Policy Update Magnitude: 0.49620
Value Function Update Magnitude: 0.37595

Collected Steps per Second: 21,995.03455
Overall Steps per Second: 10,475.64064

Timestep Collection Time: 2.27524
Timestep Consumption Time: 2.50194
PPO Batch Consumption Time: 0.29102
Total Iteration Time: 4.77718

Cumulative Model Updates: 196,148
Cumulative Timesteps: 1,635,687,864

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,131.47815
Policy Entropy: 3.70737
Value Function Loss: 0.01808

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14245
Policy Update Magnitude: 0.45443
Value Function Update Magnitude: 0.27772

Collected Steps per Second: 22,044.76572
Overall Steps per Second: 10,474.60247

Timestep Collection Time: 2.26920
Timestep Consumption Time: 2.50654
PPO Batch Consumption Time: 0.29236
Total Iteration Time: 4.77574

Cumulative Model Updates: 196,154
Cumulative Timesteps: 1,635,737,888

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1635737888...
Checkpoint 1635737888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,131.47815
Policy Entropy: 3.71207
Value Function Loss: 0.01507

Mean KL Divergence: 0.00804
SB3 Clip Fraction: 0.10493
Policy Update Magnitude: 0.45399
Value Function Update Magnitude: 0.29474

Collected Steps per Second: 22,268.41001
Overall Steps per Second: 10,664.32595

Timestep Collection Time: 2.24542
Timestep Consumption Time: 2.44329
PPO Batch Consumption Time: 0.28241
Total Iteration Time: 4.68872

Cumulative Model Updates: 196,160
Cumulative Timesteps: 1,635,787,890

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,131.47815
Policy Entropy: 3.70363
Value Function Loss: 0.01556

Mean KL Divergence: 0.00607
SB3 Clip Fraction: 0.07328
Policy Update Magnitude: 0.45775
Value Function Update Magnitude: 0.40704

Collected Steps per Second: 22,292.80998
Overall Steps per Second: 10,434.21141

Timestep Collection Time: 2.24395
Timestep Consumption Time: 2.55028
PPO Batch Consumption Time: 0.29007
Total Iteration Time: 4.79423

Cumulative Model Updates: 196,166
Cumulative Timesteps: 1,635,837,914

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1635837914...
Checkpoint 1635837914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 192,131.47815
Policy Entropy: 3.69814
Value Function Loss: 0.01520

Mean KL Divergence: 0.00539
SB3 Clip Fraction: 0.06335
Policy Update Magnitude: 0.48775
Value Function Update Magnitude: 0.52321

Collected Steps per Second: 20,993.51506
Overall Steps per Second: 10,359.01367

Timestep Collection Time: 2.38216
Timestep Consumption Time: 2.44552
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.82768

Cumulative Model Updates: 196,172
Cumulative Timesteps: 1,635,887,924

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 192,131.47815
Policy Entropy: 3.70834
Value Function Loss: 0.01543

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05141
Policy Update Magnitude: 0.49933
Value Function Update Magnitude: 0.53256

Collected Steps per Second: 20,615.44005
Overall Steps per Second: 10,254.45744

Timestep Collection Time: 2.42595
Timestep Consumption Time: 2.45115
PPO Batch Consumption Time: 0.28584
Total Iteration Time: 4.87710

Cumulative Model Updates: 196,178
Cumulative Timesteps: 1,635,937,936

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1635937936...
Checkpoint 1635937936 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,532.48618
Policy Entropy: 3.72000
Value Function Loss: 0.01433

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05371
Policy Update Magnitude: 0.46618
Value Function Update Magnitude: 0.52643

Collected Steps per Second: 21,556.36508
Overall Steps per Second: 10,348.59195

Timestep Collection Time: 2.32145
Timestep Consumption Time: 2.51418
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.83563

Cumulative Model Updates: 196,184
Cumulative Timesteps: 1,635,987,978

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,532.48618
Policy Entropy: 3.74406
Value Function Loss: 0.01170

Mean KL Divergence: 0.00531
SB3 Clip Fraction: 0.06233
Policy Update Magnitude: 0.41738
Value Function Update Magnitude: 0.48282

Collected Steps per Second: 22,976.89687
Overall Steps per Second: 10,784.27404

Timestep Collection Time: 2.17610
Timestep Consumption Time: 2.46028
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.63638

Cumulative Model Updates: 196,190
Cumulative Timesteps: 1,636,037,978

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1636037978...
Checkpoint 1636037978 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,532.48618
Policy Entropy: 3.74377
Value Function Loss: 0.01117

Mean KL Divergence: 0.00520
SB3 Clip Fraction: 0.06210
Policy Update Magnitude: 0.37220
Value Function Update Magnitude: 0.37777

Collected Steps per Second: 22,685.44229
Overall Steps per Second: 10,679.92483

Timestep Collection Time: 2.20511
Timestep Consumption Time: 2.47881
PPO Batch Consumption Time: 0.29502
Total Iteration Time: 4.68393

Cumulative Model Updates: 196,196
Cumulative Timesteps: 1,636,088,002

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,532.48618
Policy Entropy: 3.74513
Value Function Loss: 0.01007

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.04978
Policy Update Magnitude: 0.34849
Value Function Update Magnitude: 0.29711

Collected Steps per Second: 22,915.87769
Overall Steps per Second: 10,857.72581

Timestep Collection Time: 2.18189
Timestep Consumption Time: 2.42312
PPO Batch Consumption Time: 0.27804
Total Iteration Time: 4.60502

Cumulative Model Updates: 196,202
Cumulative Timesteps: 1,636,138,002

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1636138002...
Checkpoint 1636138002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,532.48618
Policy Entropy: 3.74067
Value Function Loss: 0.00984

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04519
Policy Update Magnitude: 0.32505
Value Function Update Magnitude: 0.23541

Collected Steps per Second: 22,870.78573
Overall Steps per Second: 10,685.81607

Timestep Collection Time: 2.18672
Timestep Consumption Time: 2.49350
PPO Batch Consumption Time: 0.29261
Total Iteration Time: 4.68022

Cumulative Model Updates: 196,208
Cumulative Timesteps: 1,636,188,014

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,532.48618
Policy Entropy: 3.76047
Value Function Loss: 0.00989

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04866
Policy Update Magnitude: 0.33209
Value Function Update Magnitude: 0.21581

Collected Steps per Second: 22,849.05388
Overall Steps per Second: 10,831.63909

Timestep Collection Time: 2.18880
Timestep Consumption Time: 2.42841
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.61721

Cumulative Model Updates: 196,214
Cumulative Timesteps: 1,636,238,026

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1636238026...
Checkpoint 1636238026 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,532.48618
Policy Entropy: 3.74315
Value Function Loss: 0.01238

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.05052
Policy Update Magnitude: 0.38849
Value Function Update Magnitude: 0.34093

Collected Steps per Second: 22,081.62137
Overall Steps per Second: 10,650.10674

Timestep Collection Time: 2.26460
Timestep Consumption Time: 2.43075
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.69535

Cumulative Model Updates: 196,220
Cumulative Timesteps: 1,636,288,032

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 243,532.48618
Policy Entropy: 3.72883
Value Function Loss: 0.01366

Mean KL Divergence: 0.01439
SB3 Clip Fraction: 0.18040
Policy Update Magnitude: 0.40741
Value Function Update Magnitude: 0.45614

Collected Steps per Second: 21,859.16270
Overall Steps per Second: 10,495.12683

Timestep Collection Time: 2.28774
Timestep Consumption Time: 2.47714
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.76488

Cumulative Model Updates: 196,226
Cumulative Timesteps: 1,636,338,040

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1636338040...
Checkpoint 1636338040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 243,532.48618
Policy Entropy: 3.71584
Value Function Loss: 0.01788

Mean KL Divergence: 0.03046
SB3 Clip Fraction: 0.32053
Policy Update Magnitude: 0.38931
Value Function Update Magnitude: 0.49783

Collected Steps per Second: 22,241.46048
Overall Steps per Second: 10,638.73263

Timestep Collection Time: 2.24841
Timestep Consumption Time: 2.45215
PPO Batch Consumption Time: 0.28400
Total Iteration Time: 4.70056

Cumulative Model Updates: 196,232
Cumulative Timesteps: 1,636,388,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239,148.67023
Policy Entropy: 3.70532
Value Function Loss: 0.03558

Mean KL Divergence: 0.02480
SB3 Clip Fraction: 0.28019
Policy Update Magnitude: 0.39992
Value Function Update Magnitude: 0.54702

Collected Steps per Second: 21,550.90858
Overall Steps per Second: 10,582.36152

Timestep Collection Time: 2.32018
Timestep Consumption Time: 2.40485
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.72503

Cumulative Model Updates: 196,238
Cumulative Timesteps: 1,636,438,050

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1636438050...
Checkpoint 1636438050 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 280,230.29310
Policy Entropy: 3.70061
Value Function Loss: 0.06389

Mean KL Divergence: 0.02137
SB3 Clip Fraction: 0.23354
Policy Update Magnitude: 0.47320
Value Function Update Magnitude: 0.59598

Collected Steps per Second: 20,772.75807
Overall Steps per Second: 10,415.35200

Timestep Collection Time: 2.40709
Timestep Consumption Time: 2.39370
PPO Batch Consumption Time: 0.27865
Total Iteration Time: 4.80080

Cumulative Model Updates: 196,244
Cumulative Timesteps: 1,636,488,052

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195,792.49931
Policy Entropy: 3.69177
Value Function Loss: 0.08307

Mean KL Divergence: 0.02051
SB3 Clip Fraction: 0.21025
Policy Update Magnitude: 0.54451
Value Function Update Magnitude: 0.54253

Collected Steps per Second: 20,603.25666
Overall Steps per Second: 10,232.96404

Timestep Collection Time: 2.42719
Timestep Consumption Time: 2.45976
PPO Batch Consumption Time: 0.29121
Total Iteration Time: 4.88695

Cumulative Model Updates: 196,250
Cumulative Timesteps: 1,636,538,060

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1636538060...
Checkpoint 1636538060 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,491.63179
Policy Entropy: 3.70592
Value Function Loss: 0.08822

Mean KL Divergence: 0.01753
SB3 Clip Fraction: 0.18921
Policy Update Magnitude: 0.53468
Value Function Update Magnitude: 0.56837

Collected Steps per Second: 20,943.91047
Overall Steps per Second: 10,571.36852

Timestep Collection Time: 2.38828
Timestep Consumption Time: 2.34336
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.73165

Cumulative Model Updates: 196,256
Cumulative Timesteps: 1,636,588,080

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 70,550.07203
Policy Entropy: 3.73766
Value Function Loss: 0.08566

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.17309
Policy Update Magnitude: 0.54011
Value Function Update Magnitude: 0.56608

Collected Steps per Second: 22,108.02093
Overall Steps per Second: 10,805.57936

Timestep Collection Time: 2.26217
Timestep Consumption Time: 2.36618
PPO Batch Consumption Time: 0.27979
Total Iteration Time: 4.62835

Cumulative Model Updates: 196,262
Cumulative Timesteps: 1,636,638,092

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1636638092...
Checkpoint 1636638092 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 244,902.71788
Policy Entropy: 3.78745
Value Function Loss: 0.07970

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.14856
Policy Update Magnitude: 0.54976
Value Function Update Magnitude: 0.58990

Collected Steps per Second: 22,381.98097
Overall Steps per Second: 10,667.69933

Timestep Collection Time: 2.23412
Timestep Consumption Time: 2.45330
PPO Batch Consumption Time: 0.28466
Total Iteration Time: 4.68742

Cumulative Model Updates: 196,268
Cumulative Timesteps: 1,636,688,096

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,842.64129
Policy Entropy: 3.84094
Value Function Loss: 0.06973

Mean KL Divergence: 0.01174
SB3 Clip Fraction: 0.13677
Policy Update Magnitude: 0.58701
Value Function Update Magnitude: 0.72883

Collected Steps per Second: 22,706.43092
Overall Steps per Second: 10,824.95866

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.41713
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.61932

Cumulative Model Updates: 196,274
Cumulative Timesteps: 1,636,738,100

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1636738100...
Checkpoint 1636738100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 226,034.80116
Policy Entropy: 3.82460
Value Function Loss: 0.06524

Mean KL Divergence: 0.01258
SB3 Clip Fraction: 0.14012
Policy Update Magnitude: 0.60863
Value Function Update Magnitude: 0.65329

Collected Steps per Second: 22,658.83094
Overall Steps per Second: 10,761.37908

Timestep Collection Time: 2.20762
Timestep Consumption Time: 2.44067
PPO Batch Consumption Time: 0.28111
Total Iteration Time: 4.64829

Cumulative Model Updates: 196,280
Cumulative Timesteps: 1,636,788,122

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,759.52140
Policy Entropy: 3.79538
Value Function Loss: 0.06322

Mean KL Divergence: 0.01251
SB3 Clip Fraction: 0.14376
Policy Update Magnitude: 0.62495
Value Function Update Magnitude: 0.69577

Collected Steps per Second: 22,094.11453
Overall Steps per Second: 10,501.11141

Timestep Collection Time: 2.26341
Timestep Consumption Time: 2.49875
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.76216

Cumulative Model Updates: 196,286
Cumulative Timesteps: 1,636,838,130

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1636838130...
Checkpoint 1636838130 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,236.22572
Policy Entropy: 3.75010
Value Function Loss: 0.07157

Mean KL Divergence: 0.01305
SB3 Clip Fraction: 0.15592
Policy Update Magnitude: 0.62044
Value Function Update Magnitude: 0.65201

Collected Steps per Second: 22,267.52098
Overall Steps per Second: 10,554.72775

Timestep Collection Time: 2.24632
Timestep Consumption Time: 2.49279
PPO Batch Consumption Time: 0.28869
Total Iteration Time: 4.73911

Cumulative Model Updates: 196,292
Cumulative Timesteps: 1,636,888,150

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,190.33468
Policy Entropy: 3.77307
Value Function Loss: 0.06747

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.15019
Policy Update Magnitude: 0.63221
Value Function Update Magnitude: 0.51638

Collected Steps per Second: 22,356.00276
Overall Steps per Second: 10,576.60743

Timestep Collection Time: 2.23671
Timestep Consumption Time: 2.49108
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.72779

Cumulative Model Updates: 196,298
Cumulative Timesteps: 1,636,938,154

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1636938154...
Checkpoint 1636938154 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,089.59954
Policy Entropy: 3.79462
Value Function Loss: 0.06097

Mean KL Divergence: 0.01232
SB3 Clip Fraction: 0.14680
Policy Update Magnitude: 0.65222
Value Function Update Magnitude: 0.52837

Collected Steps per Second: 22,287.56375
Overall Steps per Second: 10,545.12370

Timestep Collection Time: 2.24448
Timestep Consumption Time: 2.49932
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.74380

Cumulative Model Updates: 196,304
Cumulative Timesteps: 1,636,988,178

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,843.03401
Policy Entropy: 3.78414
Value Function Loss: 0.06575

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.14865
Policy Update Magnitude: 0.70788
Value Function Update Magnitude: 0.49349

Collected Steps per Second: 22,708.70085
Overall Steps per Second: 10,628.30744

Timestep Collection Time: 2.20189
Timestep Consumption Time: 2.50272
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.70461

Cumulative Model Updates: 196,310
Cumulative Timesteps: 1,637,038,180

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1637038180...
Checkpoint 1637038180 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,906.04296
Policy Entropy: 3.82438
Value Function Loss: 0.06180

Mean KL Divergence: 0.01015
SB3 Clip Fraction: 0.12506
Policy Update Magnitude: 0.76786
Value Function Update Magnitude: 0.53027

Collected Steps per Second: 22,633.91970
Overall Steps per Second: 10,812.13054

Timestep Collection Time: 2.21013
Timestep Consumption Time: 2.41652
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.62666

Cumulative Model Updates: 196,316
Cumulative Timesteps: 1,637,088,204

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 247.66857
Policy Entropy: 3.85029
Value Function Loss: 0.05848

Mean KL Divergence: 0.00832
SB3 Clip Fraction: 0.10275
Policy Update Magnitude: 1.04515
Value Function Update Magnitude: 0.62446

Collected Steps per Second: 22,433.88707
Overall Steps per Second: 10,537.72585

Timestep Collection Time: 2.23011
Timestep Consumption Time: 2.51760
PPO Batch Consumption Time: 0.29253
Total Iteration Time: 4.74770

Cumulative Model Updates: 196,322
Cumulative Timesteps: 1,637,138,234

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1637138234...
Checkpoint 1637138234 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,044.29497
Policy Entropy: 3.86359
Value Function Loss: 0.05416

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.09528
Policy Update Magnitude: 1.13195
Value Function Update Magnitude: 0.64293

Collected Steps per Second: 22,595.18422
Overall Steps per Second: 10,645.65339

Timestep Collection Time: 2.21339
Timestep Consumption Time: 2.48449
PPO Batch Consumption Time: 0.29032
Total Iteration Time: 4.69788

Cumulative Model Updates: 196,328
Cumulative Timesteps: 1,637,188,246

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,193.03486
Policy Entropy: 3.79870
Value Function Loss: 0.05679

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.12495
Policy Update Magnitude: 0.97989
Value Function Update Magnitude: 0.57062

Collected Steps per Second: 22,901.71330
Overall Steps per Second: 10,856.14779

Timestep Collection Time: 2.18333
Timestep Consumption Time: 2.42254
PPO Batch Consumption Time: 0.27942
Total Iteration Time: 4.60587

Cumulative Model Updates: 196,334
Cumulative Timesteps: 1,637,238,248

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1637238248...
Checkpoint 1637238248 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,435.55137
Policy Entropy: 3.76842
Value Function Loss: 0.05710

Mean KL Divergence: 0.01703
SB3 Clip Fraction: 0.19485
Policy Update Magnitude: 0.75562
Value Function Update Magnitude: 0.51766

Collected Steps per Second: 22,654.27961
Overall Steps per Second: 10,674.98963

Timestep Collection Time: 2.20709
Timestep Consumption Time: 2.47676
PPO Batch Consumption Time: 0.28847
Total Iteration Time: 4.68385

Cumulative Model Updates: 196,340
Cumulative Timesteps: 1,637,288,248

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,578.37664
Policy Entropy: 3.80589
Value Function Loss: 0.06364

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13037
Policy Update Magnitude: 0.75384
Value Function Update Magnitude: 0.48904

Collected Steps per Second: 21,689.91095
Overall Steps per Second: 10,461.25378

Timestep Collection Time: 2.30586
Timestep Consumption Time: 2.47502
PPO Batch Consumption Time: 0.28621
Total Iteration Time: 4.78088

Cumulative Model Updates: 196,346
Cumulative Timesteps: 1,637,338,262

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1637338262...
Checkpoint 1637338262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,963.50748
Policy Entropy: 3.83363
Value Function Loss: 0.05868

Mean KL Divergence: 0.01370
SB3 Clip Fraction: 0.16256
Policy Update Magnitude: 0.73441
Value Function Update Magnitude: 0.45773

Collected Steps per Second: 22,175.87123
Overall Steps per Second: 10,648.06489

Timestep Collection Time: 2.25506
Timestep Consumption Time: 2.44138
PPO Batch Consumption Time: 0.28335
Total Iteration Time: 4.69644

Cumulative Model Updates: 196,352
Cumulative Timesteps: 1,637,388,270

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59.75584
Policy Entropy: 3.85828
Value Function Loss: 0.05574

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.10731
Policy Update Magnitude: 0.80691
Value Function Update Magnitude: 0.52660

Collected Steps per Second: 21,889.37314
Overall Steps per Second: 10,776.99324

Timestep Collection Time: 2.28458
Timestep Consumption Time: 2.35568
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.64026

Cumulative Model Updates: 196,358
Cumulative Timesteps: 1,637,438,278

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1637438278...
Checkpoint 1637438278 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.59488
Policy Entropy: 3.84294
Value Function Loss: 0.04281

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07984
Policy Update Magnitude: 0.79873
Value Function Update Magnitude: 0.49974

Collected Steps per Second: 21,812.04050
Overall Steps per Second: 10,752.29138

Timestep Collection Time: 2.29231
Timestep Consumption Time: 2.35786
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.65017

Cumulative Model Updates: 196,364
Cumulative Timesteps: 1,637,488,278

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.77193
Policy Entropy: 3.81485
Value Function Loss: 0.03084

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05810
Policy Update Magnitude: 0.67899
Value Function Update Magnitude: 0.45496

Collected Steps per Second: 21,952.42894
Overall Steps per Second: 10,652.60726

Timestep Collection Time: 2.27783
Timestep Consumption Time: 2.41623
PPO Batch Consumption Time: 0.28610
Total Iteration Time: 4.69406

Cumulative Model Updates: 196,370
Cumulative Timesteps: 1,637,538,282

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1637538282...
Checkpoint 1637538282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4.80119
Policy Entropy: 3.78540
Value Function Loss: 0.02041

Mean KL Divergence: 0.00537
SB3 Clip Fraction: 0.06377
Policy Update Magnitude: 0.55109
Value Function Update Magnitude: 0.40230

Collected Steps per Second: 22,102.11486
Overall Steps per Second: 10,440.27153

Timestep Collection Time: 2.26268
Timestep Consumption Time: 2.52743
PPO Batch Consumption Time: 0.29173
Total Iteration Time: 4.79011

Cumulative Model Updates: 196,376
Cumulative Timesteps: 1,637,588,292

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17.30492
Policy Entropy: 3.76740
Value Function Loss: 0.01814

Mean KL Divergence: 0.00475
SB3 Clip Fraction: 0.05341
Policy Update Magnitude: 0.46786
Value Function Update Magnitude: 0.36376

Collected Steps per Second: 22,558.29386
Overall Steps per Second: 10,802.67454

Timestep Collection Time: 2.21666
Timestep Consumption Time: 2.41220
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.62885

Cumulative Model Updates: 196,382
Cumulative Timesteps: 1,637,638,296

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1637638296...
Checkpoint 1637638296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18.67553
Policy Entropy: 3.76112
Value Function Loss: 0.01765

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05310
Policy Update Magnitude: 0.45974
Value Function Update Magnitude: 0.30791

Collected Steps per Second: 22,886.92155
Overall Steps per Second: 10,714.67421

Timestep Collection Time: 2.18588
Timestep Consumption Time: 2.48323
PPO Batch Consumption Time: 0.29201
Total Iteration Time: 4.66911

Cumulative Model Updates: 196,388
Cumulative Timesteps: 1,637,688,324

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18.67553
Policy Entropy: 3.74522
Value Function Loss: 0.01817

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12046
Policy Update Magnitude: 0.44419
Value Function Update Magnitude: 0.28330

Collected Steps per Second: 22,464.37811
Overall Steps per Second: 10,494.23469

Timestep Collection Time: 2.22690
Timestep Consumption Time: 2.54010
PPO Batch Consumption Time: 0.29038
Total Iteration Time: 4.76700

Cumulative Model Updates: 196,394
Cumulative Timesteps: 1,637,738,350

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1637738350...
Checkpoint 1637738350 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,368.16830
Policy Entropy: 3.74363
Value Function Loss: 0.02366

Mean KL Divergence: 0.01405
SB3 Clip Fraction: 0.18045
Policy Update Magnitude: 0.39949
Value Function Update Magnitude: 0.33430

Collected Steps per Second: 22,680.29819
Overall Steps per Second: 10,614.64428

Timestep Collection Time: 2.20482
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.29129
Total Iteration Time: 4.71104

Cumulative Model Updates: 196,400
Cumulative Timesteps: 1,637,788,356

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 52,368.16830
Policy Entropy: 3.71678
Value Function Loss: 0.03278

Mean KL Divergence: 0.01247
SB3 Clip Fraction: 0.16291
Policy Update Magnitude: 0.55657
Value Function Update Magnitude: 0.32164

Collected Steps per Second: 23,085.99119
Overall Steps per Second: 10,850.95686

Timestep Collection Time: 2.16660
Timestep Consumption Time: 2.44295
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.60955

Cumulative Model Updates: 196,406
Cumulative Timesteps: 1,637,838,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1637838374...
Checkpoint 1637838374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 52,368.16830
Policy Entropy: 3.73183
Value Function Loss: 0.03392

Mean KL Divergence: 0.01221
SB3 Clip Fraction: 0.15558
Policy Update Magnitude: 0.65688
Value Function Update Magnitude: 0.26815

Collected Steps per Second: 22,089.46915
Overall Steps per Second: 10,646.64379

Timestep Collection Time: 2.26479
Timestep Consumption Time: 2.43416
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.69895

Cumulative Model Updates: 196,412
Cumulative Timesteps: 1,637,888,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 118,495.04352
Policy Entropy: 3.72708
Value Function Loss: 0.03532

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.14862
Policy Update Magnitude: 0.64877
Value Function Update Magnitude: 0.25290

Collected Steps per Second: 21,683.16853
Overall Steps per Second: 10,573.83770

Timestep Collection Time: 2.30630
Timestep Consumption Time: 2.42310
PPO Batch Consumption Time: 0.27643
Total Iteration Time: 4.72941

Cumulative Model Updates: 196,418
Cumulative Timesteps: 1,637,938,410

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1637938410...
Checkpoint 1637938410 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51,007.69642
Policy Entropy: 3.74311
Value Function Loss: 0.02876

Mean KL Divergence: 0.01928
SB3 Clip Fraction: 0.21345
Policy Update Magnitude: 0.53975
Value Function Update Magnitude: 0.24555

Collected Steps per Second: 22,408.52422
Overall Steps per Second: 10,577.97813

Timestep Collection Time: 2.23138
Timestep Consumption Time: 2.49561
PPO Batch Consumption Time: 0.29317
Total Iteration Time: 4.72699

Cumulative Model Updates: 196,424
Cumulative Timesteps: 1,637,988,412

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 148,163.78612
Policy Entropy: 3.69393
Value Function Loss: 0.04057

Mean KL Divergence: 0.02005
SB3 Clip Fraction: 0.21782
Policy Update Magnitude: 0.53036
Value Function Update Magnitude: 0.25461

Collected Steps per Second: 22,250.42460
Overall Steps per Second: 10,538.76318

Timestep Collection Time: 2.24733
Timestep Consumption Time: 2.49744
PPO Batch Consumption Time: 0.29091
Total Iteration Time: 4.74477

Cumulative Model Updates: 196,430
Cumulative Timesteps: 1,638,038,416

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1638038416...
Checkpoint 1638038416 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 93,277.38278
Policy Entropy: 3.71578
Value Function Loss: 0.04369

Mean KL Divergence: 0.01712
SB3 Clip Fraction: 0.19520
Policy Update Magnitude: 0.63063
Value Function Update Magnitude: 0.40967

Collected Steps per Second: 22,016.18110
Overall Steps per Second: 10,515.53239

Timestep Collection Time: 2.27106
Timestep Consumption Time: 2.48381
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.75487

Cumulative Model Updates: 196,436
Cumulative Timesteps: 1,638,088,416

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 40,160.57292
Policy Entropy: 3.67948
Value Function Loss: 0.05433

Mean KL Divergence: 0.01301
SB3 Clip Fraction: 0.15739
Policy Update Magnitude: 0.68839
Value Function Update Magnitude: 0.46966

Collected Steps per Second: 22,159.96575
Overall Steps per Second: 10,487.49951

Timestep Collection Time: 2.25704
Timestep Consumption Time: 2.51206
PPO Batch Consumption Time: 0.28714
Total Iteration Time: 4.76911

Cumulative Model Updates: 196,442
Cumulative Timesteps: 1,638,138,432

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1638138432...
Checkpoint 1638138432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 22,572.85327
Policy Entropy: 3.72364
Value Function Loss: 0.05576

Mean KL Divergence: 0.01345
SB3 Clip Fraction: 0.15632
Policy Update Magnitude: 0.72738
Value Function Update Magnitude: 0.51160

Collected Steps per Second: 21,988.19357
Overall Steps per Second: 10,602.09802

Timestep Collection Time: 2.27395
Timestep Consumption Time: 2.44210
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.71605

Cumulative Model Updates: 196,448
Cumulative Timesteps: 1,638,188,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 20,290.92041
Policy Entropy: 3.71560
Value Function Loss: 0.05681

Mean KL Divergence: 0.01233
SB3 Clip Fraction: 0.14924
Policy Update Magnitude: 0.76271
Value Function Update Magnitude: 0.62655

Collected Steps per Second: 22,600.25609
Overall Steps per Second: 10,653.26179

Timestep Collection Time: 2.21254
Timestep Consumption Time: 2.48123
PPO Batch Consumption Time: 0.28775
Total Iteration Time: 4.69377

Cumulative Model Updates: 196,454
Cumulative Timesteps: 1,638,238,436

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1638238436...
Checkpoint 1638238436 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,722.36983
Policy Entropy: 3.70638
Value Function Loss: 0.05235

Mean KL Divergence: 0.01189
SB3 Clip Fraction: 0.14412
Policy Update Magnitude: 0.69348
Value Function Update Magnitude: 0.62573

Collected Steps per Second: 22,539.03836
Overall Steps per Second: 10,637.27256

Timestep Collection Time: 2.21873
Timestep Consumption Time: 2.48248
PPO Batch Consumption Time: 0.28867
Total Iteration Time: 4.70121

Cumulative Model Updates: 196,460
Cumulative Timesteps: 1,638,288,444

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,722.36983
Policy Entropy: 3.66618
Value Function Loss: 0.04712

Mean KL Divergence: 0.01166
SB3 Clip Fraction: 0.14495
Policy Update Magnitude: 0.61657
Value Function Update Magnitude: 0.54229

Collected Steps per Second: 22,541.04836
Overall Steps per Second: 10,719.38927

Timestep Collection Time: 2.21835
Timestep Consumption Time: 2.44647
PPO Batch Consumption Time: 0.28253
Total Iteration Time: 4.66482

Cumulative Model Updates: 196,466
Cumulative Timesteps: 1,638,338,448

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1638338448...
Checkpoint 1638338448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,722.36983
Policy Entropy: 3.67945
Value Function Loss: 0.04161

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.60825
Value Function Update Magnitude: 0.46368

Collected Steps per Second: 22,235.35646
Overall Steps per Second: 10,663.67478

Timestep Collection Time: 2.24993
Timestep Consumption Time: 2.44151
PPO Batch Consumption Time: 0.28326
Total Iteration Time: 4.69144

Cumulative Model Updates: 196,472
Cumulative Timesteps: 1,638,388,476

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,799.97652
Policy Entropy: 3.68429
Value Function Loss: 0.04361

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.15650
Policy Update Magnitude: 0.53043
Value Function Update Magnitude: 0.40360

Collected Steps per Second: 22,713.63197
Overall Steps per Second: 10,810.00877

Timestep Collection Time: 2.20229
Timestep Consumption Time: 2.42509
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.62738

Cumulative Model Updates: 196,478
Cumulative Timesteps: 1,638,438,498

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1638438498...
Checkpoint 1638438498 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,717.07266
Policy Entropy: 3.68890
Value Function Loss: 0.04914

Mean KL Divergence: 0.01172
SB3 Clip Fraction: 0.14929
Policy Update Magnitude: 0.46404
Value Function Update Magnitude: 0.30936

Collected Steps per Second: 21,615.62418
Overall Steps per Second: 10,450.96982

Timestep Collection Time: 2.31342
Timestep Consumption Time: 2.47140
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.78482

Cumulative Model Updates: 196,484
Cumulative Timesteps: 1,638,488,504

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,587.81395
Policy Entropy: 3.71036
Value Function Loss: 0.04286

Mean KL Divergence: 0.00747
SB3 Clip Fraction: 0.09725
Policy Update Magnitude: 0.58076
Value Function Update Magnitude: 0.31520

Collected Steps per Second: 21,914.55183
Overall Steps per Second: 10,730.58528

Timestep Collection Time: 2.28205
Timestep Consumption Time: 2.37846
PPO Batch Consumption Time: 0.28211
Total Iteration Time: 4.66051

Cumulative Model Updates: 196,490
Cumulative Timesteps: 1,638,538,514

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1638538514...
Checkpoint 1638538514 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,952.85946
Policy Entropy: 3.70982
Value Function Loss: 0.03791

Mean KL Divergence: 0.00790
SB3 Clip Fraction: 0.10105
Policy Update Magnitude: 0.68984
Value Function Update Magnitude: 0.45023

Collected Steps per Second: 21,519.49988
Overall Steps per Second: 10,689.37562

Timestep Collection Time: 2.32450
Timestep Consumption Time: 2.35510
PPO Batch Consumption Time: 0.27662
Total Iteration Time: 4.67960

Cumulative Model Updates: 196,496
Cumulative Timesteps: 1,638,588,536

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,835.28752
Policy Entropy: 3.73540
Value Function Loss: 0.02584

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07140
Policy Update Magnitude: 0.61320
Value Function Update Magnitude: 0.50458

Collected Steps per Second: 21,845.57791
Overall Steps per Second: 10,742.88380

Timestep Collection Time: 2.28962
Timestep Consumption Time: 2.36630
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.65592

Cumulative Model Updates: 196,502
Cumulative Timesteps: 1,638,638,554

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1638638554...
Checkpoint 1638638554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.95538
Policy Entropy: 3.74831
Value Function Loss: 0.01956

Mean KL Divergence: 0.00589
SB3 Clip Fraction: 0.07221
Policy Update Magnitude: 0.49330
Value Function Update Magnitude: 0.49236

Collected Steps per Second: 22,062.13535
Overall Steps per Second: 10,620.38337

Timestep Collection Time: 2.26750
Timestep Consumption Time: 2.44287
PPO Batch Consumption Time: 0.27769
Total Iteration Time: 4.71038

Cumulative Model Updates: 196,508
Cumulative Timesteps: 1,638,688,580

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.95538
Policy Entropy: 3.74005
Value Function Loss: 0.01669

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05297
Policy Update Magnitude: 0.44790
Value Function Update Magnitude: 0.40316

Collected Steps per Second: 22,722.22197
Overall Steps per Second: 10,697.27160

Timestep Collection Time: 2.20084
Timestep Consumption Time: 2.47400
PPO Batch Consumption Time: 0.28929
Total Iteration Time: 4.67484

Cumulative Model Updates: 196,514
Cumulative Timesteps: 1,638,738,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1638738588...
Checkpoint 1638738588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.95538
Policy Entropy: 3.74325
Value Function Loss: 0.01349

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05308
Policy Update Magnitude: 0.39586
Value Function Update Magnitude: 0.32003

Collected Steps per Second: 22,838.36731
Overall Steps per Second: 10,727.76829

Timestep Collection Time: 2.18947
Timestep Consumption Time: 2.47170
PPO Batch Consumption Time: 0.28679
Total Iteration Time: 4.66117

Cumulative Model Updates: 196,520
Cumulative Timesteps: 1,638,788,592

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,646.95538
Policy Entropy: 3.71745
Value Function Loss: 0.01398

Mean KL Divergence: 0.00554
SB3 Clip Fraction: 0.06807
Policy Update Magnitude: 0.35328
Value Function Update Magnitude: 0.27908

Collected Steps per Second: 22,884.85231
Overall Steps per Second: 10,662.35687

Timestep Collection Time: 2.18529
Timestep Consumption Time: 2.50504
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.69033

Cumulative Model Updates: 196,526
Cumulative Timesteps: 1,638,838,602

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1638838602...
Checkpoint 1638838602 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,423.03300
Policy Entropy: 3.71761
Value Function Loss: 0.01443

Mean KL Divergence: 0.00813
SB3 Clip Fraction: 0.10940
Policy Update Magnitude: 0.35663
Value Function Update Magnitude: 0.29882

Collected Steps per Second: 22,875.07692
Overall Steps per Second: 10,648.98696

Timestep Collection Time: 2.18578
Timestep Consumption Time: 2.50950
PPO Batch Consumption Time: 0.29225
Total Iteration Time: 4.69528

Cumulative Model Updates: 196,532
Cumulative Timesteps: 1,638,888,602

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,423.03300
Policy Entropy: 3.71149
Value Function Loss: 0.01493

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13297
Policy Update Magnitude: 0.31737
Value Function Update Magnitude: 0.32557

Collected Steps per Second: 22,721.90192
Overall Steps per Second: 10,816.77042

Timestep Collection Time: 2.20087
Timestep Consumption Time: 2.42232
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.62319

Cumulative Model Updates: 196,538
Cumulative Timesteps: 1,638,938,610

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1638938610...
Checkpoint 1638938610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 78,636.48853
Policy Entropy: 3.70018
Value Function Loss: 0.01492

Mean KL Divergence: 0.00950
SB3 Clip Fraction: 0.12334
Policy Update Magnitude: 0.29653
Value Function Update Magnitude: 0.43091

Collected Steps per Second: 22,055.35166
Overall Steps per Second: 10,676.23674

Timestep Collection Time: 2.26739
Timestep Consumption Time: 2.41666
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.68405

Cumulative Model Updates: 196,544
Cumulative Timesteps: 1,638,988,618

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,698.59438
Policy Entropy: 3.70783
Value Function Loss: 0.01517

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14468
Policy Update Magnitude: 0.28000
Value Function Update Magnitude: 0.44580

Collected Steps per Second: 22,500.57648
Overall Steps per Second: 10,618.10766

Timestep Collection Time: 2.22341
Timestep Consumption Time: 2.48816
PPO Batch Consumption Time: 0.28938
Total Iteration Time: 4.71157

Cumulative Model Updates: 196,550
Cumulative Timesteps: 1,639,038,646

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1639038646...
Checkpoint 1639038646 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212,582.29841
Policy Entropy: 3.71436
Value Function Loss: 0.01665

Mean KL Divergence: 0.01205
SB3 Clip Fraction: 0.15744
Policy Update Magnitude: 0.26724
Value Function Update Magnitude: 0.44392

Collected Steps per Second: 22,562.02324
Overall Steps per Second: 10,615.86648

Timestep Collection Time: 2.21709
Timestep Consumption Time: 2.49492
PPO Batch Consumption Time: 0.29215
Total Iteration Time: 4.71200

Cumulative Model Updates: 196,556
Cumulative Timesteps: 1,639,088,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,582.29841
Policy Entropy: 3.72211
Value Function Loss: 0.01543

Mean KL Divergence: 0.01132
SB3 Clip Fraction: 0.15069
Policy Update Magnitude: 0.26794
Value Function Update Magnitude: 0.41932

Collected Steps per Second: 21,795.26315
Overall Steps per Second: 10,765.36749

Timestep Collection Time: 2.29545
Timestep Consumption Time: 2.35186
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.64731

Cumulative Model Updates: 196,562
Cumulative Timesteps: 1,639,138,698

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1639138698...
Checkpoint 1639138698 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 212,582.29841
Policy Entropy: 3.70861
Value Function Loss: 0.01566

Mean KL Divergence: 0.01089
SB3 Clip Fraction: 0.14648
Policy Update Magnitude: 0.26660
Value Function Update Magnitude: 0.40424

Collected Steps per Second: 21,982.14444
Overall Steps per Second: 10,754.19692

Timestep Collection Time: 2.27539
Timestep Consumption Time: 2.37563
PPO Batch Consumption Time: 0.27619
Total Iteration Time: 4.65102

Cumulative Model Updates: 196,568
Cumulative Timesteps: 1,639,188,716

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 212,582.29841
Policy Entropy: 3.69973
Value Function Loss: 0.01576

Mean KL Divergence: 0.01044
SB3 Clip Fraction: 0.14056
Policy Update Magnitude: 0.30050
Value Function Update Magnitude: 0.42877

Collected Steps per Second: 22,130.29744
Overall Steps per Second: 10,564.92959

Timestep Collection Time: 2.26088
Timestep Consumption Time: 2.47497
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.73586

Cumulative Model Updates: 196,574
Cumulative Timesteps: 1,639,238,750

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1639238750...
Checkpoint 1639238750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273,059.57099
Policy Entropy: 3.67601
Value Function Loss: 0.02384

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13047
Policy Update Magnitude: 0.37351
Value Function Update Magnitude: 0.50510

Collected Steps per Second: 22,584.18335
Overall Steps per Second: 10,833.56936

Timestep Collection Time: 2.21500
Timestep Consumption Time: 2.40250
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.61750

Cumulative Model Updates: 196,580
Cumulative Timesteps: 1,639,288,774

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 258,820.48122
Policy Entropy: 3.69597
Value Function Loss: 0.03110

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13501
Policy Update Magnitude: 0.44037
Value Function Update Magnitude: 0.49289

Collected Steps per Second: 22,543.09490
Overall Steps per Second: 10,696.97242

Timestep Collection Time: 2.21904
Timestep Consumption Time: 2.45742
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.67646

Cumulative Model Updates: 196,586
Cumulative Timesteps: 1,639,338,798

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1639338798...
Checkpoint 1639338798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,552.28056
Policy Entropy: 3.69861
Value Function Loss: 0.03539

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13729
Policy Update Magnitude: 0.47109
Value Function Update Magnitude: 0.43182

Collected Steps per Second: 22,768.86201
Overall Steps per Second: 10,740.60612

Timestep Collection Time: 2.19730
Timestep Consumption Time: 2.46072
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.65802

Cumulative Model Updates: 196,592
Cumulative Timesteps: 1,639,388,828

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.72531
Value Function Loss: 0.03045

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.47246
Value Function Update Magnitude: 0.46333

Collected Steps per Second: 22,977.45483
Overall Steps per Second: 10,662.72997

Timestep Collection Time: 2.17613
Timestep Consumption Time: 2.51329
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.68942

Cumulative Model Updates: 196,598
Cumulative Timesteps: 1,639,438,830

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1639438830...
Checkpoint 1639438830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.69908
Value Function Loss: 0.02749

Mean KL Divergence: 0.01081
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.47607
Value Function Update Magnitude: 0.46480

Collected Steps per Second: 22,154.56906
Overall Steps per Second: 10,703.39913

Timestep Collection Time: 2.25687
Timestep Consumption Time: 2.41454
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.67141

Cumulative Model Updates: 196,604
Cumulative Timesteps: 1,639,488,830

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.71320
Value Function Loss: 0.02277

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.46002
Value Function Update Magnitude: 0.44162

Collected Steps per Second: 22,281.68976
Overall Steps per Second: 10,593.00921

Timestep Collection Time: 2.24462
Timestep Consumption Time: 2.47679
PPO Batch Consumption Time: 0.28792
Total Iteration Time: 4.72142

Cumulative Model Updates: 196,610
Cumulative Timesteps: 1,639,538,844

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1639538844...
Checkpoint 1639538844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.68878
Value Function Loss: 0.02109

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.14176
Policy Update Magnitude: 0.41084
Value Function Update Magnitude: 0.39301

Collected Steps per Second: 22,388.71080
Overall Steps per Second: 10,649.56400

Timestep Collection Time: 2.23389
Timestep Consumption Time: 2.46245
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.69634

Cumulative Model Updates: 196,616
Cumulative Timesteps: 1,639,588,858

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.69166
Value Function Loss: 0.01725

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13609
Policy Update Magnitude: 0.38264
Value Function Update Magnitude: 0.32327

Collected Steps per Second: 22,588.94748
Overall Steps per Second: 10,646.63089

Timestep Collection Time: 2.21489
Timestep Consumption Time: 2.48444
PPO Batch Consumption Time: 0.28483
Total Iteration Time: 4.69933

Cumulative Model Updates: 196,622
Cumulative Timesteps: 1,639,638,890

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1639638890...
Checkpoint 1639638890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.69834
Value Function Loss: 0.01864

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13028
Policy Update Magnitude: 0.35668
Value Function Update Magnitude: 0.28457

Collected Steps per Second: 21,248.97308
Overall Steps per Second: 10,623.00651

Timestep Collection Time: 2.35353
Timestep Consumption Time: 2.35418
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.70771

Cumulative Model Updates: 196,628
Cumulative Timesteps: 1,639,688,900

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.69448
Value Function Loss: 0.01841

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.34520
Value Function Update Magnitude: 0.30744

Collected Steps per Second: 21,914.18491
Overall Steps per Second: 10,577.13381

Timestep Collection Time: 2.28263
Timestep Consumption Time: 2.44663
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.72926

Cumulative Model Updates: 196,634
Cumulative Timesteps: 1,639,738,922

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1639738922...
Checkpoint 1639738922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.70008
Value Function Loss: 0.01907

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13129
Policy Update Magnitude: 0.36119
Value Function Update Magnitude: 0.32179

Collected Steps per Second: 21,987.19254
Overall Steps per Second: 10,580.19145

Timestep Collection Time: 2.27460
Timestep Consumption Time: 2.45235
PPO Batch Consumption Time: 0.28686
Total Iteration Time: 4.72695

Cumulative Model Updates: 196,640
Cumulative Timesteps: 1,639,788,934

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.68260
Value Function Loss: 0.02219

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13175
Policy Update Magnitude: 0.38598
Value Function Update Magnitude: 0.34417

Collected Steps per Second: 22,901.52094
Overall Steps per Second: 10,882.59485

Timestep Collection Time: 2.18352
Timestep Consumption Time: 2.41152
PPO Batch Consumption Time: 0.27936
Total Iteration Time: 4.59504

Cumulative Model Updates: 196,646
Cumulative Timesteps: 1,639,838,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1639838940...
Checkpoint 1639838940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.69641
Value Function Loss: 0.02258

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.42327
Value Function Update Magnitude: 0.36781

Collected Steps per Second: 22,566.23474
Overall Steps per Second: 10,646.52752

Timestep Collection Time: 2.21659
Timestep Consumption Time: 2.48166
PPO Batch Consumption Time: 0.29209
Total Iteration Time: 4.69825

Cumulative Model Updates: 196,652
Cumulative Timesteps: 1,639,888,960

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.68161
Value Function Loss: 0.02422

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13053
Policy Update Magnitude: 0.41435
Value Function Update Magnitude: 0.33783

Collected Steps per Second: 22,992.93147
Overall Steps per Second: 10,879.64620

Timestep Collection Time: 2.17641
Timestep Consumption Time: 2.42319
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.59960

Cumulative Model Updates: 196,658
Cumulative Timesteps: 1,639,939,002

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1639939002...
Checkpoint 1639939002 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.70834
Value Function Loss: 0.02070

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13155
Policy Update Magnitude: 0.39042
Value Function Update Magnitude: 0.34785

Collected Steps per Second: 22,643.02469
Overall Steps per Second: 10,727.49455

Timestep Collection Time: 2.20898
Timestep Consumption Time: 2.45362
PPO Batch Consumption Time: 0.28353
Total Iteration Time: 4.66260

Cumulative Model Updates: 196,664
Cumulative Timesteps: 1,639,989,020

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.69627
Value Function Loss: 0.01869

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13447
Policy Update Magnitude: 0.37055
Value Function Update Magnitude: 0.37467

Collected Steps per Second: 22,794.94406
Overall Steps per Second: 10,806.60166

Timestep Collection Time: 2.19356
Timestep Consumption Time: 2.43343
PPO Batch Consumption Time: 0.27759
Total Iteration Time: 4.62699

Cumulative Model Updates: 196,670
Cumulative Timesteps: 1,640,039,022

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1640039022...
Checkpoint 1640039022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.72002
Value Function Loss: 0.01594

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12776
Policy Update Magnitude: 0.34717
Value Function Update Magnitude: 0.38246

Collected Steps per Second: 22,232.46489
Overall Steps per Second: 10,679.75475

Timestep Collection Time: 2.24941
Timestep Consumption Time: 2.43328
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.68269

Cumulative Model Updates: 196,676
Cumulative Timesteps: 1,640,089,032

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.71244
Value Function Loss: 0.01537

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12529
Policy Update Magnitude: 0.31145
Value Function Update Magnitude: 0.30577

Collected Steps per Second: 22,029.18896
Overall Steps per Second: 10,497.03527

Timestep Collection Time: 2.27035
Timestep Consumption Time: 2.49423
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.76458

Cumulative Model Updates: 196,682
Cumulative Timesteps: 1,640,139,046

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1640139046...
Checkpoint 1640139046 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.70837
Value Function Loss: 0.01812

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12772
Policy Update Magnitude: 0.28798
Value Function Update Magnitude: 0.22658

Collected Steps per Second: 22,195.23525
Overall Steps per Second: 10,585.17901

Timestep Collection Time: 2.25319
Timestep Consumption Time: 2.47134
PPO Batch Consumption Time: 0.28423
Total Iteration Time: 4.72453

Cumulative Model Updates: 196,688
Cumulative Timesteps: 1,640,189,056

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.69921
Value Function Loss: 0.01808

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.30844
Value Function Update Magnitude: 0.23926

Collected Steps per Second: 22,788.68812
Overall Steps per Second: 10,611.78784

Timestep Collection Time: 2.19433
Timestep Consumption Time: 2.51797
PPO Batch Consumption Time: 0.28920
Total Iteration Time: 4.71231

Cumulative Model Updates: 196,694
Cumulative Timesteps: 1,640,239,062

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1640239062...
Checkpoint 1640239062 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.69678
Value Function Loss: 0.02005

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12549
Policy Update Magnitude: 0.33597
Value Function Update Magnitude: 0.26966

Collected Steps per Second: 22,456.07620
Overall Steps per Second: 10,528.72630

Timestep Collection Time: 2.22719
Timestep Consumption Time: 2.52305
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.75024

Cumulative Model Updates: 196,700
Cumulative Timesteps: 1,640,289,076

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.68329
Value Function Loss: 0.01778

Mean KL Divergence: 0.00935
SB3 Clip Fraction: 0.12453
Policy Update Magnitude: 0.37066
Value Function Update Magnitude: 0.36948

Collected Steps per Second: 22,692.98974
Overall Steps per Second: 10,834.60592

Timestep Collection Time: 2.20491
Timestep Consumption Time: 2.41326
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.61817

Cumulative Model Updates: 196,706
Cumulative Timesteps: 1,640,339,112

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1640339112...
Checkpoint 1640339112 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.68971
Value Function Loss: 0.01663

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13191
Policy Update Magnitude: 0.38018
Value Function Update Magnitude: 0.48059

Collected Steps per Second: 22,401.32632
Overall Steps per Second: 10,756.80038

Timestep Collection Time: 2.23246
Timestep Consumption Time: 2.41669
PPO Batch Consumption Time: 0.27614
Total Iteration Time: 4.64915

Cumulative Model Updates: 196,712
Cumulative Timesteps: 1,640,389,122

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.69563
Value Function Loss: 0.01509

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13264
Policy Update Magnitude: 0.36869
Value Function Update Magnitude: 0.46126

Collected Steps per Second: 22,827.72301
Overall Steps per Second: 10,817.70093

Timestep Collection Time: 2.19032
Timestep Consumption Time: 2.43173
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.62205

Cumulative Model Updates: 196,718
Cumulative Timesteps: 1,640,439,122

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1640439122...
Checkpoint 1640439122 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 132,193.53379
Policy Entropy: 3.69173
Value Function Loss: 0.01854

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12509
Policy Update Magnitude: 0.38614
Value Function Update Magnitude: 0.42278

Collected Steps per Second: 22,158.11326
Overall Steps per Second: 10,672.45078

Timestep Collection Time: 2.25813
Timestep Consumption Time: 2.43020
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.68833

Cumulative Model Updates: 196,724
Cumulative Timesteps: 1,640,489,158

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 236,586.28018
Policy Entropy: 3.69077
Value Function Loss: 0.01939

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13126
Policy Update Magnitude: 0.46117
Value Function Update Magnitude: 0.53252

Collected Steps per Second: 21,669.96466
Overall Steps per Second: 10,597.49494

Timestep Collection Time: 2.30873
Timestep Consumption Time: 2.41220
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.72093

Cumulative Model Updates: 196,730
Cumulative Timesteps: 1,640,539,188

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1640539188...
Checkpoint 1640539188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 236,586.28018
Policy Entropy: 3.67372
Value Function Loss: 0.02148

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13423
Policy Update Magnitude: 0.48707
Value Function Update Magnitude: 0.52089

Collected Steps per Second: 21,781.26360
Overall Steps per Second: 10,484.15380

Timestep Collection Time: 2.29583
Timestep Consumption Time: 2.47385
PPO Batch Consumption Time: 0.29013
Total Iteration Time: 4.76967

Cumulative Model Updates: 196,736
Cumulative Timesteps: 1,640,589,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.67240
Value Function Loss: 0.02060

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13931
Policy Update Magnitude: 0.46983
Value Function Update Magnitude: 0.41677

Collected Steps per Second: 21,957.51414
Overall Steps per Second: 10,524.23908

Timestep Collection Time: 2.27712
Timestep Consumption Time: 2.47381
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.75094

Cumulative Model Updates: 196,742
Cumulative Timesteps: 1,640,639,194

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1640639194...
Checkpoint 1640639194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.67493
Value Function Loss: 0.01863

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13709
Policy Update Magnitude: 0.42930
Value Function Update Magnitude: 0.41624

Collected Steps per Second: 22,360.72493
Overall Steps per Second: 10,639.20302

Timestep Collection Time: 2.23741
Timestep Consumption Time: 2.46501
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.70242

Cumulative Model Updates: 196,748
Cumulative Timesteps: 1,640,689,224

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.69075
Value Function Loss: 0.01598

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.12768
Policy Update Magnitude: 0.39382
Value Function Update Magnitude: 0.47644

Collected Steps per Second: 22,390.15510
Overall Steps per Second: 10,621.20746

Timestep Collection Time: 2.23339
Timestep Consumption Time: 2.47474
PPO Batch Consumption Time: 0.28655
Total Iteration Time: 4.70813

Cumulative Model Updates: 196,754
Cumulative Timesteps: 1,640,739,230

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1640739230...
Checkpoint 1640739230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.69161
Value Function Loss: 0.01488

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12900
Policy Update Magnitude: 0.36102
Value Function Update Magnitude: 0.44681

Collected Steps per Second: 22,146.61349
Overall Steps per Second: 10,516.04558

Timestep Collection Time: 2.25867
Timestep Consumption Time: 2.49806
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.75673

Cumulative Model Updates: 196,760
Cumulative Timesteps: 1,640,789,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.69378
Value Function Loss: 0.01591

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.35293
Value Function Update Magnitude: 0.44703

Collected Steps per Second: 22,586.92218
Overall Steps per Second: 10,718.32177

Timestep Collection Time: 2.21376
Timestep Consumption Time: 2.45134
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.66510

Cumulative Model Updates: 196,766
Cumulative Timesteps: 1,640,839,254

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1640839254...
Checkpoint 1640839254 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.68928
Value Function Loss: 0.01893

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12540
Policy Update Magnitude: 0.38716
Value Function Update Magnitude: 0.42304

Collected Steps per Second: 22,599.07321
Overall Steps per Second: 10,700.56944

Timestep Collection Time: 2.21363
Timestep Consumption Time: 2.46145
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.67508

Cumulative Model Updates: 196,772
Cumulative Timesteps: 1,640,889,280

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.67273
Value Function Loss: 0.02068

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.40585
Value Function Update Magnitude: 0.40236

Collected Steps per Second: 22,675.09460
Overall Steps per Second: 10,712.93595

Timestep Collection Time: 2.20630
Timestep Consumption Time: 2.46357
PPO Batch Consumption Time: 0.28528
Total Iteration Time: 4.66987

Cumulative Model Updates: 196,778
Cumulative Timesteps: 1,640,939,308

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1640939308...
Checkpoint 1640939308 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.68188
Value Function Loss: 0.02036

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12426
Policy Update Magnitude: 0.40298
Value Function Update Magnitude: 0.35478

Collected Steps per Second: 22,879.82862
Overall Steps per Second: 10,888.46567

Timestep Collection Time: 2.18629
Timestep Consumption Time: 2.40774
PPO Batch Consumption Time: 0.27648
Total Iteration Time: 4.59404

Cumulative Model Updates: 196,784
Cumulative Timesteps: 1,640,989,330

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.69593
Value Function Loss: 0.01833

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12651
Policy Update Magnitude: 0.40190
Value Function Update Magnitude: 0.33089

Collected Steps per Second: 22,184.07064
Overall Steps per Second: 10,845.05947

Timestep Collection Time: 2.25405
Timestep Consumption Time: 2.35671
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.61076

Cumulative Model Updates: 196,790
Cumulative Timesteps: 1,641,039,334

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1641039334...
Checkpoint 1641039334 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.70893
Value Function Loss: 0.01849

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12775
Policy Update Magnitude: 0.37786
Value Function Update Magnitude: 0.34708

Collected Steps per Second: 21,849.23833
Overall Steps per Second: 10,690.54220

Timestep Collection Time: 2.28868
Timestep Consumption Time: 2.38891
PPO Batch Consumption Time: 0.28458
Total Iteration Time: 4.67759

Cumulative Model Updates: 196,796
Cumulative Timesteps: 1,641,089,340

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 382,994.93508
Policy Entropy: 3.72532
Value Function Loss: 0.01712

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13225
Policy Update Magnitude: 0.36297
Value Function Update Magnitude: 0.33614

Collected Steps per Second: 21,488.79547
Overall Steps per Second: 10,465.48038

Timestep Collection Time: 2.32772
Timestep Consumption Time: 2.45180
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.77952

Cumulative Model Updates: 196,802
Cumulative Timesteps: 1,641,139,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1641139360...
Checkpoint 1641139360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 577,324.16787
Policy Entropy: 3.72032
Value Function Loss: 0.01907

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12704
Policy Update Magnitude: 0.34413
Value Function Update Magnitude: 0.29559

Collected Steps per Second: 22,268.00295
Overall Steps per Second: 10,652.01913

Timestep Collection Time: 2.24699
Timestep Consumption Time: 2.45033
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.69733

Cumulative Model Updates: 196,808
Cumulative Timesteps: 1,641,189,396

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.72151
Value Function Loss: 0.01767

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12345
Policy Update Magnitude: 0.36730
Value Function Update Magnitude: 0.39724

Collected Steps per Second: 22,518.53127
Overall Steps per Second: 10,812.07225

Timestep Collection Time: 2.22164
Timestep Consumption Time: 2.40541
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.62705

Cumulative Model Updates: 196,814
Cumulative Timesteps: 1,641,239,424

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1641239424...
Checkpoint 1641239424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.70521
Value Function Loss: 0.01796

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12773
Policy Update Magnitude: 0.37757
Value Function Update Magnitude: 0.49466

Collected Steps per Second: 22,447.23719
Overall Steps per Second: 10,775.09197

Timestep Collection Time: 2.22798
Timestep Consumption Time: 2.41347
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.64145

Cumulative Model Updates: 196,820
Cumulative Timesteps: 1,641,289,436

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.70199
Value Function Loss: 0.01760

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13990
Policy Update Magnitude: 0.37680
Value Function Update Magnitude: 0.38819

Collected Steps per Second: 22,620.19557
Overall Steps per Second: 10,569.68913

Timestep Collection Time: 2.21130
Timestep Consumption Time: 2.52110
PPO Batch Consumption Time: 0.28928
Total Iteration Time: 4.73240

Cumulative Model Updates: 196,826
Cumulative Timesteps: 1,641,339,456

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1641339456...
Checkpoint 1641339456 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.70106
Value Function Loss: 0.01624

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.34921
Value Function Update Magnitude: 0.29568

Collected Steps per Second: 22,365.54763
Overall Steps per Second: 10,542.46977

Timestep Collection Time: 2.23674
Timestep Consumption Time: 2.50844
PPO Batch Consumption Time: 0.29163
Total Iteration Time: 4.74519

Cumulative Model Updates: 196,832
Cumulative Timesteps: 1,641,389,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.69697
Value Function Loss: 0.01897

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12387
Policy Update Magnitude: 0.35307
Value Function Update Magnitude: 0.29119

Collected Steps per Second: 22,656.76326
Overall Steps per Second: 10,769.43398

Timestep Collection Time: 2.20738
Timestep Consumption Time: 2.43651
PPO Batch Consumption Time: 0.27843
Total Iteration Time: 4.64388

Cumulative Model Updates: 196,838
Cumulative Timesteps: 1,641,439,494

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1641439494...
Checkpoint 1641439494 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.69450
Value Function Loss: 0.02322

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11899
Policy Update Magnitude: 0.39178
Value Function Update Magnitude: 0.27676

Collected Steps per Second: 22,339.49941
Overall Steps per Second: 10,761.61328

Timestep Collection Time: 2.24007
Timestep Consumption Time: 2.40998
PPO Batch Consumption Time: 0.27679
Total Iteration Time: 4.65005

Cumulative Model Updates: 196,844
Cumulative Timesteps: 1,641,489,536

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.68901
Value Function Loss: 0.02139

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12550
Policy Update Magnitude: 0.43194
Value Function Update Magnitude: 0.31425

Collected Steps per Second: 22,852.22702
Overall Steps per Second: 10,816.31044

Timestep Collection Time: 2.18815
Timestep Consumption Time: 2.43487
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.62302

Cumulative Model Updates: 196,850
Cumulative Timesteps: 1,641,539,540

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1641539540...
Checkpoint 1641539540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.68756
Value Function Loss: 0.02243

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12855
Policy Update Magnitude: 0.43388
Value Function Update Magnitude: 0.34032

Collected Steps per Second: 21,746.05013
Overall Steps per Second: 10,609.79591

Timestep Collection Time: 2.29936
Timestep Consumption Time: 2.41345
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.71281

Cumulative Model Updates: 196,856
Cumulative Timesteps: 1,641,589,542

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.69049
Value Function Loss: 0.02175

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13630
Policy Update Magnitude: 0.42382
Value Function Update Magnitude: 0.39132

Collected Steps per Second: 21,742.76628
Overall Steps per Second: 10,603.13189

Timestep Collection Time: 2.30017
Timestep Consumption Time: 2.41655
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.71672

Cumulative Model Updates: 196,862
Cumulative Timesteps: 1,641,639,554

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1641639554...
Checkpoint 1641639554 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.68647
Value Function Loss: 0.02410

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13378
Policy Update Magnitude: 0.41412
Value Function Update Magnitude: 0.41949

Collected Steps per Second: 21,551.05964
Overall Steps per Second: 10,593.45847

Timestep Collection Time: 2.32221
Timestep Consumption Time: 2.40203
PPO Batch Consumption Time: 0.28892
Total Iteration Time: 4.72424

Cumulative Model Updates: 196,868
Cumulative Timesteps: 1,641,689,600

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 306,826.17139
Policy Entropy: 3.70194
Value Function Loss: 0.02148

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13054
Policy Update Magnitude: 0.45172
Value Function Update Magnitude: 0.35251

Collected Steps per Second: 21,754.54466
Overall Steps per Second: 10,452.72219

Timestep Collection Time: 2.29855
Timestep Consumption Time: 2.48527
PPO Batch Consumption Time: 0.29019
Total Iteration Time: 4.78383

Cumulative Model Updates: 196,874
Cumulative Timesteps: 1,641,739,604

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1641739604...
Checkpoint 1641739604 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.69823
Value Function Loss: 0.02307

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.12326
Policy Update Magnitude: 0.46913
Value Function Update Magnitude: 0.35893

Collected Steps per Second: 22,071.87916
Overall Steps per Second: 10,573.01684

Timestep Collection Time: 2.26587
Timestep Consumption Time: 2.46428
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.73015

Cumulative Model Updates: 196,880
Cumulative Timesteps: 1,641,789,616

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.70028
Value Function Loss: 0.02349

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12149
Policy Update Magnitude: 0.47178
Value Function Update Magnitude: 0.34471

Collected Steps per Second: 23,088.63675
Overall Steps per Second: 10,930.68127

Timestep Collection Time: 2.16617
Timestep Consumption Time: 2.40939
PPO Batch Consumption Time: 0.27886
Total Iteration Time: 4.57556

Cumulative Model Updates: 196,886
Cumulative Timesteps: 1,641,839,630

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1641839630...
Checkpoint 1641839630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.68660
Value Function Loss: 0.02580

Mean KL Divergence: 0.01066
SB3 Clip Fraction: 0.13969
Policy Update Magnitude: 0.48878
Value Function Update Magnitude: 0.35780

Collected Steps per Second: 22,660.84852
Overall Steps per Second: 10,643.91175

Timestep Collection Time: 2.20689
Timestep Consumption Time: 2.49157
PPO Batch Consumption Time: 0.28838
Total Iteration Time: 4.69846

Cumulative Model Updates: 196,892
Cumulative Timesteps: 1,641,889,640

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.68837
Value Function Loss: 0.02606

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.46982
Value Function Update Magnitude: 0.32026

Collected Steps per Second: 22,759.39219
Overall Steps per Second: 10,704.01883

Timestep Collection Time: 2.19698
Timestep Consumption Time: 2.47435
PPO Batch Consumption Time: 0.28689
Total Iteration Time: 4.67133

Cumulative Model Updates: 196,898
Cumulative Timesteps: 1,641,939,642

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1641939642...
Checkpoint 1641939642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.68906
Value Function Loss: 0.02388

Mean KL Divergence: 0.01043
SB3 Clip Fraction: 0.13790
Policy Update Magnitude: 0.48273
Value Function Update Magnitude: 0.32229

Collected Steps per Second: 22,717.07681
Overall Steps per Second: 10,807.99331

Timestep Collection Time: 2.20231
Timestep Consumption Time: 2.42667
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.62898

Cumulative Model Updates: 196,904
Cumulative Timesteps: 1,641,989,672

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.68289
Value Function Loss: 0.02108

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14065
Policy Update Magnitude: 0.46208
Value Function Update Magnitude: 0.34697

Collected Steps per Second: 22,708.12937
Overall Steps per Second: 10,652.50500

Timestep Collection Time: 2.20335
Timestep Consumption Time: 2.49357
PPO Batch Consumption Time: 0.28973
Total Iteration Time: 4.69692

Cumulative Model Updates: 196,910
Cumulative Timesteps: 1,642,039,706

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1642039706...
Checkpoint 1642039706 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.68586
Value Function Loss: 0.02086

Mean KL Divergence: 0.01123
SB3 Clip Fraction: 0.14685
Policy Update Magnitude: 0.40659
Value Function Update Magnitude: 0.36993

Collected Steps per Second: 22,237.93200
Overall Steps per Second: 10,543.65266

Timestep Collection Time: 2.24913
Timestep Consumption Time: 2.49458
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.74371

Cumulative Model Updates: 196,916
Cumulative Timesteps: 1,642,089,722

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.67137
Value Function Loss: 0.02074

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13576
Policy Update Magnitude: 0.41297
Value Function Update Magnitude: 0.37280

Collected Steps per Second: 22,651.72636
Overall Steps per Second: 10,772.25347

Timestep Collection Time: 2.20840
Timestep Consumption Time: 2.43539
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.64378

Cumulative Model Updates: 196,922
Cumulative Timesteps: 1,642,139,746

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1642139746...
Checkpoint 1642139746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.68604
Value Function Loss: 0.02199

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12624
Policy Update Magnitude: 0.41366
Value Function Update Magnitude: 0.39441

Collected Steps per Second: 21,763.24979
Overall Steps per Second: 10,453.51137

Timestep Collection Time: 2.29745
Timestep Consumption Time: 2.48563
PPO Batch Consumption Time: 0.29023
Total Iteration Time: 4.78308

Cumulative Model Updates: 196,928
Cumulative Timesteps: 1,642,189,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.69417
Value Function Loss: 0.02011

Mean KL Divergence: 0.01008
SB3 Clip Fraction: 0.13372
Policy Update Magnitude: 0.40339
Value Function Update Magnitude: 0.42527

Collected Steps per Second: 22,315.59663
Overall Steps per Second: 10,718.96722

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.42404
PPO Batch Consumption Time: 0.27748
Total Iteration Time: 4.66463

Cumulative Model Updates: 196,934
Cumulative Timesteps: 1,642,239,746

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1642239746...
Checkpoint 1642239746 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.69220
Value Function Loss: 0.01871

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13389
Policy Update Magnitude: 0.36673
Value Function Update Magnitude: 0.43872

Collected Steps per Second: 22,266.83638
Overall Steps per Second: 10,728.07770

Timestep Collection Time: 2.24747
Timestep Consumption Time: 2.41730
PPO Batch Consumption Time: 0.27589
Total Iteration Time: 4.66477

Cumulative Model Updates: 196,940
Cumulative Timesteps: 1,642,289,790

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 660,541.38908
Policy Entropy: 3.68284
Value Function Loss: 0.01696

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12389
Policy Update Magnitude: 0.34888
Value Function Update Magnitude: 0.39755

Collected Steps per Second: 22,484.25731
Overall Steps per Second: 10,590.28683

Timestep Collection Time: 2.22422
Timestep Consumption Time: 2.49803
PPO Batch Consumption Time: 0.28880
Total Iteration Time: 4.72225

Cumulative Model Updates: 196,946
Cumulative Timesteps: 1,642,339,800

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1642339800...
Checkpoint 1642339800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,613.56130
Policy Entropy: 3.68435
Value Function Loss: 0.02065

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13198
Policy Update Magnitude: 0.36774
Value Function Update Magnitude: 0.45200

Collected Steps per Second: 22,788.95097
Overall Steps per Second: 10,829.55176

Timestep Collection Time: 2.19475
Timestep Consumption Time: 2.42373
PPO Batch Consumption Time: 0.27872
Total Iteration Time: 4.61847

Cumulative Model Updates: 196,952
Cumulative Timesteps: 1,642,389,816

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,613.56130
Policy Entropy: 3.69352
Value Function Loss: 0.01820

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12535
Policy Update Magnitude: 0.44269
Value Function Update Magnitude: 0.54945

Collected Steps per Second: 22,830.38683
Overall Steps per Second: 10,724.87306

Timestep Collection Time: 2.19225
Timestep Consumption Time: 2.47447
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.66672

Cumulative Model Updates: 196,958
Cumulative Timesteps: 1,642,439,866

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1642439866...
Checkpoint 1642439866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,613.56130
Policy Entropy: 3.69853
Value Function Loss: 0.01990

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12222
Policy Update Magnitude: 0.41792
Value Function Update Magnitude: 0.48049

Collected Steps per Second: 22,167.41150
Overall Steps per Second: 10,865.91145

Timestep Collection Time: 2.25674
Timestep Consumption Time: 2.34720
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.60394

Cumulative Model Updates: 196,964
Cumulative Timesteps: 1,642,489,892

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,613.56130
Policy Entropy: 3.70413
Value Function Loss: 0.01607

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.34640
Value Function Update Magnitude: 0.35022

Collected Steps per Second: 22,121.16629
Overall Steps per Second: 10,853.16023

Timestep Collection Time: 2.26145
Timestep Consumption Time: 2.34789
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.60935

Cumulative Model Updates: 196,970
Cumulative Timesteps: 1,642,539,918

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1642539918...
Checkpoint 1642539918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,613.56130
Policy Entropy: 3.69089
Value Function Loss: 0.02013

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12637
Policy Update Magnitude: 0.34259
Value Function Update Magnitude: 0.30575

Collected Steps per Second: 21,819.06259
Overall Steps per Second: 10,682.49215

Timestep Collection Time: 2.29222
Timestep Consumption Time: 2.38965
PPO Batch Consumption Time: 0.27688
Total Iteration Time: 4.68187

Cumulative Model Updates: 196,976
Cumulative Timesteps: 1,642,589,932

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 700,613.56130
Policy Entropy: 3.69954
Value Function Loss: 0.01853

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.39978
Value Function Update Magnitude: 0.41462

Collected Steps per Second: 22,359.79828
Overall Steps per Second: 10,641.33104

Timestep Collection Time: 2.23687
Timestep Consumption Time: 2.46329
PPO Batch Consumption Time: 0.29015
Total Iteration Time: 4.70016

Cumulative Model Updates: 196,982
Cumulative Timesteps: 1,642,639,948

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1642639948...
Checkpoint 1642639948 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 700,613.56130
Policy Entropy: 3.67938
Value Function Loss: 0.01992

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12823
Policy Update Magnitude: 0.38898
Value Function Update Magnitude: 0.46645

Collected Steps per Second: 22,444.14767
Overall Steps per Second: 10,683.78305

Timestep Collection Time: 2.22838
Timestep Consumption Time: 2.45292
PPO Batch Consumption Time: 0.28804
Total Iteration Time: 4.68130

Cumulative Model Updates: 196,988
Cumulative Timesteps: 1,642,689,962

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.67813
Value Function Loss: 0.01941

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.12151
Policy Update Magnitude: 0.36471
Value Function Update Magnitude: 0.43195

Collected Steps per Second: 22,518.89776
Overall Steps per Second: 10,764.00361

Timestep Collection Time: 2.22071
Timestep Consumption Time: 2.42514
PPO Batch Consumption Time: 0.27654
Total Iteration Time: 4.64586

Cumulative Model Updates: 196,994
Cumulative Timesteps: 1,642,739,970

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1642739970...
Checkpoint 1642739970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.67371
Value Function Loss: 0.01936

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12388
Policy Update Magnitude: 0.37252
Value Function Update Magnitude: 0.43303

Collected Steps per Second: 22,284.78492
Overall Steps per Second: 10,643.40068

Timestep Collection Time: 2.24404
Timestep Consumption Time: 2.45446
PPO Batch Consumption Time: 0.28284
Total Iteration Time: 4.69850

Cumulative Model Updates: 197,000
Cumulative Timesteps: 1,642,789,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.67355
Value Function Loss: 0.01987

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12724
Policy Update Magnitude: 0.38544
Value Function Update Magnitude: 0.36509

Collected Steps per Second: 22,772.92862
Overall Steps per Second: 10,617.29507

Timestep Collection Time: 2.19682
Timestep Consumption Time: 2.51512
PPO Batch Consumption Time: 0.28684
Total Iteration Time: 4.71193

Cumulative Model Updates: 197,006
Cumulative Timesteps: 1,642,840,006

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1642840006...
Checkpoint 1642840006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.67407
Value Function Loss: 0.01880

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.38107
Value Function Update Magnitude: 0.35476

Collected Steps per Second: 23,092.83944
Overall Steps per Second: 10,870.43493

Timestep Collection Time: 2.16734
Timestep Consumption Time: 2.43689
PPO Batch Consumption Time: 0.27826
Total Iteration Time: 4.60423

Cumulative Model Updates: 197,012
Cumulative Timesteps: 1,642,890,056

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.67174
Value Function Loss: 0.01848

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12146
Policy Update Magnitude: 0.41052
Value Function Update Magnitude: 0.51826

Collected Steps per Second: 22,890.37319
Overall Steps per Second: 10,876.55983

Timestep Collection Time: 2.18520
Timestep Consumption Time: 2.41368
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.59888

Cumulative Model Updates: 197,018
Cumulative Timesteps: 1,642,940,076

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1642940076...
Checkpoint 1642940076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.68071
Value Function Loss: 0.01716

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12828
Policy Update Magnitude: 0.42829
Value Function Update Magnitude: 0.64344

Collected Steps per Second: 22,368.09245
Overall Steps per Second: 10,763.78527

Timestep Collection Time: 2.23631
Timestep Consumption Time: 2.41094
PPO Batch Consumption Time: 0.27583
Total Iteration Time: 4.64725

Cumulative Model Updates: 197,024
Cumulative Timesteps: 1,642,990,098

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.68030
Value Function Loss: 0.01584

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.12075
Policy Update Magnitude: 0.39759
Value Function Update Magnitude: 0.63523

Collected Steps per Second: 23,123.17946
Overall Steps per Second: 10,907.91090

Timestep Collection Time: 2.16354
Timestep Consumption Time: 2.42285
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.58640

Cumulative Model Updates: 197,030
Cumulative Timesteps: 1,643,040,126

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1643040126...
Checkpoint 1643040126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.71520
Value Function Loss: 0.01417

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.38025
Value Function Update Magnitude: 0.49789

Collected Steps per Second: 22,561.17221
Overall Steps per Second: 10,616.24360

Timestep Collection Time: 2.21637
Timestep Consumption Time: 2.49377
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.71014

Cumulative Model Updates: 197,036
Cumulative Timesteps: 1,643,090,130

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.70965
Value Function Loss: 0.01243

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.36889
Value Function Update Magnitude: 0.40074

Collected Steps per Second: 22,339.76005
Overall Steps per Second: 10,628.13393

Timestep Collection Time: 2.23915
Timestep Consumption Time: 2.46742
PPO Batch Consumption Time: 0.28770
Total Iteration Time: 4.70656

Cumulative Model Updates: 197,042
Cumulative Timesteps: 1,643,140,152

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1643140152...
Checkpoint 1643140152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.72398
Value Function Loss: 0.01205

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.37514
Value Function Update Magnitude: 0.34748

Collected Steps per Second: 22,412.59150
Overall Steps per Second: 10,650.76870

Timestep Collection Time: 2.23107
Timestep Consumption Time: 2.46381
PPO Batch Consumption Time: 0.28693
Total Iteration Time: 4.69487

Cumulative Model Updates: 197,048
Cumulative Timesteps: 1,643,190,156

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.71035
Value Function Loss: 0.01172

Mean KL Divergence: 0.01059
SB3 Clip Fraction: 0.13823
Policy Update Magnitude: 0.37525
Value Function Update Magnitude: 0.34687

Collected Steps per Second: 22,772.59795
Overall Steps per Second: 10,699.29703

Timestep Collection Time: 2.19650
Timestep Consumption Time: 2.47857
PPO Batch Consumption Time: 0.28815
Total Iteration Time: 4.67507

Cumulative Model Updates: 197,054
Cumulative Timesteps: 1,643,240,176

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1643240176...
Checkpoint 1643240176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,033,102.55644
Policy Entropy: 3.73839
Value Function Loss: 0.01197

Mean KL Divergence: 0.00734
SB3 Clip Fraction: 0.09246
Policy Update Magnitude: 0.40629
Value Function Update Magnitude: 0.40766

Collected Steps per Second: 21,332.91009
Overall Steps per Second: 10,641.50232

Timestep Collection Time: 2.34380
Timestep Consumption Time: 2.35479
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.69858

Cumulative Model Updates: 197,060
Cumulative Timesteps: 1,643,290,176

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020,197.54352
Policy Entropy: 3.74027
Value Function Loss: 0.01202

Mean KL Divergence: 0.00862
SB3 Clip Fraction: 0.11332
Policy Update Magnitude: 0.42054
Value Function Update Magnitude: 0.54350

Collected Steps per Second: 21,985.88768
Overall Steps per Second: 10,662.65031

Timestep Collection Time: 2.27500
Timestep Consumption Time: 2.41595
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.69095

Cumulative Model Updates: 197,066
Cumulative Timesteps: 1,643,340,194

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1643340194...
Checkpoint 1643340194 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020,197.54352
Policy Entropy: 3.74636
Value Function Loss: 0.01195

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08318
Policy Update Magnitude: 0.43744
Value Function Update Magnitude: 0.56349

Collected Steps per Second: 21,953.38598
Overall Steps per Second: 10,433.11076

Timestep Collection Time: 2.27774
Timestep Consumption Time: 2.51508
PPO Batch Consumption Time: 0.29237
Total Iteration Time: 4.79282

Cumulative Model Updates: 197,072
Cumulative Timesteps: 1,643,390,198

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020,197.54352
Policy Entropy: 3.73814
Value Function Loss: 0.01094

Mean KL Divergence: 0.00513
SB3 Clip Fraction: 0.06035
Policy Update Magnitude: 0.43900
Value Function Update Magnitude: 0.48934

Collected Steps per Second: 23,109.70840
Overall Steps per Second: 10,958.76024

Timestep Collection Time: 2.16368
Timestep Consumption Time: 2.39906
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.56274

Cumulative Model Updates: 197,078
Cumulative Timesteps: 1,643,440,200

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1643440200...
Checkpoint 1643440200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020,197.54352
Policy Entropy: 3.72080
Value Function Loss: 0.01009

Mean KL Divergence: 0.00466
SB3 Clip Fraction: 0.05200
Policy Update Magnitude: 0.39269
Value Function Update Magnitude: 0.38268

Collected Steps per Second: 21,693.54764
Overall Steps per Second: 10,573.79068

Timestep Collection Time: 2.30612
Timestep Consumption Time: 2.42520
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.73132

Cumulative Model Updates: 197,084
Cumulative Timesteps: 1,643,490,228

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020,197.54352
Policy Entropy: 3.71278
Value Function Loss: 0.00963

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04878
Policy Update Magnitude: 0.34928
Value Function Update Magnitude: 0.27528

Collected Steps per Second: 22,782.88537
Overall Steps per Second: 10,705.28397

Timestep Collection Time: 2.19603
Timestep Consumption Time: 2.47755
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.67358

Cumulative Model Updates: 197,090
Cumulative Timesteps: 1,643,540,260

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1643540260...
Checkpoint 1643540260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020,197.54352
Policy Entropy: 3.70681
Value Function Loss: 0.01118

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05444
Policy Update Magnitude: 0.35606
Value Function Update Magnitude: 0.24246

Collected Steps per Second: 22,656.16312
Overall Steps per Second: 10,832.99489

Timestep Collection Time: 2.20770
Timestep Consumption Time: 2.40949
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.61719

Cumulative Model Updates: 197,096
Cumulative Timesteps: 1,643,590,278

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020,197.54352
Policy Entropy: 3.71721
Value Function Loss: 0.01184

Mean KL Divergence: 0.00486
SB3 Clip Fraction: 0.05628
Policy Update Magnitude: 0.39523
Value Function Update Magnitude: 0.27451

Collected Steps per Second: 23,003.75632
Overall Steps per Second: 10,859.46419

Timestep Collection Time: 2.17425
Timestep Consumption Time: 2.43150
PPO Batch Consumption Time: 0.27789
Total Iteration Time: 4.60575

Cumulative Model Updates: 197,102
Cumulative Timesteps: 1,643,640,294

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1643640294...
Checkpoint 1643640294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020,197.54352
Policy Entropy: 3.73117
Value Function Loss: 0.01326

Mean KL Divergence: 0.00558
SB3 Clip Fraction: 0.06598
Policy Update Magnitude: 0.41754
Value Function Update Magnitude: 0.31224

Collected Steps per Second: 21,970.73333
Overall Steps per Second: 10,655.44239

Timestep Collection Time: 2.27721
Timestep Consumption Time: 2.41823
PPO Batch Consumption Time: 0.27663
Total Iteration Time: 4.69544

Cumulative Model Updates: 197,108
Cumulative Timesteps: 1,643,690,326

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,020,197.54352
Policy Entropy: 3.72599
Value Function Loss: 0.01353

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.06950
Policy Update Magnitude: 0.43511
Value Function Update Magnitude: 0.31612

Collected Steps per Second: 22,262.21900
Overall Steps per Second: 10,535.59560

Timestep Collection Time: 2.24713
Timestep Consumption Time: 2.50116
PPO Batch Consumption Time: 0.29096
Total Iteration Time: 4.74828

Cumulative Model Updates: 197,114
Cumulative Timesteps: 1,643,740,352

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1643740352...
Checkpoint 1643740352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,394.52740
Policy Entropy: 3.73450
Value Function Loss: 0.01495

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.06154
Policy Update Magnitude: 0.47694
Value Function Update Magnitude: 0.41966

Collected Steps per Second: 22,126.12395
Overall Steps per Second: 10,705.02580

Timestep Collection Time: 2.26086
Timestep Consumption Time: 2.41209
PPO Batch Consumption Time: 0.27588
Total Iteration Time: 4.67295

Cumulative Model Updates: 197,120
Cumulative Timesteps: 1,643,790,376

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,394.52740
Policy Entropy: 3.72430
Value Function Loss: 0.01570

Mean KL Divergence: 0.00544
SB3 Clip Fraction: 0.06414
Policy Update Magnitude: 0.52888
Value Function Update Magnitude: 0.42415

Collected Steps per Second: 22,520.60318
Overall Steps per Second: 10,751.01905

Timestep Collection Time: 2.22134
Timestep Consumption Time: 2.43180
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.65314

Cumulative Model Updates: 197,126
Cumulative Timesteps: 1,643,840,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1643840402...
Checkpoint 1643840402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,394.52740
Policy Entropy: 3.74407
Value Function Loss: 0.01533

Mean KL Divergence: 0.00612
SB3 Clip Fraction: 0.07277
Policy Update Magnitude: 0.55411
Value Function Update Magnitude: 0.41506

Collected Steps per Second: 22,370.62141
Overall Steps per Second: 10,661.87392

Timestep Collection Time: 2.23642
Timestep Consumption Time: 2.45601
PPO Batch Consumption Time: 0.27713
Total Iteration Time: 4.69242

Cumulative Model Updates: 197,132
Cumulative Timesteps: 1,643,890,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,394.52740
Policy Entropy: 3.74296
Value Function Loss: 0.01441

Mean KL Divergence: 0.00527
SB3 Clip Fraction: 0.05998
Policy Update Magnitude: 0.53159
Value Function Update Magnitude: 0.41437

Collected Steps per Second: 22,658.75365
Overall Steps per Second: 10,639.08792

Timestep Collection Time: 2.20718
Timestep Consumption Time: 2.49360
PPO Batch Consumption Time: 0.28999
Total Iteration Time: 4.70078

Cumulative Model Updates: 197,138
Cumulative Timesteps: 1,643,940,444

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1643940444...
Checkpoint 1643940444 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,394.52740
Policy Entropy: 3.75054
Value Function Loss: 0.01209

Mean KL Divergence: 0.00374
SB3 Clip Fraction: 0.03730
Policy Update Magnitude: 0.47410
Value Function Update Magnitude: 0.39955

Collected Steps per Second: 22,678.70422
Overall Steps per Second: 10,699.14047

Timestep Collection Time: 2.20471
Timestep Consumption Time: 2.46856
PPO Batch Consumption Time: 0.28846
Total Iteration Time: 4.67327

Cumulative Model Updates: 197,144
Cumulative Timesteps: 1,643,990,444

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,394.52740
Policy Entropy: 3.74171
Value Function Loss: 0.01069

Mean KL Divergence: 0.00450
SB3 Clip Fraction: 0.04736
Policy Update Magnitude: 0.42599
Value Function Update Magnitude: 0.39332

Collected Steps per Second: 23,195.78292
Overall Steps per Second: 10,711.03829

Timestep Collection Time: 2.15582
Timestep Consumption Time: 2.51282
PPO Batch Consumption Time: 0.29248
Total Iteration Time: 4.66864

Cumulative Model Updates: 197,150
Cumulative Timesteps: 1,644,040,450

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1644040450...
Checkpoint 1644040450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,394.52740
Policy Entropy: 3.74869
Value Function Loss: 0.00905

Mean KL Divergence: 0.00429
SB3 Clip Fraction: 0.04486
Policy Update Magnitude: 0.37250
Value Function Update Magnitude: 0.34518

Collected Steps per Second: 21,913.42868
Overall Steps per Second: 10,637.02993

Timestep Collection Time: 2.28234
Timestep Consumption Time: 2.41953
PPO Batch Consumption Time: 0.28927
Total Iteration Time: 4.70188

Cumulative Model Updates: 197,156
Cumulative Timesteps: 1,644,090,464

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,394.52740
Policy Entropy: 3.74630
Value Function Loss: 0.01001

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.07297
Policy Update Magnitude: 0.37872
Value Function Update Magnitude: 0.36486

Collected Steps per Second: 22,176.90300
Overall Steps per Second: 10,882.54820

Timestep Collection Time: 2.25487
Timestep Consumption Time: 2.34019
PPO Batch Consumption Time: 0.27735
Total Iteration Time: 4.59506

Cumulative Model Updates: 197,162
Cumulative Timesteps: 1,644,140,470

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1644140470...
Checkpoint 1644140470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,394.52740
Policy Entropy: 3.74165
Value Function Loss: 0.01088

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05311
Policy Update Magnitude: 0.38829
Value Function Update Magnitude: 0.48043

Collected Steps per Second: 21,035.66092
Overall Steps per Second: 10,308.41953

Timestep Collection Time: 2.37711
Timestep Consumption Time: 2.47369
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.85079

Cumulative Model Updates: 197,168
Cumulative Timesteps: 1,644,190,474

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,404,394.52740
Policy Entropy: 3.73074
Value Function Loss: 0.01192

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.11179
Policy Update Magnitude: 0.39849
Value Function Update Magnitude: 0.47870

Collected Steps per Second: 22,428.21150
Overall Steps per Second: 10,811.95541

Timestep Collection Time: 2.23014
Timestep Consumption Time: 2.39604
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.62618

Cumulative Model Updates: 197,174
Cumulative Timesteps: 1,644,240,492

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1644240492...
Checkpoint 1644240492 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,348,704.87823
Policy Entropy: 3.72565
Value Function Loss: 0.01490

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.17651
Policy Update Magnitude: 0.35642
Value Function Update Magnitude: 0.45029

Collected Steps per Second: 22,116.78610
Overall Steps per Second: 10,655.52355

Timestep Collection Time: 2.26073
Timestep Consumption Time: 2.43168
PPO Batch Consumption Time: 0.28321
Total Iteration Time: 4.69240

Cumulative Model Updates: 197,180
Cumulative Timesteps: 1,644,290,492

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 380,934.17475
Policy Entropy: 3.72049
Value Function Loss: 0.02007

Mean KL Divergence: 0.01285
SB3 Clip Fraction: 0.16674
Policy Update Magnitude: 0.41455
Value Function Update Magnitude: 0.50173

Collected Steps per Second: 22,516.71348
Overall Steps per Second: 10,521.24160

Timestep Collection Time: 2.22199
Timestep Consumption Time: 2.53334
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.75533

Cumulative Model Updates: 197,186
Cumulative Timesteps: 1,644,340,524

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1644340524...
Checkpoint 1644340524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,932.26328
Policy Entropy: 3.69354
Value Function Loss: 0.02792

Mean KL Divergence: 0.02581
SB3 Clip Fraction: 0.25259
Policy Update Magnitude: 0.53629
Value Function Update Magnitude: 0.47709

Collected Steps per Second: 22,377.34324
Overall Steps per Second: 10,608.11441

Timestep Collection Time: 2.23467
Timestep Consumption Time: 2.47927
PPO Batch Consumption Time: 0.28199
Total Iteration Time: 4.71394

Cumulative Model Updates: 197,192
Cumulative Timesteps: 1,644,390,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 983,625.14934
Policy Entropy: 3.66689
Value Function Loss: 0.07052

Mean KL Divergence: 0.02272
SB3 Clip Fraction: 0.23624
Policy Update Magnitude: 0.63541
Value Function Update Magnitude: 0.46947

Collected Steps per Second: 22,229.25218
Overall Steps per Second: 10,546.58293

Timestep Collection Time: 2.24974
Timestep Consumption Time: 2.49208
PPO Batch Consumption Time: 0.28968
Total Iteration Time: 4.74182

Cumulative Model Updates: 197,198
Cumulative Timesteps: 1,644,440,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1644440540...
Checkpoint 1644440540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327,932.24205
Policy Entropy: 3.67838
Value Function Loss: 0.08585

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.18425
Policy Update Magnitude: 0.90896
Value Function Update Magnitude: 0.70953

Collected Steps per Second: 22,113.73330
Overall Steps per Second: 10,522.70136

Timestep Collection Time: 2.26149
Timestep Consumption Time: 2.49109
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.75258

Cumulative Model Updates: 197,204
Cumulative Timesteps: 1,644,490,550

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 292,172.54411
Policy Entropy: 3.67872
Value Function Loss: 0.08680

Mean KL Divergence: 0.01783
SB3 Clip Fraction: 0.19238
Policy Update Magnitude: 1.23895
Value Function Update Magnitude: 0.78338

Collected Steps per Second: 22,480.40715
Overall Steps per Second: 10,590.90788

Timestep Collection Time: 2.22549
Timestep Consumption Time: 2.49837
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.72386

Cumulative Model Updates: 197,210
Cumulative Timesteps: 1,644,540,580

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1644540580...
Checkpoint 1644540580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,172.90923
Policy Entropy: 3.69417
Value Function Loss: 0.07755

Mean KL Divergence: 0.02797
SB3 Clip Fraction: 0.25307
Policy Update Magnitude: 1.11459
Value Function Update Magnitude: 0.71835

Collected Steps per Second: 22,312.71506
Overall Steps per Second: 10,492.52004

Timestep Collection Time: 2.24123
Timestep Consumption Time: 2.52483
PPO Batch Consumption Time: 0.29377
Total Iteration Time: 4.76606

Cumulative Model Updates: 197,216
Cumulative Timesteps: 1,644,590,588

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,318.42391
Policy Entropy: 3.73451
Value Function Loss: 0.07302

Mean KL Divergence: 0.02140
SB3 Clip Fraction: 0.22438
Policy Update Magnitude: 1.12164
Value Function Update Magnitude: 0.71510

Collected Steps per Second: 22,763.81479
Overall Steps per Second: 10,848.12841

Timestep Collection Time: 2.19691
Timestep Consumption Time: 2.41310
PPO Batch Consumption Time: 0.27930
Total Iteration Time: 4.61001

Cumulative Model Updates: 197,222
Cumulative Timesteps: 1,644,640,598

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1644640598...
Checkpoint 1644640598 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 17,680.13195
Policy Entropy: 3.75482
Value Function Loss: 0.05695

Mean KL Divergence: 0.02084
SB3 Clip Fraction: 0.22559
Policy Update Magnitude: 0.95516
Value Function Update Magnitude: 0.77681

Collected Steps per Second: 22,048.98676
Overall Steps per Second: 10,705.82773

Timestep Collection Time: 2.26768
Timestep Consumption Time: 2.40268
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.67035

Cumulative Model Updates: 197,228
Cumulative Timesteps: 1,644,690,598

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 668.58555
Policy Entropy: 3.77204
Value Function Loss: 0.04959

Mean KL Divergence: 0.01220
SB3 Clip Fraction: 0.15030
Policy Update Magnitude: 0.83702
Value Function Update Magnitude: 0.73812

Collected Steps per Second: 22,351.41336
Overall Steps per Second: 10,630.49886

Timestep Collection Time: 2.23834
Timestep Consumption Time: 2.46793
PPO Batch Consumption Time: 0.28962
Total Iteration Time: 4.70627

Cumulative Model Updates: 197,234
Cumulative Timesteps: 1,644,740,628

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1644740628...
Checkpoint 1644740628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64.79561
Policy Entropy: 3.75807
Value Function Loss: 0.04139

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.11895
Policy Update Magnitude: 0.86461
Value Function Update Magnitude: 0.70448

Collected Steps per Second: 22,201.79640
Overall Steps per Second: 10,534.41743

Timestep Collection Time: 2.25216
Timestep Consumption Time: 2.49438
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.74654

Cumulative Model Updates: 197,240
Cumulative Timesteps: 1,644,790,630

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 12,652.84917
Policy Entropy: 3.73959
Value Function Loss: 0.03752

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10395
Policy Update Magnitude: 0.79607
Value Function Update Magnitude: 0.78888

Collected Steps per Second: 22,684.69771
Overall Steps per Second: 10,784.62082

Timestep Collection Time: 2.20589
Timestep Consumption Time: 2.43405
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.63994

Cumulative Model Updates: 197,246
Cumulative Timesteps: 1,644,840,670

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1644840670...
Checkpoint 1644840670 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,587.96629
Policy Entropy: 3.73246
Value Function Loss: 0.03037

Mean KL Divergence: 0.00646
SB3 Clip Fraction: 0.07817
Policy Update Magnitude: 0.72967
Value Function Update Magnitude: 0.79513

Collected Steps per Second: 22,205.70711
Overall Steps per Second: 10,673.89654

Timestep Collection Time: 2.25221
Timestep Consumption Time: 2.43324
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.68545

Cumulative Model Updates: 197,252
Cumulative Timesteps: 1,644,890,682

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279,191.01838
Policy Entropy: 3.72748
Value Function Loss: 0.02736

Mean KL Divergence: 0.00694
SB3 Clip Fraction: 0.08625
Policy Update Magnitude: 0.64553
Value Function Update Magnitude: 0.74338

Collected Steps per Second: 22,534.68728
Overall Steps per Second: 10,529.09769

Timestep Collection Time: 2.21916
Timestep Consumption Time: 2.53035
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.74950

Cumulative Model Updates: 197,258
Cumulative Timesteps: 1,644,940,690

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1644940690...
Checkpoint 1644940690 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279,191.01838
Policy Entropy: 3.73112
Value Function Loss: 0.02098

Mean KL Divergence: 0.00622
SB3 Clip Fraction: 0.07598
Policy Update Magnitude: 0.58279
Value Function Update Magnitude: 0.65001

Collected Steps per Second: 22,396.67828
Overall Steps per Second: 10,582.53776

Timestep Collection Time: 2.23363
Timestep Consumption Time: 2.49359
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.72722

Cumulative Model Updates: 197,264
Cumulative Timesteps: 1,644,990,716

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 279,191.01838
Policy Entropy: 3.73364
Value Function Loss: 0.01631

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07742
Policy Update Magnitude: 0.49637
Value Function Update Magnitude: 0.56786

Collected Steps per Second: 23,167.22085
Overall Steps per Second: 10,801.33098

Timestep Collection Time: 2.15926
Timestep Consumption Time: 2.47202
PPO Batch Consumption Time: 0.27973
Total Iteration Time: 4.63128

Cumulative Model Updates: 197,270
Cumulative Timesteps: 1,645,040,740

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1645040740...
Checkpoint 1645040740 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 257,577.38320
Policy Entropy: 3.72249
Value Function Loss: 0.01504

Mean KL Divergence: 0.00481
SB3 Clip Fraction: 0.05228
Policy Update Magnitude: 0.43767
Value Function Update Magnitude: 0.46950

Collected Steps per Second: 22,555.55432
Overall Steps per Second: 10,777.90057

Timestep Collection Time: 2.21701
Timestep Consumption Time: 2.42266
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.63968

Cumulative Model Updates: 197,276
Cumulative Timesteps: 1,645,090,746

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 110,907.29473
Policy Entropy: 3.72809
Value Function Loss: 0.01591

Mean KL Divergence: 0.00771
SB3 Clip Fraction: 0.09941
Policy Update Magnitude: 0.39184
Value Function Update Magnitude: 0.42974

Collected Steps per Second: 22,212.51680
Overall Steps per Second: 10,873.95907

Timestep Collection Time: 2.25143
Timestep Consumption Time: 2.34763
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.59906

Cumulative Model Updates: 197,282
Cumulative Timesteps: 1,645,140,756

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1645140756...
Checkpoint 1645140756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 58,943.15099
Policy Entropy: 3.71755
Value Function Loss: 0.01883

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.18320
Policy Update Magnitude: 0.30688
Value Function Update Magnitude: 0.51466

Collected Steps per Second: 21,660.45592
Overall Steps per Second: 10,754.26366

Timestep Collection Time: 2.30863
Timestep Consumption Time: 2.34125
PPO Batch Consumption Time: 0.27555
Total Iteration Time: 4.64988

Cumulative Model Updates: 197,288
Cumulative Timesteps: 1,645,190,762

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,775.81114
Policy Entropy: 3.73713
Value Function Loss: 0.02005

Mean KL Divergence: 0.01339
SB3 Clip Fraction: 0.17343
Policy Update Magnitude: 0.29901
Value Function Update Magnitude: 0.57080

Collected Steps per Second: 21,839.98751
Overall Steps per Second: 10,763.34394

Timestep Collection Time: 2.29011
Timestep Consumption Time: 2.35677
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.64688

Cumulative Model Updates: 197,294
Cumulative Timesteps: 1,645,240,778

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1645240778...
Checkpoint 1645240778 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,028.74975
Policy Entropy: 3.74585
Value Function Loss: 0.02305

Mean KL Divergence: 0.01245
SB3 Clip Fraction: 0.16291
Policy Update Magnitude: 0.35748
Value Function Update Magnitude: 0.75280

Collected Steps per Second: 21,382.52368
Overall Steps per Second: 10,411.89397

Timestep Collection Time: 2.33967
Timestep Consumption Time: 2.46522
PPO Batch Consumption Time: 0.29010
Total Iteration Time: 4.80489

Cumulative Model Updates: 197,300
Cumulative Timesteps: 1,645,290,806

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,028.74975
Policy Entropy: 3.73775
Value Function Loss: 0.02328

Mean KL Divergence: 0.01076
SB3 Clip Fraction: 0.14591
Policy Update Magnitude: 0.38980
Value Function Update Magnitude: 0.81076

Collected Steps per Second: 22,432.00484
Overall Steps per Second: 10,813.46292

Timestep Collection Time: 2.22949
Timestep Consumption Time: 2.39548
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.62498

Cumulative Model Updates: 197,306
Cumulative Timesteps: 1,645,340,818

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1645340818...
Checkpoint 1645340818 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 18,028.74975
Policy Entropy: 3.73216
Value Function Loss: 0.02190

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14916
Policy Update Magnitude: 0.38376
Value Function Update Magnitude: 0.73956

Collected Steps per Second: 22,343.21857
Overall Steps per Second: 10,575.81826

Timestep Collection Time: 2.23808
Timestep Consumption Time: 2.49025
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.72833

Cumulative Model Updates: 197,312
Cumulative Timesteps: 1,645,390,824

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,028.74975
Policy Entropy: 3.70623
Value Function Loss: 0.01904

Mean KL Divergence: 0.01104
SB3 Clip Fraction: 0.14697
Policy Update Magnitude: 0.34231
Value Function Update Magnitude: 0.64582

Collected Steps per Second: 22,440.50920
Overall Steps per Second: 10,553.22650

Timestep Collection Time: 2.22981
Timestep Consumption Time: 2.51168
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.74149

Cumulative Model Updates: 197,318
Cumulative Timesteps: 1,645,440,862

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1645440862...
Checkpoint 1645440862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 496,577.45791
Policy Entropy: 3.71592
Value Function Loss: 0.01933

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13748
Policy Update Magnitude: 0.33323
Value Function Update Magnitude: 0.66089

Collected Steps per Second: 22,534.80150
Overall Steps per Second: 10,570.41137

Timestep Collection Time: 2.21906
Timestep Consumption Time: 2.51170
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.73075

Cumulative Model Updates: 197,324
Cumulative Timesteps: 1,645,490,868

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 79,037.28762
Policy Entropy: 3.74264
Value Function Loss: 0.01940

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.13151
Policy Update Magnitude: 0.35141
Value Function Update Magnitude: 0.71983

Collected Steps per Second: 22,841.22825
Overall Steps per Second: 10,815.43776

Timestep Collection Time: 2.18911
Timestep Consumption Time: 2.43409
PPO Batch Consumption Time: 0.27837
Total Iteration Time: 4.62321

Cumulative Model Updates: 197,330
Cumulative Timesteps: 1,645,540,870

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1645540870...
Checkpoint 1645540870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,993.28281
Policy Entropy: 3.76520
Value Function Loss: 0.02270

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12794
Policy Update Magnitude: 0.37323
Value Function Update Magnitude: 0.79124

Collected Steps per Second: 22,334.77531
Overall Steps per Second: 10,724.99909

Timestep Collection Time: 2.23938
Timestep Consumption Time: 2.42412
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.66350

Cumulative Model Updates: 197,336
Cumulative Timesteps: 1,645,590,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 225,967.06143
Policy Entropy: 3.76070
Value Function Loss: 0.02418

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13082
Policy Update Magnitude: 0.43595
Value Function Update Magnitude: 0.92116

Collected Steps per Second: 22,887.66463
Overall Steps per Second: 10,841.95635

Timestep Collection Time: 2.18493
Timestep Consumption Time: 2.42752
PPO Batch Consumption Time: 0.27726
Total Iteration Time: 4.61245

Cumulative Model Updates: 197,342
Cumulative Timesteps: 1,645,640,894

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1645640894...
Checkpoint 1645640894 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,896.73679
Policy Entropy: 3.72861
Value Function Loss: 0.02559

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13062
Policy Update Magnitude: 0.44789
Value Function Update Magnitude: 0.97318

Collected Steps per Second: 22,161.45375
Overall Steps per Second: 10,691.00466

Timestep Collection Time: 2.25698
Timestep Consumption Time: 2.42153
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.67851

Cumulative Model Updates: 197,348
Cumulative Timesteps: 1,645,690,912

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,896.73679
Policy Entropy: 3.71330
Value Function Loss: 0.02327

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13240
Policy Update Magnitude: 0.42704
Value Function Update Magnitude: 0.73611

Collected Steps per Second: 21,679.65278
Overall Steps per Second: 10,592.22350

Timestep Collection Time: 2.30631
Timestep Consumption Time: 2.41413
PPO Batch Consumption Time: 0.29074
Total Iteration Time: 4.72044

Cumulative Model Updates: 197,354
Cumulative Timesteps: 1,645,740,912

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1645740912...
Checkpoint 1645740912 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121,896.73679
Policy Entropy: 3.71832
Value Function Loss: 0.01941

Mean KL Divergence: 0.01018
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.39567
Value Function Update Magnitude: 0.52524

Collected Steps per Second: 21,348.31844
Overall Steps per Second: 10,556.47712

Timestep Collection Time: 2.34295
Timestep Consumption Time: 2.39519
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.73813

Cumulative Model Updates: 197,360
Cumulative Timesteps: 1,645,790,930

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 121,896.73679
Policy Entropy: 3.70949
Value Function Loss: 0.01858

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13181
Policy Update Magnitude: 0.35143
Value Function Update Magnitude: 0.40822

Collected Steps per Second: 22,125.23004
Overall Steps per Second: 10,571.32029

Timestep Collection Time: 2.26167
Timestep Consumption Time: 2.47189
PPO Batch Consumption Time: 0.28989
Total Iteration Time: 4.73356

Cumulative Model Updates: 197,366
Cumulative Timesteps: 1,645,840,970

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1645840970...
Checkpoint 1645840970 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,761.73513
Policy Entropy: 3.69500
Value Function Loss: 0.01991

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.14002
Policy Update Magnitude: 0.35062
Value Function Update Magnitude: 0.47141

Collected Steps per Second: 22,370.65711
Overall Steps per Second: 10,617.83065

Timestep Collection Time: 2.23543
Timestep Consumption Time: 2.47439
PPO Batch Consumption Time: 0.28967
Total Iteration Time: 4.70981

Cumulative Model Updates: 197,372
Cumulative Timesteps: 1,645,890,978

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,761.73513
Policy Entropy: 3.70109
Value Function Loss: 0.02082

Mean KL Divergence: 0.01006
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.36619
Value Function Update Magnitude: 0.50808

Collected Steps per Second: 22,885.54577
Overall Steps per Second: 10,739.74637

Timestep Collection Time: 2.18505
Timestep Consumption Time: 2.47111
PPO Batch Consumption Time: 0.28447
Total Iteration Time: 4.65616

Cumulative Model Updates: 197,378
Cumulative Timesteps: 1,645,940,984

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1645940984...
Checkpoint 1645940984 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,761.73513
Policy Entropy: 3.68312
Value Function Loss: 0.02709

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13365
Policy Update Magnitude: 0.38349
Value Function Update Magnitude: 0.38585

Collected Steps per Second: 22,612.61098
Overall Steps per Second: 10,692.52596

Timestep Collection Time: 2.21204
Timestep Consumption Time: 2.46599
PPO Batch Consumption Time: 0.28498
Total Iteration Time: 4.67803

Cumulative Model Updates: 197,384
Cumulative Timesteps: 1,645,991,004

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 176,761.73513
Policy Entropy: 3.70032
Value Function Loss: 0.02520

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.13337
Policy Update Magnitude: 0.37979
Value Function Update Magnitude: 0.29601

Collected Steps per Second: 22,756.68056
Overall Steps per Second: 10,809.10262

Timestep Collection Time: 2.19716
Timestep Consumption Time: 2.42857
PPO Batch Consumption Time: 0.27821
Total Iteration Time: 4.62573

Cumulative Model Updates: 197,390
Cumulative Timesteps: 1,646,041,004

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1646041004...
Checkpoint 1646041004 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 610,965.63178
Policy Entropy: 3.70510
Value Function Loss: 0.02224

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.13095
Policy Update Magnitude: 0.38122
Value Function Update Magnitude: 0.34813

Collected Steps per Second: 22,482.81559
Overall Steps per Second: 10,718.47285

Timestep Collection Time: 2.22463
Timestep Consumption Time: 2.44170
PPO Batch Consumption Time: 0.28191
Total Iteration Time: 4.66634

Cumulative Model Updates: 197,396
Cumulative Timesteps: 1,646,091,020

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 610,965.63178
Policy Entropy: 3.72004
Value Function Loss: 0.01634

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12676
Policy Update Magnitude: 0.39319
Value Function Update Magnitude: 0.50914

Collected Steps per Second: 22,943.00034
Overall Steps per Second: 10,861.68593

Timestep Collection Time: 2.18001
Timestep Consumption Time: 2.42480
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.60481

Cumulative Model Updates: 197,402
Cumulative Timesteps: 1,646,141,036

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1646141036...
Checkpoint 1646141036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 681,238.15746
Policy Entropy: 3.70217
Value Function Loss: 0.01906

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13355
Policy Update Magnitude: 0.40746
Value Function Update Magnitude: 0.60910

Collected Steps per Second: 22,602.80893
Overall Steps per Second: 10,735.25722

Timestep Collection Time: 2.21406
Timestep Consumption Time: 2.44759
PPO Batch Consumption Time: 0.28248
Total Iteration Time: 4.66165

Cumulative Model Updates: 197,408
Cumulative Timesteps: 1,646,191,080

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 237,556.85694
Policy Entropy: 3.70677
Value Function Loss: 0.02079

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13590
Policy Update Magnitude: 0.42625
Value Function Update Magnitude: 0.64827

Collected Steps per Second: 22,203.51141
Overall Steps per Second: 10,534.76095

Timestep Collection Time: 2.25289
Timestep Consumption Time: 2.49539
PPO Batch Consumption Time: 0.29086
Total Iteration Time: 4.74828

Cumulative Model Updates: 197,414
Cumulative Timesteps: 1,646,241,102

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1646241102...
Checkpoint 1646241102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 155,872.39429
Policy Entropy: 3.69612
Value Function Loss: 0.02343

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13684
Policy Update Magnitude: 0.42592
Value Function Update Magnitude: 0.66720

Collected Steps per Second: 21,946.19969
Overall Steps per Second: 10,513.18929

Timestep Collection Time: 2.27921
Timestep Consumption Time: 2.47862
PPO Batch Consumption Time: 0.28461
Total Iteration Time: 4.75783

Cumulative Model Updates: 197,420
Cumulative Timesteps: 1,646,291,122

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 155,872.39429
Policy Entropy: 3.71090
Value Function Loss: 0.02296

Mean KL Divergence: 0.01012
SB3 Clip Fraction: 0.13497
Policy Update Magnitude: 0.42578
Value Function Update Magnitude: 0.59114

Collected Steps per Second: 22,126.20414
Overall Steps per Second: 10,487.16757

Timestep Collection Time: 2.25994
Timestep Consumption Time: 2.50817
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.76811

Cumulative Model Updates: 197,426
Cumulative Timesteps: 1,646,341,126

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1646341126...
Checkpoint 1646341126 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,654.61266
Policy Entropy: 3.70123
Value Function Loss: 0.02582

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.44119
Value Function Update Magnitude: 0.47240

Collected Steps per Second: 22,012.68140
Overall Steps per Second: 10,691.98122

Timestep Collection Time: 2.27324
Timestep Consumption Time: 2.40691
PPO Batch Consumption Time: 0.27602
Total Iteration Time: 4.68014

Cumulative Model Updates: 197,432
Cumulative Timesteps: 1,646,391,166

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,116.94448
Policy Entropy: 3.72529
Value Function Loss: 0.02482

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12076
Policy Update Magnitude: 0.46431
Value Function Update Magnitude: 0.46651

Collected Steps per Second: 22,461.46432
Overall Steps per Second: 10,493.78985

Timestep Collection Time: 2.22701
Timestep Consumption Time: 2.53981
PPO Batch Consumption Time: 0.29061
Total Iteration Time: 4.76682

Cumulative Model Updates: 197,438
Cumulative Timesteps: 1,646,441,188

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1646441188...
Checkpoint 1646441188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,261.05873
Policy Entropy: 3.72548
Value Function Loss: 0.02488

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12147
Policy Update Magnitude: 0.49309
Value Function Update Magnitude: 0.62059

Collected Steps per Second: 22,454.60912
Overall Steps per Second: 10,540.70949

Timestep Collection Time: 2.22823
Timestep Consumption Time: 2.51851
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.74674

Cumulative Model Updates: 197,444
Cumulative Timesteps: 1,646,491,222

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 136,467.01245
Policy Entropy: 3.74226
Value Function Loss: 0.02531

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12498
Policy Update Magnitude: 0.50590
Value Function Update Magnitude: 0.66343

Collected Steps per Second: 23,027.38321
Overall Steps per Second: 10,870.78599

Timestep Collection Time: 2.17228
Timestep Consumption Time: 2.42922
PPO Batch Consumption Time: 0.27842
Total Iteration Time: 4.60151

Cumulative Model Updates: 197,450
Cumulative Timesteps: 1,646,541,244

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1646541244...
Checkpoint 1646541244 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,739.20553
Policy Entropy: 3.74513
Value Function Loss: 0.02749

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12200
Policy Update Magnitude: 0.55422
Value Function Update Magnitude: 0.66433

Collected Steps per Second: 21,697.28820
Overall Steps per Second: 10,590.59444

Timestep Collection Time: 2.30462
Timestep Consumption Time: 2.41693
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.72155

Cumulative Model Updates: 197,456
Cumulative Timesteps: 1,646,591,248

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,420.50667
Policy Entropy: 3.75386
Value Function Loss: 0.02843

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12497
Policy Update Magnitude: 0.57146
Value Function Update Magnitude: 0.66331

Collected Steps per Second: 22,435.95567
Overall Steps per Second: 10,569.91166

Timestep Collection Time: 2.22910
Timestep Consumption Time: 2.50244
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.73154

Cumulative Model Updates: 197,462
Cumulative Timesteps: 1,646,641,260

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1646641260...
Checkpoint 1646641260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,159.06505
Policy Entropy: 3.75035
Value Function Loss: 0.02837

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12648
Policy Update Magnitude: 0.53074
Value Function Update Magnitude: 0.70408

Collected Steps per Second: 22,738.58433
Overall Steps per Second: 10,666.56045

Timestep Collection Time: 2.19987
Timestep Consumption Time: 2.48974
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.68961

Cumulative Model Updates: 197,468
Cumulative Timesteps: 1,646,691,282

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 413.59626
Policy Entropy: 3.74242
Value Function Loss: 0.02529

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12584
Policy Update Magnitude: 0.52182
Value Function Update Magnitude: 0.71945

Collected Steps per Second: 22,341.04515
Overall Steps per Second: 10,904.61097

Timestep Collection Time: 2.23902
Timestep Consumption Time: 2.34822
PPO Batch Consumption Time: 0.27654
Total Iteration Time: 4.58723

Cumulative Model Updates: 197,474
Cumulative Timesteps: 1,646,741,304

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1646741304...
Checkpoint 1646741304 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103.52934
Policy Entropy: 3.72423
Value Function Loss: 0.02382

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12673
Policy Update Magnitude: 0.49668
Value Function Update Magnitude: 0.60222

Collected Steps per Second: 20,865.26077
Overall Steps per Second: 10,552.74296

Timestep Collection Time: 2.39671
Timestep Consumption Time: 2.34215
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.73886

Cumulative Model Updates: 197,480
Cumulative Timesteps: 1,646,791,312

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 45.77199
Policy Entropy: 3.70865
Value Function Loss: 0.02548

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.45434
Value Function Update Magnitude: 0.48212

Collected Steps per Second: 21,770.77184
Overall Steps per Second: 10,592.05757

Timestep Collection Time: 2.29776
Timestep Consumption Time: 2.42502
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.72278

Cumulative Model Updates: 197,486
Cumulative Timesteps: 1,646,841,336

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1646841336...
Checkpoint 1646841336 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 32.46476
Policy Entropy: 3.69812
Value Function Loss: 0.02796

Mean KL Divergence: 0.01014
SB3 Clip Fraction: 0.13461
Policy Update Magnitude: 0.45417
Value Function Update Magnitude: 0.40494

Collected Steps per Second: 21,700.82328
Overall Steps per Second: 10,556.50691

Timestep Collection Time: 2.30517
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.28356
Total Iteration Time: 4.73869

Cumulative Model Updates: 197,492
Cumulative Timesteps: 1,646,891,360

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,260.41501
Policy Entropy: 3.70618
Value Function Loss: 0.02649

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.46615
Value Function Update Magnitude: 0.39007

Collected Steps per Second: 22,500.15073
Overall Steps per Second: 10,830.61171

Timestep Collection Time: 2.22247
Timestep Consumption Time: 2.39462
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.61710

Cumulative Model Updates: 197,498
Cumulative Timesteps: 1,646,941,366

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1646941366...
Checkpoint 1646941366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,265.75710
Policy Entropy: 3.70646
Value Function Loss: 0.02951

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12658
Policy Update Magnitude: 0.51884
Value Function Update Magnitude: 0.40263

Collected Steps per Second: 21,924.48800
Overall Steps per Second: 10,669.20504

Timestep Collection Time: 2.28192
Timestep Consumption Time: 2.40727
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.68920

Cumulative Model Updates: 197,504
Cumulative Timesteps: 1,646,991,396

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 195,143.91248
Policy Entropy: 3.69977
Value Function Loss: 0.03108

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13189
Policy Update Magnitude: 0.55844
Value Function Update Magnitude: 0.55239

Collected Steps per Second: 22,846.80029
Overall Steps per Second: 10,643.01088

Timestep Collection Time: 2.18945
Timestep Consumption Time: 2.51053
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.69999

Cumulative Model Updates: 197,510
Cumulative Timesteps: 1,647,041,418

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1647041418...
Checkpoint 1647041418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,710.14434
Policy Entropy: 3.70998
Value Function Loss: 0.03241

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13779
Policy Update Magnitude: 0.58159
Value Function Update Magnitude: 0.63444

Collected Steps per Second: 22,437.68375
Overall Steps per Second: 10,558.25502

Timestep Collection Time: 2.22937
Timestep Consumption Time: 2.50834
PPO Batch Consumption Time: 0.29254
Total Iteration Time: 4.73771

Cumulative Model Updates: 197,516
Cumulative Timesteps: 1,647,091,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 68,710.37887
Policy Entropy: 3.71086
Value Function Loss: 0.02768

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.12870
Policy Update Magnitude: 0.56427
Value Function Update Magnitude: 0.60898

Collected Steps per Second: 22,963.75952
Overall Steps per Second: 10,832.13300

Timestep Collection Time: 2.17769
Timestep Consumption Time: 2.43894
PPO Batch Consumption Time: 0.27931
Total Iteration Time: 4.61663

Cumulative Model Updates: 197,522
Cumulative Timesteps: 1,647,141,448

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1647141448...
Checkpoint 1647141448 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,710.37887
Policy Entropy: 3.70903
Value Function Loss: 0.02435

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12963
Policy Update Magnitude: 0.51126
Value Function Update Magnitude: 0.55517

Collected Steps per Second: 22,543.75898
Overall Steps per Second: 10,688.68990

Timestep Collection Time: 2.21880
Timestep Consumption Time: 2.46092
PPO Batch Consumption Time: 0.28548
Total Iteration Time: 4.67971

Cumulative Model Updates: 197,528
Cumulative Timesteps: 1,647,191,468

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,204.68084
Policy Entropy: 3.69446
Value Function Loss: 0.02349

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13300
Policy Update Magnitude: 0.47819
Value Function Update Magnitude: 0.54878

Collected Steps per Second: 22,883.17275
Overall Steps per Second: 10,828.67898

Timestep Collection Time: 2.18650
Timestep Consumption Time: 2.43401
PPO Batch Consumption Time: 0.27766
Total Iteration Time: 4.62051

Cumulative Model Updates: 197,534
Cumulative Timesteps: 1,647,241,502

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1647241502...
Checkpoint 1647241502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 33,415.08101
Policy Entropy: 3.70968
Value Function Loss: 0.02840

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.12901
Policy Update Magnitude: 0.50325
Value Function Update Magnitude: 0.72071

Collected Steps per Second: 22,421.32259
Overall Steps per Second: 10,646.18788

Timestep Collection Time: 2.23020
Timestep Consumption Time: 2.46669
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.69689

Cumulative Model Updates: 197,540
Cumulative Timesteps: 1,647,291,506

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,202.68513
Policy Entropy: 3.71852
Value Function Loss: 0.02958

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12244
Policy Update Magnitude: 0.53338
Value Function Update Magnitude: 0.79660

Collected Steps per Second: 22,253.10311
Overall Steps per Second: 10,518.81765

Timestep Collection Time: 2.24778
Timestep Consumption Time: 2.50751
PPO Batch Consumption Time: 0.29235
Total Iteration Time: 4.75529

Cumulative Model Updates: 197,546
Cumulative Timesteps: 1,647,341,526

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1647341526...
Checkpoint 1647341526 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,202.68513
Policy Entropy: 3.71386
Value Function Loss: 0.02875

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.11943
Policy Update Magnitude: 0.49453
Value Function Update Magnitude: 0.75242

Collected Steps per Second: 21,789.43170
Overall Steps per Second: 10,609.57388

Timestep Collection Time: 2.29552
Timestep Consumption Time: 2.41890
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.71442

Cumulative Model Updates: 197,552
Cumulative Timesteps: 1,647,391,544

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 6,202.68513
Policy Entropy: 3.69837
Value Function Loss: 0.02625

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.49047
Value Function Update Magnitude: 0.61376

Collected Steps per Second: 22,325.36567
Overall Steps per Second: 10,540.67008

Timestep Collection Time: 2.24059
Timestep Consumption Time: 2.50503
PPO Batch Consumption Time: 0.29198
Total Iteration Time: 4.74562

Cumulative Model Updates: 197,558
Cumulative Timesteps: 1,647,441,566

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1647441566...
Checkpoint 1647441566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,510.93022
Policy Entropy: 3.68280
Value Function Loss: 0.02820

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12616
Policy Update Magnitude: 0.49014
Value Function Update Magnitude: 0.47097

Collected Steps per Second: 22,190.64973
Overall Steps per Second: 10,586.90846

Timestep Collection Time: 2.25428
Timestep Consumption Time: 2.47080
PPO Batch Consumption Time: 0.28511
Total Iteration Time: 4.72508

Cumulative Model Updates: 197,564
Cumulative Timesteps: 1,647,491,590

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 47,510.93022
Policy Entropy: 3.68314
Value Function Loss: 0.02485

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.13607
Policy Update Magnitude: 0.50122
Value Function Update Magnitude: 0.54885

Collected Steps per Second: 22,369.02525
Overall Steps per Second: 10,537.32635

Timestep Collection Time: 2.23675
Timestep Consumption Time: 2.51151
PPO Batch Consumption Time: 0.29185
Total Iteration Time: 4.74826

Cumulative Model Updates: 197,570
Cumulative Timesteps: 1,647,541,624

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1647541624...
Checkpoint 1647541624 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 47,510.93022
Policy Entropy: 3.66000
Value Function Loss: 0.02811

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.13544
Policy Update Magnitude: 0.49999
Value Function Update Magnitude: 0.65988

Collected Steps per Second: 21,485.04139
Overall Steps per Second: 10,582.40726

Timestep Collection Time: 2.32832
Timestep Consumption Time: 2.39877
PPO Batch Consumption Time: 0.28202
Total Iteration Time: 4.72709

Cumulative Model Updates: 197,576
Cumulative Timesteps: 1,647,591,648

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 285,513.03722
Policy Entropy: 3.66282
Value Function Loss: 0.02862

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12256
Policy Update Magnitude: 0.50449
Value Function Update Magnitude: 0.50992

Collected Steps per Second: 22,204.11144
Overall Steps per Second: 10,838.85232

Timestep Collection Time: 2.25256
Timestep Consumption Time: 2.36195
PPO Batch Consumption Time: 0.27891
Total Iteration Time: 4.61451

Cumulative Model Updates: 197,582
Cumulative Timesteps: 1,647,641,664

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1647641664...
Checkpoint 1647641664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 507,928.22740
Policy Entropy: 3.66845
Value Function Loss: 0.03374

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11979
Policy Update Magnitude: 0.51840
Value Function Update Magnitude: 0.44944

Collected Steps per Second: 21,611.80219
Overall Steps per Second: 10,597.00673

Timestep Collection Time: 2.31466
Timestep Consumption Time: 2.40592
PPO Batch Consumption Time: 0.27870
Total Iteration Time: 4.72058

Cumulative Model Updates: 197,588
Cumulative Timesteps: 1,647,691,688

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 507,928.22740
Policy Entropy: 3.67321
Value Function Loss: 0.03059

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12033
Policy Update Magnitude: 0.52932
Value Function Update Magnitude: 0.49512

Collected Steps per Second: 22,296.63050
Overall Steps per Second: 10,597.76995

Timestep Collection Time: 2.24339
Timestep Consumption Time: 2.47647
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.71986

Cumulative Model Updates: 197,594
Cumulative Timesteps: 1,647,741,708

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1647741708...
Checkpoint 1647741708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284,380.51633
Policy Entropy: 3.67920
Value Function Loss: 0.02879

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12586
Policy Update Magnitude: 0.50086
Value Function Update Magnitude: 0.50791

Collected Steps per Second: 22,515.65451
Overall Steps per Second: 10,658.13027

Timestep Collection Time: 2.22077
Timestep Consumption Time: 2.47068
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 4.69144

Cumulative Model Updates: 197,600
Cumulative Timesteps: 1,647,791,710

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284,380.51633
Policy Entropy: 3.67176
Value Function Loss: 0.02386

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.12563
Policy Update Magnitude: 0.48373
Value Function Update Magnitude: 0.43281

Collected Steps per Second: 22,902.07699
Overall Steps per Second: 10,855.72252

Timestep Collection Time: 2.18321
Timestep Consumption Time: 2.42266
PPO Batch Consumption Time: 0.27730
Total Iteration Time: 4.60587

Cumulative Model Updates: 197,606
Cumulative Timesteps: 1,647,841,710

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1647841710...
Checkpoint 1647841710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284,380.51633
Policy Entropy: 3.68636
Value Function Loss: 0.02164

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12720
Policy Update Magnitude: 0.44201
Value Function Update Magnitude: 0.37747

Collected Steps per Second: 21,888.92435
Overall Steps per Second: 10,588.32161

Timestep Collection Time: 2.28444
Timestep Consumption Time: 2.43812
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.72256

Cumulative Model Updates: 197,612
Cumulative Timesteps: 1,647,891,714

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284,380.51633
Policy Entropy: 3.68099
Value Function Loss: 0.02200

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.37476
Value Function Update Magnitude: 0.31805

Collected Steps per Second: 22,353.81468
Overall Steps per Second: 10,557.65192

Timestep Collection Time: 2.23765
Timestep Consumption Time: 2.50015
PPO Batch Consumption Time: 0.29094
Total Iteration Time: 4.73780

Cumulative Model Updates: 197,618
Cumulative Timesteps: 1,647,941,734

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1647941734...
Checkpoint 1647941734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 284,380.51633
Policy Entropy: 3.68583
Value Function Loss: 0.01881

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.34802
Value Function Update Magnitude: 0.26386

Collected Steps per Second: 21,932.80630
Overall Steps per Second: 10,561.24285

Timestep Collection Time: 2.27996
Timestep Consumption Time: 2.45490
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.73486

Cumulative Model Updates: 197,624
Cumulative Timesteps: 1,647,991,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284,380.51633
Policy Entropy: 3.68064
Value Function Loss: 0.01952

Mean KL Divergence: 0.00945
SB3 Clip Fraction: 0.12328
Policy Update Magnitude: 0.33625
Value Function Update Magnitude: 0.27363

Collected Steps per Second: 22,575.04680
Overall Steps per Second: 10,588.55872

Timestep Collection Time: 2.21528
Timestep Consumption Time: 2.50774
PPO Batch Consumption Time: 0.29004
Total Iteration Time: 4.72302

Cumulative Model Updates: 197,630
Cumulative Timesteps: 1,648,041,750

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1648041750...
Checkpoint 1648041750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 344,660.69708
Policy Entropy: 3.69198
Value Function Loss: 0.01852

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12707
Policy Update Magnitude: 0.36853
Value Function Update Magnitude: 0.40178

Collected Steps per Second: 22,827.31611
Overall Steps per Second: 10,682.16796

Timestep Collection Time: 2.19132
Timestep Consumption Time: 2.49144
PPO Batch Consumption Time: 0.28921
Total Iteration Time: 4.68276

Cumulative Model Updates: 197,636
Cumulative Timesteps: 1,648,091,772

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 350,813.43553
Policy Entropy: 3.69859
Value Function Loss: 0.02160

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.12729
Policy Update Magnitude: 0.40982
Value Function Update Magnitude: 0.50066

Collected Steps per Second: 22,247.95232
Overall Steps per Second: 10,734.33910

Timestep Collection Time: 2.24830
Timestep Consumption Time: 2.41152
PPO Batch Consumption Time: 0.28758
Total Iteration Time: 4.65981

Cumulative Model Updates: 197,642
Cumulative Timesteps: 1,648,141,792

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1648141792...
Checkpoint 1648141792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 186,441.46291
Policy Entropy: 3.70973
Value Function Loss: 0.02208

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12574
Policy Update Magnitude: 0.44584
Value Function Update Magnitude: 0.58505

Collected Steps per Second: 21,875.06234
Overall Steps per Second: 10,644.69145

Timestep Collection Time: 2.28580
Timestep Consumption Time: 2.41157
PPO Batch Consumption Time: 0.28879
Total Iteration Time: 4.69736

Cumulative Model Updates: 197,648
Cumulative Timesteps: 1,648,191,794

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,441.46291
Policy Entropy: 3.70266
Value Function Loss: 0.02093

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12350
Policy Update Magnitude: 0.44277
Value Function Update Magnitude: 0.63811

Collected Steps per Second: 22,485.67226
Overall Steps per Second: 10,775.74062

Timestep Collection Time: 2.22382
Timestep Consumption Time: 2.41661
PPO Batch Consumption Time: 0.27888
Total Iteration Time: 4.64042

Cumulative Model Updates: 197,654
Cumulative Timesteps: 1,648,241,798

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1648241798...
Checkpoint 1648241798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 394,885.96140
Policy Entropy: 3.69088
Value Function Loss: 0.02226

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12756
Policy Update Magnitude: 0.43101
Value Function Update Magnitude: 0.50760

Collected Steps per Second: 22,613.51120
Overall Steps per Second: 10,735.65263

Timestep Collection Time: 2.21124
Timestep Consumption Time: 2.44651
PPO Batch Consumption Time: 0.28552
Total Iteration Time: 4.65775

Cumulative Model Updates: 197,660
Cumulative Timesteps: 1,648,291,802

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,863.93665
Policy Entropy: 3.68943
Value Function Loss: 0.02078

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13333
Policy Update Magnitude: 0.44985
Value Function Update Magnitude: 0.46005

Collected Steps per Second: 23,064.24570
Overall Steps per Second: 10,929.98867

Timestep Collection Time: 2.16916
Timestep Consumption Time: 2.40816
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.57731

Cumulative Model Updates: 197,666
Cumulative Timesteps: 1,648,341,832

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1648341832...
Checkpoint 1648341832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 209,863.93665
Policy Entropy: 3.67325
Value Function Loss: 0.02305

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13785
Policy Update Magnitude: 0.44171
Value Function Update Magnitude: 0.47334

Collected Steps per Second: 22,198.50773
Overall Steps per Second: 10,647.10431

Timestep Collection Time: 2.25376
Timestep Consumption Time: 2.44518
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.69893

Cumulative Model Updates: 197,672
Cumulative Timesteps: 1,648,391,862

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 209,863.93665
Policy Entropy: 3.69506
Value Function Loss: 0.02041

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13103
Policy Update Magnitude: 0.45911
Value Function Update Magnitude: 0.44726

Collected Steps per Second: 22,223.07722
Overall Steps per Second: 10,533.36899

Timestep Collection Time: 2.25081
Timestep Consumption Time: 2.49790
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.74872

Cumulative Model Updates: 197,678
Cumulative Timesteps: 1,648,441,882

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1648441882...
Checkpoint 1648441882 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 417,657.60268
Policy Entropy: 3.68109
Value Function Loss: 0.02589

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12143
Policy Update Magnitude: 0.47449
Value Function Update Magnitude: 0.39335

Collected Steps per Second: 21,954.70531
Overall Steps per Second: 10,525.97110

Timestep Collection Time: 2.27824
Timestep Consumption Time: 2.47363
PPO Batch Consumption Time: 0.28570
Total Iteration Time: 4.75187

Cumulative Model Updates: 197,684
Cumulative Timesteps: 1,648,491,900

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 222,097.78288
Policy Entropy: 3.70325
Value Function Loss: 0.02373

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11993
Policy Update Magnitude: 0.51304
Value Function Update Magnitude: 0.51214

Collected Steps per Second: 22,253.19967
Overall Steps per Second: 10,535.65326

Timestep Collection Time: 2.24687
Timestep Consumption Time: 2.49892
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.74579

Cumulative Model Updates: 197,690
Cumulative Timesteps: 1,648,541,900

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1648541900...
Checkpoint 1648541900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,729.60588
Policy Entropy: 3.70695
Value Function Loss: 0.02799

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12295
Policy Update Magnitude: 0.53751
Value Function Update Magnitude: 0.56728

Collected Steps per Second: 21,992.80650
Overall Steps per Second: 10,672.36815

Timestep Collection Time: 2.27547
Timestep Consumption Time: 2.41365
PPO Batch Consumption Time: 0.27590
Total Iteration Time: 4.68912

Cumulative Model Updates: 197,696
Cumulative Timesteps: 1,648,591,944

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,488.24579
Policy Entropy: 3.71380
Value Function Loss: 0.02552

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12323
Policy Update Magnitude: 0.55210
Value Function Update Magnitude: 0.58695

Collected Steps per Second: 23,090.94702
Overall Steps per Second: 10,773.54961

Timestep Collection Time: 2.16613
Timestep Consumption Time: 2.47654
PPO Batch Consumption Time: 0.28417
Total Iteration Time: 4.64267

Cumulative Model Updates: 197,702
Cumulative Timesteps: 1,648,641,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1648641962...
Checkpoint 1648641962 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,488.24579
Policy Entropy: 3.71413
Value Function Loss: 0.02274

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.50348
Value Function Update Magnitude: 0.67917

Collected Steps per Second: 22,506.69877
Overall Steps per Second: 10,639.67521

Timestep Collection Time: 2.22183
Timestep Consumption Time: 2.47813
PPO Batch Consumption Time: 0.28524
Total Iteration Time: 4.69996

Cumulative Model Updates: 197,708
Cumulative Timesteps: 1,648,691,968

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,488.24579
Policy Entropy: 3.70017
Value Function Loss: 0.02066

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13496
Policy Update Magnitude: 0.45648
Value Function Update Magnitude: 0.55087

Collected Steps per Second: 23,099.01609
Overall Steps per Second: 10,883.57008

Timestep Collection Time: 2.16546
Timestep Consumption Time: 2.43046
PPO Batch Consumption Time: 0.27758
Total Iteration Time: 4.59592

Cumulative Model Updates: 197,714
Cumulative Timesteps: 1,648,741,988

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1648741988...
Checkpoint 1648741988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,488.24579
Policy Entropy: 3.71044
Value Function Loss: 0.01669

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13330
Policy Update Magnitude: 0.44970
Value Function Update Magnitude: 0.47037

Collected Steps per Second: 22,550.42086
Overall Steps per Second: 10,720.89052

Timestep Collection Time: 2.21832
Timestep Consumption Time: 2.44771
PPO Batch Consumption Time: 0.28332
Total Iteration Time: 4.66603

Cumulative Model Updates: 197,720
Cumulative Timesteps: 1,648,792,012

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,488.24579
Policy Entropy: 3.70758
Value Function Loss: 0.01670

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.42554
Value Function Update Magnitude: 0.43604

Collected Steps per Second: 23,102.28004
Overall Steps per Second: 10,876.57613

Timestep Collection Time: 2.16472
Timestep Consumption Time: 2.43323
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.59795

Cumulative Model Updates: 197,726
Cumulative Timesteps: 1,648,842,022

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1648842022...
Checkpoint 1648842022 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 73,488.24579
Policy Entropy: 3.72407
Value Function Loss: 0.01485

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13108
Policy Update Magnitude: 0.40588
Value Function Update Magnitude: 0.35041

Collected Steps per Second: 22,482.55586
Overall Steps per Second: 10,684.01195

Timestep Collection Time: 2.22466
Timestep Consumption Time: 2.45673
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.68139

Cumulative Model Updates: 197,732
Cumulative Timesteps: 1,648,892,038

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 73,488.24579
Policy Entropy: 3.70496
Value Function Loss: 0.01526

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.37344
Value Function Update Magnitude: 0.29919

Collected Steps per Second: 22,504.94403
Overall Steps per Second: 10,646.55700

Timestep Collection Time: 2.22182
Timestep Consumption Time: 2.47472
PPO Batch Consumption Time: 0.28711
Total Iteration Time: 4.69654

Cumulative Model Updates: 197,738
Cumulative Timesteps: 1,648,942,040

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1648942040...
Checkpoint 1648942040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,213.42700
Policy Entropy: 3.68423
Value Function Loss: 0.02030

Mean KL Divergence: 0.02286
SB3 Clip Fraction: 0.26312
Policy Update Magnitude: 0.37676
Value Function Update Magnitude: 0.42743

Collected Steps per Second: 22,171.22395
Overall Steps per Second: 10,536.51566

Timestep Collection Time: 2.25707
Timestep Consumption Time: 2.49232
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.74939

Cumulative Model Updates: 197,744
Cumulative Timesteps: 1,648,992,082

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 856,327.04749
Policy Entropy: 3.67473
Value Function Loss: 0.04553

Mean KL Divergence: 0.01589
SB3 Clip Fraction: 0.19337
Policy Update Magnitude: 0.47226
Value Function Update Magnitude: 0.61309

Collected Steps per Second: 21,995.95521
Overall Steps per Second: 10,524.03174

Timestep Collection Time: 2.27315
Timestep Consumption Time: 2.47789
PPO Batch Consumption Time: 0.28899
Total Iteration Time: 4.75103

Cumulative Model Updates: 197,750
Cumulative Timesteps: 1,649,042,082

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1649042082...
Checkpoint 1649042082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,649.72509
Policy Entropy: 3.72218
Value Function Loss: 0.05715

Mean KL Divergence: 0.01829
SB3 Clip Fraction: 0.19488
Policy Update Magnitude: 0.77541
Value Function Update Magnitude: 0.64631

Collected Steps per Second: 22,223.76511
Overall Steps per Second: 10,505.58556

Timestep Collection Time: 2.25119
Timestep Consumption Time: 2.51103
PPO Batch Consumption Time: 0.29178
Total Iteration Time: 4.76223

Cumulative Model Updates: 197,756
Cumulative Timesteps: 1,649,092,112

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,613.48479
Policy Entropy: 3.76608
Value Function Loss: 0.06587

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.17498
Policy Update Magnitude: 0.90684
Value Function Update Magnitude: 0.67260

Collected Steps per Second: 22,926.51863
Overall Steps per Second: 10,775.66615

Timestep Collection Time: 2.18184
Timestep Consumption Time: 2.46029
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.64213

Cumulative Model Updates: 197,762
Cumulative Timesteps: 1,649,142,134

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1649142134...
Checkpoint 1649142134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 650.53184
Policy Entropy: 3.82473
Value Function Loss: 0.03685

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.14837
Policy Update Magnitude: 0.87146
Value Function Update Magnitude: 0.69933

Collected Steps per Second: 22,217.04578
Overall Steps per Second: 10,693.91983

Timestep Collection Time: 2.25079
Timestep Consumption Time: 2.42532
PPO Batch Consumption Time: 0.27858
Total Iteration Time: 4.67612

Cumulative Model Updates: 197,768
Cumulative Timesteps: 1,649,192,140

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 433.97935
Policy Entropy: 3.81149
Value Function Loss: 0.02387

Mean KL Divergence: 0.00844
SB3 Clip Fraction: 0.10624
Policy Update Magnitude: 0.72114
Value Function Update Magnitude: 0.78224

Collected Steps per Second: 22,676.21513
Overall Steps per Second: 10,647.94641

Timestep Collection Time: 2.20513
Timestep Consumption Time: 2.49099
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.69612

Cumulative Model Updates: 197,774
Cumulative Timesteps: 1,649,242,144

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1649242144...
Checkpoint 1649242144 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433.97935
Policy Entropy: 3.78567
Value Function Loss: 0.01658

Mean KL Divergence: 0.00583
SB3 Clip Fraction: 0.06976
Policy Update Magnitude: 0.62195
Value Function Update Magnitude: 0.70390

Collected Steps per Second: 22,053.47500
Overall Steps per Second: 10,847.67972

Timestep Collection Time: 2.26794
Timestep Consumption Time: 2.34281
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.61076

Cumulative Model Updates: 197,780
Cumulative Timesteps: 1,649,292,160

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 177,703.27810
Policy Entropy: 3.74980
Value Function Loss: 0.01457

Mean KL Divergence: 0.00596
SB3 Clip Fraction: 0.07289
Policy Update Magnitude: 0.53575
Value Function Update Magnitude: 0.58908

Collected Steps per Second: 22,242.02810
Overall Steps per Second: 10,755.92219

Timestep Collection Time: 2.24827
Timestep Consumption Time: 2.40089
PPO Batch Consumption Time: 0.28748
Total Iteration Time: 4.64916

Cumulative Model Updates: 197,786
Cumulative Timesteps: 1,649,342,166

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1649342166...
Checkpoint 1649342166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 61,968.28790
Policy Entropy: 3.74339
Value Function Loss: 0.01350

Mean KL Divergence: 0.00430
SB3 Clip Fraction: 0.04713
Policy Update Magnitude: 0.45229
Value Function Update Magnitude: 0.53352

Collected Steps per Second: 21,766.45461
Overall Steps per Second: 10,806.53807

Timestep Collection Time: 2.29730
Timestep Consumption Time: 2.32990
PPO Batch Consumption Time: 0.27760
Total Iteration Time: 4.62720

Cumulative Model Updates: 197,792
Cumulative Timesteps: 1,649,392,170

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,509.31454
Policy Entropy: 3.75538
Value Function Loss: 0.01413

Mean KL Divergence: 0.00464
SB3 Clip Fraction: 0.05204
Policy Update Magnitude: 0.41809
Value Function Update Magnitude: 0.53100

Collected Steps per Second: 21,953.78598
Overall Steps per Second: 10,533.46616

Timestep Collection Time: 2.27778
Timestep Consumption Time: 2.46956
PPO Batch Consumption Time: 0.28852
Total Iteration Time: 4.74735

Cumulative Model Updates: 197,798
Cumulative Timesteps: 1,649,442,176

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1649442176...
Checkpoint 1649442176 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,115.38001
Policy Entropy: 3.77243
Value Function Loss: 0.01340

Mean KL Divergence: 0.00434
SB3 Clip Fraction: 0.04707
Policy Update Magnitude: 0.39969
Value Function Update Magnitude: 0.55910

Collected Steps per Second: 22,043.81511
Overall Steps per Second: 10,613.44101

Timestep Collection Time: 2.26848
Timestep Consumption Time: 2.44309
PPO Batch Consumption Time: 0.28510
Total Iteration Time: 4.71157

Cumulative Model Updates: 197,804
Cumulative Timesteps: 1,649,492,182

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,733.42787
Policy Entropy: 3.78862
Value Function Loss: 0.01260

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05483
Policy Update Magnitude: 0.37897
Value Function Update Magnitude: 0.52297

Collected Steps per Second: 22,784.55517
Overall Steps per Second: 10,874.61222

Timestep Collection Time: 2.19447
Timestep Consumption Time: 2.40340
PPO Batch Consumption Time: 0.27773
Total Iteration Time: 4.59787

Cumulative Model Updates: 197,810
Cumulative Timesteps: 1,649,542,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1649542182...
Checkpoint 1649542182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 617.98233
Policy Entropy: 3.79701
Value Function Loss: 0.01315

Mean KL Divergence: 0.00391
SB3 Clip Fraction: 0.04057
Policy Update Magnitude: 0.38596
Value Function Update Magnitude: 0.51452

Collected Steps per Second: 22,491.32512
Overall Steps per Second: 10,661.36403

Timestep Collection Time: 2.22335
Timestep Consumption Time: 2.46705
PPO Batch Consumption Time: 0.27880
Total Iteration Time: 4.69039

Cumulative Model Updates: 197,816
Cumulative Timesteps: 1,649,592,188

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 223.45319
Policy Entropy: 3.78754
Value Function Loss: 0.01319

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03884
Policy Update Magnitude: 0.43498
Value Function Update Magnitude: 0.54870

Collected Steps per Second: 23,110.84910
Overall Steps per Second: 10,871.76578

Timestep Collection Time: 2.16444
Timestep Consumption Time: 2.43665
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.60109

Cumulative Model Updates: 197,822
Cumulative Timesteps: 1,649,642,210

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1649642210...
Checkpoint 1649642210 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75.80927
Policy Entropy: 3.76869
Value Function Loss: 0.01422

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05220
Policy Update Magnitude: 0.44640
Value Function Update Magnitude: 0.56702

Collected Steps per Second: 22,678.13745
Overall Steps per Second: 10,680.07925

Timestep Collection Time: 2.20477
Timestep Consumption Time: 2.47685
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.68161

Cumulative Model Updates: 197,828
Cumulative Timesteps: 1,649,692,210

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.75709
Value Function Loss: 0.01389

Mean KL Divergence: 0.00420
SB3 Clip Fraction: 0.04304
Policy Update Magnitude: 0.44294
Value Function Update Magnitude: 0.61259

Collected Steps per Second: 22,734.75088
Overall Steps per Second: 10,669.59102

Timestep Collection Time: 2.20156
Timestep Consumption Time: 2.48953
PPO Batch Consumption Time: 0.28805
Total Iteration Time: 4.69109

Cumulative Model Updates: 197,834
Cumulative Timesteps: 1,649,742,262

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1649742262...
Checkpoint 1649742262 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.75776
Value Function Loss: 0.01410

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06221
Policy Update Magnitude: 0.45115
Value Function Update Magnitude: 0.56125

Collected Steps per Second: 22,440.74889
Overall Steps per Second: 10,587.96260

Timestep Collection Time: 2.22871
Timestep Consumption Time: 2.49495
PPO Batch Consumption Time: 0.28925
Total Iteration Time: 4.72367

Cumulative Model Updates: 197,840
Cumulative Timesteps: 1,649,792,276

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.74426
Value Function Loss: 0.01313

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.11940
Policy Update Magnitude: 0.42689
Value Function Update Magnitude: 0.52553

Collected Steps per Second: 22,717.68970
Overall Steps per Second: 10,815.24855

Timestep Collection Time: 2.20181
Timestep Consumption Time: 2.42314
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.62495

Cumulative Model Updates: 197,846
Cumulative Timesteps: 1,649,842,296

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1649842296...
Checkpoint 1649842296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.72217
Value Function Loss: 0.01385

Mean KL Divergence: 0.00586
SB3 Clip Fraction: 0.07099
Policy Update Magnitude: 0.43797
Value Function Update Magnitude: 0.44256

Collected Steps per Second: 21,611.00324
Overall Steps per Second: 10,490.34475

Timestep Collection Time: 2.31419
Timestep Consumption Time: 2.45324
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.76743

Cumulative Model Updates: 197,852
Cumulative Timesteps: 1,649,892,308

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.72664
Value Function Loss: 0.01426

Mean KL Divergence: 0.00534
SB3 Clip Fraction: 0.06250
Policy Update Magnitude: 0.48318
Value Function Update Magnitude: 0.32827

Collected Steps per Second: 22,426.70712
Overall Steps per Second: 10,550.63277

Timestep Collection Time: 2.22984
Timestep Consumption Time: 2.50997
PPO Batch Consumption Time: 0.29054
Total Iteration Time: 4.73981

Cumulative Model Updates: 197,858
Cumulative Timesteps: 1,649,942,316

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1649942316...
Checkpoint 1649942316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.73250
Value Function Loss: 0.01395

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04946
Policy Update Magnitude: 0.47314
Value Function Update Magnitude: 0.28852

Collected Steps per Second: 22,007.95271
Overall Steps per Second: 10,692.17137

Timestep Collection Time: 2.27309
Timestep Consumption Time: 2.40566
PPO Batch Consumption Time: 0.27548
Total Iteration Time: 4.67875

Cumulative Model Updates: 197,864
Cumulative Timesteps: 1,649,992,342

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.73413
Value Function Loss: 0.01266

Mean KL Divergence: 0.00449
SB3 Clip Fraction: 0.04828
Policy Update Magnitude: 0.43719
Value Function Update Magnitude: 0.25890

Collected Steps per Second: 22,635.39976
Overall Steps per Second: 10,793.46142

Timestep Collection Time: 2.20955
Timestep Consumption Time: 2.42418
PPO Batch Consumption Time: 0.27743
Total Iteration Time: 4.63373

Cumulative Model Updates: 197,870
Cumulative Timesteps: 1,650,042,356

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1650042356...
Checkpoint 1650042356 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.74216
Value Function Loss: 0.01166

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06892
Policy Update Magnitude: 0.42185
Value Function Update Magnitude: 0.24247

Collected Steps per Second: 21,926.36759
Overall Steps per Second: 10,627.02869

Timestep Collection Time: 2.28118
Timestep Consumption Time: 2.42550
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.70668

Cumulative Model Updates: 197,876
Cumulative Timesteps: 1,650,092,374

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.74770
Value Function Loss: 0.01315

Mean KL Divergence: 0.00673
SB3 Clip Fraction: 0.08438
Policy Update Magnitude: 0.42584
Value Function Update Magnitude: 0.36395

Collected Steps per Second: 23,029.40424
Overall Steps per Second: 10,680.86409

Timestep Collection Time: 2.17235
Timestep Consumption Time: 2.51154
PPO Batch Consumption Time: 0.28885
Total Iteration Time: 4.68389

Cumulative Model Updates: 197,882
Cumulative Timesteps: 1,650,142,402

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1650142402...
Checkpoint 1650142402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.74983
Value Function Loss: 0.01284

Mean KL Divergence: 0.00825
SB3 Clip Fraction: 0.10608
Policy Update Magnitude: 0.43053
Value Function Update Magnitude: 0.53434

Collected Steps per Second: 22,549.12256
Overall Steps per Second: 10,644.88144

Timestep Collection Time: 2.21889
Timestep Consumption Time: 2.48140
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.70029

Cumulative Model Updates: 197,888
Cumulative Timesteps: 1,650,192,436

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.73572
Value Function Loss: 0.01376

Mean KL Divergence: 0.01095
SB3 Clip Fraction: 0.14222
Policy Update Magnitude: 0.35744
Value Function Update Magnitude: 0.50815

Collected Steps per Second: 22,938.09068
Overall Steps per Second: 10,750.11277

Timestep Collection Time: 2.18057
Timestep Consumption Time: 2.47222
PPO Batch Consumption Time: 0.28352
Total Iteration Time: 4.65279

Cumulative Model Updates: 197,894
Cumulative Timesteps: 1,650,242,454

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1650242454...
Checkpoint 1650242454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.74509
Value Function Loss: 0.01272

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06267
Policy Update Magnitude: 0.37226
Value Function Update Magnitude: 0.38653

Collected Steps per Second: 21,729.93049
Overall Steps per Second: 10,642.06539

Timestep Collection Time: 2.30153
Timestep Consumption Time: 2.39794
PPO Batch Consumption Time: 0.28721
Total Iteration Time: 4.69946

Cumulative Model Updates: 197,900
Cumulative Timesteps: 1,650,292,466

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31.91106
Policy Entropy: 3.72256
Value Function Loss: 0.01491

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.06009
Policy Update Magnitude: 0.47354
Value Function Update Magnitude: 0.37140

Collected Steps per Second: 22,353.66075
Overall Steps per Second: 10,897.37294

Timestep Collection Time: 2.23677
Timestep Consumption Time: 2.35149
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.58826

Cumulative Model Updates: 197,906
Cumulative Timesteps: 1,650,342,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1650342466...
Checkpoint 1650342466 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,866.45785
Policy Entropy: 3.74833
Value Function Loss: 0.01424

Mean KL Divergence: 0.00474
SB3 Clip Fraction: 0.05140
Policy Update Magnitude: 0.52558
Value Function Update Magnitude: 0.44212

Collected Steps per Second: 21,651.38115
Overall Steps per Second: 10,656.44148

Timestep Collection Time: 2.30932
Timestep Consumption Time: 2.38268
PPO Batch Consumption Time: 0.28337
Total Iteration Time: 4.69200

Cumulative Model Updates: 197,912
Cumulative Timesteps: 1,650,392,466

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,866.45785
Policy Entropy: 3.73715
Value Function Loss: 0.01726

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.11818
Policy Update Magnitude: 0.56151
Value Function Update Magnitude: 0.57038

Collected Steps per Second: 22,133.54958
Overall Steps per Second: 10,567.70553

Timestep Collection Time: 2.26010
Timestep Consumption Time: 2.47357
PPO Batch Consumption Time: 0.29036
Total Iteration Time: 4.73367

Cumulative Model Updates: 197,918
Cumulative Timesteps: 1,650,442,490

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1650442490...
Checkpoint 1650442490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,866.45785
Policy Entropy: 3.73314
Value Function Loss: 0.01748

Mean KL Divergence: 0.01630
SB3 Clip Fraction: 0.20572
Policy Update Magnitude: 0.46725
Value Function Update Magnitude: 0.56417

Collected Steps per Second: 21,506.25460
Overall Steps per Second: 10,461.48822

Timestep Collection Time: 2.32621
Timestep Consumption Time: 2.45590
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.78211

Cumulative Model Updates: 197,924
Cumulative Timesteps: 1,650,492,518

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,866.45785
Policy Entropy: 3.72256
Value Function Loss: 0.01670

Mean KL Divergence: 0.01523
SB3 Clip Fraction: 0.18932
Policy Update Magnitude: 0.39069
Value Function Update Magnitude: 0.52569

Collected Steps per Second: 22,316.70577
Overall Steps per Second: 10,525.61010

Timestep Collection Time: 2.24074
Timestep Consumption Time: 2.51015
PPO Batch Consumption Time: 0.29217
Total Iteration Time: 4.75089

Cumulative Model Updates: 197,930
Cumulative Timesteps: 1,650,542,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1650542524...
Checkpoint 1650542524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,866.45785
Policy Entropy: 3.71221
Value Function Loss: 0.01546

Mean KL Divergence: 0.01503
SB3 Clip Fraction: 0.18211
Policy Update Magnitude: 0.36981
Value Function Update Magnitude: 0.42945

Collected Steps per Second: 21,648.98653
Overall Steps per Second: 10,563.82461

Timestep Collection Time: 2.31087
Timestep Consumption Time: 2.42491
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.73578

Cumulative Model Updates: 197,936
Cumulative Timesteps: 1,650,592,552

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,866.45785
Policy Entropy: 3.71560
Value Function Loss: 0.01615

Mean KL Divergence: 0.01170
SB3 Clip Fraction: 0.15609
Policy Update Magnitude: 0.33878
Value Function Update Magnitude: 0.36903

Collected Steps per Second: 21,429.48354
Overall Steps per Second: 10,244.12223

Timestep Collection Time: 2.33445
Timestep Consumption Time: 2.54894
PPO Batch Consumption Time: 0.29001
Total Iteration Time: 4.88339

Cumulative Model Updates: 197,942
Cumulative Timesteps: 1,650,642,578

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1650642578...
Checkpoint 1650642578 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,866.45785
Policy Entropy: 3.69620
Value Function Loss: 0.01877

Mean KL Divergence: 0.01165
SB3 Clip Fraction: 0.15521
Policy Update Magnitude: 0.33625
Value Function Update Magnitude: 0.40888

Collected Steps per Second: 21,306.39345
Overall Steps per Second: 10,224.03580

Timestep Collection Time: 2.34775
Timestep Consumption Time: 2.54484
PPO Batch Consumption Time: 0.28781
Total Iteration Time: 4.89259

Cumulative Model Updates: 197,948
Cumulative Timesteps: 1,650,692,600

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,914.86279
Policy Entropy: 3.69296
Value Function Loss: 0.01939

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15765
Policy Update Magnitude: 0.36462
Value Function Update Magnitude: 0.40078

Collected Steps per Second: 23,166.36047
Overall Steps per Second: 10,691.40389

Timestep Collection Time: 2.15882
Timestep Consumption Time: 2.51896
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.67778

Cumulative Model Updates: 197,954
Cumulative Timesteps: 1,650,742,612

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1650742612...
Checkpoint 1650742612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,914.86279
Policy Entropy: 3.69811
Value Function Loss: 0.01773

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14921
Policy Update Magnitude: 0.35312
Value Function Update Magnitude: 0.38870

Collected Steps per Second: 22,704.58226
Overall Steps per Second: 10,668.69664

Timestep Collection Time: 2.20317
Timestep Consumption Time: 2.48550
PPO Batch Consumption Time: 0.28906
Total Iteration Time: 4.68867

Cumulative Model Updates: 197,960
Cumulative Timesteps: 1,650,792,634

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,914.86279
Policy Entropy: 3.69756
Value Function Loss: 0.01499

Mean KL Divergence: 0.01085
SB3 Clip Fraction: 0.14882
Policy Update Magnitude: 0.32022
Value Function Update Magnitude: 0.33806

Collected Steps per Second: 22,284.34252
Overall Steps per Second: 10,849.67684

Timestep Collection Time: 2.24400
Timestep Consumption Time: 2.36499
PPO Batch Consumption Time: 0.27892
Total Iteration Time: 4.60899

Cumulative Model Updates: 197,966
Cumulative Timesteps: 1,650,842,640

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1650842640...
Checkpoint 1650842640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,914.86279
Policy Entropy: 3.68967
Value Function Loss: 0.01521

Mean KL Divergence: 0.01028
SB3 Clip Fraction: 0.14284
Policy Update Magnitude: 0.29908
Value Function Update Magnitude: 0.35325

Collected Steps per Second: 21,986.17341
Overall Steps per Second: 10,714.87679

Timestep Collection Time: 2.27507
Timestep Consumption Time: 2.39321
PPO Batch Consumption Time: 0.28433
Total Iteration Time: 4.66828

Cumulative Model Updates: 197,972
Cumulative Timesteps: 1,650,892,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 286,619.77573
Policy Entropy: 3.68472
Value Function Loss: 0.01678

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.14205
Policy Update Magnitude: 0.35076
Value Function Update Magnitude: 0.57441

Collected Steps per Second: 22,196.83317
Overall Steps per Second: 10,601.33852

Timestep Collection Time: 2.25311
Timestep Consumption Time: 2.46440
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.71752

Cumulative Model Updates: 197,978
Cumulative Timesteps: 1,650,942,672

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1650942672...
Checkpoint 1650942672 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 133,603.55064
Policy Entropy: 3.70432
Value Function Loss: 0.01810

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13872
Policy Update Magnitude: 0.40760
Value Function Update Magnitude: 0.70198

Collected Steps per Second: 22,268.62806
Overall Steps per Second: 10,628.51260

Timestep Collection Time: 2.24603
Timestep Consumption Time: 2.45980
PPO Batch Consumption Time: 0.28960
Total Iteration Time: 4.70583

Cumulative Model Updates: 197,984
Cumulative Timesteps: 1,650,992,688

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 421,486.54033
Policy Entropy: 3.71334
Value Function Loss: 0.02088

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13921
Policy Update Magnitude: 0.42064
Value Function Update Magnitude: 0.66477

Collected Steps per Second: 22,525.52203
Overall Steps per Second: 10,824.37261

Timestep Collection Time: 2.22184
Timestep Consumption Time: 2.40180
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.62364

Cumulative Model Updates: 197,990
Cumulative Timesteps: 1,651,042,736

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1651042736...
Checkpoint 1651042736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,541.16749
Policy Entropy: 3.71183
Value Function Loss: 0.02025

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13827
Policy Update Magnitude: 0.40774
Value Function Update Magnitude: 0.69789

Collected Steps per Second: 22,010.75907
Overall Steps per Second: 10,631.30992

Timestep Collection Time: 2.27198
Timestep Consumption Time: 2.43186
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.70384

Cumulative Model Updates: 197,996
Cumulative Timesteps: 1,651,092,744

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,541.16749
Policy Entropy: 3.68913
Value Function Loss: 0.01828

Mean KL Divergence: 0.01030
SB3 Clip Fraction: 0.14422
Policy Update Magnitude: 0.41481
Value Function Update Magnitude: 0.70665

Collected Steps per Second: 22,276.56344
Overall Steps per Second: 10,571.62377

Timestep Collection Time: 2.24577
Timestep Consumption Time: 2.48652
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.73229

Cumulative Model Updates: 198,002
Cumulative Timesteps: 1,651,142,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1651142772...
Checkpoint 1651142772 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,541.16749
Policy Entropy: 3.67942
Value Function Loss: 0.01577

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.14046
Policy Update Magnitude: 0.37812
Value Function Update Magnitude: 0.59010

Collected Steps per Second: 22,002.91167
Overall Steps per Second: 10,487.68468

Timestep Collection Time: 2.27306
Timestep Consumption Time: 2.49577
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.76883

Cumulative Model Updates: 198,008
Cumulative Timesteps: 1,651,192,786

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 276,541.16749
Policy Entropy: 3.67654
Value Function Loss: 0.01567

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.14321
Policy Update Magnitude: 0.35971
Value Function Update Magnitude: 0.42889

Collected Steps per Second: 22,252.73279
Overall Steps per Second: 10,516.08421

Timestep Collection Time: 2.24745
Timestep Consumption Time: 2.50831
PPO Batch Consumption Time: 0.29166
Total Iteration Time: 4.75576

Cumulative Model Updates: 198,014
Cumulative Timesteps: 1,651,242,798

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1651242798...
Checkpoint 1651242798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 276,541.16749
Policy Entropy: 3.66667
Value Function Loss: 0.01706

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13755
Policy Update Magnitude: 0.34135
Value Function Update Magnitude: 0.32564

Collected Steps per Second: 21,959.53260
Overall Steps per Second: 10,651.33007

Timestep Collection Time: 2.27728
Timestep Consumption Time: 2.41772
PPO Batch Consumption Time: 0.27566
Total Iteration Time: 4.69500

Cumulative Model Updates: 198,020
Cumulative Timesteps: 1,651,292,806

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 366,893.37408
Policy Entropy: 3.69122
Value Function Loss: 0.01789

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13379
Policy Update Magnitude: 0.35595
Value Function Update Magnitude: 0.35872

Collected Steps per Second: 22,557.94326
Overall Steps per Second: 10,766.33416

Timestep Collection Time: 2.21793
Timestep Consumption Time: 2.42915
PPO Batch Consumption Time: 0.27729
Total Iteration Time: 4.64708

Cumulative Model Updates: 198,026
Cumulative Timesteps: 1,651,342,838

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1651342838...
Checkpoint 1651342838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 297,187.89913
Policy Entropy: 3.68732
Value Function Loss: 0.02022

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13362
Policy Update Magnitude: 0.37969
Value Function Update Magnitude: 0.44842

Collected Steps per Second: 21,690.91564
Overall Steps per Second: 10,774.18332

Timestep Collection Time: 2.30585
Timestep Consumption Time: 2.33636
PPO Batch Consumption Time: 0.27607
Total Iteration Time: 4.64221

Cumulative Model Updates: 198,032
Cumulative Timesteps: 1,651,392,854

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 297,187.89913
Policy Entropy: 3.69809
Value Function Loss: 0.02060

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.13163
Policy Update Magnitude: 0.44116
Value Function Update Magnitude: 0.51697

Collected Steps per Second: 22,235.31519
Overall Steps per Second: 10,877.61698

Timestep Collection Time: 2.24921
Timestep Consumption Time: 2.34848
PPO Batch Consumption Time: 0.27761
Total Iteration Time: 4.59770

Cumulative Model Updates: 198,038
Cumulative Timesteps: 1,651,442,866

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1651442866...
Checkpoint 1651442866 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 279,072.88367
Policy Entropy: 3.69878
Value Function Loss: 0.02228

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13914
Policy Update Magnitude: 0.46157
Value Function Update Magnitude: 0.55736

Collected Steps per Second: 21,802.17951
Overall Steps per Second: 10,631.84466

Timestep Collection Time: 2.29362
Timestep Consumption Time: 2.40979
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.70342

Cumulative Model Updates: 198,044
Cumulative Timesteps: 1,651,492,872

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,322.56448
Policy Entropy: 3.71183
Value Function Loss: 0.02186

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13764
Policy Update Magnitude: 0.45473
Value Function Update Magnitude: 0.51651

Collected Steps per Second: 23,141.79084
Overall Steps per Second: 10,965.89989

Timestep Collection Time: 2.16068
Timestep Consumption Time: 2.39909
PPO Batch Consumption Time: 0.27650
Total Iteration Time: 4.55977

Cumulative Model Updates: 198,050
Cumulative Timesteps: 1,651,542,874

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1651542874...
Checkpoint 1651542874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 405,241.12033
Policy Entropy: 3.72563
Value Function Loss: 0.02188

Mean KL Divergence: 0.00989
SB3 Clip Fraction: 0.13811
Policy Update Magnitude: 0.42785
Value Function Update Magnitude: 0.52948

Collected Steps per Second: 22,058.51447
Overall Steps per Second: 10,575.53793

Timestep Collection Time: 2.26733
Timestep Consumption Time: 2.46188
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.72922

Cumulative Model Updates: 198,056
Cumulative Timesteps: 1,651,592,888

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,720.06182
Policy Entropy: 3.73616
Value Function Loss: 0.02234

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13583
Policy Update Magnitude: 0.38774
Value Function Update Magnitude: 0.52004

Collected Steps per Second: 22,611.03590
Overall Steps per Second: 10,634.28285

Timestep Collection Time: 2.21255
Timestep Consumption Time: 2.49186
PPO Batch Consumption Time: 0.28862
Total Iteration Time: 4.70441

Cumulative Model Updates: 198,062
Cumulative Timesteps: 1,651,642,916

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1651642916...
Checkpoint 1651642916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 305,501.89160
Policy Entropy: 3.75019
Value Function Loss: 0.02571

Mean KL Divergence: 0.00854
SB3 Clip Fraction: 0.11996
Policy Update Magnitude: 0.38992
Value Function Update Magnitude: 0.64877

Collected Steps per Second: 22,257.82600
Overall Steps per Second: 10,595.41725

Timestep Collection Time: 2.24739
Timestep Consumption Time: 2.47371
PPO Batch Consumption Time: 0.28990
Total Iteration Time: 4.72110

Cumulative Model Updates: 198,068
Cumulative Timesteps: 1,651,692,938

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 56,622.31980
Policy Entropy: 3.74686
Value Function Loss: 0.02945

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12715
Policy Update Magnitude: 0.46485
Value Function Update Magnitude: 0.68469

Collected Steps per Second: 22,756.02207
Overall Steps per Second: 10,811.80380

Timestep Collection Time: 2.19942
Timestep Consumption Time: 2.42978
PPO Batch Consumption Time: 0.27674
Total Iteration Time: 4.62920

Cumulative Model Updates: 198,074
Cumulative Timesteps: 1,651,742,988

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1651742988...
Checkpoint 1651742988 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 264,914.35671
Policy Entropy: 3.73194
Value Function Loss: 0.02990

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12679
Policy Update Magnitude: 0.50103
Value Function Update Magnitude: 0.67091

Collected Steps per Second: 22,001.40197
Overall Steps per Second: 10,680.29691

Timestep Collection Time: 2.27395
Timestep Consumption Time: 2.41038
PPO Batch Consumption Time: 0.27594
Total Iteration Time: 4.68433

Cumulative Model Updates: 198,080
Cumulative Timesteps: 1,651,793,018

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,812.14393
Policy Entropy: 3.71378
Value Function Loss: 0.02657

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13421
Policy Update Magnitude: 0.44937
Value Function Update Magnitude: 0.60709

Collected Steps per Second: 23,294.01814
Overall Steps per Second: 10,879.57646

Timestep Collection Time: 2.14776
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.59852

Cumulative Model Updates: 198,086
Cumulative Timesteps: 1,651,843,048

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1651843048...
Checkpoint 1651843048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,812.14393
Policy Entropy: 3.70548
Value Function Loss: 0.02066

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.13020
Policy Update Magnitude: 0.40110
Value Function Update Magnitude: 0.55994

Collected Steps per Second: 22,710.86684
Overall Steps per Second: 10,597.40431

Timestep Collection Time: 2.20265
Timestep Consumption Time: 2.51776
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.72040

Cumulative Model Updates: 198,092
Cumulative Timesteps: 1,651,893,072

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,812.14393
Policy Entropy: 3.72489
Value Function Loss: 0.01638

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12968
Policy Update Magnitude: 0.38170
Value Function Update Magnitude: 0.60527

Collected Steps per Second: 23,012.20009
Overall Steps per Second: 10,859.52108

Timestep Collection Time: 2.17337
Timestep Consumption Time: 2.43217
PPO Batch Consumption Time: 0.27783
Total Iteration Time: 4.60554

Cumulative Model Updates: 198,098
Cumulative Timesteps: 1,651,943,086

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1651943086...
Checkpoint 1651943086 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 70,804.51814
Policy Entropy: 3.72308
Value Function Loss: 0.01701

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12822
Policy Update Magnitude: 0.40767
Value Function Update Magnitude: 0.65325

Collected Steps per Second: 22,395.09486
Overall Steps per Second: 10,719.63478

Timestep Collection Time: 2.23335
Timestep Consumption Time: 2.43248
PPO Batch Consumption Time: 0.27944
Total Iteration Time: 4.66583

Cumulative Model Updates: 198,104
Cumulative Timesteps: 1,651,993,102

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,693.87202
Policy Entropy: 3.74389
Value Function Loss: 0.01594

Mean KL Divergence: 0.00856
SB3 Clip Fraction: 0.12158
Policy Update Magnitude: 0.40576
Value Function Update Magnitude: 0.72223

Collected Steps per Second: 22,922.87932
Overall Steps per Second: 10,839.62349

Timestep Collection Time: 2.18184
Timestep Consumption Time: 2.43216
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.61400

Cumulative Model Updates: 198,110
Cumulative Timesteps: 1,652,043,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1652043116...
Checkpoint 1652043116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,219.76985
Policy Entropy: 3.73130
Value Function Loss: 0.01687

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12568
Policy Update Magnitude: 0.38991
Value Function Update Magnitude: 0.75165

Collected Steps per Second: 22,640.68241
Overall Steps per Second: 10,635.21434

Timestep Collection Time: 2.20841
Timestep Consumption Time: 2.49295
PPO Batch Consumption Time: 0.28608
Total Iteration Time: 4.70136

Cumulative Model Updates: 198,116
Cumulative Timesteps: 1,652,093,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,219.76985
Policy Entropy: 3.73560
Value Function Loss: 0.01455

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.38033
Value Function Update Magnitude: 0.66825

Collected Steps per Second: 22,227.54955
Overall Steps per Second: 10,482.27387

Timestep Collection Time: 2.25045
Timestep Consumption Time: 2.52161
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.77206

Cumulative Model Updates: 198,122
Cumulative Timesteps: 1,652,143,138

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1652143138...
Checkpoint 1652143138 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,219.76985
Policy Entropy: 3.71097
Value Function Loss: 0.01615

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12977
Policy Update Magnitude: 0.39367
Value Function Update Magnitude: 0.61116

Collected Steps per Second: 22,079.73288
Overall Steps per Second: 10,696.99774

Timestep Collection Time: 2.26570
Timestep Consumption Time: 2.41094
PPO Batch Consumption Time: 0.27656
Total Iteration Time: 4.67664

Cumulative Model Updates: 198,128
Cumulative Timesteps: 1,652,193,164

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 290,933.02541
Policy Entropy: 3.70497
Value Function Loss: 0.01825

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.42056
Value Function Update Magnitude: 0.63488

Collected Steps per Second: 22,492.13059
Overall Steps per Second: 10,645.63539

Timestep Collection Time: 2.22336
Timestep Consumption Time: 2.47416
PPO Batch Consumption Time: 0.28724
Total Iteration Time: 4.69751

Cumulative Model Updates: 198,134
Cumulative Timesteps: 1,652,243,172

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1652243172...
Checkpoint 1652243172 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,201,103.66651
Policy Entropy: 3.71402
Value Function Loss: 0.02044

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13408
Policy Update Magnitude: 0.42352
Value Function Update Magnitude: 0.72780

Collected Steps per Second: 21,949.06311
Overall Steps per Second: 10,431.11450

Timestep Collection Time: 2.27864
Timestep Consumption Time: 2.51605
PPO Batch Consumption Time: 0.28980
Total Iteration Time: 4.79469

Cumulative Model Updates: 198,140
Cumulative Timesteps: 1,652,293,186

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 418,820.46947
Policy Entropy: 3.71525
Value Function Loss: 0.01945

Mean KL Divergence: 0.00888
SB3 Clip Fraction: 0.12646
Policy Update Magnitude: 0.43346
Value Function Update Magnitude: 0.77885

Collected Steps per Second: 23,303.95692
Overall Steps per Second: 10,956.23318

Timestep Collection Time: 2.14564
Timestep Consumption Time: 2.41815
PPO Batch Consumption Time: 0.27601
Total Iteration Time: 4.56379

Cumulative Model Updates: 198,146
Cumulative Timesteps: 1,652,343,188

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1652343188...
Checkpoint 1652343188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 563,102.76340
Policy Entropy: 3.72050
Value Function Loss: 0.01751

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13021
Policy Update Magnitude: 0.41305
Value Function Update Magnitude: 0.70061

Collected Steps per Second: 22,470.84717
Overall Steps per Second: 10,567.03494

Timestep Collection Time: 2.22617
Timestep Consumption Time: 2.50779
PPO Batch Consumption Time: 0.29311
Total Iteration Time: 4.73397

Cumulative Model Updates: 198,152
Cumulative Timesteps: 1,652,393,212

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305,430.08473
Policy Entropy: 3.70171
Value Function Loss: 0.02030

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.13078
Policy Update Magnitude: 0.39667
Value Function Update Magnitude: 0.67927

Collected Steps per Second: 22,207.95884
Overall Steps per Second: 10,859.83163

Timestep Collection Time: 2.25208
Timestep Consumption Time: 2.35334
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.60541

Cumulative Model Updates: 198,158
Cumulative Timesteps: 1,652,443,226

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1652443226...
Checkpoint 1652443226 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 168,940.26974
Policy Entropy: 3.72958
Value Function Loss: 0.02254

Mean KL Divergence: 0.00973
SB3 Clip Fraction: 0.13498
Policy Update Magnitude: 0.41963
Value Function Update Magnitude: 0.79977

Collected Steps per Second: 21,796.73188
Overall Steps per Second: 10,674.94637

Timestep Collection Time: 2.29429
Timestep Consumption Time: 2.39032
PPO Batch Consumption Time: 0.28401
Total Iteration Time: 4.68461

Cumulative Model Updates: 198,164
Cumulative Timesteps: 1,652,493,234

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196,480.81880
Policy Entropy: 3.72666
Value Function Loss: 0.02548

Mean KL Divergence: 0.00981
SB3 Clip Fraction: 0.13758
Policy Update Magnitude: 0.42658
Value Function Update Magnitude: 0.86697

Collected Steps per Second: 22,320.09504
Overall Steps per Second: 10,887.89019

Timestep Collection Time: 2.24130
Timestep Consumption Time: 2.35335
PPO Batch Consumption Time: 0.27809
Total Iteration Time: 4.59465

Cumulative Model Updates: 198,170
Cumulative Timesteps: 1,652,543,260

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1652543260...
Checkpoint 1652543260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 55,500.99290
Policy Entropy: 3.73811
Value Function Loss: 0.02308

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.13246
Policy Update Magnitude: 0.42630
Value Function Update Magnitude: 0.86493

Collected Steps per Second: 21,504.21983
Overall Steps per Second: 10,717.05184

Timestep Collection Time: 2.32624
Timestep Consumption Time: 2.34146
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.66770

Cumulative Model Updates: 198,176
Cumulative Timesteps: 1,652,593,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,962.07378
Policy Entropy: 3.71638
Value Function Loss: 0.01960

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.13352
Policy Update Magnitude: 0.39797
Value Function Update Magnitude: 0.78797

Collected Steps per Second: 22,007.89900
Overall Steps per Second: 10,533.87347

Timestep Collection Time: 2.27327
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.28935
Total Iteration Time: 4.74944

Cumulative Model Updates: 198,182
Cumulative Timesteps: 1,652,643,314

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1652643314...
Checkpoint 1652643314 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,962.07378
Policy Entropy: 3.72844
Value Function Loss: 0.01470

Mean KL Divergence: 0.00893
SB3 Clip Fraction: 0.12454
Policy Update Magnitude: 0.37925
Value Function Update Magnitude: 0.64248

Collected Steps per Second: 21,983.95043
Overall Steps per Second: 10,544.45444

Timestep Collection Time: 2.27511
Timestep Consumption Time: 2.46823
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.74335

Cumulative Model Updates: 198,188
Cumulative Timesteps: 1,652,693,330

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,962.07378
Policy Entropy: 3.71322
Value Function Loss: 0.01268

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.38247
Value Function Update Magnitude: 0.58261

Collected Steps per Second: 22,504.23591
Overall Steps per Second: 10,855.11358

Timestep Collection Time: 2.22225
Timestep Consumption Time: 2.38480
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.60705

Cumulative Model Updates: 198,194
Cumulative Timesteps: 1,652,743,340

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1652743340...
Checkpoint 1652743340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 234,450.87166
Policy Entropy: 3.71427
Value Function Loss: 0.01304

Mean KL Divergence: 0.00899
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.38884
Value Function Update Magnitude: 0.53728

Collected Steps per Second: 21,652.43487
Overall Steps per Second: 10,422.74547

Timestep Collection Time: 2.31013
Timestep Consumption Time: 2.48899
PPO Batch Consumption Time: 0.28877
Total Iteration Time: 4.79912

Cumulative Model Updates: 198,200
Cumulative Timesteps: 1,652,793,360

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,679.13220
Policy Entropy: 3.71163
Value Function Loss: 0.01683

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.12459
Policy Update Magnitude: 0.36960
Value Function Update Magnitude: 0.55377

Collected Steps per Second: 23,023.93818
Overall Steps per Second: 10,747.87693

Timestep Collection Time: 2.17296
Timestep Consumption Time: 2.48192
PPO Batch Consumption Time: 0.28166
Total Iteration Time: 4.65487

Cumulative Model Updates: 198,206
Cumulative Timesteps: 1,652,843,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1652843390...
Checkpoint 1652843390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 37,336.01425
Policy Entropy: 3.73188
Value Function Loss: 0.01778

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.12329
Policy Update Magnitude: 0.40959
Value Function Update Magnitude: 0.68730

Collected Steps per Second: 22,616.33991
Overall Steps per Second: 10,565.13812

Timestep Collection Time: 2.21088
Timestep Consumption Time: 2.52186
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.73274

Cumulative Model Updates: 198,212
Cumulative Timesteps: 1,652,893,392

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,037.13949
Policy Entropy: 3.73141
Value Function Loss: 0.01734

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.40790
Value Function Update Magnitude: 0.70924

Collected Steps per Second: 22,997.16652
Overall Steps per Second: 10,888.87879

Timestep Collection Time: 2.17549
Timestep Consumption Time: 2.41911
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.59460

Cumulative Model Updates: 198,218
Cumulative Timesteps: 1,652,943,422

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1652943422...
Checkpoint 1652943422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,446.12307
Policy Entropy: 3.72003
Value Function Loss: 0.02160

Mean KL Divergence: 0.00879
SB3 Clip Fraction: 0.12230
Policy Update Magnitude: 0.40152
Value Function Update Magnitude: 0.67741

Collected Steps per Second: 22,232.47931
Overall Steps per Second: 10,665.88799

Timestep Collection Time: 2.24950
Timestep Consumption Time: 2.43947
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.68897

Cumulative Model Updates: 198,224
Cumulative Timesteps: 1,652,993,434

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,474.63209
Policy Entropy: 3.72732
Value Function Loss: 0.02442

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.42673
Value Function Update Magnitude: 0.61133

Collected Steps per Second: 21,469.08785
Overall Steps per Second: 10,463.00229

Timestep Collection Time: 2.32930
Timestep Consumption Time: 2.45021
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.77951

Cumulative Model Updates: 198,230
Cumulative Timesteps: 1,653,043,442

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1653043442...
Checkpoint 1653043442 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,347.82805
Policy Entropy: 3.73466
Value Function Loss: 0.02651

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12628
Policy Update Magnitude: 0.43623
Value Function Update Magnitude: 0.65328

Collected Steps per Second: 22,528.19041
Overall Steps per Second: 10,671.82651

Timestep Collection Time: 2.22051
Timestep Consumption Time: 2.46698
PPO Batch Consumption Time: 0.28438
Total Iteration Time: 4.68748

Cumulative Model Updates: 198,236
Cumulative Timesteps: 1,653,093,466

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 78,345.72668
Policy Entropy: 3.76021
Value Function Loss: 0.02451

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12456
Policy Update Magnitude: 0.45251
Value Function Update Magnitude: 0.74496

Collected Steps per Second: 22,960.12086
Overall Steps per Second: 10,839.69905

Timestep Collection Time: 2.17786
Timestep Consumption Time: 2.43518
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.61304

Cumulative Model Updates: 198,242
Cumulative Timesteps: 1,653,143,470

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1653143470...
Checkpoint 1653143470 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,537.69869
Policy Entropy: 3.73716
Value Function Loss: 0.02633

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12615
Policy Update Magnitude: 0.48914
Value Function Update Magnitude: 0.71634

Collected Steps per Second: 21,821.69971
Overall Steps per Second: 10,491.04711

Timestep Collection Time: 2.29249
Timestep Consumption Time: 2.47596
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.76845

Cumulative Model Updates: 198,248
Cumulative Timesteps: 1,653,193,496

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,537.69869
Policy Entropy: 3.74564
Value Function Loss: 0.02194

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.12959
Policy Update Magnitude: 0.48724
Value Function Update Magnitude: 0.62151

Collected Steps per Second: 22,771.96327
Overall Steps per Second: 10,709.41730

Timestep Collection Time: 2.19586
Timestep Consumption Time: 2.47330
PPO Batch Consumption Time: 0.28650
Total Iteration Time: 4.66916

Cumulative Model Updates: 198,254
Cumulative Timesteps: 1,653,243,500

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1653243500...
Checkpoint 1653243500 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,537.69869
Policy Entropy: 3.71354
Value Function Loss: 0.02035

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12757
Policy Update Magnitude: 0.47416
Value Function Update Magnitude: 0.51700

Collected Steps per Second: 22,161.53799
Overall Steps per Second: 10,608.55511

Timestep Collection Time: 2.25751
Timestep Consumption Time: 2.45849
PPO Batch Consumption Time: 0.28360
Total Iteration Time: 4.71601

Cumulative Model Updates: 198,260
Cumulative Timesteps: 1,653,293,530

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 728,933.25699
Policy Entropy: 3.72545
Value Function Loss: 0.01687

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12728
Policy Update Magnitude: 0.46928
Value Function Update Magnitude: 0.49607

Collected Steps per Second: 22,698.28598
Overall Steps per Second: 10,652.29431

Timestep Collection Time: 2.20281
Timestep Consumption Time: 2.49101
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.69382

Cumulative Model Updates: 198,266
Cumulative Timesteps: 1,653,343,530

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1653343530...
Checkpoint 1653343530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 703,865.66140
Policy Entropy: 3.70121
Value Function Loss: 0.02193

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12812
Policy Update Magnitude: 0.52033
Value Function Update Magnitude: 0.58760

Collected Steps per Second: 22,421.72773
Overall Steps per Second: 10,529.88703

Timestep Collection Time: 2.23043
Timestep Consumption Time: 2.51891
PPO Batch Consumption Time: 0.29065
Total Iteration Time: 4.74934

Cumulative Model Updates: 198,272
Cumulative Timesteps: 1,653,393,540

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 463,036.02817
Policy Entropy: 3.72275
Value Function Loss: 0.02281

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12910
Policy Update Magnitude: 0.59576
Value Function Update Magnitude: 0.62972

Collected Steps per Second: 22,924.80204
Overall Steps per Second: 10,808.08846

Timestep Collection Time: 2.18227
Timestep Consumption Time: 2.44649
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.62876

Cumulative Model Updates: 198,278
Cumulative Timesteps: 1,653,443,568

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1653443568...
Checkpoint 1653443568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 348,024.96535
Policy Entropy: 3.69385
Value Function Loss: 0.03097

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12980
Policy Update Magnitude: 0.55471
Value Function Update Magnitude: 0.63217

Collected Steps per Second: 22,362.78081
Overall Steps per Second: 10,636.18947

Timestep Collection Time: 2.23639
Timestep Consumption Time: 2.46567
PPO Batch Consumption Time: 0.28451
Total Iteration Time: 4.70206

Cumulative Model Updates: 198,284
Cumulative Timesteps: 1,653,493,580

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 246,882.88643
Policy Entropy: 3.70650
Value Function Loss: 0.02902

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13802
Policy Update Magnitude: 0.53257
Value Function Update Magnitude: 0.50951

Collected Steps per Second: 23,218.50134
Overall Steps per Second: 10,926.33334

Timestep Collection Time: 2.15414
Timestep Consumption Time: 2.42342
PPO Batch Consumption Time: 0.27780
Total Iteration Time: 4.57756

Cumulative Model Updates: 198,290
Cumulative Timesteps: 1,653,543,596

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1653543596...
Checkpoint 1653543596 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,113.82299
Policy Entropy: 3.71925
Value Function Loss: 0.02494

Mean KL Divergence: 0.01060
SB3 Clip Fraction: 0.14151
Policy Update Magnitude: 0.46705
Value Function Update Magnitude: 0.49069

Collected Steps per Second: 21,781.83472
Overall Steps per Second: 10,668.80387

Timestep Collection Time: 2.29668
Timestep Consumption Time: 2.39231
PPO Batch Consumption Time: 0.28656
Total Iteration Time: 4.68900

Cumulative Model Updates: 198,296
Cumulative Timesteps: 1,653,593,622

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 24,327.44169
Policy Entropy: 3.75175
Value Function Loss: 0.01985

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12402
Policy Update Magnitude: 0.39789
Value Function Update Magnitude: 0.51426

Collected Steps per Second: 22,098.18307
Overall Steps per Second: 10,837.03789

Timestep Collection Time: 2.26335
Timestep Consumption Time: 2.35193
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.61528

Cumulative Model Updates: 198,302
Cumulative Timesteps: 1,653,643,638

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1653643638...
Checkpoint 1653643638 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,487.89087
Policy Entropy: 3.75643
Value Function Loss: 0.01832

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13331
Policy Update Magnitude: 0.39542
Value Function Update Magnitude: 0.51326

Collected Steps per Second: 21,738.44915
Overall Steps per Second: 10,796.37724

Timestep Collection Time: 2.30062
Timestep Consumption Time: 2.33167
PPO Batch Consumption Time: 0.27564
Total Iteration Time: 4.63229

Cumulative Model Updates: 198,308
Cumulative Timesteps: 1,653,693,650

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,487.89087
Policy Entropy: 3.73369
Value Function Loss: 0.01857

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12343
Policy Update Magnitude: 0.42305
Value Function Update Magnitude: 0.57051

Collected Steps per Second: 21,880.85575
Overall Steps per Second: 10,561.30993

Timestep Collection Time: 2.28547
Timestep Consumption Time: 2.44955
PPO Batch Consumption Time: 0.28833
Total Iteration Time: 4.73502

Cumulative Model Updates: 198,314
Cumulative Timesteps: 1,653,743,658

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1653743658...
Checkpoint 1653743658 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,487.89087
Policy Entropy: 3.72194
Value Function Loss: 0.01704

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.42359
Value Function Update Magnitude: 0.58053

Collected Steps per Second: 22,166.51715
Overall Steps per Second: 10,642.13075

Timestep Collection Time: 2.25665
Timestep Consumption Time: 2.44373
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.70037

Cumulative Model Updates: 198,320
Cumulative Timesteps: 1,653,793,680

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,487.89087
Policy Entropy: 3.70448
Value Function Loss: 0.01767

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13361
Policy Update Magnitude: 0.39284
Value Function Update Magnitude: 0.57804

Collected Steps per Second: 22,641.96959
Overall Steps per Second: 10,717.86283

Timestep Collection Time: 2.20926
Timestep Consumption Time: 2.45790
PPO Batch Consumption Time: 0.28715
Total Iteration Time: 4.66716

Cumulative Model Updates: 198,326
Cumulative Timesteps: 1,653,843,702

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1653843702...
Checkpoint 1653843702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,487.89087
Policy Entropy: 3.70938
Value Function Loss: 0.01675

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.40735
Value Function Update Magnitude: 0.52946

Collected Steps per Second: 22,200.33937
Overall Steps per Second: 10,633.62533

Timestep Collection Time: 2.25240
Timestep Consumption Time: 2.45004
PPO Batch Consumption Time: 0.27812
Total Iteration Time: 4.70244

Cumulative Model Updates: 198,332
Cumulative Timesteps: 1,653,893,706

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,487.89087
Policy Entropy: 3.69936
Value Function Loss: 0.01810

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.43828
Value Function Update Magnitude: 0.48937

Collected Steps per Second: 23,104.18046
Overall Steps per Second: 10,845.51169

Timestep Collection Time: 2.16489
Timestep Consumption Time: 2.44697
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.61186

Cumulative Model Updates: 198,338
Cumulative Timesteps: 1,653,943,724

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1653943724...
Checkpoint 1653943724 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,487.89087
Policy Entropy: 3.70096
Value Function Loss: 0.01615

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12803
Policy Update Magnitude: 0.44174
Value Function Update Magnitude: 0.42676

Collected Steps per Second: 22,283.76165
Overall Steps per Second: 10,652.25862

Timestep Collection Time: 2.24441
Timestep Consumption Time: 2.45074
PPO Batch Consumption Time: 0.27764
Total Iteration Time: 4.69515

Cumulative Model Updates: 198,344
Cumulative Timesteps: 1,653,993,738

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,487.89087
Policy Entropy: 3.69826
Value Function Loss: 0.01483

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13522
Policy Update Magnitude: 0.42306
Value Function Update Magnitude: 0.41434

Collected Steps per Second: 22,725.03485
Overall Steps per Second: 10,655.96576

Timestep Collection Time: 2.20074
Timestep Consumption Time: 2.49259
PPO Batch Consumption Time: 0.28914
Total Iteration Time: 4.69333

Cumulative Model Updates: 198,350
Cumulative Timesteps: 1,654,043,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1654043750...
Checkpoint 1654043750 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 86,564.36540
Policy Entropy: 3.70981
Value Function Loss: 0.01680

Mean KL Divergence: 0.00836
SB3 Clip Fraction: 0.11595
Policy Update Magnitude: 0.43384
Value Function Update Magnitude: 0.53511

Collected Steps per Second: 22,631.99937
Overall Steps per Second: 10,674.04210

Timestep Collection Time: 2.21041
Timestep Consumption Time: 2.47629
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.68670

Cumulative Model Updates: 198,356
Cumulative Timesteps: 1,654,093,776

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 506,473.82213
Policy Entropy: 3.72348
Value Function Loss: 0.02058

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.11569
Policy Update Magnitude: 0.50304
Value Function Update Magnitude: 0.72019

Collected Steps per Second: 23,002.61740
Overall Steps per Second: 10,725.56433

Timestep Collection Time: 2.17445
Timestep Consumption Time: 2.48899
PPO Batch Consumption Time: 0.28844
Total Iteration Time: 4.66344

Cumulative Model Updates: 198,362
Cumulative Timesteps: 1,654,143,794

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1654143794...
Checkpoint 1654143794 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 115,869.92223
Policy Entropy: 3.70261
Value Function Loss: 0.03186

Mean KL Divergence: 0.01203
SB3 Clip Fraction: 0.15032
Policy Update Magnitude: 0.54916
Value Function Update Magnitude: 0.76104

Collected Steps per Second: 22,351.70330
Overall Steps per Second: 10,649.42157

Timestep Collection Time: 2.23732
Timestep Consumption Time: 2.45852
PPO Batch Consumption Time: 0.28527
Total Iteration Time: 4.69584

Cumulative Model Updates: 198,368
Cumulative Timesteps: 1,654,193,802

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 53,520.24247
Policy Entropy: 3.70377
Value Function Loss: 0.04563

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14237
Policy Update Magnitude: 0.61175
Value Function Update Magnitude: 0.69437

Collected Steps per Second: 21,941.55656
Overall Steps per Second: 10,430.88723

Timestep Collection Time: 2.27878
Timestep Consumption Time: 2.51468
PPO Batch Consumption Time: 0.29130
Total Iteration Time: 4.79346

Cumulative Model Updates: 198,374
Cumulative Timesteps: 1,654,243,802

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1654243802...
Checkpoint 1654243802 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,938.28126
Policy Entropy: 3.68206
Value Function Loss: 0.05248

Mean KL Divergence: 0.01621
SB3 Clip Fraction: 0.18437
Policy Update Magnitude: 0.79550
Value Function Update Magnitude: 0.65731

Collected Steps per Second: 21,598.97364
Overall Steps per Second: 10,553.88435

Timestep Collection Time: 2.31530
Timestep Consumption Time: 2.42306
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.73835

Cumulative Model Updates: 198,380
Cumulative Timesteps: 1,654,293,810

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,095.05404
Policy Entropy: 3.73512
Value Function Loss: 0.05293

Mean KL Divergence: 0.01237
SB3 Clip Fraction: 0.15504
Policy Update Magnitude: 0.81829
Value Function Update Magnitude: 0.53667

Collected Steps per Second: 22,062.47730
Overall Steps per Second: 10,561.29727

Timestep Collection Time: 2.26720
Timestep Consumption Time: 2.46896
PPO Batch Consumption Time: 0.28503
Total Iteration Time: 4.73616

Cumulative Model Updates: 198,386
Cumulative Timesteps: 1,654,343,830

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1654343830...
Checkpoint 1654343830 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 12,830.23639
Policy Entropy: 3.74247
Value Function Loss: 0.04804

Mean KL Divergence: 0.01306
SB3 Clip Fraction: 0.16068
Policy Update Magnitude: 0.74837
Value Function Update Magnitude: 0.53787

Collected Steps per Second: 21,729.79280
Overall Steps per Second: 10,608.74919

Timestep Collection Time: 2.30228
Timestep Consumption Time: 2.41345
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.71573

Cumulative Model Updates: 198,392
Cumulative Timesteps: 1,654,393,858

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,113.78236
Policy Entropy: 3.74413
Value Function Loss: 0.04266

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14597
Policy Update Magnitude: 0.69129
Value Function Update Magnitude: 0.54847

Collected Steps per Second: 22,288.76645
Overall Steps per Second: 10,530.54850

Timestep Collection Time: 2.24382
Timestep Consumption Time: 2.50541
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.74923

Cumulative Model Updates: 198,398
Cumulative Timesteps: 1,654,443,870

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1654443870...
Checkpoint 1654443870 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,625.84723
Policy Entropy: 3.74911
Value Function Loss: 0.03265

Mean KL Divergence: 0.01142
SB3 Clip Fraction: 0.15078
Policy Update Magnitude: 0.58133
Value Function Update Magnitude: 0.50025

Collected Steps per Second: 22,354.25098
Overall Steps per Second: 10,657.41405

Timestep Collection Time: 2.23796
Timestep Consumption Time: 2.45623
PPO Batch Consumption Time: 0.27585
Total Iteration Time: 4.69420

Cumulative Model Updates: 198,404
Cumulative Timesteps: 1,654,493,898

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 76,395.80365
Policy Entropy: 3.72743
Value Function Loss: 0.03436

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.50246
Value Function Update Magnitude: 0.58057

Collected Steps per Second: 22,995.17353
Overall Steps per Second: 10,833.49935

Timestep Collection Time: 2.17515
Timestep Consumption Time: 2.44182
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.61698

Cumulative Model Updates: 198,410
Cumulative Timesteps: 1,654,543,916

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1654543916...
Checkpoint 1654543916 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,295.03926
Policy Entropy: 3.73023
Value Function Loss: 0.03346

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12688
Policy Update Magnitude: 0.56767
Value Function Update Magnitude: 0.67732

Collected Steps per Second: 21,569.85520
Overall Steps per Second: 10,659.64924

Timestep Collection Time: 2.31861
Timestep Consumption Time: 2.37311
PPO Batch Consumption Time: 0.28249
Total Iteration Time: 4.69171

Cumulative Model Updates: 198,416
Cumulative Timesteps: 1,654,593,928

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 26,170.58421
Policy Entropy: 3.72612
Value Function Loss: 0.03516

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12736
Policy Update Magnitude: 0.60130
Value Function Update Magnitude: 0.63609

Collected Steps per Second: 22,121.18510
Overall Steps per Second: 10,832.14818

Timestep Collection Time: 2.26082
Timestep Consumption Time: 2.35618
PPO Batch Consumption Time: 0.27868
Total Iteration Time: 4.61700

Cumulative Model Updates: 198,422
Cumulative Timesteps: 1,654,643,940

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1654643940...
Checkpoint 1654643940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,453.60872
Policy Entropy: 3.74356
Value Function Loss: 0.02848

Mean KL Divergence: 0.00818
SB3 Clip Fraction: 0.11258
Policy Update Magnitude: 0.55693
Value Function Update Magnitude: 0.61003

Collected Steps per Second: 21,897.87926
Overall Steps per Second: 10,716.48499

Timestep Collection Time: 2.28378
Timestep Consumption Time: 2.38286
PPO Batch Consumption Time: 0.28506
Total Iteration Time: 4.66664

Cumulative Model Updates: 198,428
Cumulative Timesteps: 1,654,693,950

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,909.79817
Policy Entropy: 3.74533
Value Function Loss: 0.02552

Mean KL Divergence: 0.00878
SB3 Clip Fraction: 0.12145
Policy Update Magnitude: 0.49677
Value Function Update Magnitude: 0.61561

Collected Steps per Second: 22,094.20887
Overall Steps per Second: 10,856.28344

Timestep Collection Time: 2.26367
Timestep Consumption Time: 2.34325
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.60692

Cumulative Model Updates: 198,434
Cumulative Timesteps: 1,654,743,964

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1654743964...
Checkpoint 1654743964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,723.27431
Policy Entropy: 3.74017
Value Function Loss: 0.02282

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.46129
Value Function Update Magnitude: 0.68959

Collected Steps per Second: 21,526.34602
Overall Steps per Second: 10,618.33186

Timestep Collection Time: 2.32348
Timestep Consumption Time: 2.38687
PPO Batch Consumption Time: 0.27731
Total Iteration Time: 4.71034

Cumulative Model Updates: 198,440
Cumulative Timesteps: 1,654,793,980

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 319,609.54215
Policy Entropy: 3.75055
Value Function Loss: 0.02211

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12485
Policy Update Magnitude: 0.44104
Value Function Update Magnitude: 0.78430

Collected Steps per Second: 22,477.70981
Overall Steps per Second: 10,651.77728

Timestep Collection Time: 2.22638
Timestep Consumption Time: 2.47180
PPO Batch Consumption Time: 0.29024
Total Iteration Time: 4.69818

Cumulative Model Updates: 198,446
Cumulative Timesteps: 1,654,844,024

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1654844024...
Checkpoint 1654844024 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 90,286.61662
Policy Entropy: 3.74714
Value Function Loss: 0.02313

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12730
Policy Update Magnitude: 0.44368
Value Function Update Magnitude: 0.81933

Collected Steps per Second: 22,281.06575
Overall Steps per Second: 10,624.78348

Timestep Collection Time: 2.24531
Timestep Consumption Time: 2.46330
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.70861

Cumulative Model Updates: 198,452
Cumulative Timesteps: 1,654,894,052

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,161.43498
Policy Entropy: 3.75581
Value Function Loss: 0.02271

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12645
Policy Update Magnitude: 0.43653
Value Function Update Magnitude: 0.82853

Collected Steps per Second: 21,845.46707
Overall Steps per Second: 10,362.12016

Timestep Collection Time: 2.29100
Timestep Consumption Time: 2.53890
PPO Batch Consumption Time: 0.28681
Total Iteration Time: 4.82990

Cumulative Model Updates: 198,458
Cumulative Timesteps: 1,654,944,100

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


Saving checkpoint 1654944100...
Checkpoint 1654944100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 131,443.79377
Policy Entropy: 3.74391
Value Function Loss: 0.02247

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12614
Policy Update Magnitude: 0.42753
Value Function Update Magnitude: 0.84635

Collected Steps per Second: 22,186.17208
Overall Steps per Second: 10,687.64401

Timestep Collection Time: 2.25384
Timestep Consumption Time: 2.42484
PPO Batch Consumption Time: 0.27653
Total Iteration Time: 4.67867

Cumulative Model Updates: 198,464
Cumulative Timesteps: 1,654,994,104

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 30,080.93945
Policy Entropy: 3.74300
Value Function Loss: 0.02046

Mean KL Divergence: 0.00877
SB3 Clip Fraction: 0.12511
Policy Update Magnitude: 0.41289
Value Function Update Magnitude: 0.80003

Collected Steps per Second: 23,231.38307
Overall Steps per Second: 10,928.24291

Timestep Collection Time: 2.15416
Timestep Consumption Time: 2.42517
PPO Batch Consumption Time: 0.27705
Total Iteration Time: 4.57933

Cumulative Model Updates: 198,470
Cumulative Timesteps: 1,655,044,148

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1655044148...
Checkpoint 1655044148 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 463,984.96968
Policy Entropy: 3.74205
Value Function Loss: 0.02197

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12569
Policy Update Magnitude: 0.42052
Value Function Update Magnitude: 0.81345

Collected Steps per Second: 22,478.22094
Overall Steps per Second: 10,578.23848

Timestep Collection Time: 2.22518
Timestep Consumption Time: 2.50321
PPO Batch Consumption Time: 0.29097
Total Iteration Time: 4.72839

Cumulative Model Updates: 198,476
Cumulative Timesteps: 1,655,094,166

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 196,581.74342
Policy Entropy: 3.74108
Value Function Loss: 0.02173

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13010
Policy Update Magnitude: 0.45863
Value Function Update Magnitude: 0.82564

Collected Steps per Second: 22,808.48025
Overall Steps per Second: 10,839.96889

Timestep Collection Time: 2.19348
Timestep Consumption Time: 2.42184
PPO Batch Consumption Time: 0.27738
Total Iteration Time: 4.61533

Cumulative Model Updates: 198,482
Cumulative Timesteps: 1,655,144,196

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1655144196...
Checkpoint 1655144196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 68,544.67708
Policy Entropy: 3.73198
Value Function Loss: 0.02149

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.47988
Value Function Update Magnitude: 0.77696

Collected Steps per Second: 22,036.83271
Overall Steps per Second: 10,662.44109

Timestep Collection Time: 2.26956
Timestep Consumption Time: 2.42111
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.69067

Cumulative Model Updates: 198,488
Cumulative Timesteps: 1,655,194,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,648.10886
Policy Entropy: 3.73643
Value Function Loss: 0.02076

Mean KL Divergence: 0.00971
SB3 Clip Fraction: 0.12685
Policy Update Magnitude: 0.49592
Value Function Update Magnitude: 0.75575

Collected Steps per Second: 22,356.12157
Overall Steps per Second: 10,500.81498

Timestep Collection Time: 2.23742
Timestep Consumption Time: 2.52602
PPO Batch Consumption Time: 0.29040
Total Iteration Time: 4.76344

Cumulative Model Updates: 198,494
Cumulative Timesteps: 1,655,244,230

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1655244230...
Checkpoint 1655244230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,759.85268
Policy Entropy: 3.73246
Value Function Loss: 0.02287

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13068
Policy Update Magnitude: 0.52546
Value Function Update Magnitude: 0.74980

Collected Steps per Second: 22,138.92991
Overall Steps per Second: 10,648.91810

Timestep Collection Time: 2.25946
Timestep Consumption Time: 2.43792
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.69738

Cumulative Model Updates: 198,500
Cumulative Timesteps: 1,655,294,252

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 61,651.55263
Policy Entropy: 3.74371
Value Function Loss: 0.02495

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13049
Policy Update Magnitude: 0.54250
Value Function Update Magnitude: 0.77508

Collected Steps per Second: 22,286.21816
Overall Steps per Second: 10,553.38929

Timestep Collection Time: 2.24480
Timestep Consumption Time: 2.49567
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.74047

Cumulative Model Updates: 198,506
Cumulative Timesteps: 1,655,344,280

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1655344280...
Checkpoint 1655344280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 27,981.00730
Policy Entropy: 3.73214
Value Function Loss: 0.02694

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12528
Policy Update Magnitude: 0.58569
Value Function Update Magnitude: 0.82372

Collected Steps per Second: 21,836.86790
Overall Steps per Second: 10,545.97155

Timestep Collection Time: 2.29016
Timestep Consumption Time: 2.45193
PPO Batch Consumption Time: 0.27722
Total Iteration Time: 4.74210

Cumulative Model Updates: 198,512
Cumulative Timesteps: 1,655,394,290

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 35,003.68586
Policy Entropy: 3.73168
Value Function Loss: 0.02683

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11821
Policy Update Magnitude: 0.58491
Value Function Update Magnitude: 0.89073

Collected Steps per Second: 22,304.73788
Overall Steps per Second: 10,468.10944

Timestep Collection Time: 2.24221
Timestep Consumption Time: 2.53534
PPO Batch Consumption Time: 0.29343
Total Iteration Time: 4.77756

Cumulative Model Updates: 198,518
Cumulative Timesteps: 1,655,444,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1655444302...
Checkpoint 1655444302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 71,027.16337
Policy Entropy: 3.72851
Value Function Loss: 0.02495

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.51339
Value Function Update Magnitude: 0.85707

Collected Steps per Second: 22,661.97885
Overall Steps per Second: 10,697.12293

Timestep Collection Time: 2.20740
Timestep Consumption Time: 2.46900
PPO Batch Consumption Time: 0.27581
Total Iteration Time: 4.67640

Cumulative Model Updates: 198,524
Cumulative Timesteps: 1,655,494,326

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,174.42112
Policy Entropy: 3.72039
Value Function Loss: 0.02330

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12384
Policy Update Magnitude: 0.49889
Value Function Update Magnitude: 0.85292

Collected Steps per Second: 23,129.98086
Overall Steps per Second: 10,935.27924

Timestep Collection Time: 2.16239
Timestep Consumption Time: 2.41143
PPO Batch Consumption Time: 0.27645
Total Iteration Time: 4.57382

Cumulative Model Updates: 198,530
Cumulative Timesteps: 1,655,544,342

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1655544342...
Checkpoint 1655544342 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 75,670.02706
Policy Entropy: 3.70975
Value Function Loss: 0.02279

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.49348
Value Function Update Magnitude: 0.86200

Collected Steps per Second: 22,537.60406
Overall Steps per Second: 10,592.68787

Timestep Collection Time: 2.21887
Timestep Consumption Time: 2.50212
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.72099

Cumulative Model Updates: 198,536
Cumulative Timesteps: 1,655,594,350

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 674,634.97373
Policy Entropy: 3.69056
Value Function Loss: 0.02363

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12401
Policy Update Magnitude: 0.49733
Value Function Update Magnitude: 0.75212

Collected Steps per Second: 22,258.18147
Overall Steps per Second: 10,855.20329

Timestep Collection Time: 2.24717
Timestep Consumption Time: 2.36057
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.60774

Cumulative Model Updates: 198,542
Cumulative Timesteps: 1,655,644,368

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1655644368...
Checkpoint 1655644368 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,454.37154
Policy Entropy: 3.70568
Value Function Loss: 0.02566

Mean KL Divergence: 0.01011
SB3 Clip Fraction: 0.13096
Policy Update Magnitude: 0.47768
Value Function Update Magnitude: 0.58934

Collected Steps per Second: 21,802.41335
Overall Steps per Second: 10,670.51169

Timestep Collection Time: 2.29360
Timestep Consumption Time: 2.39277
PPO Batch Consumption Time: 0.28591
Total Iteration Time: 4.68637

Cumulative Model Updates: 198,548
Cumulative Timesteps: 1,655,694,374

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 296,540.07890
Policy Entropy: 3.71282
Value Function Loss: 0.02766

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.12907
Policy Update Magnitude: 0.45191
Value Function Update Magnitude: 0.51616

Collected Steps per Second: 21,779.91316
Overall Steps per Second: 10,632.03363

Timestep Collection Time: 2.29680
Timestep Consumption Time: 2.40823
PPO Batch Consumption Time: 0.28837
Total Iteration Time: 4.70503

Cumulative Model Updates: 198,554
Cumulative Timesteps: 1,655,744,398

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1655744398...
Checkpoint 1655744398 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 134,675.95573
Policy Entropy: 3.71488
Value Function Loss: 0.03047

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.13450
Policy Update Magnitude: 0.47462
Value Function Update Magnitude: 0.62149

Collected Steps per Second: 21,216.43464
Overall Steps per Second: 10,559.56450

Timestep Collection Time: 2.35874
Timestep Consumption Time: 2.38047
PPO Batch Consumption Time: 0.27549
Total Iteration Time: 4.73921

Cumulative Model Updates: 198,560
Cumulative Timesteps: 1,655,794,442

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,089.12196
Policy Entropy: 3.70121
Value Function Loss: 0.03282

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14590
Policy Update Magnitude: 0.50858
Value Function Update Magnitude: 0.59122

Collected Steps per Second: 22,537.78262
Overall Steps per Second: 10,788.63307

Timestep Collection Time: 2.21903
Timestep Consumption Time: 2.41659
PPO Batch Consumption Time: 0.27871
Total Iteration Time: 4.63562

Cumulative Model Updates: 198,566
Cumulative Timesteps: 1,655,844,454

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1655844454...
Checkpoint 1655844454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,089.12196
Policy Entropy: 3.69699
Value Function Loss: 0.02810

Mean KL Divergence: 0.01101
SB3 Clip Fraction: 0.14318
Policy Update Magnitude: 0.52739
Value Function Update Magnitude: 0.51437

Collected Steps per Second: 21,798.58885
Overall Steps per Second: 10,647.15652

Timestep Collection Time: 2.29455
Timestep Consumption Time: 2.40323
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.69778

Cumulative Model Updates: 198,572
Cumulative Timesteps: 1,655,894,472

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,089.12196
Policy Entropy: 3.69513
Value Function Loss: 0.02137

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13374
Policy Update Magnitude: 0.51387
Value Function Update Magnitude: 0.51293

Collected Steps per Second: 22,664.00086
Overall Steps per Second: 10,696.92463

Timestep Collection Time: 2.20747
Timestep Consumption Time: 2.46958
PPO Batch Consumption Time: 0.28713
Total Iteration Time: 4.67705

Cumulative Model Updates: 198,578
Cumulative Timesteps: 1,655,944,502

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1655944502...
Checkpoint 1655944502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 109,089.12196
Policy Entropy: 3.68617
Value Function Loss: 0.01787

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12571
Policy Update Magnitude: 0.49422
Value Function Update Magnitude: 0.50303

Collected Steps per Second: 21,946.51153
Overall Steps per Second: 10,465.45797

Timestep Collection Time: 2.27854
Timestep Consumption Time: 2.49966
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.77820

Cumulative Model Updates: 198,584
Cumulative Timesteps: 1,655,994,508

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 109,089.12196
Policy Entropy: 3.67481
Value Function Loss: 0.02015

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12521
Policy Update Magnitude: 0.49171
Value Function Update Magnitude: 0.49743

Collected Steps per Second: 22,615.71603
Overall Steps per Second: 10,618.54533

Timestep Collection Time: 2.21227
Timestep Consumption Time: 2.49949
PPO Batch Consumption Time: 0.28692
Total Iteration Time: 4.71176

Cumulative Model Updates: 198,590
Cumulative Timesteps: 1,656,044,540

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1656044540...
Checkpoint 1656044540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 203,262.78241
Policy Entropy: 3.66790
Value Function Loss: 0.02389

Mean KL Divergence: 0.01042
SB3 Clip Fraction: 0.13741
Policy Update Magnitude: 0.51208
Value Function Update Magnitude: 0.47386

Collected Steps per Second: 22,585.66074
Overall Steps per Second: 10,791.51182

Timestep Collection Time: 2.21433
Timestep Consumption Time: 2.42006
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.63438

Cumulative Model Updates: 198,596
Cumulative Timesteps: 1,656,094,552

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 284,915.93252
Policy Entropy: 3.66471
Value Function Loss: 0.02947

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.13814
Policy Update Magnitude: 0.57222
Value Function Update Magnitude: 0.47152

Collected Steps per Second: 22,647.58881
Overall Steps per Second: 10,637.97451

Timestep Collection Time: 2.20827
Timestep Consumption Time: 2.49300
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.70127

Cumulative Model Updates: 198,602
Cumulative Timesteps: 1,656,144,564

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1656144564...
Checkpoint 1656144564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,634.51290
Policy Entropy: 3.69160
Value Function Loss: 0.03140

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.13201
Policy Update Magnitude: 0.63479
Value Function Update Magnitude: 0.53198

Collected Steps per Second: 22,310.27449
Overall Steps per Second: 10,559.17429

Timestep Collection Time: 2.24273
Timestep Consumption Time: 2.49589
PPO Batch Consumption Time: 0.28737
Total Iteration Time: 4.73863

Cumulative Model Updates: 198,608
Cumulative Timesteps: 1,656,194,600

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 16,172.88497
Policy Entropy: 3.70349
Value Function Loss: 0.03193

Mean KL Divergence: 0.01047
SB3 Clip Fraction: 0.13184
Policy Update Magnitude: 0.70582
Value Function Update Magnitude: 0.58326

Collected Steps per Second: 22,748.90432
Overall Steps per Second: 10,676.86974

Timestep Collection Time: 2.19870
Timestep Consumption Time: 2.48601
PPO Batch Consumption Time: 0.28673
Total Iteration Time: 4.68471

Cumulative Model Updates: 198,614
Cumulative Timesteps: 1,656,244,618

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1656244618...
Checkpoint 1656244618 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,172.88497
Policy Entropy: 3.69854
Value Function Loss: 0.02682

Mean KL Divergence: 0.02405
SB3 Clip Fraction: 0.25803
Policy Update Magnitude: 0.62919
Value Function Update Magnitude: 0.67228

Collected Steps per Second: 21,900.89523
Overall Steps per Second: 10,482.23742

Timestep Collection Time: 2.28347
Timestep Consumption Time: 2.48746
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.77093

Cumulative Model Updates: 198,620
Cumulative Timesteps: 1,656,294,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 272,278.18050
Policy Entropy: 3.69177
Value Function Loss: 0.04071

Mean KL Divergence: 0.01697
SB3 Clip Fraction: 0.18815
Policy Update Magnitude: 0.64142
Value Function Update Magnitude: 0.67141

Collected Steps per Second: 21,727.39615
Overall Steps per Second: 10,423.43578

Timestep Collection Time: 2.30354
Timestep Consumption Time: 2.49814
PPO Batch Consumption Time: 0.29191
Total Iteration Time: 4.80168

Cumulative Model Updates: 198,626
Cumulative Timesteps: 1,656,344,678

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


Saving checkpoint 1656344678...
Checkpoint 1656344678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 208,028.68405
Policy Entropy: 3.67944
Value Function Loss: 0.04965

Mean KL Divergence: 0.01436
SB3 Clip Fraction: 0.16250
Policy Update Magnitude: 0.86474
Value Function Update Magnitude: 0.60141

Collected Steps per Second: 21,396.22704
Overall Steps per Second: 10,519.48453

Timestep Collection Time: 2.33723
Timestep Consumption Time: 2.41661
PPO Batch Consumption Time: 0.27701
Total Iteration Time: 4.75385

Cumulative Model Updates: 198,632
Cumulative Timesteps: 1,656,394,686

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 108,078.69546
Policy Entropy: 3.71263
Value Function Loss: 0.05766

Mean KL Divergence: 0.01364
SB3 Clip Fraction: 0.15569
Policy Update Magnitude: 0.98515
Value Function Update Magnitude: 0.49071

Collected Steps per Second: 21,954.73428
Overall Steps per Second: 10,532.49919

Timestep Collection Time: 2.27805
Timestep Consumption Time: 2.47049
PPO Batch Consumption Time: 0.28893
Total Iteration Time: 4.74854

Cumulative Model Updates: 198,638
Cumulative Timesteps: 1,656,444,700

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1656444700...
Checkpoint 1656444700 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,204.71103
Policy Entropy: 3.76051
Value Function Loss: 0.05073

Mean KL Divergence: 0.01947
SB3 Clip Fraction: 0.19632
Policy Update Magnitude: 0.92168
Value Function Update Magnitude: 0.50490

Collected Steps per Second: 21,592.07842
Overall Steps per Second: 10,532.01411

Timestep Collection Time: 2.31650
Timestep Consumption Time: 2.43264
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.74914

Cumulative Model Updates: 198,644
Cumulative Timesteps: 1,656,494,718

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 21,617.95546
Policy Entropy: 3.78175
Value Function Loss: 0.05348

Mean KL Divergence: 0.01191
SB3 Clip Fraction: 0.14132
Policy Update Magnitude: 1.02990
Value Function Update Magnitude: 0.59520

Collected Steps per Second: 22,110.08865
Overall Steps per Second: 10,580.63761

Timestep Collection Time: 2.26204
Timestep Consumption Time: 2.46489
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.72694

Cumulative Model Updates: 198,650
Cumulative Timesteps: 1,656,544,732

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1656544732...
Checkpoint 1656544732 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 111,252.53654
Policy Entropy: 3.75857
Value Function Loss: 0.05220

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13011
Policy Update Magnitude: 1.13625
Value Function Update Magnitude: 0.50169

Collected Steps per Second: 21,656.30286
Overall Steps per Second: 10,525.52870

Timestep Collection Time: 2.31009
Timestep Consumption Time: 2.44293
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.75302

Cumulative Model Updates: 198,656
Cumulative Timesteps: 1,656,594,760

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 31,432.02461
Policy Entropy: 3.73259
Value Function Loss: 0.04545

Mean KL Divergence: 0.01117
SB3 Clip Fraction: 0.13218
Policy Update Magnitude: 1.10271
Value Function Update Magnitude: 0.50497

Collected Steps per Second: 22,942.95346
Overall Steps per Second: 10,726.60366

Timestep Collection Time: 2.18019
Timestep Consumption Time: 2.48298
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.66317

Cumulative Model Updates: 198,662
Cumulative Timesteps: 1,656,644,780

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1656644780...
Checkpoint 1656644780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 60,733.42540
Policy Entropy: 3.74474
Value Function Loss: 0.03443

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.14796
Policy Update Magnitude: 0.92847
Value Function Update Magnitude: 0.55540

Collected Steps per Second: 22,313.13818
Overall Steps per Second: 10,557.80435

Timestep Collection Time: 2.24119
Timestep Consumption Time: 2.49540
PPO Batch Consumption Time: 0.29153
Total Iteration Time: 4.73659

Cumulative Model Updates: 198,668
Cumulative Timesteps: 1,656,694,788

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,079.55134
Policy Entropy: 3.71821
Value Function Loss: 0.03078

Mean KL Divergence: 0.01037
SB3 Clip Fraction: 0.13292
Policy Update Magnitude: 0.68914
Value Function Update Magnitude: 0.63823

Collected Steps per Second: 22,917.86717
Overall Steps per Second: 10,877.75054

Timestep Collection Time: 2.18415
Timestep Consumption Time: 2.41754
PPO Batch Consumption Time: 0.27646
Total Iteration Time: 4.60169

Cumulative Model Updates: 198,674
Cumulative Timesteps: 1,656,744,844

Timesteps Collected: 50,056
--------END ITERATION REPORT--------


Saving checkpoint 1656744844...
Checkpoint 1656744844 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,077.81872
Policy Entropy: 3.74352
Value Function Loss: 0.02851

Mean KL Divergence: 0.00887
SB3 Clip Fraction: 0.11406
Policy Update Magnitude: 0.65753
Value Function Update Magnitude: 0.76555

Collected Steps per Second: 22,235.64106
Overall Steps per Second: 10,630.95209

Timestep Collection Time: 2.24891
Timestep Consumption Time: 2.45490
PPO Batch Consumption Time: 0.28457
Total Iteration Time: 4.70381

Cumulative Model Updates: 198,680
Cumulative Timesteps: 1,656,794,850

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,502.75961
Policy Entropy: 3.73220
Value Function Loss: 0.03271

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.12897
Policy Update Magnitude: 0.65282
Value Function Update Magnitude: 0.78590

Collected Steps per Second: 22,051.35034
Overall Steps per Second: 10,408.18020

Timestep Collection Time: 2.26880
Timestep Consumption Time: 2.53800
PPO Batch Consumption Time: 0.29033
Total Iteration Time: 4.80680

Cumulative Model Updates: 198,686
Cumulative Timesteps: 1,656,844,880

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1656844880...
Checkpoint 1656844880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 273.84908
Policy Entropy: 3.79191
Value Function Loss: 0.02937

Mean KL Divergence: 0.01198
SB3 Clip Fraction: 0.15655
Policy Update Magnitude: 0.61286
Value Function Update Magnitude: 0.64421

Collected Steps per Second: 22,076.96491
Overall Steps per Second: 10,643.08373

Timestep Collection Time: 2.26562
Timestep Consumption Time: 2.43396
PPO Batch Consumption Time: 0.27790
Total Iteration Time: 4.69958

Cumulative Model Updates: 198,692
Cumulative Timesteps: 1,656,894,898

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33,330.17013
Policy Entropy: 3.79454
Value Function Loss: 0.02829

Mean KL Divergence: 0.01096
SB3 Clip Fraction: 0.14630
Policy Update Magnitude: 0.53374
Value Function Update Magnitude: 0.81591

Collected Steps per Second: 22,467.95405
Overall Steps per Second: 10,608.02094

Timestep Collection Time: 2.22557
Timestep Consumption Time: 2.48822
PPO Batch Consumption Time: 0.29057
Total Iteration Time: 4.71379

Cumulative Model Updates: 198,698
Cumulative Timesteps: 1,656,944,902

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1656944902...
Checkpoint 1656944902 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,697.64925
Policy Entropy: 3.79984
Value Function Loss: 0.02396

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13318
Policy Update Magnitude: 0.45443
Value Function Update Magnitude: 0.89672

Collected Steps per Second: 21,954.93148
Overall Steps per Second: 10,529.31816

Timestep Collection Time: 2.27885
Timestep Consumption Time: 2.47283
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.75168

Cumulative Model Updates: 198,704
Cumulative Timesteps: 1,656,994,934

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 947.48523
Policy Entropy: 3.75128
Value Function Loss: 0.02324

Mean KL Divergence: 0.01139
SB3 Clip Fraction: 0.15023
Policy Update Magnitude: 0.41980
Value Function Update Magnitude: 0.83819

Collected Steps per Second: 22,600.57473
Overall Steps per Second: 10,600.13745

Timestep Collection Time: 2.21260
Timestep Consumption Time: 2.50489
PPO Batch Consumption Time: 0.28849
Total Iteration Time: 4.71749

Cumulative Model Updates: 198,710
Cumulative Timesteps: 1,657,044,940

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1657044940...
Checkpoint 1657044940 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 337.08472
Policy Entropy: 3.72475
Value Function Loss: 0.01999

Mean KL Divergence: 0.01361
SB3 Clip Fraction: 0.17385
Policy Update Magnitude: 0.44662
Value Function Update Magnitude: 0.78274

Collected Steps per Second: 22,264.12884
Overall Steps per Second: 10,485.26731

Timestep Collection Time: 2.24711
Timestep Consumption Time: 2.52434
PPO Batch Consumption Time: 0.29210
Total Iteration Time: 4.77146

Cumulative Model Updates: 198,716
Cumulative Timesteps: 1,657,094,970

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 145.18086
Policy Entropy: 3.72300
Value Function Loss: 0.01918

Mean KL Divergence: 0.01351
SB3 Clip Fraction: 0.17726
Policy Update Magnitude: 0.41847
Value Function Update Magnitude: 0.70459

Collected Steps per Second: 22,849.25378
Overall Steps per Second: 10,643.80072

Timestep Collection Time: 2.18834
Timestep Consumption Time: 2.50942
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.69776

Cumulative Model Updates: 198,722
Cumulative Timesteps: 1,657,144,972

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1657144972...
Checkpoint 1657144972 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 77,389.53590
Policy Entropy: 3.74947
Value Function Loss: 0.01998

Mean KL Divergence: 0.01787
SB3 Clip Fraction: 0.22329
Policy Update Magnitude: 0.40453
Value Function Update Magnitude: 0.63249

Collected Steps per Second: 22,538.20210
Overall Steps per Second: 10,645.53986

Timestep Collection Time: 2.21899
Timestep Consumption Time: 2.47894
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.69793

Cumulative Model Updates: 198,728
Cumulative Timesteps: 1,657,194,984

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,642.30403
Policy Entropy: 3.74478
Value Function Loss: 0.02477

Mean KL Divergence: 0.01752
SB3 Clip Fraction: 0.22306
Policy Update Magnitude: 0.34337
Value Function Update Magnitude: 0.67538

Collected Steps per Second: 22,895.88061
Overall Steps per Second: 10,701.42350

Timestep Collection Time: 2.18389
Timestep Consumption Time: 2.48858
PPO Batch Consumption Time: 0.28722
Total Iteration Time: 4.67246

Cumulative Model Updates: 198,734
Cumulative Timesteps: 1,657,244,986

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1657244986...
Checkpoint 1657244986 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,589.50921
Policy Entropy: 3.74907
Value Function Loss: 0.02731

Mean KL Divergence: 0.00869
SB3 Clip Fraction: 0.11498
Policy Update Magnitude: 0.46793
Value Function Update Magnitude: 0.72995

Collected Steps per Second: 22,343.31176
Overall Steps per Second: 10,620.57708

Timestep Collection Time: 2.23906
Timestep Consumption Time: 2.47142
PPO Batch Consumption Time: 0.28442
Total Iteration Time: 4.71048

Cumulative Model Updates: 198,740
Cumulative Timesteps: 1,657,295,014

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,838.71938
Policy Entropy: 3.74800
Value Function Loss: 0.02783

Mean KL Divergence: 0.00826
SB3 Clip Fraction: 0.10602
Policy Update Magnitude: 0.56969
Value Function Update Magnitude: 0.79920

Collected Steps per Second: 22,999.87213
Overall Steps per Second: 10,856.07698

Timestep Collection Time: 2.17479
Timestep Consumption Time: 2.43276
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.60756

Cumulative Model Updates: 198,746
Cumulative Timesteps: 1,657,345,034

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1657345034...
Checkpoint 1657345034 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,501.89706
Policy Entropy: 3.74551
Value Function Loss: 0.02446

Mean KL Divergence: 0.00551
SB3 Clip Fraction: 0.06478
Policy Update Magnitude: 0.60126
Value Function Update Magnitude: 0.65227

Collected Steps per Second: 22,362.71992
Overall Steps per Second: 10,745.97631

Timestep Collection Time: 2.23721
Timestep Consumption Time: 2.41849
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.65570

Cumulative Model Updates: 198,752
Cumulative Timesteps: 1,657,395,064

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.58802
Policy Entropy: 3.74494
Value Function Loss: 0.02111

Mean KL Divergence: 0.00446
SB3 Clip Fraction: 0.05022
Policy Update Magnitude: 0.56596
Value Function Update Magnitude: 0.52908

Collected Steps per Second: 22,802.10301
Overall Steps per Second: 10,830.57609

Timestep Collection Time: 2.19278
Timestep Consumption Time: 2.42378
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.61656

Cumulative Model Updates: 198,758
Cumulative Timesteps: 1,657,445,064

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1657445064...
Checkpoint 1657445064 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.58802
Policy Entropy: 3.73484
Value Function Loss: 0.01707

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04304
Policy Update Magnitude: 0.52462
Value Function Update Magnitude: 0.46865

Collected Steps per Second: 21,907.62550
Overall Steps per Second: 10,616.82776

Timestep Collection Time: 2.28268
Timestep Consumption Time: 2.42758
PPO Batch Consumption Time: 0.27672
Total Iteration Time: 4.71026

Cumulative Model Updates: 198,764
Cumulative Timesteps: 1,657,495,072

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.58802
Policy Entropy: 3.74125
Value Function Loss: 0.01533

Mean KL Divergence: 0.00440
SB3 Clip Fraction: 0.04730
Policy Update Magnitude: 0.45949
Value Function Update Magnitude: 0.36465

Collected Steps per Second: 22,664.60468
Overall Steps per Second: 10,686.22135

Timestep Collection Time: 2.20661
Timestep Consumption Time: 2.47343
PPO Batch Consumption Time: 0.28942
Total Iteration Time: 4.68005

Cumulative Model Updates: 198,770
Cumulative Timesteps: 1,657,545,084

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1657545084...
Checkpoint 1657545084 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.58802
Policy Entropy: 3.72724
Value Function Loss: 0.01333

Mean KL Divergence: 0.00693
SB3 Clip Fraction: 0.08930
Policy Update Magnitude: 0.38664
Value Function Update Magnitude: 0.28117

Collected Steps per Second: 21,684.41154
Overall Steps per Second: 10,481.15815

Timestep Collection Time: 2.30590
Timestep Consumption Time: 2.46476
PPO Batch Consumption Time: 0.28403
Total Iteration Time: 4.77066

Cumulative Model Updates: 198,776
Cumulative Timesteps: 1,657,595,086

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.58802
Policy Entropy: 3.73525
Value Function Loss: 0.01255

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.29303
Value Function Update Magnitude: 0.27888

Collected Steps per Second: 22,164.89289
Overall Steps per Second: 10,434.65000

Timestep Collection Time: 2.25717
Timestep Consumption Time: 2.53743
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.79460

Cumulative Model Updates: 198,782
Cumulative Timesteps: 1,657,645,116

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1657645116...
Checkpoint 1657645116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.58802
Policy Entropy: 3.70551
Value Function Loss: 0.01509

Mean KL Divergence: 0.01033
SB3 Clip Fraction: 0.14531
Policy Update Magnitude: 0.26906
Value Function Update Magnitude: 0.31705

Collected Steps per Second: 22,495.82140
Overall Steps per Second: 10,700.99638

Timestep Collection Time: 2.22264
Timestep Consumption Time: 2.44983
PPO Batch Consumption Time: 0.27589
Total Iteration Time: 4.67246

Cumulative Model Updates: 198,788
Cumulative Timesteps: 1,657,695,116

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.58802
Policy Entropy: 3.73709
Value Function Loss: 0.01405

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13878
Policy Update Magnitude: 0.33620
Value Function Update Magnitude: 0.39193

Collected Steps per Second: 22,863.31525
Overall Steps per Second: 10,854.58194

Timestep Collection Time: 2.18743
Timestep Consumption Time: 2.42002
PPO Batch Consumption Time: 0.27794
Total Iteration Time: 4.60746

Cumulative Model Updates: 198,794
Cumulative Timesteps: 1,657,745,128

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1657745128...
Checkpoint 1657745128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,034.58802
Policy Entropy: 3.72017
Value Function Loss: 0.01305

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13210
Policy Update Magnitude: 0.33549
Value Function Update Magnitude: 0.44761

Collected Steps per Second: 22,449.20514
Overall Steps per Second: 10,660.20256

Timestep Collection Time: 2.22859
Timestep Consumption Time: 2.46457
PPO Batch Consumption Time: 0.28398
Total Iteration Time: 4.69316

Cumulative Model Updates: 198,800
Cumulative Timesteps: 1,657,795,158

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 86,695.57008
Policy Entropy: 3.74546
Value Function Loss: 0.01385

Mean KL Divergence: 0.00849
SB3 Clip Fraction: 0.11971
Policy Update Magnitude: 0.32976
Value Function Update Magnitude: 0.47485

Collected Steps per Second: 22,405.35528
Overall Steps per Second: 10,875.69626

Timestep Collection Time: 2.23170
Timestep Consumption Time: 2.36589
PPO Batch Consumption Time: 0.27861
Total Iteration Time: 4.59759

Cumulative Model Updates: 198,806
Cumulative Timesteps: 1,657,845,160

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1657845160...
Checkpoint 1657845160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 49,359.80946
Policy Entropy: 3.72642
Value Function Loss: 0.01503

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.31338
Value Function Update Magnitude: 0.59611

Collected Steps per Second: 21,986.06035
Overall Steps per Second: 10,661.85137

Timestep Collection Time: 2.27508
Timestep Consumption Time: 2.41641
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.69149

Cumulative Model Updates: 198,812
Cumulative Timesteps: 1,657,895,180

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 17,222.52029
Policy Entropy: 3.73181
Value Function Loss: 0.01699

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12647
Policy Update Magnitude: 0.32913
Value Function Update Magnitude: 0.65486

Collected Steps per Second: 22,358.43888
Overall Steps per Second: 10,899.76739

Timestep Collection Time: 2.23683
Timestep Consumption Time: 2.35153
PPO Batch Consumption Time: 0.27793
Total Iteration Time: 4.58835

Cumulative Model Updates: 198,818
Cumulative Timesteps: 1,657,945,192

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1657945192...
Checkpoint 1657945192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202,150.74828
Policy Entropy: 3.72975
Value Function Loss: 0.01856

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12452
Policy Update Magnitude: 0.35520
Value Function Update Magnitude: 0.62223

Collected Steps per Second: 21,424.08282
Overall Steps per Second: 10,578.59333

Timestep Collection Time: 2.33560
Timestep Consumption Time: 2.39452
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.73012

Cumulative Model Updates: 198,824
Cumulative Timesteps: 1,657,995,230

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,050.76508
Policy Entropy: 3.73365
Value Function Loss: 0.01854

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.37697
Value Function Update Magnitude: 0.61511

Collected Steps per Second: 22,660.64631
Overall Steps per Second: 10,760.25552

Timestep Collection Time: 2.20647
Timestep Consumption Time: 2.44026
PPO Batch Consumption Time: 0.28607
Total Iteration Time: 4.64673

Cumulative Model Updates: 198,830
Cumulative Timesteps: 1,658,045,230

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1658045230...
Checkpoint 1658045230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,050.76508
Policy Entropy: 3.72163
Value Function Loss: 0.02162

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12745
Policy Update Magnitude: 0.43608
Value Function Update Magnitude: 0.55093

Collected Steps per Second: 22,277.56639
Overall Steps per Second: 10,797.95674

Timestep Collection Time: 2.24450
Timestep Consumption Time: 2.38619
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.63069

Cumulative Model Updates: 198,836
Cumulative Timesteps: 1,658,095,232

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 164,365.77553
Policy Entropy: 3.72969
Value Function Loss: 0.02081

Mean KL Divergence: 0.00923
SB3 Clip Fraction: 0.12954
Policy Update Magnitude: 0.46344
Value Function Update Magnitude: 0.60477

Collected Steps per Second: 22,725.60300
Overall Steps per Second: 10,609.41635

Timestep Collection Time: 2.20095
Timestep Consumption Time: 2.51354
PPO Batch Consumption Time: 0.29003
Total Iteration Time: 4.71449

Cumulative Model Updates: 198,842
Cumulative Timesteps: 1,658,145,250

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1658145250...
Checkpoint 1658145250 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 57,321.68376
Policy Entropy: 3.72761
Value Function Loss: 0.01948

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13235
Policy Update Magnitude: 0.44503
Value Function Update Magnitude: 0.71263

Collected Steps per Second: 22,523.69413
Overall Steps per Second: 10,539.21743

Timestep Collection Time: 2.22033
Timestep Consumption Time: 2.52481
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.74513

Cumulative Model Updates: 198,848
Cumulative Timesteps: 1,658,195,260

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,426.79067
Policy Entropy: 3.73784
Value Function Loss: 0.01656

Mean KL Divergence: 0.00864
SB3 Clip Fraction: 0.12353
Policy Update Magnitude: 0.39520
Value Function Update Magnitude: 0.58332

Collected Steps per Second: 22,820.52509
Overall Steps per Second: 10,802.03093

Timestep Collection Time: 2.19154
Timestep Consumption Time: 2.43833
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.62987

Cumulative Model Updates: 198,854
Cumulative Timesteps: 1,658,245,272

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1658245272...
Checkpoint 1658245272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 443,180.17390
Policy Entropy: 3.71141
Value Function Loss: 0.01652

Mean KL Divergence: 0.00867
SB3 Clip Fraction: 0.12487
Policy Update Magnitude: 0.37342
Value Function Update Magnitude: 0.55895

Collected Steps per Second: 22,479.97474
Overall Steps per Second: 10,763.83179

Timestep Collection Time: 2.22500
Timestep Consumption Time: 2.42186
PPO Batch Consumption Time: 0.27720
Total Iteration Time: 4.64686

Cumulative Model Updates: 198,860
Cumulative Timesteps: 1,658,295,290

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 154,535.98814
Policy Entropy: 3.70963
Value Function Loss: 0.01686

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.38875
Value Function Update Magnitude: 0.58291

Collected Steps per Second: 22,656.73658
Overall Steps per Second: 10,810.50024

Timestep Collection Time: 2.20738
Timestep Consumption Time: 2.41886
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.62624

Cumulative Model Updates: 198,866
Cumulative Timesteps: 1,658,345,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1658345302...
Checkpoint 1658345302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,371.14472
Policy Entropy: 3.70001
Value Function Loss: 0.02019

Mean KL Divergence: 0.00834
SB3 Clip Fraction: 0.11779
Policy Update Magnitude: 0.41072
Value Function Update Magnitude: 0.58504

Collected Steps per Second: 22,333.35858
Overall Steps per Second: 10,747.12366

Timestep Collection Time: 2.23925
Timestep Consumption Time: 2.41409
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.65334

Cumulative Model Updates: 198,872
Cumulative Timesteps: 1,658,395,312

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,379.21636
Policy Entropy: 3.70934
Value Function Loss: 0.01862

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.39923
Value Function Update Magnitude: 0.63334

Collected Steps per Second: 22,690.76860
Overall Steps per Second: 10,788.50188

Timestep Collection Time: 2.20442
Timestep Consumption Time: 2.43200
PPO Batch Consumption Time: 0.27819
Total Iteration Time: 4.63642

Cumulative Model Updates: 198,878
Cumulative Timesteps: 1,658,445,332

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1658445332...
Checkpoint 1658445332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,379.21636
Policy Entropy: 3.70047
Value Function Loss: 0.01759

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12585
Policy Update Magnitude: 0.38249
Value Function Update Magnitude: 0.56014

Collected Steps per Second: 21,943.63763
Overall Steps per Second: 10,640.64853

Timestep Collection Time: 2.27902
Timestep Consumption Time: 2.42088
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.69990

Cumulative Model Updates: 198,884
Cumulative Timesteps: 1,658,495,342

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,379.21636
Policy Entropy: 3.70662
Value Function Loss: 0.01526

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.12477
Policy Update Magnitude: 0.36084
Value Function Update Magnitude: 0.41914

Collected Steps per Second: 22,561.37490
Overall Steps per Second: 10,608.88984

Timestep Collection Time: 2.21751
Timestep Consumption Time: 2.49835
PPO Batch Consumption Time: 0.29110
Total Iteration Time: 4.71586

Cumulative Model Updates: 198,890
Cumulative Timesteps: 1,658,545,372

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1658545372...
Checkpoint 1658545372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 62,379.21636
Policy Entropy: 3.69269
Value Function Loss: 0.01736

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12726
Policy Update Magnitude: 0.40104
Value Function Update Magnitude: 0.51836

Collected Steps per Second: 21,755.04409
Overall Steps per Second: 10,565.58572

Timestep Collection Time: 2.29841
Timestep Consumption Time: 2.43413
PPO Batch Consumption Time: 0.28109
Total Iteration Time: 4.73253

Cumulative Model Updates: 198,896
Cumulative Timesteps: 1,658,595,374

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 178,382.60518
Policy Entropy: 3.70933
Value Function Loss: 0.01762

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.12394
Policy Update Magnitude: 0.45560
Value Function Update Magnitude: 0.70151

Collected Steps per Second: 22,682.21089
Overall Steps per Second: 10,818.34625

Timestep Collection Time: 2.20525
Timestep Consumption Time: 2.41837
PPO Batch Consumption Time: 0.27753
Total Iteration Time: 4.62363

Cumulative Model Updates: 198,902
Cumulative Timesteps: 1,658,645,394

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1658645394...
Checkpoint 1658645394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,391.33887
Policy Entropy: 3.71253
Value Function Loss: 0.01985

Mean KL Divergence: 0.00917
SB3 Clip Fraction: 0.12197
Policy Update Magnitude: 0.46149
Value Function Update Magnitude: 0.75931

Collected Steps per Second: 22,207.60578
Overall Steps per Second: 10,691.40731

Timestep Collection Time: 2.25256
Timestep Consumption Time: 2.42634
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.67890

Cumulative Model Updates: 198,908
Cumulative Timesteps: 1,658,695,418

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 97,516.59474
Policy Entropy: 3.73330
Value Function Loss: 0.01918

Mean KL Divergence: 0.00858
SB3 Clip Fraction: 0.11548
Policy Update Magnitude: 0.46955
Value Function Update Magnitude: 0.73833

Collected Steps per Second: 22,125.10624
Overall Steps per Second: 10,625.82299

Timestep Collection Time: 2.26087
Timestep Consumption Time: 2.44672
PPO Batch Consumption Time: 0.28982
Total Iteration Time: 4.70759

Cumulative Model Updates: 198,914
Cumulative Timesteps: 1,658,745,440

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1658745440...
Checkpoint 1658745440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,983.42179
Policy Entropy: 3.74056
Value Function Loss: 0.01688

Mean KL Divergence: 0.00806
SB3 Clip Fraction: 0.10394
Policy Update Magnitude: 0.44102
Value Function Update Magnitude: 0.72285

Collected Steps per Second: 21,853.81871
Overall Steps per Second: 10,663.63159

Timestep Collection Time: 2.28921
Timestep Consumption Time: 2.40225
PPO Batch Consumption Time: 0.28997
Total Iteration Time: 4.69146

Cumulative Model Updates: 198,920
Cumulative Timesteps: 1,658,795,468

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,983.42179
Policy Entropy: 3.71335
Value Function Loss: 0.01813

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.12683
Policy Update Magnitude: 0.42628
Value Function Update Magnitude: 0.66991

Collected Steps per Second: 22,487.39080
Overall Steps per Second: 10,738.92992

Timestep Collection Time: 2.22445
Timestep Consumption Time: 2.43356
PPO Batch Consumption Time: 0.29350
Total Iteration Time: 4.65801

Cumulative Model Updates: 198,926
Cumulative Timesteps: 1,658,845,490

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1658845490...
Checkpoint 1658845490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 63,983.42179
Policy Entropy: 3.71297
Value Function Loss: 0.01741

Mean KL Divergence: 0.01180
SB3 Clip Fraction: 0.15185
Policy Update Magnitude: 0.46703
Value Function Update Magnitude: 0.70063

Collected Steps per Second: 21,784.33120
Overall Steps per Second: 10,625.42270

Timestep Collection Time: 2.29541
Timestep Consumption Time: 2.41066
PPO Batch Consumption Time: 0.27882
Total Iteration Time: 4.70607

Cumulative Model Updates: 198,932
Cumulative Timesteps: 1,658,895,494

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,983.42179
Policy Entropy: 3.69976
Value Function Loss: 0.01960

Mean KL Divergence: 0.01157
SB3 Clip Fraction: 0.15091
Policy Update Magnitude: 0.46521
Value Function Update Magnitude: 0.74878

Collected Steps per Second: 23,050.47948
Overall Steps per Second: 10,979.61480

Timestep Collection Time: 2.17037
Timestep Consumption Time: 2.38608
PPO Batch Consumption Time: 0.27606
Total Iteration Time: 4.55644

Cumulative Model Updates: 198,938
Cumulative Timesteps: 1,658,945,522

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1658945522...
Checkpoint 1658945522 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,616.47965
Policy Entropy: 3.72974
Value Function Loss: 0.01952

Mean KL Divergence: 0.00674
SB3 Clip Fraction: 0.08404
Policy Update Magnitude: 0.55567
Value Function Update Magnitude: 0.80531

Collected Steps per Second: 22,437.68599
Overall Steps per Second: 10,661.12368

Timestep Collection Time: 2.23018
Timestep Consumption Time: 2.46351
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.69369

Cumulative Model Updates: 198,944
Cumulative Timesteps: 1,658,995,562

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,356.36210
Policy Entropy: 3.74814
Value Function Loss: 0.01839

Mean KL Divergence: 0.00566
SB3 Clip Fraction: 0.06761
Policy Update Magnitude: 0.57097
Value Function Update Magnitude: 0.84298

Collected Steps per Second: 22,674.05897
Overall Steps per Second: 10,771.34283

Timestep Collection Time: 2.20543
Timestep Consumption Time: 2.43708
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.64250

Cumulative Model Updates: 198,950
Cumulative Timesteps: 1,659,045,568

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1659045568...
Checkpoint 1659045568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,876.34038
Policy Entropy: 3.75877
Value Function Loss: 0.01583

Mean KL Divergence: 0.00422
SB3 Clip Fraction: 0.04449
Policy Update Magnitude: 0.52510
Value Function Update Magnitude: 0.82172

Collected Steps per Second: 21,895.10078
Overall Steps per Second: 10,630.31358

Timestep Collection Time: 2.28426
Timestep Consumption Time: 2.42059
PPO Batch Consumption Time: 0.27718
Total Iteration Time: 4.70485

Cumulative Model Updates: 198,956
Cumulative Timesteps: 1,659,095,582

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.75809
Value Function Loss: 0.01406

Mean KL Divergence: 0.00518
SB3 Clip Fraction: 0.05935
Policy Update Magnitude: 0.46726
Value Function Update Magnitude: 0.73595

Collected Steps per Second: 22,807.75480
Overall Steps per Second: 10,682.35143

Timestep Collection Time: 2.19329
Timestep Consumption Time: 2.48958
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.68286

Cumulative Model Updates: 198,962
Cumulative Timesteps: 1,659,145,606

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1659145606...
Checkpoint 1659145606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.73514
Value Function Loss: 0.01258

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05285
Policy Update Magnitude: 0.44057
Value Function Update Magnitude: 0.61891

Collected Steps per Second: 21,934.79157
Overall Steps per Second: 10,522.68348

Timestep Collection Time: 2.28040
Timestep Consumption Time: 2.47314
PPO Batch Consumption Time: 0.28685
Total Iteration Time: 4.75354

Cumulative Model Updates: 198,968
Cumulative Timesteps: 1,659,195,626

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.71361
Value Function Loss: 0.01383

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04669
Policy Update Magnitude: 0.47604
Value Function Update Magnitude: 0.52817

Collected Steps per Second: 23,290.34915
Overall Steps per Second: 10,815.98827

Timestep Collection Time: 2.14698
Timestep Consumption Time: 2.47617
PPO Batch Consumption Time: 0.27836
Total Iteration Time: 4.62316

Cumulative Model Updates: 198,974
Cumulative Timesteps: 1,659,245,630

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1659245630...
Checkpoint 1659245630 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.70845
Value Function Loss: 0.01290

Mean KL Divergence: 0.00488
SB3 Clip Fraction: 0.05552
Policy Update Magnitude: 0.50690
Value Function Update Magnitude: 0.50627

Collected Steps per Second: 22,507.44558
Overall Steps per Second: 10,627.87871

Timestep Collection Time: 2.22149
Timestep Consumption Time: 2.48312
PPO Batch Consumption Time: 0.28578
Total Iteration Time: 4.70461

Cumulative Model Updates: 198,980
Cumulative Timesteps: 1,659,295,630

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.71781
Value Function Loss: 0.01290

Mean KL Divergence: 0.00483
SB3 Clip Fraction: 0.05366
Policy Update Magnitude: 0.48347
Value Function Update Magnitude: 0.47946

Collected Steps per Second: 22,835.64846
Overall Steps per Second: 10,702.11339

Timestep Collection Time: 2.18965
Timestep Consumption Time: 2.48251
PPO Batch Consumption Time: 0.28864
Total Iteration Time: 4.67216

Cumulative Model Updates: 198,986
Cumulative Timesteps: 1,659,345,632

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1659345632...
Checkpoint 1659345632 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.72384
Value Function Loss: 0.01286

Mean KL Divergence: 0.00590
SB3 Clip Fraction: 0.07191
Policy Update Magnitude: 0.43988
Value Function Update Magnitude: 0.39770

Collected Steps per Second: 22,161.21306
Overall Steps per Second: 10,549.59577

Timestep Collection Time: 2.25755
Timestep Consumption Time: 2.48481
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.74236

Cumulative Model Updates: 198,992
Cumulative Timesteps: 1,659,395,662

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.73746
Value Function Loss: 0.01259

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06143
Policy Update Magnitude: 0.44303
Value Function Update Magnitude: 0.32278

Collected Steps per Second: 22,751.92141
Overall Steps per Second: 10,811.57638

Timestep Collection Time: 2.19964
Timestep Consumption Time: 2.42929
PPO Batch Consumption Time: 0.27899
Total Iteration Time: 4.62893

Cumulative Model Updates: 198,998
Cumulative Timesteps: 1,659,445,708

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1659445708...
Checkpoint 1659445708 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.73801
Value Function Loss: 0.01328

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06893
Policy Update Magnitude: 0.46182
Value Function Update Magnitude: 0.30190

Collected Steps per Second: 22,460.90105
Overall Steps per Second: 10,671.37334

Timestep Collection Time: 2.22636
Timestep Consumption Time: 2.45964
PPO Batch Consumption Time: 0.28541
Total Iteration Time: 4.68599

Cumulative Model Updates: 199,004
Cumulative Timesteps: 1,659,495,714

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.74691
Value Function Loss: 0.01284

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.05930
Policy Update Magnitude: 0.46609
Value Function Update Magnitude: 0.27219

Collected Steps per Second: 22,412.40327
Overall Steps per Second: 10,959.31610

Timestep Collection Time: 2.23198
Timestep Consumption Time: 2.33254
PPO Batch Consumption Time: 0.27542
Total Iteration Time: 4.56452

Cumulative Model Updates: 199,010
Cumulative Timesteps: 1,659,545,738

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1659545738...
Checkpoint 1659545738 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.74168
Value Function Loss: 0.01321

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.05989
Policy Update Magnitude: 0.44585
Value Function Update Magnitude: 0.26535

Collected Steps per Second: 21,296.69681
Overall Steps per Second: 10,687.40563

Timestep Collection Time: 2.34835
Timestep Consumption Time: 2.33118
PPO Batch Consumption Time: 0.27574
Total Iteration Time: 4.67953

Cumulative Model Updates: 199,016
Cumulative Timesteps: 1,659,595,750

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.75541
Value Function Loss: 0.01222

Mean KL Divergence: 0.00557
SB3 Clip Fraction: 0.06544
Policy Update Magnitude: 0.42587
Value Function Update Magnitude: 0.24188

Collected Steps per Second: 21,804.57662
Overall Steps per Second: 10,506.55386

Timestep Collection Time: 2.29319
Timestep Consumption Time: 2.46594
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.75912

Cumulative Model Updates: 199,022
Cumulative Timesteps: 1,659,645,752

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1659645752...
Checkpoint 1659645752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,388.80316
Policy Entropy: 3.75038
Value Function Loss: 0.01183

Mean KL Divergence: 0.00743
SB3 Clip Fraction: 0.09632
Policy Update Magnitude: 0.40803
Value Function Update Magnitude: 0.26397

Collected Steps per Second: 21,994.46347
Overall Steps per Second: 10,551.21089

Timestep Collection Time: 2.27366
Timestep Consumption Time: 2.46589
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.73955

Cumulative Model Updates: 199,028
Cumulative Timesteps: 1,659,695,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,697.86881
Policy Entropy: 3.73195
Value Function Loss: 0.01491

Mean KL Divergence: 0.01212
SB3 Clip Fraction: 0.16105
Policy Update Magnitude: 0.40830
Value Function Update Magnitude: 0.45398

Collected Steps per Second: 21,993.59016
Overall Steps per Second: 10,574.78345

Timestep Collection Time: 2.27584
Timestep Consumption Time: 2.45749
PPO Batch Consumption Time: 0.28884
Total Iteration Time: 4.73334

Cumulative Model Updates: 199,034
Cumulative Timesteps: 1,659,745,814

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


Saving checkpoint 1659745814...
Checkpoint 1659745814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,697.86881
Policy Entropy: 3.73004
Value Function Loss: 0.01390

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14351
Policy Update Magnitude: 0.45598
Value Function Update Magnitude: 0.55882

Collected Steps per Second: 22,478.58125
Overall Steps per Second: 10,527.73148

Timestep Collection Time: 2.22559
Timestep Consumption Time: 2.52644
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.75202

Cumulative Model Updates: 199,040
Cumulative Timesteps: 1,659,795,842

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,697.86881
Policy Entropy: 3.70801
Value Function Loss: 0.01519

Mean KL Divergence: 0.01073
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.43490
Value Function Update Magnitude: 0.53724

Collected Steps per Second: 23,161.75725
Overall Steps per Second: 10,897.28616

Timestep Collection Time: 2.15916
Timestep Consumption Time: 2.43005
PPO Batch Consumption Time: 0.27689
Total Iteration Time: 4.58922

Cumulative Model Updates: 199,046
Cumulative Timesteps: 1,659,845,852

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1659845852...
Checkpoint 1659845852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,697.86881
Policy Entropy: 3.73968
Value Function Loss: 0.01183

Mean KL Divergence: 0.01116
SB3 Clip Fraction: 0.14545
Policy Update Magnitude: 0.40439
Value Function Update Magnitude: 0.50976

Collected Steps per Second: 22,830.15611
Overall Steps per Second: 10,687.56253

Timestep Collection Time: 2.19087
Timestep Consumption Time: 2.48915
PPO Batch Consumption Time: 0.29186
Total Iteration Time: 4.68002

Cumulative Model Updates: 199,052
Cumulative Timesteps: 1,659,895,870

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,697.86881
Policy Entropy: 3.72174
Value Function Loss: 0.01281

Mean KL Divergence: 0.01145
SB3 Clip Fraction: 0.14941
Policy Update Magnitude: 0.35460
Value Function Update Magnitude: 0.43463

Collected Steps per Second: 22,960.56192
Overall Steps per Second: 10,892.29110

Timestep Collection Time: 2.17834
Timestep Consumption Time: 2.41353
PPO Batch Consumption Time: 0.27634
Total Iteration Time: 4.59187

Cumulative Model Updates: 199,058
Cumulative Timesteps: 1,659,945,886

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1659945886...
Checkpoint 1659945886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 87,697.86881
Policy Entropy: 3.72764
Value Function Loss: 0.01181

Mean KL Divergence: 0.01177
SB3 Clip Fraction: 0.15279
Policy Update Magnitude: 0.33073
Value Function Update Magnitude: 0.37755

Collected Steps per Second: 22,311.32871
Overall Steps per Second: 10,577.74098

Timestep Collection Time: 2.24101
Timestep Consumption Time: 2.48589
PPO Batch Consumption Time: 0.28897
Total Iteration Time: 4.72691

Cumulative Model Updates: 199,064
Cumulative Timesteps: 1,659,995,886

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 87,697.86881
Policy Entropy: 3.68900
Value Function Loss: 0.01509

Mean KL Divergence: 0.01261
SB3 Clip Fraction: 0.15598
Policy Update Magnitude: 0.32361
Value Function Update Magnitude: 0.50710

Collected Steps per Second: 22,943.45780
Overall Steps per Second: 10,862.32114

Timestep Collection Time: 2.18067
Timestep Consumption Time: 2.42535
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.60601

Cumulative Model Updates: 199,070
Cumulative Timesteps: 1,660,045,918

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1660045918...
Checkpoint 1660045918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,961.98125
Policy Entropy: 3.70795
Value Function Loss: 0.01609

Mean KL Divergence: 0.01210
SB3 Clip Fraction: 0.15670
Policy Update Magnitude: 0.40240
Value Function Update Magnitude: 0.71795

Collected Steps per Second: 21,736.01058
Overall Steps per Second: 10,612.23130

Timestep Collection Time: 2.30153
Timestep Consumption Time: 2.41247
PPO Batch Consumption Time: 0.27711
Total Iteration Time: 4.71399

Cumulative Model Updates: 199,076
Cumulative Timesteps: 1,660,095,944

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 82,961.98125
Policy Entropy: 3.69109
Value Function Loss: 0.01883

Mean KL Divergence: 0.01519
SB3 Clip Fraction: 0.18777
Policy Update Magnitude: 0.39608
Value Function Update Magnitude: 0.69425

Collected Steps per Second: 22,275.43770
Overall Steps per Second: 10,559.41105

Timestep Collection Time: 2.24525
Timestep Consumption Time: 2.49119
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.73644

Cumulative Model Updates: 199,082
Cumulative Timesteps: 1,660,145,958

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1660145958...
Checkpoint 1660145958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 82,961.98125
Policy Entropy: 3.69142
Value Function Loss: 0.02267

Mean KL Divergence: 0.01401
SB3 Clip Fraction: 0.17525
Policy Update Magnitude: 0.42223
Value Function Update Magnitude: 0.53253

Collected Steps per Second: 22,016.00869
Overall Steps per Second: 10,682.85442

Timestep Collection Time: 2.27153
Timestep Consumption Time: 2.40980
PPO Batch Consumption Time: 0.27618
Total Iteration Time: 4.68133

Cumulative Model Updates: 199,088
Cumulative Timesteps: 1,660,195,968

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302,375.77609
Policy Entropy: 3.68248
Value Function Loss: 0.03308

Mean KL Divergence: 0.01192
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.55051
Value Function Update Magnitude: 0.36740

Collected Steps per Second: 22,401.20457
Overall Steps per Second: 10,753.19645

Timestep Collection Time: 2.23309
Timestep Consumption Time: 2.41892
PPO Batch Consumption Time: 0.27863
Total Iteration Time: 4.65201

Cumulative Model Updates: 199,094
Cumulative Timesteps: 1,660,245,992

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1660245992...
Checkpoint 1660245992 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262,390.45323
Policy Entropy: 3.67859
Value Function Loss: 0.03175

Mean KL Divergence: 0.01263
SB3 Clip Fraction: 0.16409
Policy Update Magnitude: 0.57031
Value Function Update Magnitude: 0.43786

Collected Steps per Second: 21,256.75607
Overall Steps per Second: 10,625.39319

Timestep Collection Time: 2.35248
Timestep Consumption Time: 2.35380
PPO Batch Consumption Time: 0.27895
Total Iteration Time: 4.70627

Cumulative Model Updates: 199,100
Cumulative Timesteps: 1,660,295,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 262,390.45323
Policy Entropy: 3.69813
Value Function Loss: 0.02862

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14609
Policy Update Magnitude: 0.56456
Value Function Update Magnitude: 0.46376

Collected Steps per Second: 22,178.68720
Overall Steps per Second: 10,569.21782

Timestep Collection Time: 2.25586
Timestep Consumption Time: 2.47789
PPO Batch Consumption Time: 0.29283
Total Iteration Time: 4.73375

Cumulative Model Updates: 199,106
Cumulative Timesteps: 1,660,346,030

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1660346030...
Checkpoint 1660346030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 262,390.45323
Policy Entropy: 3.68423
Value Function Loss: 0.02453

Mean KL Divergence: 0.00962
SB3 Clip Fraction: 0.12504
Policy Update Magnitude: 0.51281
Value Function Update Magnitude: 0.41528

Collected Steps per Second: 21,771.11204
Overall Steps per Second: 10,591.63082

Timestep Collection Time: 2.29745
Timestep Consumption Time: 2.42496
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.72241

Cumulative Model Updates: 199,112
Cumulative Timesteps: 1,660,396,048

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,978.63964
Policy Entropy: 3.70427
Value Function Loss: 0.01893

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.14950
Policy Update Magnitude: 0.48166
Value Function Update Magnitude: 0.37958

Collected Steps per Second: 22,457.94783
Overall Steps per Second: 10,679.56667

Timestep Collection Time: 2.22638
Timestep Consumption Time: 2.45545
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.68184

Cumulative Model Updates: 199,118
Cumulative Timesteps: 1,660,446,048

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1660446048...
Checkpoint 1660446048 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,978.63964
Policy Entropy: 3.70368
Value Function Loss: 0.02259

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13659
Policy Update Magnitude: 0.39093
Value Function Update Magnitude: 0.37408

Collected Steps per Second: 22,696.11989
Overall Steps per Second: 10,859.17159

Timestep Collection Time: 2.20372
Timestep Consumption Time: 2.40215
PPO Batch Consumption Time: 0.27855
Total Iteration Time: 4.60588

Cumulative Model Updates: 199,124
Cumulative Timesteps: 1,660,496,064

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,978.63964
Policy Entropy: 3.72198
Value Function Loss: 0.01835

Mean KL Divergence: 0.00814
SB3 Clip Fraction: 0.10387
Policy Update Magnitude: 0.35178
Value Function Update Magnitude: 0.27826

Collected Steps per Second: 23,020.95530
Overall Steps per Second: 10,895.66856

Timestep Collection Time: 2.17306
Timestep Consumption Time: 2.41830
PPO Batch Consumption Time: 0.27710
Total Iteration Time: 4.59137

Cumulative Model Updates: 199,130
Cumulative Timesteps: 1,660,546,090

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1660546090...
Checkpoint 1660546090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,978.63964
Policy Entropy: 3.72250
Value Function Loss: 0.01535

Mean KL Divergence: 0.00661
SB3 Clip Fraction: 0.08428
Policy Update Magnitude: 0.37627
Value Function Update Magnitude: 0.28134

Collected Steps per Second: 22,262.09632
Overall Steps per Second: 10,738.56549

Timestep Collection Time: 2.24741
Timestep Consumption Time: 2.41169
PPO Batch Consumption Time: 0.27626
Total Iteration Time: 4.65910

Cumulative Model Updates: 199,136
Cumulative Timesteps: 1,660,596,122

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,978.63964
Policy Entropy: 3.73047
Value Function Loss: 0.01252

Mean KL Divergence: 0.00658
SB3 Clip Fraction: 0.08250
Policy Update Magnitude: 0.39783
Value Function Update Magnitude: 0.28240

Collected Steps per Second: 22,666.67470
Overall Steps per Second: 10,802.26148

Timestep Collection Time: 2.20721
Timestep Consumption Time: 2.42423
PPO Batch Consumption Time: 0.27776
Total Iteration Time: 4.63144

Cumulative Model Updates: 199,142
Cumulative Timesteps: 1,660,646,152

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1660646152...
Checkpoint 1660646152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,978.63964
Policy Entropy: 3.75393
Value Function Loss: 0.00944

Mean KL Divergence: 0.00884
SB3 Clip Fraction: 0.11804
Policy Update Magnitude: 0.33095
Value Function Update Magnitude: 0.25535

Collected Steps per Second: 21,208.49307
Overall Steps per Second: 10,281.44970

Timestep Collection Time: 2.35783
Timestep Consumption Time: 2.50588
PPO Batch Consumption Time: 0.29241
Total Iteration Time: 4.86371

Cumulative Model Updates: 199,148
Cumulative Timesteps: 1,660,696,158

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,978.63964
Policy Entropy: 3.73698
Value Function Loss: 0.01048

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.08152
Policy Update Magnitude: 0.30792
Value Function Update Magnitude: 0.26262

Collected Steps per Second: 22,592.96647
Overall Steps per Second: 10,683.85039

Timestep Collection Time: 2.21334
Timestep Consumption Time: 2.46718
PPO Batch Consumption Time: 0.28512
Total Iteration Time: 4.68052

Cumulative Model Updates: 199,154
Cumulative Timesteps: 1,660,746,164

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1660746164...
Checkpoint 1660746164 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 220,992.33844
Policy Entropy: 3.73126
Value Function Loss: 0.01196

Mean KL Divergence: 0.00662
SB3 Clip Fraction: 0.08596
Policy Update Magnitude: 0.44345
Value Function Update Magnitude: 0.44508

Collected Steps per Second: 21,771.75299
Overall Steps per Second: 10,435.43300

Timestep Collection Time: 2.29802
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.28998
Total Iteration Time: 4.79443

Cumulative Model Updates: 199,160
Cumulative Timesteps: 1,660,796,196

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,003.44539
Policy Entropy: 3.73270
Value Function Loss: 0.01270

Mean KL Divergence: 0.00569
SB3 Clip Fraction: 0.06805
Policy Update Magnitude: 0.50383
Value Function Update Magnitude: 0.58181

Collected Steps per Second: 22,682.27389
Overall Steps per Second: 10,784.23985

Timestep Collection Time: 2.20516
Timestep Consumption Time: 2.43291
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.63806

Cumulative Model Updates: 199,166
Cumulative Timesteps: 1,660,846,214

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1660846214...
Checkpoint 1660846214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,003.44539
Policy Entropy: 3.74193
Value Function Loss: 0.01109

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07483
Policy Update Magnitude: 0.48327
Value Function Update Magnitude: 0.60680

Collected Steps per Second: 21,919.18474
Overall Steps per Second: 10,732.11864

Timestep Collection Time: 2.28330
Timestep Consumption Time: 2.38009
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.66338

Cumulative Model Updates: 199,172
Cumulative Timesteps: 1,660,896,262

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 179,003.44539
Policy Entropy: 3.72286
Value Function Loss: 0.01147

Mean KL Divergence: 0.00752
SB3 Clip Fraction: 0.09639
Policy Update Magnitude: 0.40532
Value Function Update Magnitude: 0.50569

Collected Steps per Second: 22,057.53926
Overall Steps per Second: 10,819.34808

Timestep Collection Time: 2.26725
Timestep Consumption Time: 2.35502
PPO Batch Consumption Time: 0.27791
Total Iteration Time: 4.62227

Cumulative Model Updates: 199,178
Cumulative Timesteps: 1,660,946,272

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1660946272...
Checkpoint 1660946272 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 179,003.44539
Policy Entropy: 3.70374
Value Function Loss: 0.01223

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.16407
Policy Update Magnitude: 0.36073
Value Function Update Magnitude: 0.43526

Collected Steps per Second: 21,643.38572
Overall Steps per Second: 10,485.57818

Timestep Collection Time: 2.31147
Timestep Consumption Time: 2.45966
PPO Batch Consumption Time: 0.28816
Total Iteration Time: 4.77112

Cumulative Model Updates: 199,184
Cumulative Timesteps: 1,660,996,300

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 483,563.89743
Policy Entropy: 3.69019
Value Function Loss: 0.01535

Mean KL Divergence: 0.01481
SB3 Clip Fraction: 0.17761
Policy Update Magnitude: 0.36894
Value Function Update Magnitude: 0.47700

Collected Steps per Second: 23,144.07022
Overall Steps per Second: 10,767.20326

Timestep Collection Time: 2.16159
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.29247
Total Iteration Time: 4.64633

Cumulative Model Updates: 199,190
Cumulative Timesteps: 1,661,046,328

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1661046328...
Checkpoint 1661046328 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 335,012.87925
Policy Entropy: 3.69554
Value Function Loss: 0.01842

Mean KL Divergence: 0.01435
SB3 Clip Fraction: 0.17452
Policy Update Magnitude: 0.43773
Value Function Update Magnitude: 0.60177

Collected Steps per Second: 22,406.28788
Overall Steps per Second: 10,616.51459

Timestep Collection Time: 2.23277
Timestep Consumption Time: 2.47951
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.71228

Cumulative Model Updates: 199,196
Cumulative Timesteps: 1,661,096,356

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 524,555.73658
Policy Entropy: 3.71478
Value Function Loss: 0.02551

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.14513
Policy Update Magnitude: 0.54790
Value Function Update Magnitude: 0.55476

Collected Steps per Second: 22,500.16878
Overall Steps per Second: 10,640.43141

Timestep Collection Time: 2.22336
Timestep Consumption Time: 2.47814
PPO Batch Consumption Time: 0.28704
Total Iteration Time: 4.70150

Cumulative Model Updates: 199,202
Cumulative Timesteps: 1,661,146,382

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1661146382...
Checkpoint 1661146382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 615,406.84922
Policy Entropy: 3.69160
Value Function Loss: 0.03371

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15626
Policy Update Magnitude: 0.62269
Value Function Update Magnitude: 0.42797

Collected Steps per Second: 21,974.76303
Overall Steps per Second: 10,452.30088

Timestep Collection Time: 2.27607
Timestep Consumption Time: 2.50910
PPO Batch Consumption Time: 0.29238
Total Iteration Time: 4.78517

Cumulative Model Updates: 199,208
Cumulative Timesteps: 1,661,196,398

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,970.43611
Policy Entropy: 3.69092
Value Function Loss: 0.03444

Mean KL Divergence: 0.01458
SB3 Clip Fraction: 0.17680
Policy Update Magnitude: 0.66028
Value Function Update Magnitude: 0.41644

Collected Steps per Second: 22,113.91718
Overall Steps per Second: 10,492.55563

Timestep Collection Time: 2.26192
Timestep Consumption Time: 2.50527
PPO Batch Consumption Time: 0.29155
Total Iteration Time: 4.76719

Cumulative Model Updates: 199,214
Cumulative Timesteps: 1,661,246,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1661246418...
Checkpoint 1661246418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,081.72101
Policy Entropy: 3.69488
Value Function Loss: 0.03537

Mean KL Divergence: 0.01335
SB3 Clip Fraction: 0.15650
Policy Update Magnitude: 0.72392
Value Function Update Magnitude: 0.51122

Collected Steps per Second: 21,953.01595
Overall Steps per Second: 10,643.64534

Timestep Collection Time: 2.27796
Timestep Consumption Time: 2.42043
PPO Batch Consumption Time: 0.27660
Total Iteration Time: 4.69839

Cumulative Model Updates: 199,220
Cumulative Timesteps: 1,661,296,426

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 137,312.88305
Policy Entropy: 3.66442
Value Function Loss: 0.04019

Mean KL Divergence: 0.03396
SB3 Clip Fraction: 0.28987
Policy Update Magnitude: 0.62716
Value Function Update Magnitude: 0.49833

Collected Steps per Second: 22,359.92049
Overall Steps per Second: 10,527.00963

Timestep Collection Time: 2.23632
Timestep Consumption Time: 2.51374
PPO Batch Consumption Time: 0.28969
Total Iteration Time: 4.75007

Cumulative Model Updates: 199,226
Cumulative Timesteps: 1,661,346,430

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1661346430...
Checkpoint 1661346430 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 638,432.91954
Policy Entropy: 3.71639
Value Function Loss: 0.06948

Mean KL Divergence: 0.01816
SB3 Clip Fraction: 0.20032
Policy Update Magnitude: 0.63554
Value Function Update Magnitude: 0.51513

Collected Steps per Second: 22,044.29165
Overall Steps per Second: 10,528.45060

Timestep Collection Time: 2.26925
Timestep Consumption Time: 2.48207
PPO Batch Consumption Time: 0.28281
Total Iteration Time: 4.75132

Cumulative Model Updates: 199,232
Cumulative Timesteps: 1,661,396,454

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 274,068.22955
Policy Entropy: 3.69908
Value Function Loss: 0.07846

Mean KL Divergence: 0.01318
SB3 Clip Fraction: 0.15666
Policy Update Magnitude: 0.82214
Value Function Update Magnitude: 0.48138

Collected Steps per Second: 22,268.37655
Overall Steps per Second: 10,564.57855

Timestep Collection Time: 2.24561
Timestep Consumption Time: 2.48776
PPO Batch Consumption Time: 0.29073
Total Iteration Time: 4.73336

Cumulative Model Updates: 199,238
Cumulative Timesteps: 1,661,446,460

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1661446460...
Checkpoint 1661446460 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,878.89298
Policy Entropy: 3.69952
Value Function Loss: 0.06896

Mean KL Divergence: 0.01293
SB3 Clip Fraction: 0.15908
Policy Update Magnitude: 0.78643
Value Function Update Magnitude: 0.47824

Collected Steps per Second: 22,317.81192
Overall Steps per Second: 10,563.37827

Timestep Collection Time: 2.24162
Timestep Consumption Time: 2.49437
PPO Batch Consumption Time: 0.29257
Total Iteration Time: 4.73598

Cumulative Model Updates: 199,244
Cumulative Timesteps: 1,661,496,488

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,016.98026
Policy Entropy: 3.71620
Value Function Loss: 0.04526

Mean KL Divergence: 0.01112
SB3 Clip Fraction: 0.14477
Policy Update Magnitude: 0.70483
Value Function Update Magnitude: 0.47342

Collected Steps per Second: 22,968.41457
Overall Steps per Second: 10,898.92180

Timestep Collection Time: 2.17777
Timestep Consumption Time: 2.41167
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.58944

Cumulative Model Updates: 199,250
Cumulative Timesteps: 1,661,546,508

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1661546508...
Checkpoint 1661546508 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,238.03933
Policy Entropy: 3.72255
Value Function Loss: 0.03055

Mean KL Divergence: 0.01062
SB3 Clip Fraction: 0.14238
Policy Update Magnitude: 0.62602
Value Function Update Magnitude: 0.44029

Collected Steps per Second: 21,654.96301
Overall Steps per Second: 10,655.16301

Timestep Collection Time: 2.30986
Timestep Consumption Time: 2.38457
PPO Batch Consumption Time: 0.28568
Total Iteration Time: 4.69444

Cumulative Model Updates: 199,256
Cumulative Timesteps: 1,661,596,528

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332,371.44089
Policy Entropy: 3.72303
Value Function Loss: 0.02644

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.13368
Policy Update Magnitude: 0.50975
Value Function Update Magnitude: 0.43654

Collected Steps per Second: 22,263.87922
Overall Steps per Second: 10,912.74187

Timestep Collection Time: 2.24687
Timestep Consumption Time: 2.33713
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.58400

Cumulative Model Updates: 199,262
Cumulative Timesteps: 1,661,646,552

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1661646552...
Checkpoint 1661646552 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269,216.27420
Policy Entropy: 3.71940
Value Function Loss: 0.02410

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12670
Policy Update Magnitude: 0.48237
Value Function Update Magnitude: 0.45549

Collected Steps per Second: 21,621.41788
Overall Steps per Second: 10,609.32209

Timestep Collection Time: 2.31345
Timestep Consumption Time: 2.40127
PPO Batch Consumption Time: 0.28800
Total Iteration Time: 4.71472

Cumulative Model Updates: 199,268
Cumulative Timesteps: 1,661,696,572

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 269,216.27420
Policy Entropy: 3.71305
Value Function Loss: 0.02267

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.12970
Policy Update Magnitude: 0.47417
Value Function Update Magnitude: 0.44912

Collected Steps per Second: 21,782.76160
Overall Steps per Second: 10,480.04667

Timestep Collection Time: 2.29558
Timestep Consumption Time: 2.47578
PPO Batch Consumption Time: 0.29114
Total Iteration Time: 4.77135

Cumulative Model Updates: 199,274
Cumulative Timesteps: 1,661,746,576

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1661746576...
Checkpoint 1661746576 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 269,216.27420
Policy Entropy: 3.71635
Value Function Loss: 0.01637

Mean KL Divergence: 0.00911
SB3 Clip Fraction: 0.12860
Policy Update Magnitude: 0.42616
Value Function Update Magnitude: 0.43889

Collected Steps per Second: 22,063.96273
Overall Steps per Second: 10,610.10433

Timestep Collection Time: 2.26732
Timestep Consumption Time: 2.44762
PPO Batch Consumption Time: 0.28682
Total Iteration Time: 4.71494

Cumulative Model Updates: 199,280
Cumulative Timesteps: 1,661,796,602

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,435.22581
Policy Entropy: 3.70830
Value Function Loss: 0.01676

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.13018
Policy Update Magnitude: 0.37543
Value Function Update Magnitude: 0.47422

Collected Steps per Second: 22,384.07295
Overall Steps per Second: 10,790.11346

Timestep Collection Time: 2.23427
Timestep Consumption Time: 2.40072
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.63498

Cumulative Model Updates: 199,286
Cumulative Timesteps: 1,661,846,614

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1661846614...
Checkpoint 1661846614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332,250.68600
Policy Entropy: 3.71261
Value Function Loss: 0.01830

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12612
Policy Update Magnitude: 0.41078
Value Function Update Magnitude: 0.53404

Collected Steps per Second: 21,994.64352
Overall Steps per Second: 10,487.87134

Timestep Collection Time: 2.27455
Timestep Consumption Time: 2.49553
PPO Batch Consumption Time: 0.28822
Total Iteration Time: 4.77008

Cumulative Model Updates: 199,292
Cumulative Timesteps: 1,661,896,642

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 332,250.68600
Policy Entropy: 3.70013
Value Function Loss: 0.02026

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12644
Policy Update Magnitude: 0.48287
Value Function Update Magnitude: 0.54949

Collected Steps per Second: 22,770.96041
Overall Steps per Second: 10,705.69465

Timestep Collection Time: 2.19762
Timestep Consumption Time: 2.47671
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.67433

Cumulative Model Updates: 199,298
Cumulative Timesteps: 1,661,946,684

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1661946684...
Checkpoint 1661946684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 332,250.68600
Policy Entropy: 3.71522
Value Function Loss: 0.02011

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11767
Policy Update Magnitude: 0.50112
Value Function Update Magnitude: 0.55329

Collected Steps per Second: 22,291.34608
Overall Steps per Second: 10,592.60430

Timestep Collection Time: 2.24383
Timestep Consumption Time: 2.47814
PPO Batch Consumption Time: 0.28479
Total Iteration Time: 4.72197

Cumulative Model Updates: 199,304
Cumulative Timesteps: 1,661,996,702

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,737.67771
Policy Entropy: 3.71754
Value Function Loss: 0.01938

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12581
Policy Update Magnitude: 0.50824
Value Function Update Magnitude: 0.49377

Collected Steps per Second: 22,729.42152
Overall Steps per Second: 10,690.80810

Timestep Collection Time: 2.20102
Timestep Consumption Time: 2.47851
PPO Batch Consumption Time: 0.28808
Total Iteration Time: 4.67953

Cumulative Model Updates: 199,310
Cumulative Timesteps: 1,662,046,730

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1662046730...
Checkpoint 1662046730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,737.67771
Policy Entropy: 3.72717
Value Function Loss: 0.01885

Mean KL Divergence: 0.00980
SB3 Clip Fraction: 0.13703
Policy Update Magnitude: 0.45958
Value Function Update Magnitude: 0.52872

Collected Steps per Second: 22,450.24085
Overall Steps per Second: 10,600.54344

Timestep Collection Time: 2.22777
Timestep Consumption Time: 2.49029
PPO Batch Consumption Time: 0.28965
Total Iteration Time: 4.71806

Cumulative Model Updates: 199,316
Cumulative Timesteps: 1,662,096,744

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,737.67771
Policy Entropy: 3.72569
Value Function Loss: 0.01625

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.13069
Policy Update Magnitude: 0.43745
Value Function Update Magnitude: 0.64133

Collected Steps per Second: 22,795.47700
Overall Steps per Second: 10,795.09995

Timestep Collection Time: 2.19394
Timestep Consumption Time: 2.43890
PPO Batch Consumption Time: 0.28200
Total Iteration Time: 4.63284

Cumulative Model Updates: 199,322
Cumulative Timesteps: 1,662,146,756

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1662146756...
Checkpoint 1662146756 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,737.67771
Policy Entropy: 3.71788
Value Function Loss: 0.01572

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13754
Policy Update Magnitude: 0.45485
Value Function Update Magnitude: 0.62099

Collected Steps per Second: 22,307.43526
Overall Steps per Second: 10,645.97304

Timestep Collection Time: 2.24230
Timestep Consumption Time: 2.45619
PPO Batch Consumption Time: 0.28659
Total Iteration Time: 4.69849

Cumulative Model Updates: 199,328
Cumulative Timesteps: 1,662,196,776

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,737.67771
Policy Entropy: 3.71607
Value Function Loss: 0.01352

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11513
Policy Update Magnitude: 0.44897
Value Function Update Magnitude: 0.53143

Collected Steps per Second: 22,295.72386
Overall Steps per Second: 10,572.40288

Timestep Collection Time: 2.24276
Timestep Consumption Time: 2.48691
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.72967

Cumulative Model Updates: 199,334
Cumulative Timesteps: 1,662,246,780

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1662246780...
Checkpoint 1662246780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 642,737.67771
Policy Entropy: 3.70961
Value Function Loss: 0.01519

Mean KL Divergence: 0.00947
SB3 Clip Fraction: 0.12627
Policy Update Magnitude: 0.42623
Value Function Update Magnitude: 0.48823

Collected Steps per Second: 21,520.60560
Overall Steps per Second: 10,538.78256

Timestep Collection Time: 2.32419
Timestep Consumption Time: 2.42190
PPO Batch Consumption Time: 0.29143
Total Iteration Time: 4.74609

Cumulative Model Updates: 199,340
Cumulative Timesteps: 1,662,296,798

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 642,737.67771
Policy Entropy: 3.71177
Value Function Loss: 0.01511

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13560
Policy Update Magnitude: 0.41351
Value Function Update Magnitude: 0.47473

Collected Steps per Second: 21,700.68967
Overall Steps per Second: 10,787.81747

Timestep Collection Time: 2.30417
Timestep Consumption Time: 2.33088
PPO Batch Consumption Time: 0.27647
Total Iteration Time: 4.63504

Cumulative Model Updates: 199,346
Cumulative Timesteps: 1,662,346,800

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1662346800...
Checkpoint 1662346800 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 815,924.75340
Policy Entropy: 3.71306
Value Function Loss: 0.01863

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14084
Policy Update Magnitude: 0.43986
Value Function Update Magnitude: 0.50248

Collected Steps per Second: 21,131.88716
Overall Steps per Second: 10,342.53519

Timestep Collection Time: 2.36780
Timestep Consumption Time: 2.47009
PPO Batch Consumption Time: 0.29165
Total Iteration Time: 4.83789

Cumulative Model Updates: 199,352
Cumulative Timesteps: 1,662,396,836

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 180,204.92899
Policy Entropy: 3.73284
Value Function Loss: 0.01961

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.07085
Policy Update Magnitude: 0.55080
Value Function Update Magnitude: 0.60419

Collected Steps per Second: 23,057.05929
Overall Steps per Second: 10,799.53239

Timestep Collection Time: 2.16966
Timestep Consumption Time: 2.46258
PPO Batch Consumption Time: 0.28276
Total Iteration Time: 4.63224

Cumulative Model Updates: 199,358
Cumulative Timesteps: 1,662,446,862

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1662446862...
Checkpoint 1662446862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 50,985.70818
Policy Entropy: 3.74078
Value Function Loss: 0.02005

Mean KL Divergence: 0.00535
SB3 Clip Fraction: 0.06225
Policy Update Magnitude: 0.62729
Value Function Update Magnitude: 0.62582

Collected Steps per Second: 22,341.19699
Overall Steps per Second: 10,657.07151

Timestep Collection Time: 2.23864
Timestep Consumption Time: 2.45439
PPO Batch Consumption Time: 0.28657
Total Iteration Time: 4.69303

Cumulative Model Updates: 199,364
Cumulative Timesteps: 1,662,496,876

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 22,426.32606
Policy Entropy: 3.74541
Value Function Loss: 0.01712

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05113
Policy Update Magnitude: 0.60701
Value Function Update Magnitude: 0.64585

Collected Steps per Second: 22,978.88248
Overall Steps per Second: 10,973.95881

Timestep Collection Time: 2.17696
Timestep Consumption Time: 2.38147
PPO Batch Consumption Time: 0.27619
Total Iteration Time: 4.55843

Cumulative Model Updates: 199,370
Cumulative Timesteps: 1,662,546,900

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1662546900...
Checkpoint 1662546900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,926.16584
Policy Entropy: 3.74028
Value Function Loss: 0.01487

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04726
Policy Update Magnitude: 0.54451
Value Function Update Magnitude: 0.64235

Collected Steps per Second: 21,049.83029
Overall Steps per Second: 10,313.52595

Timestep Collection Time: 2.37560
Timestep Consumption Time: 2.47298
PPO Batch Consumption Time: 0.28937
Total Iteration Time: 4.84858

Cumulative Model Updates: 199,376
Cumulative Timesteps: 1,662,596,906

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,926.16584
Policy Entropy: 3.73944
Value Function Loss: 0.01195

Mean KL Divergence: 0.00379
SB3 Clip Fraction: 0.03779
Policy Update Magnitude: 0.47327
Value Function Update Magnitude: 0.51382

Collected Steps per Second: 22,363.80280
Overall Steps per Second: 10,699.08733

Timestep Collection Time: 2.23629
Timestep Consumption Time: 2.43813
PPO Batch Consumption Time: 0.27833
Total Iteration Time: 4.67442

Cumulative Model Updates: 199,382
Cumulative Timesteps: 1,662,646,918

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1662646918...
Checkpoint 1662646918 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,926.16584
Policy Entropy: 3.73793
Value Function Loss: 0.01115

Mean KL Divergence: 0.00431
SB3 Clip Fraction: 0.04652
Policy Update Magnitude: 0.45577
Value Function Update Magnitude: 0.40542

Collected Steps per Second: 21,733.03129
Overall Steps per Second: 10,589.24030

Timestep Collection Time: 2.30111
Timestep Consumption Time: 2.42161
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.72272

Cumulative Model Updates: 199,388
Cumulative Timesteps: 1,662,696,928

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 11,926.16584
Policy Entropy: 3.74478
Value Function Loss: 0.00949

Mean KL Divergence: 0.00482
SB3 Clip Fraction: 0.05302
Policy Update Magnitude: 0.43235
Value Function Update Magnitude: 0.37554

Collected Steps per Second: 22,269.18518
Overall Steps per Second: 10,555.52241

Timestep Collection Time: 2.24588
Timestep Consumption Time: 2.49230
PPO Batch Consumption Time: 0.28870
Total Iteration Time: 4.73818

Cumulative Model Updates: 199,394
Cumulative Timesteps: 1,662,746,942

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1662746942...
Checkpoint 1662746942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 579,072.58497
Policy Entropy: 3.74281
Value Function Loss: 0.01092

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04650
Policy Update Magnitude: 0.42164
Value Function Update Magnitude: 0.36315

Collected Steps per Second: 22,543.03957
Overall Steps per Second: 10,642.52750

Timestep Collection Time: 2.21975
Timestep Consumption Time: 2.48214
PPO Batch Consumption Time: 0.28272
Total Iteration Time: 4.70189

Cumulative Model Updates: 199,400
Cumulative Timesteps: 1,662,796,982

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,287.02353
Policy Entropy: 3.74664
Value Function Loss: 0.01210

Mean KL Divergence: 0.00412
SB3 Clip Fraction: 0.04373
Policy Update Magnitude: 0.46870
Value Function Update Magnitude: 0.43216

Collected Steps per Second: 23,004.60354
Overall Steps per Second: 10,879.41369

Timestep Collection Time: 2.17478
Timestep Consumption Time: 2.42381
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.59859

Cumulative Model Updates: 199,406
Cumulative Timesteps: 1,662,847,012

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1662847012...
Checkpoint 1662847012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,287.02353
Policy Entropy: 3.73253
Value Function Loss: 0.01402

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05540
Policy Update Magnitude: 0.54329
Value Function Update Magnitude: 0.49567

Collected Steps per Second: 21,523.28447
Overall Steps per Second: 10,654.70654

Timestep Collection Time: 2.32381
Timestep Consumption Time: 2.37045
PPO Batch Consumption Time: 0.28065
Total Iteration Time: 4.69426

Cumulative Model Updates: 199,412
Cumulative Timesteps: 1,662,897,028

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,287.02353
Policy Entropy: 3.72289
Value Function Loss: 0.01420

Mean KL Divergence: 0.00556
SB3 Clip Fraction: 0.06432
Policy Update Magnitude: 0.57636
Value Function Update Magnitude: 0.46588

Collected Steps per Second: 22,276.31862
Overall Steps per Second: 10,906.42351

Timestep Collection Time: 2.24570
Timestep Consumption Time: 2.34114
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.58684

Cumulative Model Updates: 199,418
Cumulative Timesteps: 1,662,947,054

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1662947054...
Checkpoint 1662947054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 249,287.02353
Policy Entropy: 3.72625
Value Function Loss: 0.01297

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05309
Policy Update Magnitude: 0.54733
Value Function Update Magnitude: 0.37635

Collected Steps per Second: 21,741.20275
Overall Steps per Second: 10,630.19777

Timestep Collection Time: 2.30052
Timestep Consumption Time: 2.40457
PPO Batch Consumption Time: 0.27810
Total Iteration Time: 4.70509

Cumulative Model Updates: 199,424
Cumulative Timesteps: 1,662,997,070

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,287.02353
Policy Entropy: 3.74314
Value Function Loss: 0.01176

Mean KL Divergence: 0.00459
SB3 Clip Fraction: 0.05039
Policy Update Magnitude: 0.48211
Value Function Update Magnitude: 0.31019

Collected Steps per Second: 22,893.29450
Overall Steps per Second: 10,901.18046

Timestep Collection Time: 2.18413
Timestep Consumption Time: 2.40271
PPO Batch Consumption Time: 0.27728
Total Iteration Time: 4.58684

Cumulative Model Updates: 199,430
Cumulative Timesteps: 1,663,047,072

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1663047072...
Checkpoint 1663047072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,688.49213
Policy Entropy: 3.74796
Value Function Loss: 0.01161

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.04977
Policy Update Magnitude: 0.45396
Value Function Update Magnitude: 0.31498

Collected Steps per Second: 22,365.28223
Overall Steps per Second: 10,675.94902

Timestep Collection Time: 2.23588
Timestep Consumption Time: 2.44811
PPO Batch Consumption Time: 0.28575
Total Iteration Time: 4.68399

Cumulative Model Updates: 199,436
Cumulative Timesteps: 1,663,097,078

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 455,688.49213
Policy Entropy: 3.74444
Value Function Loss: 0.01181

Mean KL Divergence: 0.00444
SB3 Clip Fraction: 0.04766
Policy Update Magnitude: 0.47797
Value Function Update Magnitude: 0.41329

Collected Steps per Second: 22,108.57447
Overall Steps per Second: 10,491.72304

Timestep Collection Time: 2.26347
Timestep Consumption Time: 2.50620
PPO Batch Consumption Time: 0.29181
Total Iteration Time: 4.76966

Cumulative Model Updates: 199,442
Cumulative Timesteps: 1,663,147,120

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1663147120...
Checkpoint 1663147120 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455,688.49213
Policy Entropy: 3.72600
Value Function Loss: 0.01219

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.04923
Policy Update Magnitude: 0.49640
Value Function Update Magnitude: 0.49027

Collected Steps per Second: 22,009.39445
Overall Steps per Second: 10,673.62373

Timestep Collection Time: 2.27294
Timestep Consumption Time: 2.41394
PPO Batch Consumption Time: 0.27587
Total Iteration Time: 4.68688

Cumulative Model Updates: 199,448
Cumulative Timesteps: 1,663,197,146

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,031.35942
Policy Entropy: 3.72828
Value Function Loss: 0.01222

Mean KL Divergence: 0.00620
SB3 Clip Fraction: 0.07599
Policy Update Magnitude: 0.49497
Value Function Update Magnitude: 0.49758

Collected Steps per Second: 22,727.38530
Overall Steps per Second: 10,788.43963

Timestep Collection Time: 2.20061
Timestep Consumption Time: 2.43528
PPO Batch Consumption Time: 0.27775
Total Iteration Time: 4.63589

Cumulative Model Updates: 199,454
Cumulative Timesteps: 1,663,247,160

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1663247160...
Checkpoint 1663247160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,031.35942
Policy Entropy: 3.72160
Value Function Loss: 0.01157

Mean KL Divergence: 0.00532
SB3 Clip Fraction: 0.05922
Policy Update Magnitude: 0.43119
Value Function Update Magnitude: 0.44094

Collected Steps per Second: 22,517.68301
Overall Steps per Second: 10,671.24358

Timestep Collection Time: 2.22083
Timestep Consumption Time: 2.46541
PPO Batch Consumption Time: 0.27774
Total Iteration Time: 4.68624

Cumulative Model Updates: 199,460
Cumulative Timesteps: 1,663,297,168

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,031.35942
Policy Entropy: 3.72896
Value Function Loss: 0.01292

Mean KL Divergence: 0.00368
SB3 Clip Fraction: 0.03653
Policy Update Magnitude: 0.48921
Value Function Update Magnitude: 0.44940

Collected Steps per Second: 22,809.21537
Overall Steps per Second: 10,837.59250

Timestep Collection Time: 2.19236
Timestep Consumption Time: 2.42176
PPO Batch Consumption Time: 0.27719
Total Iteration Time: 4.61412

Cumulative Model Updates: 199,466
Cumulative Timesteps: 1,663,347,174

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1663347174...
Checkpoint 1663347174 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 424,485.69949
Policy Entropy: 3.73185
Value Function Loss: 0.01362

Mean KL Divergence: 0.00515
SB3 Clip Fraction: 0.05927
Policy Update Magnitude: 0.52047
Value Function Update Magnitude: 0.55997

Collected Steps per Second: 22,314.48083
Overall Steps per Second: 10,749.28438

Timestep Collection Time: 2.24186
Timestep Consumption Time: 2.41203
PPO Batch Consumption Time: 0.27733
Total Iteration Time: 4.65389

Cumulative Model Updates: 199,472
Cumulative Timesteps: 1,663,397,200

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343,839.74612
Policy Entropy: 3.73530
Value Function Loss: 0.01508

Mean KL Divergence: 0.00585
SB3 Clip Fraction: 0.06969
Policy Update Magnitude: 0.52306
Value Function Update Magnitude: 0.61862

Collected Steps per Second: 22,993.63718
Overall Steps per Second: 10,857.83046

Timestep Collection Time: 2.17591
Timestep Consumption Time: 2.43201
PPO Batch Consumption Time: 0.27876
Total Iteration Time: 4.60792

Cumulative Model Updates: 199,478
Cumulative Timesteps: 1,663,447,232

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1663447232...
Checkpoint 1663447232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 343,839.74612
Policy Entropy: 3.73524
Value Function Loss: 0.01316

Mean KL Divergence: 0.00670
SB3 Clip Fraction: 0.08530
Policy Update Magnitude: 0.48228
Value Function Update Magnitude: 0.56400

Collected Steps per Second: 22,608.08422
Overall Steps per Second: 10,638.43910

Timestep Collection Time: 2.21178
Timestep Consumption Time: 2.48854
PPO Batch Consumption Time: 0.28749
Total Iteration Time: 4.70031

Cumulative Model Updates: 199,484
Cumulative Timesteps: 1,663,497,236

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 343,839.74612
Policy Entropy: 3.71458
Value Function Loss: 0.01206

Mean KL Divergence: 0.00689
SB3 Clip Fraction: 0.08780
Policy Update Magnitude: 0.46193
Value Function Update Magnitude: 0.47533

Collected Steps per Second: 22,549.46974
Overall Steps per Second: 10,607.42257

Timestep Collection Time: 2.21939
Timestep Consumption Time: 2.49863
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.71802

Cumulative Model Updates: 199,490
Cumulative Timesteps: 1,663,547,282

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1663547282...
Checkpoint 1663547282 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,011,039.75144
Policy Entropy: 3.72598
Value Function Loss: 0.01253

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07559
Policy Update Magnitude: 0.50232
Value Function Update Magnitude: 0.48023

Collected Steps per Second: 22,435.02678
Overall Steps per Second: 10,597.61136

Timestep Collection Time: 2.22901
Timestep Consumption Time: 2.48978
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.71880

Cumulative Model Updates: 199,496
Cumulative Timesteps: 1,663,597,290

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960,594.31144
Policy Entropy: 3.70207
Value Function Loss: 0.01608

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.07628
Policy Update Magnitude: 0.56241
Value Function Update Magnitude: 0.56142

Collected Steps per Second: 22,123.08249
Overall Steps per Second: 10,553.00315

Timestep Collection Time: 2.26063
Timestep Consumption Time: 2.47850
PPO Batch Consumption Time: 0.28904
Total Iteration Time: 4.73912

Cumulative Model Updates: 199,502
Cumulative Timesteps: 1,663,647,302

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1663647302...
Checkpoint 1663647302 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 960,594.31144
Policy Entropy: 3.72213
Value Function Loss: 0.01496

Mean KL Divergence: 0.00571
SB3 Clip Fraction: 0.06566
Policy Update Magnitude: 0.59814
Value Function Update Magnitude: 0.56218

Collected Steps per Second: 22,316.06361
Overall Steps per Second: 10,556.79070

Timestep Collection Time: 2.24090
Timestep Consumption Time: 2.49615
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.73705

Cumulative Model Updates: 199,508
Cumulative Timesteps: 1,663,697,310

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 960,594.31144
Policy Entropy: 3.71939
Value Function Loss: 0.01475

Mean KL Divergence: 0.00494
SB3 Clip Fraction: 0.05387
Policy Update Magnitude: 0.56563
Value Function Update Magnitude: 0.49893

Collected Steps per Second: 22,196.17931
Overall Steps per Second: 10,575.55797

Timestep Collection Time: 2.25363
Timestep Consumption Time: 2.47633
PPO Batch Consumption Time: 0.28769
Total Iteration Time: 4.72996

Cumulative Model Updates: 199,514
Cumulative Timesteps: 1,663,747,332

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1663747332...
Checkpoint 1663747332 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 940,457.90053
Policy Entropy: 3.72502
Value Function Loss: 0.01555

Mean KL Divergence: 0.00572
SB3 Clip Fraction: 0.06742
Policy Update Magnitude: 0.59428
Value Function Update Magnitude: 0.53258

Collected Steps per Second: 22,295.82850
Overall Steps per Second: 10,591.15418

Timestep Collection Time: 2.24356
Timestep Consumption Time: 2.47944
PPO Batch Consumption Time: 0.28995
Total Iteration Time: 4.72300

Cumulative Model Updates: 199,520
Cumulative Timesteps: 1,663,797,354

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 327,927.20596
Policy Entropy: 3.72500
Value Function Loss: 0.01600

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09133
Policy Update Magnitude: 0.60374
Value Function Update Magnitude: 0.64930

Collected Steps per Second: 22,714.54634
Overall Steps per Second: 10,711.95956

Timestep Collection Time: 2.20176
Timestep Consumption Time: 2.46704
PPO Batch Consumption Time: 0.27866
Total Iteration Time: 4.66880

Cumulative Model Updates: 199,526
Cumulative Timesteps: 1,663,847,366

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1663847366...
Checkpoint 1663847366 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206,076.79542
Policy Entropy: 3.73712
Value Function Loss: 0.01745

Mean KL Divergence: 0.00645
SB3 Clip Fraction: 0.07726
Policy Update Magnitude: 0.53155
Value Function Update Magnitude: 0.65612

Collected Steps per Second: 22,343.22307
Overall Steps per Second: 10,667.77376

Timestep Collection Time: 2.23844
Timestep Consumption Time: 2.44988
PPO Batch Consumption Time: 0.27814
Total Iteration Time: 4.68833

Cumulative Model Updates: 199,532
Cumulative Timesteps: 1,663,897,380

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 206,076.79542
Policy Entropy: 3.73805
Value Function Loss: 0.01438

Mean KL Divergence: 0.01113
SB3 Clip Fraction: 0.15380
Policy Update Magnitude: 0.44103
Value Function Update Magnitude: 0.55536

Collected Steps per Second: 22,010.11585
Overall Steps per Second: 10,814.24591

Timestep Collection Time: 2.27259
Timestep Consumption Time: 2.35279
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.62538

Cumulative Model Updates: 199,538
Cumulative Timesteps: 1,663,947,400

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1663947400...
Checkpoint 1663947400 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 206,076.79542
Policy Entropy: 3.72243
Value Function Loss: 0.01402

Mean KL Divergence: 0.01147
SB3 Clip Fraction: 0.15257
Policy Update Magnitude: 0.37301
Value Function Update Magnitude: 0.45565

Collected Steps per Second: 21,615.34294
Overall Steps per Second: 10,719.93245

Timestep Collection Time: 2.31345
Timestep Consumption Time: 2.35132
PPO Batch Consumption Time: 0.27874
Total Iteration Time: 4.66477

Cumulative Model Updates: 199,544
Cumulative Timesteps: 1,663,997,406

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 328,251.61685
Policy Entropy: 3.72938
Value Function Loss: 0.01308

Mean KL Divergence: 0.02723
SB3 Clip Fraction: 0.28336
Policy Update Magnitude: 0.35311
Value Function Update Magnitude: 0.40883

Collected Steps per Second: 22,245.50817
Overall Steps per Second: 10,882.73608

Timestep Collection Time: 2.24818
Timestep Consumption Time: 2.34735
PPO Batch Consumption Time: 0.27848
Total Iteration Time: 4.59554

Cumulative Model Updates: 199,550
Cumulative Timesteps: 1,664,047,418

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1664047418...
Checkpoint 1664047418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 265,884.49924
Policy Entropy: 3.72993
Value Function Loss: 0.01469

Mean KL Divergence: 0.03334
SB3 Clip Fraction: 0.33048
Policy Update Magnitude: 0.27248
Value Function Update Magnitude: 0.46507

Collected Steps per Second: 21,897.87158
Overall Steps per Second: 10,676.44696

Timestep Collection Time: 2.28378
Timestep Consumption Time: 2.40036
PPO Batch Consumption Time: 0.27831
Total Iteration Time: 4.68414

Cumulative Model Updates: 199,556
Cumulative Timesteps: 1,664,097,428

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 527,630.53983
Policy Entropy: 3.70545
Value Function Loss: 0.02496

Mean KL Divergence: 0.01617
SB3 Clip Fraction: 0.19913
Policy Update Magnitude: 0.42748
Value Function Update Magnitude: 0.58174

Collected Steps per Second: 21,996.51463
Overall Steps per Second: 10,468.03489

Timestep Collection Time: 2.27391
Timestep Consumption Time: 2.50426
PPO Batch Consumption Time: 0.29310
Total Iteration Time: 4.77817

Cumulative Model Updates: 199,562
Cumulative Timesteps: 1,664,147,446

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1664147446...
Checkpoint 1664147446 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 120,729.38984
Policy Entropy: 3.69951
Value Function Loss: 0.02964

Mean KL Divergence: 0.01574
SB3 Clip Fraction: 0.19472
Policy Update Magnitude: 0.58184
Value Function Update Magnitude: 0.61799

Collected Steps per Second: 22,058.35359
Overall Steps per Second: 10,666.01057

Timestep Collection Time: 2.26717
Timestep Consumption Time: 2.42156
PPO Batch Consumption Time: 0.28306
Total Iteration Time: 4.68873

Cumulative Model Updates: 199,568
Cumulative Timesteps: 1,664,197,456

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 264,311.31958
Policy Entropy: 3.67443
Value Function Loss: 0.03813

Mean KL Divergence: 0.01798
SB3 Clip Fraction: 0.21820
Policy Update Magnitude: 0.51907
Value Function Update Magnitude: 0.46994

Collected Steps per Second: 22,494.75897
Overall Steps per Second: 10,596.05443

Timestep Collection Time: 2.22390
Timestep Consumption Time: 2.49730
PPO Batch Consumption Time: 0.28957
Total Iteration Time: 4.72119

Cumulative Model Updates: 199,574
Cumulative Timesteps: 1,664,247,482

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1664247482...
Checkpoint 1664247482 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 214,100.10302
Policy Entropy: 3.71799
Value Function Loss: 0.02803

Mean KL Divergence: 0.01432
SB3 Clip Fraction: 0.17586
Policy Update Magnitude: 0.54578
Value Function Update Magnitude: 0.41624

Collected Steps per Second: 22,330.60364
Overall Steps per Second: 10,542.25535

Timestep Collection Time: 2.24015
Timestep Consumption Time: 2.50494
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.74509

Cumulative Model Updates: 199,580
Cumulative Timesteps: 1,664,297,506

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 214,100.10302
Policy Entropy: 3.69682
Value Function Loss: 0.02525

Mean KL Divergence: 0.01354
SB3 Clip Fraction: 0.17330
Policy Update Magnitude: 0.50993
Value Function Update Magnitude: 0.38882

Collected Steps per Second: 22,855.48368
Overall Steps per Second: 10,804.80007

Timestep Collection Time: 2.18766
Timestep Consumption Time: 2.43991
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.62757

Cumulative Model Updates: 199,586
Cumulative Timesteps: 1,664,347,506

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1664347506...
Checkpoint 1664347506 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,007.03359
Policy Entropy: 3.71715
Value Function Loss: 0.02123

Mean KL Divergence: 0.01054
SB3 Clip Fraction: 0.14285
Policy Update Magnitude: 0.47955
Value Function Update Magnitude: 0.42662

Collected Steps per Second: 22,257.06487
Overall Steps per Second: 10,678.49619

Timestep Collection Time: 2.24693
Timestep Consumption Time: 2.43632
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.68324

Cumulative Model Updates: 199,592
Cumulative Timesteps: 1,664,397,516

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,007.03359
Policy Entropy: 3.69446
Value Function Loss: 0.02148

Mean KL Divergence: 0.01219
SB3 Clip Fraction: 0.15601
Policy Update Magnitude: 0.48370
Value Function Update Magnitude: 0.48233

Collected Steps per Second: 22,676.82370
Overall Steps per Second: 10,803.95846

Timestep Collection Time: 2.20551
Timestep Consumption Time: 2.42372
PPO Batch Consumption Time: 0.27745
Total Iteration Time: 4.62923

Cumulative Model Updates: 199,598
Cumulative Timesteps: 1,664,447,530

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1664447530...
Checkpoint 1664447530 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 446,007.03359
Policy Entropy: 3.71059
Value Function Loss: 0.01838

Mean KL Divergence: 0.01122
SB3 Clip Fraction: 0.14988
Policy Update Magnitude: 0.43530
Value Function Update Magnitude: 0.47078

Collected Steps per Second: 21,489.83172
Overall Steps per Second: 10,271.15909

Timestep Collection Time: 2.32919
Timestep Consumption Time: 2.54406
PPO Batch Consumption Time: 0.29344
Total Iteration Time: 4.87326

Cumulative Model Updates: 199,604
Cumulative Timesteps: 1,664,497,584

Timesteps Collected: 50,054
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 446,007.03359
Policy Entropy: 3.68661
Value Function Loss: 0.02174

Mean KL Divergence: 0.01107
SB3 Clip Fraction: 0.14683
Policy Update Magnitude: 0.39287
Value Function Update Magnitude: 0.44189

Collected Steps per Second: 22,291.76529
Overall Steps per Second: 10,516.69851

Timestep Collection Time: 2.24424
Timestep Consumption Time: 2.51277
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.75701

Cumulative Model Updates: 199,610
Cumulative Timesteps: 1,664,547,612

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1664547612...
Checkpoint 1664547612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 272,131.98779
Policy Entropy: 3.70591
Value Function Loss: 0.02071

Mean KL Divergence: 0.01102
SB3 Clip Fraction: 0.14265
Policy Update Magnitude: 0.46493
Value Function Update Magnitude: 0.51858

Collected Steps per Second: 22,569.36764
Overall Steps per Second: 10,617.87688

Timestep Collection Time: 2.21734
Timestep Consumption Time: 2.49584
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.71318

Cumulative Model Updates: 199,616
Cumulative Timesteps: 1,664,597,656

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 471,843.66104
Policy Entropy: 3.69188
Value Function Loss: 0.02338

Mean KL Divergence: 0.01272
SB3 Clip Fraction: 0.15541
Policy Update Magnitude: 0.49476
Value Function Update Magnitude: 0.56639

Collected Steps per Second: 22,438.95188
Overall Steps per Second: 10,638.09043

Timestep Collection Time: 2.22952
Timestep Consumption Time: 2.47321
PPO Batch Consumption Time: 0.28813
Total Iteration Time: 4.70272

Cumulative Model Updates: 199,622
Cumulative Timesteps: 1,664,647,684

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1664647684...
Checkpoint 1664647684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302,879.41079
Policy Entropy: 3.73887
Value Function Loss: 0.02095

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12106
Policy Update Magnitude: 0.48950
Value Function Update Magnitude: 0.70028

Collected Steps per Second: 22,358.43250
Overall Steps per Second: 10,629.15296

Timestep Collection Time: 2.23746
Timestep Consumption Time: 2.46903
PPO Batch Consumption Time: 0.28832
Total Iteration Time: 4.70649

Cumulative Model Updates: 199,628
Cumulative Timesteps: 1,664,697,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302,879.41079
Policy Entropy: 3.71253
Value Function Loss: 0.01925

Mean KL Divergence: 0.01080
SB3 Clip Fraction: 0.14547
Policy Update Magnitude: 0.44015
Value Function Update Magnitude: 0.71701

Collected Steps per Second: 22,016.93892
Overall Steps per Second: 10,739.98367

Timestep Collection Time: 2.27207
Timestep Consumption Time: 2.38567
PPO Batch Consumption Time: 0.28370
Total Iteration Time: 4.65774

Cumulative Model Updates: 199,634
Cumulative Timesteps: 1,664,747,734

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1664747734...
Checkpoint 1664747734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302,879.41079
Policy Entropy: 3.71265
Value Function Loss: 0.01663

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.14267
Policy Update Magnitude: 0.36646
Value Function Update Magnitude: 0.61806

Collected Steps per Second: 21,432.49142
Overall Steps per Second: 10,701.21782

Timestep Collection Time: 2.33309
Timestep Consumption Time: 2.33965
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.67274

Cumulative Model Updates: 199,640
Cumulative Timesteps: 1,664,797,738

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302,879.41079
Policy Entropy: 3.69455
Value Function Loss: 0.01438

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14746
Policy Update Magnitude: 0.34514
Value Function Update Magnitude: 0.49108

Collected Steps per Second: 21,935.17398
Overall Steps per Second: 10,759.28889

Timestep Collection Time: 2.28054
Timestep Consumption Time: 2.36884
PPO Batch Consumption Time: 0.27841
Total Iteration Time: 4.64938

Cumulative Model Updates: 199,646
Cumulative Timesteps: 1,664,847,762

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1664847762...
Checkpoint 1664847762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302,879.41079
Policy Entropy: 3.70927
Value Function Loss: 0.01330

Mean KL Divergence: 0.01027
SB3 Clip Fraction: 0.14053
Policy Update Magnitude: 0.35020
Value Function Update Magnitude: 0.46914

Collected Steps per Second: 21,992.42276
Overall Steps per Second: 10,679.92733

Timestep Collection Time: 2.27460
Timestep Consumption Time: 2.40933
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.68393

Cumulative Model Updates: 199,652
Cumulative Timesteps: 1,664,897,786

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302,879.41079
Policy Entropy: 3.70250
Value Function Loss: 0.01312

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14347
Policy Update Magnitude: 0.36037
Value Function Update Magnitude: 0.48334

Collected Steps per Second: 22,691.46245
Overall Steps per Second: 10,856.01985

Timestep Collection Time: 2.20391
Timestep Consumption Time: 2.40275
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.60666

Cumulative Model Updates: 199,658
Cumulative Timesteps: 1,664,947,796

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1664947796...
Checkpoint 1664947796 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 302,879.41079
Policy Entropy: 3.70336
Value Function Loss: 0.01327

Mean KL Divergence: 0.01040
SB3 Clip Fraction: 0.14387
Policy Update Magnitude: 0.35498
Value Function Update Magnitude: 0.49659

Collected Steps per Second: 22,585.75260
Overall Steps per Second: 10,786.69697

Timestep Collection Time: 2.21467
Timestep Consumption Time: 2.42252
PPO Batch Consumption Time: 0.27598
Total Iteration Time: 4.63719

Cumulative Model Updates: 199,664
Cumulative Timesteps: 1,664,997,816

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 316,796.37133
Policy Entropy: 3.70317
Value Function Loss: 0.01948

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13998
Policy Update Magnitude: 0.39514
Value Function Update Magnitude: 0.50006

Collected Steps per Second: 22,722.04360
Overall Steps per Second: 10,779.34166

Timestep Collection Time: 2.20183
Timestep Consumption Time: 2.43946
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.64129

Cumulative Model Updates: 199,670
Cumulative Timesteps: 1,665,047,846

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1665047846...
Checkpoint 1665047846 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 110,469.75022
Policy Entropy: 3.70336
Value Function Loss: 0.02099

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13975
Policy Update Magnitude: 0.43952
Value Function Update Magnitude: 0.55246

Collected Steps per Second: 22,303.15685
Overall Steps per Second: 10,697.20799

Timestep Collection Time: 2.24219
Timestep Consumption Time: 2.43267
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.67486

Cumulative Model Updates: 199,676
Cumulative Timesteps: 1,665,097,854

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,494.36475
Policy Entropy: 3.71119
Value Function Loss: 0.02280

Mean KL Divergence: 0.01038
SB3 Clip Fraction: 0.14030
Policy Update Magnitude: 0.46522
Value Function Update Magnitude: 0.53006

Collected Steps per Second: 22,400.64434
Overall Steps per Second: 10,595.46712

Timestep Collection Time: 2.23235
Timestep Consumption Time: 2.48722
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.71957

Cumulative Model Updates: 199,682
Cumulative Timesteps: 1,665,147,860

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1665147860...
Checkpoint 1665147860 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,494.36475
Policy Entropy: 3.72319
Value Function Loss: 0.01687

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13267
Policy Update Magnitude: 0.43229
Value Function Update Magnitude: 0.49144

Collected Steps per Second: 22,328.01150
Overall Steps per Second: 10,554.67214

Timestep Collection Time: 2.23997
Timestep Consumption Time: 2.49860
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.73856

Cumulative Model Updates: 199,688
Cumulative Timesteps: 1,665,197,874

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,494.36475
Policy Entropy: 3.70539
Value Function Loss: 0.01502

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13866
Policy Update Magnitude: 0.37691
Value Function Update Magnitude: 0.46052

Collected Steps per Second: 22,280.84064
Overall Steps per Second: 10,588.46921

Timestep Collection Time: 2.24408
Timestep Consumption Time: 2.47804
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.72212

Cumulative Model Updates: 199,694
Cumulative Timesteps: 1,665,247,874

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1665247874...
Checkpoint 1665247874 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,494.36475
Policy Entropy: 3.69820
Value Function Loss: 0.01550

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13642
Policy Update Magnitude: 0.36036
Value Function Update Magnitude: 0.40194

Collected Steps per Second: 22,539.47280
Overall Steps per Second: 10,609.45970

Timestep Collection Time: 2.21966
Timestep Consumption Time: 2.49594
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.71560

Cumulative Model Updates: 199,700
Cumulative Timesteps: 1,665,297,904

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,494.36475
Policy Entropy: 3.70773
Value Function Loss: 0.01476

Mean KL Divergence: 0.00970
SB3 Clip Fraction: 0.13621
Policy Update Magnitude: 0.36519
Value Function Update Magnitude: 0.41497

Collected Steps per Second: 22,056.35509
Overall Steps per Second: 10,777.73537

Timestep Collection Time: 2.26864
Timestep Consumption Time: 2.37408
PPO Batch Consumption Time: 0.27724
Total Iteration Time: 4.64272

Cumulative Model Updates: 199,706
Cumulative Timesteps: 1,665,347,942

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1665347942...
Checkpoint 1665347942 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,494.36475
Policy Entropy: 3.70180
Value Function Loss: 0.01649

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13373
Policy Update Magnitude: 0.34523
Value Function Update Magnitude: 0.37626

Collected Steps per Second: 21,974.34721
Overall Steps per Second: 10,602.55876

Timestep Collection Time: 2.27629
Timestep Consumption Time: 2.44144
PPO Batch Consumption Time: 0.29090
Total Iteration Time: 4.71773

Cumulative Model Updates: 199,712
Cumulative Timesteps: 1,665,397,962

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,494.36475
Policy Entropy: 3.71646
Value Function Loss: 0.01824

Mean KL Divergence: 0.00938
SB3 Clip Fraction: 0.13144
Policy Update Magnitude: 0.35056
Value Function Update Magnitude: 0.28598

Collected Steps per Second: 21,934.89885
Overall Steps per Second: 10,490.93460

Timestep Collection Time: 2.28102
Timestep Consumption Time: 2.48824
PPO Batch Consumption Time: 0.29149
Total Iteration Time: 4.76926

Cumulative Model Updates: 199,718
Cumulative Timesteps: 1,665,447,996

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1665447996...
Checkpoint 1665447996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,494.36475
Policy Entropy: 3.69594
Value Function Loss: 0.02156

Mean KL Divergence: 0.00993
SB3 Clip Fraction: 0.13774
Policy Update Magnitude: 0.35606
Value Function Update Magnitude: 0.21822

Collected Steps per Second: 22,736.42517
Overall Steps per Second: 10,714.78985

Timestep Collection Time: 2.19911
Timestep Consumption Time: 2.46733
PPO Batch Consumption Time: 0.29162
Total Iteration Time: 4.66645

Cumulative Model Updates: 199,724
Cumulative Timesteps: 1,665,497,996

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 89,494.36475
Policy Entropy: 3.71414
Value Function Loss: 0.01672

Mean KL Divergence: 0.00939
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.40282
Value Function Update Magnitude: 0.27600

Collected Steps per Second: 22,993.65174
Overall Steps per Second: 10,838.67169

Timestep Collection Time: 2.17556
Timestep Consumption Time: 2.43977
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.61533

Cumulative Model Updates: 199,730
Cumulative Timesteps: 1,665,548,020

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1665548020...
Checkpoint 1665548020 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 89,494.36475
Policy Entropy: 3.71439
Value Function Loss: 0.01475

Mean KL Divergence: 0.01067
SB3 Clip Fraction: 0.14439
Policy Update Magnitude: 0.39249
Value Function Update Magnitude: 0.39085

Collected Steps per Second: 22,461.33792
Overall Steps per Second: 10,664.22793

Timestep Collection Time: 2.22738
Timestep Consumption Time: 2.46400
PPO Batch Consumption Time: 0.28532
Total Iteration Time: 4.69139

Cumulative Model Updates: 199,736
Cumulative Timesteps: 1,665,598,050

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 159,945.68369
Policy Entropy: 3.72546
Value Function Loss: 0.01478

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13063
Policy Update Magnitude: 0.37587
Value Function Update Magnitude: 0.47182

Collected Steps per Second: 22,369.88799
Overall Steps per Second: 10,591.48361

Timestep Collection Time: 2.23613
Timestep Consumption Time: 2.48672
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.72285

Cumulative Model Updates: 199,742
Cumulative Timesteps: 1,665,648,072

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1665648072...
Checkpoint 1665648072 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,945.40762
Policy Entropy: 3.71897
Value Function Loss: 0.01513

Mean KL Divergence: 0.01055
SB3 Clip Fraction: 0.14811
Policy Update Magnitude: 0.37918
Value Function Update Magnitude: 0.49747

Collected Steps per Second: 22,348.78578
Overall Steps per Second: 10,571.71627

Timestep Collection Time: 2.23735
Timestep Consumption Time: 2.49244
PPO Batch Consumption Time: 0.29135
Total Iteration Time: 4.72979

Cumulative Model Updates: 199,748
Cumulative Timesteps: 1,665,698,074

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,945.40762
Policy Entropy: 3.71427
Value Function Loss: 0.01739

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.14334
Policy Update Magnitude: 0.36572
Value Function Update Magnitude: 0.52769

Collected Steps per Second: 22,828.34871
Overall Steps per Second: 10,825.80512

Timestep Collection Time: 2.19140
Timestep Consumption Time: 2.42960
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.62100

Cumulative Model Updates: 199,754
Cumulative Timesteps: 1,665,748,100

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1665748100...
Checkpoint 1665748100 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,945.40762
Policy Entropy: 3.71746
Value Function Loss: 0.01617

Mean KL Divergence: 0.01090
SB3 Clip Fraction: 0.14977
Policy Update Magnitude: 0.36135
Value Function Update Magnitude: 0.56252

Collected Steps per Second: 22,018.61353
Overall Steps per Second: 10,630.18618

Timestep Collection Time: 2.27190
Timestep Consumption Time: 2.43395
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.70584

Cumulative Model Updates: 199,760
Cumulative Timesteps: 1,665,798,124

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,945.40762
Policy Entropy: 3.68575
Value Function Loss: 0.02196

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.13602
Policy Update Magnitude: 0.37003
Value Function Update Magnitude: 0.47581

Collected Steps per Second: 22,289.43797
Overall Steps per Second: 10,514.39512

Timestep Collection Time: 2.24438
Timestep Consumption Time: 2.51348
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.75786

Cumulative Model Updates: 199,766
Cumulative Timesteps: 1,665,848,150

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1665848150...
Checkpoint 1665848150 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,945.40762
Policy Entropy: 3.69883
Value Function Loss: 0.02024

Mean KL Divergence: 0.00994
SB3 Clip Fraction: 0.13739
Policy Update Magnitude: 0.41376
Value Function Update Magnitude: 0.36182

Collected Steps per Second: 22,746.75607
Overall Steps per Second: 10,589.84689

Timestep Collection Time: 2.19873
Timestep Consumption Time: 2.52409
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.72283

Cumulative Model Updates: 199,772
Cumulative Timesteps: 1,665,898,164

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,945.40762
Policy Entropy: 3.69207
Value Function Loss: 0.02027

Mean KL Divergence: 0.01007
SB3 Clip Fraction: 0.13776
Policy Update Magnitude: 0.40965
Value Function Update Magnitude: 0.30604

Collected Steps per Second: 22,961.68986
Overall Steps per Second: 10,846.23085

Timestep Collection Time: 2.17859
Timestep Consumption Time: 2.43352
PPO Batch Consumption Time: 0.27749
Total Iteration Time: 4.61211

Cumulative Model Updates: 199,778
Cumulative Timesteps: 1,665,948,188

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1665948188...
Checkpoint 1665948188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,945.40762
Policy Entropy: 3.71290
Value Function Loss: 0.01604

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.38442
Value Function Update Magnitude: 0.26202

Collected Steps per Second: 22,604.14934
Overall Steps per Second: 10,691.15223

Timestep Collection Time: 2.21225
Timestep Consumption Time: 2.46508
PPO Batch Consumption Time: 0.28397
Total Iteration Time: 4.67733

Cumulative Model Updates: 199,784
Cumulative Timesteps: 1,665,998,194

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 104,945.40762
Policy Entropy: 3.70312
Value Function Loss: 0.01570

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13268
Policy Update Magnitude: 0.34508
Value Function Update Magnitude: 0.24080

Collected Steps per Second: 22,808.07124
Overall Steps per Second: 10,822.92470

Timestep Collection Time: 2.19378
Timestep Consumption Time: 2.42936
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.62315

Cumulative Model Updates: 199,790
Cumulative Timesteps: 1,666,048,230

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1666048230...
Checkpoint 1666048230 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,945.40762
Policy Entropy: 3.71159
Value Function Loss: 0.01517

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12764
Policy Update Magnitude: 0.33845
Value Function Update Magnitude: 0.23134

Collected Steps per Second: 22,538.89758
Overall Steps per Second: 10,794.31584

Timestep Collection Time: 2.21910
Timestep Consumption Time: 2.41445
PPO Batch Consumption Time: 0.27599
Total Iteration Time: 4.63355

Cumulative Model Updates: 199,796
Cumulative Timesteps: 1,666,098,246

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061,460.45990
Policy Entropy: 3.70857
Value Function Loss: 0.01832

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.37236
Value Function Update Magnitude: 0.31517

Collected Steps per Second: 23,034.55898
Overall Steps per Second: 10,895.40272

Timestep Collection Time: 2.17065
Timestep Consumption Time: 2.41844
PPO Batch Consumption Time: 0.27628
Total Iteration Time: 4.58909

Cumulative Model Updates: 199,802
Cumulative Timesteps: 1,666,148,246

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1666148246...
Checkpoint 1666148246 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061,460.45990
Policy Entropy: 3.72122
Value Function Loss: 0.01737

Mean KL Divergence: 0.00885
SB3 Clip Fraction: 0.12479
Policy Update Magnitude: 0.41688
Value Function Update Magnitude: 0.37999

Collected Steps per Second: 21,409.89520
Overall Steps per Second: 10,604.83302

Timestep Collection Time: 2.33574
Timestep Consumption Time: 2.37984
PPO Batch Consumption Time: 0.28287
Total Iteration Time: 4.71559

Cumulative Model Updates: 199,808
Cumulative Timesteps: 1,666,198,254

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061,460.45990
Policy Entropy: 3.72126
Value Function Loss: 0.01611

Mean KL Divergence: 0.00988
SB3 Clip Fraction: 0.13769
Policy Update Magnitude: 0.40972
Value Function Update Magnitude: 0.36946

Collected Steps per Second: 21,899.06295
Overall Steps per Second: 10,676.25148

Timestep Collection Time: 2.28348
Timestep Consumption Time: 2.40038
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.68385

Cumulative Model Updates: 199,814
Cumulative Timesteps: 1,666,248,260

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1666248260...
Checkpoint 1666248260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061,460.45990
Policy Entropy: 3.72894
Value Function Loss: 0.01309

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12866
Policy Update Magnitude: 0.35216
Value Function Update Magnitude: 0.31553

Collected Steps per Second: 21,188.25517
Overall Steps per Second: 10,409.49255

Timestep Collection Time: 2.36093
Timestep Consumption Time: 2.44468
PPO Batch Consumption Time: 0.28426
Total Iteration Time: 4.80561

Cumulative Model Updates: 199,820
Cumulative Timesteps: 1,666,298,284

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061,460.45990
Policy Entropy: 3.74759
Value Function Loss: 0.01208

Mean KL Divergence: 0.00932
SB3 Clip Fraction: 0.13172
Policy Update Magnitude: 0.32501
Value Function Update Magnitude: 0.30919

Collected Steps per Second: 22,309.06340
Overall Steps per Second: 10,638.16513

Timestep Collection Time: 2.24330
Timestep Consumption Time: 2.46108
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.70438

Cumulative Model Updates: 199,826
Cumulative Timesteps: 1,666,348,330

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1666348330...
Checkpoint 1666348330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,061,460.45990
Policy Entropy: 3.73661
Value Function Loss: 0.01181

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.13206
Policy Update Magnitude: 0.33498
Value Function Update Magnitude: 0.34629

Collected Steps per Second: 22,093.74015
Overall Steps per Second: 10,481.53112

Timestep Collection Time: 2.26363
Timestep Consumption Time: 2.50781
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.77144

Cumulative Model Updates: 199,832
Cumulative Timesteps: 1,666,398,342

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 948,003.74051
Policy Entropy: 3.72983
Value Function Loss: 0.01687

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13005
Policy Update Magnitude: 0.37898
Value Function Update Magnitude: 0.43245

Collected Steps per Second: 22,392.35769
Overall Steps per Second: 10,439.63398

Timestep Collection Time: 2.23308
Timestep Consumption Time: 2.55674
PPO Batch Consumption Time: 0.29303
Total Iteration Time: 4.78982

Cumulative Model Updates: 199,838
Cumulative Timesteps: 1,666,448,346

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1666448346...
Checkpoint 1666448346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767,880.98784
Policy Entropy: 3.72236
Value Function Loss: 0.01964

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.11914
Policy Update Magnitude: 0.47712
Value Function Update Magnitude: 0.54534

Collected Steps per Second: 22,604.61150
Overall Steps per Second: 10,628.18275

Timestep Collection Time: 2.21327
Timestep Consumption Time: 2.49403
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.70730

Cumulative Model Updates: 199,844
Cumulative Timesteps: 1,666,498,376

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767,880.98784
Policy Entropy: 3.72480
Value Function Loss: 0.02001

Mean KL Divergence: 0.00561
SB3 Clip Fraction: 0.06574
Policy Update Magnitude: 0.59845
Value Function Update Magnitude: 0.54028

Collected Steps per Second: 22,949.66135
Overall Steps per Second: 10,867.17663

Timestep Collection Time: 2.17981
Timestep Consumption Time: 2.42359
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.60340

Cumulative Model Updates: 199,850
Cumulative Timesteps: 1,666,548,402

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1666548402...
Checkpoint 1666548402 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767,880.98784
Policy Entropy: 3.73472
Value Function Loss: 0.01573

Mean KL Divergence: 0.00785
SB3 Clip Fraction: 0.10082
Policy Update Magnitude: 0.56141
Value Function Update Magnitude: 0.44956

Collected Steps per Second: 22,749.08532
Overall Steps per Second: 10,699.10492

Timestep Collection Time: 2.19921
Timestep Consumption Time: 2.47688
PPO Batch Consumption Time: 0.28694
Total Iteration Time: 4.67609

Cumulative Model Updates: 199,856
Cumulative Timesteps: 1,666,598,432

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767,880.98784
Policy Entropy: 3.73275
Value Function Loss: 0.01689

Mean KL Divergence: 0.01041
SB3 Clip Fraction: 0.14280
Policy Update Magnitude: 0.43177
Value Function Update Magnitude: 0.36754

Collected Steps per Second: 22,648.77326
Overall Steps per Second: 10,674.91206

Timestep Collection Time: 2.20789
Timestep Consumption Time: 2.47655
PPO Batch Consumption Time: 0.28790
Total Iteration Time: 4.68444

Cumulative Model Updates: 199,862
Cumulative Timesteps: 1,666,648,438

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1666648438...
Checkpoint 1666648438 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767,880.98784
Policy Entropy: 3.75348
Value Function Loss: 0.01481

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14594
Policy Update Magnitude: 0.36624
Value Function Update Magnitude: 0.32273

Collected Steps per Second: 22,082.87909
Overall Steps per Second: 10,533.28121

Timestep Collection Time: 2.26537
Timestep Consumption Time: 2.48395
PPO Batch Consumption Time: 0.28959
Total Iteration Time: 4.74933

Cumulative Model Updates: 199,868
Cumulative Timesteps: 1,666,698,464

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 767,880.98784
Policy Entropy: 3.72082
Value Function Loss: 0.01739

Mean KL Divergence: 0.01057
SB3 Clip Fraction: 0.14259
Policy Update Magnitude: 0.35612
Value Function Update Magnitude: 0.29714

Collected Steps per Second: 22,770.15422
Overall Steps per Second: 10,804.31802

Timestep Collection Time: 2.19691
Timestep Consumption Time: 2.43309
PPO Batch Consumption Time: 0.27817
Total Iteration Time: 4.63000

Cumulative Model Updates: 199,874
Cumulative Timesteps: 1,666,748,488

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1666748488...
Checkpoint 1666748488 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 767,880.98784
Policy Entropy: 3.72703
Value Function Loss: 0.01405

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13971
Policy Update Magnitude: 0.36620
Value Function Update Magnitude: 0.31421

Collected Steps per Second: 22,263.48353
Overall Steps per Second: 10,678.48577

Timestep Collection Time: 2.24709
Timestep Consumption Time: 2.43785
PPO Batch Consumption Time: 0.28152
Total Iteration Time: 4.68493

Cumulative Model Updates: 199,880
Cumulative Timesteps: 1,666,798,516

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 460,622.09785
Policy Entropy: 3.71844
Value Function Loss: 0.02290

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13777
Policy Update Magnitude: 0.40816
Value Function Update Magnitude: 0.31134

Collected Steps per Second: 22,058.53820
Overall Steps per Second: 10,495.97070

Timestep Collection Time: 2.26778
Timestep Consumption Time: 2.49824
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.76602

Cumulative Model Updates: 199,886
Cumulative Timesteps: 1,666,848,540

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1666848540...
Checkpoint 1666848540 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 56,014.35896
Policy Entropy: 3.73644
Value Function Loss: 0.02297

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13117
Policy Update Magnitude: 0.49106
Value Function Update Magnitude: 0.43959

Collected Steps per Second: 22,153.33971
Overall Steps per Second: 10,567.31793

Timestep Collection Time: 2.25718
Timestep Consumption Time: 2.47477
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.73195

Cumulative Model Updates: 199,892
Cumulative Timesteps: 1,666,898,544

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 10,393.47160
Policy Entropy: 3.74009
Value Function Loss: 0.02792

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.50091
Value Function Update Magnitude: 0.51066

Collected Steps per Second: 22,474.37351
Overall Steps per Second: 10,628.64196

Timestep Collection Time: 2.22493
Timestep Consumption Time: 2.47971
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.70465

Cumulative Model Updates: 199,898
Cumulative Timesteps: 1,666,948,548

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1666948548...
Checkpoint 1666948548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 956,412.41581
Policy Entropy: 3.72709
Value Function Loss: 0.02759

Mean KL Divergence: 0.01079
SB3 Clip Fraction: 0.13980
Policy Update Magnitude: 0.52789
Value Function Update Magnitude: 0.43541

Collected Steps per Second: 22,522.26896
Overall Steps per Second: 10,529.30993

Timestep Collection Time: 2.22065
Timestep Consumption Time: 2.52933
PPO Batch Consumption Time: 0.29164
Total Iteration Time: 4.74998

Cumulative Model Updates: 199,904
Cumulative Timesteps: 1,666,998,562

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 333,501.26922
Policy Entropy: 3.71914
Value Function Loss: 0.02706

Mean KL Divergence: 0.01197
SB3 Clip Fraction: 0.15161
Policy Update Magnitude: 0.51437
Value Function Update Magnitude: 0.38062

Collected Steps per Second: 22,907.25941
Overall Steps per Second: 10,779.52681

Timestep Collection Time: 2.18289
Timestep Consumption Time: 2.45590
PPO Batch Consumption Time: 0.27906
Total Iteration Time: 4.63879

Cumulative Model Updates: 199,910
Cumulative Timesteps: 1,667,048,566

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1667048566...
Checkpoint 1667048566 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 218,811.49125
Policy Entropy: 3.71026
Value Function Loss: 0.02594

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13124
Policy Update Magnitude: 0.49622
Value Function Update Magnitude: 0.41988

Collected Steps per Second: 21,755.87884
Overall Steps per Second: 10,679.92314

Timestep Collection Time: 2.29860
Timestep Consumption Time: 2.38383
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.68243

Cumulative Model Updates: 199,916
Cumulative Timesteps: 1,667,098,574

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 732,220.16267
Policy Entropy: 3.72281
Value Function Loss: 0.02459

Mean KL Divergence: 0.00954
SB3 Clip Fraction: 0.12761
Policy Update Magnitude: 0.51535
Value Function Update Magnitude: 0.43835

Collected Steps per Second: 22,040.79596
Overall Steps per Second: 10,844.31823

Timestep Collection Time: 2.26916
Timestep Consumption Time: 2.34284
PPO Batch Consumption Time: 0.27811
Total Iteration Time: 4.61200

Cumulative Model Updates: 199,922
Cumulative Timesteps: 1,667,148,588

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1667148588...
Checkpoint 1667148588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 315,200.93556
Policy Entropy: 3.71296
Value Function Loss: 0.02701

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13652
Policy Update Magnitude: 0.51541
Value Function Update Magnitude: 0.41768

Collected Steps per Second: 21,597.06788
Overall Steps per Second: 10,758.41027

Timestep Collection Time: 2.31541
Timestep Consumption Time: 2.33268
PPO Batch Consumption Time: 0.27648
Total Iteration Time: 4.64808

Cumulative Model Updates: 199,928
Cumulative Timesteps: 1,667,198,594

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 315,200.93556
Policy Entropy: 3.71185
Value Function Loss: 0.02587

Mean KL Divergence: 0.01002
SB3 Clip Fraction: 0.13187
Policy Update Magnitude: 0.46924
Value Function Update Magnitude: 0.37652

Collected Steps per Second: 21,901.27416
Overall Steps per Second: 10,524.17709

Timestep Collection Time: 2.28443
Timestep Consumption Time: 2.46957
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.75401

Cumulative Model Updates: 199,934
Cumulative Timesteps: 1,667,248,626

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1667248626...
Checkpoint 1667248626 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 379,985.05192
Policy Entropy: 3.70771
Value Function Loss: 0.02445

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.12850
Policy Update Magnitude: 0.46509
Value Function Update Magnitude: 0.31101

Collected Steps per Second: 22,730.79534
Overall Steps per Second: 10,907.42069

Timestep Collection Time: 2.20071
Timestep Consumption Time: 2.38552
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.58624

Cumulative Model Updates: 199,940
Cumulative Timesteps: 1,667,298,650

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301,351.15677
Policy Entropy: 3.71357
Value Function Loss: 0.02568

Mean KL Divergence: 0.00937
SB3 Clip Fraction: 0.12754
Policy Update Magnitude: 0.51888
Value Function Update Magnitude: 0.33364

Collected Steps per Second: 22,152.45839
Overall Steps per Second: 10,535.64164

Timestep Collection Time: 2.25727
Timestep Consumption Time: 2.48891
PPO Batch Consumption Time: 0.29216
Total Iteration Time: 4.74618

Cumulative Model Updates: 199,946
Cumulative Timesteps: 1,667,348,654

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1667348654...
Checkpoint 1667348654 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 36,640.75285
Policy Entropy: 3.73224
Value Function Loss: 0.02414

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.12769
Policy Update Magnitude: 0.57668
Value Function Update Magnitude: 0.43417

Collected Steps per Second: 21,939.43019
Overall Steps per Second: 10,636.65024

Timestep Collection Time: 2.27982
Timestep Consumption Time: 2.42260
PPO Batch Consumption Time: 0.27778
Total Iteration Time: 4.70242

Cumulative Model Updates: 199,952
Cumulative Timesteps: 1,667,398,672

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 430,291.72385
Policy Entropy: 3.73920
Value Function Loss: 0.02639

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12469
Policy Update Magnitude: 0.56320
Value Function Update Magnitude: 0.42969

Collected Steps per Second: 22,315.54543
Overall Steps per Second: 10,542.26710

Timestep Collection Time: 2.24158
Timestep Consumption Time: 2.50332
PPO Batch Consumption Time: 0.29145
Total Iteration Time: 4.74490

Cumulative Model Updates: 199,958
Cumulative Timesteps: 1,667,448,694

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1667448694...
Checkpoint 1667448694 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,241.19435
Policy Entropy: 3.72926
Value Function Loss: 0.02433

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.12121
Policy Update Magnitude: 0.52007
Value Function Update Magnitude: 0.44085

Collected Steps per Second: 22,234.67067
Overall Steps per Second: 10,545.45192

Timestep Collection Time: 2.24892
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.29087
Total Iteration Time: 4.74176

Cumulative Model Updates: 199,964
Cumulative Timesteps: 1,667,498,698

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,241.19435
Policy Entropy: 3.71877
Value Function Loss: 0.02479

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12285
Policy Update Magnitude: 0.50621
Value Function Update Magnitude: 0.42879

Collected Steps per Second: 22,786.98435
Overall Steps per Second: 10,601.28723

Timestep Collection Time: 2.19441
Timestep Consumption Time: 2.52238
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.71679

Cumulative Model Updates: 199,970
Cumulative Timesteps: 1,667,548,702

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1667548702...
Checkpoint 1667548702 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 185,241.19435
Policy Entropy: 3.71104
Value Function Loss: 0.02056

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13006
Policy Update Magnitude: 0.47022
Value Function Update Magnitude: 0.32111

Collected Steps per Second: 22,691.57744
Overall Steps per Second: 10,682.49560

Timestep Collection Time: 2.20452
Timestep Consumption Time: 2.47828
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.68280

Cumulative Model Updates: 199,976
Cumulative Timesteps: 1,667,598,726

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 185,241.19435
Policy Entropy: 3.71037
Value Function Loss: 0.02118

Mean KL Divergence: 0.01420
SB3 Clip Fraction: 0.17644
Policy Update Magnitude: 0.45368
Value Function Update Magnitude: 0.27472

Collected Steps per Second: 22,854.64383
Overall Steps per Second: 10,721.62299

Timestep Collection Time: 2.18783
Timestep Consumption Time: 2.47583
PPO Batch Consumption Time: 0.28649
Total Iteration Time: 4.66366

Cumulative Model Updates: 199,982
Cumulative Timesteps: 1,667,648,728

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1667648728...
Checkpoint 1667648728 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,923.68133
Policy Entropy: 3.70878
Value Function Loss: 0.02552

Mean KL Divergence: 0.01447
SB3 Clip Fraction: 0.18594
Policy Update Magnitude: 0.46611
Value Function Update Magnitude: 0.31441

Collected Steps per Second: 21,910.37151
Overall Steps per Second: 10,568.74713

Timestep Collection Time: 2.28294
Timestep Consumption Time: 2.44988
PPO Batch Consumption Time: 0.29122
Total Iteration Time: 4.73282

Cumulative Model Updates: 199,988
Cumulative Timesteps: 1,667,698,748

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,685.66271
Policy Entropy: 3.72574
Value Function Loss: 0.03111

Mean KL Divergence: 0.01336
SB3 Clip Fraction: 0.17069
Policy Update Magnitude: 0.54951
Value Function Update Magnitude: 0.41306

Collected Steps per Second: 21,913.33517
Overall Steps per Second: 10,673.98737

Timestep Collection Time: 2.28363
Timestep Consumption Time: 2.40459
PPO Batch Consumption Time: 0.28922
Total Iteration Time: 4.68822

Cumulative Model Updates: 199,994
Cumulative Timesteps: 1,667,748,790

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1667748790...
Checkpoint 1667748790 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 119,869.25595
Policy Entropy: 3.72673
Value Function Loss: 0.04518

Mean KL Divergence: 0.01644
SB3 Clip Fraction: 0.19362
Policy Update Magnitude: 0.60805
Value Function Update Magnitude: 0.48184

Collected Steps per Second: 22,156.63722
Overall Steps per Second: 10,901.67308

Timestep Collection Time: 2.25810
Timestep Consumption Time: 2.33128
PPO Batch Consumption Time: 0.27763
Total Iteration Time: 4.58939

Cumulative Model Updates: 200,000
Cumulative Timesteps: 1,667,798,822

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,368.96391
Policy Entropy: 3.76045
Value Function Loss: 0.04160

Mean KL Divergence: 0.02315
SB3 Clip Fraction: 0.25389
Policy Update Magnitude: 0.66115
Value Function Update Magnitude: 0.55515

Collected Steps per Second: 21,785.01156
Overall Steps per Second: 10,642.16530

Timestep Collection Time: 2.29662
Timestep Consumption Time: 2.40467
PPO Batch Consumption Time: 0.28930
Total Iteration Time: 4.70130

Cumulative Model Updates: 200,006
Cumulative Timesteps: 1,667,848,854

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1667848854...
Checkpoint 1667848854 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191.85466
Policy Entropy: 3.76749
Value Function Loss: 0.04045

Mean KL Divergence: 0.02000
SB3 Clip Fraction: 0.21146
Policy Update Magnitude: 0.63507
Value Function Update Magnitude: 0.62954

Collected Steps per Second: 21,672.65700
Overall Steps per Second: 10,605.08073

Timestep Collection Time: 2.30788
Timestep Consumption Time: 2.40853
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.71642

Cumulative Model Updates: 200,012
Cumulative Timesteps: 1,667,898,872

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 293,681.10838
Policy Entropy: 3.77582
Value Function Loss: 0.03493

Mean KL Divergence: 0.01273
SB3 Clip Fraction: 0.15295
Policy Update Magnitude: 0.63874
Value Function Update Magnitude: 0.78888

Collected Steps per Second: 21,429.09921
Overall Steps per Second: 10,393.96273

Timestep Collection Time: 2.33458
Timestep Consumption Time: 2.47860
PPO Batch Consumption Time: 0.29160
Total Iteration Time: 4.81318

Cumulative Model Updates: 200,018
Cumulative Timesteps: 1,667,948,900

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1667948900...
Checkpoint 1667948900 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 65,264.21204
Policy Entropy: 3.75591
Value Function Loss: 0.03407

Mean KL Divergence: 0.01374
SB3 Clip Fraction: 0.16207
Policy Update Magnitude: 0.72204
Value Function Update Magnitude: 0.77001

Collected Steps per Second: 22,140.75862
Overall Steps per Second: 10,605.10025

Timestep Collection Time: 2.25846
Timestep Consumption Time: 2.45663
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.71509

Cumulative Model Updates: 200,024
Cumulative Timesteps: 1,667,998,904

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 9,802.66677
Policy Entropy: 3.76579
Value Function Loss: 0.03053

Mean KL Divergence: 0.00676
SB3 Clip Fraction: 0.08382
Policy Update Magnitude: 0.76866
Value Function Update Magnitude: 0.67430

Collected Steps per Second: 22,272.89516
Overall Steps per Second: 10,631.55352

Timestep Collection Time: 2.24560
Timestep Consumption Time: 2.45889
PPO Batch Consumption Time: 0.28836
Total Iteration Time: 4.70449

Cumulative Model Updates: 200,030
Cumulative Timesteps: 1,668,048,920

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1668048920...
Checkpoint 1668048920 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,127.60607
Policy Entropy: 3.79905
Value Function Loss: 0.02692

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07398
Policy Update Magnitude: 0.73286
Value Function Update Magnitude: 0.62566

Collected Steps per Second: 22,285.73338
Overall Steps per Second: 10,622.28831

Timestep Collection Time: 2.24458
Timestep Consumption Time: 2.46458
PPO Batch Consumption Time: 0.28889
Total Iteration Time: 4.70915

Cumulative Model Updates: 200,036
Cumulative Timesteps: 1,668,098,942

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,294.35009
Policy Entropy: 3.81148
Value Function Loss: 0.02117

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06482
Policy Update Magnitude: 0.65436
Value Function Update Magnitude: 0.69157

Collected Steps per Second: 22,981.72884
Overall Steps per Second: 10,767.73721

Timestep Collection Time: 2.17642
Timestep Consumption Time: 2.46875
PPO Batch Consumption Time: 0.28229
Total Iteration Time: 4.64517

Cumulative Model Updates: 200,042
Cumulative Timesteps: 1,668,148,960

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1668148960...
Checkpoint 1668148960 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,433.75292
Policy Entropy: 3.79932
Value Function Loss: 0.01939

Mean KL Divergence: 0.00930
SB3 Clip Fraction: 0.12575
Policy Update Magnitude: 0.58476
Value Function Update Magnitude: 0.73699

Collected Steps per Second: 22,604.48698
Overall Steps per Second: 10,599.90138

Timestep Collection Time: 2.21204
Timestep Consumption Time: 2.50517
PPO Batch Consumption Time: 0.29318
Total Iteration Time: 4.71721

Cumulative Model Updates: 200,048
Cumulative Timesteps: 1,668,198,962

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 194,603.21090
Policy Entropy: 3.76295
Value Function Loss: 0.01774

Mean KL Divergence: 0.01214
SB3 Clip Fraction: 0.16412
Policy Update Magnitude: 0.43946
Value Function Update Magnitude: 0.73479

Collected Steps per Second: 22,817.31142
Overall Steps per Second: 10,837.86314

Timestep Collection Time: 2.19141
Timestep Consumption Time: 2.42223
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.61364

Cumulative Model Updates: 200,054
Cumulative Timesteps: 1,668,248,964

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1668248964...
Checkpoint 1668248964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,431.56250
Policy Entropy: 3.74360
Value Function Loss: 0.01731

Mean KL Divergence: 0.00999
SB3 Clip Fraction: 0.13371
Policy Update Magnitude: 0.40051
Value Function Update Magnitude: 0.67607

Collected Steps per Second: 22,523.71703
Overall Steps per Second: 10,669.84661

Timestep Collection Time: 2.22113
Timestep Consumption Time: 2.46760
PPO Batch Consumption Time: 0.28469
Total Iteration Time: 4.68873

Cumulative Model Updates: 200,060
Cumulative Timesteps: 1,668,298,992

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,431.56250
Policy Entropy: 3.72969
Value Function Loss: 0.01648

Mean KL Divergence: 0.00872
SB3 Clip Fraction: 0.11644
Policy Update Magnitude: 0.43330
Value Function Update Magnitude: 0.61626

Collected Steps per Second: 22,261.55020
Overall Steps per Second: 10,553.25045

Timestep Collection Time: 2.24629
Timestep Consumption Time: 2.49215
PPO Batch Consumption Time: 0.29212
Total Iteration Time: 4.73845

Cumulative Model Updates: 200,066
Cumulative Timesteps: 1,668,348,998

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1668348998...
Checkpoint 1668348998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 103,431.56250
Policy Entropy: 3.72729
Value Function Loss: 0.01592

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12361
Policy Update Magnitude: 0.43334
Value Function Update Magnitude: 0.50865

Collected Steps per Second: 22,507.13743
Overall Steps per Second: 10,597.64052

Timestep Collection Time: 2.22223
Timestep Consumption Time: 2.49731
PPO Batch Consumption Time: 0.29223
Total Iteration Time: 4.71954

Cumulative Model Updates: 200,072
Cumulative Timesteps: 1,668,399,014

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,431.56250
Policy Entropy: 3.72504
Value Function Loss: 0.01852

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.09185
Policy Update Magnitude: 0.51487
Value Function Update Magnitude: 0.45742

Collected Steps per Second: 21,313.73854
Overall Steps per Second: 10,447.33563

Timestep Collection Time: 2.34609
Timestep Consumption Time: 2.44020
PPO Batch Consumption Time: 0.29220
Total Iteration Time: 4.78629

Cumulative Model Updates: 200,078
Cumulative Timesteps: 1,668,449,018

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1668449018...
Checkpoint 1668449018 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,053.10274
Policy Entropy: 3.72375
Value Function Loss: 0.02092

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.11970
Policy Update Magnitude: 0.53660
Value Function Update Magnitude: 0.49085

Collected Steps per Second: 21,318.82905
Overall Steps per Second: 10,673.18231

Timestep Collection Time: 2.34553
Timestep Consumption Time: 2.33948
PPO Batch Consumption Time: 0.27573
Total Iteration Time: 4.68501

Cumulative Model Updates: 200,084
Cumulative Timesteps: 1,668,499,022

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,053.10274
Policy Entropy: 3.71498
Value Function Loss: 0.02104

Mean KL Divergence: 0.00720
SB3 Clip Fraction: 0.08973
Policy Update Magnitude: 0.55062
Value Function Update Magnitude: 0.52613

Collected Steps per Second: 22,043.02696
Overall Steps per Second: 10,839.97661

Timestep Collection Time: 2.26911
Timestep Consumption Time: 2.34511
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.61422

Cumulative Model Updates: 200,090
Cumulative Timesteps: 1,668,549,040

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1668549040...
Checkpoint 1668549040 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 84,053.10274
Policy Entropy: 3.72175
Value Function Loss: 0.01909

Mean KL Divergence: 0.00671
SB3 Clip Fraction: 0.08415
Policy Update Magnitude: 0.57836
Value Function Update Magnitude: 0.56542

Collected Steps per Second: 22,016.43863
Overall Steps per Second: 10,624.28645

Timestep Collection Time: 2.27139
Timestep Consumption Time: 2.43556
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.70695

Cumulative Model Updates: 200,096
Cumulative Timesteps: 1,668,599,048

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 289,363.13499
Policy Entropy: 3.72818
Value Function Loss: 0.01809

Mean KL Divergence: 0.00601
SB3 Clip Fraction: 0.07440
Policy Update Magnitude: 0.57909
Value Function Update Magnitude: 0.54280

Collected Steps per Second: 22,647.77164
Overall Steps per Second: 10,821.01235

Timestep Collection Time: 2.20852
Timestep Consumption Time: 2.41379
PPO Batch Consumption Time: 0.27822
Total Iteration Time: 4.62230

Cumulative Model Updates: 200,102
Cumulative Timesteps: 1,668,649,066

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1668649066...
Checkpoint 1668649066 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 289,363.13499
Policy Entropy: 3.74716
Value Function Loss: 0.01558

Mean KL Divergence: 0.00615
SB3 Clip Fraction: 0.07601
Policy Update Magnitude: 0.56947
Value Function Update Magnitude: 0.51841

Collected Steps per Second: 22,391.84211
Overall Steps per Second: 10,726.81644

Timestep Collection Time: 2.23403
Timestep Consumption Time: 2.42942
PPO Batch Consumption Time: 0.27897
Total Iteration Time: 4.66345

Cumulative Model Updates: 200,108
Cumulative Timesteps: 1,668,699,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 556,131.60112
Policy Entropy: 3.73643
Value Function Loss: 0.01649

Mean KL Divergence: 0.01464
SB3 Clip Fraction: 0.18549
Policy Update Magnitude: 0.44718
Value Function Update Magnitude: 0.48850

Collected Steps per Second: 22,430.69701
Overall Steps per Second: 10,586.27505

Timestep Collection Time: 2.22936
Timestep Consumption Time: 2.49431
PPO Batch Consumption Time: 0.29042
Total Iteration Time: 4.72366

Cumulative Model Updates: 200,114
Cumulative Timesteps: 1,668,749,096

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1668749096...
Checkpoint 1668749096 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 193,987.25999
Policy Entropy: 3.72798
Value Function Loss: 0.02304

Mean KL Divergence: 0.00801
SB3 Clip Fraction: 0.10102
Policy Update Magnitude: 0.52054
Value Function Update Magnitude: 0.45366

Collected Steps per Second: 22,532.07734
Overall Steps per Second: 10,626.91441

Timestep Collection Time: 2.21906
Timestep Consumption Time: 2.48598
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.70503

Cumulative Model Updates: 200,120
Cumulative Timesteps: 1,668,799,096

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 67,645.41363
Policy Entropy: 3.71632
Value Function Loss: 0.02439

Mean KL Divergence: 0.01455
SB3 Clip Fraction: 0.17834
Policy Update Magnitude: 0.58782
Value Function Update Magnitude: 0.44400

Collected Steps per Second: 22,222.72987
Overall Steps per Second: 10,707.21816

Timestep Collection Time: 2.25004
Timestep Consumption Time: 2.41990
PPO Batch Consumption Time: 0.27799
Total Iteration Time: 4.66993

Cumulative Model Updates: 200,126
Cumulative Timesteps: 1,668,849,098

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1668849098...
Checkpoint 1668849098 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,380.40688
Policy Entropy: 3.72194
Value Function Loss: 0.02449

Mean KL Divergence: 0.01322
SB3 Clip Fraction: 0.16544
Policy Update Magnitude: 0.51295
Value Function Update Magnitude: 0.39331

Collected Steps per Second: 22,551.58299
Overall Steps per Second: 10,829.70543

Timestep Collection Time: 2.21811
Timestep Consumption Time: 2.40085
PPO Batch Consumption Time: 0.27522
Total Iteration Time: 4.61896

Cumulative Model Updates: 200,132
Cumulative Timesteps: 1,668,899,120

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,380.40688
Policy Entropy: 3.71551
Value Function Loss: 0.02103

Mean KL Divergence: 0.01185
SB3 Clip Fraction: 0.14445
Policy Update Magnitude: 0.47947
Value Function Update Magnitude: 0.36153

Collected Steps per Second: 22,526.47347
Overall Steps per Second: 10,700.74012

Timestep Collection Time: 2.21979
Timestep Consumption Time: 2.45316
PPO Batch Consumption Time: 0.28245
Total Iteration Time: 4.67295

Cumulative Model Updates: 200,138
Cumulative Timesteps: 1,668,949,124

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1668949124...
Checkpoint 1668949124 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,380.40688
Policy Entropy: 3.70407
Value Function Loss: 0.02244

Mean KL Divergence: 0.01072
SB3 Clip Fraction: 0.13843
Policy Update Magnitude: 0.44515
Value Function Update Magnitude: 0.32980

Collected Steps per Second: 21,118.06098
Overall Steps per Second: 10,481.28805

Timestep Collection Time: 2.36906
Timestep Consumption Time: 2.40421
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.77327

Cumulative Model Updates: 200,144
Cumulative Timesteps: 1,668,999,154

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,380.40688
Policy Entropy: 3.69584
Value Function Loss: 0.02130

Mean KL Divergence: 0.01048
SB3 Clip Fraction: 0.13873
Policy Update Magnitude: 0.43037
Value Function Update Magnitude: 0.31517

Collected Steps per Second: 21,377.00171
Overall Steps per Second: 10,664.13973

Timestep Collection Time: 2.33952
Timestep Consumption Time: 2.35021
PPO Batch Consumption Time: 0.27801
Total Iteration Time: 4.68974

Cumulative Model Updates: 200,150
Cumulative Timesteps: 1,669,049,166

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1669049166...
Checkpoint 1669049166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,380.40688
Policy Entropy: 3.70667
Value Function Loss: 0.02102

Mean KL Divergence: 0.01031
SB3 Clip Fraction: 0.13721
Policy Update Magnitude: 0.43485
Value Function Update Magnitude: 0.26986

Collected Steps per Second: 21,356.98757
Overall Steps per Second: 10,408.92982

Timestep Collection Time: 2.34228
Timestep Consumption Time: 2.46360
PPO Batch Consumption Time: 0.29082
Total Iteration Time: 4.80587

Cumulative Model Updates: 200,156
Cumulative Timesteps: 1,669,099,190

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,380.40688
Policy Entropy: 3.71133
Value Function Loss: 0.01751

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13740
Policy Update Magnitude: 0.41703
Value Function Update Magnitude: 0.24659

Collected Steps per Second: 22,863.84779
Overall Steps per Second: 10,846.38707

Timestep Collection Time: 2.18756
Timestep Consumption Time: 2.42375
PPO Batch Consumption Time: 0.27621
Total Iteration Time: 4.61131

Cumulative Model Updates: 200,162
Cumulative Timesteps: 1,669,149,206

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1669149206...
Checkpoint 1669149206 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,380.40688
Policy Entropy: 3.71061
Value Function Loss: 0.01983

Mean KL Divergence: 0.01010
SB3 Clip Fraction: 0.13669
Policy Update Magnitude: 0.40673
Value Function Update Magnitude: 0.26196

Collected Steps per Second: 22,606.37643
Overall Steps per Second: 10,659.83210

Timestep Collection Time: 2.21221
Timestep Consumption Time: 2.47924
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.69144

Cumulative Model Updates: 200,168
Cumulative Timesteps: 1,669,199,216

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 138,895.33872
Policy Entropy: 3.69843
Value Function Loss: 0.01923

Mean KL Divergence: 0.01056
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.43742
Value Function Update Magnitude: 0.41348

Collected Steps per Second: 22,976.23568
Overall Steps per Second: 10,778.50008

Timestep Collection Time: 2.17668
Timestep Consumption Time: 2.46329
PPO Batch Consumption Time: 0.28251
Total Iteration Time: 4.63998

Cumulative Model Updates: 200,174
Cumulative Timesteps: 1,669,249,228

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1669249228...
Checkpoint 1669249228 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 138,895.33872
Policy Entropy: 3.68435
Value Function Loss: 0.02329

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13796
Policy Update Magnitude: 0.44030
Value Function Update Magnitude: 0.41300

Collected Steps per Second: 22,462.17820
Overall Steps per Second: 10,669.46829

Timestep Collection Time: 2.22712
Timestep Consumption Time: 2.46158
PPO Batch Consumption Time: 0.28354
Total Iteration Time: 4.68871

Cumulative Model Updates: 200,180
Cumulative Timesteps: 1,669,299,254

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,123.33082
Policy Entropy: 3.69677
Value Function Loss: 0.02121

Mean KL Divergence: 0.01032
SB3 Clip Fraction: 0.13894
Policy Update Magnitude: 0.42387
Value Function Update Magnitude: 0.38341

Collected Steps per Second: 22,709.66749
Overall Steps per Second: 10,826.08583

Timestep Collection Time: 2.20311
Timestep Consumption Time: 2.41832
PPO Batch Consumption Time: 0.27779
Total Iteration Time: 4.62143

Cumulative Model Updates: 200,186
Cumulative Timesteps: 1,669,349,286

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1669349286...
Checkpoint 1669349286 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,123.33082
Policy Entropy: 3.69949
Value Function Loss: 0.02184

Mean KL Divergence: 0.00992
SB3 Clip Fraction: 0.13188
Policy Update Magnitude: 0.43374
Value Function Update Magnitude: 0.41892

Collected Steps per Second: 22,533.68790
Overall Steps per Second: 10,794.24918

Timestep Collection Time: 2.21970
Timestep Consumption Time: 2.41406
PPO Batch Consumption Time: 0.27633
Total Iteration Time: 4.63376

Cumulative Model Updates: 200,192
Cumulative Timesteps: 1,669,399,304

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,123.33082
Policy Entropy: 3.71636
Value Function Loss: 0.01869

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.12934
Policy Update Magnitude: 0.44357
Value Function Update Magnitude: 0.39542

Collected Steps per Second: 21,894.70957
Overall Steps per Second: 10,452.67750

Timestep Collection Time: 2.28466
Timestep Consumption Time: 2.50091
PPO Batch Consumption Time: 0.29112
Total Iteration Time: 4.78557

Cumulative Model Updates: 200,198
Cumulative Timesteps: 1,669,449,326

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1669449326...
Checkpoint 1669449326 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,123.33082
Policy Entropy: 3.70714
Value Function Loss: 0.01894

Mean KL Divergence: 0.00944
SB3 Clip Fraction: 0.12967
Policy Update Magnitude: 0.44116
Value Function Update Magnitude: 0.38930

Collected Steps per Second: 22,305.13583
Overall Steps per Second: 10,572.63440

Timestep Collection Time: 2.24191
Timestep Consumption Time: 2.48785
PPO Batch Consumption Time: 0.28812
Total Iteration Time: 4.72976

Cumulative Model Updates: 200,204
Cumulative Timesteps: 1,669,499,332

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,123.33082
Policy Entropy: 3.69687
Value Function Loss: 0.01783

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.44091
Value Function Update Magnitude: 0.38643

Collected Steps per Second: 21,937.92234
Overall Steps per Second: 10,450.42052

Timestep Collection Time: 2.27943
Timestep Consumption Time: 2.50564
PPO Batch Consumption Time: 0.29092
Total Iteration Time: 4.78507

Cumulative Model Updates: 200,210
Cumulative Timesteps: 1,669,549,338

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1669549338...
Checkpoint 1669549338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,123.33082
Policy Entropy: 3.69904
Value Function Loss: 0.01808

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12888
Policy Update Magnitude: 0.43958
Value Function Update Magnitude: 0.40062

Collected Steps per Second: 21,869.49942
Overall Steps per Second: 10,617.97078

Timestep Collection Time: 2.28720
Timestep Consumption Time: 2.42368
PPO Batch Consumption Time: 0.27751
Total Iteration Time: 4.71088

Cumulative Model Updates: 200,216
Cumulative Timesteps: 1,669,599,358

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,123.33082
Policy Entropy: 3.69007
Value Function Loss: 0.01944

Mean KL Divergence: 0.01004
SB3 Clip Fraction: 0.13384
Policy Update Magnitude: 0.44639
Value Function Update Magnitude: 0.36638

Collected Steps per Second: 22,506.81931
Overall Steps per Second: 10,502.78773

Timestep Collection Time: 2.22182
Timestep Consumption Time: 2.53940
PPO Batch Consumption Time: 0.29183
Total Iteration Time: 4.76121

Cumulative Model Updates: 200,222
Cumulative Timesteps: 1,669,649,364

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1669649364...
Checkpoint 1669649364 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,123.33082
Policy Entropy: 3.69669
Value Function Loss: 0.01775

Mean KL Divergence: 0.00964
SB3 Clip Fraction: 0.13137
Policy Update Magnitude: 0.43357
Value Function Update Magnitude: 0.27741

Collected Steps per Second: 22,407.70429
Overall Steps per Second: 10,578.52154

Timestep Collection Time: 2.23236
Timestep Consumption Time: 2.49628
PPO Batch Consumption Time: 0.28795
Total Iteration Time: 4.72864

Cumulative Model Updates: 200,228
Cumulative Timesteps: 1,669,699,386

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 114,123.33082
Policy Entropy: 3.69151
Value Function Loss: 0.01789

Mean KL Divergence: 0.00977
SB3 Clip Fraction: 0.13186
Policy Update Magnitude: 0.40269
Value Function Update Magnitude: 0.22742

Collected Steps per Second: 22,756.91714
Overall Steps per Second: 10,690.21672

Timestep Collection Time: 2.19749
Timestep Consumption Time: 2.48044
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.67792

Cumulative Model Updates: 200,234
Cumulative Timesteps: 1,669,749,394

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1669749394...
Checkpoint 1669749394 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 156,212.60321
Policy Entropy: 3.70892
Value Function Loss: 0.02266

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.12732
Policy Update Magnitude: 0.45053
Value Function Update Magnitude: 0.27816

Collected Steps per Second: 22,775.74808
Overall Steps per Second: 10,823.94384

Timestep Collection Time: 2.19620
Timestep Consumption Time: 2.42504
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.62124

Cumulative Model Updates: 200,240
Cumulative Timesteps: 1,669,799,414

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,809.41293
Policy Entropy: 3.72271
Value Function Loss: 0.02440

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.13428
Policy Update Magnitude: 0.48786
Value Function Update Magnitude: 0.40037

Collected Steps per Second: 21,915.52198
Overall Steps per Second: 10,652.63086

Timestep Collection Time: 2.28167
Timestep Consumption Time: 2.41238
PPO Batch Consumption Time: 0.29012
Total Iteration Time: 4.69405

Cumulative Model Updates: 200,246
Cumulative Timesteps: 1,669,849,418

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1669849418...
Checkpoint 1669849418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 35,843.67620
Policy Entropy: 3.73448
Value Function Loss: 0.03182

Mean KL Divergence: 0.00998
SB3 Clip Fraction: 0.13358
Policy Update Magnitude: 0.52522
Value Function Update Magnitude: 0.41942

Collected Steps per Second: 21,685.61289
Overall Steps per Second: 10,590.71121

Timestep Collection Time: 2.30660
Timestep Consumption Time: 2.41641
PPO Batch Consumption Time: 0.29144
Total Iteration Time: 4.72301

Cumulative Model Updates: 200,252
Cumulative Timesteps: 1,669,899,438

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,979.13624
Policy Entropy: 3.73429
Value Function Loss: 0.02421

Mean KL Divergence: 0.00995
SB3 Clip Fraction: 0.12836
Policy Update Magnitude: 0.59779
Value Function Update Magnitude: 0.48154

Collected Steps per Second: 21,419.45150
Overall Steps per Second: 10,553.61448

Timestep Collection Time: 2.33507
Timestep Consumption Time: 2.40416
PPO Batch Consumption Time: 0.28811
Total Iteration Time: 4.73923

Cumulative Model Updates: 200,258
Cumulative Timesteps: 1,669,949,454

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1669949454...
Checkpoint 1669949454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 488,514.22104
Policy Entropy: 3.71789
Value Function Loss: 0.02771

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12711
Policy Update Magnitude: 0.60338
Value Function Update Magnitude: 0.53468

Collected Steps per Second: 21,487.86175
Overall Steps per Second: 10,463.94646

Timestep Collection Time: 2.32801
Timestep Consumption Time: 2.45259
PPO Batch Consumption Time: 0.28593
Total Iteration Time: 4.78061

Cumulative Model Updates: 200,264
Cumulative Timesteps: 1,669,999,478

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 59,412.38012
Policy Entropy: 3.73887
Value Function Loss: 0.02632

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13294
Policy Update Magnitude: 0.55950
Value Function Update Magnitude: 0.51149

Collected Steps per Second: 21,990.58528
Overall Steps per Second: 10,508.98951

Timestep Collection Time: 2.27525
Timestep Consumption Time: 2.48582
PPO Batch Consumption Time: 0.29239
Total Iteration Time: 4.76107

Cumulative Model Updates: 200,270
Cumulative Timesteps: 1,670,049,512

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


Saving checkpoint 1670049512...
Checkpoint 1670049512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,605.81739
Policy Entropy: 3.73125
Value Function Loss: 0.02800

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13573
Policy Update Magnitude: 0.51369
Value Function Update Magnitude: 0.45778

Collected Steps per Second: 21,918.59308
Overall Steps per Second: 10,648.80271

Timestep Collection Time: 2.28153
Timestep Consumption Time: 2.41458
PPO Batch Consumption Time: 0.27657
Total Iteration Time: 4.69611

Cumulative Model Updates: 200,276
Cumulative Timesteps: 1,670,099,520

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 218,471.68245
Policy Entropy: 3.74648
Value Function Loss: 0.02719

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12883
Policy Update Magnitude: 0.53121
Value Function Update Magnitude: 0.47411

Collected Steps per Second: 22,587.64033
Overall Steps per Second: 10,770.31407

Timestep Collection Time: 2.21466
Timestep Consumption Time: 2.42996
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.64462

Cumulative Model Updates: 200,282
Cumulative Timesteps: 1,670,149,544

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1670149544...
Checkpoint 1670149544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 64,723.05062
Policy Entropy: 3.73120
Value Function Loss: 0.02881

Mean KL Divergence: 0.01034
SB3 Clip Fraction: 0.13342
Policy Update Magnitude: 0.56051
Value Function Update Magnitude: 0.67705

Collected Steps per Second: 22,748.98746
Overall Steps per Second: 10,674.23037

Timestep Collection Time: 2.19834
Timestep Consumption Time: 2.48678
PPO Batch Consumption Time: 0.28732
Total Iteration Time: 4.68512

Cumulative Model Updates: 200,288
Cumulative Timesteps: 1,670,199,554

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,171.83090
Policy Entropy: 3.73486
Value Function Loss: 0.02770

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.12737
Policy Update Magnitude: 0.53187
Value Function Update Magnitude: 0.75634

Collected Steps per Second: 22,082.91606
Overall Steps per Second: 10,455.61119

Timestep Collection Time: 2.26483
Timestep Consumption Time: 2.51863
PPO Batch Consumption Time: 0.29117
Total Iteration Time: 4.78346

Cumulative Model Updates: 200,294
Cumulative Timesteps: 1,670,249,568

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1670249568...
Checkpoint 1670249568 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 991.99780
Policy Entropy: 3.73559
Value Function Loss: 0.02761

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.13791
Policy Update Magnitude: 0.54765
Value Function Update Magnitude: 0.76439

Collected Steps per Second: 22,701.25304
Overall Steps per Second: 10,635.86336

Timestep Collection Time: 2.20331
Timestep Consumption Time: 2.49945
PPO Batch Consumption Time: 0.28950
Total Iteration Time: 4.70277

Cumulative Model Updates: 200,300
Cumulative Timesteps: 1,670,299,586

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,313.40633
Policy Entropy: 3.74005
Value Function Loss: 0.02701

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.13719
Policy Update Magnitude: 0.53164
Value Function Update Magnitude: 0.82254

Collected Steps per Second: 21,984.82604
Overall Steps per Second: 10,480.11404

Timestep Collection Time: 2.27466
Timestep Consumption Time: 2.49704
PPO Batch Consumption Time: 0.28859
Total Iteration Time: 4.77170

Cumulative Model Updates: 200,306
Cumulative Timesteps: 1,670,349,594

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1670349594...
Checkpoint 1670349594 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 714,571.64048
Policy Entropy: 3.75071
Value Function Loss: 0.02855

Mean KL Divergence: 0.01230
SB3 Clip Fraction: 0.15317
Policy Update Magnitude: 0.59023
Value Function Update Magnitude: 0.88424

Collected Steps per Second: 22,354.62155
Overall Steps per Second: 10,631.13388

Timestep Collection Time: 2.23739
Timestep Consumption Time: 2.46728
PPO Batch Consumption Time: 0.28507
Total Iteration Time: 4.70467

Cumulative Model Updates: 200,312
Cumulative Timesteps: 1,670,399,610

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 302,068.76343
Policy Entropy: 3.74166
Value Function Loss: 0.03117

Mean KL Divergence: 0.02294
SB3 Clip Fraction: 0.23480
Policy Update Magnitude: 0.54098
Value Function Update Magnitude: 0.89789

Collected Steps per Second: 22,360.70768
Overall Steps per Second: 10,665.64706

Timestep Collection Time: 2.23651
Timestep Consumption Time: 2.45237
PPO Batch Consumption Time: 0.28785
Total Iteration Time: 4.68889

Cumulative Model Updates: 200,318
Cumulative Timesteps: 1,670,449,620

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1670449620...
Checkpoint 1670449620 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 26,410.49588
Policy Entropy: 3.74838
Value Function Loss: 0.04643

Mean KL Divergence: 0.01960
SB3 Clip Fraction: 0.21353
Policy Update Magnitude: 0.60222
Value Function Update Magnitude: 0.86963

Collected Steps per Second: 22,186.19185
Overall Steps per Second: 10,517.13324

Timestep Collection Time: 2.25483
Timestep Consumption Time: 2.50179
PPO Batch Consumption Time: 0.29132
Total Iteration Time: 4.75662

Cumulative Model Updates: 200,324
Cumulative Timesteps: 1,670,499,646

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,430.63260
Policy Entropy: 3.77101
Value Function Loss: 0.05109

Mean KL Divergence: 0.01309
SB3 Clip Fraction: 0.15428
Policy Update Magnitude: 0.84458
Value Function Update Magnitude: 0.84871

Collected Steps per Second: 21,760.93855
Overall Steps per Second: 10,405.54673

Timestep Collection Time: 2.29871
Timestep Consumption Time: 2.50854
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.80724

Cumulative Model Updates: 200,330
Cumulative Timesteps: 1,670,549,668

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1670549668...
Checkpoint 1670549668 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,349.01380
Policy Entropy: 3.80742
Value Function Loss: 0.05141

Mean KL Divergence: 0.01303
SB3 Clip Fraction: 0.15858
Policy Update Magnitude: 0.90361
Value Function Update Magnitude: 0.73286

Collected Steps per Second: 22,272.59080
Overall Steps per Second: 10,623.89779

Timestep Collection Time: 2.24527
Timestep Consumption Time: 2.46185
PPO Batch Consumption Time: 0.28429
Total Iteration Time: 4.70712

Cumulative Model Updates: 200,336
Cumulative Timesteps: 1,670,599,676

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 36.76153
Policy Entropy: 3.81256
Value Function Loss: 0.04109

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.10817
Policy Update Magnitude: 0.89484
Value Function Update Magnitude: 0.63475

Collected Steps per Second: 21,873.05408
Overall Steps per Second: 10,439.39872

Timestep Collection Time: 2.28683
Timestep Consumption Time: 2.50463
PPO Batch Consumption Time: 0.28887
Total Iteration Time: 4.79146

Cumulative Model Updates: 200,342
Cumulative Timesteps: 1,670,649,696

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1670649696...
Checkpoint 1670649696 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,671.98097
Policy Entropy: 3.81652
Value Function Loss: 0.03262

Mean KL Divergence: 0.00745
SB3 Clip Fraction: 0.09379
Policy Update Magnitude: 0.84680
Value Function Update Magnitude: 0.73694

Collected Steps per Second: 22,426.26044
Overall Steps per Second: 10,639.57366

Timestep Collection Time: 2.23042
Timestep Consumption Time: 2.47090
PPO Batch Consumption Time: 0.28460
Total Iteration Time: 4.70132

Cumulative Model Updates: 200,348
Cumulative Timesteps: 1,670,699,716

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,841.41364
Policy Entropy: 3.79285
Value Function Loss: 0.02763

Mean KL Divergence: 0.00663
SB3 Clip Fraction: 0.08329
Policy Update Magnitude: 0.74475
Value Function Update Magnitude: 0.90592

Collected Steps per Second: 22,724.41874
Overall Steps per Second: 10,598.06227

Timestep Collection Time: 2.20107
Timestep Consumption Time: 2.51847
PPO Batch Consumption Time: 0.29063
Total Iteration Time: 4.71954

Cumulative Model Updates: 200,354
Cumulative Timesteps: 1,670,749,734

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1670749734...
Checkpoint 1670749734 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,738.10011
Policy Entropy: 3.80460
Value Function Loss: 0.02472

Mean KL Divergence: 0.00605
SB3 Clip Fraction: 0.07474
Policy Update Magnitude: 0.66230
Value Function Update Magnitude: 0.96251

Collected Steps per Second: 22,707.27105
Overall Steps per Second: 10,673.93819

Timestep Collection Time: 2.20220
Timestep Consumption Time: 2.48267
PPO Batch Consumption Time: 0.28956
Total Iteration Time: 4.68487

Cumulative Model Updates: 200,360
Cumulative Timesteps: 1,670,799,740

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.77311
Value Function Loss: 0.02095

Mean KL Divergence: 0.00604
SB3 Clip Fraction: 0.07361
Policy Update Magnitude: 0.59788
Value Function Update Magnitude: 0.96091

Collected Steps per Second: 22,873.98827
Overall Steps per Second: 10,751.52779

Timestep Collection Time: 2.18606
Timestep Consumption Time: 2.46481
PPO Batch Consumption Time: 0.28437
Total Iteration Time: 4.65087

Cumulative Model Updates: 200,366
Cumulative Timesteps: 1,670,849,744

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1670849744...
Checkpoint 1670849744 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.75638
Value Function Loss: 0.01668

Mean KL Divergence: 0.00547
SB3 Clip Fraction: 0.06365
Policy Update Magnitude: 0.53877
Value Function Update Magnitude: 0.86519

Collected Steps per Second: 22,641.53198
Overall Steps per Second: 10,625.53020

Timestep Collection Time: 2.20957
Timestep Consumption Time: 2.49871
PPO Batch Consumption Time: 0.28883
Total Iteration Time: 4.70828

Cumulative Model Updates: 200,372
Cumulative Timesteps: 1,670,899,772

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.74530
Value Function Loss: 0.01139

Mean KL Divergence: 0.00562
SB3 Clip Fraction: 0.06538
Policy Update Magnitude: 0.48748
Value Function Update Magnitude: 0.68459

Collected Steps per Second: 23,143.81473
Overall Steps per Second: 10,883.04147

Timestep Collection Time: 2.16075
Timestep Consumption Time: 2.43429
PPO Batch Consumption Time: 0.27823
Total Iteration Time: 4.59504

Cumulative Model Updates: 200,378
Cumulative Timesteps: 1,670,949,780

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1670949780...
Checkpoint 1670949780 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.73194
Value Function Loss: 0.00967

Mean KL Divergence: 0.00599
SB3 Clip Fraction: 0.07204
Policy Update Magnitude: 0.41308
Value Function Update Magnitude: 0.47886

Collected Steps per Second: 22,775.54336
Overall Steps per Second: 10,672.87239

Timestep Collection Time: 2.19595
Timestep Consumption Time: 2.49013
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.68609

Cumulative Model Updates: 200,384
Cumulative Timesteps: 1,670,999,794

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.73252
Value Function Loss: 0.00919

Mean KL Divergence: 0.00611
SB3 Clip Fraction: 0.07611
Policy Update Magnitude: 0.34846
Value Function Update Magnitude: 0.32707

Collected Steps per Second: 22,317.78859
Overall Steps per Second: 10,514.52523

Timestep Collection Time: 2.24135
Timestep Consumption Time: 2.51607
PPO Batch Consumption Time: 0.29150
Total Iteration Time: 4.75742

Cumulative Model Updates: 200,390
Cumulative Timesteps: 1,671,049,816

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1671049816...
Checkpoint 1671049816 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.72730
Value Function Loss: 0.00971

Mean KL Divergence: 0.00405
SB3 Clip Fraction: 0.04180
Policy Update Magnitude: 0.35818
Value Function Update Magnitude: 0.33966

Collected Steps per Second: 22,240.39236
Overall Steps per Second: 10,545.89887

Timestep Collection Time: 2.24960
Timestep Consumption Time: 2.49461
PPO Batch Consumption Time: 0.28894
Total Iteration Time: 4.74421

Cumulative Model Updates: 200,396
Cumulative Timesteps: 1,671,099,848

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.72394
Value Function Loss: 0.01027

Mean KL Divergence: 0.00438
SB3 Clip Fraction: 0.04699
Policy Update Magnitude: 0.40989
Value Function Update Magnitude: 0.43077

Collected Steps per Second: 22,610.32095
Overall Steps per Second: 10,665.71496

Timestep Collection Time: 2.21156
Timestep Consumption Time: 2.47674
PPO Batch Consumption Time: 0.28807
Total Iteration Time: 4.68829

Cumulative Model Updates: 200,402
Cumulative Timesteps: 1,671,149,852

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1671149852...
Checkpoint 1671149852 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.72780
Value Function Loss: 0.01052

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06511
Policy Update Magnitude: 0.45615
Value Function Update Magnitude: 0.44400

Collected Steps per Second: 22,355.43079
Overall Steps per Second: 10,597.26303

Timestep Collection Time: 2.23758
Timestep Consumption Time: 2.48270
PPO Batch Consumption Time: 0.29017
Total Iteration Time: 4.72028

Cumulative Model Updates: 200,408
Cumulative Timesteps: 1,671,199,874

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.72285
Value Function Loss: 0.01220

Mean KL Divergence: 0.00516
SB3 Clip Fraction: 0.05809
Policy Update Magnitude: 0.50173
Value Function Update Magnitude: 0.50174

Collected Steps per Second: 22,487.96722
Overall Steps per Second: 10,744.93773

Timestep Collection Time: 2.22394
Timestep Consumption Time: 2.43053
PPO Batch Consumption Time: 0.27800
Total Iteration Time: 4.65447

Cumulative Model Updates: 200,414
Cumulative Timesteps: 1,671,249,886

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1671249886...
Checkpoint 1671249886 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.72612
Value Function Loss: 0.01321

Mean KL Divergence: 0.00509
SB3 Clip Fraction: 0.05843
Policy Update Magnitude: 0.56240
Value Function Update Magnitude: 0.60633

Collected Steps per Second: 22,475.86858
Overall Steps per Second: 10,664.94335

Timestep Collection Time: 2.22479
Timestep Consumption Time: 2.46385
PPO Batch Consumption Time: 0.27734
Total Iteration Time: 4.68863

Cumulative Model Updates: 200,420
Cumulative Timesteps: 1,671,299,890

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,194.72777
Policy Entropy: 3.72503
Value Function Loss: 0.01466

Mean KL Divergence: 0.00448
SB3 Clip Fraction: 0.04664
Policy Update Magnitude: 0.56553
Value Function Update Magnitude: 0.64319

Collected Steps per Second: 22,683.20684
Overall Steps per Second: 10,818.28526

Timestep Collection Time: 2.20568
Timestep Consumption Time: 2.41908
PPO Batch Consumption Time: 0.27777
Total Iteration Time: 4.62476

Cumulative Model Updates: 200,426
Cumulative Timesteps: 1,671,349,922

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1671349922...
Checkpoint 1671349922 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,951.28474
Policy Entropy: 3.72686
Value Function Loss: 0.01606

Mean KL Divergence: 0.00649
SB3 Clip Fraction: 0.07950
Policy Update Magnitude: 0.58785
Value Function Update Magnitude: 0.67206

Collected Steps per Second: 22,279.72950
Overall Steps per Second: 10,747.53450

Timestep Collection Time: 2.24563
Timestep Consumption Time: 2.40958
PPO Batch Consumption Time: 0.27687
Total Iteration Time: 4.65521

Cumulative Model Updates: 200,432
Cumulative Timesteps: 1,671,399,954

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,951.28474
Policy Entropy: 3.71053
Value Function Loss: 0.01960

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12912
Policy Update Magnitude: 0.52070
Value Function Update Magnitude: 0.62539

Collected Steps per Second: 22,509.63425
Overall Steps per Second: 10,782.12845

Timestep Collection Time: 2.22145
Timestep Consumption Time: 2.41623
PPO Batch Consumption Time: 0.27869
Total Iteration Time: 4.63767

Cumulative Model Updates: 200,438
Cumulative Timesteps: 1,671,449,958

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1671449958...
Checkpoint 1671449958 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,951.28474
Policy Entropy: 3.71961
Value Function Loss: 0.01902

Mean KL Divergence: 0.01482
SB3 Clip Fraction: 0.18423
Policy Update Magnitude: 0.52636
Value Function Update Magnitude: 0.45899

Collected Steps per Second: 21,712.09027
Overall Steps per Second: 10,757.43141

Timestep Collection Time: 2.30342
Timestep Consumption Time: 2.34565
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.64907

Cumulative Model Updates: 200,444
Cumulative Timesteps: 1,671,499,970

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,951.28474
Policy Entropy: 3.71694
Value Function Loss: 0.01816

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.17012
Policy Update Magnitude: 0.45331
Value Function Update Magnitude: 0.33653

Collected Steps per Second: 21,589.56996
Overall Steps per Second: 10,615.06004

Timestep Collection Time: 2.31714
Timestep Consumption Time: 2.39560
PPO Batch Consumption Time: 0.28900
Total Iteration Time: 4.71274

Cumulative Model Updates: 200,450
Cumulative Timesteps: 1,671,549,996

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1671549996...
Checkpoint 1671549996 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,951.28474
Policy Entropy: 3.75792
Value Function Loss: 0.01427

Mean KL Divergence: 0.01182
SB3 Clip Fraction: 0.15433
Policy Update Magnitude: 0.36672
Value Function Update Magnitude: 0.26125

Collected Steps per Second: 21,591.58375
Overall Steps per Second: 10,481.77997

Timestep Collection Time: 2.31600
Timestep Consumption Time: 2.45476
PPO Batch Consumption Time: 0.28305
Total Iteration Time: 4.77075

Cumulative Model Updates: 200,456
Cumulative Timesteps: 1,671,600,002

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,951.28474
Policy Entropy: 3.72902
Value Function Loss: 0.01568

Mean KL Divergence: 0.01130
SB3 Clip Fraction: 0.14586
Policy Update Magnitude: 0.31037
Value Function Update Magnitude: 0.20745

Collected Steps per Second: 22,087.95552
Overall Steps per Second: 10,566.55584

Timestep Collection Time: 2.26494
Timestep Consumption Time: 2.46962
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.73456

Cumulative Model Updates: 200,462
Cumulative Timesteps: 1,671,650,030

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1671650030...
Checkpoint 1671650030 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,951.28474
Policy Entropy: 3.75687
Value Function Loss: 0.01410

Mean KL Divergence: 0.01208
SB3 Clip Fraction: 0.15889
Policy Update Magnitude: 0.28552
Value Function Update Magnitude: 0.17280

Collected Steps per Second: 22,189.37831
Overall Steps per Second: 10,634.58517

Timestep Collection Time: 2.25423
Timestep Consumption Time: 2.44929
PPO Batch Consumption Time: 0.28996
Total Iteration Time: 4.70352

Cumulative Model Updates: 200,468
Cumulative Timesteps: 1,671,700,050

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,951.28474
Policy Entropy: 3.73433
Value Function Loss: 0.01322

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15701
Policy Update Magnitude: 0.26172
Value Function Update Magnitude: 0.18254

Collected Steps per Second: 22,643.34612
Overall Steps per Second: 10,775.08668

Timestep Collection Time: 2.20948
Timestep Consumption Time: 2.43364
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.64312

Cumulative Model Updates: 200,474
Cumulative Timesteps: 1,671,750,080

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1671750080...
Checkpoint 1671750080 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 500,572.75847
Policy Entropy: 3.74317
Value Function Loss: 0.01357

Mean KL Divergence: 0.01179
SB3 Clip Fraction: 0.15411
Policy Update Magnitude: 0.26181
Value Function Update Magnitude: 0.28671

Collected Steps per Second: 22,253.58262
Overall Steps per Second: 10,707.45007

Timestep Collection Time: 2.24728
Timestep Consumption Time: 2.42330
PPO Batch Consumption Time: 0.27600
Total Iteration Time: 4.67058

Cumulative Model Updates: 200,480
Cumulative Timesteps: 1,671,800,090

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 141,395.31381
Policy Entropy: 3.72520
Value Function Loss: 0.01677

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.15705
Policy Update Magnitude: 0.29588
Value Function Update Magnitude: 0.33551

Collected Steps per Second: 23,102.61741
Overall Steps per Second: 10,809.20829

Timestep Collection Time: 2.16495
Timestep Consumption Time: 2.46222
PPO Batch Consumption Time: 0.27853
Total Iteration Time: 4.62717

Cumulative Model Updates: 200,486
Cumulative Timesteps: 1,671,850,106

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1671850106...
Checkpoint 1671850106 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 39,942.75174
Policy Entropy: 3.73801
Value Function Loss: 0.01896

Mean KL Divergence: 0.01193
SB3 Clip Fraction: 0.15446
Policy Update Magnitude: 0.31351
Value Function Update Magnitude: 0.35137

Collected Steps per Second: 22,672.31729
Overall Steps per Second: 10,658.92181

Timestep Collection Time: 2.20613
Timestep Consumption Time: 2.48647
PPO Batch Consumption Time: 0.28654
Total Iteration Time: 4.69259

Cumulative Model Updates: 200,492
Cumulative Timesteps: 1,671,900,124

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,925.01990
Policy Entropy: 3.73499
Value Function Loss: 0.02122

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15196
Policy Update Magnitude: 0.35410
Value Function Update Magnitude: 0.44118

Collected Steps per Second: 22,896.58673
Overall Steps per Second: 10,847.70107

Timestep Collection Time: 2.18391
Timestep Consumption Time: 2.42573
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.60964

Cumulative Model Updates: 200,498
Cumulative Timesteps: 1,671,950,128

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1671950128...
Checkpoint 1671950128 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 124,547.35597
Policy Entropy: 3.74194
Value Function Loss: 0.02297

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.16718
Policy Update Magnitude: 0.42273
Value Function Update Magnitude: 0.67893

Collected Steps per Second: 22,611.94504
Overall Steps per Second: 10,750.68009

Timestep Collection Time: 2.21184
Timestep Consumption Time: 2.44033
PPO Batch Consumption Time: 0.27656
Total Iteration Time: 4.65217

Cumulative Model Updates: 200,504
Cumulative Timesteps: 1,672,000,142

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 63,463.62173
Policy Entropy: 3.75235
Value Function Loss: 0.02278

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.14276
Policy Update Magnitude: 0.44886
Value Function Update Magnitude: 0.89956

Collected Steps per Second: 22,656.73171
Overall Steps per Second: 10,781.28718

Timestep Collection Time: 2.20729
Timestep Consumption Time: 2.43130
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.63859

Cumulative Model Updates: 200,510
Cumulative Timesteps: 1,672,050,152

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1672050152...
Checkpoint 1672050152 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 14,540.07200
Policy Entropy: 3.75279
Value Function Loss: 0.02333

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13479
Policy Update Magnitude: 0.46629
Value Function Update Magnitude: 0.91657

Collected Steps per Second: 22,322.46144
Overall Steps per Second: 10,696.18008

Timestep Collection Time: 2.24106
Timestep Consumption Time: 2.43594
PPO Batch Consumption Time: 0.27827
Total Iteration Time: 4.67700

Cumulative Model Updates: 200,516
Cumulative Timesteps: 1,672,100,178

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 83,923.33697
Policy Entropy: 3.73789
Value Function Loss: 0.02152

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13465
Policy Update Magnitude: 0.49187
Value Function Update Magnitude: 0.91962

Collected Steps per Second: 21,259.04571
Overall Steps per Second: 10,468.93604

Timestep Collection Time: 2.35279
Timestep Consumption Time: 2.42497
PPO Batch Consumption Time: 0.27736
Total Iteration Time: 4.77775

Cumulative Model Updates: 200,522
Cumulative Timesteps: 1,672,150,196

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1672150196...
Checkpoint 1672150196 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 96,472.19882
Policy Entropy: 3.74180
Value Function Loss: 0.02198

Mean KL Divergence: 0.00956
SB3 Clip Fraction: 0.12952
Policy Update Magnitude: 0.47702
Value Function Update Magnitude: 0.82418

Collected Steps per Second: 22,094.74765
Overall Steps per Second: 10,664.63373

Timestep Collection Time: 2.26361
Timestep Consumption Time: 2.42609
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.68971

Cumulative Model Updates: 200,528
Cumulative Timesteps: 1,672,200,210

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 156,325.01628
Policy Entropy: 3.75864
Value Function Loss: 0.02597

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12106
Policy Update Magnitude: 0.50438
Value Function Update Magnitude: 0.66207

Collected Steps per Second: 22,325.28175
Overall Steps per Second: 10,660.50336

Timestep Collection Time: 2.24015
Timestep Consumption Time: 2.45118
PPO Batch Consumption Time: 0.28743
Total Iteration Time: 4.69134

Cumulative Model Updates: 200,534
Cumulative Timesteps: 1,672,250,222

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1672250222...
Checkpoint 1672250222 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 21,799.67787
Policy Entropy: 3.78648
Value Function Loss: 0.03645

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.11862
Policy Update Magnitude: 0.56731
Value Function Update Magnitude: 0.62925

Collected Steps per Second: 22,642.26574
Overall Steps per Second: 10,661.05537

Timestep Collection Time: 2.20835
Timestep Consumption Time: 2.48181
PPO Batch Consumption Time: 0.28744
Total Iteration Time: 4.69015

Cumulative Model Updates: 200,540
Cumulative Timesteps: 1,672,300,224

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65.49745
Policy Entropy: 3.83457
Value Function Loss: 0.03809

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.11903
Policy Update Magnitude: 0.62400
Value Function Update Magnitude: 0.65569

Collected Steps per Second: 22,579.74488
Overall Steps per Second: 10,697.11997

Timestep Collection Time: 2.21437
Timestep Consumption Time: 2.45978
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.67416

Cumulative Model Updates: 200,546
Cumulative Timesteps: 1,672,350,224

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1672350224...
Checkpoint 1672350224 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.54377
Policy Entropy: 3.86628
Value Function Loss: 0.04011

Mean KL Divergence: 0.00902
SB3 Clip Fraction: 0.11575
Policy Update Magnitude: 0.65472
Value Function Update Magnitude: 0.66146

Collected Steps per Second: 22,565.83280
Overall Steps per Second: 10,659.66420

Timestep Collection Time: 2.21698
Timestep Consumption Time: 2.47623
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.69321

Cumulative Model Updates: 200,552
Cumulative Timesteps: 1,672,400,252

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19.76581
Policy Entropy: 3.86575
Value Function Loss: 0.03311

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12042
Policy Update Magnitude: 0.55589
Value Function Update Magnitude: 0.70043

Collected Steps per Second: 22,585.34006
Overall Steps per Second: 10,845.96605

Timestep Collection Time: 2.21462
Timestep Consumption Time: 2.39705
PPO Batch Consumption Time: 0.27873
Total Iteration Time: 4.61167

Cumulative Model Updates: 200,558
Cumulative Timesteps: 1,672,450,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1672450270...
Checkpoint 1672450270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 7,482.50876
Policy Entropy: 3.84458
Value Function Loss: 0.03826

Mean KL Divergence: 0.01069
SB3 Clip Fraction: 0.13694
Policy Update Magnitude: 0.47901
Value Function Update Magnitude: 0.63163

Collected Steps per Second: 22,649.92636
Overall Steps per Second: 10,696.29740

Timestep Collection Time: 2.20822
Timestep Consumption Time: 2.46779
PPO Batch Consumption Time: 0.29206
Total Iteration Time: 4.67601

Cumulative Model Updates: 200,564
Cumulative Timesteps: 1,672,500,286

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,309.37832
Policy Entropy: 3.83514
Value Function Loss: 0.03431

Mean KL Divergence: 0.01003
SB3 Clip Fraction: 0.13211
Policy Update Magnitude: 0.48989
Value Function Update Magnitude: 0.58442

Collected Steps per Second: 22,447.66446
Overall Steps per Second: 10,638.45403

Timestep Collection Time: 2.22776
Timestep Consumption Time: 2.47292
PPO Batch Consumption Time: 0.28742
Total Iteration Time: 4.70068

Cumulative Model Updates: 200,570
Cumulative Timesteps: 1,672,550,294

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1672550294...
Checkpoint 1672550294 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 144.14488
Policy Entropy: 3.80117
Value Function Loss: 0.03860

Mean KL Divergence: 0.01036
SB3 Clip Fraction: 0.12999
Policy Update Magnitude: 0.53933
Value Function Update Magnitude: 0.61720

Collected Steps per Second: 22,521.66464
Overall Steps per Second: 10,815.21774

Timestep Collection Time: 2.22106
Timestep Consumption Time: 2.40409
PPO Batch Consumption Time: 0.27818
Total Iteration Time: 4.62515

Cumulative Model Updates: 200,576
Cumulative Timesteps: 1,672,600,316

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,380.48728
Policy Entropy: 3.77943
Value Function Loss: 0.03281

Mean KL Divergence: 0.01124
SB3 Clip Fraction: 0.14204
Policy Update Magnitude: 0.59957
Value Function Update Magnitude: 0.69378

Collected Steps per Second: 22,196.86275
Overall Steps per Second: 10,507.32607

Timestep Collection Time: 2.25320
Timestep Consumption Time: 2.50672
PPO Batch Consumption Time: 0.29059
Total Iteration Time: 4.75992

Cumulative Model Updates: 200,582
Cumulative Timesteps: 1,672,650,330

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1672650330...
Checkpoint 1672650330 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 8,080.75834
Policy Entropy: 3.74213
Value Function Loss: 0.03362

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.15374
Policy Update Magnitude: 0.63634
Value Function Update Magnitude: 0.77213

Collected Steps per Second: 21,637.12956
Overall Steps per Second: 10,564.42694

Timestep Collection Time: 2.31094
Timestep Consumption Time: 2.42212
PPO Batch Consumption Time: 0.27781
Total Iteration Time: 4.73305

Cumulative Model Updates: 200,588
Cumulative Timesteps: 1,672,700,332

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 626.18804
Policy Entropy: 3.72679
Value Function Loss: 0.03983

Mean KL Divergence: 0.01930
SB3 Clip Fraction: 0.21032
Policy Update Magnitude: 0.61377
Value Function Update Magnitude: 0.65616

Collected Steps per Second: 22,043.32258
Overall Steps per Second: 10,551.74265

Timestep Collection Time: 2.26917
Timestep Consumption Time: 2.47128
PPO Batch Consumption Time: 0.28454
Total Iteration Time: 4.74045

Cumulative Model Updates: 200,594
Cumulative Timesteps: 1,672,750,352

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1672750352...
Checkpoint 1672750352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 174,847.21213
Policy Entropy: 3.75809
Value Function Loss: 0.04624

Mean KL Divergence: 0.01238
SB3 Clip Fraction: 0.15291
Policy Update Magnitude: 0.73013
Value Function Update Magnitude: 0.58511

Collected Steps per Second: 21,696.95171
Overall Steps per Second: 10,556.18992

Timestep Collection Time: 2.30484
Timestep Consumption Time: 2.43248
PPO Batch Consumption Time: 0.27716
Total Iteration Time: 4.73732

Cumulative Model Updates: 200,600
Cumulative Timesteps: 1,672,800,360

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 491.20531
Policy Entropy: 3.79450
Value Function Loss: 0.04689

Mean KL Divergence: 0.01070
SB3 Clip Fraction: 0.13404
Policy Update Magnitude: 0.87209
Value Function Update Magnitude: 0.58980

Collected Steps per Second: 22,138.04256
Overall Steps per Second: 10,494.21828

Timestep Collection Time: 2.25856
Timestep Consumption Time: 2.50597
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.76453

Cumulative Model Updates: 200,606
Cumulative Timesteps: 1,672,850,360

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1672850360...
Checkpoint 1672850360 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,409.72241
Policy Entropy: 3.83288
Value Function Loss: 0.04249

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.86744
Value Function Update Magnitude: 0.64230

Collected Steps per Second: 22,751.50819
Overall Steps per Second: 10,665.29505

Timestep Collection Time: 2.19898
Timestep Consumption Time: 2.49194
PPO Batch Consumption Time: 0.28939
Total Iteration Time: 4.69092

Cumulative Model Updates: 200,612
Cumulative Timesteps: 1,672,900,390

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,138.37126
Policy Entropy: 3.81706
Value Function Loss: 0.03647

Mean KL Divergence: 0.00978
SB3 Clip Fraction: 0.12819
Policy Update Magnitude: 0.76505
Value Function Update Magnitude: 0.70968

Collected Steps per Second: 22,879.88904
Overall Steps per Second: 10,841.29634

Timestep Collection Time: 2.18611
Timestep Consumption Time: 2.42754
PPO Batch Consumption Time: 0.27854
Total Iteration Time: 4.61365

Cumulative Model Updates: 200,618
Cumulative Timesteps: 1,672,950,408

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1672950408...
Checkpoint 1672950408 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16,663.14234
Policy Entropy: 3.81055
Value Function Loss: 0.02889

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.61935
Value Function Update Magnitude: 0.81900

Collected Steps per Second: 22,622.00329
Overall Steps per Second: 10,702.24286

Timestep Collection Time: 2.21024
Timestep Consumption Time: 2.46168
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.67192

Cumulative Model Updates: 200,624
Cumulative Timesteps: 1,673,000,408

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 233,548.07255
Policy Entropy: 3.78613
Value Function Loss: 0.02954

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.12727
Policy Update Magnitude: 0.54191
Value Function Update Magnitude: 0.93965

Collected Steps per Second: 22,566.30764
Overall Steps per Second: 10,629.28800

Timestep Collection Time: 2.21773
Timestep Consumption Time: 2.49058
PPO Batch Consumption Time: 0.28977
Total Iteration Time: 4.70831

Cumulative Model Updates: 200,630
Cumulative Timesteps: 1,673,050,454

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1673050454...
Checkpoint 1673050454 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,735.61293
Policy Entropy: 3.83305
Value Function Loss: 0.03080

Mean KL Divergence: 0.00812
SB3 Clip Fraction: 0.10845
Policy Update Magnitude: 0.55181
Value Function Update Magnitude: 1.03178

Collected Steps per Second: 22,733.54029
Overall Steps per Second: 10,871.55455

Timestep Collection Time: 2.20036
Timestep Consumption Time: 2.40082
PPO Batch Consumption Time: 0.27849
Total Iteration Time: 4.60118

Cumulative Model Updates: 200,636
Cumulative Timesteps: 1,673,100,476

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 93.09982
Policy Entropy: 3.83257
Value Function Loss: 0.03697

Mean KL Divergence: 0.00908
SB3 Clip Fraction: 0.12115
Policy Update Magnitude: 0.54933
Value Function Update Magnitude: 1.04364

Collected Steps per Second: 22,770.53709
Overall Steps per Second: 10,707.47840

Timestep Collection Time: 2.19591
Timestep Consumption Time: 2.47391
PPO Batch Consumption Time: 0.28760
Total Iteration Time: 4.66982

Cumulative Model Updates: 200,642
Cumulative Timesteps: 1,673,150,478

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1673150478...
Checkpoint 1673150478 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10.08981
Policy Entropy: 3.85990
Value Function Loss: 0.03411

Mean KL Divergence: 0.00793
SB3 Clip Fraction: 0.10945
Policy Update Magnitude: 0.55857
Value Function Update Magnitude: 1.02160

Collected Steps per Second: 22,524.70843
Overall Steps per Second: 10,833.98272

Timestep Collection Time: 2.22041
Timestep Consumption Time: 2.39599
PPO Batch Consumption Time: 0.27805
Total Iteration Time: 4.61640

Cumulative Model Updates: 200,648
Cumulative Timesteps: 1,673,200,492

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27,251.31563
Policy Entropy: 3.84276
Value Function Loss: 0.03057

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12437
Policy Update Magnitude: 0.49589
Value Function Update Magnitude: 0.99347

Collected Steps per Second: 22,359.98585
Overall Steps per Second: 10,651.86768

Timestep Collection Time: 2.23658
Timestep Consumption Time: 2.45837
PPO Batch Consumption Time: 0.29018
Total Iteration Time: 4.69495

Cumulative Model Updates: 200,654
Cumulative Timesteps: 1,673,250,502

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1673250502...
Checkpoint 1673250502 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 621.54219
Policy Entropy: 3.82982
Value Function Loss: 0.02937

Mean KL Divergence: 0.00835
SB3 Clip Fraction: 0.11630
Policy Update Magnitude: 0.44527
Value Function Update Magnitude: 0.95243

Collected Steps per Second: 22,299.93493
Overall Steps per Second: 10,570.26602

Timestep Collection Time: 2.24288
Timestep Consumption Time: 2.48889
PPO Batch Consumption Time: 0.29062
Total Iteration Time: 4.73176

Cumulative Model Updates: 200,660
Cumulative Timesteps: 1,673,300,518

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 65,693.46577
Policy Entropy: 3.82867
Value Function Loss: 0.02903

Mean KL Divergence: 0.00852
SB3 Clip Fraction: 0.11855
Policy Update Magnitude: 0.49977
Value Function Update Magnitude: 0.94563

Collected Steps per Second: 22,773.37292
Overall Steps per Second: 10,855.69048

Timestep Collection Time: 2.19581
Timestep Consumption Time: 2.41062
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.60643

Cumulative Model Updates: 200,666
Cumulative Timesteps: 1,673,350,524

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1673350524...
Checkpoint 1673350524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 658.86269
Policy Entropy: 3.80844
Value Function Loss: 0.03036

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11875
Policy Update Magnitude: 0.52484
Value Function Update Magnitude: 0.87732

Collected Steps per Second: 22,166.09282
Overall Steps per Second: 10,602.16265

Timestep Collection Time: 2.25669
Timestep Consumption Time: 2.46140
PPO Batch Consumption Time: 0.27911
Total Iteration Time: 4.71809

Cumulative Model Updates: 200,672
Cumulative Timesteps: 1,673,400,546

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 33.86817
Policy Entropy: 3.81694
Value Function Loss: 0.02894

Mean KL Divergence: 0.00949
SB3 Clip Fraction: 0.12634
Policy Update Magnitude: 0.53087
Value Function Update Magnitude: 0.75296

Collected Steps per Second: 22,948.58007
Overall Steps per Second: 10,797.26142

Timestep Collection Time: 2.17939
Timestep Consumption Time: 2.45271
PPO Batch Consumption Time: 0.27839
Total Iteration Time: 4.63210

Cumulative Model Updates: 200,678
Cumulative Timesteps: 1,673,450,560

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1673450560...
Checkpoint 1673450560 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11,165.89745
Policy Entropy: 3.78668
Value Function Loss: 0.03064

Mean KL Divergence: 0.01088
SB3 Clip Fraction: 0.14454
Policy Update Magnitude: 0.48092
Value Function Update Magnitude: 0.68931

Collected Steps per Second: 22,521.43716
Overall Steps per Second: 10,783.07308

Timestep Collection Time: 2.22037
Timestep Consumption Time: 2.41708
PPO Batch Consumption Time: 0.27750
Total Iteration Time: 4.63745

Cumulative Model Updates: 200,684
Cumulative Timesteps: 1,673,500,566

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37,446.76999
Policy Entropy: 3.77110
Value Function Loss: 0.03743

Mean KL Divergence: 0.01454
SB3 Clip Fraction: 0.17468
Policy Update Magnitude: 0.48127
Value Function Update Magnitude: 0.62075

Collected Steps per Second: 22,851.31011
Overall Steps per Second: 10,833.83752

Timestep Collection Time: 2.18902
Timestep Consumption Time: 2.42818
PPO Batch Consumption Time: 0.27806
Total Iteration Time: 4.61720

Cumulative Model Updates: 200,690
Cumulative Timesteps: 1,673,550,588

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1673550588...
Checkpoint 1673550588 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 121.93446
Policy Entropy: 3.77523
Value Function Loss: 0.04196

Mean KL Divergence: 0.01229
SB3 Clip Fraction: 0.15511
Policy Update Magnitude: 0.56573
Value Function Update Magnitude: 0.63662

Collected Steps per Second: 22,594.25363
Overall Steps per Second: 10,682.37288

Timestep Collection Time: 2.21366
Timestep Consumption Time: 2.46845
PPO Batch Consumption Time: 0.29047
Total Iteration Time: 4.68211

Cumulative Model Updates: 200,696
Cumulative Timesteps: 1,673,600,604

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,361.73291
Policy Entropy: 3.82023
Value Function Loss: 0.03971

Mean KL Divergence: 0.01425
SB3 Clip Fraction: 0.17332
Policy Update Magnitude: 0.59209
Value Function Update Magnitude: 0.69081

Collected Steps per Second: 22,430.71284
Overall Steps per Second: 10,815.43004

Timestep Collection Time: 2.22918
Timestep Consumption Time: 2.39403
PPO Batch Consumption Time: 0.27770
Total Iteration Time: 4.62321

Cumulative Model Updates: 200,702
Cumulative Timesteps: 1,673,650,606

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1673650606...
Checkpoint 1673650606 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23.73897
Policy Entropy: 3.84478
Value Function Loss: 0.03363

Mean KL Divergence: 0.00958
SB3 Clip Fraction: 0.12293
Policy Update Magnitude: 0.55836
Value Function Update Magnitude: 0.70718

Collected Steps per Second: 21,978.85553
Overall Steps per Second: 10,689.19123

Timestep Collection Time: 2.27546
Timestep Consumption Time: 2.40329
PPO Batch Consumption Time: 0.27820
Total Iteration Time: 4.67875

Cumulative Model Updates: 200,708
Cumulative Timesteps: 1,673,700,618

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 27.03100
Policy Entropy: 3.85426
Value Function Loss: 0.02771

Mean KL Divergence: 0.00536
SB3 Clip Fraction: 0.06758
Policy Update Magnitude: 0.56603
Value Function Update Magnitude: 0.86846

Collected Steps per Second: 22,429.19532
Overall Steps per Second: 10,580.08908

Timestep Collection Time: 2.22968
Timestep Consumption Time: 2.49712
PPO Batch Consumption Time: 0.29152
Total Iteration Time: 4.72680

Cumulative Model Updates: 200,714
Cumulative Timesteps: 1,673,750,628

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1673750628...
Checkpoint 1673750628 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 160,066.33563
Policy Entropy: 3.83497
Value Function Loss: 0.02825

Mean KL Divergence: 0.00581
SB3 Clip Fraction: 0.07376
Policy Update Magnitude: 0.57724
Value Function Update Magnitude: 0.93033

Collected Steps per Second: 22,272.20470
Overall Steps per Second: 10,568.33195

Timestep Collection Time: 2.24639
Timestep Consumption Time: 2.48776
PPO Batch Consumption Time: 0.29055
Total Iteration Time: 4.73414

Cumulative Model Updates: 200,720
Cumulative Timesteps: 1,673,800,660

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,632.23235
Policy Entropy: 3.84034
Value Function Loss: 0.02740

Mean KL Divergence: 0.00627
SB3 Clip Fraction: 0.07981
Policy Update Magnitude: 0.53899
Value Function Update Magnitude: 0.92991

Collected Steps per Second: 22,470.04850
Overall Steps per Second: 10,614.20766

Timestep Collection Time: 2.22714
Timestep Consumption Time: 2.48767
PPO Batch Consumption Time: 0.28910
Total Iteration Time: 4.71481

Cumulative Model Updates: 200,726
Cumulative Timesteps: 1,673,850,704

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1673850704...
Checkpoint 1673850704 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 455.78288
Policy Entropy: 3.82110
Value Function Loss: 0.02410

Mean KL Divergence: 0.00524
SB3 Clip Fraction: 0.06265
Policy Update Magnitude: 0.51444
Value Function Update Magnitude: 0.86139

Collected Steps per Second: 22,181.35387
Overall Steps per Second: 10,545.84742

Timestep Collection Time: 2.25532
Timestep Consumption Time: 2.48835
PPO Batch Consumption Time: 0.29170
Total Iteration Time: 4.74367

Cumulative Model Updates: 200,732
Cumulative Timesteps: 1,673,900,730

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84.12786
Policy Entropy: 3.79607
Value Function Loss: 0.02021

Mean KL Divergence: 0.00478
SB3 Clip Fraction: 0.05446
Policy Update Magnitude: 0.46664
Value Function Update Magnitude: 0.72586

Collected Steps per Second: 22,921.90681
Overall Steps per Second: 10,805.75325

Timestep Collection Time: 2.18132
Timestep Consumption Time: 2.44585
PPO Batch Consumption Time: 0.27762
Total Iteration Time: 4.62716

Cumulative Model Updates: 200,738
Cumulative Timesteps: 1,673,950,730

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1673950730...
Checkpoint 1673950730 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 11.81490
Policy Entropy: 3.77933
Value Function Loss: 0.01740

Mean KL Divergence: 0.00451
SB3 Clip Fraction: 0.05017
Policy Update Magnitude: 0.44578
Value Function Update Magnitude: 0.65333

Collected Steps per Second: 23,014.14211
Overall Steps per Second: 10,720.20292

Timestep Collection Time: 2.17310
Timestep Consumption Time: 2.49211
PPO Batch Consumption Time: 0.29196
Total Iteration Time: 4.66521

Cumulative Model Updates: 200,744
Cumulative Timesteps: 1,674,000,742

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 49,770.01167
Policy Entropy: 3.75992
Value Function Loss: 0.02124

Mean KL Divergence: 0.00455
SB3 Clip Fraction: 0.05105
Policy Update Magnitude: 0.51005
Value Function Update Magnitude: 0.70325

Collected Steps per Second: 21,583.39973
Overall Steps per Second: 10,385.62423

Timestep Collection Time: 2.31734
Timestep Consumption Time: 2.49855
PPO Batch Consumption Time: 0.28873
Total Iteration Time: 4.81589

Cumulative Model Updates: 200,750
Cumulative Timesteps: 1,674,050,758

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1674050758...
Checkpoint 1674050758 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 4,919.66956
Policy Entropy: 3.75317
Value Function Loss: 0.02272

Mean KL Divergence: 0.00575
SB3 Clip Fraction: 0.06834
Policy Update Magnitude: 0.58336
Value Function Update Magnitude: 0.78918

Collected Steps per Second: 22,338.97002
Overall Steps per Second: 10,724.99978

Timestep Collection Time: 2.23896
Timestep Consumption Time: 2.42454
PPO Batch Consumption Time: 0.27686
Total Iteration Time: 4.66350

Cumulative Model Updates: 200,756
Cumulative Timesteps: 1,674,100,774

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 920.09959
Policy Entropy: 3.74495
Value Function Loss: 0.02429

Mean KL Divergence: 0.00600
SB3 Clip Fraction: 0.07236
Policy Update Magnitude: 0.58399
Value Function Update Magnitude: 0.75936

Collected Steps per Second: 22,561.53333
Overall Steps per Second: 10,770.37307

Timestep Collection Time: 2.21820
Timestep Consumption Time: 2.42844
PPO Batch Consumption Time: 0.27757
Total Iteration Time: 4.64664

Cumulative Model Updates: 200,762
Cumulative Timesteps: 1,674,150,820

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


Saving checkpoint 1674150820...
Checkpoint 1674150820 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 749.71969
Policy Entropy: 3.74095
Value Function Loss: 0.02881

Mean KL Divergence: 0.00550
SB3 Clip Fraction: 0.06416
Policy Update Magnitude: 0.57709
Value Function Update Magnitude: 0.59583

Collected Steps per Second: 22,510.95059
Overall Steps per Second: 10,782.64088

Timestep Collection Time: 2.22132
Timestep Consumption Time: 2.41614
PPO Batch Consumption Time: 0.27625
Total Iteration Time: 4.63745

Cumulative Model Updates: 200,768
Cumulative Timesteps: 1,674,200,824

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 48,848.84864
Policy Entropy: 3.76124
Value Function Loss: 0.02580

Mean KL Divergence: 0.00895
SB3 Clip Fraction: 0.12203
Policy Update Magnitude: 0.55474
Value Function Update Magnitude: 0.49223

Collected Steps per Second: 22,124.03376
Overall Steps per Second: 10,536.10470

Timestep Collection Time: 2.26053
Timestep Consumption Time: 2.48620
PPO Batch Consumption Time: 0.28966
Total Iteration Time: 4.74673

Cumulative Model Updates: 200,774
Cumulative Timesteps: 1,674,250,836

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1674250836...
Checkpoint 1674250836 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 28,185.87533
Policy Entropy: 3.77153
Value Function Loss: 0.02216

Mean KL Divergence: 0.00855
SB3 Clip Fraction: 0.11273
Policy Update Magnitude: 0.48507
Value Function Update Magnitude: 0.71293

Collected Steps per Second: 22,566.94537
Overall Steps per Second: 10,659.17016

Timestep Collection Time: 2.21652
Timestep Consumption Time: 2.47616
PPO Batch Consumption Time: 0.28896
Total Iteration Time: 4.69267

Cumulative Model Updates: 200,780
Cumulative Timesteps: 1,674,300,856

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 14,159.76300
Policy Entropy: 3.75631
Value Function Loss: 0.02454

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12028
Policy Update Magnitude: 0.47593
Value Function Update Magnitude: 0.79360

Collected Steps per Second: 22,373.63169
Overall Steps per Second: 10,783.44024

Timestep Collection Time: 2.23710
Timestep Consumption Time: 2.40446
PPO Batch Consumption Time: 0.27624
Total Iteration Time: 4.64156

Cumulative Model Updates: 200,786
Cumulative Timesteps: 1,674,350,908

Timesteps Collected: 50,052
--------END ITERATION REPORT--------


Saving checkpoint 1674350908...
Checkpoint 1674350908 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,630.48002
Policy Entropy: 3.74409
Value Function Loss: 0.03302

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.11824
Policy Update Magnitude: 0.55454
Value Function Update Magnitude: 0.70854

Collected Steps per Second: 20,790.43055
Overall Steps per Second: 10,518.30394

Timestep Collection Time: 2.40495
Timestep Consumption Time: 2.34867
PPO Batch Consumption Time: 0.27786
Total Iteration Time: 4.75362

Cumulative Model Updates: 200,792
Cumulative Timesteps: 1,674,400,908

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,096.84944
Policy Entropy: 3.73537
Value Function Loss: 0.03721

Mean KL Divergence: 0.01355
SB3 Clip Fraction: 0.17087
Policy Update Magnitude: 0.58612
Value Function Update Magnitude: 0.64333

Collected Steps per Second: 21,831.09391
Overall Steps per Second: 10,578.66888

Timestep Collection Time: 2.29141
Timestep Consumption Time: 2.43735
PPO Batch Consumption Time: 0.29141
Total Iteration Time: 4.72876

Cumulative Model Updates: 200,798
Cumulative Timesteps: 1,674,450,932

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1674450932...
Checkpoint 1674450932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 108,388.91848
Policy Entropy: 3.75771
Value Function Loss: 0.04242

Mean KL Divergence: 0.01235
SB3 Clip Fraction: 0.15662
Policy Update Magnitude: 0.55188
Value Function Update Magnitude: 0.48663

Collected Steps per Second: 21,906.43807
Overall Steps per Second: 10,643.34661

Timestep Collection Time: 2.28389
Timestep Consumption Time: 2.41688
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.70078

Cumulative Model Updates: 200,804
Cumulative Timesteps: 1,674,500,964

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 863.79533
Policy Entropy: 3.79680
Value Function Loss: 0.03440

Mean KL Divergence: 0.00721
SB3 Clip Fraction: 0.09603
Policy Update Magnitude: 0.64765
Value Function Update Magnitude: 0.50744

Collected Steps per Second: 22,191.20045
Overall Steps per Second: 10,864.88806

Timestep Collection Time: 2.25369
Timestep Consumption Time: 2.34940
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.60308

Cumulative Model Updates: 200,810
Cumulative Timesteps: 1,674,550,976

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1674550976...
Checkpoint 1674550976 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46.80607
Policy Entropy: 3.80069
Value Function Loss: 0.03294

Mean KL Divergence: 0.00823
SB3 Clip Fraction: 0.10604
Policy Update Magnitude: 0.76162
Value Function Update Magnitude: 0.57325

Collected Steps per Second: 22,060.87899
Overall Steps per Second: 10,677.63169

Timestep Collection Time: 2.26727
Timestep Consumption Time: 2.41710
PPO Batch Consumption Time: 0.29199
Total Iteration Time: 4.68437

Cumulative Model Updates: 200,816
Cumulative Timesteps: 1,674,600,994

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,061.87174
Policy Entropy: 3.81929
Value Function Loss: 0.03551

Mean KL Divergence: 0.01340
SB3 Clip Fraction: 0.16872
Policy Update Magnitude: 0.65563
Value Function Update Magnitude: 0.63506

Collected Steps per Second: 22,040.10495
Overall Steps per Second: 10,790.63704

Timestep Collection Time: 2.26914
Timestep Consumption Time: 2.36562
PPO Batch Consumption Time: 0.27824
Total Iteration Time: 4.63476

Cumulative Model Updates: 200,822
Cumulative Timesteps: 1,674,651,006

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1674651006...
Checkpoint 1674651006 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 10,499.24259
Policy Entropy: 3.82620
Value Function Loss: 0.04462

Mean KL Divergence: 0.01260
SB3 Clip Fraction: 0.15327
Policy Update Magnitude: 0.65540
Value Function Update Magnitude: 0.58386

Collected Steps per Second: 21,912.64730
Overall Steps per Second: 10,708.49244

Timestep Collection Time: 2.28270
Timestep Consumption Time: 2.38836
PPO Batch Consumption Time: 0.28476
Total Iteration Time: 4.67106

Cumulative Model Updates: 200,828
Cumulative Timesteps: 1,674,701,026

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,481.03019
Policy Entropy: 3.87316
Value Function Loss: 0.04395

Mean KL Divergence: 0.00961
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.64712
Value Function Update Magnitude: 0.68479

Collected Steps per Second: 22,012.07681
Overall Steps per Second: 10,841.58591

Timestep Collection Time: 2.27293
Timestep Consumption Time: 2.34189
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.61482

Cumulative Model Updates: 200,834
Cumulative Timesteps: 1,674,751,058

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1674751058...
Checkpoint 1674751058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 16.90638
Policy Entropy: 3.88792
Value Function Loss: 0.04118

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.65761
Value Function Update Magnitude: 0.80092

Collected Steps per Second: 21,789.62287
Overall Steps per Second: 10,745.71691

Timestep Collection Time: 2.29522
Timestep Consumption Time: 2.35891
PPO Batch Consumption Time: 0.28137
Total Iteration Time: 4.65413

Cumulative Model Updates: 200,840
Cumulative Timesteps: 1,674,801,070

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51.53331
Policy Entropy: 3.88043
Value Function Loss: 0.03757

Mean KL Divergence: 0.00461
SB3 Clip Fraction: 0.05298
Policy Update Magnitude: 0.71906
Value Function Update Magnitude: 0.80429

Collected Steps per Second: 21,604.54704
Overall Steps per Second: 10,578.73756

Timestep Collection Time: 2.31544
Timestep Consumption Time: 2.41329
PPO Batch Consumption Time: 0.28944
Total Iteration Time: 4.72873

Cumulative Model Updates: 200,846
Cumulative Timesteps: 1,674,851,094

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1674851094...
Checkpoint 1674851094 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34.00166
Policy Entropy: 3.83819
Value Function Loss: 0.03314

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05790
Policy Update Magnitude: 0.71525
Value Function Update Magnitude: 0.65752

Collected Steps per Second: 21,921.76738
Overall Steps per Second: 10,680.41023

Timestep Collection Time: 2.28221
Timestep Consumption Time: 2.40207
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.68428

Cumulative Model Updates: 200,852
Cumulative Timesteps: 1,674,901,124

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.41084
Policy Entropy: 3.79404
Value Function Loss: 0.02354

Mean KL Divergence: 0.00465
SB3 Clip Fraction: 0.05027
Policy Update Magnitude: 0.61269
Value Function Update Magnitude: 0.61018

Collected Steps per Second: 22,249.05210
Overall Steps per Second: 10,740.13078

Timestep Collection Time: 2.24783
Timestep Consumption Time: 2.40873
PPO Batch Consumption Time: 0.28256
Total Iteration Time: 4.65655

Cumulative Model Updates: 200,858
Cumulative Timesteps: 1,674,951,136

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1674951136...
Checkpoint 1674951136 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51004
Policy Entropy: 3.77234
Value Function Loss: 0.01667

Mean KL Divergence: 0.00473
SB3 Clip Fraction: 0.05354
Policy Update Magnitude: 0.50442
Value Function Update Magnitude: 0.57261

Collected Steps per Second: 22,041.04130
Overall Steps per Second: 10,600.34331

Timestep Collection Time: 2.27040
Timestep Consumption Time: 2.45039
PPO Batch Consumption Time: 0.28574
Total Iteration Time: 4.72079

Cumulative Model Updates: 200,864
Cumulative Timesteps: 1,675,001,178

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51004
Policy Entropy: 3.74344
Value Function Loss: 0.01502

Mean KL Divergence: 0.00436
SB3 Clip Fraction: 0.04509
Policy Update Magnitude: 0.45284
Value Function Update Magnitude: 0.49103

Collected Steps per Second: 22,817.75406
Overall Steps per Second: 10,873.62686

Timestep Collection Time: 2.19224
Timestep Consumption Time: 2.40806
PPO Batch Consumption Time: 0.27808
Total Iteration Time: 4.60030

Cumulative Model Updates: 200,870
Cumulative Timesteps: 1,675,051,200

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1675051200...
Checkpoint 1675051200 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51004
Policy Entropy: 3.73833
Value Function Loss: 0.01487

Mean KL Divergence: 0.00708
SB3 Clip Fraction: 0.09083
Policy Update Magnitude: 0.46699
Value Function Update Magnitude: 0.48501

Collected Steps per Second: 22,635.83572
Overall Steps per Second: 10,682.46231

Timestep Collection Time: 2.20959
Timestep Consumption Time: 2.47247
PPO Batch Consumption Time: 0.28589
Total Iteration Time: 4.68207

Cumulative Model Updates: 200,876
Cumulative Timesteps: 1,675,101,216

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51004
Policy Entropy: 3.74062
Value Function Loss: 0.01530

Mean KL Divergence: 0.01164
SB3 Clip Fraction: 0.15807
Policy Update Magnitude: 0.37793
Value Function Update Magnitude: 0.39717

Collected Steps per Second: 22,898.25549
Overall Steps per Second: 10,837.85140

Timestep Collection Time: 2.18366
Timestep Consumption Time: 2.42999
PPO Batch Consumption Time: 0.27803
Total Iteration Time: 4.61365

Cumulative Model Updates: 200,882
Cumulative Timesteps: 1,675,151,218

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1675151218...
Checkpoint 1675151218 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51004
Policy Entropy: 3.73144
Value Function Loss: 0.01958

Mean KL Divergence: 0.01304
SB3 Clip Fraction: 0.17068
Policy Update Magnitude: 0.33952
Value Function Update Magnitude: 0.37811

Collected Steps per Second: 22,295.18091
Overall Steps per Second: 10,741.00690

Timestep Collection Time: 2.24416
Timestep Consumption Time: 2.41406
PPO Batch Consumption Time: 0.27598
Total Iteration Time: 4.65822

Cumulative Model Updates: 200,888
Cumulative Timesteps: 1,675,201,252

Timesteps Collected: 50,034
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13.51004
Policy Entropy: 3.72931
Value Function Loss: 0.01861

Mean KL Divergence: 0.01249
SB3 Clip Fraction: 0.16591
Policy Update Magnitude: 0.41298
Value Function Update Magnitude: 0.39181

Collected Steps per Second: 22,159.49895
Overall Steps per Second: 10,548.05138

Timestep Collection Time: 2.25718
Timestep Consumption Time: 2.48474
PPO Batch Consumption Time: 0.29064
Total Iteration Time: 4.74192

Cumulative Model Updates: 200,894
Cumulative Timesteps: 1,675,251,270

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1675251270...
Checkpoint 1675251270 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 34,781.19940
Policy Entropy: 3.71417
Value Function Loss: 0.02372

Mean KL Divergence: 0.01222
SB3 Clip Fraction: 0.15592
Policy Update Magnitude: 0.47229
Value Function Update Magnitude: 0.50295

Collected Steps per Second: 22,063.94460
Overall Steps per Second: 10,492.68011

Timestep Collection Time: 2.26759
Timestep Consumption Time: 2.50069
PPO Batch Consumption Time: 0.28872
Total Iteration Time: 4.76828

Cumulative Model Updates: 200,900
Cumulative Timesteps: 1,675,301,302

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 29,670.38816
Policy Entropy: 3.74645
Value Function Loss: 0.02312

Mean KL Divergence: 0.00986
SB3 Clip Fraction: 0.13559
Policy Update Magnitude: 0.49961
Value Function Update Magnitude: 0.58739

Collected Steps per Second: 22,361.49726
Overall Steps per Second: 10,592.60440

Timestep Collection Time: 2.23795
Timestep Consumption Time: 2.48647
PPO Batch Consumption Time: 0.29022
Total Iteration Time: 4.72443

Cumulative Model Updates: 200,906
Cumulative Timesteps: 1,675,351,346

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1675351346...
Checkpoint 1675351346 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,927.76498
Policy Entropy: 3.77114
Value Function Loss: 0.02676

Mean KL Divergence: 0.01024
SB3 Clip Fraction: 0.14078
Policy Update Magnitude: 0.48106
Value Function Update Magnitude: 0.61809

Collected Steps per Second: 22,011.99163
Overall Steps per Second: 10,524.75872

Timestep Collection Time: 2.27203
Timestep Consumption Time: 2.47981
PPO Batch Consumption Time: 0.28626
Total Iteration Time: 4.75184

Cumulative Model Updates: 200,912
Cumulative Timesteps: 1,675,401,358

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,357.58072
Policy Entropy: 3.78597
Value Function Loss: 0.02192

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12984
Policy Update Magnitude: 0.43359
Value Function Update Magnitude: 0.58110

Collected Steps per Second: 22,597.70398
Overall Steps per Second: 10,627.53429

Timestep Collection Time: 2.21323
Timestep Consumption Time: 2.49284
PPO Batch Consumption Time: 0.28850
Total Iteration Time: 4.70608

Cumulative Model Updates: 200,918
Cumulative Timesteps: 1,675,451,372

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1675451372...
Checkpoint 1675451372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,333.43845
Policy Entropy: 3.77545
Value Function Loss: 0.02026

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.38032
Value Function Update Magnitude: 0.59131

Collected Steps per Second: 23,097.56451
Overall Steps per Second: 10,841.85751

Timestep Collection Time: 2.16551
Timestep Consumption Time: 2.44791
PPO Batch Consumption Time: 0.27857
Total Iteration Time: 4.61342

Cumulative Model Updates: 200,924
Cumulative Timesteps: 1,675,501,390

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 219.14189
Policy Entropy: 3.77374
Value Function Loss: 0.01625

Mean KL Divergence: 0.00891
SB3 Clip Fraction: 0.12680
Policy Update Magnitude: 0.34094
Value Function Update Magnitude: 0.60847

Collected Steps per Second: 22,138.54933
Overall Steps per Second: 10,734.97708

Timestep Collection Time: 2.25850
Timestep Consumption Time: 2.39917
PPO Batch Consumption Time: 0.28720
Total Iteration Time: 4.65767

Cumulative Model Updates: 200,930
Cumulative Timesteps: 1,675,551,390

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1675551390...
Checkpoint 1675551390 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.70823
Policy Entropy: 3.76544
Value Function Loss: 0.01623

Mean KL Divergence: 0.00941
SB3 Clip Fraction: 0.13207
Policy Update Magnitude: 0.32745
Value Function Update Magnitude: 0.61761

Collected Steps per Second: 22,131.19241
Overall Steps per Second: 10,905.70041

Timestep Collection Time: 2.25980
Timestep Consumption Time: 2.32606
PPO Batch Consumption Time: 0.27629
Total Iteration Time: 4.58586

Cumulative Model Updates: 200,936
Cumulative Timesteps: 1,675,601,402

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.70823
Policy Entropy: 3.75131
Value Function Loss: 0.01293

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.13245
Policy Update Magnitude: 0.31000
Value Function Update Magnitude: 0.57534

Collected Steps per Second: 22,217.17569
Overall Steps per Second: 10,841.61870

Timestep Collection Time: 2.25105
Timestep Consumption Time: 2.36191
PPO Batch Consumption Time: 0.27890
Total Iteration Time: 4.61296

Cumulative Model Updates: 200,942
Cumulative Timesteps: 1,675,651,414

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1675651414...
Checkpoint 1675651414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.70823
Policy Entropy: 3.72295
Value Function Loss: 0.01273

Mean KL Divergence: 0.00946
SB3 Clip Fraction: 0.13284
Policy Update Magnitude: 0.28953
Value Function Update Magnitude: 0.44872

Collected Steps per Second: 21,781.04123
Overall Steps per Second: 10,645.71134

Timestep Collection Time: 2.29649
Timestep Consumption Time: 2.40211
PPO Batch Consumption Time: 0.27771
Total Iteration Time: 4.69861

Cumulative Model Updates: 200,948
Cumulative Timesteps: 1,675,701,434

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 202.70823
Policy Entropy: 3.70880
Value Function Loss: 0.01171

Mean KL Divergence: 0.00960
SB3 Clip Fraction: 0.13502
Policy Update Magnitude: 0.26800
Value Function Update Magnitude: 0.33741

Collected Steps per Second: 22,788.85948
Overall Steps per Second: 10,919.93568

Timestep Collection Time: 2.19432
Timestep Consumption Time: 2.38501
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.57933

Cumulative Model Updates: 200,954
Cumulative Timesteps: 1,675,751,440

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1675751440...
Checkpoint 1675751440 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 202.70823
Policy Entropy: 3.70165
Value Function Loss: 0.01457

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13612
Policy Update Magnitude: 0.31240
Value Function Update Magnitude: 0.38702

Collected Steps per Second: 22,360.65283
Overall Steps per Second: 10,684.22919

Timestep Collection Time: 2.23697
Timestep Consumption Time: 2.44470
PPO Batch Consumption Time: 0.28796
Total Iteration Time: 4.68167

Cumulative Model Updates: 200,960
Cumulative Timesteps: 1,675,801,460

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 90,471.79488
Policy Entropy: 3.72287
Value Function Loss: 0.01595

Mean KL Divergence: 0.00910
SB3 Clip Fraction: 0.12862
Policy Update Magnitude: 0.39483
Value Function Update Magnitude: 0.57819

Collected Steps per Second: 22,414.67170
Overall Steps per Second: 10,602.05585

Timestep Collection Time: 2.23202
Timestep Consumption Time: 2.48688
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.71890

Cumulative Model Updates: 200,966
Cumulative Timesteps: 1,675,851,490

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1675851490...
Checkpoint 1675851490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 25,555.17283
Policy Entropy: 3.71693
Value Function Loss: 0.02032

Mean KL Divergence: 0.00890
SB3 Clip Fraction: 0.12371
Policy Update Magnitude: 0.42761
Value Function Update Magnitude: 0.71926

Collected Steps per Second: 22,126.78513
Overall Steps per Second: 10,523.79648

Timestep Collection Time: 2.26187
Timestep Consumption Time: 2.49382
PPO Batch Consumption Time: 0.29127
Total Iteration Time: 4.75570

Cumulative Model Updates: 200,972
Cumulative Timesteps: 1,675,901,538

Timesteps Collected: 50,048
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 13,592.25975
Policy Entropy: 3.72742
Value Function Loss: 0.02052

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.13228
Policy Update Magnitude: 0.44637
Value Function Update Magnitude: 0.72960

Collected Steps per Second: 22,244.99358
Overall Steps per Second: 10,454.31296

Timestep Collection Time: 2.24815
Timestep Consumption Time: 2.53553
PPO Batch Consumption Time: 0.29118
Total Iteration Time: 4.78367

Cumulative Model Updates: 200,978
Cumulative Timesteps: 1,675,951,548

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1675951548...
Checkpoint 1675951548 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,592.25975
Policy Entropy: 3.70637
Value Function Loss: 0.02007

Mean KL Divergence: 0.00943
SB3 Clip Fraction: 0.13445
Policy Update Magnitude: 0.42520
Value Function Update Magnitude: 0.73160

Collected Steps per Second: 22,653.16060
Overall Steps per Second: 10,594.05007

Timestep Collection Time: 2.20737
Timestep Consumption Time: 2.51263
PPO Batch Consumption Time: 0.29182
Total Iteration Time: 4.72001

Cumulative Model Updates: 200,984
Cumulative Timesteps: 1,676,001,552

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 384,395.51712
Policy Entropy: 3.70937
Value Function Loss: 0.01906

Mean KL Divergence: 0.00912
SB3 Clip Fraction: 0.12992
Policy Update Magnitude: 0.42175
Value Function Update Magnitude: 0.65150

Collected Steps per Second: 22,568.59988
Overall Steps per Second: 10,635.39932

Timestep Collection Time: 2.21680
Timestep Consumption Time: 2.48730
PPO Batch Consumption Time: 0.28703
Total Iteration Time: 4.70410

Cumulative Model Updates: 200,990
Cumulative Timesteps: 1,676,051,582

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1676051582...
Checkpoint 1676051582 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 165,471.36850
Policy Entropy: 3.69737
Value Function Loss: 0.01938

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.43316
Value Function Update Magnitude: 0.65007

Collected Steps per Second: 22,943.43215
Overall Steps per Second: 10,851.89950

Timestep Collection Time: 2.17988
Timestep Consumption Time: 2.42890
PPO Batch Consumption Time: 0.27829
Total Iteration Time: 4.60878

Cumulative Model Updates: 200,996
Cumulative Timesteps: 1,676,101,596

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,471.36850
Policy Entropy: 3.69173
Value Function Loss: 0.02107

Mean KL Divergence: 0.00959
SB3 Clip Fraction: 0.13226
Policy Update Magnitude: 0.43717
Value Function Update Magnitude: 0.53605

Collected Steps per Second: 22,385.00818
Overall Steps per Second: 10,538.38363

Timestep Collection Time: 2.23426
Timestep Consumption Time: 2.51163
PPO Batch Consumption Time: 0.29104
Total Iteration Time: 4.74589

Cumulative Model Updates: 201,002
Cumulative Timesteps: 1,676,151,610

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1676151610...
Checkpoint 1676151610 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 514,026.70200
Policy Entropy: 3.69117
Value Function Loss: 0.02359

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12923
Policy Update Magnitude: 0.42041
Value Function Update Magnitude: 0.41102

Collected Steps per Second: 22,787.20283
Overall Steps per Second: 10,675.63756

Timestep Collection Time: 2.19623
Timestep Consumption Time: 2.49164
PPO Batch Consumption Time: 0.29230
Total Iteration Time: 4.68787

Cumulative Model Updates: 201,008
Cumulative Timesteps: 1,676,201,656

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,605.65009
Policy Entropy: 3.71028
Value Function Loss: 0.02160

Mean KL Divergence: 0.00942
SB3 Clip Fraction: 0.12988
Policy Update Magnitude: 0.45273
Value Function Update Magnitude: 0.47700

Collected Steps per Second: 22,529.55298
Overall Steps per Second: 10,786.75521

Timestep Collection Time: 2.21975
Timestep Consumption Time: 2.41649
PPO Batch Consumption Time: 0.27802
Total Iteration Time: 4.63624

Cumulative Model Updates: 201,014
Cumulative Timesteps: 1,676,251,666

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1676251666...
Checkpoint 1676251666 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 235,360.05383
Policy Entropy: 3.71288
Value Function Loss: 0.02435

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13568
Policy Update Magnitude: 0.45045
Value Function Update Magnitude: 0.54311

Collected Steps per Second: 22,041.15595
Overall Steps per Second: 10,726.50494

Timestep Collection Time: 2.26903
Timestep Consumption Time: 2.39344
PPO Batch Consumption Time: 0.28707
Total Iteration Time: 4.66247

Cumulative Model Updates: 201,020
Cumulative Timesteps: 1,676,301,678

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,562.30294
Policy Entropy: 3.72976
Value Function Loss: 0.02140

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.12233
Policy Update Magnitude: 0.42901
Value Function Update Magnitude: 0.60041

Collected Steps per Second: 21,354.70854
Overall Steps per Second: 10,538.21243

Timestep Collection Time: 2.34140
Timestep Consumption Time: 2.40323
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.74464

Cumulative Model Updates: 201,026
Cumulative Timesteps: 1,676,351,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1676351678...
Checkpoint 1676351678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 123,170.14643
Policy Entropy: 3.72598
Value Function Loss: 0.02318

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13611
Policy Update Magnitude: 0.42896
Value Function Update Magnitude: 0.59576

Collected Steps per Second: 21,912.29771
Overall Steps per Second: 10,688.54521

Timestep Collection Time: 2.28246
Timestep Consumption Time: 2.39675
PPO Batch Consumption Time: 0.28828
Total Iteration Time: 4.67921

Cumulative Model Updates: 201,032
Cumulative Timesteps: 1,676,401,692

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 146,924.41175
Policy Entropy: 3.74015
Value Function Loss: 0.02495

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12337
Policy Update Magnitude: 0.45709
Value Function Update Magnitude: 0.61135

Collected Steps per Second: 21,838.28232
Overall Steps per Second: 10,790.26701

Timestep Collection Time: 2.29038
Timestep Consumption Time: 2.34509
PPO Batch Consumption Time: 0.27675
Total Iteration Time: 4.63547

Cumulative Model Updates: 201,038
Cumulative Timesteps: 1,676,451,710

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1676451710...
Checkpoint 1676451710 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 54,481.47172
Policy Entropy: 3.74109
Value Function Loss: 0.02758

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12869
Policy Update Magnitude: 0.51847
Value Function Update Magnitude: 0.70867

Collected Steps per Second: 21,443.18290
Overall Steps per Second: 10,552.14657

Timestep Collection Time: 2.33202
Timestep Consumption Time: 2.40692
PPO Batch Consumption Time: 0.27785
Total Iteration Time: 4.73894

Cumulative Model Updates: 201,044
Cumulative Timesteps: 1,676,501,716

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,008.47720
Policy Entropy: 3.74274
Value Function Loss: 0.02751

Mean KL Divergence: 0.00948
SB3 Clip Fraction: 0.13192
Policy Update Magnitude: 0.52196
Value Function Update Magnitude: 0.75699

Collected Steps per Second: 22,536.36347
Overall Steps per Second: 10,554.83776

Timestep Collection Time: 2.21890
Timestep Consumption Time: 2.51883
PPO Batch Consumption Time: 0.29116
Total Iteration Time: 4.73773

Cumulative Model Updates: 201,050
Cumulative Timesteps: 1,676,551,722

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1676551722...
Checkpoint 1676551722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 6,636.83688
Policy Entropy: 3.73229
Value Function Loss: 0.02339

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13110
Policy Update Magnitude: 0.49894
Value Function Update Magnitude: 0.70445

Collected Steps per Second: 22,681.32042
Overall Steps per Second: 10,675.36552

Timestep Collection Time: 2.20525
Timestep Consumption Time: 2.48012
PPO Batch Consumption Time: 0.29107
Total Iteration Time: 4.68537

Cumulative Model Updates: 201,056
Cumulative Timesteps: 1,676,601,740

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,467.92338
Policy Entropy: 3.73470
Value Function Loss: 0.02136

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.13259
Policy Update Magnitude: 0.46430
Value Function Update Magnitude: 0.70771

Collected Steps per Second: 22,910.67301
Overall Steps per Second: 10,843.41810

Timestep Collection Time: 2.18370
Timestep Consumption Time: 2.43016
PPO Batch Consumption Time: 0.27732
Total Iteration Time: 4.61386

Cumulative Model Updates: 201,062
Cumulative Timesteps: 1,676,651,770

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1676651770...
Checkpoint 1676651770 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,729.48296
Policy Entropy: 3.73222
Value Function Loss: 0.02202

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.12738
Policy Update Magnitude: 0.44024
Value Function Update Magnitude: 0.79765

Collected Steps per Second: 22,467.15043
Overall Steps per Second: 10,569.70373

Timestep Collection Time: 2.22609
Timestep Consumption Time: 2.50573
PPO Batch Consumption Time: 0.29124
Total Iteration Time: 4.73183

Cumulative Model Updates: 201,068
Cumulative Timesteps: 1,676,701,784

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 7,245.66007
Policy Entropy: 3.73314
Value Function Loss: 0.02183

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12547
Policy Update Magnitude: 0.45758
Value Function Update Magnitude: 0.82150

Collected Steps per Second: 22,735.93683
Overall Steps per Second: 10,694.96598

Timestep Collection Time: 2.19951
Timestep Consumption Time: 2.47633
PPO Batch Consumption Time: 0.28890
Total Iteration Time: 4.67584

Cumulative Model Updates: 201,074
Cumulative Timesteps: 1,676,751,792

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1676751792...
Checkpoint 1676751792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,543.30428
Policy Entropy: 3.73084
Value Function Loss: 0.02076

Mean KL Divergence: 0.00897
SB3 Clip Fraction: 0.12443
Policy Update Magnitude: 0.45438
Value Function Update Magnitude: 0.68855

Collected Steps per Second: 22,635.80431
Overall Steps per Second: 10,809.65775

Timestep Collection Time: 2.21092
Timestep Consumption Time: 2.41883
PPO Batch Consumption Time: 0.27840
Total Iteration Time: 4.62975

Cumulative Model Updates: 201,080
Cumulative Timesteps: 1,676,801,838

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 894.43958
Policy Entropy: 3.73343
Value Function Loss: 0.01774

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.12643
Policy Update Magnitude: 0.39800
Value Function Update Magnitude: 0.49301

Collected Steps per Second: 22,532.22905
Overall Steps per Second: 10,599.81960

Timestep Collection Time: 2.22011
Timestep Consumption Time: 2.49922
PPO Batch Consumption Time: 0.29213
Total Iteration Time: 4.71933

Cumulative Model Updates: 201,086
Cumulative Timesteps: 1,676,851,862

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1676851862...
Checkpoint 1676851862 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 253.51736
Policy Entropy: 3.75958
Value Function Loss: 0.01447

Mean KL Divergence: 0.00821
SB3 Clip Fraction: 0.11964
Policy Update Magnitude: 0.34884
Value Function Update Magnitude: 0.44883

Collected Steps per Second: 22,219.56300
Overall Steps per Second: 10,555.70898

Timestep Collection Time: 2.25045
Timestep Consumption Time: 2.48670
PPO Batch Consumption Time: 0.28835
Total Iteration Time: 4.73715

Cumulative Model Updates: 201,092
Cumulative Timesteps: 1,676,901,866

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.54431
Policy Entropy: 3.74466
Value Function Loss: 0.01392

Mean KL Divergence: 0.00848
SB3 Clip Fraction: 0.12280
Policy Update Magnitude: 0.32075
Value Function Update Magnitude: 0.49804

Collected Steps per Second: 21,801.44807
Overall Steps per Second: 10,632.41391

Timestep Collection Time: 2.29407
Timestep Consumption Time: 2.40985
PPO Batch Consumption Time: 0.28834
Total Iteration Time: 4.70392

Cumulative Model Updates: 201,098
Cumulative Timesteps: 1,676,951,880

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1676951880...
Checkpoint 1676951880 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.54431
Policy Entropy: 3.73107
Value Function Loss: 0.01359

Mean KL Divergence: 0.00842
SB3 Clip Fraction: 0.12110
Policy Update Magnitude: 0.36931
Value Function Update Magnitude: 0.54053

Collected Steps per Second: 21,772.52671
Overall Steps per Second: 10,643.78947

Timestep Collection Time: 2.29757
Timestep Consumption Time: 2.40226
PPO Batch Consumption Time: 0.28857
Total Iteration Time: 4.69983

Cumulative Model Updates: 201,104
Cumulative Timesteps: 1,677,001,904

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 207.54431
Policy Entropy: 3.68647
Value Function Loss: 0.01604

Mean KL Divergence: 0.00929
SB3 Clip Fraction: 0.13146
Policy Update Magnitude: 0.41721
Value Function Update Magnitude: 0.52103

Collected Steps per Second: 21,572.38455
Overall Steps per Second: 10,691.70103

Timestep Collection Time: 2.31880
Timestep Consumption Time: 2.35978
PPO Batch Consumption Time: 0.27835
Total Iteration Time: 4.67858

Cumulative Model Updates: 201,110
Cumulative Timesteps: 1,677,051,926

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1677051926...
Checkpoint 1677051926 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 207.54431
Policy Entropy: 3.69520
Value Function Loss: 0.01966

Mean KL Divergence: 0.00931
SB3 Clip Fraction: 0.12871
Policy Update Magnitude: 0.48025
Value Function Update Magnitude: 0.55190

Collected Steps per Second: 21,864.51817
Overall Steps per Second: 10,600.04739

Timestep Collection Time: 2.28699
Timestep Consumption Time: 2.43034
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.71734

Cumulative Model Updates: 201,116
Cumulative Timesteps: 1,677,101,930

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 134,012.42036
Policy Entropy: 3.71526
Value Function Loss: 0.02146

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.13254
Policy Update Magnitude: 0.52849
Value Function Update Magnitude: 0.65154

Collected Steps per Second: 22,543.87149
Overall Steps per Second: 10,698.42321

Timestep Collection Time: 2.21808
Timestep Consumption Time: 2.45588
PPO Batch Consumption Time: 0.28851
Total Iteration Time: 4.67396

Cumulative Model Updates: 201,122
Cumulative Timesteps: 1,677,151,934

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1677151934...
Checkpoint 1677151934 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 104,378.15263
Policy Entropy: 3.75291
Value Function Loss: 0.02235

Mean KL Divergence: 0.00906
SB3 Clip Fraction: 0.12241
Policy Update Magnitude: 0.53041
Value Function Update Magnitude: 0.77789

Collected Steps per Second: 22,821.18992
Overall Steps per Second: 10,916.17713

Timestep Collection Time: 2.19296
Timestep Consumption Time: 2.39161
PPO Batch Consumption Time: 0.27947
Total Iteration Time: 4.58457

Cumulative Model Updates: 201,128
Cumulative Timesteps: 1,677,201,980

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 5,516.45887
Policy Entropy: 3.77757
Value Function Loss: 0.01985

Mean KL Divergence: 0.00822
SB3 Clip Fraction: 0.10530
Policy Update Magnitude: 0.51990
Value Function Update Magnitude: 0.77606

Collected Steps per Second: 22,591.83415
Overall Steps per Second: 10,663.70669

Timestep Collection Time: 2.21399
Timestep Consumption Time: 2.47650
PPO Batch Consumption Time: 0.28774
Total Iteration Time: 4.69049

Cumulative Model Updates: 201,134
Cumulative Timesteps: 1,677,251,998

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1677251998...
Checkpoint 1677251998 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 137,786.68947
Policy Entropy: 3.76450
Value Function Loss: 0.02365

Mean KL Divergence: 0.01082
SB3 Clip Fraction: 0.14168
Policy Update Magnitude: 0.54722
Value Function Update Magnitude: 0.78805

Collected Steps per Second: 22,511.79658
Overall Steps per Second: 10,641.89021

Timestep Collection Time: 2.22266
Timestep Consumption Time: 2.47914
PPO Batch Consumption Time: 0.28891
Total Iteration Time: 4.70180

Cumulative Model Updates: 201,140
Cumulative Timesteps: 1,677,302,034

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 46,560.09952
Policy Entropy: 3.76555
Value Function Loss: 0.02524

Mean KL Divergence: 0.03094
SB3 Clip Fraction: 0.30662
Policy Update Magnitude: 0.51651
Value Function Update Magnitude: 0.75244

Collected Steps per Second: 22,855.47905
Overall Steps per Second: 10,743.66674

Timestep Collection Time: 2.18845
Timestep Consumption Time: 2.46713
PPO Batch Consumption Time: 0.28586
Total Iteration Time: 4.65558

Cumulative Model Updates: 201,146
Cumulative Timesteps: 1,677,352,052

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1677352052...
Checkpoint 1677352052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,722.27194
Policy Entropy: 3.74155
Value Function Loss: 0.03850

Mean KL Divergence: 0.02269
SB3 Clip Fraction: 0.23392
Policy Update Magnitude: 0.46986
Value Function Update Magnitude: 0.59984

Collected Steps per Second: 22,600.93633
Overall Steps per Second: 10,616.48046

Timestep Collection Time: 2.21256
Timestep Consumption Time: 2.49766
PPO Batch Consumption Time: 0.29133
Total Iteration Time: 4.71022

Cumulative Model Updates: 201,152
Cumulative Timesteps: 1,677,402,058

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 309.82723
Policy Entropy: 3.77431
Value Function Loss: 0.04569

Mean KL Divergence: 0.01487
SB3 Clip Fraction: 0.17144
Policy Update Magnitude: 0.58073
Value Function Update Magnitude: 0.42918

Collected Steps per Second: 22,473.39588
Overall Steps per Second: 10,601.23033

Timestep Collection Time: 2.22485
Timestep Consumption Time: 2.49158
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.71643

Cumulative Model Updates: 201,158
Cumulative Timesteps: 1,677,452,058

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1677452058...
Checkpoint 1677452058 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 51.04740
Policy Entropy: 3.76312
Value Function Loss: 0.03943

Mean KL Divergence: 0.01460
SB3 Clip Fraction: 0.17598
Policy Update Magnitude: 0.52557
Value Function Update Magnitude: 0.40084

Collected Steps per Second: 22,060.06132
Overall Steps per Second: 10,478.32441

Timestep Collection Time: 2.26745
Timestep Consumption Time: 2.50622
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 4.77366

Cumulative Model Updates: 201,164
Cumulative Timesteps: 1,677,502,078

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34.79884
Policy Entropy: 3.74964
Value Function Loss: 0.04165

Mean KL Divergence: 0.01262
SB3 Clip Fraction: 0.15871
Policy Update Magnitude: 0.46412
Value Function Update Magnitude: 0.34012

Collected Steps per Second: 22,163.51626
Overall Steps per Second: 10,532.40525

Timestep Collection Time: 2.25614
Timestep Consumption Time: 2.49149
PPO Batch Consumption Time: 0.29126
Total Iteration Time: 4.74763

Cumulative Model Updates: 201,170
Cumulative Timesteps: 1,677,552,082

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1677552082...
Checkpoint 1677552082 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 317.33834
Policy Entropy: 3.73285
Value Function Loss: 0.03215

Mean KL Divergence: 0.01328
SB3 Clip Fraction: 0.16653
Policy Update Magnitude: 0.48275
Value Function Update Magnitude: 0.36398

Collected Steps per Second: 22,505.77864
Overall Steps per Second: 10,603.51421

Timestep Collection Time: 2.22254
Timestep Consumption Time: 2.49476
PPO Batch Consumption Time: 0.29154
Total Iteration Time: 4.71730

Cumulative Model Updates: 201,176
Cumulative Timesteps: 1,677,602,102

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 362,993.20954
Policy Entropy: 3.70585
Value Function Loss: 0.03412

Mean KL Divergence: 0.01071
SB3 Clip Fraction: 0.13620
Policy Update Magnitude: 0.46576
Value Function Update Magnitude: 0.37732

Collected Steps per Second: 22,373.53033
Overall Steps per Second: 10,597.41839

Timestep Collection Time: 2.23541
Timestep Consumption Time: 2.48404
PPO Batch Consumption Time: 0.28839
Total Iteration Time: 4.71945

Cumulative Model Updates: 201,182
Cumulative Timesteps: 1,677,652,116

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1677652116...
Checkpoint 1677652116 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,531.74875
Policy Entropy: 3.73314
Value Function Loss: 0.02713

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12548
Policy Update Magnitude: 0.46206
Value Function Update Magnitude: 0.41331

Collected Steps per Second: 22,030.43490
Overall Steps per Second: 10,581.98797

Timestep Collection Time: 2.27022
Timestep Consumption Time: 2.45611
PPO Batch Consumption Time: 0.28878
Total Iteration Time: 4.72633

Cumulative Model Updates: 201,188
Cumulative Timesteps: 1,677,702,130

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 102,531.74875
Policy Entropy: 3.70335
Value Function Loss: 0.02916

Mean KL Divergence: 0.00951
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.45330
Value Function Update Magnitude: 0.43362

Collected Steps per Second: 22,093.76855
Overall Steps per Second: 10,761.07863

Timestep Collection Time: 2.26444
Timestep Consumption Time: 2.38472
PPO Batch Consumption Time: 0.28312
Total Iteration Time: 4.64916

Cumulative Model Updates: 201,194
Cumulative Timesteps: 1,677,752,160

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1677752160...
Checkpoint 1677752160 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 102,531.74875
Policy Entropy: 3.69831
Value Function Loss: 0.02314

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.43579
Value Function Update Magnitude: 0.51663

Collected Steps per Second: 21,984.55657
Overall Steps per Second: 10,646.15956

Timestep Collection Time: 2.27496
Timestep Consumption Time: 2.42288
PPO Batch Consumption Time: 0.29078
Total Iteration Time: 4.69784

Cumulative Model Updates: 201,200
Cumulative Timesteps: 1,677,802,174

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 215,399.41179
Policy Entropy: 3.69401
Value Function Loss: 0.02176

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12945
Policy Update Magnitude: 0.44448
Value Function Update Magnitude: 0.47711

Collected Steps per Second: 21,916.96764
Overall Steps per Second: 10,433.90079

Timestep Collection Time: 2.28152
Timestep Consumption Time: 2.51093
PPO Batch Consumption Time: 0.29203
Total Iteration Time: 4.79245

Cumulative Model Updates: 201,206
Cumulative Timesteps: 1,677,852,178

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1677852178...
Checkpoint 1677852178 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 114,561.13246
Policy Entropy: 3.69404
Value Function Loss: 0.01880

Mean KL Divergence: 0.00905
SB3 Clip Fraction: 0.12799
Policy Update Magnitude: 0.44525
Value Function Update Magnitude: 0.51704

Collected Steps per Second: 22,592.35683
Overall Steps per Second: 10,653.01644

Timestep Collection Time: 2.21331
Timestep Consumption Time: 2.48057
PPO Batch Consumption Time: 0.29026
Total Iteration Time: 4.69388

Cumulative Model Updates: 201,212
Cumulative Timesteps: 1,677,902,182

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 75,172.78835
Policy Entropy: 3.70160
Value Function Loss: 0.01945

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13109
Policy Update Magnitude: 0.43863
Value Function Update Magnitude: 0.54410

Collected Steps per Second: 22,670.92209
Overall Steps per Second: 10,665.70283

Timestep Collection Time: 2.20547
Timestep Consumption Time: 2.48246
PPO Batch Consumption Time: 0.28802
Total Iteration Time: 4.68792

Cumulative Model Updates: 201,218
Cumulative Timesteps: 1,677,952,182

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1677952182...
Checkpoint 1677952182 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 184,287.62899
Policy Entropy: 3.70298
Value Function Loss: 0.02073

Mean KL Divergence: 0.00889
SB3 Clip Fraction: 0.12553
Policy Update Magnitude: 0.43820
Value Function Update Magnitude: 0.54480

Collected Steps per Second: 22,317.66636
Overall Steps per Second: 10,573.04075

Timestep Collection Time: 2.24092
Timestep Consumption Time: 2.48923
PPO Batch Consumption Time: 0.29158
Total Iteration Time: 4.73014

Cumulative Model Updates: 201,224
Cumulative Timesteps: 1,678,002,194

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 149,273.33125
Policy Entropy: 3.71868
Value Function Loss: 0.02027

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.43227
Value Function Update Magnitude: 0.53212

Collected Steps per Second: 22,369.74087
Overall Steps per Second: 10,574.08420

Timestep Collection Time: 2.23606
Timestep Consumption Time: 2.49438
PPO Batch Consumption Time: 0.28674
Total Iteration Time: 4.73043

Cumulative Model Updates: 201,230
Cumulative Timesteps: 1,678,052,214

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1678052214...
Checkpoint 1678052214 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 130,639.53490
Policy Entropy: 3.72005
Value Function Loss: 0.01881

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.12994
Policy Update Magnitude: 0.39072
Value Function Update Magnitude: 0.56022

Collected Steps per Second: 21,992.92026
Overall Steps per Second: 10,515.53928

Timestep Collection Time: 2.27491
Timestep Consumption Time: 2.48300
PPO Batch Consumption Time: 0.29045
Total Iteration Time: 4.75791

Cumulative Model Updates: 201,236
Cumulative Timesteps: 1,678,102,246

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,433.52647
Policy Entropy: 3.72596
Value Function Loss: 0.01827

Mean KL Divergence: 0.00909
SB3 Clip Fraction: 0.12748
Policy Update Magnitude: 0.38615
Value Function Update Magnitude: 0.57426

Collected Steps per Second: 22,238.84728
Overall Steps per Second: 10,762.58559

Timestep Collection Time: 2.24895
Timestep Consumption Time: 2.39808
PPO Batch Consumption Time: 0.27489
Total Iteration Time: 4.64702

Cumulative Model Updates: 201,242
Cumulative Timesteps: 1,678,152,260

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1678152260...
Checkpoint 1678152260 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,433.52647
Policy Entropy: 3.71053
Value Function Loss: 0.02079

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12736
Policy Update Magnitude: 0.39040
Value Function Update Magnitude: 0.50984

Collected Steps per Second: 22,337.80500
Overall Steps per Second: 10,739.82871

Timestep Collection Time: 2.23863
Timestep Consumption Time: 2.41750
PPO Batch Consumption Time: 0.27651
Total Iteration Time: 4.65613

Cumulative Model Updates: 201,248
Cumulative Timesteps: 1,678,202,266

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 69,433.52647
Policy Entropy: 3.71410
Value Function Loss: 0.01998

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13230
Policy Update Magnitude: 0.40336
Value Function Update Magnitude: 0.39279

Collected Steps per Second: 22,649.46601
Overall Steps per Second: 10,598.02904

Timestep Collection Time: 2.20897
Timestep Consumption Time: 2.51191
PPO Batch Consumption Time: 0.28768
Total Iteration Time: 4.72088

Cumulative Model Updates: 201,254
Cumulative Timesteps: 1,678,252,298

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1678252298...
Checkpoint 1678252298 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 69,433.52647
Policy Entropy: 3.71436
Value Function Loss: 0.01944

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13196
Policy Update Magnitude: 0.42654
Value Function Update Magnitude: 0.44170

Collected Steps per Second: 21,864.45733
Overall Steps per Second: 10,773.58572

Timestep Collection Time: 2.28755
Timestep Consumption Time: 2.35492
PPO Batch Consumption Time: 0.27797
Total Iteration Time: 4.64247

Cumulative Model Updates: 201,260
Cumulative Timesteps: 1,678,302,314

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.72856
Value Function Loss: 0.02147

Mean KL Divergence: 0.00965
SB3 Clip Fraction: 0.13285
Policy Update Magnitude: 0.45918
Value Function Update Magnitude: 0.49727

Collected Steps per Second: 22,013.28489
Overall Steps per Second: 10,663.92630

Timestep Collection Time: 2.27254
Timestep Consumption Time: 2.41861
PPO Batch Consumption Time: 0.29167
Total Iteration Time: 4.69114

Cumulative Model Updates: 201,266
Cumulative Timesteps: 1,678,352,340

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1678352340...
Checkpoint 1678352340 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.71706
Value Function Loss: 0.02095

Mean KL Divergence: 0.00967
SB3 Clip Fraction: 0.12927
Policy Update Magnitude: 0.49932
Value Function Update Magnitude: 0.50654

Collected Steps per Second: 21,861.97445
Overall Steps per Second: 10,673.60925

Timestep Collection Time: 2.28726
Timestep Consumption Time: 2.39757
PPO Batch Consumption Time: 0.29053
Total Iteration Time: 4.68483

Cumulative Model Updates: 201,272
Cumulative Timesteps: 1,678,402,344

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.71707
Value Function Loss: 0.02169

Mean KL Divergence: 0.00987
SB3 Clip Fraction: 0.13553
Policy Update Magnitude: 0.47927
Value Function Update Magnitude: 0.46255

Collected Steps per Second: 21,880.65039
Overall Steps per Second: 10,684.32381

Timestep Collection Time: 2.28640
Timestep Consumption Time: 2.39597
PPO Batch Consumption Time: 0.27796
Total Iteration Time: 4.68237

Cumulative Model Updates: 201,278
Cumulative Timesteps: 1,678,452,372

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1678452372...
Checkpoint 1678452372 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.72242
Value Function Loss: 0.01869

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12974
Policy Update Magnitude: 0.42862
Value Function Update Magnitude: 0.36893

Collected Steps per Second: 22,535.43064
Overall Steps per Second: 10,735.55537

Timestep Collection Time: 2.21891
Timestep Consumption Time: 2.43889
PPO Batch Consumption Time: 0.28550
Total Iteration Time: 4.65779

Cumulative Model Updates: 201,284
Cumulative Timesteps: 1,678,502,376

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.71360
Value Function Loss: 0.01808

Mean KL Divergence: 0.00991
SB3 Clip Fraction: 0.13469
Policy Update Magnitude: 0.40392
Value Function Update Magnitude: 0.33504

Collected Steps per Second: 22,673.34961
Overall Steps per Second: 10,695.11282

Timestep Collection Time: 2.20550
Timestep Consumption Time: 2.47010
PPO Batch Consumption Time: 0.28627
Total Iteration Time: 4.67559

Cumulative Model Updates: 201,290
Cumulative Timesteps: 1,678,552,382

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1678552382...
Checkpoint 1678552382 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.71943
Value Function Loss: 0.01569

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13623
Policy Update Magnitude: 0.40708
Value Function Update Magnitude: 0.40146

Collected Steps per Second: 22,256.65535
Overall Steps per Second: 10,607.07168

Timestep Collection Time: 2.24661
Timestep Consumption Time: 2.46742
PPO Batch Consumption Time: 0.28716
Total Iteration Time: 4.71402

Cumulative Model Updates: 201,296
Cumulative Timesteps: 1,678,602,384

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.72261
Value Function Loss: 0.01440

Mean KL Divergence: 0.01013
SB3 Clip Fraction: 0.13928
Policy Update Magnitude: 0.36346
Value Function Update Magnitude: 0.39369

Collected Steps per Second: 21,813.87625
Overall Steps per Second: 10,621.95226

Timestep Collection Time: 2.29386
Timestep Consumption Time: 2.41695
PPO Batch Consumption Time: 0.27767
Total Iteration Time: 4.71081

Cumulative Model Updates: 201,302
Cumulative Timesteps: 1,678,652,422

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1678652422...
Checkpoint 1678652422 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.71850
Value Function Loss: 0.01324

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13696
Policy Update Magnitude: 0.31909
Value Function Update Magnitude: 0.34790

Collected Steps per Second: 21,711.37469
Overall Steps per Second: 10,606.19685

Timestep Collection Time: 2.30340
Timestep Consumption Time: 2.41177
PPO Batch Consumption Time: 0.27737
Total Iteration Time: 4.71517

Cumulative Model Updates: 201,308
Cumulative Timesteps: 1,678,702,432

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.71259
Value Function Loss: 0.01479

Mean KL Divergence: 0.00936
SB3 Clip Fraction: 0.12915
Policy Update Magnitude: 0.32577
Value Function Update Magnitude: 0.36214

Collected Steps per Second: 22,423.31149
Overall Steps per Second: 10,556.04985

Timestep Collection Time: 2.22982
Timestep Consumption Time: 2.50680
PPO Batch Consumption Time: 0.29195
Total Iteration Time: 4.73662

Cumulative Model Updates: 201,314
Cumulative Timesteps: 1,678,752,432

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1678752432...
Checkpoint 1678752432 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.70373
Value Function Loss: 0.01519

Mean KL Divergence: 0.00896
SB3 Clip Fraction: 0.12294
Policy Update Magnitude: 0.38642
Value Function Update Magnitude: 0.43620

Collected Steps per Second: 22,726.34564
Overall Steps per Second: 10,636.46904

Timestep Collection Time: 2.20141
Timestep Consumption Time: 2.50222
PPO Batch Consumption Time: 0.28422
Total Iteration Time: 4.70363

Cumulative Model Updates: 201,320
Cumulative Timesteps: 1,678,802,462

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.72015
Value Function Loss: 0.01490

Mean KL Divergence: 0.00914
SB3 Clip Fraction: 0.12171
Policy Update Magnitude: 0.42200
Value Function Update Magnitude: 0.44538

Collected Steps per Second: 22,855.10180
Overall Steps per Second: 10,813.23450

Timestep Collection Time: 2.18822
Timestep Consumption Time: 2.43685
PPO Batch Consumption Time: 0.27846
Total Iteration Time: 4.62507

Cumulative Model Updates: 201,326
Cumulative Timesteps: 1,678,852,474

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1678852474...
Checkpoint 1678852474 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 248,202.29344
Policy Entropy: 3.73042
Value Function Loss: 0.01226

Mean KL Divergence: 0.00833
SB3 Clip Fraction: 0.11181
Policy Update Magnitude: 0.39306
Value Function Update Magnitude: 0.38793

Collected Steps per Second: 22,042.28223
Overall Steps per Second: 10,707.92393

Timestep Collection Time: 2.26928
Timestep Consumption Time: 2.40203
PPO Batch Consumption Time: 0.28747
Total Iteration Time: 4.67131

Cumulative Model Updates: 201,332
Cumulative Timesteps: 1,678,902,494

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435,410.89307
Policy Entropy: 3.72965
Value Function Loss: 0.01243

Mean KL Divergence: 0.01188
SB3 Clip Fraction: 0.15613
Policy Update Magnitude: 0.32650
Value Function Update Magnitude: 0.34393

Collected Steps per Second: 22,069.26803
Overall Steps per Second: 10,844.85260

Timestep Collection Time: 2.26695
Timestep Consumption Time: 2.34630
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.61325

Cumulative Model Updates: 201,338
Cumulative Timesteps: 1,678,952,524

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1678952524...
Checkpoint 1678952524 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 151,828.81636
Policy Entropy: 3.69039
Value Function Loss: 0.02043

Mean KL Divergence: 0.02304
SB3 Clip Fraction: 0.25427
Policy Update Magnitude: 0.28980
Value Function Update Magnitude: 0.41431

Collected Steps per Second: 21,953.42744
Overall Steps per Second: 10,656.89646

Timestep Collection Time: 2.27782
Timestep Consumption Time: 2.41454
PPO Batch Consumption Time: 0.27787
Total Iteration Time: 4.69236

Cumulative Model Updates: 201,344
Cumulative Timesteps: 1,679,002,530

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 583,085.84447
Policy Entropy: 3.68789
Value Function Loss: 0.04162

Mean KL Divergence: 0.01441
SB3 Clip Fraction: 0.17780
Policy Update Magnitude: 0.44446
Value Function Update Magnitude: 0.51446

Collected Steps per Second: 22,381.87769
Overall Steps per Second: 10,599.86720

Timestep Collection Time: 2.23458
Timestep Consumption Time: 2.48379
PPO Batch Consumption Time: 0.29146
Total Iteration Time: 4.71836

Cumulative Model Updates: 201,350
Cumulative Timesteps: 1,679,052,544

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1679052544...
Checkpoint 1679052544 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 366,053.03962
Policy Entropy: 3.71275
Value Function Loss: 0.04874

Mean KL Divergence: 0.02017
SB3 Clip Fraction: 0.21062
Policy Update Magnitude: 0.70112
Value Function Update Magnitude: 0.47367

Collected Steps per Second: 22,113.58689
Overall Steps per Second: 10,566.53070

Timestep Collection Time: 2.26178
Timestep Consumption Time: 2.47166
PPO Batch Consumption Time: 0.29008
Total Iteration Time: 4.73344

Cumulative Model Updates: 201,356
Cumulative Timesteps: 1,679,102,560

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 3,566.46850
Policy Entropy: 3.73384
Value Function Loss: 0.04611

Mean KL Divergence: 0.02590
SB3 Clip Fraction: 0.26040
Policy Update Magnitude: 0.59950
Value Function Update Magnitude: 0.47620

Collected Steps per Second: 22,208.20705
Overall Steps per Second: 10,625.06298

Timestep Collection Time: 2.25232
Timestep Consumption Time: 2.45542
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.70774

Cumulative Model Updates: 201,362
Cumulative Timesteps: 1,679,152,580

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1679152580...
Checkpoint 1679152580 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 129,371.07195
Policy Entropy: 3.77755
Value Function Loss: 0.04193

Mean KL Divergence: 0.01288
SB3 Clip Fraction: 0.15899
Policy Update Magnitude: 0.65732
Value Function Update Magnitude: 0.42983

Collected Steps per Second: 22,218.62848
Overall Steps per Second: 10,633.87110

Timestep Collection Time: 2.25144
Timestep Consumption Time: 2.45277
PPO Batch Consumption Time: 0.28940
Total Iteration Time: 4.70421

Cumulative Model Updates: 201,368
Cumulative Timesteps: 1,679,202,604

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 186,467.53718
Policy Entropy: 3.75706
Value Function Loss: 0.04027

Mean KL Divergence: 0.00880
SB3 Clip Fraction: 0.11172
Policy Update Magnitude: 0.81925
Value Function Update Magnitude: 0.56365

Collected Steps per Second: 22,394.14328
Overall Steps per Second: 10,710.32888

Timestep Collection Time: 2.23442
Timestep Consumption Time: 2.43752
PPO Batch Consumption Time: 0.27834
Total Iteration Time: 4.67194

Cumulative Model Updates: 201,374
Cumulative Timesteps: 1,679,252,642

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1679252642...
Checkpoint 1679252642 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 149,088.01418
Policy Entropy: 3.73726
Value Function Loss: 0.04048

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.12267
Policy Update Magnitude: 0.84940
Value Function Update Magnitude: 0.54003

Collected Steps per Second: 22,496.80645
Overall Steps per Second: 10,773.59786

Timestep Collection Time: 2.22378
Timestep Consumption Time: 2.41979
PPO Batch Consumption Time: 0.27615
Total Iteration Time: 4.64357

Cumulative Model Updates: 201,380
Cumulative Timesteps: 1,679,302,670

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 51,988.79275
Policy Entropy: 3.74918
Value Function Loss: 0.02767

Mean KL Divergence: 0.00731
SB3 Clip Fraction: 0.09158
Policy Update Magnitude: 0.73815
Value Function Update Magnitude: 0.44153

Collected Steps per Second: 22,754.31915
Overall Steps per Second: 10,742.98177

Timestep Collection Time: 2.19774
Timestep Consumption Time: 2.45721
PPO Batch Consumption Time: 0.27747
Total Iteration Time: 4.65495

Cumulative Model Updates: 201,386
Cumulative Timesteps: 1,679,352,678

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1679352678...
Checkpoint 1679352678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,111.74377
Policy Entropy: 3.73985
Value Function Loss: 0.01959

Mean KL Divergence: 0.00526
SB3 Clip Fraction: 0.06026
Policy Update Magnitude: 0.61807
Value Function Update Magnitude: 0.41289

Collected Steps per Second: 22,800.78973
Overall Steps per Second: 10,695.51112

Timestep Collection Time: 2.19291
Timestep Consumption Time: 2.48195
PPO Batch Consumption Time: 0.28576
Total Iteration Time: 4.67486

Cumulative Model Updates: 201,392
Cumulative Timesteps: 1,679,402,678

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,111.74377
Policy Entropy: 3.74062
Value Function Loss: 0.01563

Mean KL Divergence: 0.00472
SB3 Clip Fraction: 0.05253
Policy Update Magnitude: 0.55805
Value Function Update Magnitude: 0.37569

Collected Steps per Second: 22,378.19608
Overall Steps per Second: 10,610.40040

Timestep Collection Time: 2.23602
Timestep Consumption Time: 2.47992
PPO Batch Consumption Time: 0.29043
Total Iteration Time: 4.71594

Cumulative Model Updates: 201,398
Cumulative Timesteps: 1,679,452,716

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


Saving checkpoint 1679452716...
Checkpoint 1679452716 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,111.74377
Policy Entropy: 3.74374
Value Function Loss: 0.01380

Mean KL Divergence: 0.00443
SB3 Clip Fraction: 0.04584
Policy Update Magnitude: 0.51956
Value Function Update Magnitude: 0.32780

Collected Steps per Second: 22,762.97301
Overall Steps per Second: 10,710.38488

Timestep Collection Time: 2.19778
Timestep Consumption Time: 2.47320
PPO Batch Consumption Time: 0.28612
Total Iteration Time: 4.67098

Cumulative Model Updates: 201,404
Cumulative Timesteps: 1,679,502,744

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 42,111.74377
Policy Entropy: 3.73866
Value Function Loss: 0.01432

Mean KL Divergence: 0.00416
SB3 Clip Fraction: 0.04304
Policy Update Magnitude: 0.54101
Value Function Update Magnitude: 0.36777

Collected Steps per Second: 22,026.91187
Overall Steps per Second: 10,714.28587

Timestep Collection Time: 2.27077
Timestep Consumption Time: 2.39758
PPO Batch Consumption Time: 0.28544
Total Iteration Time: 4.66835

Cumulative Model Updates: 201,410
Cumulative Timesteps: 1,679,552,762

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1679552762...
Checkpoint 1679552762 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 42,111.74377
Policy Entropy: 3.74229
Value Function Loss: 0.01399

Mean KL Divergence: 0.00635
SB3 Clip Fraction: 0.07736
Policy Update Magnitude: 0.53864
Value Function Update Magnitude: 0.52961

Collected Steps per Second: 22,043.09745
Overall Steps per Second: 10,660.32792

Timestep Collection Time: 2.26955
Timestep Consumption Time: 2.42336
PPO Batch Consumption Time: 0.29125
Total Iteration Time: 4.69291

Cumulative Model Updates: 201,416
Cumulative Timesteps: 1,679,602,790

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 204,789.69633
Policy Entropy: 3.74545
Value Function Loss: 0.01749

Mean KL Divergence: 0.00811
SB3 Clip Fraction: 0.10950
Policy Update Magnitude: 0.49087
Value Function Update Magnitude: 0.63610

Collected Steps per Second: 21,468.55255
Overall Steps per Second: 10,399.61263

Timestep Collection Time: 2.32908
Timestep Consumption Time: 2.47898
PPO Batch Consumption Time: 0.28821
Total Iteration Time: 4.80806

Cumulative Model Updates: 201,422
Cumulative Timesteps: 1,679,652,792

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1679652792...
Checkpoint 1679652792 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 20,176.19942
Policy Entropy: 3.75826
Value Function Loss: 0.01829

Mean KL Divergence: 0.00639
SB3 Clip Fraction: 0.08148
Policy Update Magnitude: 0.55054
Value Function Update Magnitude: 0.70188

Collected Steps per Second: 22,117.78670
Overall Steps per Second: 10,636.26908

Timestep Collection Time: 2.26090
Timestep Consumption Time: 2.44057
PPO Batch Consumption Time: 0.28500
Total Iteration Time: 4.70146

Cumulative Model Updates: 201,428
Cumulative Timesteps: 1,679,702,798

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 345,973.77934
Policy Entropy: 3.76144
Value Function Loss: 0.02115

Mean KL Divergence: 0.00733
SB3 Clip Fraction: 0.09623
Policy Update Magnitude: 0.57067
Value Function Update Magnitude: 0.75651

Collected Steps per Second: 22,019.22261
Overall Steps per Second: 10,475.40773

Timestep Collection Time: 2.27074
Timestep Consumption Time: 2.50234
PPO Batch Consumption Time: 0.29292
Total Iteration Time: 4.77308

Cumulative Model Updates: 201,434
Cumulative Timesteps: 1,679,752,798

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1679752798...
Checkpoint 1679752798 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 98,192.60834
Policy Entropy: 3.77324
Value Function Loss: 0.02041

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05639
Policy Update Magnitude: 0.56150
Value Function Update Magnitude: 0.75550

Collected Steps per Second: 21,682.96770
Overall Steps per Second: 10,620.60680

Timestep Collection Time: 2.30642
Timestep Consumption Time: 2.40235
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.70877

Cumulative Model Updates: 201,440
Cumulative Timesteps: 1,679,802,808

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 34,249.53477
Policy Entropy: 3.77885
Value Function Loss: 0.01702

Mean KL Divergence: 0.00480
SB3 Clip Fraction: 0.05451
Policy Update Magnitude: 0.53505
Value Function Update Magnitude: 0.66079

Collected Steps per Second: 22,878.75400
Overall Steps per Second: 10,655.67206

Timestep Collection Time: 2.18543
Timestep Consumption Time: 2.50690
PPO Batch Consumption Time: 0.28652
Total Iteration Time: 4.69234

Cumulative Model Updates: 201,446
Cumulative Timesteps: 1,679,852,808

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1679852808...
Checkpoint 1679852808 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,826.51638
Policy Entropy: 3.77231
Value Function Loss: 0.01448

Mean KL Divergence: 0.00453
SB3 Clip Fraction: 0.04935
Policy Update Magnitude: 0.47724
Value Function Update Magnitude: 0.54860

Collected Steps per Second: 22,902.79405
Overall Steps per Second: 10,827.86253

Timestep Collection Time: 2.18366
Timestep Consumption Time: 2.43516
PPO Batch Consumption Time: 0.27784
Total Iteration Time: 4.61882

Cumulative Model Updates: 201,452
Cumulative Timesteps: 1,679,902,820

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,300.99421
Policy Entropy: 3.77113
Value Function Loss: 0.01256

Mean KL Divergence: 0.00468
SB3 Clip Fraction: 0.05241
Policy Update Magnitude: 0.43808
Value Function Update Magnitude: 0.49797

Collected Steps per Second: 22,519.26106
Overall Steps per Second: 10,603.23889

Timestep Collection Time: 2.22085
Timestep Consumption Time: 2.49582
PPO Batch Consumption Time: 0.29095
Total Iteration Time: 4.71667

Cumulative Model Updates: 201,458
Cumulative Timesteps: 1,679,952,832

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1679952832...
Checkpoint 1679952832 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 19,300.99421
Policy Entropy: 3.75454
Value Function Loss: 0.01256

Mean KL Divergence: 0.00511
SB3 Clip Fraction: 0.06123
Policy Update Magnitude: 0.44699
Value Function Update Magnitude: 0.46422

Collected Steps per Second: 22,812.74084
Overall Steps per Second: 10,727.98876

Timestep Collection Time: 2.19377
Timestep Consumption Time: 2.47122
PPO Batch Consumption Time: 0.28987
Total Iteration Time: 4.66499

Cumulative Model Updates: 201,464
Cumulative Timesteps: 1,680,002,878

Timesteps Collected: 50,046
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 19,300.99421
Policy Entropy: 3.74660
Value Function Loss: 0.01199

Mean KL Divergence: 0.00372
SB3 Clip Fraction: 0.03671
Policy Update Magnitude: 0.45696
Value Function Update Magnitude: 0.40525

Collected Steps per Second: 22,695.37069
Overall Steps per Second: 10,785.22181

Timestep Collection Time: 2.20362
Timestep Consumption Time: 2.43346
PPO Batch Consumption Time: 0.27706
Total Iteration Time: 4.63709

Cumulative Model Updates: 201,470
Cumulative Timesteps: 1,680,052,890

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1680052890...
Checkpoint 1680052890 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 205,351.48478
Policy Entropy: 3.74134
Value Function Loss: 0.01238

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04166
Policy Update Magnitude: 0.49886
Value Function Update Magnitude: 0.46060

Collected Steps per Second: 22,572.98749
Overall Steps per Second: 10,596.63994

Timestep Collection Time: 2.21566
Timestep Consumption Time: 2.50414
PPO Batch Consumption Time: 0.29200
Total Iteration Time: 4.71980

Cumulative Model Updates: 201,476
Cumulative Timesteps: 1,680,102,904

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,345.19746
Policy Entropy: 3.75174
Value Function Loss: 0.01216

Mean KL Divergence: 0.00383
SB3 Clip Fraction: 0.03849
Policy Update Magnitude: 0.53556
Value Function Update Magnitude: 0.60044

Collected Steps per Second: 22,475.14185
Overall Steps per Second: 10,644.91995

Timestep Collection Time: 2.22513
Timestep Consumption Time: 2.47289
PPO Batch Consumption Time: 0.28789
Total Iteration Time: 4.69802

Cumulative Model Updates: 201,482
Cumulative Timesteps: 1,680,152,914

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1680152914...
Checkpoint 1680152914 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,345.19746
Policy Entropy: 3.74138
Value Function Loss: 0.01385

Mean KL Divergence: 0.00508
SB3 Clip Fraction: 0.05688
Policy Update Magnitude: 0.58679
Value Function Update Magnitude: 0.62775

Collected Steps per Second: 22,417.08176
Overall Steps per Second: 10,643.67715

Timestep Collection Time: 2.23160
Timestep Consumption Time: 2.46847
PPO Batch Consumption Time: 0.28741
Total Iteration Time: 4.70007

Cumulative Model Updates: 201,488
Cumulative Timesteps: 1,680,202,940

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,345.19746
Policy Entropy: 3.74668
Value Function Loss: 0.01416

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13319
Policy Update Magnitude: 0.53820
Value Function Update Magnitude: 0.54734

Collected Steps per Second: 22,426.94290
Overall Steps per Second: 10,701.93789

Timestep Collection Time: 2.22964
Timestep Consumption Time: 2.44279
PPO Batch Consumption Time: 0.28218
Total Iteration Time: 4.67242

Cumulative Model Updates: 201,494
Cumulative Timesteps: 1,680,252,944

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1680252944...
Checkpoint 1680252944 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,345.19746
Policy Entropy: 3.74531
Value Function Loss: 0.01512

Mean KL Divergence: 0.01275
SB3 Clip Fraction: 0.16761
Policy Update Magnitude: 0.45531
Value Function Update Magnitude: 0.48053

Collected Steps per Second: 21,465.41797
Overall Steps per Second: 10,704.02631

Timestep Collection Time: 2.33017
Timestep Consumption Time: 2.34265
PPO Batch Consumption Time: 0.27644
Total Iteration Time: 4.67282

Cumulative Model Updates: 201,500
Cumulative Timesteps: 1,680,302,962

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,345.19746
Policy Entropy: 3.75783
Value Function Loss: 0.01478

Mean KL Divergence: 0.01250
SB3 Clip Fraction: 0.16034
Policy Update Magnitude: 0.41052
Value Function Update Magnitude: 0.39026

Collected Steps per Second: 22,092.94582
Overall Steps per Second: 10,791.81269

Timestep Collection Time: 2.26443
Timestep Consumption Time: 2.37130
PPO Batch Consumption Time: 0.27678
Total Iteration Time: 4.63574

Cumulative Model Updates: 201,506
Cumulative Timesteps: 1,680,352,990

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1680352990...
Checkpoint 1680352990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,345.19746
Policy Entropy: 3.76496
Value Function Loss: 0.01303

Mean KL Divergence: 0.00781
SB3 Clip Fraction: 0.10075
Policy Update Magnitude: 0.43623
Value Function Update Magnitude: 0.33592

Collected Steps per Second: 21,909.63764
Overall Steps per Second: 10,661.86326

Timestep Collection Time: 2.28283
Timestep Consumption Time: 2.40828
PPO Batch Consumption Time: 0.27740
Total Iteration Time: 4.69111

Cumulative Model Updates: 201,512
Cumulative Timesteps: 1,680,403,006

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 166,345.19746
Policy Entropy: 3.75962
Value Function Loss: 0.01091

Mean KL Divergence: 0.00828
SB3 Clip Fraction: 0.10673
Policy Update Magnitude: 0.38820
Value Function Update Magnitude: 0.33558

Collected Steps per Second: 22,432.69955
Overall Steps per Second: 10,646.16744

Timestep Collection Time: 2.22933
Timestep Consumption Time: 2.46813
PPO Batch Consumption Time: 0.28915
Total Iteration Time: 4.69747

Cumulative Model Updates: 201,518
Cumulative Timesteps: 1,680,453,016

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1680453016...
Checkpoint 1680453016 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,345.19746
Policy Entropy: 3.73264
Value Function Loss: 0.01283

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12703
Policy Update Magnitude: 0.34234
Value Function Update Magnitude: 0.33923

Collected Steps per Second: 22,373.68781
Overall Steps per Second: 10,688.11731

Timestep Collection Time: 2.23602
Timestep Consumption Time: 2.44469
PPO Batch Consumption Time: 0.28829
Total Iteration Time: 4.68071

Cumulative Model Updates: 201,524
Cumulative Timesteps: 1,680,503,044

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 239,808.26140
Policy Entropy: 3.73493
Value Function Loss: 0.01502

Mean KL Divergence: 0.00975
SB3 Clip Fraction: 0.13460
Policy Update Magnitude: 0.33864
Value Function Update Magnitude: 0.46792

Collected Steps per Second: 23,216.33522
Overall Steps per Second: 10,751.91023

Timestep Collection Time: 2.15400
Timestep Consumption Time: 2.49708
PPO Batch Consumption Time: 0.29189
Total Iteration Time: 4.65108

Cumulative Model Updates: 201,530
Cumulative Timesteps: 1,680,553,052

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1680553052...
Checkpoint 1680553052 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 758,310.36032
Policy Entropy: 3.73682
Value Function Loss: 0.02114

Mean KL Divergence: 0.01053
SB3 Clip Fraction: 0.14291
Policy Update Magnitude: 0.37058
Value Function Update Magnitude: 0.69822

Collected Steps per Second: 22,506.45538
Overall Steps per Second: 10,625.14041

Timestep Collection Time: 2.22167
Timestep Consumption Time: 2.48433
PPO Batch Consumption Time: 0.28932
Total Iteration Time: 4.70601

Cumulative Model Updates: 201,536
Cumulative Timesteps: 1,680,603,054

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 125,520.70379
Policy Entropy: 3.76673
Value Function Loss: 0.02241

Mean KL Divergence: 0.01050
SB3 Clip Fraction: 0.14019
Policy Update Magnitude: 0.40543
Value Function Update Magnitude: 0.72606

Collected Steps per Second: 22,458.77198
Overall Steps per Second: 10,623.90655

Timestep Collection Time: 2.22630
Timestep Consumption Time: 2.48007
PPO Batch Consumption Time: 0.28773
Total Iteration Time: 4.70637

Cumulative Model Updates: 201,542
Cumulative Timesteps: 1,680,653,054

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1680653054...
Checkpoint 1680653054 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 43,773.91421
Policy Entropy: 3.76186
Value Function Loss: 0.02466

Mean KL Divergence: 0.00963
SB3 Clip Fraction: 0.13202
Policy Update Magnitude: 0.42823
Value Function Update Magnitude: 0.63670

Collected Steps per Second: 22,219.90796
Overall Steps per Second: 10,563.60415

Timestep Collection Time: 2.25077
Timestep Consumption Time: 2.48359
PPO Batch Consumption Time: 0.28994
Total Iteration Time: 4.73437

Cumulative Model Updates: 201,548
Cumulative Timesteps: 1,680,703,066

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 122,122.32730
Policy Entropy: 3.73495
Value Function Loss: 0.02160

Mean KL Divergence: 0.01017
SB3 Clip Fraction: 0.13753
Policy Update Magnitude: 0.47449
Value Function Update Magnitude: 0.69947

Collected Steps per Second: 22,276.87830
Overall Steps per Second: 10,724.61124

Timestep Collection Time: 2.24556
Timestep Consumption Time: 2.41885
PPO Batch Consumption Time: 0.27680
Total Iteration Time: 4.66441

Cumulative Model Updates: 201,554
Cumulative Timesteps: 1,680,753,090

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1680753090...
Checkpoint 1680753090 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 364,796.25968
Policy Entropy: 3.70889
Value Function Loss: 0.02936

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.13615
Policy Update Magnitude: 0.50024
Value Function Update Magnitude: 0.75600

Collected Steps per Second: 22,102.37482
Overall Steps per Second: 10,680.68477

Timestep Collection Time: 2.26256
Timestep Consumption Time: 2.41953
PPO Batch Consumption Time: 0.27752
Total Iteration Time: 4.68210

Cumulative Model Updates: 201,560
Cumulative Timesteps: 1,680,803,098

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 60,776.43726
Policy Entropy: 3.73933
Value Function Loss: 0.02969

Mean KL Divergence: 0.00972
SB3 Clip Fraction: 0.13145
Policy Update Magnitude: 0.54849
Value Function Update Magnitude: 0.61215

Collected Steps per Second: 22,016.45864
Overall Steps per Second: 10,452.90553

Timestep Collection Time: 2.27175
Timestep Consumption Time: 2.51313
PPO Batch Consumption Time: 0.29161
Total Iteration Time: 4.78489

Cumulative Model Updates: 201,566
Cumulative Timesteps: 1,680,853,114

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1680853114...
Checkpoint 1680853114 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 13,982.56285
Policy Entropy: 3.76911
Value Function Loss: 0.03035

Mean KL Divergence: 0.00984
SB3 Clip Fraction: 0.13075
Policy Update Magnitude: 0.55993
Value Function Update Magnitude: 0.66065

Collected Steps per Second: 22,560.58437
Overall Steps per Second: 10,619.76174

Timestep Collection Time: 2.21670
Timestep Consumption Time: 2.49245
PPO Batch Consumption Time: 0.28376
Total Iteration Time: 4.70915

Cumulative Model Updates: 201,572
Cumulative Timesteps: 1,680,903,124

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 4,880.37349
Policy Entropy: 3.76571
Value Function Loss: 0.02168

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12409
Policy Update Magnitude: 0.51843
Value Function Update Magnitude: 0.71695

Collected Steps per Second: 23,049.85283
Overall Steps per Second: 10,899.75302

Timestep Collection Time: 2.17017
Timestep Consumption Time: 2.41911
PPO Batch Consumption Time: 0.27741
Total Iteration Time: 4.58928

Cumulative Model Updates: 201,578
Cumulative Timesteps: 1,680,953,146

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1680953146...
Checkpoint 1680953146 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 3,958.52112
Policy Entropy: 3.72203
Value Function Loss: 0.02313

Mean KL Divergence: 0.00996
SB3 Clip Fraction: 0.13462
Policy Update Magnitude: 0.47377
Value Function Update Magnitude: 0.66106

Collected Steps per Second: 22,666.51031
Overall Steps per Second: 10,716.31372

Timestep Collection Time: 2.20696
Timestep Consumption Time: 2.46107
PPO Batch Consumption Time: 0.28504
Total Iteration Time: 4.66802

Cumulative Model Updates: 201,584
Cumulative Timesteps: 1,681,003,170

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,468.93082
Policy Entropy: 3.70481
Value Function Loss: 0.02181

Mean KL Divergence: 0.00982
SB3 Clip Fraction: 0.13341
Policy Update Magnitude: 0.46586
Value Function Update Magnitude: 0.53124

Collected Steps per Second: 22,751.62889
Overall Steps per Second: 10,829.81457

Timestep Collection Time: 2.19844
Timestep Consumption Time: 2.42011
PPO Batch Consumption Time: 0.27862
Total Iteration Time: 4.61855

Cumulative Model Updates: 201,590
Cumulative Timesteps: 1,681,053,188

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1681053188...
Checkpoint 1681053188 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 426,468.93082
Policy Entropy: 3.69288
Value Function Loss: 0.02210

Mean KL Divergence: 0.01046
SB3 Clip Fraction: 0.14122
Policy Update Magnitude: 0.46752
Value Function Update Magnitude: 0.45675

Collected Steps per Second: 21,951.47758
Overall Steps per Second: 10,673.33873

Timestep Collection Time: 2.27866
Timestep Consumption Time: 2.40778
PPO Batch Consumption Time: 0.28638
Total Iteration Time: 4.68644

Cumulative Model Updates: 201,596
Cumulative Timesteps: 1,681,103,208

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 426,468.93082
Policy Entropy: 3.69964
Value Function Loss: 0.01733

Mean KL Divergence: 0.00933
SB3 Clip Fraction: 0.13039
Policy Update Magnitude: 0.41792
Value Function Update Magnitude: 0.45605

Collected Steps per Second: 22,158.00959
Overall Steps per Second: 10,854.69011

Timestep Collection Time: 2.25760
Timestep Consumption Time: 2.35091
PPO Batch Consumption Time: 0.27746
Total Iteration Time: 4.60851

Cumulative Model Updates: 201,602
Cumulative Timesteps: 1,681,153,232

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1681153232...
Checkpoint 1681153232 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 510,066.94726
Policy Entropy: 3.70353
Value Function Loss: 0.01826

Mean KL Divergence: 0.00922
SB3 Clip Fraction: 0.12896
Policy Update Magnitude: 0.37797
Value Function Update Magnitude: 0.48560

Collected Steps per Second: 21,864.32345
Overall Steps per Second: 10,759.78900

Timestep Collection Time: 2.28793
Timestep Consumption Time: 2.36123
PPO Batch Consumption Time: 0.28289
Total Iteration Time: 4.64916

Cumulative Model Updates: 201,608
Cumulative Timesteps: 1,681,203,256

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 510,066.94726
Policy Entropy: 3.70805
Value Function Loss: 0.01811

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13351
Policy Update Magnitude: 0.37334
Value Function Update Magnitude: 0.52653

Collected Steps per Second: 21,768.52434
Overall Steps per Second: 10,468.19692

Timestep Collection Time: 2.29699
Timestep Consumption Time: 2.47958
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.77656

Cumulative Model Updates: 201,614
Cumulative Timesteps: 1,681,253,258

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1681253258...
Checkpoint 1681253258 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301,129.77681
Policy Entropy: 3.72744
Value Function Loss: 0.02215

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12993
Policy Update Magnitude: 0.41454
Value Function Update Magnitude: 0.45279

Collected Steps per Second: 21,739.10114
Overall Steps per Second: 10,650.07497

Timestep Collection Time: 2.30037
Timestep Consumption Time: 2.39518
PPO Batch Consumption Time: 0.27597
Total Iteration Time: 4.69555

Cumulative Model Updates: 201,620
Cumulative Timesteps: 1,681,303,266

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 301,129.77681
Policy Entropy: 3.72949
Value Function Loss: 0.01751

Mean KL Divergence: 0.00957
SB3 Clip Fraction: 0.13299
Policy Update Magnitude: 0.39434
Value Function Update Magnitude: 0.40666

Collected Steps per Second: 22,352.96495
Overall Steps per Second: 10,587.79902

Timestep Collection Time: 2.23693
Timestep Consumption Time: 2.48568
PPO Batch Consumption Time: 0.28799
Total Iteration Time: 4.72261

Cumulative Model Updates: 201,626
Cumulative Timesteps: 1,681,353,268

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1681353268...
Checkpoint 1681353268 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 301,129.77681
Policy Entropy: 3.73484
Value Function Loss: 0.01846

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12758
Policy Update Magnitude: 0.43723
Value Function Update Magnitude: 0.55508

Collected Steps per Second: 22,852.16495
Overall Steps per Second: 10,680.25105

Timestep Collection Time: 2.18841
Timestep Consumption Time: 2.49406
PPO Batch Consumption Time: 0.28623
Total Iteration Time: 4.68247

Cumulative Model Updates: 201,632
Cumulative Timesteps: 1,681,403,278

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 84,060.43858
Policy Entropy: 3.73587
Value Function Loss: 0.01919

Mean KL Divergence: 0.00907
SB3 Clip Fraction: 0.12816
Policy Update Magnitude: 0.48356
Value Function Update Magnitude: 0.81084

Collected Steps per Second: 22,707.24389
Overall Steps per Second: 10,651.32542

Timestep Collection Time: 2.20273
Timestep Consumption Time: 2.49321
PPO Batch Consumption Time: 0.28683
Total Iteration Time: 4.69594

Cumulative Model Updates: 201,638
Cumulative Timesteps: 1,681,453,296

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1681453296...
Checkpoint 1681453296 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 9,710.21435
Policy Entropy: 3.74780
Value Function Loss: 0.02188

Mean KL Divergence: 0.00919
SB3 Clip Fraction: 0.12621
Policy Update Magnitude: 0.52251
Value Function Update Magnitude: 0.94232

Collected Steps per Second: 22,839.48216
Overall Steps per Second: 10,641.54079

Timestep Collection Time: 2.18998
Timestep Consumption Time: 2.51028
PPO Batch Consumption Time: 0.29290
Total Iteration Time: 4.70026

Cumulative Model Updates: 201,644
Cumulative Timesteps: 1,681,503,314

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 2,250.89198
Policy Entropy: 3.74130
Value Function Loss: 0.02346

Mean KL Divergence: 0.00952
SB3 Clip Fraction: 0.13098
Policy Update Magnitude: 0.50196
Value Function Update Magnitude: 0.89315

Collected Steps per Second: 23,039.52221
Overall Steps per Second: 10,860.40766

Timestep Collection Time: 2.17027
Timestep Consumption Time: 2.43379
PPO Batch Consumption Time: 0.27879
Total Iteration Time: 4.60406

Cumulative Model Updates: 201,650
Cumulative Timesteps: 1,681,553,316

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1681553316...
Checkpoint 1681553316 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 787.76032
Policy Entropy: 3.73211
Value Function Loss: 0.02479

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12494
Policy Update Magnitude: 0.53280
Value Function Update Magnitude: 0.88894

Collected Steps per Second: 22,765.21206
Overall Steps per Second: 10,691.48055

Timestep Collection Time: 2.19651
Timestep Consumption Time: 2.48049
PPO Batch Consumption Time: 0.28752
Total Iteration Time: 4.67699

Cumulative Model Updates: 201,656
Cumulative Timesteps: 1,681,603,320

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 428,767.68553
Policy Entropy: 3.71727
Value Function Loss: 0.02286

Mean KL Divergence: 0.01001
SB3 Clip Fraction: 0.13534
Policy Update Magnitude: 0.52747
Value Function Update Magnitude: 0.89925

Collected Steps per Second: 22,878.63726
Overall Steps per Second: 10,823.51530

Timestep Collection Time: 2.18667
Timestep Consumption Time: 2.43549
PPO Batch Consumption Time: 0.27772
Total Iteration Time: 4.62216

Cumulative Model Updates: 201,662
Cumulative Timesteps: 1,681,653,348

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1681653348...
Checkpoint 1681653348 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 327,970.43695
Policy Entropy: 3.72043
Value Function Loss: 0.02512

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.13339
Policy Update Magnitude: 0.50888
Value Function Update Magnitude: 0.79054

Collected Steps per Second: 21,340.25396
Overall Steps per Second: 10,342.20568

Timestep Collection Time: 2.34383
Timestep Consumption Time: 2.49247
PPO Batch Consumption Time: 0.29156
Total Iteration Time: 4.83630

Cumulative Model Updates: 201,668
Cumulative Timesteps: 1,681,703,366

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 265,664.69003
Policy Entropy: 3.72290
Value Function Loss: 0.02278

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13383
Policy Update Magnitude: 0.50891
Value Function Update Magnitude: 0.62067

Collected Steps per Second: 22,173.90365
Overall Steps per Second: 10,543.63054

Timestep Collection Time: 2.25526
Timestep Consumption Time: 2.48769
PPO Batch Consumption Time: 0.28972
Total Iteration Time: 4.74296

Cumulative Model Updates: 201,674
Cumulative Timesteps: 1,681,753,374

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1681753374...
Checkpoint 1681753374 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 433,397.45509
Policy Entropy: 3.70863
Value Function Loss: 0.02399

Mean KL Divergence: 0.00985
SB3 Clip Fraction: 0.13513
Policy Update Magnitude: 0.47030
Value Function Update Magnitude: 0.55943

Collected Steps per Second: 22,427.20394
Overall Steps per Second: 10,584.98963

Timestep Collection Time: 2.23059
Timestep Consumption Time: 2.49553
PPO Batch Consumption Time: 0.29218
Total Iteration Time: 4.72613

Cumulative Model Updates: 201,680
Cumulative Timesteps: 1,681,803,400

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 540,289.59571
Policy Entropy: 3.71107
Value Function Loss: 0.01971

Mean KL Divergence: 0.00976
SB3 Clip Fraction: 0.13327
Policy Update Magnitude: 0.45149
Value Function Update Magnitude: 0.45329

Collected Steps per Second: 22,790.57966
Overall Steps per Second: 9,967.41091

Timestep Collection Time: 2.19450
Timestep Consumption Time: 2.82325
PPO Batch Consumption Time: 0.33615
Total Iteration Time: 5.01775

Cumulative Model Updates: 201,686
Cumulative Timesteps: 1,681,853,414

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1681853414...
Checkpoint 1681853414 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 540,289.59571
Policy Entropy: 3.71238
Value Function Loss: 0.02085

Mean KL Divergence: 0.01086
SB3 Clip Fraction: 0.14748
Policy Update Magnitude: 0.44755
Value Function Update Magnitude: 0.43689

Collected Steps per Second: 15,590.37145
Overall Steps per Second: 8,546.92952

Timestep Collection Time: 3.20775
Timestep Consumption Time: 2.64348
PPO Batch Consumption Time: 0.30579
Total Iteration Time: 5.85122

Cumulative Model Updates: 201,692
Cumulative Timesteps: 1,681,903,424

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 305,413.53678
Policy Entropy: 3.72291
Value Function Loss: 0.01759

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13258
Policy Update Magnitude: 0.44617
Value Function Update Magnitude: 0.42812

Collected Steps per Second: 19,369.68714
Overall Steps per Second: 9,801.66738

Timestep Collection Time: 2.58135
Timestep Consumption Time: 2.51982
PPO Batch Consumption Time: 0.28824
Total Iteration Time: 5.10117

Cumulative Model Updates: 201,698
Cumulative Timesteps: 1,681,953,424

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1681953424...
Checkpoint 1681953424 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,534.88958
Policy Entropy: 3.72970
Value Function Loss: 0.01658

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12702
Policy Update Magnitude: 0.44971
Value Function Update Magnitude: 0.48548

Collected Steps per Second: 16,727.63731
Overall Steps per Second: 8,627.66730

Timestep Collection Time: 2.99062
Timestep Consumption Time: 2.80770
PPO Batch Consumption Time: 0.30336
Total Iteration Time: 5.79832

Cumulative Model Updates: 201,704
Cumulative Timesteps: 1,682,003,450

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 165,824.24231
Policy Entropy: 3.72447
Value Function Loss: 0.01880

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11392
Policy Update Magnitude: 0.47858
Value Function Update Magnitude: 0.45827

Collected Steps per Second: 21,081.93132
Overall Steps per Second: 9,568.45020

Timestep Collection Time: 2.37293
Timestep Consumption Time: 2.85529
PPO Batch Consumption Time: 0.29255
Total Iteration Time: 5.22822

Cumulative Model Updates: 201,710
Cumulative Timesteps: 1,682,053,476

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1682053476...
Checkpoint 1682053476 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,627.79484
Policy Entropy: 3.72199
Value Function Loss: 0.02402

Mean KL Divergence: 0.00875
SB3 Clip Fraction: 0.11599
Policy Update Magnitude: 0.52881
Value Function Update Magnitude: 0.49811

Collected Steps per Second: 17,521.06093
Overall Steps per Second: 8,755.84372

Timestep Collection Time: 2.85519
Timestep Consumption Time: 2.85825
PPO Batch Consumption Time: 0.33484
Total Iteration Time: 5.71344

Cumulative Model Updates: 201,716
Cumulative Timesteps: 1,682,103,502

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 62,749.43195
Policy Entropy: 3.70480
Value Function Loss: 0.02579

Mean KL Divergence: 0.00894
SB3 Clip Fraction: 0.11611
Policy Update Magnitude: 0.63437
Value Function Update Magnitude: 0.55762

Collected Steps per Second: 18,129.36361
Overall Steps per Second: 9,284.45619

Timestep Collection Time: 2.75851
Timestep Consumption Time: 2.62791
PPO Batch Consumption Time: 0.29477
Total Iteration Time: 5.38642

Cumulative Model Updates: 201,722
Cumulative Timesteps: 1,682,153,512

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1682153512...
Checkpoint 1682153512 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 472,997.00133
Policy Entropy: 3.70493
Value Function Loss: 0.02771

Mean KL Divergence: 0.00915
SB3 Clip Fraction: 0.12182
Policy Update Magnitude: 0.60656
Value Function Update Magnitude: 0.59710

Collected Steps per Second: 20,812.22510
Overall Steps per Second: 10,329.01887

Timestep Collection Time: 2.40368
Timestep Consumption Time: 2.43956
PPO Batch Consumption Time: 0.27816
Total Iteration Time: 4.84325

Cumulative Model Updates: 201,728
Cumulative Timesteps: 1,682,203,538

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 770,010.21944
Policy Entropy: 3.69283
Value Function Loss: 0.03195

Mean KL Divergence: 0.00871
SB3 Clip Fraction: 0.11527
Policy Update Magnitude: 0.62864
Value Function Update Magnitude: 0.60966

Collected Steps per Second: 21,500.50280
Overall Steps per Second: 10,447.71590

Timestep Collection Time: 2.32636
Timestep Consumption Time: 2.46109
PPO Batch Consumption Time: 0.28439
Total Iteration Time: 4.78746

Cumulative Model Updates: 201,734
Cumulative Timesteps: 1,682,253,556

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1682253556...
Checkpoint 1682253556 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 176,345.51525
Policy Entropy: 3.70090
Value Function Loss: 0.03664

Mean KL Divergence: 0.00974
SB3 Clip Fraction: 0.12818
Policy Update Magnitude: 0.67035
Value Function Update Magnitude: 0.57316

Collected Steps per Second: 21,899.43608
Overall Steps per Second: 10,577.51399

Timestep Collection Time: 2.28380
Timestep Consumption Time: 2.44453
PPO Batch Consumption Time: 0.27933
Total Iteration Time: 4.72833

Cumulative Model Updates: 201,740
Cumulative Timesteps: 1,682,303,570

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.70726
Value Function Loss: 0.03555

Mean KL Divergence: 0.00968
SB3 Clip Fraction: 0.13064
Policy Update Magnitude: 0.71156
Value Function Update Magnitude: 0.59145

Collected Steps per Second: 22,518.51431
Overall Steps per Second: 10,493.74205

Timestep Collection Time: 2.22235
Timestep Consumption Time: 2.54659
PPO Batch Consumption Time: 0.29397
Total Iteration Time: 4.76894

Cumulative Model Updates: 201,746
Cumulative Timesteps: 1,682,353,614

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1682353614...
Checkpoint 1682353614 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.68845
Value Function Loss: 0.03412

Mean KL Divergence: 0.01022
SB3 Clip Fraction: 0.13418
Policy Update Magnitude: 0.68670
Value Function Update Magnitude: 0.57846

Collected Steps per Second: 18,909.25696
Overall Steps per Second: 9,529.57247

Timestep Collection Time: 2.64537
Timestep Consumption Time: 2.60376
PPO Batch Consumption Time: 0.29724
Total Iteration Time: 5.24913

Cumulative Model Updates: 201,752
Cumulative Timesteps: 1,682,403,636

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.68811
Value Function Loss: 0.02921

Mean KL Divergence: 0.01097
SB3 Clip Fraction: 0.14232
Policy Update Magnitude: 0.67300
Value Function Update Magnitude: 0.54255

Collected Steps per Second: 21,614.06911
Overall Steps per Second: 10,316.95114

Timestep Collection Time: 2.31460
Timestep Consumption Time: 2.53450
PPO Batch Consumption Time: 0.28856
Total Iteration Time: 4.84911

Cumulative Model Updates: 201,758
Cumulative Timesteps: 1,682,453,664

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1682453664...
Checkpoint 1682453664 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.65922
Value Function Loss: 0.03151

Mean KL Divergence: 0.01110
SB3 Clip Fraction: 0.14522
Policy Update Magnitude: 0.60179
Value Function Update Magnitude: 0.48483

Collected Steps per Second: 18,134.50565
Overall Steps per Second: 9,502.45435

Timestep Collection Time: 2.75795
Timestep Consumption Time: 2.50533
PPO Batch Consumption Time: 0.28733
Total Iteration Time: 5.26327

Cumulative Model Updates: 201,764
Cumulative Timesteps: 1,682,503,678

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.67805
Value Function Loss: 0.02463

Mean KL Divergence: 0.00990
SB3 Clip Fraction: 0.13443
Policy Update Magnitude: 0.53817
Value Function Update Magnitude: 0.48309

Collected Steps per Second: 21,624.55005
Overall Steps per Second: 10,514.00592

Timestep Collection Time: 2.31246
Timestep Consumption Time: 2.44367
PPO Batch Consumption Time: 0.27739
Total Iteration Time: 4.75613

Cumulative Model Updates: 201,770
Cumulative Timesteps: 1,682,553,684

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


Saving checkpoint 1682553684...
Checkpoint 1682553684 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.67568
Value Function Loss: 0.02353

Mean KL Divergence: 0.01051
SB3 Clip Fraction: 0.13992
Policy Update Magnitude: 0.49559
Value Function Update Magnitude: 0.49816

Collected Steps per Second: 19,933.77457
Overall Steps per Second: 10,149.31850

Timestep Collection Time: 2.50961
Timestep Consumption Time: 2.41939
PPO Batch Consumption Time: 0.28745
Total Iteration Time: 4.92900

Cumulative Model Updates: 201,776
Cumulative Timesteps: 1,682,603,710

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.70700
Value Function Loss: 0.01847

Mean KL Divergence: 0.00953
SB3 Clip Fraction: 0.12868
Policy Update Magnitude: 0.45474
Value Function Update Magnitude: 0.39309

Collected Steps per Second: 20,900.52459
Overall Steps per Second: 10,467.59960

Timestep Collection Time: 2.39286
Timestep Consumption Time: 2.38493
PPO Batch Consumption Time: 0.27860
Total Iteration Time: 4.77779

Cumulative Model Updates: 201,782
Cumulative Timesteps: 1,682,653,722

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1682653722...
Checkpoint 1682653722 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.71286
Value Function Loss: 0.01610

Mean KL Divergence: 0.00955
SB3 Clip Fraction: 0.13019
Policy Update Magnitude: 0.42292
Value Function Update Magnitude: 0.29895

Collected Steps per Second: 21,706.27862
Overall Steps per Second: 10,173.21689

Timestep Collection Time: 2.30376
Timestep Consumption Time: 2.61170
PPO Batch Consumption Time: 0.32094
Total Iteration Time: 4.91546

Cumulative Model Updates: 201,788
Cumulative Timesteps: 1,682,703,728

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.71723
Value Function Loss: 0.01361

Mean KL Divergence: 0.00901
SB3 Clip Fraction: 0.12315
Policy Update Magnitude: 0.40039
Value Function Update Magnitude: 0.30325

Collected Steps per Second: 18,832.56541
Overall Steps per Second: 9,496.23124

Timestep Collection Time: 2.65625
Timestep Consumption Time: 2.61152
PPO Batch Consumption Time: 0.30895
Total Iteration Time: 5.26777

Cumulative Model Updates: 201,794
Cumulative Timesteps: 1,682,753,752

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1682753752...
Checkpoint 1682753752 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.70887
Value Function Loss: 0.01277

Mean KL Divergence: 0.00892
SB3 Clip Fraction: 0.12265
Policy Update Magnitude: 0.40462
Value Function Update Magnitude: 0.33096

Collected Steps per Second: 21,120.60504
Overall Steps per Second: 10,095.63437

Timestep Collection Time: 2.36774
Timestep Consumption Time: 2.58569
PPO Batch Consumption Time: 0.29951
Total Iteration Time: 4.95343

Cumulative Model Updates: 201,800
Cumulative Timesteps: 1,682,803,760

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.71022
Value Function Loss: 0.01124

Mean KL Divergence: 0.00506
SB3 Clip Fraction: 0.05804
Policy Update Magnitude: 0.41999
Value Function Update Magnitude: 0.30608

Collected Steps per Second: 21,085.57542
Overall Steps per Second: 10,368.60273

Timestep Collection Time: 2.37252
Timestep Consumption Time: 2.45224
PPO Batch Consumption Time: 0.27898
Total Iteration Time: 4.82476

Cumulative Model Updates: 201,806
Cumulative Timesteps: 1,682,853,786

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1682853786...
Checkpoint 1682853786 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 44,256.88437
Policy Entropy: 3.70696
Value Function Loss: 0.01053

Mean KL Divergence: 0.00415
SB3 Clip Fraction: 0.04393
Policy Update Magnitude: 0.41057
Value Function Update Magnitude: 0.23701

Collected Steps per Second: 21,112.69097
Overall Steps per Second: 9,990.93842

Timestep Collection Time: 2.36976
Timestep Consumption Time: 2.63798
PPO Batch Consumption Time: 0.30599
Total Iteration Time: 5.00774

Cumulative Model Updates: 201,812
Cumulative Timesteps: 1,682,903,818

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,788.47384
Policy Entropy: 3.72524
Value Function Loss: 0.01174

Mean KL Divergence: 0.00445
SB3 Clip Fraction: 0.04866
Policy Update Magnitude: 0.41640
Value Function Update Magnitude: 0.24579

Collected Steps per Second: 20,237.04332
Overall Steps per Second: 10,116.83607

Timestep Collection Time: 2.47190
Timestep Consumption Time: 2.47273
PPO Batch Consumption Time: 0.28382
Total Iteration Time: 4.94463

Cumulative Model Updates: 201,818
Cumulative Timesteps: 1,682,953,842

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1682953842...
Checkpoint 1682953842 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,788.47384
Policy Entropy: 3.72651
Value Function Loss: 0.01312

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07786
Policy Update Magnitude: 0.48643
Value Function Update Magnitude: 0.36710

Collected Steps per Second: 20,356.93066
Overall Steps per Second: 10,082.77974

Timestep Collection Time: 2.45626
Timestep Consumption Time: 2.50288
PPO Batch Consumption Time: 0.29000
Total Iteration Time: 4.95915

Cumulative Model Updates: 201,824
Cumulative Timesteps: 1,683,003,844

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,788.47384
Policy Entropy: 3.70774
Value Function Loss: 0.01510

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12710
Policy Update Magnitude: 0.48388
Value Function Update Magnitude: 0.43978

Collected Steps per Second: 19,442.81441
Overall Steps per Second: 9,493.41845

Timestep Collection Time: 2.57391
Timestep Consumption Time: 2.69753
PPO Batch Consumption Time: 0.31262
Total Iteration Time: 5.27144

Cumulative Model Updates: 201,830
Cumulative Timesteps: 1,683,053,888

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1683053888...
Checkpoint 1683053888 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,788.47384
Policy Entropy: 3.71201
Value Function Loss: 0.01580

Mean KL Divergence: 0.01077
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.45583
Value Function Update Magnitude: 0.43247

Collected Steps per Second: 19,356.53044
Overall Steps per Second: 9,673.44783

Timestep Collection Time: 2.58373
Timestep Consumption Time: 2.58630
PPO Batch Consumption Time: 0.29956
Total Iteration Time: 5.17003

Cumulative Model Updates: 201,836
Cumulative Timesteps: 1,683,103,900

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,788.47384
Policy Entropy: 3.71002
Value Function Loss: 0.01579

Mean KL Divergence: 0.01175
SB3 Clip Fraction: 0.15393
Policy Update Magnitude: 0.45597
Value Function Update Magnitude: 0.39093

Collected Steps per Second: 21,461.60248
Overall Steps per Second: 10,089.24800

Timestep Collection Time: 2.33114
Timestep Consumption Time: 2.62760
PPO Batch Consumption Time: 0.30192
Total Iteration Time: 4.95874

Cumulative Model Updates: 201,842
Cumulative Timesteps: 1,683,153,930

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1683153930...
Checkpoint 1683153930 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,788.47384
Policy Entropy: 3.70464
Value Function Loss: 0.01678

Mean KL Divergence: 0.01168
SB3 Clip Fraction: 0.15090
Policy Update Magnitude: 0.47617
Value Function Update Magnitude: 0.36519

Collected Steps per Second: 19,962.37145
Overall Steps per Second: 9,827.46477

Timestep Collection Time: 2.50501
Timestep Consumption Time: 2.58338
PPO Batch Consumption Time: 0.30259
Total Iteration Time: 5.08839

Cumulative Model Updates: 201,848
Cumulative Timesteps: 1,683,203,936

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,788.47384
Policy Entropy: 3.69075
Value Function Loss: 0.02043

Mean KL Divergence: 0.01201
SB3 Clip Fraction: 0.15156
Policy Update Magnitude: 0.43682
Value Function Update Magnitude: 0.30466

Collected Steps per Second: 20,333.04521
Overall Steps per Second: 9,960.07445

Timestep Collection Time: 2.45915
Timestep Consumption Time: 2.56109
PPO Batch Consumption Time: 0.29093
Total Iteration Time: 5.02024

Cumulative Model Updates: 201,854
Cumulative Timesteps: 1,683,253,938

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1683253938...
Checkpoint 1683253938 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 95,788.47384
Policy Entropy: 3.69323
Value Function Loss: 0.02347

Mean KL Divergence: 0.01109
SB3 Clip Fraction: 0.14248
Policy Update Magnitude: 0.44999
Value Function Update Magnitude: 0.25417

Collected Steps per Second: 20,981.86098
Overall Steps per Second: 10,345.56431

Timestep Collection Time: 2.38377
Timestep Consumption Time: 2.45076
PPO Batch Consumption Time: 0.29098
Total Iteration Time: 4.83454

Cumulative Model Updates: 201,860
Cumulative Timesteps: 1,683,303,954

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 95,788.47384
Policy Entropy: 3.69796
Value Function Loss: 0.02555

Mean KL Divergence: 0.00979
SB3 Clip Fraction: 0.12964
Policy Update Magnitude: 0.44955
Value Function Update Magnitude: 0.22612

Collected Steps per Second: 21,074.05539
Overall Steps per Second: 10,581.99939

Timestep Collection Time: 2.37306
Timestep Consumption Time: 2.35289
PPO Batch Consumption Time: 0.27727
Total Iteration Time: 4.72595

Cumulative Model Updates: 201,866
Cumulative Timesteps: 1,683,353,964

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1683353964...
Checkpoint 1683353964 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 99,213.62607
Policy Entropy: 3.70187
Value Function Loss: 0.02572

Mean KL Divergence: 0.00983
SB3 Clip Fraction: 0.12592
Policy Update Magnitude: 0.43288
Value Function Update Magnitude: 0.26593

Collected Steps per Second: 21,250.91448
Overall Steps per Second: 10,569.27904

Timestep Collection Time: 2.35406
Timestep Consumption Time: 2.37909
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.73315

Cumulative Model Updates: 201,872
Cumulative Timesteps: 1,683,403,990

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 221,013.66420
Policy Entropy: 3.70604
Value Function Loss: 0.02790

Mean KL Divergence: 0.00997
SB3 Clip Fraction: 0.12936
Policy Update Magnitude: 0.46092
Value Function Update Magnitude: 0.35698

Collected Steps per Second: 21,123.85300
Overall Steps per Second: 10,281.35059

Timestep Collection Time: 2.36803
Timestep Consumption Time: 2.49728
PPO Batch Consumption Time: 0.28598
Total Iteration Time: 4.86531

Cumulative Model Updates: 201,878
Cumulative Timesteps: 1,683,454,012

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


Saving checkpoint 1683454012...
Checkpoint 1683454012 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,459.75285
Policy Entropy: 3.72273
Value Function Loss: 0.02697

Mean KL Divergence: 0.01021
SB3 Clip Fraction: 0.13271
Policy Update Magnitude: 0.49003
Value Function Update Magnitude: 0.34619

Collected Steps per Second: 20,696.83083
Overall Steps per Second: 10,008.42868

Timestep Collection Time: 2.41641
Timestep Consumption Time: 2.58058
PPO Batch Consumption Time: 0.30101
Total Iteration Time: 4.99699

Cumulative Model Updates: 201,884
Cumulative Timesteps: 1,683,504,024

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,459.75285
Policy Entropy: 3.72640
Value Function Loss: 0.02079

Mean KL Divergence: 0.00928
SB3 Clip Fraction: 0.12635
Policy Update Magnitude: 0.48846
Value Function Update Magnitude: 0.38604

Collected Steps per Second: 21,395.39189
Overall Steps per Second: 10,140.12818

Timestep Collection Time: 2.33789
Timestep Consumption Time: 2.59499
PPO Batch Consumption Time: 0.29390
Total Iteration Time: 4.93288

Cumulative Model Updates: 201,890
Cumulative Timesteps: 1,683,554,044

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1683554044...
Checkpoint 1683554044 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,459.75285
Policy Entropy: 3.71168
Value Function Loss: 0.01708

Mean KL Divergence: 0.00969
SB3 Clip Fraction: 0.13058
Policy Update Magnitude: 0.45288
Value Function Update Magnitude: 0.38904

Collected Steps per Second: 20,527.60039
Overall Steps per Second: 9,897.70465

Timestep Collection Time: 2.43575
Timestep Consumption Time: 2.61593
PPO Batch Consumption Time: 0.30316
Total Iteration Time: 5.05168

Cumulative Model Updates: 201,896
Cumulative Timesteps: 1,683,604,044

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,459.75285
Policy Entropy: 3.71356
Value Function Loss: 0.01469

Mean KL Divergence: 0.00926
SB3 Clip Fraction: 0.12830
Policy Update Magnitude: 0.42640
Value Function Update Magnitude: 0.35086

Collected Steps per Second: 20,049.57573
Overall Steps per Second: 9,598.53723

Timestep Collection Time: 2.49541
Timestep Consumption Time: 2.71705
PPO Batch Consumption Time: 0.31752
Total Iteration Time: 5.21246

Cumulative Model Updates: 201,902
Cumulative Timesteps: 1,683,654,076

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1683654076...
Checkpoint 1683654076 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,459.75285
Policy Entropy: 3.70959
Value Function Loss: 0.01442

Mean KL Divergence: 0.00924
SB3 Clip Fraction: 0.12696
Policy Update Magnitude: 0.38590
Value Function Update Magnitude: 0.29855

Collected Steps per Second: 19,542.84658
Overall Steps per Second: 9,646.41699

Timestep Collection Time: 2.56053
Timestep Consumption Time: 2.62689
PPO Batch Consumption Time: 0.30677
Total Iteration Time: 5.18742

Cumulative Model Updates: 201,908
Cumulative Timesteps: 1,683,704,116

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,459.75285
Policy Entropy: 3.71565
Value Function Loss: 0.01627

Mean KL Divergence: 0.00866
SB3 Clip Fraction: 0.11995
Policy Update Magnitude: 0.35414
Value Function Update Magnitude: 0.26082

Collected Steps per Second: 19,418.61630
Overall Steps per Second: 9,332.37630

Timestep Collection Time: 2.57578
Timestep Consumption Time: 2.78385
PPO Batch Consumption Time: 0.32852
Total Iteration Time: 5.35962

Cumulative Model Updates: 201,914
Cumulative Timesteps: 1,683,754,134

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1683754134...
Checkpoint 1683754134 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,459.75285
Policy Entropy: 3.71547
Value Function Loss: 0.01827

Mean KL Divergence: 0.00916
SB3 Clip Fraction: 0.12841
Policy Update Magnitude: 0.44170
Value Function Update Magnitude: 0.34773

Collected Steps per Second: 20,329.89434
Overall Steps per Second: 10,145.12494

Timestep Collection Time: 2.46012
Timestep Consumption Time: 2.46973
PPO Batch Consumption Time: 0.28597
Total Iteration Time: 4.92986

Cumulative Model Updates: 201,920
Cumulative Timesteps: 1,683,804,148

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 117,459.75285
Policy Entropy: 3.71372
Value Function Loss: 0.01835

Mean KL Divergence: 0.00904
SB3 Clip Fraction: 0.12857
Policy Update Magnitude: 0.46583
Value Function Update Magnitude: 0.48817

Collected Steps per Second: 19,876.95126
Overall Steps per Second: 9,895.44871

Timestep Collection Time: 2.51648
Timestep Consumption Time: 2.53837
PPO Batch Consumption Time: 0.29493
Total Iteration Time: 5.05485

Cumulative Model Updates: 201,926
Cumulative Timesteps: 1,683,854,168

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1683854168...
Checkpoint 1683854168 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 117,459.75285
Policy Entropy: 3.71227
Value Function Loss: 0.01814

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12998
Policy Update Magnitude: 0.47509
Value Function Update Magnitude: 0.62860

Collected Steps per Second: 19,725.58662
Overall Steps per Second: 9,997.06049

Timestep Collection Time: 2.53549
Timestep Consumption Time: 2.46738
PPO Batch Consumption Time: 0.29229
Total Iteration Time: 5.00287

Cumulative Model Updates: 201,932
Cumulative Timesteps: 1,683,904,182

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 249,940.98818
Policy Entropy: 3.71352
Value Function Loss: 0.01892

Mean KL Divergence: 0.00925
SB3 Clip Fraction: 0.12833
Policy Update Magnitude: 0.50277
Value Function Update Magnitude: 0.65626

Collected Steps per Second: 21,340.85975
Overall Steps per Second: 10,518.54314

Timestep Collection Time: 2.34339
Timestep Consumption Time: 2.41107
PPO Batch Consumption Time: 0.28728
Total Iteration Time: 4.75446

Cumulative Model Updates: 201,938
Cumulative Timesteps: 1,683,954,192

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


Saving checkpoint 1683954192...
Checkpoint 1683954192 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 107,589.45549
Policy Entropy: 3.72073
Value Function Loss: 0.01739

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.12905
Policy Update Magnitude: 0.48736
Value Function Update Magnitude: 0.73833

Collected Steps per Second: 21,144.07492
Overall Steps per Second: 10,329.99791

Timestep Collection Time: 2.36615
Timestep Consumption Time: 2.47703
PPO Batch Consumption Time: 0.29338
Total Iteration Time: 4.84318

Cumulative Model Updates: 201,944
Cumulative Timesteps: 1,684,004,222

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 107,589.45549
Policy Entropy: 3.72463
Value Function Loss: 0.01710

Mean KL Divergence: 0.00927
SB3 Clip Fraction: 0.13031
Policy Update Magnitude: 0.46303
Value Function Update Magnitude: 0.73375

Collected Steps per Second: 22,076.89977
Overall Steps per Second: 10,653.13580

Timestep Collection Time: 2.26544
Timestep Consumption Time: 2.42932
PPO Batch Consumption Time: 0.28112
Total Iteration Time: 4.69477

Cumulative Model Updates: 201,950
Cumulative Timesteps: 1,684,054,236

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1684054236...
Checkpoint 1684054236 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341,519.15047
Policy Entropy: 3.69380
Value Function Loss: 0.01868

Mean KL Divergence: 0.00903
SB3 Clip Fraction: 0.12779
Policy Update Magnitude: 0.49455
Value Function Update Magnitude: 0.75519

Collected Steps per Second: 21,941.22149
Overall Steps per Second: 10,304.35797

Timestep Collection Time: 2.27882
Timestep Consumption Time: 2.57350
PPO Batch Consumption Time: 0.29136
Total Iteration Time: 4.85232

Cumulative Model Updates: 201,956
Cumulative Timesteps: 1,684,104,236

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341,519.15047
Policy Entropy: 3.69647
Value Function Loss: 0.01767

Mean KL Divergence: 0.00934
SB3 Clip Fraction: 0.13232
Policy Update Magnitude: 0.52193
Value Function Update Magnitude: 0.77999

Collected Steps per Second: 21,681.46042
Overall Steps per Second: 10,459.97906

Timestep Collection Time: 2.30815
Timestep Consumption Time: 2.47618
PPO Batch Consumption Time: 0.28091
Total Iteration Time: 4.78433

Cumulative Model Updates: 201,962
Cumulative Timesteps: 1,684,154,280

Timesteps Collected: 50,044
--------END ITERATION REPORT--------


Saving checkpoint 1684154280...
Checkpoint 1684154280 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341,519.15047
Policy Entropy: 3.68450
Value Function Loss: 0.01775

Mean KL Divergence: 0.00921
SB3 Clip Fraction: 0.12740
Policy Update Magnitude: 0.48110
Value Function Update Magnitude: 0.66262

Collected Steps per Second: 21,907.69918
Overall Steps per Second: 10,509.50198

Timestep Collection Time: 2.28294
Timestep Consumption Time: 2.47599
PPO Batch Consumption Time: 0.28096
Total Iteration Time: 4.75893

Cumulative Model Updates: 201,968
Cumulative Timesteps: 1,684,204,294

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341,519.15047
Policy Entropy: 3.70818
Value Function Loss: 0.01603

Mean KL Divergence: 0.00883
SB3 Clip Fraction: 0.11531
Policy Update Magnitude: 0.43299
Value Function Update Magnitude: 0.46325

Collected Steps per Second: 21,590.73132
Overall Steps per Second: 10,505.25805

Timestep Collection Time: 2.31655
Timestep Consumption Time: 2.44449
PPO Batch Consumption Time: 0.28146
Total Iteration Time: 4.76104

Cumulative Model Updates: 201,974
Cumulative Timesteps: 1,684,254,310

Timesteps Collected: 50,016
--------END ITERATION REPORT--------


Saving checkpoint 1684254310...
Checkpoint 1684254310 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 341,519.15047
Policy Entropy: 3.71125
Value Function Loss: 0.01599

Mean KL Divergence: 0.00940
SB3 Clip Fraction: 0.12806
Policy Update Magnitude: 0.40352
Value Function Update Magnitude: 0.35970

Collected Steps per Second: 21,996.50000
Overall Steps per Second: 10,483.27214

Timestep Collection Time: 2.27309
Timestep Consumption Time: 2.49641
PPO Batch Consumption Time: 0.28955
Total Iteration Time: 4.76950

Cumulative Model Updates: 201,980
Cumulative Timesteps: 1,684,304,310

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 341,519.15047
Policy Entropy: 3.72660
Value Function Loss: 0.01470

Mean KL Divergence: 0.00667
SB3 Clip Fraction: 0.08554
Policy Update Magnitude: 0.46573
Value Function Update Magnitude: 0.36214

Collected Steps per Second: 20,765.98198
Overall Steps per Second: 10,325.55423

Timestep Collection Time: 2.40913
Timestep Consumption Time: 2.43593
PPO Batch Consumption Time: 0.27765
Total Iteration Time: 4.84507

Cumulative Model Updates: 201,986
Cumulative Timesteps: 1,684,354,338

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1684354338...
Checkpoint 1684354338 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 556,790.74000
Policy Entropy: 3.72692
Value Function Loss: 0.01698

Mean KL Divergence: 0.00552
SB3 Clip Fraction: 0.06698
Policy Update Magnitude: 0.57925
Value Function Update Magnitude: 0.55325

Collected Steps per Second: 21,110.10031
Overall Steps per Second: 10,598.18624

Timestep Collection Time: 2.36863
Timestep Consumption Time: 2.34935
PPO Batch Consumption Time: 0.27921
Total Iteration Time: 4.71798

Cumulative Model Updates: 201,992
Cumulative Timesteps: 1,684,404,340

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295,955.02047
Policy Entropy: 3.73221
Value Function Loss: 0.01661

Mean KL Divergence: 0.00410
SB3 Clip Fraction: 0.04255
Policy Update Magnitude: 0.63783
Value Function Update Magnitude: 0.67436

Collected Steps per Second: 21,691.27588
Overall Steps per Second: 10,550.41515

Timestep Collection Time: 2.30563
Timestep Consumption Time: 2.43466
PPO Batch Consumption Time: 0.29134
Total Iteration Time: 4.74029

Cumulative Model Updates: 201,998
Cumulative Timesteps: 1,684,454,352

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


Saving checkpoint 1684454352...
Checkpoint 1684454352 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295,955.02047
Policy Entropy: 3.73494
Value Function Loss: 0.01636

Mean KL Divergence: 0.00457
SB3 Clip Fraction: 0.04778
Policy Update Magnitude: 0.59673
Value Function Update Magnitude: 0.62748

Collected Steps per Second: 20,317.10095
Overall Steps per Second: 10,027.61744

Timestep Collection Time: 2.46216
Timestep Consumption Time: 2.52646
PPO Batch Consumption Time: 0.29262
Total Iteration Time: 4.98862

Cumulative Model Updates: 202,004
Cumulative Timesteps: 1,684,504,376

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 295,955.02047
Policy Entropy: 3.74275
Value Function Loss: 0.01463

Mean KL Divergence: 0.00381
SB3 Clip Fraction: 0.03737
Policy Update Magnitude: 0.51905
Value Function Update Magnitude: 0.45181

Collected Steps per Second: 22,648.57534
Overall Steps per Second: 10,639.61516

Timestep Collection Time: 2.20800
Timestep Consumption Time: 2.49217
PPO Batch Consumption Time: 0.29301
Total Iteration Time: 4.70017

Cumulative Model Updates: 202,010
Cumulative Timesteps: 1,684,554,384

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1684554384...
Checkpoint 1684554384 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 295,955.02047
Policy Entropy: 3.74025
Value Function Loss: 0.01396

Mean KL Divergence: 0.00471
SB3 Clip Fraction: 0.05154
Policy Update Magnitude: 0.47402
Value Function Update Magnitude: 0.34439

Collected Steps per Second: 21,364.22544
Overall Steps per Second: 10,467.23958

Timestep Collection Time: 2.34102
Timestep Consumption Time: 2.43713
PPO Batch Consumption Time: 0.28047
Total Iteration Time: 4.77815

Cumulative Model Updates: 202,016
Cumulative Timesteps: 1,684,604,398

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 401,799.17116
Policy Entropy: 3.73622
Value Function Loss: 0.01460

Mean KL Divergence: 0.00523
SB3 Clip Fraction: 0.06022
Policy Update Magnitude: 0.50786
Value Function Update Magnitude: 0.38268

Collected Steps per Second: 22,212.84524
Overall Steps per Second: 10,530.02531

Timestep Collection Time: 2.25185
Timestep Consumption Time: 2.49838
PPO Batch Consumption Time: 0.28845
Total Iteration Time: 4.75023

Cumulative Model Updates: 202,022
Cumulative Timesteps: 1,684,654,418

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


Saving checkpoint 1684654418...
Checkpoint 1684654418 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 140,101.75839
Policy Entropy: 3.74306
Value Function Loss: 0.01667

Mean KL Divergence: 0.00900
SB3 Clip Fraction: 0.11960
Policy Update Magnitude: 0.50319
Value Function Update Magnitude: 0.42168

Collected Steps per Second: 21,572.86165
Overall Steps per Second: 10,055.04644

Timestep Collection Time: 2.31856
Timestep Consumption Time: 2.65586
PPO Batch Consumption Time: 0.30449
Total Iteration Time: 4.97442

Cumulative Model Updates: 202,028
Cumulative Timesteps: 1,684,704,436

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 140,101.75839
Policy Entropy: 3.74307
Value Function Loss: 0.01616

Mean KL Divergence: 0.01000
SB3 Clip Fraction: 0.13353
Policy Update Magnitude: 0.43610
Value Function Update Magnitude: 0.48009

Collected Steps per Second: 18,147.63299
Overall Steps per Second: 9,086.44724

Timestep Collection Time: 2.75595
Timestep Consumption Time: 2.74829
PPO Batch Consumption Time: 0.31603
Total Iteration Time: 5.50424

Cumulative Model Updates: 202,034
Cumulative Timesteps: 1,684,754,450

Timesteps Collected: 50,014
--------END ITERATION REPORT--------


Saving checkpoint 1684754450...
Checkpoint 1684754450 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 191,361.61938
Policy Entropy: 3.75321
Value Function Loss: 0.01578

Mean KL Divergence: 0.00528
SB3 Clip Fraction: 0.06320
Policy Update Magnitude: 0.47748
Value Function Update Magnitude: 0.48361

Collected Steps per Second: 19,435.51888
Overall Steps per Second: 9,692.85199

Timestep Collection Time: 2.57323
Timestep Consumption Time: 2.58645
PPO Batch Consumption Time: 0.29430
Total Iteration Time: 5.15968

Cumulative Model Updates: 202,040
Cumulative Timesteps: 1,684,804,462

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 66,732.25259
Policy Entropy: 3.74022
Value Function Loss: 0.01522

Mean KL Divergence: 0.00519
SB3 Clip Fraction: 0.06035
Policy Update Magnitude: 0.57657
Value Function Update Magnitude: 0.49720

Collected Steps per Second: 21,156.85379
Overall Steps per Second: 10,239.03254

Timestep Collection Time: 2.36462
Timestep Consumption Time: 2.52138
PPO Batch Consumption Time: 0.29099
Total Iteration Time: 4.88601

Cumulative Model Updates: 202,046
Cumulative Timesteps: 1,684,854,490

Timesteps Collected: 50,028
--------END ITERATION REPORT--------


Saving checkpoint 1684854490...
Checkpoint 1684854490 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 23,271.18187
Policy Entropy: 3.74291
Value Function Loss: 0.01657

Mean KL Divergence: 0.00491
SB3 Clip Fraction: 0.05440
Policy Update Magnitude: 0.58942
Value Function Update Magnitude: 0.52237

Collected Steps per Second: 21,608.98751
Overall Steps per Second: 10,543.08339

Timestep Collection Time: 2.31617
Timestep Consumption Time: 2.43102
PPO Batch Consumption Time: 0.27825
Total Iteration Time: 4.74719

Cumulative Model Updates: 202,052
Cumulative Timesteps: 1,684,904,540

Timesteps Collected: 50,050
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 8,130.54517
Policy Entropy: 3.74770
Value Function Loss: 0.01594

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07332
Policy Update Magnitude: 0.55403
Value Function Update Magnitude: 0.54847

Collected Steps per Second: 21,709.86166
Overall Steps per Second: 10,518.11338

Timestep Collection Time: 2.30421
Timestep Consumption Time: 2.45178
PPO Batch Consumption Time: 0.29620
Total Iteration Time: 4.75599

Cumulative Model Updates: 202,058
Cumulative Timesteps: 1,684,954,564

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1684954564...
Checkpoint 1684954564 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 2,308.43492
Policy Entropy: 3.74631
Value Function Loss: 0.01920

Mean KL Divergence: 0.00619
SB3 Clip Fraction: 0.07592
Policy Update Magnitude: 0.56533
Value Function Update Magnitude: 0.48492

Collected Steps per Second: 17,779.68851
Overall Steps per Second: 9,094.79459

Timestep Collection Time: 2.81265
Timestep Consumption Time: 2.68588
PPO Batch Consumption Time: 0.32730
Total Iteration Time: 5.49853

Cumulative Model Updates: 202,064
Cumulative Timesteps: 1,685,004,572

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 811.41315
Policy Entropy: 3.75094
Value Function Loss: 0.02042

Mean KL Divergence: 0.00529
SB3 Clip Fraction: 0.06127
Policy Update Magnitude: 0.58548
Value Function Update Magnitude: 0.44417

Collected Steps per Second: 19,010.94603
Overall Steps per Second: 9,750.04995

Timestep Collection Time: 2.63217
Timestep Consumption Time: 2.50011
PPO Batch Consumption Time: 0.29427
Total Iteration Time: 5.13228

Cumulative Model Updates: 202,070
Cumulative Timesteps: 1,685,054,612

Timesteps Collected: 50,040
--------END ITERATION REPORT--------


Saving checkpoint 1685054612...
Checkpoint 1685054612 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.43300
Policy Entropy: 3.76076
Value Function Loss: 0.01819

Mean KL Divergence: 0.02035
SB3 Clip Fraction: 0.22206
Policy Update Magnitude: 0.49758
Value Function Update Magnitude: 0.41832

Collected Steps per Second: 19,097.07543
Overall Steps per Second: 9,558.12902

Timestep Collection Time: 2.61841
Timestep Consumption Time: 2.61316
PPO Batch Consumption Time: 0.31502
Total Iteration Time: 5.23157

Cumulative Model Updates: 202,076
Cumulative Timesteps: 1,685,104,616

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.43300
Policy Entropy: 3.78552
Value Function Loss: 0.01402

Mean KL Divergence: 0.01769
SB3 Clip Fraction: 0.21489
Policy Update Magnitude: 0.41328
Value Function Update Magnitude: 0.38374

Collected Steps per Second: 19,146.20862
Overall Steps per Second: 9,377.58457

Timestep Collection Time: 2.61274
Timestep Consumption Time: 2.72169
PPO Batch Consumption Time: 0.31818
Total Iteration Time: 5.33442

Cumulative Model Updates: 202,082
Cumulative Timesteps: 1,685,154,640

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


Saving checkpoint 1685154640...
Checkpoint 1685154640 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.43300
Policy Entropy: 3.77587
Value Function Loss: 0.01147

Mean KL Divergence: 0.01658
SB3 Clip Fraction: 0.21412
Policy Update Magnitude: 0.35759
Value Function Update Magnitude: 0.35499

Collected Steps per Second: 18,966.93095
Overall Steps per Second: 9,467.30008

Timestep Collection Time: 2.63722
Timestep Consumption Time: 2.64623
PPO Batch Consumption Time: 0.31177
Total Iteration Time: 5.28345

Cumulative Model Updates: 202,088
Cumulative Timesteps: 1,685,204,660

Timesteps Collected: 50,020
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.43300
Policy Entropy: 3.75208
Value Function Loss: 0.01041

Mean KL Divergence: 0.01239
SB3 Clip Fraction: 0.16102
Policy Update Magnitude: 0.31299
Value Function Update Magnitude: 0.33726

Collected Steps per Second: 21,064.06414
Overall Steps per Second: 10,230.50691

Timestep Collection Time: 2.37457
Timestep Consumption Time: 2.51454
PPO Batch Consumption Time: 0.27941
Total Iteration Time: 4.88910

Cumulative Model Updates: 202,094
Cumulative Timesteps: 1,685,254,678

Timesteps Collected: 50,018
--------END ITERATION REPORT--------


Saving checkpoint 1685254678...
Checkpoint 1685254678 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.43300
Policy Entropy: 3.69861
Value Function Loss: 0.01210

Mean KL Divergence: 0.01346
SB3 Clip Fraction: 0.17276
Policy Update Magnitude: 0.31424
Value Function Update Magnitude: 0.31159

Collected Steps per Second: 18,768.85313
Overall Steps per Second: 9,284.39693

Timestep Collection Time: 2.66537
Timestep Consumption Time: 2.72281
PPO Batch Consumption Time: 0.32632
Total Iteration Time: 5.38818

Cumulative Model Updates: 202,100
Cumulative Timesteps: 1,685,304,704

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.43300
Policy Entropy: 3.68970
Value Function Loss: 0.01491

Mean KL Divergence: 0.00860
SB3 Clip Fraction: 0.11136
Policy Update Magnitude: 0.38547
Value Function Update Magnitude: 0.30763

Collected Steps per Second: 15,167.26800
Overall Steps per Second: 8,071.60419

Timestep Collection Time: 3.29868
Timestep Consumption Time: 2.89984
PPO Batch Consumption Time: 0.34548
Total Iteration Time: 6.19852

Cumulative Model Updates: 202,106
Cumulative Timesteps: 1,685,354,736

Timesteps Collected: 50,032
--------END ITERATION REPORT--------


Saving checkpoint 1685354736...
Checkpoint 1685354736 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.43300
Policy Entropy: 3.69313
Value Function Loss: 0.01641

Mean KL Divergence: 0.01241
SB3 Clip Fraction: 0.15893
Policy Update Magnitude: 0.40643
Value Function Update Magnitude: 0.30101

Collected Steps per Second: 19,196.87359
Overall Steps per Second: 9,072.47092

Timestep Collection Time: 2.60511
Timestep Consumption Time: 2.90717
PPO Batch Consumption Time: 0.34617
Total Iteration Time: 5.51228

Cumulative Model Updates: 202,112
Cumulative Timesteps: 1,685,404,746

Timesteps Collected: 50,010
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.43300
Policy Entropy: 3.69437
Value Function Loss: 0.01967

Mean KL Divergence: 0.01376
SB3 Clip Fraction: 0.17451
Policy Update Magnitude: 0.40363
Value Function Update Magnitude: 0.30196

Collected Steps per Second: 19,674.94823
Overall Steps per Second: 9,077.72727

Timestep Collection Time: 2.54140
Timestep Consumption Time: 2.96680
PPO Batch Consumption Time: 0.35715
Total Iteration Time: 5.50821

Cumulative Model Updates: 202,118
Cumulative Timesteps: 1,685,454,748

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1685454748...
Checkpoint 1685454748 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 435.43300
Policy Entropy: 3.70557
Value Function Loss: 0.02008

Mean KL Divergence: 0.01016
SB3 Clip Fraction: 0.13203
Policy Update Magnitude: 0.47878
Value Function Update Magnitude: 0.34230

Collected Steps per Second: 17,485.04977
Overall Steps per Second: 8,618.55447

Timestep Collection Time: 2.86096
Timestep Consumption Time: 2.94326
PPO Batch Consumption Time: 0.35879
Total Iteration Time: 5.80422

Cumulative Model Updates: 202,124
Cumulative Timesteps: 1,685,504,772

Timesteps Collected: 50,024
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 435.43300
Policy Entropy: 3.69579
Value Function Loss: 0.02377

Mean KL Divergence: 0.01169
SB3 Clip Fraction: 0.14943
Policy Update Magnitude: 0.47444
Value Function Update Magnitude: 0.32022

Collected Steps per Second: 16,874.28787
Overall Steps per Second: 9,170.26913

Timestep Collection Time: 2.96558
Timestep Consumption Time: 2.49141
PPO Batch Consumption Time: 0.29897
Total Iteration Time: 5.45698

Cumulative Model Updates: 202,130
Cumulative Timesteps: 1,685,554,814

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1685554814...
Checkpoint 1685554814 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 46,167.03455
Policy Entropy: 3.70048
Value Function Loss: 0.02416

Mean KL Divergence: 0.01595
SB3 Clip Fraction: 0.18940
Policy Update Magnitude: 0.48644
Value Function Update Magnitude: 0.25916

Collected Steps per Second: 17,935.92827
Overall Steps per Second: 9,495.20933

Timestep Collection Time: 2.78893
Timestep Consumption Time: 2.47920
PPO Batch Consumption Time: 0.29645
Total Iteration Time: 5.26813

Cumulative Model Updates: 202,136
Cumulative Timesteps: 1,685,604,836

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 555,098.84211
Policy Entropy: 3.68290
Value Function Loss: 0.02872

Mean KL Divergence: 0.02157
SB3 Clip Fraction: 0.22693
Policy Update Magnitude: 0.51199
Value Function Update Magnitude: 0.28177

Collected Steps per Second: 20,229.82181
Overall Steps per Second: 9,743.98774

Timestep Collection Time: 2.47170
Timestep Consumption Time: 2.65988
PPO Batch Consumption Time: 0.31788
Total Iteration Time: 5.13157

Cumulative Model Updates: 202,142
Cumulative Timesteps: 1,685,654,838

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1685654838...
Checkpoint 1685654838 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 166,442.17441
Policy Entropy: 3.71425
Value Function Loss: 0.03297

Mean KL Divergence: 0.01152
SB3 Clip Fraction: 0.14510
Policy Update Magnitude: 0.55771
Value Function Update Magnitude: 0.37269

Collected Steps per Second: 15,303.06915
Overall Steps per Second: 8,512.99566

Timestep Collection Time: 3.26980
Timestep Consumption Time: 2.60804
PPO Batch Consumption Time: 0.29306
Total Iteration Time: 5.87784

Cumulative Model Updates: 202,148
Cumulative Timesteps: 1,685,704,876

Timesteps Collected: 50,038
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 38,091.11417
Policy Entropy: 3.73256
Value Function Loss: 0.02998

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14380
Policy Update Magnitude: 0.65926
Value Function Update Magnitude: 0.42510

Collected Steps per Second: 17,254.57755
Overall Steps per Second: 7,529.20919

Timestep Collection Time: 2.89825
Timestep Consumption Time: 3.74362
PPO Batch Consumption Time: 0.48972
Total Iteration Time: 6.64187

Cumulative Model Updates: 202,154
Cumulative Timesteps: 1,685,754,884

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


Saving checkpoint 1685754884...
Checkpoint 1685754884 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,091.11417
Policy Entropy: 3.73161
Value Function Loss: 0.02807

Mean KL Divergence: 0.01127
SB3 Clip Fraction: 0.14162
Policy Update Magnitude: 0.60217
Value Function Update Magnitude: 0.49893

Collected Steps per Second: 16,284.26600
Overall Steps per Second: 6,992.89152

Timestep Collection Time: 3.07119
Timestep Consumption Time: 4.08065
PPO Batch Consumption Time: 0.54875
Total Iteration Time: 7.15183

Cumulative Model Updates: 202,160
Cumulative Timesteps: 1,685,804,896

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 103,014.44562
Policy Entropy: 3.72725
Value Function Loss: 0.02830

Mean KL Divergence: 0.01105
SB3 Clip Fraction: 0.14185
Policy Update Magnitude: 0.62262
Value Function Update Magnitude: 0.43886

Collected Steps per Second: 12,205.20393
Overall Steps per Second: 5,970.66275

Timestep Collection Time: 4.09956
Timestep Consumption Time: 4.28075
PPO Batch Consumption Time: 0.57254
Total Iteration Time: 8.38031

Cumulative Model Updates: 202,166
Cumulative Timesteps: 1,685,854,932

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


Saving checkpoint 1685854932...
Checkpoint 1685854932 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 217,899.13861
Policy Entropy: 3.72401
Value Function Loss: 0.02876

Mean KL Divergence: 0.00800
SB3 Clip Fraction: 0.10193
Policy Update Magnitude: 0.69890
Value Function Update Magnitude: 0.57839

Collected Steps per Second: 14,846.55136
Overall Steps per Second: 6,957.45922

Timestep Collection Time: 3.36927
Timestep Consumption Time: 3.82043
PPO Batch Consumption Time: 0.50342
Total Iteration Time: 7.18969

Cumulative Model Updates: 202,172
Cumulative Timesteps: 1,685,904,954

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 130,089.47119
Policy Entropy: 3.74107
Value Function Loss: 0.02798

Mean KL Divergence: 0.00719
SB3 Clip Fraction: 0.09311
Policy Update Magnitude: 0.77024
Value Function Update Magnitude: 0.60308

Collected Steps per Second: 15,360.66520
Overall Steps per Second: 7,494.53588

Timestep Collection Time: 3.25676
Timestep Consumption Time: 3.41824
PPO Batch Consumption Time: 0.43986
Total Iteration Time: 6.67500

Cumulative Model Updates: 202,178
Cumulative Timesteps: 1,685,954,980

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1685954980...
Checkpoint 1685954980 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 29,773.77169
Policy Entropy: 3.74536
Value Function Loss: 0.02533

Mean KL Divergence: 0.00763
SB3 Clip Fraction: 0.09691
Policy Update Magnitude: 0.70615
Value Function Update Magnitude: 0.56869

Collected Steps per Second: 16,250.48957
Overall Steps per Second: 7,741.08880

Timestep Collection Time: 3.07720
Timestep Consumption Time: 3.38262
PPO Batch Consumption Time: 0.43490
Total Iteration Time: 6.45981

Cumulative Model Updates: 202,184
Cumulative Timesteps: 1,686,004,986

Timesteps Collected: 50,006
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 461,654.97475
Policy Entropy: 3.72428
Value Function Loss: 0.02579

Mean KL Divergence: 0.00617
SB3 Clip Fraction: 0.07588
Policy Update Magnitude: 0.68785
Value Function Update Magnitude: 0.51999

Collected Steps per Second: 15,974.75679
Overall Steps per Second: 7,205.21795

Timestep Collection Time: 3.13019
Timestep Consumption Time: 3.80978
PPO Batch Consumption Time: 0.50477
Total Iteration Time: 6.93997

Cumulative Model Updates: 202,190
Cumulative Timesteps: 1,686,054,990

Timesteps Collected: 50,004
--------END ITERATION REPORT--------


Saving checkpoint 1686054990...
Checkpoint 1686054990 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 106,242.35561
Policy Entropy: 3.74735
Value Function Loss: 0.02872

Mean KL Divergence: 0.00588
SB3 Clip Fraction: 0.07063
Policy Update Magnitude: 0.75677
Value Function Update Magnitude: 0.52510

Collected Steps per Second: 15,431.19359
Overall Steps per Second: 7,413.71062

Timestep Collection Time: 3.24097
Timestep Consumption Time: 3.50491
PPO Batch Consumption Time: 0.45546
Total Iteration Time: 6.74588

Cumulative Model Updates: 202,196
Cumulative Timesteps: 1,686,105,002

Timesteps Collected: 50,012
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 18,266.22849
Policy Entropy: 3.77514
Value Function Loss: 0.03141

Mean KL Divergence: 0.00881
SB3 Clip Fraction: 0.11042
Policy Update Magnitude: 0.72080
Value Function Update Magnitude: 0.59613

Collected Steps per Second: 18,590.00536
Overall Steps per Second: 9,479.28886

Timestep Collection Time: 2.69102
Timestep Consumption Time: 2.58638
PPO Batch Consumption Time: 0.29366
Total Iteration Time: 5.27740

Cumulative Model Updates: 202,202
Cumulative Timesteps: 1,686,155,028

Timesteps Collected: 50,026
--------END ITERATION REPORT--------


Saving checkpoint 1686155028...
Checkpoint 1686155028 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 158.13569
Policy Entropy: 3.82631
Value Function Loss: 0.03204

Mean KL Divergence: 0.01156
SB3 Clip Fraction: 0.15341
Policy Update Magnitude: 0.54662
Value Function Update Magnitude: 0.66882

Collected Steps per Second: 17,885.72286
Overall Steps per Second: 9,388.46683

Timestep Collection Time: 2.79597
Timestep Consumption Time: 2.53056
PPO Batch Consumption Time: 0.28523
Total Iteration Time: 5.32654

Cumulative Model Updates: 202,208
Cumulative Timesteps: 1,686,205,036

Timesteps Collected: 50,008
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 160,588.98056
Policy Entropy: 3.82417
Value Function Loss: 0.03342

Mean KL Divergence: 0.01154
SB3 Clip Fraction: 0.15180
Policy Update Magnitude: 0.44434
Value Function Update Magnitude: 0.72410

Collected Steps per Second: 20,215.32965
Overall Steps per Second: 9,727.21107

Timestep Collection Time: 2.47337
Timestep Consumption Time: 2.66685
PPO Batch Consumption Time: 0.29447
Total Iteration Time: 5.14022

Cumulative Model Updates: 202,214
Cumulative Timesteps: 1,686,255,036

Timesteps Collected: 50,000
--------END ITERATION REPORT--------


Saving checkpoint 1686255036...
Checkpoint 1686255036 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 1,591.52799
Policy Entropy: 3.82680
Value Function Loss: 0.02951

Mean KL Divergence: 0.01019
SB3 Clip Fraction: 0.13417
Policy Update Magnitude: 0.44498
Value Function Update Magnitude: 0.85525

Collected Steps per Second: 21,036.79054
Overall Steps per Second: 10,259.34537

Timestep Collection Time: 2.37850
Timestep Consumption Time: 2.49861
PPO Batch Consumption Time: 0.28194
Total Iteration Time: 4.87711

Cumulative Model Updates: 202,220
Cumulative Timesteps: 1,686,305,072

Timesteps Collected: 50,036
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 37.77170
Policy Entropy: 3.81637
Value Function Loss: 0.02787

Mean KL Divergence: 0.00632
SB3 Clip Fraction: 0.08038
Policy Update Magnitude: 0.49199
Value Function Update Magnitude: 0.86965

Collected Steps per Second: 20,977.76688
Overall Steps per Second: 10,307.14127

Timestep Collection Time: 2.38491
Timestep Consumption Time: 2.46901
PPO Batch Consumption Time: 0.28780
Total Iteration Time: 4.85392

Cumulative Model Updates: 202,226
Cumulative Timesteps: 1,686,355,102

Timesteps Collected: 50,030
--------END ITERATION REPORT--------


Saving checkpoint 1686355102...
Checkpoint 1686355102 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 66,839.16799
Policy Entropy: 3.82331
Value Function Loss: 0.02669

Mean KL Divergence: 0.00606
SB3 Clip Fraction: 0.07651
Policy Update Magnitude: 0.55468
Value Function Update Magnitude: 0.84964

Collected Steps per Second: 20,739.44827
Overall Steps per Second: 9,620.67754

Timestep Collection Time: 2.41193
Timestep Consumption Time: 2.78750
PPO Batch Consumption Time: 0.32357
Total Iteration Time: 5.19943

Cumulative Model Updates: 202,232
Cumulative Timesteps: 1,686,405,124

Timesteps Collected: 50,022
--------END ITERATION REPORT--------


--------BEGIN ITERATION REPORT--------
Policy Reward: 1,000.34087
Policy Entropy: 3.81672
Value Function Loss: 0.02751

Mean KL Divergence: 0.00469
SB3 Clip Fraction: 0.05260
Policy Update Magnitude: 0.58039
Value Function Update Magnitude: 0.90932

Collected Steps per Second: 19,524.99201
Overall Steps per Second: 9,682.70573

Timestep Collection Time: 2.56297
Timestep Consumption Time: 2.60521
PPO Batch Consumption Time: 0.29361
Total Iteration Time: 5.16818

Cumulative Model Updates: 202,238
Cumulative Timesteps: 1,686,455,166

Timesteps Collected: 50,042
--------END ITERATION REPORT--------


Saving checkpoint 1686455166...
Checkpoint 1686455166 saved!

--------BEGIN ITERATION REPORT--------
Policy Reward: 38,629.63881
Policy Entropy: 3.81855
Value Function Loss: 0.02689

Mean KL Divergence: 0.00490
SB3 Clip Fraction: 0.05654
Policy Update Magnitude: 0.62634
Value Function Update Magnitude: 0.97215

Collected Steps per Second: 20,951.83040
Overall Steps per Second: 9,592.42680

Timestep Collection Time: 2.38652
Timestep Consumption Time: 2.82613
PPO Batch Consumption Time: 0.34026
Total Iteration Time: 5.21265

Cumulative Model Updates: 202,244
Cumulative Timesteps: 1,686,505,168

Timesteps Collected: 50,002
--------END ITERATION REPORT--------


Saving checkpoint 1686505168...
Checkpoint 1686505168 saved!
